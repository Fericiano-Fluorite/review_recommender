IS,Ca not import graph containing batch sequences with states,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 3 0 0rc0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem As I'm working with sequences I make extensive use of tf contrib training batch seq with states I need to be able to load my graph afterwards so I write out a meta graph file containing a graph definition using Saver save Upon loading using tf train import meta graph I get an error hinting the batch seq with states operation is not saved in the graph Using Tensorboard I can inspect input batch seq with states InputQueueingStateSaver just fine from the same files I will for now try to work around this by writing out a separate graph that relies on placeholders for data loading instead of batch seq with states and then load the weights separate,,,2017-07-28 13:50:01,2018-01-29 17:29:02
PR,MKL Reverting the switch to max pool v2 in python,A prior commit changed python interface to call max pool v2 causing failure in MKL build Currently MKL does not support max pool v2 Reverting the commit for now will change it back when MKL implementation is complete,,agramesh1,2018-01-28 20:54:41,2018-01-29 17:46:06
PR,Add tf unravel index as an equivalent of np unravel index,This fix tries to address the issue raised in 2075 where there was no implementation of tf unravel index The tf unravel index could be quite useful in many places This fix adds the tf unravel index in CPU kernel Note order in np unravel index has not been added yet Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,yongtang,yongtang,josh11b,josh11b,yongtang,yongtang,yongtang,drpngx,yongtang,drpngx,martinwicke,yongtang,martinwicke",2017-11-27 01:14:24,2018-01-29 17:58:27
IS,Running problems when building a VGG model through tflearn on Ubuntu to train your own data,File ipython input 15 fc398a1d9321 line 1 in module runfile ' home lab326 songpeng anacoda tflearn vgg1 py' wdir ' home lab326 songpeng anacoda ' File home lab326 anaconda3 lib python3 5 site packages spyder utils site sitecustomize py line 705 in runfile execfile filename namespace File home lab326 anaconda3 lib python3 5 site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File home lab326 songpeng anacoda tflearn vgg1 py line 59 in module files extension ' jpg' filter channel True File home lab326 anaconda3 lib python3 5 site packages tflearn data utils py line 512 in image preloader flags files extension filter channel filter channel File home lab326 anaconda3 lib python3 5 site packages tflearn data utils py line 732 in directory to samples classes sorted os walk directory next 1 StopIteration from tflearn data utils import image preloader X Y image preloader files list image shape 224 224 mode 'folder' categorical labels True normalize False files extension ' jpg' filter channel True,,reedwm,2018-01-29 02:48:00,2018-01-29 19:33:05
IS,TF1 5 0 not working with CUDA 8 0,After upgrading to TF 1 5 0 when I import tensorflow it raises System Ubuntu 14 04 5 LTS 64 bit Python 2 7 6 TensorFlow tensorflow gpu 1 5 0 GPU GeForce GTX TITAN CUDA 8 0,,reedwm,2018-01-28 10:24:08,2018-01-29 19:34:12
PR,Branch 183683856,,,andrewharp,2018-01-29 18:20:43,2018-01-29 19:36:49
IS,ResourceExhaustedError when running UNET,My computer has a gpu GeForce 940MX installed It has the Memory bandwidth 16 02 GB s I'm trying to train LUNA dataset using UNET model using following code from future import print function import numpy as np from keras models import Model from keras layers import Input Conv2D MaxPooling2D UpSampling2D from keras layers import concatenate from keras optimizers import Adam from keras optimizers import SGD from keras callbacks import ModelCheckpoint LearningRateScheduler from keras import backend as K K set image dim ordering 'th' Theano dimension ordering in this code img rows 512 img cols 512 smooth 1 def dice coef y true y pred y true f K flatten y true y pred f K flatten y pred intersection K sum y true f y pred f return 2 intersection smooth K sum y true f K sum y pred f smooth def dice coef np y true y pred y true f y true flatten y pred f y pred flatten intersection np sum y true f y pred f return 2 intersection smooth np sum y true f np sum y pred f smooth def dice coef loss y true y pred return dice coef y true y pred def get unet inputs Input 1 img rows img cols conv1 Conv2D 32 3 3 activation arelu' padding isame' inputs conv1 Conv2D 32 3 3 activation arelu' padding isame' conv1 pool1 MaxPooling2D pool size 2 2 conv1 conv2 Conv2D 64 3 3 activation arelu' padding isame' pool1 conv2 Conv2D 64 3 3 activation arelu' padding isame' conv2 pool2 MaxPooling2D pool size 2 2 conv2 conv3 Conv2D 128 3 3 activation arelu' padding isame' pool2 conv3 Conv2D 128 3 3 activation arelu' padding isame' conv3 pool3 MaxPooling2D pool size 2 2 conv3 conv4 Conv2D 256 3 3 activation arelu' padding isame' pool3 conv4 Conv2D 256 3 3 activation arelu' padding isame' conv4 pool4 MaxPooling2D pool size 2 2 conv4 conv5 Conv2D 512 3 3 activation arelu' padding isame' pool4 conv5 Conv2D 512 3 3 activation arelu' padding isame' conv5 up6 merge UpSampling2D size 2 2 conv5 conv4 mode 'concat' concat axis 1 up6 concatenate UpSampling2D size 2 2 conv5 conv4 axis 1 conv6 Conv2D 256 3 3 activation arelu' padding isame' up6 conv6 Conv2D 256 3 3 activation arelu' padding isame' conv6 up7 merge UpSampling2D size 2 2 conv6 conv3 mode 'concat' concat axis 1 up7 concatenate UpSampling2D size 2 2 conv6 conv3 axis 1 conv7 Conv2D 128 3 3 activation arelu' padding isame' up7 conv7 Conv2D 128 3 3 activation arelu' padding isame' conv7 up8 merge UpSampling2D size 2 2 conv7 conv2 mode 'concat' concat axis 1 up8 concatenate UpSampling2D size 2 2 conv7 conv2 axis 1 conv8 Conv2D 64 3 3 activation arelu' padding isame' up8 conv8 Conv2D 64 3 3 activation arelu' padding isame' conv8 up9 merge UpSampling2D size 2 2 conv8 conv1 mode 'concat' concat axis 1 up9 concatenate UpSampling2D size 2 2 conv8 conv1 axis 1 conv9 Conv2D 32 3 3 activation arelu' padding isame' up9 conv9 Conv2D 32 3 3 activation arelu' padding isame' conv9 conv10 Conv2D 1 1 1 activation isigmoid' conv9 model Model inputs inputs outputs conv10 model compile optimizer Adam lr 1 0e 5 loss dice coef loss metrics dice coef return model def train and predict use existing print ' ' 30 print 'Loading and preprocessing train data ' print ' ' 30 imgs train np load C Users hirplk Desktop unet Luna2016 Lung Nodule Detection master new DATA PROCESS scratch cse dual cs5130287 Luna2016 output final trainImages npy astype np float32 imgs mask train np load C Users hirplk Desktop unet Luna2016 Lung Nodule Detection master new DATA PROCESS scratch cse dual cs5130287 Luna2016 output final trainMasks npy astype np float32 imgs test np load C Users hirplk Desktop unet Luna2016 Lung Nodule Detection master new DATA PROCESS scratch cse dual cs5130287 Luna2016 output final testImages npy astype np float32 imgs mask test true np load C Users hirplk Desktop unet Luna2016 Lung Nodule Detection master new DATA PROCESS scratch cse dual cs5130287 Luna2016 output final testMasks npy astype np float32 mean np mean imgs train mean for data centering std np std imgs train std for data normalization imgs train mean images should already be standardized but just in case imgs train std print ' ' 30 print 'Creating and compiling model ' print ' ' 30 model get unet Saving weights to unet hdf5 at checkpoints model checkpoint ModelCheckpoint 'unet hdf5' monitor 'loss' save best only True Should we load existing weights Set argument for call to train and predict to true at end of script if use existing model load weights ' unet hdf5' The final results for this tutorial were produced using a multi GPU machine using TitanX is For a home GPU computation benchmark on my home set up with a GTX970 I was able to run 20 epochs with a training set size of 320 and batch size of 2 in about an hour I started getting reseasonable masks after about 3 hours of training print ' ' 30 print 'Fitting model ' print ' ' 30 model fit imgs train imgs mask train batch size 50 epochs 10 verbose 1 shuffle True callbacks model checkpoint loading best weights from training session print ' ' 30 print 'Loading saved weights ' print ' ' 30 model load weights ' unet hdf5' print ' ' 30 print 'Predicting masks on test data ' print ' ' 30 num test len imgs test imgs mask test np ndarray num test 1 512 512 dtype np float32 for i in range num test imgs mask test i model predict imgs test i i 1 verbose 0 0 np save 'masksTestPredicted npy' imgs mask test mean 0 0 for i in range num test mean dice coef np imgs mask test true i 0 imgs mask test i 0 mean num test print Mean Dice Coeff mean if name ' main ' train and predict False But when running it using GPU I'm getting the following error Warning from warnings module File C Research Python installation lib site packages h5py init py line 36 from conv import register converters as register converters FutureWarning Conversion of the second argument of issubdtype from float to np floating is deprecated In future it will be treated as np float64 np dtype float type Using TensorFlow backend Loading and preprocessing train data Creating and compiling model Fitting model Epoch 1 10 Traceback most recent call last File C Research Python installation lib site packages tensorflow python client session py line 1327 in do call return fn args File C Research Python installation lib site packages tensorflow python client session py line 1306 in run fn status run metadata File C Research Python installation lib contextlib py line 66 in exit next self gen File C Research Python installation lib site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl ResourceExhaustedError OOM when allocating tensor with shape 50 32 512 512 Node conv2d 1 convolution Conv2D T DT FLOAT data format NCHW padding SAME strides 1 1 1 1 use cudnn on gpu true device job localhost replica 0 task 0 gpu 0 arg input 1 0 2 261 conv2d 1 kernel read Node loss mul 273 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 3022 loss mul tensor type DT FLOAT device job localhost replica 0 task 0 cpu 0 During handling of the above exception another exception occurred Traceback most recent call last File C Users hirplk Desktop unet DSB3Tutorial master tutorial code LUNA train unet py line 150 in module train and predict False File C Users hirplk Desktop unet DSB3Tutorial master tutorial code LUNA train unet py line 127 in train and predict callbacks model checkpoint File C Research Python installation lib site packages keras engine training py line 1657 in fit validation steps validation steps File C Research Python installation lib site packages keras engine training py line 1213 in fit loop outs f ins batch File C Research Python installation lib site packages keras backend tensorflow backend py line 2357 in call self session kwargs File C Research Python installation lib site packages tensorflow python client session py line 895 in run run metadata ptr File C Research Python installation lib site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File C Research Python installation lib site packages tensorflow python client session py line 1321 in do run options run metadata File C Research Python installation lib site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl ResourceExhaustedError OOM when allocating tensor with shape 50 32 512 512 Node conv2d 1 convolution Conv2D T DT FLOAT data format NCHW padding SAME strides 1 1 1 1 use cudnn on gpu true device job localhost replica 0 task 0 gpu 0 arg input 1 0 2 261 conv2d 1 kernel read Node loss mul 273 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 3022 loss mul tensor type DT FLOAT device job localhost replica 0 task 0 cpu 0 Caused by op 'conv2d 1 convolution' defined at File string line 1 in module File C Research Python installation lib idlelib run py line 124 in main ret method args kwargs File C Research Python installation lib idlelib run py line 351 in runcode exec code self locals File C Users hirplk Desktop unet DSB3Tutorial master tutorial code LUNA train unet py line 150 in module train and predict False File C Users hirplk Desktop unet DSB3Tutorial master tutorial code LUNA train unet py line 106 in train and predict model get unet File C Users hirplk Desktop unet DSB3Tutorial master tutorial code LUNA train unet py line 39 in get unet conv1 Conv2D 32 3 3 activation arelu' padding isame' inputs File C Research Python installation lib site packages keras engine topology py line 603 in call output self call inputs kwargs File C Research Python installation lib site packages keras layers convolutional py line 164 in call dilation rate self dilation rate File C Research Python installation lib site packages keras backend tensorflow backend py line 3195 in conv2d data format tf data format File C Research Python installation lib site packages tensorflow python ops nn ops py line 672 in convolution op op File C Research Python installation lib site packages tensorflow python ops nn ops py line 338 in with space to batch return op input num spatial dims padding File C Research Python installation lib site packages tensorflow python ops nn ops py line 664 in op name name File C Research Python installation lib site packages tensorflow python ops nn ops py line 131 in non atrous convolution name name File C Research Python installation lib site packages tensorflow python ops gen nn ops py line 397 in conv2d data format data format name name File C Research Python installation lib site packages tensorflow python framework op def library py line 767 in apply op op def op def File C Research Python installation lib site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File C Research Python installation lib site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 50 32 512 512 Node conv2d 1 convolution Conv2D T DT FLOAT data format NCHW padding SAME strides 1 1 1 1 use cudnn on gpu true device job localhost replica 0 task 0 gpu 0 arg input 1 0 2 261 conv2d 1 kernel read Node loss mul 273 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 3022 loss mul tensor type DT FLOAT device job localhost replica 0 task 0 cpu 0 Can someone please kindly explain me the reason behind this error ResourceExhaustedError Is it because that the memory of GPU is not enough to load the dataset This worked fine without GPU But took around 6 hours to finish one epoch,,reedwm,2018-01-28 01:43:47,2018-01-29 19:47:54
IS,Turning on grappler makes SLIM Resnet v1 50 slower on AWS K80,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source binary link here TensorFlow version use command below 1 3 the sha hash is in the link to download the binary I compiled Python version 2 7 Bazel version if compiling from source 4 5 CUDA cuDNN version cuDNN 6 CUDA 8 GPU model and memory K80 on AWS p2 8xlarge Exact command to reproduce Running SLIM from tensorflow models slim I used the following command CUDA VISIBLE DEVICES 1 python train image classifier py train dir TRAIN DIR dataset name imagenet dataset split name train dataset dir DATASET DIR model name resnet v1 50 num clones 1 optimizer sgd batch size 64 max number of steps 110 I added the following code to train image classifier py I used this binary to test and it includes the sha hash The build was done from head on 09 SEP 2017 using this command bazel build c opt copt march haswell config cuda tensorflow tools pip package build pip package For configure I did not include XLA I did all of the defaults with the exception of adding CUDA and cuDNN Nothing additional was included With out grappler I get 1 5 seconds per step and with grappler 2 0 seconds per step There is some variance of plus or minus 1 but it is definitely slower in my testing which was not expected Edited I was running v1 but I think v2 gave a very similar result,,"tfboyd,zhangyaobit,zhangyaobit,tfboyd",2017-09-09 07:07:12,2018-01-29 20:41:47
PR,remove SRU num units x shape 1 restriction,Based on the author is response the restriction is unnecessary Simply add a linear transform to the input will solve the issue 13094,,"rmlarsen,rmlarsen,rmlarsen",2018-01-25 13:06:58,2018-01-29 21:33:49
PR,Check more cpu features for Clang on Windows,Clang on Windows will define SSE SSE2 and other macros 15990,,rongjiecomputer,2018-01-28 03:08:58,2018-01-29 21:35:46
PR,Allow step callback for scipy SLSQP,This simple fix allows SLSQP method of scipy optimizer to use step callback as reported in issue 16294,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen",2018-01-23 03:56:13,2018-01-29 21:36:18
PR,contrib learn Typo in variable name x exrta x extra,flake8 testing of flake8 count select E901 E999 F821 F822 F823 show source statistics,,"cclauss,caisq,caisq,cclauss,caisq,cclauss",2018-01-27 17:58:50,2018-01-29 21:50:40
PR,Fix incorrect docs for DecodeVideoOp,This fix fixes incorrect docs for DecodeVideoOp Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-28 21:41:18,2018-01-29 21:59:09
IS,How TF Detect draw a rectangular,How TF Detect draw a rectangular I can not find the corresponding code Is it calling OpenGL to draw a rectangular,,reedwm,2018-01-11 13:12:20,2018-01-29 22:16:53
PR,Add nsync lib dep to cc library rule android tensorflow lib selective registration,The nsync lib dep is missed in rule android tensorflow lib selective registration This pr adds it,,resec,2018-01-15 01:10:32,2018-01-29 22:36:21
PR,Spelling,,,carlthome,2018-01-29 16:55:02,2018-01-29 23:06:29
IS,How to change the model without any change into android APK file,Hello I want to make an android app in this way like we can change model file anytime in future and it will not require any change into application code means no need to generate new APK file of application on any change into model In short I want to know is there anyway to place model file other then assets folder So that I can refer updated model file anytime from app Thanks Sumeet Guha,,reedwm,2018-01-09 10:46:45,2018-01-29 23:07:03
IS,Slim VGG losses increase gradually with default training configuration,Hi when I try to train imagenet with slim vgg network with default configuration The loss increases gradually from 0 1 to over 10000 I am not even able to debug this issue because all tensors losses are encapsulated inside slim Is there any way to debug this issue,,reedwm,2018-01-08 09:30:13,2018-01-29 23:13:45
PR,Fix typos 'followings' 'optionanl',,,,2018-01-29 17:26:39,2018-01-29 23:27:58
PR,Fix some typos in the documation tensorflow docs src,This fix fixes some typos in the documentation tensorflow docs src md,,imsheridan,2018-01-28 16:35:13,2018-01-29 23:28:28
IS,What is the possible op substitute for set of OPerations on CPU to DSP Hexagon,OS Ubuntu 16 04 64bits Android Version 7 1 Nougat NDK Version android ndk r12b HEXAGON SDK 3 1 nnlib source I am trying to build a graph to run on hexagon it uses few op is which hexagon does not support native graph transferer cc 109 Failed to transfer graph Invalid argument Mean has not been implemented yet OP is details are as below Mean SupportedOpType RealDiv SupportedOpType Pow SupportedOpType Conv2DBackpropInput SupportedOpType Square SupportedOpType SquaredDifference SupportedOpType StopGradient SupportedOpType Reciprocal SupportedOpType Is there any possible substitute for the operation types Mean Pow Conv2DBackpropInput etc for hexagon thanks in advance,,"petewarden,petewarden,petewarden",2017-06-16 13:36:49,2018-01-29 23:46:26
IS,Quantize weights causes accuracy to plunge when run in mobile but not in computers,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Thank you,,"Androbin,Androbin,Androbin,Androbin,martinwicke,petewarden,Androbin,aselle,aselle,petewarden",2017-06-30 16:09:20,2018-01-29 23:51:25
IS,import graph def input map not updating all attributes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Reproducible script below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary pip TensorFlow version use command below 1 2 1 Python version 3 5 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce,,"jart,mrry,petewarden",2017-07-13 21:13:34,2018-01-29 23:56:11
IS,Feature Request Kill session run process,For mobile embedded devices session run is typically initiated through a user interaction If the user presses the back button or continues to another screen before session run finishes the process is still lingering in the background wasting resources Since these devices are relatively low powered it would be great if we could cancel kill the process when it is not needed anymore,,"yaroslavvb,petewarden",2017-08-03 01:53:12,2018-01-29 23:59:14
IS,Feature Request Tensor Roll,Could you add an equivalent to Numpy roll on Tensor in tensorflow in order to allow the user to roll a Tensor along one of the axis of the tensor,,"aselle,martinwicke,asimshankar",2017-06-16 11:16:52,2018-01-30 00:03:32
PR,Tensor roll op implementation,Closes 10761 Added a tf manip roll op that works similarly to numpy is np roll This was a feature requested in 10761 and was marked as contributions welcome Usage Rolls the elements of a tensor by the offsets of shift along the dimensions of axis Elements that roll passed the last position will wrap around to the first For example I had made a pull request for this before but accidentally closed it,,"jhseu,jhseu,jhseu,yzhwang,asimshankar,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,asimshankar,rmlarsen,rmlarsen",2017-11-28 19:57:27,2018-01-30 00:03:32
IS,Quantized graph not running with commit bb88ec7ecc4dc7ba72548a5115fb86e20b14de5b,OS Ubuntu 16 04 64bits Android Version 7 1 Nougat NDK Version android ndk r12b commit bb88ec7ecc4dc7ba72548a5115fb86e20b14de5b Author Alan Yee alyee ucsd edu Date Mon Jul 24 22 46 38 2017 0700 LOG Earlier this error was not getting reported Thanks,,"petewarden,petewarden",2017-08-03 17:00:28,2018-01-30 00:05:28
PR,Fix freeze graph command line argument error,Fix TypeError main missing 1 required positional argument 'unused args' when using freeze graph command line tool pip console script entry point,,vrv,2018-01-10 00:12:56,2018-01-30 00:05:57
IS,Bug Restoring a graph created by tensorflow python tools optimize for inference has errors with RNN models,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes below OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 1 TensorFlow installed from source or binary binary TensorFlow version use command below tensorflow gpu 1 1 0 Python version 2 7 12 Bazel version if compiling from source NA CUDA cuDNN version usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61 GPU model and memory Tesla K80 24GB Exact command to reproduce see below Describe the problem I believe I have found a bug The freeze and optimize scripts appear to have bugs related to the proper function of RNNs Creating a simple RNN running the freeze script and the optimize script and then attempting to restore and use the optimized graph creates a puzzling series of errors 1 After running freeze and optimize the placeholder for sequence lengths has datatype float32 instead of tf int32 even though the placeholder specifies that it is tf int32 This breaks evaluating an instance of GRUCell which expects length to be of type tf int32 2 If I add a tf to int32 to coerce the sequence length placeholder to type tf int32 then we obtain a different error which appears to pertain to the internal operation of the tf nn dynamic rnn function Source code logs The code is divided into 2 user created scripts and 2 TF provided scripts are employed along the way The first of my scripts defines a model and saves it and is called optimize graph minimal py Then the freeze and optimize scripts are run The second of my scripts attempts to restore the model to a new Python session and this appears to be buggy This is the code I used to create and save the graph,,"angersson,angersson,ebrevdo,ebrevdo,petewarden",2017-08-09 20:29:07,2018-01-30 00:08:03
IS,When data become large parition variables can not initialized successfully,i use tensorflow to distributed trainning models i use the partition valriables to store an array data when the data is not so bigger everything looks ok but when the array data become larger when the session initialize the partition variables can not initialized and the session will wait util time out Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request the feat info can initialize successfully but the adj info cannot initialized the adj info is larger than feat info Source code logs i use ps num 4 worker num 4 and i also try some other distributed config like ps num 1 worker num 4 the result is the same source code with tf device tf train replica device setter worker device job worker task d task id cluster cluster spec feat info tf get variable feature info len id map FLAGS features column tf float32 trainable False partitioner tf fixed size partitioner num workers adj info tf get variable adj info len id map FLAGS max degree tf int64 trainable False partitioner tf fixed size partitioner num workers with tf device ' job worker task d' task id adj local tf Variable tf constant minibatch adj dtype tf int64 trainable False name adj local collections tf GraphKeys LOCAL VARIABLES feat local tf Variable tf constant features dtype tf float32 trainable False name feat local collections tf GraphKeys LOCAL VARIABLES length begin end split node by task len id map task id num workers adj tf nn embedding lookup adj info x for x in range begin end adj adj local feat tf nn embedding lookup feat info x for x in range begin end feat feat local log 2017 12 08 23 54 17 377290 I tensorflow core distributed runtime master session cc 998 Start master session c2b3ba9b700261ba with config INFO tensorflow Waiting for model to be ready Ready for local init op None ready Variables not initialized adj info part 0 adj info part 1 adj info part 2 adj info part 3 adj info part 4 adj info part 5 adj info part 6 adj info part 7 adj info part 8 adj info part 9 adj info part 10 adj info part 11 adj info part 12 adj info part 13 adj info part 14 adj info part 15 2017 12 09 00 00 35 637019 I tensorflow core distributed runtime master session cc 998 Start master session f35fcf332e3908ec with config INFO tensorflow Waiting for model to be ready Ready for local init op None ready Variables not initialized adj info part 0 adj info part 1 adj info part 2 adj info part 3 adj info part 4 adj info part 5 adj info part 6 adj info part 7 adj info part 8 adj info part 9 adj info part 10 adj info part 11 adj info part 12 adj info part 13 adj info part 14 adj info part 15 and it will alway waiting adj info to initialize,,reedwm,2017-12-08 16:03:41,2018-01-30 00:16:16
IS,When data become large parition variables can not initialized successfully,15216 i have a issue but nobody help me to solve it,,reedwm,2018-01-03 12:42:54,2018-01-30 00:17:14
IS,The problem of the tensorboard,Hi I am the newbie of the tensorflow there is a problem during learning the usage of tensorboard There is no problem with the first code compilation after start the Compiler Anaconda spyder but recompiling the code will go wrong that is very strange can anyone help me thank you very much First compilation 1 2 3 everything is ok during first compilation Second compilation 4 Something was wrong the code of the tensorflow,,,2017-12-28 12:25:23,2018-01-30 00:34:55
IS,Failed to load the native TensorFlow runtime error on Raspbian stretch,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Raspbian Strecth TensorFlow installed from source or binary Source Compiled from git on raspberry pi 3 TensorFlow version use command below 1 4 1 Python version 3 5 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source gcc version 4 8 5 Raspbian 4 8 5 4 CUDA cuDNN version No nonconfigured GPU model and memory No nonconfigured Exact command to reproduce python3 import tensorflow Hi I have compiled tensorflow is 1 4 1 source code from git source There was no error while compiling from source but after installition by pip3 I can not import tensorflow library in python3 When I gave import tensorflow command in the python 3 shell it gives this error import tensorflow Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal so undefined symbol ZN3Aws11Environment6GetEnvEPKc During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File usr local lib python3 5 dist packages tensorflow init py line 24 in module from tensorflow python import File usr local lib python3 5 dist packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 72 in module raise ImportError msg ImportError Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal so undefined symbol ZN3Aws11Environment6GetEnvEPKc Failed to load the native TensorFlow runtime See common installation problems,,,2017-12-30 14:40:22,2018-01-30 01:03:49
IS,Compile with selective register on meta file,I want to apply the selective registration feature on my model to decrease the lib size However I need to apply it on a meta file saved via saver rather than a frozen pb file as shown in many posts I have found When I try to run bazel bin tensorflow python tools print selective registration header graphs model test ckpt 390760 meta it comes to the error libprotobuf ERROR external protobuf src google protobuf wire format lite cc 621 String field 'tensorflow NodeDef op' contains invalid UTF 8 data when parsing a protocol buffer Use the 'bytes' type if you intend to send raw bytes I tried to add proto fileformat textproto but another error comes up raise self ParseError 'Expected identifier or number ' google protobuf text format ParseError 2 1 Expected identifier or number Is it even possible to do this at all The ultimate goal of compiling this lib is to restore a pretrained model and incrementally train it on Android,,,2017-12-26 13:23:09,2018-01-30 01:38:03
IS,Fatal error while compiling Tensorflow with CUDA 9 1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS GNU Linux 4 4 0 104 generic x86 64 TensorFlow installed from source or binary Source TensorFlow version use command below unknown 1 4 0 Source code is cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90 Python version 3 6 3 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source gcc version 5 4 0 20160609 CUDA cuDNN version CUDA 9 1 cuDNN 7 0 5 GPU model and memory 2 Tesla V100 PCIE 16GB Exact command to reproduce See description below Describe the problem While trying to compile the latest TensorFlow cloned from 798fa36d11119e6fdc13b90a14abfe1805e7de90 such error will be raised It turns out that in CUDA 9 1 math functions hpp is located at cuda include crt math functions hpp rather than cuda include math functions hpp CUDA 9 0 does which leads to this error ln s usr local cuda include crt math functions hpp usr local cuda include math functions hpp will fix this problem and complete the compiling process Reference Source code logs Traceback is available above,,"angersson,snnn,reedwm,nluehr,nluehr,reedwm,gunan,av8ramit",2017-12-15 09:19:39,2018-01-30 01:39:42
IS,Beam Search Decoder API,ebrevdo Why is it that the user needs to call tile batch explicitly for beam search decoders when using attention models Could not the beam search decoder internally tile the provided initial state in its constructor It seems that this API is prone to wrong usage so I'm trying to understand why it is necessary Thank you,,"eaplatanios,ebrevdo,reedwm,eaplatanios",2017-12-12 21:45:03,2018-01-30 01:55:50
IS,tf layers conv3d with channels first does not accept batch dimension to be None,code to reproduce however you might suggest a deeper fix 1 L181 L185,,"facaiy,facaiy,martinwicke,reedwm",2017-12-27 13:55:37,2018-01-30 01:58:15
IS,Source Built r1 4 on GPUs with CPU optimized is always slower than 'no cpu optimization',System information Have I written custom code Yes the model named PSIque arXiv 1711 10644 OS Platform and Distribution CentOS 7 1 CentOS 7 3 TensorFlow installed from source build w Bazel TensorFlow version 1 4 Python version Anaconda 3 6 2 Bazel version 0 8 1 GCC Compiler version if compiling from source gcc version 4 8 3 20140911 Red Hat4 8 3 9 GCC CUDA cuDNN version CUDA 8 0 r375 26 cuDNN 6 0 0 CUDA 9 0 r384 81 cuDNN 7 0 5 GPU model and memory E5 2660v3 2 Socket K40m 12GB P100 PCIE 16GB Exact command to reproduce python model py Describe the problem I built tensorflow from source for boosting operation performance 6 different distributions were built CPU only No CPU optimization NO EXTRA flags CPU only CPU optimization config opt GPU support CUDA 8 9 No CPU optimization config cuda GPU support CUDA 8 9 CPU optimization config opt config cuda Experiments were basically done by 5 phases experiments on CPU only are still going on so please focus on GPU version results Results are quite frustrating me because 'most of CPU optimized versions' gave me slow results results Test were made on multiple machine with random order P100 2 nodes K40m 7 nodes CPU only 8 nodes I am curious why CPU optimized version is slow on every experiment combinations even different GPU environments even Dual CPU socket E5 2660v3 Extra I believe my current model does not require high throughputs tf env collect sh cat etc issue Linux hostname 3 10 0 229 el7 x86 64 1 SMP Fri Mar 6 11 36 42 UTC 2015 x86 64 x86 64 x86 64 GNU Linux VERSION 7 Core VERSION ID 7 CENTOS MANTISBT PROJECT VERSION 7 REDHAT SUPPORT PRODUCT VERSION 7 are we in docker No compiler c GCC 4 8 3 20140911 Red Hat 4 8 3 9 Copyright C 2013 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux vis5 3 10 0 229 el7 x86 64 1 SMP Fri Mar 6 11 36 42 UTC 2015 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 4 0 tensorflow tensorboard 0 4 0rc3 check for virtualenv False tensorflow import tf VERSION 1 4 0 tf GIT VERSION b'unknown' tf COMPILER VERSION b'unknown' Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda lib64 usr local cuda extras CUPTI lib64 DYLD LIBRARY PATH is unset nvidia smi Sat Dec 30 12 39 08 2017 NVIDIA SMI 384 81 Driver Version 384 81 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Tesla P100 PCIE On 00000000 04 00 0 Off 0 N A 28C P0 35W 250W 0MiB 16276MiB 0 Default 1 Tesla P100 PCIE On 00000000 82 00 0 Off 0 N A 35C P0 38W 250W 15661MiB 16276MiB 19 Default Processes GPU Memory GPU PID Type Process name Usage 1 68169 C python 15643MiB cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 9 0 doc man man7 libcudart 7 usr local cuda 9 0 doc man man7 libcudart so 7 usr local cuda 9 0 lib64 libcudart so 9 0 176 usr local cuda 9 0 lib64 libcudart static a,,"reedwm,tfboyd",2017-12-30 03:46:20,2018-01-30 02:00:04
IS,Behavior change of tf app flags parsing boolean args,tf version 1 5 0 dev20171219 for example below args flags DEFINE boolean 'pre calc image feature' False '' when using tf 1 4 1 it is ok to do pre calc image feature 0 which got FLAGS pre calc image feature False But for tf 1 5 you must use pre calc image feature 0 if you still use pre calc image feature 0 then you will get FLAGS pre calc image feature True Not sure if this is a bug or just by design but personally I think tf version 1 4 1 is better handling this case,,"reedwm,yilei,reedwm,martinwicke",2017-12-20 07:22:34,2018-01-30 02:34:59
IS,deconv output length input length filter size padding stride,deconv output length input length filter size padding stride is defined here L159 When padding is valid input length max filter size stride 0 why to use max function See more details on 2118 For conv2d Even when filter size is less than stride I think output is also input stride filter stride rather input stride so why to use max,,drpngx,2018-01-29 15:12:08,2018-01-30 02:37:56
IS,Feature Suggestion Float bit strings,System information Not really relevant Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 3 6 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version 8 GPU model and memory GTX 1070 Exact command to reproduce NA Summary This proposes the use of what I call float bit strings or float bits instead of one hot encoded arrays so as to greatly reduce the memory and computational usage e g in language models I do not think this preliminary discussion belongs on StackOverflow so I hope it is OK to post it here It is a new feature that could be added to TensorFlow There is quite likely somebody on the TensorFlow dev team or in the community who has already thought of this But I have searched the internet and cannot find any mentioning of a similar idea Background I have started looking at language models using e g LSTM and encoder decoder architectures There are some aspects that seem to be incredibly wasteful and limiting Let me briefly describe this and please forgive me if I am ignorant I have only spent a week or two on studying LSTM and language models so far For example in Machine Translation we typically have the text data for the source and target languages as lists of integer tokens where each integer maps to a word in the vocabulary There may be e g 100k different words so these integer tokens can take on values between zero and 100k This data cannot be input directly to a Neural Network so we use an embedding layer to convert these integers to n dimensional vectors with values between zero and one according to a mapping function that may either be loaded from disk or trained along with the rest of the Neural Network if I understand correctly For the decoder in a language model we have a similar problem where we must somehow convert integer tokens to data that the neural network can work on A typical way of doing this seems to be a one hot encoding if I understand correctly This could also be done for the encoder part but it does not seem to be necessary I can not figure out what the max size of one hot encodings are in TensorFlow and whether it can even handle 100k one hot encoded tensors But it is obviously an extremely wasteful data mapping For example for a vocab of 100k words we only need 17 bits log2 100k to represent each integer token but for a one hot encoding using 32 bit floats we need 32 x 100k bits I can not figure out what people normally do but it seems like the common practice is to limit the vocab to a smaller number of words e g 1k or 10k It appears that Google Translate runs on multiple GPU is and maybe that is why they can handle extremely large vocabs with one hot encoded tensors Float bit strings I thought it might be possible to use a bit string like representation inside a TensorFlow model I have searched the internet and cannot find anyone who has proposed a similar idea The idea is to convert each integer token to what I call a float bit string or float bits For example the number 123 has the bit string 01111011 We can then make a corresponding tensor with floats 0 1 1 1 1 0 1 1 and input this to the TensorFlow model In a language model we would then have to input and output these float bits instead of one hot encoded arrays This would dramatically reduce the memory and computational requirements of the models Test I have hacked together a little test using numpy and Keras TensorFlow The idea is to see if we can learn to map integers x with values between 0 and 10k to y 123 x using these float bit encodings And it works as you can see by running the code further below That is perhaps not a surprise as neural networks are general function approximators but it is not always that they work according to theory However the network cannot learn the arithmetic mapping of e g y 123 x when x and y are float bits This means it cannot generalize to data it has not seen during training in the arithmetic manner we might expect But I do not think that is necessary for use in e g language models where we merely want to be able to map some tensor from e g an LSTM to an integer token from the vocabulary Loss Functions I have tested this with both MSE and binary cross entropy in Keras which unfortunately is not documented so I'm not completely sure what it does But in both cases it works and the model trains to get the bit wise mapping correct There might be cases where you are more concerned about the MSE between the actual integer values instead of their float bit string representations in which case we would need a TensorFlow method to convert float bits to integers and then take the MSE of the resulting integer and the true integer from the data set This is not relevant for language models because the proximity of integer keys do not correspond to words that are necessarily similar in meaning But it could be useful in other applications TensorFlow Implementation In order to make this work in TensorFlow it seems that we just need a couple of TensorFlow methods for converting between integers and float bit strings I have hacked this together using numpy but I'm sure somebody on the dev team can make a super fast native TensorFlow implementation Then we just need a wrapper in Keras and that might be enough to do e g language models with gigantic vocabs Test Code import numpy as np from tensorflow python keras models import Sequential from tensorflow python keras layers import InputLayer from tensorflow python keras layers import Dense from tensorflow python keras optimizers import RMSprop Number of bits to use in our float bit strings num bits 32 def int to floatbits value Convert a single integer value to an array of 0 0 and 1 0 floats corresponding to the bit string Example value 123 gives 0 0 1 1 1 1 0 1 1 Convert the integer value to a bit string NOTE This has been fixed to 32 bit length bitstr 0 032b format value Convert the bit string to an array of equivalent float values floatbits np array 1 0 if bit '1' else 0 0 for bit in bitstr return floatbits def floatbits to strbits floatbits Convert an array of floats to a bit string A float value greater than 0 5 results in 1 0 and a float value less or equal to 0 5 results in 0 0 Example 0 1 0 49 0 51 0 9 1 1 2 3 gives 001110 Convert the float array to a list of bit characters '0' or '1' charbits '1' if floatbit 0 5 else '0' for floatbit in floatbits Convert the bit characters to a string strbits join charbits return strbits def floatbits to int floatbits Convert a float array to an integer assuming each element of the float array corresponds to a bit Example 0 1 0 49 0 51 0 9 1 1 2 3 corresponds to the bit string 001110 which is the integer 14 Convert the float array to a bit string strbits floatbits to strbits floatbits floatbits Convert the bit string to an integer value value int strbits base 2 return value Various tests of the above functions if True foo int to floatbits 123 print foo print floatbits to strbits foo print floatbits to int foo bar 0 3 0 9 0 8 0 51 0 501 0 4999 0 999 1 1 print floatbits to strbits bar print floatbits to int bar baz 0 1 0 49 0 51 0 9 1 1 2 3 print floatbits to strbits baz print floatbits to int baz quit We will now train a TensorFlow Keras model that maps integers between 0 and 10000 to the same numbers multiplied by 123 If we were to use one hot encoding then we would need 10000 inputs to the Neural Network and 1230000 outputs if using the full output range Using bit strings encoded as floats we only need 14 bits for the input and 21 bits for the output We round it up to 32 bits The dataset as integers we want the Neural Network to map from x to y x int np arange 10000 dtype int y int 123 x int Convert the dataset to float bit strings aka float bits x np array list map int to floatbits x int y true np array list map int to floatbits y int Check the mapping is correct E g if the number of required bits exceeds num bits then these may not create numpy matrices correctly if False print x shape print y true shape print x 0 10 print y true 0 10 Start construction of the Keras Sequential model model Sequential Add an input layer to the model model add InputLayer input shape num bits Fully connected dense layers with ReLU activation model add Dense 512 activation arelu' model add Dense 512 activation arelu' Last fully connected dense layer with sigmoid activation so the output is between 0 0 and 1 0 model add Dense num bits activation isigmoid' optimizer RMSprop lr 1e 3 if True Loss is MSE model compile optimizer optimizer loss 'mean squared error' else Loss is Binary Crossentropy but also report MSE model compile optimizer optimizer loss 'binary crossentropy' metrics 'mse' epochs 50 if True Fit the model using the entire data set model fit x y true epochs epochs else Fit the model using the data set split into training and validation You will see that the validation error is high so the model has not learned the arithmetic function of the data set model fit x y true epochs epochs validation split 0 2 Use the model to predict the output for a part of the data set y pred model predict x 0 10 The true output for this part of the data set y true subset y true 0 10 Map the float bit strings to integers y pred int list map floatbits to int y pred y true int list map floatbits to int y true subset Print the predicted and true integers print zip y pred int y true int Round the float bit strings to 2 decimals for pretty printing def rounded numbers return np array 2f format x for x in row for row in numbers y pred rounded rounded y pred y true rounded rounded y true subset Print the predicted and true float bit strings I know it is bad to reuse the same variable names here for y pred int y true int y pred rounded y true rounded in zip y pred int y true int y pred rounded y true rounded print y true int t y true rounded print y pred int t y pred rounded print Output True integer and true float bit string note that the numbers are all exactly 0 00 or 1 00 738 '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '1 00' '0 00' '1 00' '1 00' '1 00' '0 00' '0 00' '0 00' '1 00' '0 00' Predicted integer and predicted float bit string note that the numbers a not all exactly 0 00 or 1 00 738 '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 00' '0 03' '0 00' '0 00' '0 00' '0 01' '0 00' '0 00' '0 00' '0 00' '0 99' '0 00' '1 00' '1 00' '1 00' '0 00' '0 00' '0 00' '1 00' '0 00',,"drpngx,drpngx",2018-01-27 15:23:29,2018-01-30 03:22:21
IS,Feature request Have Estimator display Loss and Metrics for Every Epoch and not Every Step,Most of the papers I ve read measure the time it takes to train a model with every epoch and not every step If it isn t possible to display the loss only for every epoch I think it would be nice to print when an epoch has passed,,"selcouthlyBlue,drpngx",2018-01-28 00:03:46,2018-01-30 03:31:05
IS,how to install ffmpeg in tensorflow 1 4 binary,hi i want to install ffmpeg in tensorflow 1 4 binary python 3 5 on ubuntu 16 04 please help me how do i do the output type python c from tensorflow contrib import ffmpeg is ok dont have anly error but i dont know why from tensorflow contrib import ffmpeg i get error from tensorflow contrib import ffmpeg File stdin line 1 from tensorflow contrib import ffmpeg IndentationError unexpected indent,,drpngx,2018-01-28 07:56:25,2018-01-30 03:34:18
PR,Support optionally passing mode to GANEstimator discriminator fn,This fulfills a feature request,,joel-shor,2018-01-30 03:35:07,2018-01-30 03:38:12
PR,Add options to enable new features for cloud tpu profiler,Add options for the user to manually include dataset ops in trace collection and to automatically recapture the traces when no trace event is collected Also change tf flags to absl flags since the former is going to be deprecated,,gunan,2018-01-29 17:28:23,2018-01-30 06:58:20
PR,Fix typo,fix typo,,ManHyuk,2018-01-30 00:49:28,2018-01-30 06:59:06
PR,Fixing hard sigmoid is documentation to match impl,,,rmlarsen,2018-01-26 21:25:42,2018-01-30 07:15:07
IS,Read tflite file failed on iOS,Hi I tried the examples on iOS according to TF Lite guide but failed when assign data to tflite because address out is NULL probably my tflite file is incorrect but I am not sure can anybody give some help My test step is as follows 1 Try the following code get the tflite file converteds model tflite So my questions are 1 The tflite created above is right or not 2 The reading tflite code is right or not 2 If the tflite file is not right do I must create tflite with pb ckpt and FrozenGraphDef mentioned in guide Thanks,,asimshankar,2017-12-26 07:37:09,2018-01-30 07:26:52
IS,java lang InternalError Cannot find requested resource bundle for locale en US,bazel version 0 9 0 java version 1 8 0 161 os Ubuntu 16 Building tensorflow examples android libtensorflow demo jar 24 source files failed Exit 1 java lang InternalError Cannot find requested resource bundle for locale en US,,,2018-01-25 03:29:34,2018-01-30 07:48:01
IS,tf contrib metrics streaming precision raise an exception Attempting to use uninitialized value model precision true positives count,Please go to Stack Overflow for help and support System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-30 08:36:54,2018-01-30 08:37:05
IS,Feature Request Separated Name Spaces of RNN Cells for hidden weights and recurrent states,This feature request is based on the following question of StackOverflow if it is not appropriate I will close this issue placeholders inputs tf placeholder tf float32 shape None None 1000 cell tf nn rnn cell BasicLSTMCell 80 outs states tf nn dynamic rnn cell cell inputs placeholders inputs dtype tf float32 This graph building gives us tf global variables list as follows tf Variable 'rnn basic lstm cell kernel 0' shape 1080 320 dtype float32 ref tf Variable 'rnn basic lstm cell bias 0' shape 320 dtype float32 ref The proposed new feature separates two name spaces of kernel hidden weights and recurrent states The expected tf gloabal variables list with new feature is as follows tf Variable 'rnn basic lstm cell kernel hidden weights 0' shape 1000 320 dtype float32 ref tf Variable 'rnn basic lstm cell kernel recurrent state 0' shape 80 320 dtype float32 ref tf Variable 'rnn basic lstm cell bias 0' shape 320 dtype float32 ref In the new feature a kernel name space has two sub spaces rnn basic lstm cell kernel hidden weights rnn basic lstm cell kernel recurrent state,,,2018-01-30 02:55:48,2018-01-30 09:12:02
IS,DownloadfileTask Failed,try projrct as android sample apps but downloadtask failed then solve it may be you shoule change the download models gradle classpath woulde undercouch gradle download task 3 2 0' to 3 3 0,,,2018-01-09 03:37:07,2018-01-30 10:07:20
IS,Different result between python and C with same pb file and same data,I got different result between python and C using same pb file and same data I print result below the fisrt 10000 number is diff is close to zero but it is get bigger then line C result Python result diff sum diff 0 0 010966 0 010966 0 000000 0 000000 1 0 050666 0 050666 0 000000 0 000000 2 0 007573 0 007573 0 000000 0 000000 3 0 498266 0 498266 0 000000 0 000000 4 0 079290 0 079290 0 000000 0 000000 5 0 044778 0 044778 0 000000 0 000000 6 0 003472 0 003472 0 000000 0 000000 7 0 542518 0 542518 0 000000 0 000000 8 0 087951 0 087951 0 000000 0 000000 9 0 035723 0 035723 0 000000 0 000000 10000 0 041655 0 041655 0 000001 0 000050 10001 0 059743 0 059742 0 000001 0 000049 10002 0 003410 0 003410 0 000000 0 000049 10003 0 671292 0 671294 0 000001 0 000048 10004 0 117169 0 117170 0 000001 0 000047 10005 0 144822 0 144821 0 000001 0 000045 10006 0 001332 0 001332 0 000000 0 000045 10007 0 795729 0 795729 0 000001 0 000045 10008 0 058562 0 058562 0 000000 0 000045 10009 0 080222 0 080223 0 000000 0 000045 40000 0 056272 0 261853 0 318125 83 999641 40001 0 001396 0 006732 0 005336 83 994308 40002 0 000540 0 004921 0 005461 83 999771 40003 0 601443 0 382969 0 218474 83 781296 40004 0 088934 0 222222 0 311156 83 470139 40005 0 048725 0 100866 0 052141 83 417999 40006 0 002078 0 011184 0 009106 83 427109 40007 0 652765 0 507083 0 145682 83 281425 40008 0 079999 0 267384 0 347384 82 934044 40009 0 027125 0 091063 0 118188 82 815857 64470 0 001395 0 003402 0 002008 673 607727 64471 0 001808 0 013858 0 012051 673 619751 64472 0 003523 0 001226 0 004749 673 624512 64473 0 001785 0 015721 0 013935 673 610596 64474 0 001010 0 002219 0 003228 673 613831 64475 0 000174 0 000121 0 000053 673 613770 64476 0 002843 0 005779 0 002935 673 610840 64477 0 002199 0 007970 0 010169 673 621033 64478 0 002163 0 000151 0 002314 673 618713 64479 0 018321 0 215750 0 197428 673 421265,,,2018-01-30 09:49:12,2018-01-30 12:08:43
IS,Failed to build error mismatched argument pack lenghts,System information OS Platform and Distribution e g Linux Ubuntu 16 04 4 14 13 1 ARCH TensorFlow installed from source or binary git Python version 3 6 4 Bazel version if compiling from source 0 9 0 1 GCC Compiler version if compiling from source 6 4 1 CUDA cuDNN version 9 1 85 1 7 0 5 2 Exact command to reproduce configure bazel build config opt config cuda jobs 12 tensorflow tools pip package build pip package Describe the problem failed to build Source code logs usr lib gcc x86 64 pc linux gnu 6 4 1 include c tuple 489 65 error mismatched argument pack lengths while expanding istd is convertible UElements Elements ' return and is convertible UElements Elements value usr lib gcc x86 64 pc linux gnu 6 4 1 include c tuple 490 1 error body of constexpr function istatic constexpr bool std TC anonymous Elements ImplicitlyMoveConvertibleTuple with UElements const std tuple tensorflow VariantBinaryOp tensorflow StringPiece tensorflow StringPiece bool anonymous true Elements tensorflow VariantBinaryOp tensorflow StringPiece tensorflow StringPiece ' not a return statement ERROR home user dev git tensorflow tensorflow core kernels BUILD 1884 1 output 'tensorflow core kernels objs list kernels gpu tensorflow core kernels list kernels cu pic o' was not created ERROR home user dev git tensorflow tensorflow core kernels BUILD 1884 1 not all outputs were created or valid Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 29 727s Critical Path 28 35s FAILED Build did NOT complete successfully,,drpngx,2018-01-19 17:10:53,2018-01-30 14:32:42
IS,There is no problem running on window and there is a problem on Ubuntu,Traceback most recent call last File ipython input 1 fc398a1d9321 line 1 in module runfile ' home lab326 songpeng anacoda tflearn vgg1 py' wdir ' home lab326 songpeng anacoda ' File home lab326 anaconda3 lib python3 5 site packages spyder utils site sitecustomize py line 705 in runfile execfile filename namespace File home lab326 anaconda3 lib python3 5 site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File home lab326 songpeng anacoda tflearn vgg1 py line 59 in module files extension ' jpg' filter channel True File home lab326 anaconda3 lib python3 5 site packages tflearn data utils py line 512 in image preloader flags files extension filter channel filter channel File home lab326 anaconda3 lib python3 5 site packages tflearn data utils py line 732 in directory to samples classes sorted os walk directory next 1 StopIteration There is no problem running on window and there is a problem on Ubuntu code from tflearn data utils import image preloader data dir home songpeng dataset X Y image preloader data dir image shape 224 224 mode 'folder' categorical labels True normalize True files extension ' jpg' filter channel True,,reedwm,2018-01-30 09:31:33,2018-01-30 18:38:58
PR,Merge pull request 1 from tensorflow master,merge upstream changes,,rmlarsen,2018-01-30 19:00:14,2018-01-30 19:00:27
PR,Branch 183846994,,,rmlarsen,2018-01-30 19:03:17,2018-01-30 19:04:28
IS,ou must feed a value for placeholder tensor 'import Placeholder when i test my frozen model,Hello I trying create mobile app for object recognition for my own created model I fallow this tutorial 2 But when i even get a testing model from step 3 i get error,,reedwm,2018-01-28 16:15:22,2018-01-30 19:10:44
PR,Update README md,added a friendly badge to get the latest android tensorflow version,,,2018-01-29 23:20:34,2018-01-30 19:10:57
PR,Branch 183846994,,,rmlarsen,2018-01-30 19:13:26,2018-01-30 19:14:23
IS,seg fault training tf nn conv3d with minibatch size 2,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code You can find it here OS Platform and Distribution e g Linux Ubuntu 16 04 SUSE Linux 12 2 TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 3 0 rc1 3112 g65b6a75' '1 4 0 rc0' Note this is NOT compiled with the Intel MKL options Python version 2 7 13 Bazel version if compiling from source 0 6 0 GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version N A GPU model and memory N A Running on x86 64 Intel Haswell node Exact command to reproduce See README in Describe the problem A seg fault when training a tf nn conv3d with minibatch size more than 2 on a single Intel Haswell The seg fault occurs at line 187 L187 Source code logs GDB log It looks like some kind of cyclic dependency in Eigen TensorEvaluator,,"facaiy,tatatodd,tatatodd,reedwm",2017-11-22 20:05:42,2018-01-30 19:26:40
IS,bazel build ask for ANDROID NDK HOME ANDROID SDK HOME no way to disable it,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 5 0 rc0 1 g793280a' '1 5 0 rc0' Python version 2 7 Bazel version if compiling from source On machines with AVX2 everything is fine Further there is no way to skip to setup ANDROID NDK HOME ANDROID SDK HOME I manually uncommented this in configure py edit I am willing to provide a pull request for configure py adding something like TF NEED ANDROID,,"shivaniag,gunan,angersson,reedwm",2018-01-10 14:10:14,2018-01-30 19:31:57
PR,Moving code using new in the linear algebra kernels to absl make unique This should make cleaning,Moving code using new in the linear algebra kernels to absl make unique This should make cleaning this up when std make unique is available with automatic tooling easier and remove references to new,,,2018-01-30 19:55:53,2018-01-30 19:59:55
IS,cmake compile error C2678 binary ' ' no operator found sparse column iterable cc,cmake A x64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE C ProgramData chocolatey bin swig exe DPYTHON EXECUTABLE C Python36 python exe DPYTHON LIBRARIES C Python36 libs python36 lib Dtensorflow WIN CPU SIMD OPTIONS arch AVX2 Windows 8 1 x64 cmake 3 10 1 swig 3 0 9 Visual Studio 2017 Community the same problem asked,,reedwm,2018-01-07 12:22:32,2018-01-30 19:59:57
PR,Merge in final changes from the r1 5 branch,,,angersson,2018-01-30 19:11:32,2018-01-30 20:20:26
PR,Fix typo,fix typos,,ManHyuk,2018-01-30 12:47:59,2018-01-30 20:20:47
IS,Feature Request enable rechanging tf device of a tensor,It seems that once a tensor is GPU was defined using tf device the GPU cannot be changed anymore When loading saved graphs the graph will use the same GPU that was chosen years ago and it cannot be set again thanks,,"angersson,ppwwyyxx,reedwm,mrry",2017-12-13 15:01:38,2018-01-30 20:45:09
IS,saved model pb needs a different file extension,isaved model pb' file extension type clashes with every other ' pb' file created Apps that register the ' pb' file extension wo not be able to tell apart Saved Models from other protobuf files,,"reedwm,mrry,mrry,nfiedel,reedwm",2017-12-02 20:52:21,2018-01-30 21:16:42
IS,tensorflow contrib lite kernels resize bilinear cc 42 NumInputs node 1 2 1,System information Have I written custom code Yes OS Platform and Distribution Ubuntu14 04 TensorFlow installed from source build w Bazel TensorFlow version 1 4 Python version Anaconda 3 5 2 Bazel version 0 9 0 GCC Compiler version if compiling from source gcc version 4 8 4 CUDA cuDNN version Not relevant GPU model and memory Not relevant Exact command to reproduce Not relevant Describe the problem I construct a network with only bilinear resize operation I use the tf image resize bilinear and add operation and convert it to a tflite model successfully However when I run the tflite mode it comes to the errors as follows java lang NullPointerException Can not allocate memory for the given inputs tensorflow contrib lite kernels resize bilinear cc 42 NumInputs node 1 2 1 I find the code line in resize bilinear cc 42 as follows TF LITE ENSURE EQ context NumInputs node 1 Is it right to modify the code line to TF LITE ENSURE context NumInputs node 1 NumInputs node 2 Source code logs def network img tf placeholder name 'img' dtype tf float32 shape 1 100 100 3 img tf layers conv2d img 3 3 3 padding isame' name 'conv1' img tf image resize bilinear img 200 200 var tf get variable 'weights' dtype tf float32 shape 1 200 200 3 val img var out tf identity val name 'out',,,2018-01-04 03:42:09,2018-01-30 22:09:50
IS,Description in docs of one hot vector for mnist deep example confusing and or wrong,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow n a OS Platform and Distribution e g Linux Ubuntu 16 04 Windows TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 3 6 4 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce n a You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Documentation found at describes one of the two parameters passed to the training process as a 2d tensor of one hot 10 dimensional vectors specifying the classes of the samples in the other 2d tensor parameter But clearly the placeholders define 2d and 1d tensors not 2d and 2d There is no one hot representation used at all as far as I can tell by using print statements if the class if a sample is class 3 then the corresponding entry is simple 3 not the one hot representation of it If this class is subsequently converted into a one hot representation it does not happen in the mnist deep py source file I'm too much of a beginner to say what the documentation should say but it seems at best confusing and at worst completely wrong Source code logs n a,,"reedwm,reedwm",2018-01-30 22:19:50,2018-01-30 23:11:10
IS,A bug when applying MultiRNNCell,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow This code is very similar to an official example OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below b'unknown' 1 4 0 Python version Python 3 5 2 Anaconda 4 2 0 64 bit Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem tf nn MultiRNNCell sometimes does not work It raises an issue like this ValueError Dimensions must be equal but are 64 and 96 for 'lstm rnn while rnn multi rnn cell cell 0 cell 0 basic lstm cell MatMul 1' op 'MatMul' with input shapes 128 64 96 128 Source code logs import tensorflow as tf import numpy as np hidden layer size 32 embed tf zeros 128 6 64 dtype tf float32 num LSTM layers 2 with tf variable scope lstm lstm cell tf contrib rnn BasicLSTMCell hidden layer size forget bias 1 0 cell tf contrib rnn MultiRNNCell cells lstm cell num LSTM layers state is tuple True outputs states tf nn dynamic rnn cell embed dtype tf float32 Error ValueError Dimensions must be equal but are 64 and 96 for 'lstm rnn while rnn multi rnn cell cell 0 cell 0 basic lstm cell MatMul 1' op 'MatMul' with input shapes 128 64 96 128,,facaiy,2018-01-17 09:23:15,2018-01-30 23:31:09
PR,Branch 183881907,,,"rmlarsen,yifeif,rmlarsen",2018-01-30 22:12:40,2018-01-30 23:33:14
IS,tfdbg error Dump root directory does not exist with empty fetches,System information Have I written custom code yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary pip install TensorFlow version tensorflow import tf VERSION 1 4 1 tf GIT VERSION v1 4 0 19 ga52c8d9 tf COMPILER VERSION v1 4 0 19 ga52c8d9 Sanity check array 1 dtype int32 Python version 2 7 12 CUDA cuDNN version cuda libs usr local cuda 9 0 targets x86 64 linux lib libcudart static a usr local cuda 9 0 targets x86 64 linux lib libcudart so 9 0 176 usr local cuda 9 0 doc man man7 libcudart so 7 usr local cuda 9 0 doc man man7 libcudart 7 usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61 usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 GPU model and memory GeForce GTX 1080 8114MiB Exact command to reproduce see code below Describe the problem LocalCLIDebugWrapperSession run does not behave like tf Session run if there are no fetches The dump directory will never be created and it crashes with an IOError For me this issue occured in a situation like this,,caisq,2018-01-05 15:34:48,2018-01-30 23:34:01
PR,Branch 183846994,,,"case540,case540,rjpower,case540",2018-01-30 18:37:36,2018-01-30 23:43:41
IS,Successful Local Build of Tensorflow r1 5 GPU for Python 3 6 CUDA Toolkit 9 0 and CUDNN 7 0 on Windows 7 X64 SP1 using CMake in VS 2015 Update 3,I have spent a week trying to compile Tensorflow from source using Bazel on Windows with no success In 2 days I was able to compile it using CMake following the command output from a successful build I saw on Jenkins on 02 Jan 2018 I wanted to provide details to spare others the pain of development in the future The whole build took 6 hours to compile on my system I have an older system which is why I was doing this You will need to path variables in the attached scripts to work with the path variables for your system For the most part however the scripts replicate what is mentioned on github here System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 x64 SP1 TensorFlow installed from source or binary Source TensorFlow version use command below r1 5 0 rc0 Python version 3 6 4 CMake version if compiling from source CMake 3 10 1 GCC Compiler version if compiling from source cl exe Visual Studio 2015 Update 3 CUDA cuDNN version 9 0 176 7 0 4 GPU model and memory NVIDIA Quadro K4000 P8 Driver 385 54 3072 MiB SWIG Version swigwin 3 0 12 Git Version Git for Windows 2 15 1 64 bit MSBuild Version 14 0 25420 1 CPU Intel Xeon E5 2620 v2 Exact command to reproduce After installing the above I wrote a batch script to set and clean up system environment variables please see attached script Due to the 1024 character limit for PATH on windows I manually edited the PATH in the registry editor to overcome this limitation I then wrote another script that set local variables cloned tensorflow source and checked out version 1 5 then prepared the source with cmake and compiled with msbuild The final output was a python wheel which I pip installed I successfully ran the standard hello world script without error i e as well as a small AlexNet network without issues I hope this helps future users and further emphasizes that it is possible to build Tensorflow 1 5 for GPU on Windows 7 I have not compiled this with AVX support but that could be a next improvement I'm not sure if this is possible I only know MKL support is limited to Linux at the moment However Windows binaries for MKL and MPI can be downloaded from the Intel website Scripts zip,,"drpngx,MarkDaoust",2018-01-05 18:50:07,2018-01-31 00:41:51
IS,Change GitHub repo URL from to,Reasoning HTTPS all the things,,"drpngx,martinwicke,martinwicke",2018-01-05 22:24:22,2018-01-31 00:52:25
IS,InvalidArgumentError slice index 0 of dimension 0 out of bounds,Hi Describe the problem I am trying to encode and decode an image using tf image decode jpeg and b64 encoding The code is so simple but it seems I have an error regarding StrideSlice I am not sure if the problem coming from the undefined shape of input placeholder or related to jpeg decode Thanks Source code logs System information TF version 1 4 0 Linux Ubuntu 16 04 Python version 2 7 No CUDA or GPU,,,2017-12-21 23:52:52,2018-01-31 02:18:22
IS,tf argmax appears to be functioning incorrectly on occasion,EDIT Link to script and input label data as pickle files to reproduce the error System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I have written my own code My code base data set and batch generating algorithm are quite large so I am attempting to illustrate this as best as possible If no mistake of mine can be seen in this post and the examples I have given then I will provide further code data I have asked on StackOverflow but have got not replies If I am missing something simple then I'm sure it would have been pointed out on StackOverflow by now OS Platform and Distribution e g Linux Ubuntu 16 04 Manjaro 17 1 3 Kernel 4 14 TensorFlow installed from source or binary python pip TensorFlow version use command below tensorflow gpu 1 5 0 Python version 3 6 4 CUDA cuDNN version CUDA 9 0 cuDNN 7 0 GPU model and memory Nvidia GeForce GTX 1050 8GB Describe the problem tf argmax seems to be occasionally producing incorrect results when used on the last axis of a 3 dimensional tensor Source code logs To debug this I have printed out the following operations,,"drpngx,drpngx,drpngx",2018-01-29 22:34:01,2018-01-31 02:34:55
IS,CIFAR10 slows down every 100th step,System information Have I written custom code No OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from Have tried both binary and source TensorFlow version 1 4 0 19 ga52c8d9 1 4 1 Python version 2 7 12 CUDA cuDNN version 8 0 61 Hardware GPU NVIDIA GeForce GTX 1080 Ti 11GB RAM 64GB CPU Intel i7 6850K Exact command to reproduce python cifar10 train py Describe the problem The CIFAR10 Tensorflow tutorial seems to have a few odd patterns when it comes to the number of examples per second it can compute Step 0 is extremely slow Every 100th step is significantly slow The step after a really slow step is either a little slow or average The next 10 30 steps after that are slightly boosted faster than average The rest of the steps are average speed I'm hoping for in order of importance An explanation and fix for every 100th step being so slow An explanation and instructions showing me how to make every step run at the boosted speed the speed shortly after a slow step An explanation and fix for the slow 0th and 1st step I can not find any additional logging or processing that happens on every 100th step Could it be tf train MonitoredSession Reproducible when training on CPU rather than GPU independent of batch size on MacBook Pro Retina 13 inch Mid 2014 Hardware utilization 1 Average CPU 82 84 GPU 70 85 RAM 3 7GB 2 Every 100th step CPU 9 GPU 0 RAM 3 7GB 3 Boosted after slow step GPU 92 CPU 82 84 RAM 3 7GB 4 Idle CPU 1 GPU 0 RAM 1 6GB Overall CPU and RAM usage clearly showing CPU trough every 100 steps Overall CPU and RAM usage Logs excerpt full logs step 0 587 3 examples sec 6 974 sec batch step 1 22630 6 examples sec 0 181 sec batch step 2 36253 6 examples sec 0 113 sec batch step 3 37966 0 examples sec 0 108 sec batch step 4 38511 4 examples sec 0 106 sec batch step 5 38554 6 examples sec 0 106 sec batch step 6 32112 4 examples sec 0 128 sec batch step 7 38912 4 examples sec 0 105 sec batch step 8 39377 0 examples sec 0 104 sec batch step 9 38206 2 examples sec 0 107 sec batch step 10 38222 1 examples sec 0 107 sec batch step 11 38757 5 examples sec 0 106 sec batch step 12 38833 1 examples sec 0 105 sec batch step 13 39774 8 examples sec 0 103 sec batch step 14 39795 9 examples sec 0 103 sec batch step 15 37850 5 examples sec 0 108 sec batch step 16 38443 5 examples sec 0 107 sec batch step 17 39194 6 examples sec 0 105 sec batch step 18 39164 0 examples sec 0 105 sec batch step 19 39057 5 examples sec 0 105 sec batch step 20 33268 7 examples sec 0 123 sec batch step 21 39459 7 examples sec 0 104 sec batch step 22 39336 2 examples sec 0 104 sec batch step 23 39207 1 examples sec 0 104 sec batch step 24 39330 5 examples sec 0 104 sec batch step 25 38783 9 examples sec 0 106 sec batch step 26 39038 9 examples sec 0 105 sec batch step 27 39214 2 examples sec 0 104 sec batch step 28 39525 9 examples sec 0 104 sec batch step 29 37209 0 examples sec 0 110 sec batch step 30 38356 7 examples sec 0 107 sec batch step 31 36077 0 examples sec 0 114 sec batch step 32 37143 8 examples sec 0 110 sec batch step 33 35961 1 examples sec 0 114 sec batch step 34 33378 4 examples sec 0 123 sec batch step 35 37830 3 examples sec 0 108 sec batch step 36 36789 5 examples sec 0 111 sec batch step 37 36638 2 examples sec 0 112 sec batch step 38 36848 1 examples sec 0 111 sec batch step 39 36041 4 examples sec 0 114 sec batch step 40 36612 0 examples sec 0 112 sec batch step 41 35623 9 examples sec 0 115 sec batch step 42 37589 3 examples sec 0 109 sec batch step 43 37462 9 examples sec 0 109 sec batch step 44 35823 6 examples sec 0 114 sec batch step 45 35911 8 examples sec 0 114 sec batch step 46 36073 8 examples sec 0 114 sec batch step 47 36930 2 examples sec 0 111 sec batch step 48 36142 9 examples sec 0 113 sec batch step 99 36434 8 examples sec 0 112 sec batch step 100 1215 0 examples sec 3 371 sec batch step 101 35952 9 examples sec 0 114 sec batch step 102 38422 5 examples sec 0 107 sec batch step 103 39315 8 examples sec 0 104 sec batch step 104 38989 1 examples sec 0 105 sec batch step 105 39091 4 examples sec 0 105 sec batch step 106 39247 6 examples sec 0 104 sec batch step 107 38009 7 examples sec 0 108 sec batch step 108 38746 7 examples sec 0 106 sec batch step 109 39505 4 examples sec 0 104 sec batch step 110 39340 0 examples sec 0 104 sec batch step 111 39065 0 examples sec 0 105 sec batch step 112 38561 1 examples sec 0 106 sec batch step 113 39109 0 examples sec 0 105 sec batch step 114 39203 7 examples sec 0 104 sec batch step 115 39144 4 examples sec 0 105 sec batch step 116 38317 6 examples sec 0 107 sec batch step 117 33757 5 examples sec 0 121 sec batch step 118 34115 4 examples sec 0 120 sec batch step 119 35671 4 examples sec 0 115 sec batch step 120 35297 2 examples sec 0 116 sec batch step 121 36152 8 examples sec 0 113 sec batch step 122 35780 1 examples sec 0 114 sec batch step 123 35847 1 examples sec 0 114 sec batch step 124 36888 9 examples sec 0 111 sec batch step 125 36946 2 examples sec 0 111 sec batch,,"skye,nealwu,nealwu,drpngx,tfboyd,drpngx",2017-12-31 09:02:50,2018-01-31 02:39:47
IS,Maven Version of tensorflow Java API jar wrongly updated in Documentation,System information Have I written custom code N A OS Platform and Distribution N A TensorFlow installed from N A TensorFlow version N A Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem shows maven version as 1 4 1 However this version is not available in public maven Repositories Only versions 1 3 0 1 4 0 1 4 0 rc0 and 1 5 0 rc0 are available Please correct documentation or release 1 4 1 Versions Source code logs N A,,"drpngx,asimshankar",2018-01-09 09:44:50,2018-01-31 02:51:10
IS,Feature Request clarify supported environments for official binaries,As it stands now binary release of TensorFlow 1 5 is set to drop compatibility with Ubuntu 14 04 and compatibility with Debian Linux distros such as Amazon Linux AMI ImportError lib64 libm so 6 version GLIBC 2 23' not found To avoid surprise TensorFlow should either 1 Follow other open source projects like Ray PyTorch and provide official binaries for these systems or 2 Document that support is dropped to encourage other players ie AWS to take over the job of providing these binaries,,"yaroslavvb,martinwicke,yongtang,yaroslavvb,jart,yaroslavvb,yaroslavvb,yongtang,drpngx,yaroslavvb,martinwicke",2018-01-11 18:13:57,2018-01-31 04:22:09
IS,Feature Request Sparse compute gradient,I am working on an extremely large scale linear model and have been trying to optimize the performance of the TF optimizer Have I written custom code Version I My feature size is huge 500Mil and sparse so I was testing if I could make TF only compute the necessary gradients and apply it using some function like tf scatter sub My graph is like this OS Platform and Distribution Centos Linux version 3 10 0 229 4 2 el7 x86 64 gcc version 4 8 2 20140120 Red Hat 4 8 2 16 GCC TensorFlow installed from source or binary pip install tensorflow TF version 1 3 0 Python version 2 7 5 Bazel version CUDA cuDNN GPU model and memory Exact command to reproduce N A Also there might be a potential bug If in the second approach tf gather and tf segment sum I replace GradientDescentOptimizer with Adam or Adagrad optimizer the memory would blow up very quickly I did not look into why that happened so I am not sure if this worth a bug ticket,,drpngx,2017-12-19 00:42:07,2018-01-31 08:10:18
PR,Increase tolerance in losses impl test py fixes 16238,,,"joel-shor,rmlarsen",2018-01-24 07:53:22,2018-01-31 15:24:35
IS,after ops to register h changed IOS camera example still return No OpKernel support 'Less' op,System information Run on MacOS 10 12 Xcode 8 3 3 Python 3 5 tensorflow 1 2 1 installed with anaconda bazel 0 5 2 homebrew Main Problem Although I changed ops to register h file and recompile the static library IOS camera example code still returned No OpKernel support 'Less' op error The same library works fine in another project JieHe is ios tensorflow object detection project when I replace the model load the model I can not tell why I got the issues with official tensorflow ios code Describe the problem I trained my model based on the ssd mobilenet network T hen the model was optimized for usage on ios Freeze it with export inference graph py optimize it with optimize for inference py and then binary reduced the size with bazel build c tensorflow tools graph transforms transform graph In that the model was well generated as desired For the static library And then I try to import the model into my app So I print all the ops and put the file under tensorflow core framework bazel build tensorflow python tools print selective registration header bazel bin tensorflow python tools print selective registration header graphs path to graph pb ops to register h In the Makefile first delete the line D ANDROID TYPES SLIM under Settings for iOS for all IOS ARCH And run After I generated the static tensorflow library I pod install the podfile in camera example as required Modified the input output tensor and try to build the app However the same error with No kernel registed XXX still occurs I also tried my model and the same library on JieHe is ios tensorflow code it can run smoothly So I assumed my static library was well generated to including all the ops I need So I do not really know how to solve it with the example code My error log 2017 08 24 17 21 18 679927 F Users yingjie tensorflow master tensorflow examples ios App test camera CameraExampleViewController mm 730 Could not load model Invalid argument No OpKernel was registered to support Op 'Less' with these attrs Registered devices CPU Registered kernels device 'CPU' T in DT FLOAT,,petewarden,2017-08-24 17:28:53,2018-01-31 18:47:41
IS,Android Tensorflow model loading issue with SavedModelBundle load,Loading the model in Android give below error FATAL EXCEPTION main Process tensorflow lgsi com posapplication PID 516 java lang RuntimeException Unable to start activity ComponentInfo tensorflow lgsi com posapplication tensorflow lgsi com posapplication MainActivity java lang U nsupportedOperationException Loading a SavedModel is not supported in Android File a bug at if this feature is important to you at android app ActivityThread performLaunchActivity ActivityThread java 2727 at android app ActivityThread handleLaunchActivity ActivityThread java 2788 at android app ActivityThread wrap12 ActivityThread java at android app ActivityThread H handleMessage ActivityThread java 1504 at android os Handler dispatchMessage Handler java 102 at android os Looper loop Looper java 154 at android app ActivityThread main ActivityThread java 6248 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 872 at com android internal os ZygoteInit main ZygoteInit java 762 Caused by java lang UnsupportedOperationException Loading a SavedModel is not supported in Android File a bug at if this feature is important to you at org tensorflow SavedModelBundle load Native Method at org tensorflow SavedModelBundle load SavedModelBundle java 38 at tensorflow com posapplication tagger PosTagger init PosTagger java 23 at tensorflow lgsi com posapplication tagger PosTagger getInsPosTagger PosTagger java 30 at tensorflow com posapplication MainActivity onCreate MainActivity java 56 at android app Activity performCreate Activity java 6757 at android app Instrumentation callActivityOnCreate Instrumentation java 1119 at android app ActivityThread performLaunchActivity ActivityThread java 2680 at android app ActivityThread handleLaunchActivity ActivityThread java 2788 at android app ActivityThread wrap12 ActivityThread java at android app ActivityThread H handleMessage ActivityThread java 1504 at android os Handler dispatchMessage Handler java 102 at android os Looper loop Looper java 154 at android app ActivityThread main ActivityThread java 6248 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 872 at com android internal os ZygoteInit main ZygoteInit java 762 I art Starting Model is saved in Python by using below API builder tf saved model builder SavedModelBuilder r' tmp model' builder add meta graph and variables session tf saved model tag constants SERVING builder save True Model is loading in Andoid using below api inferenceInterface new TensorFlowInferenceInterface context getAssets MODEL FILE,,petewarden,2017-09-01 10:12:47,2018-01-31 18:48:43
IS,No tf metrics true negatives,TensorFlow version 1 4 1 Is there any particular reason for why there is no tf metrics true negatives method I know it is simple to calculate from other confusion metrics that are available but I was wondering why the developers chose to let this one method out,,"drpngx,ispirmustafa",2018-01-14 09:47:59,2018-01-31 19:02:00
PR,Fixed iOS build script for all architectures fixes 12904,Fixes the nightly iOS build which has been suffering failures,,petewarden,2018-01-29 23:42:13,2018-01-31 19:11:58
IS,make build all ios sh occur error,I try to build tensorflow support at Android and iOS by makefile tutorial in current master branch 04c318b69c5b565436cfeeaab1cb7fd5419dde27 When running the build all ios sh script the below error message show The download dependencies sh and compile ios protobuf sh run successfully but compile ios tensorflow sh failed I find same issues 3191 and 4252 and seem to be fixed at 4287 but this problem still happen,,"rohan100jain,aselle,powderluv,aselle,powderluv",2017-09-08 09:34:17,2018-01-31 19:12:43
IS,optimize for inference KeyError,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yUP OS Platform and Distribution e g Linux Ubuntu 16 04 Elementary OS 0 4 Loki TensorFlow installed from source or binary,,petewarden,2017-10-19 20:15:42,2018-01-31 19:18:09
IS,AttributeError module 'tensorflow' has no attribute 'keras',tensorflow admins Mac Pro get started admin python premade estimator py Traceback most recent call last File premade estimator py line 88 in module tf app run main File Users admin Work tensorflow lib python3 6 site packages tensorflow python platform app py line 43 in run sys exit main sys argv 1 flags passthrough File premade estimator py line 34 in main train x train y test x test y iris data load data File Users admin Work tensorflow models samples core get started iris data py line 19 in load data train path test path maybe download File Users admin Work tensorflow models samples core get started iris data py line 12 in maybe download train path tf keras utils get file TRAIN URL split ' ' 1 TRAIN URL AttributeError module 'tensorflow' has no attribute 'keras',,,2018-01-31 07:40:10,2018-01-31 19:20:00
IS,Tensorflow switches to CPU when using Variable assign,System information OS Windows 10 TensorFlow installed from binary TensorFlow version use command below 1 4 0 Python version 3 6 4 CUDA cuDNN version 8 0 64 GPU model and memory GeForce GTX 1080 8 GB Exact command to reproduce run the provided code below Describe the problem I'm using a tf Variable for the learning rate of a optimizer If I change its value with sess run var assign 0 1 the performance drops extremly and it seems tensorflow switches from GPU use to only CPU use no workload on the GPU and more load on the CPU Source code logs I did write a minimal working example training a network with XOR To see the difference just comment the line sess run learning rate assign 0 1 out and it will run much much faster using the GPU,,ppwwyyxx,2018-01-31 18:17:24,2018-01-31 19:20:50
IS,AttributeError module 'tensorflow python layers layers' has no attribute 'conv 2d',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow see below OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 13 2 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version 3 6 3 GPU model and memory no GPU Exact command to reproduce,,"drpngx,drpngx,drpngx,drpngx",2018-01-29 17:01:12,2018-01-31 19:21:38
PR,use tflite bilinear op to resize input of label image,replace previous naive downsize function with a resize using TF Lite RESIZE BILINEAR operator,,"freedomtan,freedomtan,freedomtan,rmlarsen",2018-01-26 07:44:36,2018-01-31 19:22:18
IS,example script multivariate py throws UserWarning Converting sparse IndexedSlices to a dense Tensor of unknown shape This may consume a large amount of memory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I am using the example script tensorflow contrib timeseries examples multivariate py OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS High Sierra darwin TensorFlow installed from source or binary source TensorFlow version use command below v1 5 0 rc1 1781 g86c10063c8 1 5 0 rc1 Python version 3 6 4 Bazel version if compiling from source 0 9 0 homebrew GCC Compiler version if compiling from source Apple LLVM version 9 0 0 clang 900 0 39 2 CUDA cuDNN version n a compiled without CUDA support GPU model and memory n a GPU not supported on Mac with SIP Exact command to reproduce python GOPATH src github com tensorflow tensorflow tensorflow contrib timeseries examples multivariate py Describe the problem The script throws warning UserWarning Converting sparse IndexedSlices to a dense Tensor of unknown shape This may consume a large amount of memory Source code logs Here is the traceback of the warning on my system I have tensorflow installed in a virtual environment called tf3 I see discussion about this warning on SO But the problem seems to happen in the estimator train method not in any custom code I have written,,drpngx,2018-01-31 16:34:00,2018-01-31 19:24:53
IS,Quantization make graph slower during inference,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from using TF source code GPU build can provide docker to reproduce environment conditions if necessary TensorFlow version using r1 3 branch version 1 3 1 Python version 2 7 Bazel version if compiling from source 0 6 1 CUDA cuDNN version 8 0 6 0 GPU model and memory GeForce GTX 1080 Ti 11170 MB Exact command to reproduce tensorflow bazel bin tensorflow tools graph transforms transform graph in graph quantization VGG16 frozen model pb outputs Validation segmentation Validation decoder Softmax out graph quantization VGG16 optimized model pb transforms 'add default attributes strip unused nodes type float shape 384 1248 3 remove nodes op Identity op CheckNumerics fold constants ignore errors true fold batch norms fold old batch norms quantize weights quantize nodes' Describe the problem Hi I compressed a graph using transform graph tool but the resulting graph is actually slower during inference I am compressing a graph similar to the one presented in this article which has VGG16 as an encoder in input and a classification decoder with a Softmax in output Inference uses same python script for both graph original and quantized and make an average of 100 inferences Original graph takes 0 1s for inference quantized graph takes 70s If I perform quantization without quantize nodes inference takes 0 3s I understand that this quantization is still in a work in progress and maybe was more aimed at improving inference on mobile devices but I'm surprised that it is actually so much slower so that is why I'm logging it as a bug here I posted this on stackoverflow but did not get any answer The graph takes 500Mb let me know if I should attach it to this ticket or include an external link Source code logs quantization logs txt tf env txt inference py txt,,petewarden,2017-10-24 07:19:04,2018-01-31 19:25:00
IS,Tensorboard is down after upgrading the tensorflow,Hello everyone I meet a issue about tensorboard after upgrading the tensorflow It runs nicely before but I want maintain some Python2 7 codes in Python3 4 That is why I install tensorflow whl file of Python 3 4 and modify some grammer from Python2 7 to Python3 4 Then codes still run fine but tensorboard is donw The error message as following image OS Platform Ubuntu 14 04 TensorFlow installed from pip instll whl file TensorFlow version tensorflow 1 2 1 for Python2 but can not check the version for Python 3 What should I do for this issue degrade tensorflow or upgrade CUDA Can anybody give me any help Thank you,,drpngx,2018-01-17 07:00:41,2018-01-31 19:25:03
IS,Bus Error when running a session,System information Running on an ODROID XU4 Have I written custom code No OS Platform and Distribution Linux Ubuntu Mate 16 04 CUDA cuDNN version N A GPU model and memory N A TensorFlow installed from source TensorFlow version 1 4 0 Python version 3 5 2 Bazel version 0 8 0 GCC Version 5 4 0 Exact command to reproduce python3 5 import tensorflow as tf hello tf constant 'Hello TensorFlow' sess tf Session print sess run hello Describe the problem I have built and installed TensorFlow as a pip package onboard an ODROID XU4 32 bit ARM following the steps in this guide Everything went smoothly and I was able to install TensorFlow after a lengthy build time However when I try to run any session such as in the basic example above the program fails with a Bus Error Running pip3 list shows that Tensorflow is indeed installed and no errors are thrown when I merely import TensorFlow Source code logs I traced the bus error by looking into the var log syslog file and found the following lines associated with the error Dec 2 21 24 21 odroid kernel 3658 433306 Alignment trap python3 5 10189 PC 0xac0bac42 Instr 0xf9068a1f Address 0xbe8a7da4 FSR 0x811 Dec 2 21 24 21 odroid kernel 3658 433313 Alignment trap not handling instruction f9068a1f at ac0bac42 Dec 2 21 24 21 odroid kernel 3658 439021 Unhandled fault alignment exception 0x811 at 0xbe8a7da4 So it appears to be an alignment issue I tried to force the kernel to attempt to fix the error instead of simply failing by using the following command echo 3 proc cpu alignment The three is meant to tell the kernel to fix these alignment issues However this strategy has not changed anything about the Bus Error when attempting to run a session Perhaps this is related to the 32 bit architecture I am attempting to run on,,"drpngx,drpngx,petewarden",2017-12-02 21:57:41,2018-01-31 19:34:35
IS,tensorflow python framework errors impl NotFoundError Can not get size for,D Python Python35 models master research object detection D Python Python35 python train py logtostderr train dir training pipline config path training ssd mobilenet v1 pets config Traceback most recent call last File train py line 163 in module tf app run File C Users USER AppData Roaming Python Python35 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File train py line 106 in main overwrite True File C Users USER AppData Roaming Python Python35 site packages tensorflow python lib io file io py line 384 in copy compat as bytes oldpath compat as bytes newpath overwrite status File D Python Python35 lib contextlib py line 66 in exit next self gen File C Users USER AppData Roaming Python Python35 site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl NotFoundError Can not get size for path d udc92acc udce8s sp udce9cifi udce9 not found,,drpngx,2017-12-12 13:43:35,2018-01-31 19:35:54
IS,iOS Op type not registered 'DecodeWav',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I am trying to run graph model from Simple Audio Recognition example on iOS OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 13 TensorFlow installed from source or binary Branch r1 4 TensorFlow version use command below 1 4 Python version 2 7 Bazel version if compiling from source Build label 0 9 0 homebrew GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I am trying to run graph model from Simple Audio Recognition example on iOS When I am calling session Create tensorflow graph with the graph I get the error Could not create TensorFlow Graph Not found Op type not registered 'DecodeWav' My initial thought is that because I am using TensorFlow experimental 1 1 1 from pods it is possible that this Op type is not registered So I tried building it myself which builds without errors with command tensorflow contrib makefile build all ios sh I then remove TensorFlow experimental 1 1 1 from the project and link my own build of tensorflow but I get the same error I also found the following PR iOS Add optional Selective Registration of Ops 14421 I tried building from master with the above PR merged like so For iPhone 5 tensorflow contrib makefile build all ios sh a armv7 g Users anton Development tensorflow tensorflow examples ios simple data tensorflow inception graph speech pb For iPhone SE tensorflow contrib makefile build all ios sh a arm64 g Users anton Development tensorflow tensorflow examples ios simple data tensorflow inception graph speech pb If I then go and check the file tensorflow tensorflow core framework ops to register h auto generated after above command I can see that DecodeWav is listed among kernels and operations But when I try to run the graph model I still get same error message I have removed the pod version and I am 100 sure I am running my own build version of tensorflow on iOS I can not tell if this is a bug or I am doing something wrong during the build process Has anyone tried running any graph that uses DecodeWav on iOS Thanks Source code logs Error Could not create TensorFlow Graph Not found Op type not registered 'DecodeWav' in binary running on Antons iPhone Make sure the Op and Kernel are registered in the binary running in this process,,"shivaniag,petewarden,petewarden",2018-01-07 02:55:51,2018-01-31 19:36:01
IS,Accidentally cancelled inceptionV3 during install now can not install at all,Hello i was setting up tensorflow for image classification and after i ran python m scripts retrain bottleneck dir tf files bottlenecks model dir tf files models ARCHITECTURE summaries dir tf files training summaries ARCHITECTURE output graph tf files retrained graph pb output labels tf files retrained labels txt architecture ARCHITECTURE image dir tf files flower photos It automatically started installing inception i realized that i needed to change some options so i cancelled the install of inception Now i believe that i have a half install that does not let me install the full package or use the half package I may be wrong but any suggestions would be appreciated FYI i have run pip install inception to which i receive a python setup py egg info failed with error code 1 in my local temp dir I also just tried running the scripts retrain again to which i receive a EOFError compressed file ended before the end of stream marker was reached Running on Windows 7,,"drpngx,petewarden",2018-01-16 17:28:24,2018-01-31 19:38:29
IS,x86 64 compilation failed,System information MacOS High Sierra 10 13 2 Python 3 6 3 TensorFlow Latest Pull from 1 17 18 Describe the problem I am following Pete Warden is TensorFlow for Mobile Poets guide and seem to have a found an error When I run tensorflow contrib makefile build all ios sh after about 20 minutes it returns an error I have tried running lipo info Users ryan Downloads tensorflow2 tensorflow contrib makefile gen protobuf ios lib libprotobuf a and this returns Architectures in the fat file Users ryan Downloads tensorflow2 tensorflow contrib makefile gen protobuf ios lib libprotobuf a are i386 I have the entire error script here Source code logs ld symbol s not found for architecture x86 64 clang error linker command failed with exit code 1 use v to see invocation make Users ryan Desktop tensorflow master tensorflow contrib makefile gen bin ios X86 64 benchmark Error 1 ' ' 2 ne 0 ' ' echo 'x86 64 compilation failed ' x86 64 compilation failed exit 1,,"aselle,petewarden",2018-01-18 23:51:42,2018-01-31 19:42:50
IS,Incorrect Result from Add Function,System information Have I written custom code Yes OS Platform and Distribution Linux Ubuntu 16 04 3 LTS Bazel version Not applicable TensorFlow installed from binary TensorFlow version 1 4 0 Python version 3 5 2 CUDA cuDNN version 8 0 6 0 for CUDA 8 0 GPU model and memory GM107M GeForce GTX 960M 4GB Exact command to reproduce Here is a simple program to add session tf Session a tf placeholder tf float32 print first b tf placeholder tf float32 print second result node tf add a b print starting x session run result node a 2 0 b 3 5 print x Output should be 5 5 while I am getting 2 0 on 2 machines screenshot from 2017 12 08 17 59 49 screenshot from 2017 12 08 18 00 21,,drpngx,2017-12-08 12:31:12,2018-01-31 19:52:59
IS,tensorflow compiler xla tests array elementwise ops test cpu parallel test fails on ppc64le,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source v1 3 1 TensorFlow version use command below TF1 3 1 Python version Python 2 7 5 Bazel version if compiling from source 0 5 4 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel test c opt tensorflow compiler xla tests array elementwise ops test cpu parallel Describe the problem Here 2 sub tests are failing on ppc64le i e IsFiniteScalarF32 and IsFiniteR1F32s in file array elementwise ops test cc For IsFiniteScalarF32 sub test error at line 100 L100 ComputeAndCompareR0 bool builder false The failure due to expected false vs actual true For IsFiniteR1F32s sub test error at line 126 L126 ComputeAndCompareR1 bool builder false true false true false false The failure due to expected 010100 vs actual 111100 Currently trying to find the root cause started debugging further on this Any inputs help appreciated Thanks Source code logs 1 IsFiniteScalarF32 sub test log,,"sandipmgiri,sandipmgiri,sandipmgiri,sandipmgiri,sandipmgiri,drpngx,sandipmgiri,drpngx,drpngx,sandipmgiri,drpngx,sandipmgiri,drpngx,sandipmgiri,sandipmgiri,sandipmgiri,sandipmgiri,drpngx,sandipmgiri,drpngx,sandipmgiri,sandipmgiri,drpngx,sandipmgiri,drpngx,tatatodd,drpngx,sandipmgiri,sandipmgiri",2017-12-11 10:06:30,2018-01-31 19:55:41
IS,The recognized result is not correct when converting the frozen graph to tflite for android device use,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 mac High Sierra TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version 2 7 10 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source c 4 2 1 CUDA cuDNN version GPU model and memory Exact command to reproduce The detailed system information you can check the url You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Hi I covert the frozen graph mobilenet v1 224 to tflite and put it in the tflitecamerademo app but the regonization result is not correct If I use the tflite file which download from The regonization result is correct I do not know what steps is not correct when I covert the frozeon graph to tflite file could you help me to review what steps is the wrong I put the frozen graph coverting tflite file and the regonized picture in the The correct result should be malamute but I use the my coverting tflite file the result is shower curtain I use the command to do the covert bazel run config opt tensorflow contrib lite toco toco ' input file tmp mobilenet frozen graph pb' ' output file tmp mobilenet quant 20180117 tflite' ' input format TENSORFLOW GRAPHDEF' ' output format TFLITE' ' inference type QUANTIZED UINT8' ' inference input type QUANTIZED UINT8' ' input shapes 1 224 224 3' ' input arrays input' ' output arrays MobilenetV1 Predictions Reshape 1' ' mean values 128' ' std values 128' ' default ranges min 0' ' default ranges max 6' Thanks Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,petewarden,2018-01-19 02:26:39,2018-01-31 20:13:48
IS,Using tf train SyncReplicasOptimizer with multiple optimizers,I am trying to run the DeepLab Resnet in a distributed setup I opted Synchronous Data parallel training approach similar to the one demonstrated in the Inception distributed training example In the Inception example a single RMS optimizer is used to reduce the loss The tf train SyncReplicasOptimizer function wraps the optimizer and becomes responsible for synchronization aggregation and application of gradients to various workers Also it takes care of updating the global step variable In my case the DeepLab Resnet makes use of three optimizers each handling specific portions of the network Following snippet explains the case Three optimizers declared with different learning rates opt conv tf train MomentumOptimizer learning rate args momentum opt fc w tf train MomentumOptimizer learning rate 10 0 args momentum opt fc b tf train MomentumOptimizer learning rate 20 0 args momentum Scope for every optimizer grads tf gradients reduced loss conv trainable fc w trainable fc b trainable grads conv grads len conv trainable grads fc w grads len conv trainable len conv trainable len fc w trainable grads fc b grads len conv trainable len fc w trainable Gradients applied to various portions of the network train op conv opt conv apply gradients zip grads conv conv trainable train op fc w opt fc w apply gradients zip grads fc w fc w trainable train op fc b opt fc b apply gradients zip grads fc b fc b trainable tf group to combine all three operations train op tf group train op conv train op fc w train op fc b I do not have any clue about using the tf train SyncReplicasOptimizer for multiple optimizers to achieve synchronous data parallel training Also I do not have an idea about updating the global step variable and using the chief queue runner for this case Please help me on this,,"reedwm,ispirmustafa",2018-01-31 11:59:09,2018-01-31 20:53:32
PR,Simplify loader impl py logic around main Op Tensor,,,"joel-shor,joel-shor",2018-01-31 03:08:35,2018-01-31 21:08:14
IS,Multi core CPU performance dropped for MKL TF build,System information System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 LTS 64 bit TensorFlow installed from source or binary source TensorFlow version use command below Tensorflow r1 4 Python version Python version 2 7 12 Bazel version if compiling from source Bazel release 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 CUDA cuDNN version no CUDA GPU model and memory no GPU but i7 6850K with 32Gb ddr4 Exact command to reproduce run the script below Tested on two machines 1 i7 6850K with 32Gb ddr4 2 two Xeon x5650 with 24Gb ddr3 Describe the problem When I build Tensorflow with MKL it dropped CPU performance in a strange way Performance of individual core is much higher but for multicore is much worse It is a big epic bottleneck for my project and I can not solve it by myself I will appreciate any help 1 TF installation from sources with MKL support Tensorflow r1 4 installed from source Configured with jemalloc as malloc support and other configure settings ignored bazel build config mkl c opt tensorflow tools pip package build pip package bazel bin tensorflow tools pip package build pip package tmp tensorflow pkg pip install tmp tensorflow pkg tensorflow 1 4 1 cp27 cp27mu linux x86 64 whl Run tests one core 0 03s all cores 0 12s 2 TF installation with pip pip install tensorflow tensorflow 1 4 1 cp27 cp27mu manylinux1 x86 64 whl installed Run tests one core 0 16s all cores 0 03s Source code logs,,"vivek-rane,vivek-rane,drpngx,tatianashp",2017-12-12 19:43:31,2018-01-31 21:28:18
IS,Does SavedModelBuilder save checkpoints,Does SavedModelBuilder save create checkpoint files The documentation says this is a wrapper for Saver but does not mention checkpoints It looks like this function does not create checkpoints System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 13 1 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,drpngx,2017-11-18 06:38:03,2018-01-31 22:22:18
IS,Dataset memory bottleneck not showing in debug mode,im fitting word2vec models using distributed gpus which require me to assemble multiple towers and so copy my model several times over to load data i am using the get next method of a contrib dataset iterator initialized with one shot before starting up i run into the 2gb protobuf memory bottleneck so in debug mode i compared 3 models one where dataset is given full data another where dataset is given 30 of my data and a last where dataset is given 1 of my data the first doesnt run but most importantly for the second two i compared the size of all of my tensors and they are all the same this makes debugging difficult any thoughts i suspect there is something going on with folding of constants Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-11-03 02:14:41,2018-01-31 22:38:49
IS,Keras backend functionality changed,Hi I have been using keras from within tensorflow since it was included into the contrib package but it seems that in the 1 4 release the keras backend is missing some functionality For example from tensorflow python keras import backend as K K tile Traceback most recent call last File stdin line 1 in module AttributeError module 'tensorflow python keras backend' has no attribute 'tile' Whereas in tensorflow 1 1 from tensorflow contrib keras python keras import backend as K K tile function tile at 0x7fbd9024fb70 And using pure keras from keras import backend as K Using TensorFlow backend K tile function tile at 0x7fe9743c5950 Is this just an omission or has the functionality been deliberately removed I know I can use the equivalent tensorflow operation but it is nice to be able to use a reasonably portable api and if I wanted to switch backend I could just change the import path I also try not too mix keras and tensorflow too much as I think the code is more readable just using one Regards Alex,,"fchollet,ahundt,drpngx",2017-11-04 17:55:43,2018-01-31 22:40:59
IS,Optimize graph graph transform tools do not support NCHW,I tried optimizing graph using both Graph transform tool and Optimize graph for inference Both cases produced the same error because the fused batchnorm used not NCHW but NHWC I have got the error like this Although NCHW is faster than NHWC in GPU environment why the tools do not support NCHW,,aselle,2017-12-01 10:24:45,2018-01-31 23:02:26
PR,optimize for inference lib fold batch norms preserves data format,fold batch norms currently breaks graphs containing convolutions using NCHW data format The function replaces a BiasAdd operation with a new one while not preserving the data format of the original operation As a result the new operation always has NHWC data format and the execution of the resulting graph fails because of mismatching dimensions The proposed resolution is to copy the data format property from the original operation The patch fixes,,"qmick,qmick,rmlarsen",2018-01-12 17:07:04,2018-01-31 23:02:26
IS,Allow variable overwrites on scope level,This is a request for allowing to pass a dict of variable overwrites to variable scopes which to be returned when tf get variable is called instead of the usual procedure if they are provided otherwise do the usual procedure A simple example of this beahviour is This is particularly usefull for being able easily to bootstrap neural network parameters coming from inside the layers trough a standard function interface My specific usage is for HMC for NN parameters This is a question on whether you guys are interested in this so that I spend more time on doing this properly,,"reedwm,martinwicke,martinwicke",2018-01-31 22:24:53,2018-02-01 00:27:35
PR,For Test DO NOT MERGE Add grpcio as a pip dependency of tensorflow,,,"caisq,caisq",2018-01-31 15:22:47,2018-02-01 01:41:14
PR,Update ISSUE TEMPLATE md,Fixes 16350,,"MarkDaoust,aselle",2018-02-01 01:45:57,2018-02-01 02:58:24
PR,Fixed typo,changed variable sensorOrienation to sensorOrientation This was annoying me,,,2018-01-31 02:20:07,2018-02-01 02:58:56
PR,Remove duplicated identical lines,I believe this commit 32db18b4908ec514c5fff8db95e1d05574bb05bb introduced the duplicated lines to the file,,,2018-01-30 08:15:06,2018-02-01 02:59:11
PR,Replace 'Dan' with 'Dandelion' in the citations,,,dandelionmane,2018-01-31 21:51:44,2018-02-01 02:59:32
IS,Bug LuongMonotonicAttention in contrib seq2seq python ops attention wrapper py,LuongMonotonicAttention init calls its parent BaseAttentionMechanism with query layer as follows Guessing from the way LuongAttention works there should be query layer None in LuongMonotonicAttention init,,tatatodd,2018-01-22 13:50:55,2018-02-01 03:00:34
PR,Remove query layer in LuongMonotonicAttention,In the constructor for LuongMonotonicAttention a query layer was being created but it was ultimately never used Fixes 16287,,,2018-01-30 20:58:33,2018-02-01 03:00:34
PR,Fix typos,,,,2018-01-30 03:59:02,2018-02-01 03:00:52
PR,Fix FutureWarning on issubdtype from float to np floating,This is try to fix 16587,,"imsheridan,imsheridan,cancan101,drpngx",2018-01-30 17:34:37,2018-02-01 03:03:19
PR,Add relnote about bug in ptxas in CUDA 9 and 9 1,,,"jlebar,jlebar,jlebar,jlebar",2018-02-01 01:56:29,2018-02-01 03:15:45
PR,0 6 0,,,,2018-01-28 15:29:33,2018-02-01 03:21:00
PR,Change RELEASE md to specify CUDA 9 0,PR for tinyest PR ever,,,2018-01-27 09:17:33,2018-02-01 03:22:55
IS,tf matching files order of returned files,As far as I can tell from the order of filenames returned by tf matching files can be non determinstic If that is correct it would be nice if that were stated in the documentation and also for Dataset list files and train match filenames once Even better would be to guarantee alphabetical order but I am not sure about the performance overhead that would incur This would enable to process files given as e g A 1 png A 2 png and B 1 png jointly by doing to match files followed by a zip Have I written custom code No OS Platform and Distribution N A TensorFlow installed from pip TensorFlow version 1 4 1 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"drpngx,yongtang",2017-12-14 22:57:06,2018-02-01 03:28:02
PR,Update docs for tf matching files to mention non deterministic,This fix tries to close the issue of 15374 by updating the docs of tf matching files as well as Dataset list files and train match filenames once to mention that the file names returned could be non deterministic This fix fixes 15374 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-31 23:56:16,2018-02-01 03:28:02
PR,By default only download inception if it does not exist already,Hope this saves some bandwidth I updated get graph def from url tarball to accept a default location and only download a file if the file has not already been downloaded If you do not give it a default location it will always download preserving existing behavior I added a default location for the inception model as part of default graph def fn This means you only download inception the first time you run run inception instead of every time you start your script Cheers,,"bstriner,andrewharp,bstriner,bstriner",2018-01-30 09:37:58,2018-02-01 03:28:25
IS,saved model load method support for android,I am trying load a saved model on android with java api Session session SavedModelBundle load modelDir serve session Its works on PC But on android i got this error message E tensorflow CameraActivity Exception java lang UnsupportedOperationException Loading a SavedModel is not supported in Android File a bug at if this feature is important to you at org tensorflow SavedModelBundle load Native Method my reference model for training procedure is tf estimator for iris data,,"shivaniag,asimshankar",2017-09-16 06:33:19,2018-02-01 03:54:10
PR,Re add missing argument specifier in build all android sh,The was erroneously removed in 76f70f5d62f35b5cc95121e6dfffa63a8214b626,,andrewharp,2018-01-31 23:13:04,2018-02-01 04:42:57
PR,Support multiple build types in Android build gradle with the makefile build,,,andrewharp,2018-02-01 03:33:22,2018-02-01 04:43:19
PR,Update maxout py,Specify the final number of features in the maxout axis,,"rmlarsen,drpngx",2018-01-14 22:37:39,2018-02-01 05:56:45
IS,maxout lose the number of features in the shape of its output,In tf contrib layers maxout when the shape of inputs is not completely specified the shape of its output will be completely unknown such as None None None in the 3d case Since num units has specified the final number of features in the maxout axis the output should set its shape accordingly,,,2018-01-18 19:19:05,2018-02-01 05:58:39
PR,Branch 184052073,,,case540,2018-02-01 02:13:00,2018-02-01 06:41:18
IS,AssignAddVariableOp has no output,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 rc1 Python version NA Using Go bindings Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 7 2 1 CUDA cuDNN version 9 1 7 0 GPU model and memory GTX 1060 6GB Exact command to reproduce See below Describe the problem According to the docs AssignAddVariableOp Outputs the incremented value which can be used to totally order the increments to this variable Without this feature I get non deterministic behavior when reading the value of the variable at the same time as I update it However at least in the Go bindings it returns an operation which has no outputs I can work around this problem by using two calls to sess Run but this is inelegant Source code logs,,"tatianashp,asimshankar,asimshankar",2018-01-26 17:33:42,2018-02-01 06:41:53
PR,MKL Pooling and AddN bug fixes,,,mahmoud-abuzaina,2018-01-31 00:18:08,2018-02-01 08:37:48
IS,TensorFlow op to copy weights of Keras model,I am doing a distributed calibration of an LSTM model keras 2 0 TensorFlow 1 0 with tf device tf train replica device setter model create model by keras clone model create the same model by keras but now a stateful one after calibration I want my chief worker to use the clone model copy the weights the calibration reached in model and make predictions on some test set but simply calling clone model set weights model get weights does not work I understand I need to define this weight copy as an op and then call session run of that op Can you please help with a TensorFlow op copying weights of a keras model to another identical architecture Keras model,,"drpngx,drpngx",2018-01-30 13:00:44,2018-02-01 12:38:21
IS,A fix for error in tf layers conv3d transpose when inferred batch size,Context When using the tf layers conv3d tranpose Op with a dynamic batch size and when use bias True then there is a well known error that occurs The error is due to a tf reshape Op that chunks together some of the axes before adding the bias for a slight performance improvement L1628 E g in the case of data format 'channels last' gives an error when outputs shape 0 None i e when batch size is inferred Simple fix To fix this with minimal modification to other code it would be great if someone could replace outputs shape 0 with 1 in these two lines L1627 L1632,,"facaiy,skye,fchollet,facaiy,imsheridan",2017-12-28 15:27:47,2018-02-01 12:41:42
IS,Bazel version comparison fails with bazel 0 10 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No just commented 6 lines in the bzl files out OS Platform and Distribution 16 04 on Jetson TX2 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 Python version 2 7 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 0 GPU model and memory TX2 GPU 5GB not sure Exact command to reproduce bazel build c opt local resources 3072 4 0 1 0 verbose failures config cuda tensorflow tools pip package build pip package Describe the problem I cannot build tensorflow using bazel 0 10 0 It seems like the version checks in repositories bzl and wokspace bzl fail Commenting them out solves the issue even though I know that is no persistent solution I think it is simply that bazel thinks that 0 10 0 is smaller 0 5 4 due to its string comparison but I am no bazel expert Source code logs ERROR home nvidia git tensorflow WORKSPACE 15 1 Traceback most recent call last File home nvidia git tensorflow WORKSPACE line 15 closure repositories File home nvidia cache bazel bazel nvidia 01c445c7b00bca0241913a79fcd99718 external io bazel rules closure closure repositories bzl line 69 in closure repositories check bazel version Closure Rules 0 4 5 File home nvidia cache bazel bazel nvidia 01c445c7b00bca0241913a79fcd99718 external io bazel rules closure closure repositories bzl line 172 in check bazel version fail s requires Bazel s but was Closure Rules requires Bazel 0 4 5 but was 0 10 0 non git ERROR Error evaluating WORKSPACE file ERROR home nvidia git tensorflow WORKSPACE 41 1 Traceback most recent call last File home nvidia git tensorflow WORKSPACE line 41 tf workspace File home nvidia git tensorflow tensorflow workspace bzl line 48 in tf workspace check version 0 5 4 File home nvidia git tensorflow tensorflow workspace bzl line 38 in check version fail nCurrent Bazel version is Current Bazel version is 0 10 0 non git expected at least 0 5 4 ERROR Error evaluating WORKSPACE file ERROR Skipping ' tensorflow tools pip package build pip package' error loading package 'external' Package 'external' contains errors WARNING Target pattern parsing failed ERROR error loading package 'external' Package 'external' contains errors INFO Elapsed time 3 145s FAILED Build did NOT complete successfully 0 packages loaded,,"meteorcloudy,meteorcloudy,gunan",2018-02-01 10:38:27,2018-02-01 13:36:45
IS,clear,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-01 05:23:21,2018-02-01 15:26:55
IS,Tensorflow on banana pi m64,How to install TF on banana m64 OS Linux bpi iot ros ai 3 10 105 BPI M64 Kernel When i trying install i have an error tensorflow 1 5 0 cp34 none any whl is not a supported wheel on this platform,,reedwm,2018-02-01 12:14:54,2018-02-01 18:01:59
IS,What is the difference between Univariate prediction and Multivariate prediction,My understanding is that paramenters of neurals are shared in Multivariate prediction and they can learn some correlations between series There is less training time in Multivariate prediction I wonder if that is right Could you please explain any basic principles of Multivariate prediction with LSTM or recommend related papers to me Thank you,,reedwm,2018-02-01 05:56:36,2018-02-01 18:02:23
PR,Temporarily remove three linter checks for now,C0330 bad continuation C0301 line too long C0326 bad whitespace Will fix the following 25 error and add them back tensorflow contrib session bundle bundle shim py 85 C0301 line too long Line too long 83 80 tensorflow contrib session bundle bundle shim py 94 C0301 line too long Line too long 89 80 tensorflow contrib session bundle bundle shim py 135 C0301 line too long Line too long 81 80 tensorflow contrib session bundle bundle shim py 136 C0301 line too long Line too long 81 80 tensorflow contrib kafka python ops kafka dataset ops py 33 C0301 line too long Line too long 85 80 tensorflow contrib tpu profiler pip package cloud tpu profiler main py 29 C0330 bad continuation Wrong continued indentation remove 3 spaces tensorflow contrib tpu profiler pip package cloud tpu profiler main py 31 C0330 bad continuation Wrong continued indentation remove 3 spaces tensorflow contrib tpu profiler pip package cloud tpu profiler main py 35 C0330 bad continuation Wrong continued indentation remove 3 spaces tensorflow contrib learn python learn datasets synthetic test py 139 E0102 function redefined SyntheticTest test spirals method already defined line 92 tensorflow contrib layers python layers layers py 63 C0330 bad continuation Wrong hanging indentation remove 7 spaces tensorflow contrib layers python layers layers py 1421 C0301 line too long Line too long 104 80 tensorflow contrib py2tf impl api py 89 C0301 line too long Line too long 81 80 tensorflow contrib rnn python kernel tests core rnn cell test py 160 C0326 bad whitespace Exactly one space required after comma tensorflow contrib ndlstm python lstm1d py 91 C0330 bad continuation Wrong hanging indentation add 2 spaces tensorflow contrib rnn python kernel tests rnn cell test py 1639 E0102 function redefined WeightNormLSTMCellTest class already defined line 1548 tensorflow contrib gan python eval python classifier metrics impl py 209 C0301 line too long Line too long 98 80 tensorflow contrib gan python eval python classifier metrics impl py 209 E1124 redundant keyword arg get graph def from url tarball Argument 'filename' passed by position and keyword in function call tensorflow contrib layers python layers layers test py 1311 C0301 line too long Line too long 89 80 tensorflow python kernel tests tensordot op test py 108 C0326 bad whitespace Exactly one space required after comma tensorflow python data util nest py 482 C0301 line too long Line too long 81 80 tensorflow python data ops dataset ops py 909 C0301 line too long Line too long 88 80 tensorflow python ops image ops impl py 1694 C0301 line too long Line too long 87 80 tensorflow python ops image ops impl py 1720 C0301 line too long Line too long 87 80 tensorflow python ops image ops impl py 1745 C0301 line too long Line too long 87 80 tensorflow python ops image ops impl py 1771 C0301 line too long Line too long 87 80,,"yifeif,yifeif",2018-02-01 09:55:53,2018-02-01 18:03:32
PR,MKL Fix for mkl input conversion for MKL DNN,Fix also enables elementwise operations in MKL,,"agramesh1,agramesh1",2018-01-29 23:07:55,2018-02-01 18:10:54
PR,Clang on Windows will define BYTE ORDER etc for us,15990,,rongjiecomputer,2018-01-27 14:42:49,2018-02-01 18:11:26
PR,Fix do cmake python sanity error,Add missing dir to tensorflow contrib cmake python modules txt,,yifeif,2018-02-01 09:30:18,2018-02-01 18:12:35
PR,Address sanity build issues,,,"gunan,yifeif,gunan",2018-02-01 08:18:12,2018-02-01 18:20:31
PR,Resolve pylint issues in image ops,There were 4 line too long errors reported in pylint check of image ops impl py Changed the format to not exceed 80 characters based on indentation examples in style guide Indentation Reran pylint against the file and verified errors no longer listed for image ops impl py,,gunan,2018-02-01 04:09:42,2018-02-01 18:20:43
PR,Minor refactor to remove redundant test class,There were two WeightNormLSTMCellTest classes that differed in formatting only Removed the original one at end of file since based on history the version above it contained latest formatting updates,,,2018-01-30 01:10:00,2018-02-01 18:20:46
PR,Fix an imperfect implementation of tf losses mean pairwise squared error,Here is a fix for the issue Imperfect implementation of tf losses mean pairwise squared error 15968 RELNOTES Fixed wrong normalization in tf losses mean pairwise squared error to conform to the math and documentation Numerical results will be different,,"martinwicke,rmlarsen,rmlarsen,rmlarsen",2018-01-26 02:42:02,2018-02-01 18:32:37
PR,Compile libtensorflow on windows with AVX,,,gunan,2018-02-01 18:47:35,2018-02-01 18:48:45
PR,Update README md,Correct MobilenetV1 variable,,gunan,2018-01-22 23:28:13,2018-02-01 19:17:10
IS,Current Bazel version is 0 10 0 expected at least 0 5 4,I get this error message when trying to build from source r1 5 with the new bazel version published today Current Bazel version is 0 10 0 expected at least 0 5 4 I guess the version check is wrong,,"imsheridan,imsheridan",2018-02-01 15:52:21,2018-02-01 21:40:12
PR,Fix linter error in losses impl py,,,gunan,2018-02-01 19:34:01,2018-02-01 22:23:35
PR,added audio ops cc to tf op files txt to fix the Op type not registered DecodeWav error,,,andrewharp,2018-01-29 07:38:00,2018-02-01 22:31:05
PR,fix python 2 7 build break import error on windows,fix python 2 7 build break import error on windows,,fo40225,2018-02-01 09:06:14,2018-02-01 23:09:06
PR,Improve shape function of NonMaxSuppression,This fix tries to improve shape function of NonMaxSuppression As was specified in the docs the shapes of parameters of tf image non max suppression are clearly defined with However there is no shape check in the shape function of NonMaxSuppression This fix adds the shape check for NonMaxSuppression and adds additinal test cases for it Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-01 16:45:46,2018-02-01 23:10:07
IS,Dear frinds,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-01 22:25:30,2018-02-01 23:35:20
PR,Remove BOM,These two files started with Byte Order Mark U FEFF which we do not want,,Androbin,2018-01-27 22:53:53,2018-02-02 00:00:46
IS,TensorFlow with CUDA or Python might rebuilds more than necessary instead of re using bazel cache,Context for DeepSpeech we perform tensorflow builds and then keep the cache in a tar capturing the whole of the home directory of the build user We then untar it and the deepspeech build through bazel build picks the proper cached items so it does not rebuild anything Recently we started to have increased 2 5x build time on CUDA enabled builds Debugging with Bazel showed that it was rebuilding because the actionKey computed for stream executor impl was different Instrumenting Bazel to get more informations I could get down to the reason of the different actionKey the ordering of the CUDA includes was different The list itself contained the exact same content just a different ordering Those includes are symlinks and they are generated from a genrule This is all taken care of by L915 L1035 which generated shell script for the genrules that actually do perform the symlinks Checking those shell scripts revealed the exact same and different ordering Checking more carefully one will see that the headers are discovered by read dir function L891 L894 it does directly get the output of find This is dependant on the ordering provided by readdir syscall In our case the ordering on the filesystem before making the tar archive and after untarring it would be different One simple fix for that is to force ordering the list of headers this way we are sure the order is always the same and we are not dependant on what readdir is going to get us In the past Bazel would force the ordering of the elements considered to compute the actionKey This was removed with 0 3 0 but it might have make the issue hidden,,reedwm,2018-01-30 14:16:49,2018-02-02 02:03:32
PR,Force sorting of CUDA Python headers to avoid spurious rebuilds,If one does try to re use Bazel cache of a TensorFlow CUDA enabled build then it might happen that readdir syscall behind the use of find in read dir will generate a different ordering of the very same list of headers This will make new genrules for symlinking the CUDA headers and in the end it will result in different actionKey computed by Bazel hence invalidating the action cache Fixes 16585,,,2018-01-30 14:22:12,2018-02-02 02:03:32
IS,v1 3 batch norm layer,I use the batch norm layer like this def batch norm layer x train phase scope bn bn train batch norm x decay 0 999 center True scale True is training True reuse None is this right trainable True scope scope bn bn inference batch norm x decay 0 999 center True scale True is training False reuse True is this right trainable True scope scope bn z tf cond train phase lambda bn train lambda bn inference return z I do not know in v1 3 0 is the code worked I saw the issue1122 issuecomment 232535426 someone said it would not work well thank you in advance,,drpngx,2018-02-01 10:02:01,2018-02-02 02:10:41
PR,Branch 184220615,,,"yifeif,yifeif",2018-02-02 01:59:52,2018-02-02 02:58:22
IS,Container localhost does not exist,Hi I upgraded from 1 5 0 rc1 to the current master branch and I started receiving the following error It is hard to reproduce this error but a summary of the context is that I have a lookup table op inside a dataset map operator and I get this error when I try to execute the corresponding iterator GetNext op I'm looking for information in how to parse and debug this error I never explicitly set any containers for my variables or lookup tables i e leave them to the default value an empty string Were there any changes introduced recently that could result in this error Note that this happens with my Scala API but not with the Python API and so it may be that I have not updated something in my code I just do not really know where to look for this Thanks,,"eaplatanios,mrry,eaplatanios,mrry,eaplatanios,eaplatanios,eaplatanios,eaplatanios,eaplatanios,eaplatanios,mrry,eaplatanios,mrry",2018-01-27 07:58:18,2018-02-02 02:58:59
IS,Documentation Method Templates Improvement,System information N A Describe the problem The method class templates in documentation should include a full functioning path to the method instead of just truncating to the method is name I e this is what we have at present bad img width 399 alt screen shot 2018 01 16 at 2 23 08 pm src This is a more practical and copy paste friendly version img width 426 alt screen shot 2018 01 16 at 2 22 49 pm src I'm constantly just grabbing method templates pasting to my text editor and then coming back to docs to copy paste the package path which is now the header of the page which is an awful workflow Source code logs N A,,"aselle,MarkDaoust,MarkDaoust",2018-01-16 19:28:06,2018-02-02 02:58:59
PR,Fix sanity build,x Fix build error x Update test,,"yifeif,gunan,yifeif",2018-02-01 19:00:57,2018-02-02 06:51:34
PR,Sync r1 6 to master HEAD,,,av8ramit,2018-02-02 03:01:17,2018-02-02 06:52:21
IS,Is there still a math ops h,I followed the C API tutorial But I can not make it because I do not find tensorflow cc ops math ops h and many other header files Then I go to the repo on master branch did not find them too System information my code is very simple using namespace tensorflow using namespace tensorflow ops Scope root Scope NewRootScope Matrix A 3 2 1 0 auto A Const root 3 f 2 f 1 f 0 f Vector b 3 5 auto b Const root 3 f 5 f v Ab T auto v MatMul root And the function MatMul can not be recognized OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source,,,2018-02-02 07:28:18,2018-02-02 08:03:53
PR,Updating the version to 1 6 0 rc0,,,av8ramit,2018-02-01 18:30:59,2018-02-02 08:35:04
PR,Release Notes for r1 6,,,"av8ramit,gunan,av8ramit,gunan",2018-02-01 17:58:27,2018-02-02 08:35:16
IS,Runtime Error with Qt GUI Application,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version use master Python version 2 7 Bazel version 0 9 0 GCC Compiler version 5 4 0 Without CUDA cuDNN Without GPU Describe the problem When I used QtCreator to build GUI Application if include tensorflow core lib core refcount h it will throw The program has unexpectedly finished pro like SOURCES main cpp mainwindow cpp HEADERS mainwindow h FORMS mainwindow ui tensorflow INCLUDEPATH home face Desktop tensorflow bazel genfiles INCLUDEPATH home face Desktop tensorflow INCLUDEPATH home face Desktop tensorflow tensorflow contrib makefile gen protobuf include INCLUDEPATH home face Desktop tensorflow tensorflow contrib makefile downloads nsync public INCLUDEPATH home face Desktop eigen eigen 5a0156e40feb LIBS L home face Desktop tensorflow bazel bin tensorflow ltensorflow cc ltensorflow framework main cpp include mainwindow h include QApplication include tensorflow core platform env h include tensorflow core public session h int main int argc char argv QApplication a argc argv MainWindow w w show return a exec then if tensorflow core lib core refcount h line 79 inline RefCounted RefCounted DCHECK EQ ref load 0 to inline RefCounted RefCounted DCHECK EQ ref load 0 it will work Source code logs debug log like 1 google protobuf internal Mutex Lock 0x7fffde0c3516 2 google protobuf internal OnShutdown void 0x7fffde0c3833 3 call init dl init c 72 0x7ffff7de76ba 4 call init dl init c 30 0x7ffff7de77cb 5 dl init dl init c 120 0x7ffff7de77cb 6 dl open worker dl open c 575 0x7ffff7dec8e2 7 dl catch error dl error c 187 0x7ffff7de7564 8 dl open dl open c 660 0x7ffff7debda9 9 dlopen doit dlopen c 66 0x7ffff18f0f09 10 dl catch error dl error c 187 0x7ffff7de7564 11 dlerror run dlerror c 163 0x7ffff18f1571 12 dlopen dlopen c 87 0x7ffff18f0fa1 13 0x7ffff33100e5 14 0x7ffff3309975 15 QFactoryLoader instance int const 0x7ffff32ff07e 16 QPlatformThemeFactory create QString const QString const 0x7ffff0b30231 17 QGuiApplicationPrivate createPlatformIntegration 0x7ffff0b3aaf8 18 QGuiApplicationPrivate createEventDispatcher 0x7ffff0b3b4bd 19 QCoreApplicationPrivate init 0x7ffff331ab3b 20 QGuiApplicationPrivate init 0x7ffff0b3cf7b 21 QApplicationPrivate init 0x7ffff392d3b9 22 main main cpp 103 0x402e3e,,drpngx,2018-02-01 13:04:29,2018-02-02 12:56:35
IS,Imperfect implementation of tf losses mean pairwise squared error,System information TensorFlow version 1 4 0 1 4 1 and 1 5 0 rc0 checked Have I written custom code N A OS Platform and Distribution N A TensorFlow installed from N A Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem The implementation of tf losses mean pairwise squared error looks imperfect For example as explained in the API reference of the function For example if labels a b c and predictions x y z there are three pairs of differences are summed to compute the loss loss a b x y 2 a c x z 2 b c y z 2 3 let me put the following data as labels and predictions In this case the result should be 0 0 5 2 0 1 2 0 5 1 2 3 0 5 but tensorflow returns different value 0 3333333134651184 Suggestion to fix the source code tensorflow python ops losses losses impl py If the loss function mean pairwise squared error measures the differences between pairs of corresponding elements of predictions and labels as explained in the API reference of the function here is a simple patch lines 520 521 need to be changed as term1 2 0 safe div sum squares diff per batch num present per batch 1 and lines 525 526 need to be changed as term2 2 0 safe div math ops square sum diff math ops multiply num present per batch num present per batch 1,,,2018-01-09 05:51:16,2018-02-02 13:37:01
IS,saver restore sess modelpath is able to normal run in tensorflow1 0 1 but have a problem in tensorflow 1 2 1,System information OS Platform and Distribution Ubuntu 14 04 TensorFlow installed from binary TensorFlow version Tensorflow1 0 1 and Tensorflow1 2 1 Python version Python 2 6 GPU model and memory 1080 Ti Describe the problem I meet this problem at following My predict py is able to normal run in Tensorflow 1 0 1 but have shown this proble in Tensorflow 1 2 1 I do not resovle this problem I need help Please Source code logs Source code restore dict for i in variables the first is global step restore dict i name replace ' 0' '' i print arestore variable ' i name replace ' 0' '' saver tf train Saver restore dict init tf global variables initializer sess tf Session sess run init saver restore sess 'news tf model model ckpt' the path is real predict sess run pred feed dict x imgs sess close logs 2017 08 15 16 10 46 657837 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint 2017 08 15 16 10 46 658229 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 658870 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 659232 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell bias not found in checkpoint 2017 08 15 16 10 46 660554 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 684510 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 742777 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 742852 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 743000 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 743241 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 825494 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 826179 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 826199 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 826309 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 826419 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 826988 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 833507 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices 2017 08 15 16 10 46 843310 W tensorflow core framework op kernel cc 1158 Not found Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices Traceback most recent call last File demo py line 25 in module result dict news demo newsAggreg image path File home rszj liutao news aggreg news demo py line 32 in newsAggreg predict news predict run images path File home rszj liutao news aggreg news predict py line 196 in run saver restore sess module file File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 1548 in restore self saver def filename tensor name save path File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python client session py line 789 in run run metadata ptr File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python client session py line 997 in run feed dict string options run metadata File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python client session py line 1132 in do run target list options run metadata File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python client session py line 1152 in do call raise type e node def op message tensorflow python framework errors impl NotFoundError Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices Node save RestoreV2 1 Recv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 112 save RestoreV2 tensor type DT FLOAT device job localhost replica 0 task 0 gpu 0 Caused by op u isave RestoreV2 1' defined at File demo py line 25 in module result dict news demo newsAggreg image path File home rszj liutao news aggreg news demo py line 32 in newsAggreg predict news predict run images path File home rszj liutao news aggreg news predict py line 176 in run saver tf train Saver restore dict when you want to save model File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 1139 in init self build File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 1170 in build restore sequentially self restore sequentially File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 691 in build restore sequentially reshape File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 407 in AddRestoreOps tensors self restore op filename tensor saveable preferred shard File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python training saver py line 247 in restore op spec tensor dtype 0 File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python ops gen io ops py line 640 in restore v2 dtypes dtypes name name File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python framework op def library py line 767 in apply op op def op def File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python framework ops py line 2506 in create op original op self default original op op def op def File home rszj liutao virtualenv liutao py2 mpy2tf1 2 local lib python2 7 site packages tensorflow python framework ops py line 1269 in init self traceback extract stack NotFoundError see above for traceback Key LSTM basic lstm cell kernel not found in checkpoint Node save RestoreV2 1 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 1 tensor names save RestoreV2 1 shape and slices Node save RestoreV2 1 Recv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 112 save RestoreV2 tensor type DT FLOAT device job localhost replica 0 task 0 gpu 0,,"skye,skye,aselle",2017-08-15 08:33:19,2018-02-02 15:32:51
IS,Padding algo is not working as doc says,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linus centos 7 TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 Python version 2 7 5 Bazel version if compiling from source 0 GCC Compiler version if compiling from source 0 CUDA cuDNN version 0 GPU model and memory 0 Exact command to reproduce In the following situation TF doc Convolution is not correct Input tensor shape 1 5 2 1 Kernel shape 1 3 1 1 Stride 1 5 5 1 Padding SAME According to the formula we can compute out h 1 out w 1 gives pad top 0 pad bottom 0 pad left 0 pad right 1 How tensorflow do a convolution with a kernel of height 1 on a image of height 5 and which gives output of height 1 stride 5 How TF do this The doc can not explain the method used Doing retro engineering I saw that TF apply the filter on the middle of the input tensor pad top 2 and pad bottom 2 I agree with this method but the formulas of the Convolution doc is doing max 0 so padding could never be negative according to the doc Could someone explain me clearly what is the formula used in tensorflow Could someone update the doc,,reedwm,2018-02-02 15:19:12,2018-02-02 17:38:10
PR,Branch 184236409,,,case540,2018-02-02 16:48:51,2018-02-02 18:19:25
IS,how to assign the GPU device using C,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2018-02-02 09:14:57,2018-02-02 18:52:11
IS,can tf estimator Estimator is parameters be modified by hand,TF is high level API is very convenient to defined a new model However many DNN Machine Learning task has to reuse some old model is parameter to fill a new model and then fine tune it in new tasks I have read the tf estimator Estimator'API carefully but can not find any API to set It is parameters Hope TF developer add this function to the high level API Thank very much,,"drpngx,drpngx,drpngx,martinwicke",2018-02-01 06:34:16,2018-02-02 19:11:42
PR,Revert Updating the version to 1 6 0 rc0,Accidentally pushed this to master,,av8ramit,2018-02-02 18:22:45,2018-02-02 19:13:45
PR,Update version to 1 6 0 rc0,,,av8ramit,2018-02-02 18:23:44,2018-02-02 19:14:19
IS,How to use model summary when using placeholder instead of Input keras,Dear all I follow post in The little modified code I use is import tensorflow as tf from tensorflow python keras layers import Dense from tensorflow python keras backend import categorical crossentropy from tensorflow examples tutorials mnist import input data from tensorflow python keras models import Model sess tf Session img tf placeholder tf float32 shape None 784 x Dense 128 activation arelu' img fully connected layer with 128 units and ReLU activation x Dense 128 activation arelu' x preds Dense 10 activation isoftmax' x output layer with 10 units and a softmax activation labels tf placeholder tf float32 shape None 10 loss tf reduce mean categorical crossentropy labels preds mnist data input data read data sets 'MNIST data' one hot True train step tf train GradientDescentOptimizer 0 5 minimize loss init op tf global variables initializer sess run init op with sess as default for i in range 100 batch mnist data train next batch 50 train step run feed dict img batch 0 labels batch 1 It work fine until I use model summary model Model inputs img outputs preds The error message show Input tensors to a Model must come from tf layers Input I can use tf layers Input to solve this problem But I really want to use tf placeholder so I can feed data as I like Can anyone help me Thanks,,,2018-01-31 10:23:42,2018-02-02 19:15:06
PR,Remove all files rule from com google absl BUILD,,,yifeif,2018-02-02 19:02:39,2018-02-02 19:38:07
PR,Absl fix,,,av8ramit,2018-02-02 19:41:20,2018-02-02 19:41:55
PR,Fix Define the model link,The link syntax was inverted that is round brackets were coming before square brackets but Markdown does not like it,,caisq,2018-02-01 15:38:23,2018-02-02 20:16:50
IS,Conv2D operator with SAME padding when Stride kernel size showing unexpected results,System information Have I written custom code YES only to demonstrate the problem source code is below OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary PIP TensorFlow version 1 4 0 Python version 2 7 12 Bazel version N A GCC Compiler version N A CUDA cuDNN version N A GPU model and memory N A CPU only Exact command to reproduce See Source Code Below Describe the problem There is an inconsistency between the convolution documentation on padding with 'SAME' located here Convolution and the behavior of the tf nn conv2d operator In the example below I create a 3x1 input with values 1 0 1 1 1 2 and a 1x1 filter of value 1 0 I specify the stride to be 1x3x1x1 which should result in only a single element be output and the padding to be 'SAME' From the padding calculation in the above link pad along height in height 3 strides 1 3 0 so pad along height max filter height 1 strides 1 3 0 pad along height max 2 0 0 pad along width in width 1 strides 2 1 0 so pad along width max filter width 1 strides 2 1 0 pad along width max 0 0 0 My hypothesis is that pad along is not using the max x 0 and as a result pad along height 2 Therefore pad top 1 and pad bottom 1 If that was the case then our input is reduced to only the middle element 1 1 which explains why the TF result of the code below is 1 1 rather than the expected 1 0 value of first input If I change the padding to be VALID no padding then this code below gives the result of 1 0 or if i instead change the stride to 1 2 1 1 i get the expected value of 1 0 although in this case my hypothesis proposes that pad bottom is still 1 Source code logs import tensorflow as tf import numpy as np i tf constant np ones 3 np arange 3 0 1 reshape 1 3 1 1 dtype tf float32 name 'input' f tf constant np ones 1 reshape 1 1 1 1 dtype tf float32 name 'filter' conv tf nn conv2d input i filter f strides 1 3 1 1 padding 'SAME' with tf Session as sess out sess run conv print out Output 1 10000002,,"facaiy,reedwm,yzhwang,yzhwang,reedwm,yzhwang,yongtang,yzhwang",2017-11-16 01:09:19,2018-02-02 20:31:09
PR,Update Eigen library to 2355b229ea4c and fixes conv2d padding issue,This fix updates Eigen to 2355b229ea4c so that the issue raised in 14601 could be fixed This fix fixes 14601 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-02 19:31:34,2018-02-02 20:31:09
PR,Fixing the cuda and cudnn versions in 1 5 docs,,,"av8ramit,gunan",2018-02-02 18:48:14,2018-02-02 20:32:11
IS,gcc error unrecognized command line option ' config opt',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No TensorFlow installed from source or binary source TensorFlow version use command below Python version 2 7 Bazel version if compiling from source release 0 9 0 non git GCC Compiler version if compiling from source Using built in specs COLLECT GCC gcc COLLECT LTO WRAPPER usr local stow gcc 4 9 2 libexec gcc x86 64 unknown linux gnu 4 9 2 lto wrapper Target x86 64 unknown linux gnu Configured with usr src nfs gcc 4 9 2 configure prefix usr local stow gcc 4 9 2 Thread model posix gcc version 4 9 2 GCC CUDA cuDNN version None GPU model and memory x86 64 GNU Linux Exact command to reproduce bazel build config opt tensorflow tools pip package build pip package You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request gcc error unrecognized command line option ' config opt' Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem ''' ERROR usa haoxu cache bazel bazel haoxu 95196ed5087168c723729aeb7fc160d9 external flatbuffers BUILD 22 1 C compilation of rule ' flatb uffers flatbuffers' failed Exit 1 gcc error unrecognized command line option ' config opt' Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 57 329s Critical Path 13 22s FAILED Build did NOT complete successfully ''',,,2018-02-02 16:30:17,2018-02-02 20:51:42
PR,Fix sanity,,,yifeif,2018-02-02 20:42:08,2018-02-02 20:54:21
IS,Dependency on old version of bleach 1 5,Bleach 1 5 came out Nov 4th 2016 and this is old enough to cause dependency issues for projects that stayed up to date with Bleach In particular this causes issues for Jupyter users,,"tatianashp,gunan,tatianashp,jart,jart,jart",2018-01-25 23:20:59,2018-02-02 22:16:28
PR,Add k8 to detection for when to use neon tensor utils,,,aselle,2018-02-02 21:58:36,2018-02-02 22:42:31
PR,Revert Update external protobuf codebase version for Windows cmake b,uild This reverts commit 07bec47ba5db4c2f2e33ecb49f23253a371bfbbe,,av8ramit,2018-02-02 21:02:41,2018-02-02 23:49:40
IS,import tensorflow error with correct installation the problem is Could not find field google protobuf DescriptorProto ExtensionRange options,Hi everyone System information Operating System Ubuntu 16 04 LTS Graphics card Tesla K40 Installed version of CUDA 8 0 Installed version of cuDNN v5 for CUDA 8 0 pip version 9 0 1 pip 9 0 1 from usr local lib python2 7 dist packages python 2 7 Tensorflow gpu installed from pip sudo pip install tensorflow gpu Version 1 2 1 pip version Name pip Version 9 0 1 Summary The PyPA recommended tool for installing Python packages Home page Author The pip developers Author email python virtualenv groups google com License MIT Location usr local lib python2 7 dist packages Requires tensorboard version Name tensorboard Version 1 0 0a6 Summary Standalone TensorBoard for visualizing in deep learning Home page Author zihaolucky Author email zihaolucky gmail com License Apache 2 0 Location usr local lib python2 7 dist packages Requires mock Pillow numpy protobuf wheel six werkzeug tensorflow gpu version Name tensorflow gpu Version 1 2 1 Summary TensorFlow helps the tensors flow Home page Author Google Inc Author email opensource google com License Apache 2 0 Location usr local lib python2 7 dist packages Requires mock numpy bleach markdown wheel six protobuf backports weakref html5lib werkzeug The problem When I open the terminal and type python import tensorflow I get I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcublas so 8 0 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcudnn so 5 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcufft so 8 0 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcuda so 1 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcurand so 8 0 locally Traceback most recent call last File stdin line 1 in module File home bids local lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home bids local lib python2 7 site packages tensorflow python init py line 75 in module from tensorflow core framework graph pb2 import File home bids local lib python2 7 site packages tensorflow core framework graph pb2 py line 10 in module from google protobuf import descriptor pb2 File usr local lib python2 7 dist packages google protobuf descriptor pb2 py line 409 in module options None File usr local lib python2 7 dist packages google protobuf descriptor py line 501 in new return message default pool FindFieldByName full name KeyError Could not find field google protobuf DescriptorProto ExtensionRange options Source code logs Before I upgrade the tensorboard and pip version the default pip version is 8 x in Ubuntu 16 04 LTS After that I type following code in the terminal python home wcm local lib python2 7 site packages tensorboard tensorboard py logdir ' tmp log' The problem is KeyError Could not find field google protobuf DescriptorProto ExtensionRange options Next I type import tensorflow The same problem is KeyError Could not find field google protobuf DescriptorProto ExtensionRange options Finally I re installing tensorflow gpu tensorflow and tensorboard step by step no change The same problem for import tensorflow Anyone have an idea for this problem Thanks in advance jiandanjinxin,,"reedwm,reedwm,reedwm,gunan,drpngx",2017-08-16 11:54:45,2018-02-02 23:55:59
IS,RenderScript support,Is there a reason for not supporting RenderScript It is there an ETA for this,,"bryant1410,drpngx,bryant1410",2017-09-06 11:37:01,2018-02-03 00:02:06
IS,is numeric tensor on ref variables,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 3 5 Bazel version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce Describe the problem I'm not sure if this is a bug or a feature I feel it is a bug I want to be able to test if an input to a function was a numpy style array or a tensor I use the tf is numeric tensor to check the input however it does not pick up on ref variables such as those initialized from a numpy array,,"rohan100jain,rohan100jain,langmore,facaiy,drpngx",2017-09-08 13:43:00,2018-02-03 00:04:59
PR,DO NOT MERGE Testing,,,av8ramit,2018-02-02 08:47:51,2018-02-03 00:05:11
IS,Ca not initialize an all zero SparseTensor,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Kind of OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 12 6 not relevant TensorFlow installed from source or binary binary TensorFlow version use command below v1 5 0 Python version 3 6 3 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA Describe the problem It does not seem possible to initialize a tf SparseTensor with all zero entries A call doing this would look something like tf SparseTensor indices values dense shape 10 10 However attempting this initialization produces the error ValueError Shape 0 must have rank 2 Source code logs Current relevant section from SparseTensor init indices shape indices get shape with rank 2 with rank 2 is what causes the problem values shape values get shape with rank 1 dense shape shape dense shape get shape with rank 1 Assert number of rows in indices match the number of elements in values indices shape 0 merge with values shape 0 Assert number of columns in indices matches the number of elements in dense shape indices shape 1 merge with dense shape shape 0 Example solution tf cond tf equal indices get shape 0 0 true fn lambda None false fn self validate input def validate input self indices shape self indices get shape with rank 2 values shape self values get shape with rank 1 dense shape shape self dense shape get shape with rank 1 Assert number of rows in indices match the number of elements in values indices shape 0 merge with values shape 0 Assert number of columns in indices matches the number of elements in dense shape indices shape 1 merge with dense shape shape 0 My only worry with the example solution is that tf cond is too high level a function and there is some alternative that would be better Is that the case,,"reedwm,ebrevdo,ebrevdo",2018-02-02 20:29:29,2018-02-03 00:14:37
PR,Removing the typo line,,,"av8ramit,gunan,av8ramit",2018-02-02 21:23:54,2018-02-03 00:18:26
IS,feature request recomputable operation annotation,'Training Deep Nets with Sublinear Memory Cost' and 'Memory Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory while add computation burden so we need some mechanism to annotate some op is inputs recomputable and drop this input memory after op finish set input is reference count to 0 when need this op again recompute it relate issue in short normal reference add reference count recomputable reference do not add reference count,,"yaroslavvb,aselle,zheng-xq,yaroslavvb,ahundt,zheng-xq,yaroslavvb,drpngx",2017-09-19 17:17:57,2018-02-03 00:30:28
PR,Fix spelling change invaild to invalid,,,,2018-02-02 21:56:39,2018-02-03 00:34:56
PR,Fix a broken link in regression examples md,This fix fixes a broken link in regression examples md,,yongtang,2018-02-02 05:35:05,2018-02-03 00:36:42
PR,Convert unicode to six string types for python 3,In Python 3 there is no unicode type This fix converts unicode to use six string types instead while maintaining python 2 3 compatibility Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-01 22:03:33,2018-02-03 00:37:50
PR,fix typo,fix typo,,ManHyuk,2018-02-02 01:59:24,2018-02-03 00:38:55
PR,Fix docs,Fix xcode path error,,,2018-02-01 10:24:43,2018-02-03 00:39:18
IS,Bug MultiRNNCell state size is a tuple,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Bazel version if compiling from source n a CUDA cuDNN version 8 0 GPU model and memory 1080 Ti Exact command to reproduce see below Describe the problem Version 1 The follow code will return LSTMStateTuple with h and c It will return state tensor just the c part not the h activation,,"ebrevdo,drpngx",2017-06-20 18:06:26,2018-02-03 01:26:05
IS,TF 1 2 vs 1 1 Keras K set learning phase False not working in 1 2 but works in 1 1,Hi all Works fine in 1 1 but in 1 2 This does not happen in 1 1 What may have changed that cause this in 1 2 Thank you in advance Best regards Dylan Randle,,"fchollet,drpngx",2017-07-06 21:47:48,2018-02-03 01:28:58
IS,py test dir tensorflow python bitwise ops test failing on Windows,Culprit cl 163090921,,"meteorcloudy,gunan,ebrevdo,ebrevdo,drpngx",2017-07-26 09:17:07,2018-02-03 01:30:25
IS,InternalError Blas GEMM launch failed,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Distributor ID Ubuntu Description Ubuntu 16 04 2 LTS Release 16 04 TensorFlow installed from source or binary pip3 install tensorflow gpu TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 5 CUDA cuDNN version nvcc NVIDIA R Cuda compiler driver Copyright c 2005 2016 NVIDIA Corporation Built on Tue Jan 10 13 22 03 CST 2017 Cuda compilation tools release 8 0 V8 0 61 GPU model and memory description 3D controller product GK210GL Tesla K80 vendor NVIDIA Corporation physical id 0 bus info pci 99ba 00 00 0 version a1 width 64 bits clock 33MHz capabilities bus master cap list configuration driver nvidia latency 0 resources iomemory 100 ff iomemory 140 13f irq 24 memory 21000000 21ffffff memory 1000000000 13ffffffff memory 1400000000 1401ffffff Code example estimator KerasRegressor build fn self create model function input dim self input dim output dim self output dim self model parameters param grid 'epochs' 5 'batch size' 256 'neurons' 10 10 10 wouldropout' 0 0 0 0 grid GridSearchCV estimator estimator param grid param grid n jobs 1 Describe the problem The InternalError occurred when I fit a sklearn GridSearchCV object The error occurred only if I use GPU and I I use GridSearch object It works fine on CPU and on single model fitting using Keras wrapper Error log File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn model selection search py line 945 in fit return self fit X y groups ParameterGrid self param grid File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn model selection search py line 564 in fit for parameters in parameter iterable File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel py line 728 in call n jobs self initialize backend File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel py line 540 in initialize backend self backend args File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel backends py line 311 in configure self pool MemmapingPool n jobs backend args File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib pool py line 600 in init super MemmapingPool self init poolargs File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib pool py line 420 in init super PicklingPool self init poolargs File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing pool py line 168 in init self repopulate pool File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing pool py line 233 in repopulate pool w start File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing process py line 105 in start self popen self Popen self File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing context py line 267 in Popen return Popen process obj File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing popen fork py line 20 in init self launch process obj File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing popen fork py line 74 in launch code process obj bootstrap File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing process py line 249 in bootstrap self run File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing process py line 93 in run self target self args self kwargs File home aateam conda envs amplifon dev3 lib python3 5 multiprocessing pool py line 119 in worker result True func args kwds File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel backends py line 344 in call return self func args kwargs File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel py line 131 in call return func args kwargs for func args kwargs in self items File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn externals joblib parallel py line 131 in listcomp return func args kwargs for func args kwargs in self items File home aateam conda envs amplifon dev3 lib python3 5 site packages sklearn model selection validation py line 238 in fit and score estimator fit X train y train fit params File home aateam conda envs amplifon dev3 lib python3 5 site packages keras wrappers scikit learn py line 136 in fit self model self build fn self filter sk params self build fn File home aateam Amplifon amplifon adv planning src libs amplifon objects py line 176 in create test model model add Dense neurons 0 input dim input dim activation last activation File home aateam conda envs amplifon dev3 lib python3 5 site packages keras models py line 436 in add layer x File home aateam conda envs amplifon dev3 lib python3 5 site packages keras engine topology py line 596 in call output self call inputs kwargs File home aateam conda envs amplifon dev3 lib python3 5 site packages keras layers core py line 838 in call output K dot inputs self kernel File home aateam conda envs amplifon dev3 lib python3 5 site packages keras backend tensorflow backend py line 978 in dot out tf matmul x y File home aateam local lib python3 5 site packages tensorflow python ops math ops py line 1816 in matmul a b transpose a transpose a transpose b transpose b name name File home aateam local lib python3 5 site packages tensorflow python ops gen math ops py line 1217 in mat mul transpose b transpose b name name File home aateam local lib python3 5 site packages tensorflow python framework op def library py line 767 in apply op op def op def File home aateam local lib python3 5 site packages tensorflow python framework ops py line 2506 in create op original op self default original op op def op def File home aateam local lib python3 5 site packages tensorflow python framework ops py line 1269 in init self traceback extract stack InternalError see above for traceback Blas GEMM launch failed a shape 256 32 b shape 32 10 m 256 n 10 k 32 Node dense 1 MatMul MatMul T DT FLOAT transpose a false transpose b false device job localhost replica 0 task 0 gpu 0 arg dense 1 input 0 0 15 dense 1 kernel read Node mul 1 43 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 795 mul 1 tensor type DT FLOAT device job localhost replica 0 task 0 cpu 0,,"reedwm,reedwm,fchollet,reedwm,reedwm,drpngx",2017-07-27 10:07:15,2018-02-03 01:32:24
IS,Feature request Dynamically add new machines in distributed TensorFlow,I'm not sure this has been raised before I did some search on Google and have not found relevant stuff If it do exist please direct me there Thank you I'm currently experimenting with distributed TensorFlow When building a distributed cluster all machines in the cluster should be fed into tf train Server as parameters That is the disitributed cluster configuration is defined when building the computation graph Like the example provided in But I have also read papers about robust distributed cluster that it would be nice if the framework support dynamically adding or removing machines if the cluster get larger or some machine goes down Is this doable in current version of TensorFlow If so is there an example to implement this If not is there plans for this,,"yaroslavvb,byronyi,aselle,saeta,yaroslavvb,yaroslavvb,yaroslavvb",2017-07-31 02:27:05,2018-02-03 01:33:05
IS,Memory leak in Java API when using GPU,System information Custom code OS CentOS 7 TensorFlow installed from source or binary binary TensorFlow version use command below n a Python version n a Bazel version if compiling from source n a CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1080 Exact command to reproduce see Describe the problem Main memory on the machine is continuously consumed when running on the GPU Memory consumption hovers around 600M when running on the CPU Source code logs see,,"shivaniag,asimshankar,asimshankar,drpngx",2017-08-01 18:52:55,2018-02-03 01:35:39
IS,Nudge function in fake quantization returns non nudegd scale value,The Nudge function tensorflow tensorflow core kernels fake quant ops functor h aims to keep the real zero value including in quantization input range After min max values are nudged the scale keeps its original value Is it intended to be,,"reedwm,suharshs,suharshs,drpngx",2017-08-09 09:28:15,2018-02-03 01:37:18
IS,Linker Tools Error encountered when use StepStats,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 0 16299 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 release Python version 3 5 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem Encounter link error when build the program source code attached Build went through well with TF 1 4 release Error LNK2001 unresolved external symbol class tensorflow StepStatsDefaultTypeInternal tensorflow StepStats default instance StepStats default instance tensorflow 3VStepStatsDefaultTypeInternal 1 A ReprBug c Users xx documents visual studio 2015 Projects ReprBug ReprBug Source obj Source code logs,,drpngx,2018-02-03 01:07:58,2018-02-03 01:39:35
PR,Branch 184352399,,,jhseu,2018-02-03 00:56:51,2018-02-03 01:40:59
IS,The link for the tutorial on Google is Tensorflow SyntaxNet page gives 404 error,Go tot the page and click the tutorial link It gets a 404 error The target of the link is installation,,"drpngx,MarkDaoust",2018-02-02 03:58:02,2018-02-03 04:49:04
IS,bazel build failure of current master in Docker container due to contrib lite,Building current GPU version of master branch tensorflow tensorflow 31b79e42b9e1643b3bcdc9df992eb3ce216804c5 fails in Docker container saying usr bin ld warning libcuda so 1 needed by bazel out host bin solib local U S Stensorflow Scc Cops Sdata Uflow Uops Ugen Ucc Utensorflow libtensorflow framework so not found try using rpath or rpath link and I find that it is due to contrib lite when I comment out the related dependencies in tensorflow tools pip package BUILD L164 L166 the build success I know this error is typically solved when I create a soft link inside the container before to build c f 10776 RUN ln s usr local cuda lib64 stubs libcuda so usr local cuda lib64 stubs libcuda so 1 but this time it does not help,,"angersson,angersson,angersson,gunan,gunan",2017-11-15 08:40:46,2018-02-03 09:16:42
PR,R1 6,,,,2018-02-03 12:31:58,2018-02-03 12:32:53
IS,feature request Multi arity elems in fold l r,The functions or as to how this would fit in with the larger goals for the project,,skye,2017-06-30 05:20:51,2018-02-03 13:04:34
PR,Cherrypicks,,,"av8ramit,jhseu",2018-02-03 01:54:16,2018-02-03 16:55:28
PR,Branch 184376425,,,jhseu,2018-02-03 13:39:53,2018-02-03 17:38:44
IS,Recommendation Expose tensorflow core kernels dataset h in wheel file,Hi Right now to build a new dataset op you need to access to the header file tensorflow core kernels dataset h but the tensorflow wheel does not expose this header Use case I built new Dataset Ops to read Kaldi is Table I O format to enable others to be able to move from Kaldi based automatic speech recognition recipes to tensorflow based ones without having to do a bunch of extra data munging Right now I require users to build tensorflow from source code and point my build to the tensorflow source code path so I can guarantee that I have access to a header file compatible with their binary I would prefer to be able to build my package by depending only on pip installed tensorflow to make things easier on users I manually verified that adding in tensorflow tools pip package BUILD will include the right header file This is a pretty small change Is there a particular reason why tensorflow does not already expose the header file Is this an oversight or because you are not ready to expose this interface publically,,,2018-02-02 03:08:50,2018-02-03 17:39:22
PR,Disable win io utils test for windows,,,av8ramit,2018-02-03 17:19:02,2018-02-03 18:43:39
PR,Fix Python3 crazy SessionTest testReentryWithCApi failure,credit skyewm,,av8ramit,2018-02-03 17:06:41,2018-02-03 18:44:33
PR,Fix the Windows GPU build,device functions h moved in CUDA 9 1 which breaks the Windows GPU build It is not needed here,,"jhseu,jhseu",2018-02-03 17:48:26,2018-02-03 19:00:38
PR,dupe 14385,,,,2018-02-03 20:20:46,2018-02-03 20:20:56
PR,Delete device functions h include,,,av8ramit,2018-02-03 19:04:01,2018-02-03 20:25:53
PR,Fixed a couple of typos,Fixed a couple of typos,,,2018-02-03 18:42:26,2018-02-03 23:22:23
PR,change to anchor link,Fixing markdown typo,,,2018-02-02 10:10:12,2018-02-03 23:22:49
PR,Fixing the cuda and cudnn versions in 1 5 docs 16702,,,,2018-02-04 00:40:21,2018-02-04 00:41:00
IS,Memory leak when reusing variables with slim,System information Windows 7 x64 Python 3 5 2 Anaconda 4 2 0 64 bit Tensorflow 1 3 0 installed via pip Problem I want to use TF Slim models to classify images in a server For this I would like to load the network only once and reuse the variables I adjusted the tutorial given here Code to reproduce Memory Usage monitored with Process Explorer memory This is the memory usage when calling the predict function 20 times As you can see it keeps increasing Am I doing it wrong or is it a bug,,"jart,ppwwyyxx,sguada,sguada",2017-08-30 09:58:10,2018-02-04 05:05:53
PR,Making the for canonicalization test only for py2 and 3,TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON3 label mac slave 239 consoleFull,,av8ramit,2018-02-04 01:24:34,2018-02-04 05:17:28
IS,'module' object has no attribute isparse column with vocabulary file',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Running on Cloud ML Engine TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 Describe the problem I am trying to use tf contrib layers sparse column with vocabulary file and I am getting an error that it does not exist I recognize that it is not showing up when I search for it in the API but it is showing up in the source code here L669 I even specified the r1 3 branch and it was still showing up Has this been removed and I am just looking in the wrong place It seems like this may be a bug and the function should exist in 1 3 If it was deprecated is it because there are workarounds when trying to generate a feature column from a sparse tensor of words I can create the hash table with but since I am trying to add this in the feature columns I need something to read in the sparse tensor of words in ie words tf contrib layers or words tf feature column Or Assuming deprecation is the suggested implementation just to do all of these transformations in the input fn and just pass a sparse column with integerized feature directly Personally this feels awkard to perform half of the transformation in the input function but without sparse column with vocabulary file it feels like there is no other choice With this function it should be easy to go from This is a sentence tf string split yields This is a sentence sparse tensor of strings within the input fn and then tf contrib sparse column with vocabulary file sparse tensor of ids tf contrib layers embedding column which yields the embedding from a sparse tensor of id is,,"facaiy,facaiy",2017-08-24 20:54:06,2018-02-04 05:18:31
IS,TF Slim allow soft placement for devices with train image classifier,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 5 TensorFlow installed from source or binary source TensorFlow version use command below git tag 1 2 Python version 2 7 system install Bazel version if compiling from source home brew 0 4 5 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce train Mobilenet v1 on CPU like so python train image classifier py train dir TRAIN DIR dataset dir DATASET DIR dataset name Framing dataset split name train model name mobilenet v1 checkpoint path CHECKPOINT PATH checkpoint exclude scopes MobilenetV1 Logits Conv2d 1c 1x1 biases MobilenetV1 Logits Conv2d 1c 1x1 weights Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Tensorflow 1 2 has no GPU support for macOS Thus training retraining can only happen on CPU TF Slim doesnt appear to have an out of the box way to specify soft placement of nodes therefore I can not appear to train a mobile net checkpoint Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem INFO tensorflow Summary name clone loss is illegal using clone loss instead INFO tensorflow Fine tuning from Volumes MediaArchive datasets SynopsisCinemaNet model mobilenet v1 1 0 224 2017 06 14 mobilenet v1 1 0 224 ckpt index INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' Cannot assign a device for operation 'MobilenetV1 Logits Conv2d 1c 1x1 biases RMSProp 1' Operation was explicitly assigned to device GPU 0 but available devices are job localhost replica 0 task 0 cpu 0 Make sure the device specification refers to a valid device Node MobilenetV1 Logits Conv2d 1c 1x1 biases RMSProp 1 VariableV2 class loc MobilenetV1 Logits Conv2d 1c 1x1 biases container dtype DT FLOAT shape 5 shared name device device GPU 0,,sguada,2017-06-30 17:57:01,2018-02-04 05:29:12
PR,Fix the Windows GPU build 2,Tested that this fixes the build,,jhseu,2018-02-04 06:04:01,2018-02-04 07:34:16
PR,Fix the Windows GPU build 2,,,av8ramit,2018-02-04 07:35:53,2018-02-04 10:42:53
PR,Grammatical error fixed,,,,2018-02-04 06:48:24,2018-02-04 14:42:34
IS,MonitoredSession after run hook returning empty SessionRunValues results,System information Have I written custom code yes OS Platform and Distribution Arch Linux 4 14 15 1 TensorFlow installed from source master TensorFlow version v1 5 0 2123 g66105a6144 Python version 3 6 4 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 7 3 0 CUDA cuDNN version 9 1 85 7 0 5 GPU model and memory Nvidia GTX 1080 8GB Exact command to reproduce python test py Describe the problem When running a MonitoredSession with after run hooks the result passed to run values is None when there should be output Source code logs test py I have changed this in my fork by replacing L1176 with results outputs 'caller' However this breaks training with an Estimator wrapping a MonitoredSession If I'm misinterpreting the usage of the after run hook please let me know,,ppwwyyxx,2018-02-04 03:33:56,2018-02-04 18:28:09
PR,fix typo,fix typo,,ManHyuk,2018-02-03 09:43:10,2018-02-04 18:49:49
IS,error in code,W 0 utils weight variable FLAGS z dim 64 GEN DIMENSION 2 IMAGE SIZE 16 IMAGE SIZE 16 NameError name 'utils' is not defined can you help me please,,mrry,2018-02-04 00:58:17,2018-02-04 18:58:03
PR,Fix the mac builds on r1 6,Without this setting it runs 2to3 on the python files In master it is set to PY2 which is also wrong Tested that the builds pass with this change,,jhseu,2018-02-04 19:29:55,2018-02-04 20:28:48
IS,incorrect logging formatting used in tensorflow examples image retraining retrain py causes error,In tensorflow examples image retraining retrain py currently lines 347 348 look like this This understandably causes an error since this function accepts strings and it is being fed an instance of statinfo st size which does not seem to be a string On my machine at least TensorFlow 1 5 Windows 10 this causes the following error in function maybe download and extract TypeError not all arguments converted during string formatting Here is a screenshot if that helps error The line numbers are slightly different in my screenshot because I moved a few lines around but I can assure you the line above is causing the logging error I would suggest changing this line to the following or similar tf logging info 'Successfully downloaded ' str filename ' statinfo st size ' str statinfo st size ' bytes',,yongtang,2018-02-03 22:59:57,2018-02-05 04:01:29
PR,Fix logging format error in retrain py,This fix fixes the logging format error in tensorflow examples image retraining retrain py This fix fixes 16735 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,yongtang",2018-02-03 23:50:53,2018-02-05 04:01:29
IS,Does it makes sense to use AdamOptimizer with Dropout,I was experimenting with Dropout and I tried to check the number of weights updated in every iteration My network has an input layer of size 100 and output layer of size 1 and I use dropout with keep prob of 0 8 With this configuration I am expecting to update every time around 80 neurons I tried to check this and I got weird results I asked in stackexchange and someone got the right answer the optimizer was updating all the weights I was using Adam and when I changed to GradientDescent Adagrad and Adadelta it worked well I have not tried more optimizers thought Here is the code Just in case is not clear enough in the code I'm printing two sets of numbers The first set is the number of zeros in the masked dropout layer and since I'm using 0 8 keep prob I should have around 20 of zeros so I should get a number around 20 This part works well The second set counts how many weights were NOT updated difference between the previous weight and the current weight Therefore I am expecting these two sets to display the same numbers Again with Adam does not work because it updates more weights whereas GradientDescend Adadelta and Adagrad it works well Question Is this a bug or is it supposed to be like this In the latter case does it make sense to use Adam with Dropout,,drpngx,2018-02-05 03:26:57,2018-02-05 07:23:02
IS,Tensorflow 1 5 0 import error under CUDA 8 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below 1 5 0 Python version 3 5 4 CUDA cuDNN version 8 0 6 0 GPU model and memory GTX1080ti Exact command to reproduce pip install tensorflow gpu python import tensorflow as tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Tensorflow 1 4 works fine with the same setup as described above However after upgrade tensorflow to 1 5 using pip install tensorflow gpu it fails to import tensorflow package in python Source code logs tensorflow 1 5 C WINDOWS system32 python Python 3 5 4 Continuum Analytics Inc default Aug 14 2017 13 41 13 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Program Files Anaconda3 envs tensorflow 1 5 lib site packages tensorflow python platform self check py line 75 in preload check ctypes WinDLL build info cudart dll name File C Program Files Anaconda3 envs tensorflow 1 5 lib ctypes init py line 351 in init self handle dlopen self name mode OSError WinError 126 The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Program Files Anaconda3 envs tensorflow 1 5 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Program Files Anaconda3 envs tensorflow 1 5 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Anaconda3 envs tensorflow 1 5 lib site packages tensorflow python pywrap tensorflow py line 30 in module self check preload check File C Program Files Anaconda3 envs tensorflow 1 5 lib site packages tensorflow python platform self check py line 82 in preload check build info cudart dll name build info cuda version number ImportError Could not find 'cudart64 90 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 9 0 from this URL,,"mrry,mrry,gunan,gunan,gunan,gunan,gunan",2018-02-01 17:56:40,2018-02-05 07:30:03
IS,Discrepancies between GPU and CPU in floating point operations,Running this graph on GPU results in positive infinities whereas on CPU these tensor entries evaluate to 88 72284 I could not quite figure out which operation is responsible for the difference In both cases TensorFlow reports probs as float32 The difference does not occur when replacing probs with a tf ones tensor in float32 format,,ppwwyyxx,2018-02-03 23:40:30,2018-02-05 11:40:28
PR,Fixed typo,Fixed some typos,,,2018-01-31 09:10:18,2018-02-05 13:02:05
IS,Virtual GPU config crashes TensorFlow after physical GPU loaded,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 9 3 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 5 0 2132 gbdea071e68' '1 5 0' Python version 2 7 13 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source Debian 4 9 2 10 4 9 2 CUDA cuDNN version 9 1 7 0 GPU model and memory K40m 11439 MB Exact command to reproduce see the following script Describe the problem Check failed when creating virtual GPU device after loading physical GPU information with tensorflow python client device lib list local devices Source code logs Source code,,"byronyi,aaroey",2018-02-04 12:41:27,2018-02-05 16:24:11
IS,Cross Compiled For Rpi Successfully on Gentoo No Scope and Session support,Hello everyone I cross compiled from tensorflow master using armv7a hardfloat linux gnueabi gcc built using crossdev on Gentoo AMD64 make j9 f tensorflow contrib makefile Makefile HOST OS LINUX TARGET PI OPTFLAGS Os mfpu neon vfpv4 funsafe math optimizations ftree vectorize CXX armv7a hardfloat linux gnueabi g I am able to execute on Rpi the sample label image cc program by compiling it manually using armv7a hardfloat linux gnueabi g Wl whole archive lib libtensorflow core a Wl whole archive lib libnsync a Wl no whole archive lib libprotobuf a ldl lm lpthread lz I include I include public label image cc std c 11 armv7a hardfloat linux gnueabi pkg config cflags libs libjpeg o test However when trying to compile a program that uses tensorflow Scope and tensorflow ClientSession i get undefined references to them armv7a hardfloat linux gnueabi g Wl whole archive lib libtensorflow core a Wl whole archive lib libnsync a Wl no whole archive lib libprotobuf a ldl lm lpthread lz I include I include public test cpp std c 11 o test tmp ccZyvm2X o In function main' test cpp text 0x9c undefined reference to tensorflow Scope NewRootScope ' test cpp text 0x114 undefined reference to tensorflow Input Initializer Initializer std initializer list tensorflow Input Initializer const ' test cpp text 0x128 undefined reference to tensorflow ops Const tensorflow Scope const tensorflow Input Initializer const ' test cpp text 0x1a4 undefined reference to tensorflow Input Initializer Initializer std initializer list tensorflow Input Initializer const ' test cpp text 0x1b8 undefined reference to tensorflow ops Const tensorflow Scope const tensorflow Input Initializer const ' test cpp text 0x220 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' test cpp text 0x280 undefined reference to tensorflow ops MatMul MatMul tensorflow Scope const tensorflow Input tensorflow Input tensorflow ops MatMul Attrs const ' test cpp text 0x2a4 undefined reference to tensorflow Scope Scope ' test cpp text 0x2dc undefined reference to tensorflow ClientSession ClientSession tensorflow Scope const ' test cpp text 0x334 undefined reference to tensorflow ClientSession Run std vector tensorflow Output std allocator tensorflow Output const std vector tensorflow Tensor std allocator tensorflow Tensor const' test cpp text 0x448 undefined reference to tensorflow ClientSession ClientSession ' test cpp text 0x484 undefined reference to tensorflow Scope Scope ' test cpp text 0x53c undefined reference to tensorflow Scope Scope ' test cpp text 0x5e4 undefined reference to tensorflow ClientSession ClientSession ' test cpp text 0x62c undefined reference to tensorflow Scope Scope ' collect2 error ld returned 1 exit status Has support for Scope and ClientSession intentionally been left out of the Makefile Is there a way to add support for it Regards Mandar Joshi,,,2018-02-04 07:42:49,2018-02-05 16:45:35
IS,Object Tracking Support,I have a bug after updating to the latest android studio and building the detection app with it For previous versions of android studio I did not have this issue before when I ran the tf detect app it showed an error for few seconds that says Object Tracking Support Not Found and when I add the line dependencies compile 'org tensorflow tensorflow android ' to the gradle build file it shows another error Error 42 0 Could not find method compile for arguments org tensorflow tensorflow android on object of type org gradle api internal artifacts dsl dependencies DefaultDependencyHandler a href openFile C Users mohda Desktop tensorflow master new tensorflow master tensorflow examples android build gradle Open File a any suggestions or fixes to this issue please What am I doing I have created a custom trained detector and it was working fine till android studio was updated I have even tried with a fresh copy of the original demo and I have the same error Yet when I downloaded the nightly build apk it did not show any error so it must be the android studio tensorflow compatibility dependency issue here Thanks,,andrewharp,2018-01-06 17:03:49,2018-02-05 19:32:24
PR,Fix the incorrect link to vulnerability reporting,This fix fixes the incorrect link to vulnerability reporting Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-05 16:56:21,2018-02-05 21:43:22
PR,Fix incorrect reference DOI number link for GDR,This fix fixes the incorrect reference DOI number link for GDR The previous link in the README md does not work and returns 404 The new link should be the correct one Signed off by Yong Tang yong tang github outlook com,,"yongtang,byronyi",2018-02-03 21:21:50,2018-02-05 22:01:26
PR,Propagate the name on resource variable assign,,,alextp,2018-02-03 00:01:58,2018-02-05 22:02:37
PR,Bump the required numpy version to 1 13 3 in r1 6,,,jhseu,2018-02-05 21:38:50,2018-02-05 22:54:09
PR,Fix typo,,,ManHyuk,2018-02-05 00:23:44,2018-02-05 23:11:17
PR,Resolve Programmatic mistake,SPECIES should have been either imported here or it should have referenced from iris data The corresponding code is correct but the conflict in the documentation,,"jhseu,jhseu,jhseu",2018-02-05 04:03:04,2018-02-05 23:15:12
PR,Fix issue for JNI library loading,This issue is founded when running a Java web app from docker Current NativeLibrary load JNI from a relative path the program is expecting to load the library from an absolute path,,,2018-02-04 14:35:32,2018-02-05 23:30:18
PR,Ensure bash is invoked as a login shell on windows otherwise fixups fail,Hi This PR contains a small fix to repo bzl to ensure that bash is invoked as a login shell on Windows Otherwise depending on the tf http archive execution bash fails to find rm and or patch Note this issue only manifests itself when Bazel is invoked from a Windows command prompt E g Environment Version OS Win10 Ent Bazel 0 8 1 msys2 msys2 x86 64 20161025 Cheers Andy,,"andykernahan,case540,rongjiecomputer,andykernahan,rongjiecomputer",2018-01-30 10:52:42,2018-02-05 23:33:51
PR,Removing duplicate code block that raises exception,For TensorFlow version 1 5 0 rc1 the code block below raises a ValueError Simply remove the duplication lines 274 277 are exactly the same and the issue is resolved,,,2018-01-30 03:19:48,2018-02-05 23:35:47
PR,Bump the rtol in hmc test,This test is flaky due to the rtol,,"jhseu,jhseu,jvdillon",2018-02-05 23:29:53,2018-02-06 00:05:26
PR,Remove invalid exception in linear operator,Remove unreachable NotImplementedError exception from assert non singular in LinearOperator,,,2018-02-01 23:30:20,2018-02-06 00:15:22
IS,Documentation error in attention wrapper py,In tf contrib seq2seq attention wrapper py file in line 295 it should be batch size 1 max time instead of batch time hope to fix it soon Thanks,,"reedwm,imsheridan",2017-11-16 17:40:38,2018-02-06 00:15:33
PR,Fix typo in attention wrapper py,This is to fix 14629 As said in the discussion the description of the output shape should be batch size 1 max time instead of the current batch time 1 max time which does not make sense because batch time does not occur elsewhere,,imsheridan,2018-02-01 03:54:37,2018-02-06 00:15:33
IS,Module missing,,,,2018-02-05 21:08:05,2018-02-06 05:15:41
IS,Save a numpy params as tensorflow model,Hi I have trained a model and i save the params in a numpy file in dict type Now i construct the network manually and set the params as my trained model i want to save the network as tensorflow model but the session is empty so how could i save the model,,,2018-02-06 03:21:16,2018-02-06 05:15:59
IS,build all android sh does not work on TF 1 4 branch,Run build all android sh on the 1 4 branch and it will fail with cp PATH tensorflow tensorflow contrib makefile downloads nsync public No such file or directory,,"Androbin,Androbin",2017-12-15 10:59:00,2018-02-06 07:44:02
IS,tf contrib ffmpeg decode audio prints the ffmpeg stdout,tf contrib ffmpeg decode audio prints the ffmpeg stdout for each input and there seems to be not functionality available to suppress that,,,2017-12-19 08:28:27,2018-02-06 08:04:03
IS,OOM when allocating tensor with shape,I'm using tensorflow 1 3 tested on a linux machine with 2 NVIDIA Tesla K80 cards however I keep getting OOM error on GPU but it does not happen when using cpu for training log below Exception happened during training message OOM when allocating tensor with shape 1792 4096 Node projectx trainig gpu 0 gradients projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell MatMul 36 grad MatMul 1 MatMul T DT FLOAT transpose a true transpose b false device job localhost replica 0 task 0 device GPU 0 projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell concat 36 projectx trainig gpu 0 gradients projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell BiasAdd 36 grad tuple control dependency Node projectx trainig gpu 0 gradients concat 2929 Recv client terminated false recv device job localhost replica 0 task 0 device CPU 0 send device job localhost replica 0 task 0 device GPU 0 send device incarnation 1 tensor name edge 646323 projectx trainig gpu 0 gradients concat tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0 Caused by op 'projectx trainig gpu 0 gradients projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell MatMul 36 grad MatMul 1' defined at File sync train py line 383 in module main File sync train py line 380 in main train config File sync train py line 64 in train train model projectx projectx n gpu config is training True reuse False File kaldi exp tacotron exp 2 projectx py line 291 in init grads and vars self optimizer compute gradients loss File usr local lib python3 5 dist packages tensorflow python training optimizer py line 414 in compute gradients colocate gradients with ops colocate gradients with ops File usr local lib python3 5 dist packages tensorflow python ops gradients impl py line 581 in gradients grad scope op func call lambda grad fn op out grads File usr local lib python3 5 dist packages tensorflow python ops gradients impl py line 353 in MaybeCompile return grad fn Exit early File usr local lib python3 5 dist packages tensorflow python ops gradients impl py line 581 in lambda grad scope op func call lambda grad fn op out grads File usr local lib python3 5 dist packages tensorflow python ops math grad py line 922 in MatMulGrad grad b math ops matmul a grad transpose a True File usr local lib python3 5 dist packages tensorflow python ops math ops py line 1891 in matmul a b transpose a transpose a transpose b transpose b name name File usr local lib python3 5 dist packages tensorflow python ops gen math ops py line 2437 in mat mul name name File usr local lib python3 5 dist packages tensorflow python framework op def library py line 787 in apply op helper op def op def File usr local lib python3 5 dist packages tensorflow python framework ops py line 2956 in create op op def op def File usr local lib python3 5 dist packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access which was originally created as op 'projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell MatMul 36' defined at File sync train py line 383 in module main elided 1 identical lines from previous traceback File sync train py line 64 in train train model projectx projectx n gpu config is training True reuse False File kaldi exp tacotron exp 2 projectx py line 189 in init feed previous feed previous File kaldi exp tacotron exp 2 projectx py line 427 in seq2seq pre alignments File kaldi exp tacotron exp 2 decoder py line 99 in call attention rnn outputs new attention rnn state context alignments self attention rnn cell prenet output state pre alignments File kaldi exp tacotron exp 2 attention py line 427 in call lstm output next lstm state cell lstm inputs states i 1 File kaldi exp tacotron exp 2 zoneout lstm py line 48 in call output new state self cell inputs state scope File usr local lib python3 5 dist packages tensorflow python ops rnn cell impl py line 183 in call return super RNNCell self call inputs state File usr local lib python3 5 dist packages tensorflow python layers base py line 575 in call outputs self call inputs args kwargs File usr local lib python3 5 dist packages tensorflow python ops rnn cell impl py line 611 in call lstm matrix self linear1 inputs m prev File usr local lib python3 5 dist packages tensorflow python ops rnn cell impl py line 1189 in call res math ops matmul array ops concat args 1 self weights File usr local lib python3 5 dist packages tensorflow python ops math ops py line 1891 in matmul a b transpose a transpose a transpose b transpose b name name File usr local lib python3 5 dist packages tensorflow python ops gen math ops py line 2437 in mat mul name name ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 1792 4096 Node projectx trainig gpu 0 gradients projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell MatMul 36 grad MatMul 1 MatMul T DT FLOAT transpose a true transpose b false device job localhost replica 0 task 0 device GPU 0 projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell concat 36 projectx trainig gpu 0 gradients projectx trainig gpu 0 decoder projectxDecoderCell 1 lstm 0 lstm 0 lstm cell BiasAdd 36 grad tuple control dependency Node projectx trainig gpu 0 gradients concat 2929 Recv client terminated false recv device job localhost replica 0 task 0 device CPU 0 send device job localhost replica 0 task 0 device GPU 0 send device incarnation 1 tensor name edge 646323 projectx trainig gpu 0 gradients concat tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0,,"drpngx,drpngx",2018-02-05 07:10:39,2018-02-06 08:30:56
IS,can not read my own tfrecords and face FailedPreconditionError,Please go to Stack Overflow for help and support System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 1604 TensorFlow installed from source or binary conda tensorflow TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Describe the problem I'm tryting to read my own datasets And there exists FailedPreconditionError But my test records are in the right directory I do not know why it ocurred Source code logs these are the console error,,,2017-12-11 02:53:22,2018-02-06 08:42:14
IS,S3 accessing reports Curl returned error code 6 after AWS SDK upgrading to 1 3 15,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0rc1 tag and master 2e5ff39e Python version 2 7 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 4 8 CUDA cuDNN version 8 GPU model and memory Exact command to reproduce Describe the problem TensorFlow 1 4 X was working well with S3 in my environment After upgrading to 1 5 0rc1 I found that S3 could not be accessed Curl returned error code 6 is reported I noticed that AWS SDK had been upgraded from 1 0 90 to 1 3 15 in r1 5 and master branches Thus I pulled the master 2e5ff39e and tried to change AWS SDK 1 3 15 into 1 0 90 in tensorflow workspace bzl After this modification it works well I tried with both AWS S3 with http proxy and Minio localhost and the results are the same AWS SDK 1 0 90 is Ok but 1 3 15 reports error I guess there might be some incompatible changes after AWS SDK 1 3 15 Could you please take a look Thanks I noticed that AWS SDK required gcc 4 9 but I was using 4 8 Thus this issue might be related to the old versions of gcc and glib on my server I will try with some new systems as well Source code logs Logs when using TensorFlow master 2e5ff39e,,"yongtang,tatatodd,yongtang,tatatodd",2018-01-25 08:00:10,2018-02-06 11:05:58
IS,Dynamic Bi directional RNN vs Dynamic RNN Not working as expected,I am trying to use Bidirectional RNN and pass the output through a CNN for text classification However I am getting all sorts of shape errors with bidirectional RNN Although If I use two dynamic rnn with reverse op in the second layer it appears to work fine Here is bidirectional RNN code that DOES NOT work for me,,,2018-01-12 16:12:57,2018-02-06 12:55:04
IS,IllegalArgumentException Retval 0 does not have value,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 iMac 27 inch Late 2013 OS 10 13 3 17D47 TensorFlow installed from source or binary Source TensorFlow version use command below Using TensorFlow backend 1 5 0 rc1 Python version Python 3 6 4 Bazel version if compiling from source Build label 0 9 0 homebrew Build target bazel out darwin opt bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Sun Jul 12 12 24 01 49936 1513677414241 Build timestamp 1513677414241 Build timestamp as int 1513677414241 GCC Compiler version if compiling from source Xcode 9 2 Build version 9C40b CUDA cuDNN version No CPU only GPU model and memory No Exact command to reproduce Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request if I add GRU or LSTM to my code and try to export this model to Android I have got the exception,,drpngx,2018-01-30 16:00:53,2018-02-06 13:11:39
IS,third party zlib use DZ HAVE UNISTD H instead of suppressing warnings,Hi I noticed that you built zlib by suppressing warnings about it using undeclared functions However I discovered that adding copts DZ HAVE UNISTD H could make zlib to include unistd h and therefore get rid of the warnings completely While this change is very minor I think declaring the macro is better than suppressing the warnings,,"aselle,yongtang",2017-09-20 15:29:02,2018-02-06 14:14:27
PR,Making SQLite better,,,"rajendraarora16,jart",2018-01-07 19:35:06,2018-02-06 15:36:49
PR,We must also trim everything after TAB in order to correctly parse version from TensorRT 3 0 2,Note TABS after version numbers,,"aaroey,aaroey",2018-02-02 16:41:04,2018-02-06 15:37:04
IS,Stacking CNN with LSTM,I am trying to stack CNN before LSTM however I am experience a little problem My LSTM CTC works fine However I want to pass extracted feature from CNN to LSTM instead of whole image The code is here I error I am facing is File trainer2 py line 182 in module train File trainer2 py line 75 in train logits inputs targets seq len W b model get train model File home2 kamranjanjua tf cnnlstm tlstm9Aug model py line 97 in get train model outputs tf nn bidirectional dynamic rnn forwardH1 backwardH1 x seq len dtype tf float32 File home kamranjanjua anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops rnn py line 652 in bidirectional dynamic rnn time major time major scope fw scope File home kamranjanjua anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops rnn py line 845 in dynamic rnn dtype dtype File home kamranjanjua anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops rnn py line 919 in dynamic rnn loop Input size depth of inputs must be accessible via shape inference ValueError Input size depth of inputs must be accessible via shape inference but saw value None Any help in this matter would be appreciated I am kind of stuck here System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 0 12 Using this on purpose since my older code works in 0 12 and I did not update it for the new version Python version 2 7 GPU model and memory TitanX 12 GB,,"ebrevdo,ebrevdo,ebrevdo",2017-08-23 09:53:02,2018-02-06 15:44:53
IS,libtensorflow core a contains duplicate symbol CreateGPUTracerEv,Running build all ios sh produces a libtensorflow core a that contains a symbol twice When linking on iOS the error is Branch master MacOS Sierra 10 12 6 16G29 Xcode Version 8 3 3 8E3004b,,"jart,jart",2017-08-30 07:09:49,2018-02-06 15:51:14
IS,libstdc so 6 version CXXABI 1 3 8' not found,All of my tf nightly Travis CI pipelines started failing today with following error Example Any ideas how to fix,,"yaroslavvb,yaroslavvb,yaroslavvb,alsrgv,alsrgv,ppwwyyxx,gunan,alsrgv,martinwicke,jart,jart,gunan,yaroslavvb,shivaniag,gunan,jart,gunan,angersson,jhseu,jart,jart,jart",2018-01-01 21:56:33,2018-02-06 16:05:33
IS,Op type not registered 'CudnnRNNParamsSize' in binary,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow example OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 64bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 CUDA cuDNN version Cude 8 0 cuDNN 6 0 GPU model and memory M1000M Exact command to reproduce Describe the problem The tutorial RNN model fails due to Op type not registered 'CudnnRNNParamsSize' in binary Source code logs,,,2017-08-31 13:28:36,2018-02-06 16:32:33
IS,export meta graph fails if graph has no variables,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version 8 GPU model and memory 1060 Exact command to reproduce,,,2017-08-25 18:03:26,2018-02-06 16:33:09
IS,setuptools error on upgrading to 1 4 1,Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS Sierra TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 6 normal install NO virtualenv NO anaconda Exact command to reproduce After this running pip3 install upgrade Tensorflow runs successfully,,"drpngx,gunan",2017-12-15 17:34:42,2018-02-06 16:38:44
IS,update tensorflow to 1 5,I update tensorflow to 1 5 and reinstall cuda to 9 1 now I run my program get the error Traceback most recent call last File home chris tensorflowDemo 7 1 Word2Vec py line 24 in module import tensorflow as tf File home chris local lib python3 5 site packages tensorflow init py line 24 in module from tensorflow python import File home chris local lib python3 5 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home chris local lib python3 5 site packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File home chris local lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home chris local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home chris local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 9 0 cannot open shared object file No such file or directory,,,2018-01-31 12:33:00,2018-02-06 16:45:46
IS,Slim batch image prediciton,I just finished training a model by following train image classifier py CUDA VISIBLE DEVICE 0 1 python train image classifier py train dir train logs dataset dir train num samples 15500 num classes 4 labels to names path labels txt model name inception resnet v2 checkpoint path checkpoints inception resnet v2 2016 08 30 ckpt checkpoint exclude scopes InceptionResnetV2 Logits InceptionResnetV2 AuxLogits num clones 2 num preprocessing threads 8 max number of steps 100000 batch size 32 learning rate 0 0001 learning rate decay type fixed save interval secs 60 save summaries secs 60 log every n steps 10 optimizer rmsprop weight decay 0 00004 and evaluate the model by using eval image classifier py CUDA VISIBLE DEVICE 0 1 python eval image classifier py checkpoint path train logs eval dir eval logs dataset dir val num samples 797 num classes 4 model name inception resnet v2 Everything seems great But how to test image classifier unfortunately is not provided and I cannot really find an good example of how to use this model to predict testing images Is there a good example that I can use my trained model to predict multiple images in a batch way Thank you for helping,,,2018-02-06 08:55:19,2018-02-06 16:58:18
IS,Feature Request Modification of lstm2d horizontal lstm implementation,I noticed something in the documentation of lstm2d horizontal lstm It says Run an LSTM bidirectionally over all the rows of each image Kinda looks like a bidirectional lstm to me I propose to change the implentation such that it will use bidirectional lstm within the function replacing this,,"selcouthlyBlue,ebrevdo,selcouthlyBlue,ebrevdo,selcouthlyBlue,selcouthlyBlue",2018-02-06 08:28:55,2018-02-06 16:59:19
IS,How to compile and use Opencv in tensorflow c,I want to implement a model inference in tensorflow c and have saved the model as pb file But I can not use opencv to process the image I wonder how can I add the opencv lib to the bazel project Are there any tricks to solve the problem Thanks This is the code of the bazel BUILD file package default visibility tensorflow internal licenses notice Apache 2 0 exports files LICENSE load tensorflow tensorflow bzl tf cc binary tf cc binary name mask rcnn srcs main cc prefix flower linkopts select tensorflow android pie landroid ljnigraphics llog lm z defs s Wl exclude libs ALL conditions default lm deps select tensorflow android cc cc ops is used to include image ops for label image Jpg gif and png related code wo not be included tensorflow cc cc ops tensorflow core android tensorflow lib cc android tensorflow image op is for including jpeg gif png decoder to enable real image evaluation on Android tensorflow core kernels android tensorflow image op conditions default tensorflow cc cc ops tensorflow core core cpu tensorflow core framework tensorflow core framework internal tensorflow core lib tensorflow core protos all cc tensorflow core tensorflow filegroup name all files srcs glob exclude METADATA OWNERS bin gen visibility tensorflow subpackages,,,2018-02-06 12:33:00,2018-02-06 17:00:33
IS,Unable to run custom model tensorflow on android using Android studio,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary downloaded from Githhub TensorFlow version use command below 1 5 0 Python version 3 6 Bazel version if compiling from source NA not compiling from source GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I have followed the instruction as per as were able to generate and successfully run APK for default model I got problems when i replaced the default graph pb file from rounded graph pb retained name as graph only file which is optimized version for android as per instructions in above mentioned link Updated graphs are working using command line Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem 02 04 15 09 09 642 E art 23153 No implementation found for long org tensorflow contrib android RunStats allocate tried Java org tensorflow contrib android RunStats allocate and Java org tensorflow contrib android RunStats allocate 02 04 15 09 10 105 E AndroidRuntime 23153 FATAL EXCEPTION main 02 04 15 09 10 105 E AndroidRuntime 23153 Process org tensorflow demo PID 23153 02 04 15 09 10 105 E AndroidRuntime 23153 java lang RuntimeException Failed to load model from 'file' 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 100 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 132 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo CameraActivity 1 onPreviewSizeChosen CameraActivity java 159 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo CameraConnectionFragment setUpCameraOutputs CameraConnectionFragment java 421 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo CameraConnectionFragment openCamera CameraConnectionFragment java 428 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo CameraConnectionFragment access 000 CameraConnectionFragment java 64 02 04 15 09 10 105 E AndroidRuntime 23153 at org tensorflow demo CameraConnectionFragment 1 onSurfaceTextureAvailable CameraConnectionFragment java 95 02 04 15 09 10 105 E AndroidRuntime 23153 at android view TextureView getHardwareLayer TextureView java 368 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15173 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 15969 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup drawChild ViewGroup java 3612 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup dispatchDraw ViewGroup java 3402 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15191 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 15969 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup drawChild ViewGroup java 3612 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup dispatchDraw ViewGroup java 3402 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 16202 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15196 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 15969 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup drawChild ViewGroup java 3612 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup dispatchDraw ViewGroup java 3402 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15191 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 15969 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup drawChild ViewGroup java 3612 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup dispatchDraw ViewGroup java 3402 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15191 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 15969 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup drawChild ViewGroup java 3612 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewGroup dispatchDraw ViewGroup java 3402 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View draw View java 16202 02 04 15 09 10 105 E AndroidRuntime 23153 at com android internal policy PhoneWindow DecorView draw PhoneWindow java 2690 02 04 15 09 10 105 E AndroidRuntime 23153 at android view View updateDisplayListIfDirty View java 15196 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ThreadedRenderer updateViewTreeDisplayList ThreadedRenderer java 281 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ThreadedRenderer updateRootDisplayList ThreadedRenderer java 287 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ThreadedRenderer draw ThreadedRenderer java 322 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewRootImpl draw ViewRootImpl java 2627 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewRootImpl performDraw ViewRootImpl java 2446 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewRootImpl performTraversals ViewRootImpl java 2079 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewRootImpl doTraversal ViewRootImpl java 1119 02 04 15 09 10 105 E AndroidRuntime 23153 at android view ViewRootImpl TraversalRunnable run ViewRootImpl java 6060 02 04 15 09 10 105 E AndroidRuntime 23153 at android view Choreographer CallbackRecord run Choreographer java 858 02 04 15 09 10 105 E AndroidRuntime 23153 at android view Choreographer doCallbacks Choreographer java 670 02 04 15 09 10 105 E AndroidRuntime 23153 at android view Choreographer doFrame Choreographer java 606 02 04 15 09 10 105 E AndroidRuntime 23153 at android view Choreographer FrameDisplayEventReceiver run Choreographer java 844 02 04 15 09 10 105 E AndroidRuntime 23153 at android os Handler handleCallback Handler java 746 02 04 15 09 10 105 E AndroidRuntime 23153 at android os Handler dispatchMessage Handler java 95 02 04 15 09 10 105 E AndroidRuntime 23153 at android os Looper loop Looper java 148 02 04 15 09 10 105 E AndroidRuntime 23153 at android app ActivityThread main ActivityThread java 5443 02 04 15 09 10 105 E AndroidRuntime 23153 at java lang reflect Method invoke Native Method 02 04 15 09 10 105 E AndroidRuntime 23153 at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 728 02 04 15 09 10 105 E AndroidRuntime 23153 at com android internal os ZygoteInit main ZygoteInit java 618 02 04 15 09 10 105 E AndroidRuntime 23153 Caused by java io IOException Not a valid TensorFlow Graph serialization NodeDef mentions attr wouldilations' not in Op name Conv2D signature input T filter T output T attr T type allowed DT HALF DT FLOAT attr strides list int attr use cudnn on gpu bool default true attr padding string allowed SAME VALID attr data format string default NHWC allowed NHWC NCHW NodeDef Mobi,,martinwicke,2018-02-04 10:05:15,2018-02-06 17:44:54
IS,add an interface to check if a variable is initialized,Currently if we create an Adam optimizer and minimize some loss Adam will create some new variables that need to be initialized Howerver this is only a part of variables and we donot want to use tf global variables initializer If there is an interface to check if a variable is initialized then we can filter global variables and initialize only what needs to be initialized the interface should look like Variable is initialized bool,,"alextp,alextp",2018-02-03 02:19:58,2018-02-06 17:49:55
PR,Branch 184622482,,,case540,2018-02-06 07:10:57,2018-02-06 18:28:20
IS,Dependencies of tensors created within a tf while loop might not be executed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes See test case below OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 'Sierra' Version 10 12 6 16G1114 TensorFlow installed from source or binary Both I have compiled TensorFlow at 136697ecdc64b5171522fb7f89cfe51a02f0f1c1 with my small change in PR 15823 I have also tried using the pip package TensorFlow version use command below 'v1 4 0 19 ga52c8d9b01' '1 4 1' pip package Python version 2 7 10 Bazel version if compiling from source 0 9 0 homebrew GCC Compiler version if compiling from source Apple LLVM version 8 1 0 clang 802 0 42 CUDA cuDNN version CUDA 9 0 176 mac cuDNN 9 0 osx x64 v7 GPU model and memory NVIDIA GeForce GT 750M with 2048 MB device memory CUDA Compute Capability 3 0 Exact command to reproduce python repro py where repro py contains the test case to reproduce listed below Describe the problem Here is my test case,,"dtrebbien,shivaniag,ebrevdo,ebrevdo,ebrevdo,dtrebbien,reedwm,alextp,dtrebbien,dtrebbien,alextp,asimshankar",2018-01-05 21:51:29,2018-02-06 18:29:02
IS,tf contrib rnn GLSTMCell is hilariously broken,In 3f579020bab8f00e4621e9c7c740cbf13136a809 an if was added that caches linear transformation weights L2316 The problem is that this linear is inside a loop And so the change tied weights of all these linear transformations CC,,"reedwm,reedwm,asimshankar",2018-02-02 18:54:15,2018-02-06 18:29:02
PR,Fix typo,,,ManHyuk,2018-02-06 00:55:15,2018-02-06 18:40:55
PR,remove write version saver pb2 SaverDef V1,This PR fixes the failed testAdditionalHooks and testRestoredModelPerformance test for PR 14341,,"tedhtchang,jart",2018-01-09 04:36:20,2018-02-06 18:44:49
IS,Android buffer overflow exception when running only a certain model above a certain image resolution,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Android Lollipop TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 Python version 2 7 12 Bazel version if compiling from source 4 5 CUDA cuDNN version GPU model and memory Exact command to reproduce Running app on android studio Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I have met with a very peculiar problem that seem to show that a certain model Inception V3 which I got from the TF slim library seem to consume more memory than usual and cause a bufferoverflow problem like in here Specifically if you try an image resolution higher than 360x360 in the model it crashes with the error The interesting thing is that this does not happen for a significantly larger model the Inception Resnet V2 although it supposedly consumes a lot more memory With that larger inception resnet v2 model I can use a resolution of over 400 with no issues I have rebooted my device switched it and run it on another identical device and another brand of device but still there is this problem I can not exactly locate the issue but specifically here is what I have traced in the error Specific error stack trace TensorFlowImageClassifier java inferenceInterface fetch outputName outputs TensorFlowInferenceInterace java public void fetch String var1 float var2 this fetch var1 FloatBuffer wrap var2 Tensor java public void writeTo FloatBuffer var1 if this dtype DataType FLOAT throw incompatibleBuffer var1 this dtype else ByteBuffer var2 this buffer var1 put var2 asFloatBuffer FloatBuffer java public FloatBuffer put FloatBuffer src if src this throw new IllegalArgumentException int n src remaining if n remaining throw new BufferOverflowException for int i 0 i n i put src get return this I am not sure why this happens as everything else works In fact if I try a resolution below 360 the Inception V3 model works perfectly fine Note that I got the checkpoint model from TF slim and froze it I believe the method I used to freeze it works well since there is no problem for all other models except Inception V3 So I can only conclude the problem lies within the layers But I am not exactly sure how I can find out which layer is causing the problem or even if it is because of the layers I'm not sure how to fix it I have included the layers of Inception V3 and Inception Resnet V2 in order here Inception V3 Layers Inception Resnet V2 Layers If it is really the problem within the model then I thought it could be because of a faulty implementation of a certain operation that is causing overly huge memory consumed As an alternative fix is there a way to check and raise the limit of the buffer size for the app to run successfully,,"jart,andrewharp,jart",2017-08-28 13:38:11,2018-02-06 18:47:23
PR,Merging the 1 6 branch back into master,,,av8ramit,2018-02-05 22:51:10,2018-02-06 19:04:18
IS,Keras has much better gradients calculated than native TF,Hi I am not sure if this is a bug in some TF function or Keras has just some clever ways to pull things off I was prototyping a simple logistic regression model with Keras and trying to write the exact same model with TF to reproduce the result However there is something unexplainable to me that Keras always has much better gradients calculated than TF does when I use mini batch SGD tensorflow 1 2 1 Keras 2 0 8 GPU Tesla P40 Keras version TL DR Keras has better gradients calculated updates than TF Both version implements a vanilla logistic regression with same native TF optimizer same user defined cross entropy and same data generator except for Keras accepts a dense matrix and TF accepts sparse matrix tocoo same learning rate same zero initializer for both w and b Simple calculus can show that if the first batch contains all NEGATIVE examples the gradient for b in the first update must be exactly 0 5 If a batch has very few examples e g 1 9 both version produce an exact gradient of 0 5 for b When sample size goes above 9 Keras starts to have a way better gradients calculated for both b and w For example with sample size 10 Keras calculates 0 50000006 for b and TF gives 0 49999988 With sample size 12 Keras gives 0 49999994 but TF gives 0 50000012 Though both give wrong gradient Keras is always better not to mentions the weights gradients Also trying casting the loss to float16 32 or 64 wo not make the gradient as good as Keras' The accumulated differences after 100 batches of training makes TF is model worse than Keras' in terms of AUC At this stage I am not sure where I should look for so I resort to the community to help me with this unexplainable phenomena Any suggestion will be much appreciated Oscar,,"ppwwyyxx,ppwwyyxx,reedwm,reedwm",2017-10-02 07:09:27,2018-02-06 20:00:40
IS,XLA leads to core dump,System information output of tf env collect sh Tensorflow Tensorflow compiled from the source v1 3 0 9e76bf3 with cuda with xla without mpi without mkl OS CentOS 7 out put of uname a Linux zhanghao 3 10 0 514 26 2 el7 x86 64 1 SMP Tue Jul 4 15 04 05 UTC 2017 x86 64 x86 64 x86 64 GNU Linux python Python 2 7 13 Intel Corporation default Apr 27 2017 15 33 46 GCC 4 8 2 20140120 Red Hat 4 8 2 15 on linux2 Bezel Build label 0 5 2 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Tue Jun 27 13 27 03 2017 1498570023 Build timestamp 1498570023 Build timestamp as int 1498570023 GPU CUDA 8 0 cuDNN 6 0 21 GPU GeForce GTX 950M Describe the problem core dump when use xla with gpu BTW if use cpu only xla wo not lead to core dump Source code This is code to reproduce the bug,,"jart,learyg,tatatodd,bixia1,tatatodd,bixia1,jlebar",2017-08-29 12:56:28,2018-02-06 20:09:28
IS,Connect Apache Beam Spark to TensorFlow MonitoredTrainingSession in a streaming manner,Describe the problem I have a lengthy question on SO about this But in short is there a way or a best practice to pipe big training datasets directly into a distributed setting e g GKE especially if they are subjected to a heavy preprocessing I'm basically reaching the limit of what can be sanely stored in TFRecords they are verbose and heavy The closest issue was this one and this guide but I do not see a healthy way to implement it last one with a singleton looks like a hack and not usable with the tf Dataset or MonitoredTrainingSession I believe this is a useful issue feature request for a decent amount of Tensorflow users,,"yongtang,mrry",2018-01-12 20:49:42,2018-02-06 23:10:59
IS,Session Run allocates a lot of memory after the first call,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 6 TensorFlow installed from source or binary Binary CPU C API TensorFlow version use command below 1 4 0 Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I am working on an application that deploys several TensorFlow models using TensorFlow is C API I have noticed that there seems to be a behavior where TensorFlow takes a long time to run the first time TF SessionRun is called and it allocates a lot of extra memory that hangs around until the session is destroyed In my case my program is memory footprint is 85MB after all of the models are loaded which makes sense that is about how large the model pb files are on disk but after the first call to TF SessionRun it jumps to 250MB After profiling my code it appears that TensorFlow is the culprit and I have observed similar behavior on Android as well TensorFlow seems to be doing some lazy initialization but there does not appear to be much documentation or discussion about this Could someone shed some light on what is happening here Why does it require so much memory Is this a bug or expected behavior Source code logs Here is a memory call tree from Xcode showing persistent memory allocations after the first call to TF SessionRun for one of my models img width 996 alt screen shot 2017 12 27 at 1 14 59 pm src Let me know if there is any more information that I can provide I'm curious what is going on here,,"reedwm,mrry,skye,mrry",2017-12-27 22:03:04,2018-02-06 23:35:58
IS,TFlite toco failed to convert the quantized inception protobuf to tflite format,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux qiuji01 4 4 0 72 generic 93 Ubuntu SMP Fri Mar 31 14 07 41 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial TensorFlow installed from source or binary source TensorFlow version use command below tensorflow 1 5 0rc0 git commit id commit f99275a6a309699c73e1bbebd89ba9aa32e79aa3 Author Amit Patankar amitpatankar google com Date Thu Jan 4 17 35 54 2018 0800 Python version 2 7 12 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source gcc version 5 4 0 20160609 CUDA cuDNN version no GPU model and memory no Exact command to reproduce root TF new out toco execroot org tensorflow bazel out local opt bin tensorflow contrib lite toco toco input file incept 8wn gt pb output file incept 8wn gt tflite input format TENSORFLOW GRAPHDEF output format TFLITE inference type QUANTIZED UINT8 input shape 1 299 299 3 input array Mul output array softmax Describe the problem I am trying to follow the transform graph tensorflow tools graph transforms README md to get a 8 bit quantized model then feed it into the Tflite toco tensorflow contrib lite to transform it from protobuf into tflite format My steps are 1 download the inception model from and extract it 2 build the graph transforms using the following command bazel output base out transform graph build s c opt tensorflow tools graph transforms transform graph 3 quantize and optimize the inception model using t he following command root TF new out transform graph execroot org tensorflow bazel out local opt bin tensorflow tools graph transforms transform graph in graph classify image graph def pb out graph incept 8wn gt pb inputs 'Mul 0' outputs isoftmax 0' transforms 'add default attributes strip unused nodes type float shape 1 299 299 3 remove nodes op Identity op CheckNumerics fold constants ignore errors true fold batch norms fold old batch norms quantize weights quantize nodes strip unused nodes sort by execution order' 4 build the toco using the following command bazel output base out toco build tensorflow contrib lite toco toco 5 transform the quantized inception model from protobuf format into TFlite format using the following the command root TF new out toco execroot org tensorflow bazel out local opt bin tensorflow contrib lite toco toco input file incept 8wn gt pb output file incept 8wn gt tflite input format TENSORFLOW GRAPHDEF output format TFLITE inference type QUANTIZED UINT8 input shape 1 299 299 3 input array Mul output array softmax Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem The error log is as following 2018 01 05 08 08 37 682405 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 682532 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 682593 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 682651 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 682762 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 682950 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683126 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683270 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683385 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683442 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683496 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683546 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683645 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683743 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683862 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 683960 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684051 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684106 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684156 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684210 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684273 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684364 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684418 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684468 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684538 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684591 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 684738 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685056 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685112 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685163 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685213 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685263 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685700 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685757 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 685883 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 686121 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 686378 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 686456 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688240 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688313 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688395 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688454 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688508 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688537 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 688566 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 688589 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 688612 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 688634 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 688654 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 688675 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 688697 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 688722 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 688743 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 688763 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 688781 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 688797 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 688813 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 688856 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688907 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 688949 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689010 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689133 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689182 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689298 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689361 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689442 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689709 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689791 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689845 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689940 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 689992 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 690186 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 690258 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 690290 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 690314 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 690338 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 690360 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 690382 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 690403 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 690425 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMaxPool 2018 01 05 08 08 37 690489 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 690739 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 690833 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 690915 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691020 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691122 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691263 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691368 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691476 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691513 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691536 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691727 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691757 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691782 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 691807 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692065 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692081 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692093 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692104 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692115 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692125 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692135 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692148 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692158 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692168 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692178 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692189 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692199 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692208 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692219 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMaxPool 2018 01 05 08 08 37 692229 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 692241 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692252 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692262 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692273 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692283 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692293 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692302 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692312 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692322 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692331 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692359 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692411 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692439 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692584 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692599 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692609 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692618 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692628 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692639 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692650 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692664 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692675 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692685 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692696 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692706 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692717 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692727 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692773 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692800 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692815 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 692827 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692837 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692848 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692858 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692868 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692877 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692901 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692912 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 692921 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 692932 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 692942 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 692965 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 692996 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693021 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693046 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693070 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693098 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693111 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693121 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693130 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693139 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693148 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693157 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693168 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693179 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693188 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693199 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693209 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693219 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693229 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693255 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693380 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693407 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693431 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693445 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 693459 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 693473 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693484 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693495 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693505 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693514 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693522 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693530 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693539 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693549 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693557 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693566 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693574 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693583 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693591 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693615 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693639 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693723 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693736 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693746 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693755 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693764 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693772 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693781 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693790 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 693799 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693808 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693817 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 693826 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 693834 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 693842 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 693869 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693891 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 693957 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 694080 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 694349 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 694394 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 694461 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694474 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694483 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694492 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694501 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694510 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694518 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694527 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694536 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694544 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694553 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694561 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694572 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694581 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694636 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizeV2 2018 01 05 08 08 37 694651 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694661 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694669 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694678 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694687 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694696 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694704 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694713 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 694724 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694734 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694741 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694750 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694759 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694767 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694775 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694783 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694792 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694800 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694808 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694817 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694825 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694833 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694841 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694850 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694857 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694865 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694874 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694881 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694889 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694897 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694906 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694914 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694922 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694930 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694938 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694946 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 694954 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 694963 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694971 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 694979 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 694987 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 694994 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695002 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695011 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695020 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695028 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695037 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695045 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695052 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695060 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695069 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 695079 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695088 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695096 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695105 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695113 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695120 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695128 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695137 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 695147 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695157 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695164 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695172 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695180 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695188 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695197 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695206 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695215 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695224 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695233 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695241 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695249 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695259 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695269 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695278 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695298 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695308 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695317 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695325 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695333 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695342 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMaxPool 2018 01 05 08 08 37 695352 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695361 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695370 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695378 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695387 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695395 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695403 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695411 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 695421 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695431 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695439 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695448 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695456 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695464 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695472 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695481 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695490 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695498 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695507 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695516 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695524 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695532 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695541 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695550 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695558 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695567 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695575 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695583 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695591 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695599 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695608 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695616 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695624 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695633 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695641 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695649 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695658 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695667 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695675 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695684 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695692 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695700 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695708 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695717 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695725 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695734 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695743 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695751 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695760 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695768 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695776 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695786 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695794 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695803 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695811 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695819 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695827 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695835 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695844 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695853 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695861 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695869 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695877 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695884 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695892 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695901 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695909 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695918 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695926 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695934 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695941 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 695949 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 695959 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 695969 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 695977 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 695986 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 695994 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696002 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696010 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696019 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 696029 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696040 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696048 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696056 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696064 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696072 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696079 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696088 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696096 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696105 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696114 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696121 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696130 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696138 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696146 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696155 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696163 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696172 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696180 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696188 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696195 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696204 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696212 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696221 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696229 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696237 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696245 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696252 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696261 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696270 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696278 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696287 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696296 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696303 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696311 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696319 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696328 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696337 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696345 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696354 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696362 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696370 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696378 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696387 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696395 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696404 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696412 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696420 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696427 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696436 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696445 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696453 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696462 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696471 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696479 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696487 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696495 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 696506 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696514 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696523 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696532 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696540 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696548 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696556 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696565 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696574 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696582 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696591 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696599 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696607 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696614 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696624 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 696635 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 696645 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696654 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696663 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696671 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696679 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696687 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696695 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696703 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696712 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696720 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696729 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696737 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696745 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696753 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696762 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696771 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696779 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696788 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696797 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696804 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696812 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696821 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696830 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696838 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696847 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696855 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696863 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696870 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696879 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696887 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696896 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696904 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696912 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696921 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696928 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696936 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 696945 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696953 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696962 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 696970 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 696978 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 696985 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 696994 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697002 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697011 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697019 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697028 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697036 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697045 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697053 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697062 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697070 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697078 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697086 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697094 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697102 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697111 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697120 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697129 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697137 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697145 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697153 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697161 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697169 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697178 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697186 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697195 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697203 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697211 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697218 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697227 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 697238 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 697248 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697257 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697266 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697275 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697283 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697292 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697300 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697309 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697318 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697327 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697335 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697344 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697352 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697360 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697370 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697378 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697386 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697396 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697404 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697412 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697420 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697428 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697437 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697445 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697453 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697462 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697470 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697478 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697486 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697495 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697503 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697511 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697519 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697527 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697534 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697543 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697552 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697560 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697569 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697577 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697585 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697593 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697601 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697610 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697618 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697626 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697634 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697642 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697650 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697658 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697667 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697676 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697685 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697693 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697702 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697709 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697718 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697727 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697735 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697744 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697752 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697760 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697768 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697776 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697785 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697793 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697802 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697810 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697818 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697826 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697835 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 697845 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697854 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697863 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697872 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697881 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697889 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697897 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697905 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697914 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697922 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697931 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697940 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697948 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697956 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 697965 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 697973 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 697981 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 697990 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 697998 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698006 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698014 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 698022 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 698031 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698040 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698047 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 698056 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698064 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698071 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 698080 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 698089 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698097 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698106 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 698115 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698123 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698130 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 698139 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 698147 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698155 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698163 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 698171 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698179 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698187 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 698195 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMaxPool 2018 01 05 08 08 37 698204 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 698215 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 698225 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698233 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698242 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 698250 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698258 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698266 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 698275 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 698284 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 698292 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 698301 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706033 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706066 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706077 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706089 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706101 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706111 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706121 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706131 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706139 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706147 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706160 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706179 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706200 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706216 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706229 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706243 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706257 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706276 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706294 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706487 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706530 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706543 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706552 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706560 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706570 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706580 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706589 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706598 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706607 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706615 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706624 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706655 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706669 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706677 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706686 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706696 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706704 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706712 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706725 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706737 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706746 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706756 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706764 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706772 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706781 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706791 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 706801 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706811 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706819 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706829 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706837 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706846 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706853 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706863 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 706882 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMaxPool 2018 01 05 08 08 37 706902 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706917 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706929 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706938 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 706948 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706956 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 706964 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 706973 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 706982 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 706991 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707001 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707009 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707017 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707025 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707034 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707046 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707058 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707068 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707083 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707104 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707119 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707133 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707148 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707160 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707175 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707188 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707203 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707217 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707232 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707247 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707262 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707277 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707311 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707326 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707339 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707355 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707370 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707384 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707398 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707412 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707425 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707438 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707453 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707468 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707482 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707497 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707512 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707526 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707539 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707556 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707571 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707585 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707600 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707615 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707629 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707643 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707658 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConv2D 2018 01 05 08 08 37 707673 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707687 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707702 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707717 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707731 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707744 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedRelu 2018 01 05 08 08 37 707761 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedConcat 2018 01 05 08 08 37 707780 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedAvgPool 2018 01 05 08 08 37 707798 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedReshape 2018 01 05 08 08 37 707814 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedMatMul 2018 01 05 08 08 37 707830 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707845 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707860 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation QuantizedBiasAdd 2018 01 05 08 08 37 707875 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RequantizationRange 2018 01 05 08 08 37 707890 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Requantize 2018 01 05 08 08 37 707904 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Dequantize 2018 01 05 08 08 37 763586 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 1080 operators 3039 arrays 0 quantized 2018 01 05 08 08 37 849158 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 793 operators 2752 arrays 1 quantized 2018 01 05 08 08 37 934553 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 2 793 operators 2752 arrays 1 quantized 2018 01 05 08 08 38 022469 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before pre quantization graph transformations 793 operators 2752 arrays 1 quantized 2018 01 05 08 08 38 082050 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After pre quantization graph transformations pass 1 793 operators 2752 arrays 1 quantized 2018 01 05 08 08 38 156372 F tensorflow contrib lite toco tooling util cc 1217 Array conv Conv2D eightbit Mul port 0 min which is an input to the Unsupported TensorFlow op QuantizeV2 operator producing the output array conv Conv2D eightbit Mul port 0 quantize is lacking min max data which is necessary for quantization Either target a non quantized output format or change the input graph to contain min max information or pass default ranges min and default ranges max if you do not care about the accuracy of results,,,2018-01-05 08:38:40,2018-02-06 23:39:26
IS,Tensorflow not using GPU,I use windows in my laptop Initially tensorflow worked well with GPU I do not know why suddenly it is not detecting the GPU I am using tensorflow gpu 1 4 version installed with pip install tensorflow gpu with CUDA 8 0 and cudnn 6 0 I also tried with other versions but the problem persists Attached is the error message shown I appreciate any help System information Have I written custom code as opposed to using a stock example script provided in TensorFlow just called a session OS Platform and Distribution e g Linux Ubuntu 16 04 Windows TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below 1 4 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory NVIDIA GeForce 1050 2GB Exact command to reproduce sess tf Session config tf ConfigProto log device placement True tferror ent com 19821962 35368747 e2d4ba8c 0152 11e8 871a a6a5aedf6663 png,,skye,2018-01-25 03:09:07,2018-02-07 00:11:42
IS,How to use tensorflow library in c programs,I build shared libraries in tensorflow serving with bazel However I can not build C programs with the shared libraries I build C programs like this g main cc L bazel bin tensorflow serving rnnlm lrnnlm client run ldata generator Details is shown below bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictionService Stub Predict grpc Cli entContext tensorflow serving PredictRequest const tensorflow serving PredictResponse ' 12 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to google protobuf internal fixed address empty string' 13 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow Tensor CheckTypeAndIsAligned tensorflow DataType const' 14 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictRequest slow mutable model spec ' 15 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow Tensor FromProto tensorflow TensorProto const ' 16 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictResponse PredictResponse ' 17 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorShape CheckDimsEqual int const' 18 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow Tensor Tensor ' 19 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictionService NewStub std shared ptr grpc ChannelInterface const grpc StubOptions const ' 20 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorShapeProto Dim TensorShapeProto Dim google protobuf Arena ' 21 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorProto TensorProto google protobuf Arena ' 22 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to google protobuf internal ArenaImpl AllocateAligned unsigned long ' 23 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorShapeBase tensorflow TensorShape dim size int const' 24 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictRequest PredictRequest ' 25 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to google protobuf internal RepeatedPtrFieldBase Reserve int ' 26 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorShapeProto Dim TensorShapeProto Dim ' 27 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow serving PredictRequest PredictRequest ' 28 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to google protobuf Arena OnArenaAllocation std type info const unsigned long const' 29 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorProto TensorProto ' 30 bazel bin tensorflow serving rnnlm librnnlm client run so undefined reference to tensorflow TensorProto slow mutable tensor shape ',,"reedwm,nfiedel",2018-01-29 12:06:26,2018-02-07 00:20:10
IS,Customized loss in keras,Dear all I can run properly with the following code System Information Have I written custom code As following OS Platform and Distribution Linux Ubuntu16 04 TensorFlow installed from conda script TensorFlow version '1 4 0' Bazel version N A CUDA cuDNN version CUDA8 0 cudnn6 0 GPU model and memory 1070 8G How can I do based on above code part I Thanks for any help,,skye,2018-02-03 08:08:05,2018-02-07 00:25:52
IS,Tensorflow 1 5 failed to use tf keras applications MobileNet,I updated my Tensorflow to 1 5 and I tried to run the codes as below import tensorflow as tf model tf keras applications MobileNet But it raised an error as below OSError Traceback most recent call last ipython input 14 2182e918e983 in module 1 model tf keras applications MobileNet usr local lib python3 5 dist packages tensorflow python keras impl keras applications mobilenet py in MobileNet input shape alpha depth multiplier dropout include top weights input tensor pooling classes 538 K set image data format old data format 539 elif weights is not None 540 model load weights weights 541 return model 542 usr local lib python3 5 dist packages tensorflow python keras impl keras engine topology py in load weights self filepath by name 1099 if h5py is None 1100 raise ImportError ' load weights requires h5py ' 1101 f h5py File filepath mode 'r' 1102 if 'layer names' not in f attrs and 'model weights' in f 1103 f f 'model weights' usr local lib python3 5 dist packages h5py hl files py in init self name mode driver libver userblock size swmr kwds 267 with phil 268 fapl make fapl driver libver kwds 269 fid make fid name mode userblock size fapl swmr swmr 270 271 if swmr support usr local lib python3 5 dist packages h5py hl files py in make fid name mode userblock size fapl fcpl swmr 97 if swmr and swmr support 98 flags h5f ACC SWMR READ 99 fid h5f open name flags fapl fapl 100 elif mode 'r ' 101 fid h5f open name h5f ACC RDWR fapl fapl h5py objects pyx in h5py objects with phil wrapper h5py objects pyx in h5py objects with phil wrapper h5py h5f pyx in h5py h5f open OSError Unable to open file unable to open file name 'imagenet' errno 2 error message 'No such file or directory' flags 0 o flags 0 It seems like that something wrong with h5py I try to upgrade h5py but it is still invalid This works well in Tensorflow 1 4 How should I resolve it with Tensorflow 1 5 thanks,,"reedwm,fchollet,fchollet",2018-02-02 03:43:16,2018-02-07 01:11:21
IS,Tensorflow installer assumes that the user uses CUDA 9 0 while CUDA 9 1 is out already,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2018-02-06 15:11:09,2018-02-07 06:37:43
PR,Fix incorrect links in CONTRIBUTING md,This fix fixes two incorrect links in CONTRIBUTING md about license examples The reason for broken links is because tensorboard is in another repo Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-07 00:50:36,2018-02-07 06:53:34
PR,Typo in variable name BETA self BETA,BETA is defined on line 118 as a class member so it can only be accessed via self or via the class name ElasticAverageOptimizer flake8 testing of flake8 count select E901 E999 F821 F822 F823 show source statistics,,cclauss,2018-02-01 17:17:34,2018-02-07 06:54:22
PR,Specify CUDA 9 0 version,The newest CUDA 9 1 is not supported by TF1 5 Sepecify CUDA 9 0 in order to prevent confusion,,gunan,2018-01-27 08:13:49,2018-02-07 07:04:09
IS,Bug of tf contrib estimator replicate model fn,I have used tf contrib estimator replicate model fn recently I encountered a bug of the implementation on master version When there are some global trainable variables created in model fn and if the variables are never used or if they are only used inside tf cond it will fail with the following error messages,,,2018-02-07 08:34:43,2018-02-07 08:35:49
IS,Estimator API and transfer learning fine tuning,I have been using the Estimator API with the model fn and input fn as shown in the official examples for instance This all looks great and wonderful However I'm now facing an issue for going further with it I would like to use a model trained on a dataset and transfer it to another dataset In practice I would like to take the weights from the trained model up to the softmax layer and only initialize randomly this final layer Then I can do fine tuning on the new dataset which has different labels for instance I have not found a way to do what I want Is it something missing in the interface Can we have something like a variable list to restore from a checkpoint and some other not Ideally it would be also good to specify variables to be frozen Does that all make sense,,"tatatodd,tatatodd,ispirmustafa,ispirmustafa,ispirmustafa,skye",2017-11-20 10:06:12,2018-02-07 09:24:55
IS,dynamic rnn loop flat output size prevents arbitrary shaped output tensors,I want a custom RNN cell to output multiple tensors each with a different shape I can handle the logic internally but I'm running into the issue that dynamic rnn loop automatically constructs initial outputs using flat output size nest flatten cell output size This is problematic because the flattening prevents me from specifying arbitrary shapes for my output tensors For concreteness I would like to output three tensors with shapes batch size a batch size b batch size c d e However both def output size self return a b c d e and def output size self return a b c d e fail to create a third tensor with shape batch size 210 160 3 In the first case zero output is a tuple of batch size a batch size b batch size c batch size d and batch size e In the second case the zero output is a tuple of batch size a batch size b batch size c batch size d and batch size e I feel that RNN cell outputs should be permitted to be arbitrary shapes I do not know if this is a desired feature or a bug Linux Ubuntu 16 04 TensorFlow versions 'v1 3 0 rc1 5211 gab0fcac' '1 5 0 dev20171127',,"tatatodd,ebrevdo,ebrevdo,tatatodd,alextp,akshayka,ebrevdo,ebrevdo",2017-11-28 12:50:11,2018-02-07 15:44:44
IS,Using newer NVIDIA drivers causes TF to freeze the entire system if terminated,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 3 LTS Xenial Xerus TensorFlow installed from source or binary Binary through pip install tensorflow gpu TensorFlow version use command below 1 3 0 Git Version v1 3 0 rc2 20 g0787eee Python version 2 7 13 CUDA cuDNN version CUDA 8 0 61 cuDNN 6 GPU model and memory GeForce GTX 950M 2GB Describe the problem I had changed my NVIDIA driver version to 387 12 some time ago After that sometimes when I would terminate TF code either with C in terminal or closing IPython tab in Spyder it would successfully terminate with KeyBoardInterrupt However the other times when I would terminate my entire computer would freeze and become unresponsive Could not use Ctrl Alt F1 to login into a virtual console and kill the process as keyboard also became unresponsive However if I was playing music through Spotify it would continue playing without any interruption This would happen with different files not one specific file But I noticed it would usually happen during the run of sess run tf global variables initializer in any of the files It also has happened some other times like Training completed in Spyder console and Python was idle and I closed the console tab in Spyder Training completed in Spyder IPython tab and another file was run in terminal I closed the IPython tab which was idle in Spyder when the new TF session in the terminal was initializing variables and then my computer froze completely I do not think the contents of the code mattered It would still freeze even if all my code did was define a variable and then initialize it So I tried reverting back to NVIDIA 384 98 to see if anything changed but it was still freezing Now I have reverted back to NVIDIA 381 22 and I have tried terminating TF when it is initializing variables and so far the freezing has not happened Another thing I would noticed after changing to NVIDIA 387 is that tf global variables initializer became very slow always taking 10 seconds I found 7755 where I saw it could be because of CUDA generating PTX So I tried calling the init a second time in the same session and it would run in milliseconds Same for calling init on CPU I understand the init can be slow when run on GPU however I never noticed it running slow prior to when I changed to a newer NVIDIA driver Even after the revert to 381 it still runs slow Source code logs I would really like to know what I can log and how to do that I'm not sure if I can use gdb as my computer becomes unresponsive so I have no way of going into a terminal Below is the sample code I would run and terminate during init to see if computer froze,,"angersson,zheng-xq,nluehr",2017-11-09 22:09:59,2018-02-07 18:09:31
IS,not able to install tensor flow from pip using 3 5 64 bit version of python,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-26 03:37:54,2018-02-07 18:29:38
PR,Add unsortedsegment prod min max sqrt n mean,This pull request adds CPU GPU implementations of tf unsorted segment min tf unsorted segment prod and a GPU implementation for tf unsorted segment max adds python implementations of tf unsorted segment mean tf unsorted segment sqrt n fixes the gradient calculation for unsorted segment sum max 13055 introduced silent dropping of negative values on the cpu However the gradient of e g unsorted segment sum used tf gather and therefore failed for negative indices on cpu I tried to simplify the code and to remove code duplication addressing this todo L362 Also I once filed an issue to add these ops but only now had time to finish it Some notes on this pull request tf gather returns zero on GPU for negative indices and raises an exception on CPU To overcome this the current implementation masks negative indices and sets them to zero later This is of course not as efficient as the original gather Would it make sense to use something like if gpu in op device lower to run different functions depending on the device Instead of having a native op for mean sqrt n I added them in python Making them native would require two additional template arguments a functor to process the counter resulting in more complicated code with probably only minor performance improvement if at all In my quick benchmarks the python ops are nearly as fast as unsorted segment sum However they use more memory than a native op would due to creating a tensor of ones bincount does not work here as it does not support negative indices I simply copy pasted some atomicOp code in cuda kernel helper h instead of writing this more nicely as for a short period there was a completely different version of this file online and I wanted to check back with you before doing something more sophisticated What is the status of this Additionally I guess the function AccumulateInto in segment reduction ops gpu cu cc could be removed CudaAtomicAdd has specializations for complex types in cuda kernel helper h Cheers Phil,,"rmlarsen,rmlarsen,ekelsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,gunan,rmlarsen,rmlarsen,rmlarsen,rmlarsen",2018-01-04 20:05:30,2018-02-07 19:00:00
PR,Fix the tfcompile tests,We can remove the mock import as its not being used Also some of the checkpoints are V1 and V2 versions and we need to handle both the scenarios BUILD bazel build tensorflow compiler aot tests tfcompile test TEST bazel bin tensorflow compiler aot tests tfcompile test Signed off by Subash Patel subash nod labs com,,jhseu,2018-02-07 01:59:10,2018-02-07 19:11:19
IS,TensorBoard Fit domain to data in 1 5 under Windows cuts off max values,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using TensorBoard in custom U Net implementation OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 Python version 3 5 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CUDA 9 0 CuDNN 7 GPU model and memory GeForce GTX 1050 Ti 4 GB 32 GB RAM Exact command to reproduce tensorboard with tf summary scalar Describe the problem After updating from 1 4 to 1 5 I have the problems that the y scale for the scalar graphs in TensorBoard seems to be misscalculated The maximum values are not included in the shown graph they are cut off image,,"skye,jart",2018-02-05 13:17:13,2018-02-07 19:38:54
IS,bug Error in python' malloc memory corruption,Error in python' malloc memory corruption 0x00000000723f9040 Strangely encountered this error when the training was going it happened after a certain number of iterations 7000 iterations with image batch size of 1 using coco dataset I have also attached the memory map that showed up after the backtrace memory map txt,,,2018-01-19 18:21:55,2018-02-07 19:57:04
IS,ValueError Inputs to Dense should have rank 2,error Traceback most recent call last File firstGANtf py line 90 in module G Generator input size g input size hidden size g hidden size output size g output size File firstGANtf py line 55 in init self map1 tf contrib layers linear inputs input size num outputs hidden size File Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow contrib framework python ops arg scope py line 177 in func with args return func args current args File Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow contrib layers python layers layers py line 1409 in fully connected outputs layer apply inputs File Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python layers base py line 303 in apply return self call inputs kwargs File Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python layers base py line 269 in call self build input shapes 0 File Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python layers core py line 110 in build raise ValueError 'Inputs to Dense should have rank 2 ' ValueError Inputs to Dense should have rank 2 code self map1 tf contrib layers linear inputs input size num outputs hidden size self map2 tf contrib layers linear inputs hidden size num outputs hidden size self map3 tf contrib layers linear inputs hidden size num outputs output size,,facaiy,2018-01-17 11:05:49,2018-02-07 19:58:12
PR,Branch 184768730,Pushing from Google Internal to Public,,ankurtaly,2018-02-07 02:15:13,2018-02-07 21:17:05
IS,SSL certificate for tensorflow org expired,The SSL certificate for not expired on June 29,,"martinwicke,martinwicke,gunan,gunan,martinwicke,dsmilkov",2017-08-22 15:25:02,2018-02-07 21:23:34
PR,reshuffle each iteration args now default to True,The documentation for the tf Dataset data shuffle function shuffle states the following reshuffle each iteration Optional A boolean which if true indicates that the dataset should be pseudorandomly reshuffled each time it is iterated over Defaults to True However the default value in the function is None def shuffle self buffer size seed None reshuffle each iteration None The function calls the ShuffleDataset class whose init function also sets the same argument to None by default and uses the following logic to set the default value of the argument to True if reshuffle each iteration is None self reshuffle each iteration True else self reshuffle each iteration reshuffle each iteration This commit sets the argument to True by default in both the function and the class making the above code block redundant and replacing it with only self reshuffle each iteration reshuffle each iteration,,mrry,2018-02-06 23:05:27,2018-02-07 21:34:04
PR,Have check bazel version at least compare versions as ints not stri,Fix bazel version check issue on r1 5 branch Example breakage PiperOrigin RevId 182085505,,"yifeif,yifeif,yifeif,gunan",2018-02-07 19:56:55,2018-02-07 21:34:39
PR,Fix comparison in neon depthwise conv op test,This is in preparation for enabling Grappler for all TensorFlow Python tests,,rmlarsen,2018-02-07 20:46:39,2018-02-07 21:47:05
PR,Bump JetPack default to 3 2 in Android build script,,,"andrewharp,andrewharp",2018-02-07 19:34:11,2018-02-07 22:19:12
PR,Fixes issue when linking of rule ' tensorflow contrib lite toco toco,Fixes issue when linking of rule ' tensorflow contrib lite toco toco' fails because LD LIBRARY PATH is not configured The workaround is to add action env LD LIBRARY PATH LD LIBRARY PATH to bazel build as described here 47295278 Related to issue issuecomment 352562394,,gunan,2018-02-07 17:21:21,2018-02-07 22:19:26
IS,Point Tensorflow To My Local Protobuf Installation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow sorta OS Platform and Distribution e g Linux Ubuntu 16 04 16 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 1 Python version 2 7 and 3 0 Bazel version if compiling from source 0 6 0 GCC Compiler version if compiling from source 5 CUDA cuDNN version 8 and 6 GPU model and memory GTX 1080 Exact command to reproduce make PROTOBUF VERSION 3 4 1 Folks I am using tensorflow C and I added it is path to my CMakeLists txt Everything was working fine but I had to change the protobuf installation to a different path because CAFFE needs a different version of protobuf other than 3 4 1 Now Tensorflow libraries are complaining they cannot find common h from protobuf usr local include google tensorflow tensorflow core framework tensor pb h 9 42 fatal error google protobuf stubs common h No such file or directory I installed protobuf 3 4 1 here usr local include google How do I make Tensorflow realize that protobuf is installed in a different path path,,alextp,2018-02-07 18:47:08,2018-02-07 22:41:35
IS,first session Run when inference too slow on android and mac with c api,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Android armeabi v7a macOS TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 for building so file 1 3 0 for model train Python version 3 5 2 Just used for train Bazel version if compiling from source 0 8 0 GCC Compiler version if compiling from source Apple LLVM version 9 0 0 CUDA cuDNN version V8 0 61 Just used for train GPU model and memory 11GB Just used for train Exact command to reproduce In a word after I loaded the model the cost time of first use session Run is longer 4x than the second use of session Run and the third when coding with C API First I used tensorflow 1 3 0 python to define and train a rnn model Then I used freeze graph and transform graph to make the model files to be one file and shrink the model file size After setting the WORKSPACE by adding the following lines I build the benchmark tool to test the performance If you need other information please let me know,,alextp,2018-02-07 10:01:27,2018-02-07 22:43:01
IS,tensorflow object detection issue,i developed the custom object detector with some 96 images train 76 and test 20 after trained 200k steps my losses 1 goes down correctly after that i create the interference graph all ok but my question is when i run my code to detect the object from video it not able to find the correct object thanks in advance actually i think we have a enough image for the dataset because my dataset can able to detect the object from pre built video so it can detect the object from webcam also but not i dont kw the exact problem i think the resolution may b differ thats y it not able to detect the object use predefined object detection code with my own data set ubuntu 16 04 tensorflow installed in anaconda environment tensorflow 1 4 0 bazel 0 4 5 cpu version,,skye,2018-01-25 06:22:02,2018-02-07 22:50:16
IS,Define gradient for tf linspace and make it work with higher rank tensors not just scalars,I needed to feed forward through tf linspace but it seems that it does not have gradient defined I do not know how to define gradient for existing op but I have implemented my own version of tf linspace in python using tensorflow with so that automatically defined gradient The function is taken from my project and returns 3 rank tensor with shapes num r 1 Inputs are 2 rank tensors with shapes r 1 So that I linspaced vectors columns not just scalars as tf linspace do What do you think Is it worth adding Have I written custom code Yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from pip nightly build TensorFlow version 1 4 1 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,alextp,2018-01-14 13:10:47,2018-02-07 22:52:40
IS,CudnnLSTM returns all Ones 1 after the 10th sequence,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version 3 5 Bazel version if compiling from source v1 3 0 rc1 1486 g752dcb6 1 3 0 CUDA cuDNN version 8 0 6 0 GPU model and memory GTX1050Ti Exact command to reproduce Describe the problem I tried to use CudnnLSTM to speed up the training but found it only returns one after the 10th step following code generate the output Source code logs import tensorflow as tf from tensorflow contrib cudnn rnn import CudnnLSTM import numpy as np np set printoptions linewidth 240 edgeitems 6 Reset default graph tf reset default graph num layer 5 num unit 256 input size 400 seq lenght 20 with tf device ' gpu 0' x tf random uniform seq lenght input size maxval 1 dtype tf float32 x1 tf expand dims x 1 lstm CudnnLSTM num layers num layer num units num unit input size input size input mode 'linear input' direction 'unidirectional' CudnnLSTM parameter lstm para size lstm params size lstm para tf Variable tf random uniform lstm para size validate shape False name 'lstm para' state c tf Variable tf zeros shape num layer 1 num unit trainable False state h tf Variable tf zeros shape num layer 1 num unit trainable False lstm output lstm h lstm c lstm input data x1 input h state h input c state c params lstm para Variable initializing op init tf global variables initializer with tf Session as sess sess run init cudnn output sess run lstm output print cudnn output LSTM output 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 76159418 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 96402758 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99505478 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99932933 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99990922 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 0 99998772 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1,,"tatatodd,zheng-xq,protoget,protoget",2017-10-11 07:30:44,2018-02-07 23:25:32
IS,Cudnn params to canonical failed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 rc2 Python version 3 5 2 Bazel version if compiling from source 0 52 CUDA cuDNN version 8 0 6 0 21 GPU model and memory Tesla K80 11 17GiB Exact command to reproduce Describe the problem If input mode is skip input params to canonical fails with a Check failed error for at least CudnnGRU Logs 2017 08 15 03 05 45 807704 I tensorflow stream executor cuda cuda gpu executor cc 893 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 08 15 03 05 45 808201 I tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 0000 00 1e 0 Total memory 11 17GiB Free memory 11 11GiB 2017 08 15 03 05 45 808229 I tensorflow core common runtime gpu gpu device cc 976 DMA 0 2017 08 15 03 05 45 808241 I tensorflow core common runtime gpu gpu device cc 986 0 Y 2017 08 15 03 05 45 808261 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name Tesla K80 pci bus id 0000 00 1e 0 2017 08 15 03 05 46 543863 F tensorflow contrib cudnn rnn kernels cudnn rnn ops cc 627 Check failed size width height Params size mismatch Expected 25 got 0 Aborted core dumped,,"zheng-xq,protoget",2017-08-15 03:19:45,2018-02-07 23:29:17
IS,Tensorflow website does not show older builds to install using pip,I was at tensorflow 1 4 upgraded tensorflow to 1 5 had to install cudnn 9 0 and now my system is unstable I went to the tensorflow website in order to get the tensorflow 1 4 build and noticed that there is not any reference for these build anymore and now I'm stuck at version 1 5 Where are these references about the whl files Seems that the ' install install windows' page is the same for all the versions which suggest just an ' upgrade',,,2018-02-07 23:24:29,2018-02-07 23:45:39
PR,Testing this on the 1 5 release branch,,,av8ramit,2018-02-07 19:31:38,2018-02-07 23:55:49
IS,proposed new github for tensorflow notebooks,I would like to propose that we make a separate repository in github for jupyter notebooks I think it should be separate from the main tensorflow github so that people can check it out without having to check out all of tensorflow I have created such a github and will work on it by myself for now but I think eventually there should be something more official or at least maybe what I have can be considered official enough to have pointers to it from the main tensorflow github,,aselle,2017-07-26 13:49:09,2018-02-08 00:00:45
IS,warning with tf losses softmax cross entropy,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows and Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 7 GPU model and memory Exact command to reproduce Describe the problem tf losses softmax cross entropy calls tf nn softmax cross entropy with logits in which there is a warning It is better also provide tf losses softmax cross entropy v2 to call tf nn softmax cross entropy with logits v2,,"drpngx,drpngx,yongtang,martinwicke",2018-01-29 06:17:48,2018-02-08 00:14:23
PR,Remove warnings in tf losses softmax cross entropy,This fix tries to address the issue raised in 16534 where tf losses softmax cross entropy causes warnings due to the calling of tf nn softmax cross entropy with logits This fix switches to tf nn softmax cross entropy with logits v2 to remove the warning This fix fixes 16534 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu,martinwicke,ebrevdo",2018-02-07 16:27:50,2018-02-08 00:14:24
PR,Fix typo,,,,2018-02-07 04:40:28,2018-02-08 00:20:16
PR,Remove obsolete BernoulliWithSigmoidProbs,As was pointed out by 9485 BernoulliWithSigmoidProbs is covered by Bernoulli and is obsolete This fix removes BernoulliWithSigmoidProbs This fix closes 9485 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-07 22:32:27,2018-02-08 00:21:14
PR,spelling fixes for contrib docs,,,brettkoonce,2018-02-06 23:21:29,2018-02-08 00:21:32
PR,CMake Windows Added support for ninja build and some fixes changes,Most changes have comments stuck with them but here is the summary of it Changes made Added EXACT flag on find package CUDA to clarify it is building for exactly that version the output minimum required can be misleading Tests if the compiler is compatible with CUDA before it starts building BYPRODUCTS BUILD BYPRODUCTS are added for Ninja to search for dependency otherwise it will output the error shown below ninja error 'zlib install lib zlibstatic lib' needed by 'proto text exe' missing and no known rule to make it Visual Studio is the only generator with that will output under Configuration directory thus removed if it is not Visual Studio Fixed CONFIGURE COMMAND causing some CMake versions to break it resets to default generator the CMake I tried uses NMake Makefiles as default which causes the output below Additional Info The current version of CMake has a problem with its ninja generator as it may produce an error below ninja fatal CreateProcess The filename or extension is too long The CMake with its ninja generator improved can be found here,,"mrry,mrry",2018-02-05 03:18:32,2018-02-08 00:25:49
PR,Fixed a typo in group by window documentation,Nothing else to add,,,2018-02-02 21:36:52,2018-02-08 00:26:37
PR,Fix undefined name import as str any for line 35,flake8 testing of on Python 2 7 14 flake8 count select E901 E999 F821 F822 F823 show source statistics,,cclauss,2018-02-01 17:49:41,2018-02-08 00:28:07
PR,Define Cr Fr Shared Var to resolved undefined names,flake8 testing of flake8 count select E901 E999 F821 F822 F823 show source statistics,,"cclauss,jhseu",2018-01-27 18:22:13,2018-02-08 00:35:05
PR,Fix document typo,Fix TFLite custom op typo,,,2018-01-27 11:57:09,2018-02-08 00:35:14
PR,resolve undefined name array ops,flake8 testing of on Python 2 7 14 flake8 count select E901 E999 F821 F822 F823 show source statistics,,"cclauss,cclauss",2018-01-27 09:07:33,2018-02-08 00:35:30
PR,common global variable with constant py,Made a common constant py for global commonly used variables,,"rajendraarora16,rajendraarora16,rmlarsen,rmlarsen,gunan,rmlarsen,jhseu",2018-01-25 19:56:38,2018-02-08 00:37:02
PR,Fix for GLSTMCell implementation,Fix issue described here Make it work correctly for input sizes num units,,,2018-02-06 00:23:01,2018-02-08 00:39:45
IS,Improve all in memory file copy architecture Python at least,Current file copy at least via Python tf gfile Copy gfile py L22 file io py L371 file io i L113 involves copying the source contents into memory and then writing memory to the destination For scenarios like which is working with an 11GB asset this is unacceptable design file system h is WritableFile is not stubbed to allow anything like a streaming though its RandomAccessFile is not entirely entirely true i suppose WriteableFile Append const StringPiece data could be employed in a streamable fashion ish To cull the Python low hanging fruit at least please implement file io i L113 using a regular streaming design instead of the above described current design,,"yongtang,jart,yongtang,jart",2017-08-28 04:58:44,2018-02-08 00:46:32
PR,Support CopyFile with streaming,This fix tries to address the issue raised in 12641 where it was not possible to have CopyFile with streaming The original implementation copies the whole content of the file to a string buffer and write to the file This could be an issue if the file size is too large than the memory of the host This fix streams the CopyFile operation Also sendfile is used if the file system is posix This fix fixes 12641 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rohan100jain,rohan100jain,rohan100jain,rohan100jain,rohan100jain,rohan100jain,rohan100jain,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,jart,jart,jart,jart,jart,jart,jart,jart,jart,jart,jart,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,jart,yongtang,yongtang,yongtang,drpngx,sb2nov,yongtang,yongtang,drpngx,yongtang,martinwicke,martinwicke,martinwicke,drpngx,yongtang,drpngx,yongtang,martinwicke,yongtang,yongtang,yongtang,drpngx,yongtang,martinwicke",2017-08-28 20:40:11,2018-02-08 00:46:32
PR,Add uint32 and uint64 kernel support for Invert,This fix adds uint32 and uint64 kernel support for Invert In bitwise ops cc uint32 and uint64 have been registered for Invert like other bitwise ops BitwiseAnd BitwiseOr BitwiseXor LeftShift RightShift However no uint32 and uint64 kernels available for Invert yet This fix add uint32 and uint64 kernel for Invert and adds additional test cases to cover the changes Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,caisq,drpngx,yongtang,yongtang,yongtang",2017-12-06 13:18:19,2018-02-08 00:48:01
PR,Add optimized gif support for decode gif,While revisiting the issue of 15838 I noticed that currently optimized gif is not supported However optimized gif is actually possible to be processed as essentially the subsequent frame just adds the content on top of the previous frame on canvas This fix adds the support for optimized gif with decode gif As is shown in the added test case optimized gif optimized gif could be handled the same way as original gif scan gif This fix fixes 15838 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jart,jart,rmlarsen",2018-02-06 16:31:49,2018-02-08 00:48:22
PR,Dropping the Microsoft from the Visual Studio,cmake invocation,,"av8ramit,jhseu",2018-02-08 00:31:02,2018-02-08 01:49:11
IS,Dropout hidden to hidden transition within an RNN,DropoutWrapper allows to apply dropout to either the cell is inputs outputs or states However I have not seen an option to do the same thing for the recurrent weights of the cell for example 4 out of the 8 different matrices used in the original LSTM formulation I specifically refer to the hidden to hidden transition within an RNN Take as an example Section 2 from,,"angersson,ebrevdo",2017-09-17 20:19:42,2018-02-08 02:34:03
IS,Negative indices support for tf gather,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 06 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 Bazel version if compiling from source 5 2 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem tf gather does not support negative indices yet I have implemented this feature If you are okay with this feature then can I create a pull request,,"AnishShah,skye,AnishShah,rryan,ebrevdo",2017-06-28 08:36:50,2018-02-08 02:37:52
PR,cmake flag for Visual Studio,Add the cmake flag for specifying VS version to r1 6 as well,,av8ramit,2018-02-08 03:30:07,2018-02-08 04:15:10
IS,Tensorflow set random seed,I use tf set random seed to set the seed of graph and run programs many times but the result is different Is it a bug or precision problem,,"drpngx,drpngx,gunan,sguada,sguada,sguada",2017-12-06 14:19:43,2018-02-08 14:58:53
IS,The FixedLenFeature of parse example,View API DOC The description maybe wrong Each FixedLenFeature df maps to a Tensor of the specified type or tf float32 if not specified and shape serialized size df shape But the example shows For dense results in two serialized Examples The shape of output is 2 1 not equal to 2 where 2 is serialized size and is df shape,,"aselle,aselle",2017-08-03 03:52:02,2018-02-08 14:59:31
IS,tensorflow 1 6 0 built from sources No module named 'tensorflow python',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version 'v1 5 0 2271 gf7f7036' 1 6 0 rc0 Python version 3 6 Bazel version 0 10 0 GCC Compiler version 5 0 4 CUDA cuDNN version 9 1 7 0 5 GPU model and memory NVIDIA Titan V 12 Gb 2X Exact command to reproduce among others 'from tensorflow python client import device lib' Describe the problem Bug I have installed tensorflow from source today Feb 8 2018 It all worked with the installation but when I in ipython run the command here is a link to how I installed tensorflow as well as cuda and cudnn,,,2018-02-08 13:33:46,2018-02-08 15:23:59
IS,How to redirect tfdbg dumping directory,By default tfdbg dumps saved tensors to tmp but in my case tmp is mount in root root has only several G is space running the example debug is not a problem but when debugging large network for which in one run will generate tensors that exceeds 10 G is memory it would prompts space not enough,,caisq,2018-02-08 14:12:19,2018-02-08 16:21:03
PR,py func convert unicode string results to bytes for python2,Fix 16320,,"facaiy,facaiy,rmlarsen",2018-01-23 10:34:23,2018-02-08 16:54:08
IS,Unable to install upgrade tensorflow1 5 on window10,Exception Traceback most recent call last File C ProgramData Anaconda3 lib site packages pip basecommand py line 215 in main status self run options args File C ProgramData Anaconda3 lib site packages pip commands install py line 335 in run wb build autobuilding True File C ProgramData Anaconda3 lib site packages pip wheel py line 749 in build self requirement set prepare files self finder File C ProgramData Anaconda3 lib site packages pip req req set py line 380 in prepare files ignore dependencies self ignore dependencies File C ProgramData Anaconda3 lib site packages pip req req set py line 554 in prepare file require hashes File C ProgramData Anaconda3 lib site packages pip req req install py line 278 in populate link self link finder find requirement self upgrade File C ProgramData Anaconda3 lib site packages pip index py line 465 in find requirement all candidates self find all candidates req name File C ProgramData Anaconda3 lib site packages pip index py line 423 in find all candidates for page in self get pages url locations project name File C ProgramData Anaconda3 lib site packages pip index py line 568 in get pages page self get page location File C ProgramData Anaconda3 lib site packages pip index py line 683 in get page return HTMLPage get page link session self session File C ProgramData Anaconda3 lib site packages pip index py line 811 in get page inst cls resp content resp url resp headers File C ProgramData Anaconda3 lib site packages pip index py line 731 in init namespaceHTMLElements False TypeError parse got an unexpected keyword argument 'transport encoding',,reedwm,2018-01-28 13:38:19,2018-02-08 16:54:11
IS,transform graph quantize weights does not compile on windows,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I'm executing a command from documentation and I do not think that my custom model is part of the issue OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Server 2012 R2 64 bit TensorFlow installed from source or binary Latest master 7 7 2017 compiled with bazel and msvc TensorFlow version use command below commit 1e037850f1a July 6 21 55 34 2017 0400 Python version 3 5 3 Anaconda 64 bit Bazel version if compiling from source 0 5 1 CUDA cuDNN version CPU Only GPU model and memory CPU Only CPU is dual socket Xeon E5 2687W v2 Exact command to reproduce,,petewarden,2017-07-07 14:06:34,2018-02-08 16:58:37
PR,Enable some passes for graph transform on Windows,Do not know why but the following passes are disabled on Windows quantize weights quantize nodes round weights This patch re enabled them This should fix 11351 Regarding the original commit disabled the passes on Windows git blame gives the commit Does anyone know what the commit message means I built it on Windows 7 x64 and ran it for my tiny MNIST model Looks fine So I am abusing CI to test it,,"scottcjt,scottcjt,petewarden,scottcjt,jhseu",2018-01-15 06:15:55,2018-02-08 16:58:37
IS,LSTM layer in consistent with tf keras v2 0 8 tf and keras 2 1 2,It looks like there are some inconsistencies with the output shape of the LSTM layer Running the following code does not produce an error in keras 2 1 2 More on the discussion in issuecomment 348377899,,"reedwm,fchollet,facaiy,fchollet,fchollet",2017-12-06 19:51:34,2018-02-08 16:59:09
PR,Fix static shape inference for keras layers LSTM,fix 15165 How to test x add test case pass all tests,,"facaiy,drpngx,facaiy,facaiy",2017-12-09 13:29:16,2018-02-08 16:59:09
IS,TypeError when trying to import tensorflow,Hello I have install TF 1 6 from source and getting next error when trying to import it from python System information Linux Ubuntu 16 04 Tensorflow 1 6 0 rc0 built from source Python 3 6 Bazel version 0 10 0 GCC version 5 4 0 CUDA 9 1 cuDNN 7 0 Nvidia 1050 Ti 4GB,,,2018-02-07 15:42:55,2018-02-08 17:00:18
PR,R1 5,,,,2018-02-08 12:36:35,2018-02-08 17:57:08
IS,Feature Request recompute gradient with updated weights within a graph,Hi I wonder could there could be some new features to recompute gradients with updated weights within a graph or if there is any better way to do this For example for estimating hessian norm we need to compute delta N 0 I hessian norm 1 M sum 1 M gradient f x delta gradient f x delta 2delta we need to gradient value on x delta Currently we will get None type if we use tf gradient on var delta directly Thank you very much,,"yaroslavvb,yaroslavvb",2017-10-03 11:28:44,2018-02-08 18:27:09
PR,Fix broken link in CONTRIBUTING md,This fix fixes the broken link in CONTRIBUTING md Without https the markdown will render the link incorrectly to 404 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-08 15:46:50,2018-02-08 18:35:09
PR,Improve shape function of SampleDistortedBoundingBox and fix some test cases,This fix tries to improve the shape function of SampleDistortedBoundingBox and fix several test case errors As is shown in the kernel of SampleDistortedBoundingBox the shape of SampleDistortedBoundingBox are required to be 1 D height width channels for image size 3 D with shape batch N 4 for bounding boxes In the test case the uses shape is incorrect but because there was no check in shape function the test case passes The test case only works for shape but will thrown out an error if run This fix adds the shape check for SampleDistortedBoundingBox and fixes the incorrect test cases Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-08 15:57:48,2018-02-08 18:41:04
PR,Make configure script more lenient to the length of CUDA and cuDNN ve,rsions entered Fixes 6446,,gunan,2018-02-08 04:53:41,2018-02-08 18:45:37
PR,Fix error message in record reader,Corrected error message logged if unsupported compression type,,jhseu,2018-02-06 20:40:25,2018-02-08 18:46:13
PR,Update CONTRIBUTING md,Edited a few grammar issues,,jhseu,2018-02-06 17:50:47,2018-02-08 18:47:35
PR,Fixes variable name,,,"rajendraarora16,rajendraarora16",2018-02-06 09:12:10,2018-02-08 18:48:19
IS,Feature Request 'msg' parameter for test cases,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Not relevant TensorFlow installed from source or binary source TensorFlow version use command below Master rev 3629fc4e98254c37e614ac3f77fa250b75c70f8d Python version 2 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version Not relevant GPU model and memory Not relevant Exact command to reproduce Not relevant Describe the problem Python is unittest module as well as numpy is testing tools allow to optionally pass a message to various assertion functions I would love to have this for all functions in tf TestCase as well quite a few already have this paramter It allows for more descriptive error messages where many permutations of ops dtype cpu gpu configurations are tested e g here L109 As many of the underlying testing functions already have a msg parameter this could easily be implemented e g Relevant functions assertAllClose assertAllCloseAccordingToType assertAllEqual assertAlmostEqual assertAlmostEquals assertArrayNear assertDeviceEqual assertNDArrayNear assertProtoEquals assertProtoEqualsVersion assertRaises adding a msg parameter to these test functions would probably break lot is of test cases so I would omit it assertShapeEqual checkedThread If you agree I will submit a quick pull request,,"yifeif,martinwicke,asimshankar",2017-12-30 08:45:43,2018-02-08 18:48:43
PR,Adds parameter 'msg' to tf TensorFlowTestCase,This commit adds a msg parameter that defaults to None to the following functions assertProtoEquals assertArrayNear assertNDArrayNear assertAllClose assertAllEqual assertShapeEqual assertDeviceEqual Closes 15729,,,2018-02-01 17:20:58,2018-02-08 18:48:43
PR,Add option to not include histograms,add gan model image summaries does the work of adding images to summaries but then it also calls add gan model summaries which dumps every trainable variable to histograms It would be nice to be able to get the image summaries without the histograms I would prefer to just delete that line because it is weird that the two functions are tied It would not be hard to call both functions in your code if you wanted both However this preserves existing functionality If you pass model summaries False it does not call add gan model summaries Cheers,,bstriner,2018-01-30 09:55:51,2018-02-08 18:49:24
PR,python 2 7 unit test error repair on windows,python 2 7 unit test error repair on windows,,fo40225,2018-02-03 12:51:18,2018-02-08 18:54:32
PR,Fix wrong error message for beta distribution,This PR fixes the assertion failure message for Beta distribution is valid sample check which is currently incorrect For a sample with value 1 0 the current error message is sample must be no larger than '1' wrongly suggesting that sample can be 1 0 After this PR the will say sample must be less than '1',,,2018-02-05 22:54:44,2018-02-08 18:54:58
PR,remove keep dims warning in maxout layer,Trivially replaced keep dims with keepdims,,,2018-02-05 09:57:55,2018-02-08 18:55:47
PR,Separate constant file for tpu to make reusable,Using constants is more a way of defensive programming also it improves performance optimization Most importantly it is for human reader Since I have made a nice cleanup to make a separate constant file for making global variable reusable for tpu that can be use anywhere,,"rajendraarora16,drpngx,drpngx,drpngx,rajendraarora16,rajendraarora16,rajendraarora16,rajendraarora16,rajendraarora16,jhseu",2018-02-02 12:51:11,2018-02-08 19:28:11
IS,tf metrics does not include cross entropy,In tensorflow estimator I want to use cross entropy as the evaluation metrics eval metric ops parameter of EstimatorSpec However tf metrics does not have this function Also tensorflow estimator does not allow me to use tf nn sigmoid cross entropy with logits as the eval metric ops,,"facaiy,facaiy,jhseu,jhseu,jhseu,jhseu",2017-10-27 19:52:13,2018-02-08 19:30:49
PR,Fixes two wrong links in install document,There are two wrong links in install document This fixes them,,,2018-02-08 05:12:11,2018-02-08 19:32:11
IS,Undefined symbol when compiling a custom op,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 10 TensorFlow installed from source or binary source TensorFlow version use command below v1 5 0 0 g37aa430 1 5 0 Python version 3 5 2 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source g Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version 9 1 7 GPU model and memory TitanX 12Gb x 2 Exact command to reproduce Makefile,,,2018-02-08 19:21:08,2018-02-08 19:48:08
PR,Move some ndlstm functions to contrib,Moved images to sequence and sequence to images to contrib layers since the ndlstm module might be removed in the future tensorflow versions Addresses this issue,,"selcouthlyBlue,ebrevdo,selcouthlyBlue,selcouthlyBlue,ebrevdo,selcouthlyBlue,jhseu,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,ebrevdo,selcouthlyBlue",2018-02-07 01:19:02,2018-02-08 20:16:38
PR,Improve TensorFlow Lite description,I just started working with the new TensorFlow Lite interface and noticed a few errors in the description First of all there is a small typo copy and paste error that is already fixed in this pr Furthermore the new file extension is not described consistently Sometimes it is lite and sometimes it is tflite This inconsistency may be improved at other places as well Finally the given link that shall describe the Android integration is not up to date Instead of the new compile 'org tensorflow tensorflow lite ' resource the old one compile 'org tensorflow tensorflow android ' is given,,"Johnson145,miaout17",2018-02-06 23:56:43,2018-02-08 20:16:53
PR,Fix missing,,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,jhseu",2018-01-26 16:19:31,2018-02-08 20:17:37
PR,Revert Fix missing 16460,This reverts commit 5e23338fec26f0c5ad588742b8df80e5bf1a940d,,jhseu,2018-02-08 20:31:34,2018-02-08 20:32:41
IS,Segmentation fault when using Intel MKL with np linalg svd,System information I am running this on the Graham supercomputer of Compute Canada I tested the bug on computation nodes but it also appears on login nodes without GPUs Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS 7 TensorFlow installed from source or binary Custom build with Intel MKL I guess TensorFlow version use command below b'v1 3 0 0 g9e76bf3' 1 3 0 Python version Python 3 5 2 default Jun 25 2016 21 38 40 GCC 5 4 0 on linux Bazel version if compiling from source CUDA cuDNN version 7 5 GPU model and memory Tesla P100 Exact command to reproduce Without the import tensorflow as tf the bug does not appear You can collect some of this information using our environment capture script tf env txt Describe the problem So basically when using Intel MKL with the python code above you get a segmentation fault Without the import tensorflow as tf the bug does not appear Strangely when I change the size of the 2nd axis of matrix a to below 201 it works at some point that I tested it was 188 When setting the shape of the matrix a to something bigger like 64 256 it just using all CPUs without returning anything as if it was in a deadlock or something When setting MKL NUM THREADS to 1 both bugs disappear This bug report seems related to all of these issues They are not identical to this problem but really similar so this bug report is just to let you know another symptom related to the same problem Source code logs tf env txt gdb segfault txt,,skye,2017-10-27 14:47:34,2018-02-08 20:57:25
IS,Compiler Errors Installing Tensorflow from Source,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 SP1 TensorFlow installed from source or binary Source TensorFlow version use command below r1 5 Python version 3 6 4 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 6 4 0 CUDA cuDNN version 7 0 GPU model and memory NVIDIA Quadro K4000 Exact command to reproduce bazel build c opt BUILD OPTS tensorflow tools pip package build pip package Describe the problem I have tried compiling with MSYS2 and VS2015 I am trying to get VS2015 to work Using VS2015 and cpu x64 windows msvc host cpu x64 windows msvc among other options I get the following error Any help would be appreciated I can give you more details as well Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"rongjiecomputer,rongjiecomputer,rongjiecomputer,rongjiecomputer,rongjiecomputer,mrry,mrry",2018-01-01 20:06:46,2018-02-08 21:41:17
IS,tf summary FileWriter does not support unicode paths,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes In fact I use code from Denny Britz is CNN tutorial Line 116 OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 x86 64 locale Russian TensorFlow installed from source or binary binary pip install tensorflow TensorFlow version use command below b'unknown' 1 2 0 Bazel version if compiling from source n a CUDA cuDNN version 8 0 5 1 GPU model and memory nvidia 970 Exact command to reproduce,,"rohan100jain,yongtang",2017-06-21 16:26:51,2018-02-09 00:17:35
IS,Backpropagation weight update issue with custom layer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Win 10 TensorFlow installed from source or binary From pip binary TensorFlow version use command below 1 5 Python version 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version None GPU model and memory None Exact command to reproduce See source code Describe the problem I am attempting to implement a custom layer The layer uses the Image to Patch function and simple tensorflow operator The layer is implemented in keras to simplify the model building and training but the backend is in tensorflow I am using a simple cnn as a benchmark whenever I implement my custom layer even only as the first layer to 'encode' the data backpropagation seems to break as no weights get updated in the entirety of the model From my understanding the all the operations used mult div add minus are differentiable and things such as reshape transpose and extract image patches should not prevent backpropagation and weight updates I tried using the basic layer building method and inheriting from the convolution class Conv and both cases prevent the weight update for the whole model but such a thing should not be the case Source code logs Prototype layer Model builder,,,2018-02-08 14:27:12,2018-02-09 00:33:25
IS,explained function generate batch in Deep Learning Assignment 5 word2vec,please explain formula data index data index 1 len data in function generate batch thank you so so much,,,2017-12-22 11:38:06,2018-02-09 04:21:01
IS,Tensorflow gpu 1 6 failed call to cuInit CUDA ERROR NO DEVICE,CUDA 9 0 Cudnn 7 0 Tensorflow gpu 1 6 nvida smi is good nvidia smi Error 2018 02 08 18 14 24 768537 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core platform cpu feature guard cc 140 Your CPU supports instructions that this TensorFlow binary was not compiled to use AVX2 2018 02 08 18 14 25 438352 E C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda driver cc 406 failed call to cuInit CUDA ERROR NO DEVICE 2018 02 08 18 14 25 441350 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda diagnostics cc 158 retrieving CUDA diagnostic information for host Vincent 2018 02 08 18 14 25 441633 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda diagnostics cc 165 hostname Vincent 2018 02 08 18 14 25 443152 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime direct session cc 297 Device mapping Device mapping no known devices MatMul MatMul job localhost replica 0 task 0 device CPU 0 b Const job localhost replica 0 task 0 device CPU 0 a Const job localhost replica 0 task 0 device CPU 0 Code import os import tensorflow as tf os environ CUDA DEVICE ORDER PCI BUS ID see issue 152 os environ CUDA VISIBLE DEVICES 1 from tensorflow python client import device lib print device lib list local devices Creates a graph a tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 2 3 name 'a' b tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 3 2 name 'b' c tf matmul a b Creates a session with log device placement set to True sess tf Session config tf ConfigProto log device placement True Runs the op print sess run c,,qmick,2018-02-08 11:17:04,2018-02-09 07:51:44
IS,Probably wrong implementation for tf layers max pooling1d when data format 'channels first',In function call of class Pooling1D when the input data format 'channels first' it should transform input tensor from ' N C H ' to ' N C H W ' batch size channels height width meaning that we should expand dimension on the last dimension However in the code we use inputs array ops expand dims inputs 1 expanding on the second dimension and transforming from ' N C H ' to ' N 1 C H ' Then the pool shape and strides are looking at the third dimension which is not consistant with our expand dims inputs 1 used before I think the code should be changed to inputs array ops expand dims inputs 1 and return array ops squeeze outputs 1 Using 1 will expand and squeeze on the last dimension transforming from ' N C H ' to ' N C H 1 ' and then doing pool shape and strides on the third dimension Source Code,,"aselle,zhangyaobit,taehoonlee,zhangyaobit,taehoonlee,taehoonlee,yongtang",2017-07-20 09:33:38,2018-02-09 13:06:36
IS,Does Broadcast in TF copy first or just do ops along the axis,For example we have tensor a with shape 100 100 5 and tensor b with shape 1 1 5 when running c tf multiply a b Is b first copied 100 100 times for the big dot multiply with a GPU memory consuming or the dot multiply is done with the original b along axis 0 and 1 The tf multiply page refers to numpy multiply that says it wo not copy just loop I guess it is copied first that I run into GPU memory problem by adjusting a bit the b How is it implemented in TF Could not find the source gen math ops Issue template update Have I written custom code No OS Platform and Distribution Windows 10 x64 Home version TensorFlow installed from pip anaconda with python 3 6 3 TensorFlow version 1 4 1 Bazel version N A CUDA cuDNN version CUDA 8 0 cuDNN 6 GPU model and memory GTX 1050Ti 4 GB memory 3 3 GB available Exact command to reproduce N A not relevant to the question,,skye,2018-01-23 11:52:14,2018-02-09 17:40:02
IS,TF consumes all available RAM with a particular combination of conv2d batch norm and LSTM,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 5 0 0 g37aa430d84 1 5 0 Python version 3 6 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 176 7 0 5 GPU model and memory Tesla V100 AWS P3 16GB Exact command to reproduce python debug tf py Describe the problem When the following code is run on a p3 2xlarge the python process starts consuming RAM indefinitely until the entire server RAM is used and the server dies That is system RAM not GPU memory It does not look it but the code below is the smallest I could find that produces the bad behavior 1 Replacing residual conv with a simple convolution makes the code work i e not hang 2 Reducing the repetition number in layers repeat to e g 2 makes the code work 3 Removing the batch normalization from residual conv makes the code work 4 Removing the LSTM makes the code work 5 The weirdest of all if I set is training True in batch norm instead of is training is training var whose value is set to True in the feed dict then the code works The same code runs successfully on a AWS P2 server with TensorFlow 1 3 Source code logs Edited Simplified the code,,"reedwm,ebrevdo,reedwm,rmlarsen,skye",2018-01-31 17:26:23,2018-02-09 17:40:53
IS,Debug prompts use default colors returned ERR,I was running a example code from tensorpack on Pycharm which runs properly then I changed the session to sess tf debug LocalCLIDebugWrapperSession sess in order to debug as suggested by official example but then I got which I have no clue for the reason can someone help,,skye,2018-02-06 12:23:08,2018-02-09 18:07:22
IS,how to build and install cplusplus library and header file to usr local,how to build and install cplusplus library and header file to usr local,,skye,2018-02-07 10:25:25,2018-02-09 18:09:02
IS,tensorflow is not importing even after successful installation,in Centos 6 9 i am unable to import tensorflow 1 3 0 in any anaconda 2 3 and getting this error please resolve this issue screenshot 7 screenshot 6,,,2017-10-23 04:22:08,2018-02-09 19:32:06
IS,Retval 0 does not have value in a multithreaded context with FIFOQueue and tf scan,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I provide a working script showing the buggy behaviour OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version none GPU model and memory GeForce GTX 280M 1GB Note I reproduced the buggy behaviour on different platforms too macOS High Sierra openSUSE 42 3 and with Tensorflow 1 3 problem context I found the buggy behaviour in one of the helper methods the queue loader of the DeepSpeech project ctc label dense to sparse That implementation is partially clumsy in particular when using tf scan where a scan history context is not used Nevertheless the algorithm should have worked under any circumstances I could reduce the problem scenario to a small standalone example This example uses a number of threads for filling a queue from which batches are requested by dequeu up to the same buggy behaviour if replaced by dequeue many Afterwards the batch is postproccessed For this postprocessing I provided the buggy version function buggy using tf scan and an own implementation function ok Both versions produce the same output data in cases there the buggy versions does not fail buggy behaviour description Very often but not always a test with a larger batch size and smaller thread count leads to the following output tensorflow python framework errors impl InvalidArgumentError Retval 0 does not have value I include the complete log in the next section With a larger thread count and smaller batch size it works If the switch Parameter use buggy version is set to 0 False no choice of batch size and thread count produces a bug This proves that the problem is located in the buggy function and the rest of the workflow is OK I could prove that an implementation without the tf scan works fine too In experiments using the context in tf scan instead of ignoring it did not change the behaviour Even as tf scan does not make much sense in the context it was used for in DeepSpeech it should not have failed and its correct function is essential for many tensorflow based projects And maybe a similar flaw is hidden in the other Higher Order operators too tf map fn tf foldl tf foldr log usage scan bug demo py h batch size BATCH SIZE thread count THREAD COUNT use buggy version USE BUGGY VERSION batch size 15 thread count 1 use buggy version True using buggy implementation True Traceback most recent call last File scan bug demo py line 127 in module retval do it batch size thread count use buggy version rnd seed File scan bug demo py line 99 in do it coord join queue threads File home uli tensorflow local lib python2 7 site packages tensorflow python training coordinator py line 389 in join six reraise self exc info to raise File scan bug demo py line 92 in do it res sess run batch File home uli tensorflow local lib python2 7 site packages tensorflow python client session py line 889 in run run metadata ptr File home uli tensorflow local lib python2 7 site packages tensorflow python client session py line 1120 in run feed dict tensor options run metadata File home uli tensorflow local lib python2 7 site packages tensorflow python client session py line 1317 in do run options run metadata File home uli tensorflow local lib python2 7 site packages tensorflow python client session py line 1336 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Retval 0 does not have value bug demonstration python source import tensorflow as tf from random import Random from threading import Thread import numpy as np import sys from argparse import ArgumentParser def function buggy value sequence lengths max len tf reduce max value sequence lengths max value seuence lenght tns tf expand dims max len 0 init tf expand dims tf cast tf fill max value seuence lenght tns 0 tf bool 0 def scan function previous state current input return tf expand dims tf range max len 0 current input retval tf squeeze tf scan scan function value sequence lengths initializer init parallel iterations 1 axis 1 return retval def function ok value sequence lengths max len tf reduce max value sequence lengths value sequence lengths shape tf shape value sequence lengths x repeated lenghts tf tile tf expand dims value sequence lengths 1 1 max len y repeated x indices tf tile tf expand dims tf range max len 0 value sequence lengths shape 0 1 retval y repeated x indices x repeated lenghts return retval class BatchProvider object def init self batch size function thread count rnd seed self coord None self batch size batch size self random Random rnd seed self capacity 2 batch size self thread count thread count self queue tf FIFOQueue shapes dtypes tf int32 capacity self capacity self y length tf placeholder tf int32 self enqueue op self queue enqueue self y length self close op self queue close cancel pending enqueues True self function function def start queue threads self session coord self coord coord batch threads Thread target self populate batch queue args session for i in range self thread count for batch thread in batch threads self coord register thread batch thread batch thread daemon True batch thread start return batch threads def close queue self session session run self close op def populate batch queue self session while True length self random randint 5 10 target len length try self enqueue op run session session feed dict self y length target len except tf errors CancelledError return def next batch self target lengths self queue dequeue up to self batch size retval self function target lengths return retval def do it batch size thread count use buggy version rnd seed function function buggy if use buggy version else function ok batch provider BatchProvider batch size batch size function function thread count thread count rnd seed rnd seed sess tf Session coord tf train Coordinator queue threads batch provider start queue threads sess coord batch batch provider next batch try for in range 1 if coord should stop break res sess run batch print batch print res except Exception ex coord request stop ex finally batch provider close queue sess coord join queue threads sess close return res if name ' main ' args sys argv 1 argparser ArgumentParser argparser add argument batch size dest batch size type int default 15 argparser add argument thread count dest thread count type int default 1 argparser add argument use buggy version dest use buggy version type int default True if len args 0 argparser print usage parsed argparser parse args args args batch size parsed batch size thread count parsed thread count use buggy version parsed use buggy version print batch size str batch size print thread count str thread count print use buggy version str use buggy version rnd seed Random random print using buggy implementation str use buggy version retval do it batch size thread count use buggy version rnd seed print success,,jart,2017-11-02 14:50:41,2018-02-09 19:33:43
IS,Code size with XLA AOT,I currently research about xla using AOT compilation and use Cifar10 as benchmark After using AOT compilation I got a binary file that size is 5 3MB but the original tensorflow graph is size is about 4 2MB Does it means a using AOT compilation can not promise always reduce code size efficiently,,"sanjoy,sanjoy",2018-02-07 11:05:27,2018-02-09 19:36:39
PR,DO NOT MERGE Testing Revert Dropping the Microsoft from the Visual Studio,Reverts tensorflow tensorflow 16848,,av8ramit,2018-02-08 23:24:09,2018-02-09 19:45:34
IS,Request For Tagalog Translation,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I want to help in the Translation for Tagalog version so that this project will be available in our country Hope you will grant my request Source code logs,,"skye,MarkDaoust,drpngx",2018-02-08 16:56:10,2018-02-09 20:16:32
PR,Update tensorboard dependency to 1 6 0 and new name,TensorBoard for versions 1 6 0 will use the tensorboard name on PyPI rather than the previous tensorflow tensorboard name Unfortunately PyPI pip have no notion of package renames so it will look like an unrelated dependency i e users doing an upgrade will wind up with both names installed although the new tensorboard package will overwrite the old one functionally speaking Let me know if you think it is worth mentioning this in the release notes Note that the new name currently just has TB 1 6 0 rc0 on PyPI but we should have the 1 6 0 final release out in a couple days before TF 1 6 0 is published cc,,"nfelt,gunan,nfelt,gunan,nfelt",2018-02-07 01:02:33,2018-02-09 21:15:32
IS,Tensorflow 1 5 0 Import Error on CUDA 9 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I used the stock version OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip binary for windows with GPU support TensorFlow version use command below 1 5 0 Python version Python 3 6 1 from Anaconda CUDA cuDNN version 9 0 7 0 5 GPU model and memory Exact command to reproduce import tensorflow as tf Describe the problem Installed CUDA CUDNN 8 0 6 9 0 7 9 1 7 Used pip to install tensorflow gpu 1 5 0 The installation process finished normally However when import the module by import tensorflow as tf error messages raises and it says ImportError Could not find 'cudart64 90 dll' I double checked the CUDA PATH and PATH environmental variables to make sure that CUDA CUDNN 9 0 7 are being used Later I removed the 8 0 6 and 9 1 7 and the problem still exists Source code logs Traceback most recent call last File stdin line 1 in module File C Users user Anaconda3 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users user Anaconda3 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users user Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 30 in module self check preload check File C Users user Anaconda3 lib site packages tensorflow python platform self check py line 82 in preload check build info cudart dll name build info cuda version number ImportError Could not find 'cudart64 90 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 9 0 from this URL,,"skye,MarkDaoust",2018-02-06 06:25:59,2018-02-09 21:23:56
IS,Trying to allocate large output tensor in custom op leads to multiple evaluation of Compute method,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS X 10 13 2 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version 2 7 14 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CPU version of Tensorflow GPU model and memory Exact command to reproduce make Describe the problem I wrote a custom op During debugging i have noticed then Compute method from my op fired multiple times during single op eval call My quest lead me to row If output size is small e g 1000 my op works well and executes one time If output size is big e g 15000000 my op executes multiple times Source code logs There are 3 files in archive custom op source code demo eval script makefile config to build op and run eval issue zip,,,2018-02-05 19:37:37,2018-02-09 23:03:52
IS,Restoring a model trained with tf estimator and feeding input through feed dict,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 Python version 3 6 2 CUDA cuDNN version 9 0 7 0 GPU model and memory NVIDIA 1050 4 GB I trained a resnet with tf estimator the model was saved during the training process The saved files consist of data index and meta I would like to load this model back and get predictions for new images The data was fed to the model during training using tf data Dataset I have closely followed the resnet implementation given here 1 I would like to restore the model and feed inputs to the nodes using a feed dict My attempt rebuild input pipeline images labels input fn data dir batch size 32 num epochs 1 rebuild graph prediction imagenet model fn images labels 'batch size' 32 wouldata format' 'channels first' aresnet size' 18 mode tf estimator ModeKeys EVAL predictions saver tf train Saver with tf Session as sess ckpt tf train get checkpoint state r' model' saver restore sess ckpt model checkpoint path while True try pred im sess run prediction images print pred except tf errors OutOfRangeError break I fed a dataset which was evaluated on the same model using classifier evaluate but the above method gives wrong predictions The model gives same class and probability 1 0 for all images The code I used for training and building the model is as below Specification for parsing the dataset def parse record raw record is training keys to features 'image encoded' tf FixedLenFeature tf string default value '' 'image class label' tf FixedLenFeature dtype tf int64 default value 1 parsed tf parse single example raw record keys to features image tf image decode image tf reshape parsed 'image encoded' shape 3 image tf image convert image dtype image dtype tf float32 label tf cast tf reshape parsed 'image class label' shape dtype tf int32 return image tf one hot label 2 The following function parses the data and creates batches for training def input fn is training data dir batch size num epochs 1 dataset tf data Dataset from tensor slices filenames is training data dir if is training dataset dataset shuffle buffer size FILE SHUFFLE BUFFER dataset dataset flat map tf data TFRecordDataset dataset dataset map lambda value parse record value is training num parallel calls 5 dataset dataset prefetch batch size if is training dataset dataset shuffle buffer size SHUFFLE BUFFER dataset dataset repeat num epochs dataset dataset batch batch size iterator dataset make one shot iterator images labels iterator get next return images labels A classifier is created as below for training on train set and evaluation on validation set classifier tf estimator Estimator model fn model function model dir flags model dir config run config params aresnet size' flags resnet size wouldata format' flags data format 'batch size' flags batch size Training cycle classifier train input fn lambda input function training phase True flags data dir flags batch size flags epochs per eval hooks logging hook Evaluate the model eval results classifier evaluate input fn lambda input function training phase False flags data dir flags batch size This is how I tried to load and get predictions from the model I would like to feed images through a feed dict so that I can see the model is performance on individual images What is the right way to restore a saved model and perform inference on it I want to feed images directly without using tf data Dataset I had opened a question on stackoverflow but did not get any response I'm wondering if there really is a feature that can help with restoring a model trained with tf estimator and feeding images through a feed dict 1,,,2018-02-09 21:13:31,2018-02-09 23:08:42
PR,Branch 184929151,Had probably 50 100 files with merge conflicts due to some files being formatted by internal tools during a recent GitHub pull Pretty sure I fixed all of them correctly though,,"case540,case540",2018-02-08 09:00:52,2018-02-09 23:16:02
PR,tflite make calling NNAPI work again resend,for the previous one somehow reverted overwritten calling PrepareOpsAndTensors before using NN API looks 1 unnecessary 2 decrease next execution plan index to prepare so that the logic check in the next line next execution plan index to prepare execution plan size will fail,,"freedomtan,freedomtan,freedomtan",2018-02-06 15:26:45,2018-02-09 23:50:45
PR,Fix the missing Windows cuDNN reference,,,"av8ramit,gunan",2018-02-09 22:16:26,2018-02-10 01:07:23
IS,python 3 6 latest tf infinity of msgpack numpy py 142 PendingDeprecationWarning encoding is deprecated,Symptom trying to train resnet 50 imagenet is imagenet resnet py script fails to start after 5 minutes because of some thread being blocked trying to flush a gazillion of warning messages above Since this problem is solved by downgrading from tf nightly gpu 1 7 0 dev20180208 to tensorflow gpu 1 5 TensorFlow must be blame for introducing a new usage of this deprecated method Unfortunately the warning messages are quite uninformative with no indication of who is calling this Note that Python 3 6 is the only Python 3 version supported on Amazon Deep Learning conda AMI images Warning messages look like this,,"yaroslavvb,ppwwyyxx,yaroslavvb",2018-02-10 04:21:46,2018-02-10 05:08:48
IS,control dependencies unexpected behavior with tensorflow 1 3,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary from binary TensorFlow version use command below 1 1 0 1 3 0 1 5 0 Python version 2 7 6 Bazel version if compiling from source None GCC Compiler version if compiling from source gcc version 4 9 4 Ubuntu 4 9 4 2ubuntu1 14 04 1 for compiling custom ops CUDA cuDNN version do not matter GPU model and memory do not matter Exact command to reproduce As following Describe the problem For the code below the complete sample follows later,,mrry,2018-02-09 17:09:15,2018-02-10 09:34:43
PR,Add reduction parameter to mean pairwise squared error loss,add reduction parameter to tf losses mean pairwise squared error to make it consistent with all of the other loss functions increased clarify of the documentation for the function use the axis parameter instead of reduction indices for math ops reduce sum because reduction indices is deprecated,,"chrisyeh96,jhseu",2018-02-10 00:14:40,2018-02-10 11:53:40
PR,Improve formatting of Tensor shapes in tf losses,Updating the documentation of Tensor shapes in tf losses to match the documentation guide at,,"chrisyeh96,chrisyeh96,jhseu",2018-02-09 19:31:38,2018-02-10 11:55:26
PR,Improve shape function of NonMaxSuppression,In the docs for tf image non max suppression the shapes of the args boxes and scores are num boxes 4 and num boxes respectively This fix improve the shape function of NonMaxSuppression so that boxes shape 0 scores shape 0 num boxes Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-09 13:15:51,2018-02-10 12:00:39
IS,Saver is saving empty meta and data files,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu TensorFlow installed from source or binary I do not know it is on google colaboratory TensorFlow version use command below 1 4 1 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version i do not know it is on google colaboratory GPU model and memory Tesla K40 12 gb Exact command to reproduce summarize K40 py I'm saving my model using but tensorflow creates all the files but they are always empty i e 0 bytes I'm attaching the source code but I do not think it is my fault since once every 200 runs it actually creates non empty files I'm using google colaboratory summarize K40 copy py txt,,,2018-02-10 11:37:15,2018-02-10 13:46:16
IS,Bazel can not find cudnn h ignores cudnn directory specified in configuration,cuda inst txt System information OS Platform and Distribution e g Linux Ubuntu 16 04 Fedora 27 x64 TensorFlow installed from source or binary Source Release TensorFlow version use command below 1 6 0 rc0 Python version 3 6 Bazel version if compiling from source 1 10 GCC Compiler version if compiling from source 6 4 0 CUDA cuDNN version CUDA 9 1 cudNN 7 0 5 GPU model and memory GTX 1060 Exact command to reproduce bazel build config opt config cuda incompatible load argument is label false tensorflow tools pip package build pip package Relevant cudnn files are located at,,,2018-02-10 17:51:07,2018-02-10 21:51:27
PR,dataset ops py batch checks type immediately,Currently if you inadvertently pass a non integer value for batch size you get a strangely cryptic error with a long trace This PR hopes to clear that up by checking the type right at the call site If I made a mistake in the preferred approach to such a check I would appreciate advice I did some searching and I could not find obvious examples that can accept both integers and scalar tensors there are always slight variations and acceptable imports depend on the code location,,"ahundt,mrry",2018-02-09 19:11:54,2018-02-10 22:06:37
IS,Multi GPU could not provide performance improve with dataset API,I just wrote a small piece of code in tensorflow to test its multi gpu performance with dataset API It takes the same time to finish actually single GPU is even faster perhaps due to overhead reasons Do anyone know where does the problem come from python version Python 2 7 12 tensorflow version 1 4 0 CUDA version 8 0 Ubuntu version Ubuntu 16 04 LTS Thanks,,"mrry,mrry",2018-02-10 06:59:27,2018-02-10 22:21:33
PR,Add S3 plugin to the list of file system plugin in doc add filesys md,This fix adds S3 plugin to the list of file system plugin in doc add filesys md,,yongtang,2018-02-10 20:42:57,2018-02-11 03:14:42
PR,Fix the profiler python docstring link,This fix fixes the python docstring link of the profiler profilerg3doc profiler g3doc,,yongtang,2018-02-10 19:41:09,2018-02-11 03:15:13
PR,MSVC Workaround MSVC template lambda parsing bug,16882 15213,,rongjiecomputer,2018-02-10 01:58:56,2018-02-11 03:16:47
PR,Fix typo,,,ManHyuk,2018-02-10 09:26:02,2018-02-11 03:17:01
PR,typo fix,Copied the new description from docstring on line 37 Used the phrase spectogram timeslice rather than frequency window for consistency with the tooltip on,,,2018-02-10 01:44:52,2018-02-11 03:17:14
IS,Building with MKL reduces CPU performance,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary both TensorFlow version use command below 1 4 Python version 3 6 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 8 GPU model and memory Tesla P100 PCIE 16GB Exact command to reproduce Describe the problem Building tensorflow with mkl config mkl prevents the system from using all its cores CPU load remains always below 20 in my testcase Using the same build flags but without mkl achieve 100 CPU load and a nearly 10 times faster execution While playing with the MKL flags described here optimizing for cpu i noticed some strange behavior Running the MKL build with OMP NUM THREADS 27 KMP SETTINGS 1 KMP AFFINITY verbose results in the following print If I use the same execution flags with a build without MKL or with the pip version I get the same ouput up to OMP Info 247 KMP AFFINITY pid 36958 tid 37191 thread 27 bound to OS proc set 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 Afterwards no OMP prints are created It seems like if I build with mkl tensorflow continues to create more and more threads but cant utilize them Is this a configuration issue or a bug If its a known issue please expand the performance guide pinging because of its help with the performance issue with while loop,,"qmick,rohan100jain,vivek-rane,vivek-rane,vivek-rane,vivek-rane,vivek-rane,tfboyd,vivek-rane,vivek-rane,drpngx,tatianashp",2017-11-12 13:52:22,2018-02-11 04:49:08
IS,typeid broken across shared boundary makes a271c36b5ead4686b72d972b193bf1f534a92ffd not work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom shared object linking to OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below a271c36b5ead4686b72d972b193bf1f534a92ffd Python version 3 5 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 CUDA cuDNN version 9 0 7 0 5 GPU model and memory P4000 8 GB Exact command to reproduce This is a little involved Describe the problem First of all thanks for quickly responding to my issue 16682 and for following up with the fixes in a271c36b5ead4686b72d972b193bf1f534a92ffd without my even mentioning the problem to you Very impressive I know that in that commit you mention A subsequent change will move tf contrib data kernel implementations to a custom op library When you say custom op library I assume you mean a distinct shared object file Unfortunately unless you use config monolithic to build this will not work because the typeid of DatasetVariantWrapper will be different between libtensorflow framework so and the custom op library shared object because they are loaded with RTLD LOCAL config monolithic avoids the problem because python framework internal so is loaded with RTLD GLOBAL in that case This will override the custom op library is weak I am talking about weak linkage of symbols here typeid of DatasetVariantWrapper Otherwise variant get DatasetVariantWrapper will fail in dataset cc is GetDatasetFromVariantTensor because the two typeids that get compared have two separate pointers I first found this problem documented here This stack overflow answer was also helpful I'm not sure what the right solution is to this yet It seems it may be possible to change from pointer equality for type info to checking the equality of mangled strings with strcmp based on my reading of libstdc is typeinfo header file Happy to answer any questions s ince this is rather involved Source code logs,,"mrry,mrry,mrry",2018-02-10 22:09:34,2018-02-11 18:39:30
IS,Bug Compile Tensorflow 1 5 0 Java from source failed on NVIDIA Jetson TX2 with error ' bazel tools tools jdk singlejar' must produce a single file,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 aarch64 TensorFlow installed from source or binary source on branch r1 5 TensorFlow version use command below v1 5 0 1934 g9e7ce91 1 5 0 Python version Python 3 5 Bazel version if compiling from source 0 9 0 and 0 10 0 both tried with clean installation GCC Compiler version if compiling from source gcc Ubuntu Linaro 5 4 0 6ubuntu1 16 04 6 5 4 0 20160609 CUDA cuDNN version CUDA 9 0 cuDNN 7 0 GPU model and memory NVIDIA Tegra X2 major Pascal architecture 8G JDK Version Here are some ways I tried but faild with same error 1 Configure again With same configure settings and compile 2 Remove the directory cache and do the step 1 3 Remove the directory cache and tensorflow source directory git clone tensorflow from r1 5 branch then do step 1 4 Remove cache and the bazel binary compile and install bazel from latest source release 0 10 0 without error Then I use bazel 0 10 0 to compile tensorflow java This produced same error,,"skye,asimshankar,asimshankar",2018-02-03 10:22:31,2018-02-11 22:01:46
PR,Added early stopping and CheckpointSaverListeners to train and evaluate,Addresses the issue at,,"rmlarsen,rmlarsen,xiejw,xiejw",2018-01-25 06:00:13,2018-02-11 23:44:37
IS,TypeError 'Keyword argument not understood ' 'adjustment' when passing slim batch norm as normalizer fn to slim conv2d,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes TensorFlow installed from source or binary Binary TensorFlow version 1 4 0 CPU Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Describe the problem I encountered a problem using batch norm in slim conv2d Whenever I pass slim batch norm as the normalizer fn for slim conv2d I encounter this error,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue",2018-02-12 02:56:25,2018-02-12 03:16:33
PR,Make Lstm1d ndlstm base unrolled use lstm cell with state is tuple True,This is to address the deprecation warning thrown by using state is tuple False,,"selcouthlyBlue,drpngx,selcouthlyBlue",2018-01-29 05:52:17,2018-02-12 04:13:53
PR,Ndlstm dynamic batch size,Apparently lstm2d separable lstm does not accept dynamic batch sizes number of images This pull request addresses issue,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,drpngx,selcouthlyBlue",2018-01-30 01:27:17,2018-02-12 04:14:02
IS,Linking of rule ' tensorflow python pywrap tensorflow internal so' failed usr bin ld gold fatal error bazel out k8 opt bin tensorflow core kernels objs quantize and dequantize op tensorflow core kernels quantize and dequantize op pic o read Input output error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 Python version 2 7 12 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source 5 4 0 Exact command to reproduce bazel build cxxopt D GLIBCXX USE CXX11 ABI 0 copt march native tensorflow tools pip package build pip package Describe the problem I am trying to install Tensorflow on my laptop which has i5 and 8GB RAM When I am building the Tensorflow from source I use bazel build cxxopt D GLIBCXX USE CXX11 ABI 0 copt march native tensorflow tools pip package build pip package Everything seems to go well but at the end I get this error ERROR home siladittya tensorflow tensorflow python BUILD 3166 1 Linking of rule ' tensorflow python pywrap tensorflow internal so' failed Exit 1 usr bin ld gold fatal error bazel out k8 opt bin tensorflow core kernels objs quantize and dequantize op tensorflow core kernels quantize and dequantize op pic o read Input output error collect2 error ld returned 1 exit status Target tensorflow tools pip package build pip package failed to build I looked up a few posts in some forums but they are saying that it can be solved using local resources but when I used that argument bazel build local resources 8000 2 0 2 0 cxxopt D GLIBCXX USE CXX11 ABI 0 config opt tensorflow tools pip package build pip package I am getting the same error again But it does not seem to be a error which can be solved using local resources because it does not work What else can be the solution to this problem,,,2018-02-12 03:18:39,2018-02-12 04:31:46
PR,CMake optionally link to ZLIB as systemlib shared objects,If the user has ZLIB and devel pkg installed at the system and the user wants to keep using that ZLIB for tensorflow the cmake option Dsystemlib ZLIB ON will allow to do so Another option Dsystemlib ALL ON will turn on every systemlib options This requires PR 15381 because this exposes the need for fPIC from png This PR is an implementation suggestion to the proposal 13061 Signed off by MyungJoo Ham myungjoo ham samsung com,,"myungjoo,gunan,myungjoo,rmlarsen,myungjoo,gunan,myungjoo",2017-12-15 05:46:30,2018-02-12 07:04:44
PR,Improve formatting of shapes in tf losses documentation,,,chrisyeh96,2018-02-10 20:57:19,2018-02-12 07:05:17
PR,Fix warning about keep dims keep dims keepdims for tf reduce sum,Fix warning about keep dims keep dims keepdims for tf reduce sum,,jhseu,2018-02-08 20:36:39,2018-02-12 07:05:38
IS,Windows Installation tutorial has wrong cuda version requirement 9 0 required for latest version,I just ran the installation validation and it is telling me I need 9 0 the tutorial says we must use 8 0 I do not have cheap access to Internet now I have to find 1GB plus of data without paying 15 to use my phone is data Please update the page to recommend 9 0 Thank you,,"reedwm,reedwm,gunan,av8ramit,MarkDaoust,gunan",2018-01-27 01:54:37,2018-02-12 07:11:15
IS,TF 1 3 unable to create Session in the first time,I have install TF 1 3 GPU using anaconda It is failed to create session as run TF in script file As run TF interactively or using spyder same error messages were shown and it fail to create session in the first time However it able to create session if run sess tf Session again The TF will run either by input line by line script or using exec compile open filename rb read filename 'exec' The error message as create session source activiate tf13py36 tf13py36 python import tensorflow as tf sess tf Session 2018 02 05 17 44 25 343373 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2018 02 05 17 44 25 343398 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2018 02 05 17 44 25 540883 I tensorflow stream executor cuda cuda gpu executor cc 893 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 02 05 17 44 25 541399 I tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name GeForce GTX 980 Ti major 5 minor 2 memoryClockRate GHz 1 228 pciBusID 0000 03 00 0 Total memory 5 94GiB Free memory 5 83GiB 2018 02 05 17 44 25 600695 W tensorflow stream executor cuda cuda driver cc 523 A non primary context 0x225e110 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2018 02 05 17 44 25 600988 E tensorflow core common runtime direct session cc 171 Internal failed initializing StreamExecutor for CUDA device ordinal 1 Internal failed call to cuDevicePrimaryCtxRetain CUDA ERROR INVALID DEVICE Traceback most recent call last File stdin line 1 in module File home tchen anaconda3 envs tf13py36 lib python3 6 site packages tensorflow python client session py line 1486 in init super Session self init target graph config config File home tchen anaconda3 envs tf13py36 lib python3 6 site packages tensorflow python client session py line 621 in init self session tf session TF NewDeprecatedSession opts status File home tchen anaconda3 envs tf13py36 lib python3 6 contextlib py line 89 in exit next self gen File home tchen anaconda3 envs tf13py36 lib python3 6 site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl InternalError Failed to create session sess tf Session 2018 02 05 17 45 19 371509 W tensorflow stream executor cuda cuda driver cc 523 A non primary context 0x225e110 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2018 02 05 17 45 19 371738 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 980 Ti pci bus id 0000 03 00 0 2018 02 05 17 45 19 430913 W tensorflow stream executor cuda cuda driver cc 523 A non primary context 0x225e110 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that x1 tf constant 1 2 3 4 x2 tf constant 5 6 7 8 result tf multiply x1 x2 print sess run result 5 12 21 32 SYSTEM Infomation ubuntu16 04 cuda V8 061 cudnn 6021 gtx1060 tensorflow1 3 0 python3 6 1 memory 30G used 5 5GB nvidia smi Tue Feb 6 10 21 38 2018 NVIDIA SMI 384 111 Driver Version 384 111 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 980 Ti Off 00000000 03 00 0 Off N A 22 31C P8 19W 250W 110MiB 6078MiB 0 Default 1 Quadro 600 Off 00000000 04 00 0 On N A 36 53C P0 N A N A 524MiB 959MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 19564 C python 98MiB I am grateful to anyone for helping me Thank you very much,,,2018-02-06 19:27:01,2018-02-12 15:46:09
IS,tfcompile with tf nn dynamic rnn crashes,Trying to build a C binary with tfcompile crashes with INVALID ARGUMENTS Mising Exit successor to rnn while Switch if the graph contains tf nn dynamic rnn but it works with tf nn static rnn Why is this,,"carlthome,drpngx,tatatodd,carlthome,tatatodd,carlthome,tatatodd,ebrevdo,jart,carlthome,hawkinsp,ebrevdo,hawkinsp,carlthome,hawkinsp,carlthome,carlthome,carlthome,ebrevdo,ebrevdo,ebrevdo,tatatodd,ebrevdo,carlthome,ebrevdo",2017-07-04 15:43:30,2018-02-12 16:27:22
PR,Update version string to 1 6 0 rc1,,,"gunan,av8ramit",2018-02-10 17:51:54,2018-02-12 17:35:44
PR,Update bazel version in docker,,,yifeif,2018-02-08 23:25:52,2018-02-12 18:09:21
IS,Windows Installation tutorial has wrong cuDNN version requirement 7 required for latest version,Inaccuracies in the documentation In the installation documentation Tensorflow in Windows says that the system must be running a version of CUDA 9 0 correctly and cuDNN 6 0 not correct because on the Nvidia website we can download and install only cuDNN v7 0 5 for CUDA 8 0 9 0 9 1 cuDNN v7 0 4 for CUDA 8 0 9 0 cuDNN v6 0 for CUDA 8 0 In said that If you are using GPU Acceleration on Windows or Linux TensorFlow 1 5 now has CUDA 9 and cuDNN 7 support built in In issue 16477 as said Windows also requires cuDNN 7 looks like we missed that In proof of his words let me give you output logs tensorflow15 C Windows system32 python Python 3 5 4 Anaconda Inc default Nov 8 2017 14 34 30 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Users User AppData Local conda conda envs tensorflow15 lib site packages tensorflow python platform self check py line 87 in preload check ctypes WinDLL build info cudnn dll name File C Users User AppData Local conda conda envs tensorflow15 lib ctypes init py line 351 in init self handle dlopen self name mode OSError WinError 126 The specified module was not found During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users User AppData Local conda conda envs tensorflow15 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users User AppData Local conda conda envs tensorflow15 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users User AppData Local conda conda envs tensorflow15 lib site packages tensorflow python pywrap tensorflow py line 30 in module self check preload check File C Users User AppData Local conda conda envs tensorflow15 lib site packages tensorflow python platform self check py line 97 in preload check build info cudnn dll name build info cudnn version number ImportError Could not find 'cudnn64 7 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Note that installing cuDNN is a separate step from installing CUDA and this DLL is often found in a different directory from the CUDA DLLs You may install the necessary DLL by downloading cuDNN 7 from this URL In conclusion Need to replace cuDNN v6 0 For details see NVIDIA is documentation Note that cuDNN is typically installed in a different location from the other CUDA DLLs Ensure that you add the directory where you installed the cuDNN DLL to your PATH environment variable to cuDNN v7 0 For details see NVIDIA is documentation Note that cuDNN is typically installed in a different location from the other CUDA DLLs Ensure that you add the directory where you installed the cuDNN DLL to your PATH environment variable on the web page,,,2018-02-12 16:47:36,2018-02-12 18:26:25
IS,contrib tfgan batch norm is training True for both training and inferencing non slim version,Hi I am exploring contrib tfgan such a great work shor batch norm is training True for both training and inferencing However when I see the example in source code of both generator and discriminator of MNIST as below with slim arg scope layers fully connected layers conv2d transpose activation fn tf nn relu normalizer fn layers batch norm weights regularizer layers l2 regularizer weight decay net layers fully connected noise 1024 net layers fully connected net 7 7 256 net tf reshape net 1 7 7 256 The default argument of layers batch norm is set to True and this gen fn and dis fn are used for both training phase and generating test images phase inferencing Is it a bug or it is intended If it is intended can you explain why is that non slim implementation In addition I do not really like slim and I believe some people do not either Can I use other model construction libraries like tf layers or keras to build the network Is tfslim a must Thank you System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary source TensorFlow version use command below 1 5 and 1 4 1 Python version 3 6 Bazel version if compiling from source 0 7 GCC Compiler version if compiling from source 4 2 CUDA cuDNN version NA CPU GPU model and memory NA Exact command to reproduce,,"reedwm,joel-shor,joel-shor",2018-01-30 17:48:55,2018-02-12 19:03:42
PR,Branch 185398372,,,yifeif,2018-02-12 18:51:03,2018-02-12 20:28:18
IS,cuda config h is required to build non CUDA release,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 NixOS 18 03 git 869485a Impala TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 3 5 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 6 4 0 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel build config opt tensorflow tools pip package build pip package Describe the problem TensorFlow with CUDA support disabled does not build CUDA support is disabled in configure Source code logs,,,2017-11-10 15:48:20,2018-02-12 20:28:58
PR,TESTING DO NOT MERGE,,,yifeif,2018-02-12 19:09:16,2018-02-12 20:53:47
IS,'InputFnOps' object has no attribute areceiver tensors',System information TensorFlow installed from source or binary Source Python version Python 2 7 13 cat etc issue Linux orion 4 9 0 3 amd64 1 SMP Debian 4 9 30 2 deb9u5 2017 09 19 x86 64 GNU Linux VERSION ID 9 VERSION 9 stretch are we in docker No compiler c Debian 6 3 0 18 6 3 0 20170516 Copyright C 2016 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux orion 4 9 0 3 amd64 1 SMP Debian 4 9 30 2 deb9u5 2017 09 19 x86 64 GNU Linux check pips numpy 1 12 1 protobuf 3 5 1 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 tensorflow transform 0 3 1 check for virtualenv True tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset Describe the problem I ran into some incompatibility issues running tf estimator DNNClassifier with tf contrib learn InputFnOps and tf contrib learn Experiment There has been a separate solved issue I have tried the bundle version but it does not work for me tensorflow 1 3 tensorflow transform 0 3 1 six 1 10 0 However if I switch to tf contrib learn DNNClassifier the issue go away It is also suggested to use tf estimator DNNClassifier rather than tf contrib learn DNNClassifier I would like to get tf estimator DNNClassifier work Source code logs Error message local lib python2 7 site packages tensorflow python estimator estimator py line 440 in export savedmodel serving input receiver receiver tensors AttributeError 'InputFnOps' object has no attribute areceiver tensors',,tatianashp,2018-01-26 15:07:52,2018-02-12 22:11:17
PR,1 6 Cherrypicks for RC1,,,"gunan,gunan",2018-02-12 21:01:26,2018-02-12 22:12:53
IS,tensorflow 1 3 1 4 1 5 1 6 DLL load failed with CUDA 9 1 CUDnn 7 05 Windows 10,import tensorflow strack trace,,"gunan,gunan,gunan",2018-02-11 20:23:48,2018-02-12 22:38:52
IS,Update Dockerfile to install Python 3 6,The Python 3 containers at gcr io tensorflow tensorflow generated by tensorflow tools docker are currently built using Python 3 5 It would be nice to update them to Python 3 6 instead which I think would be as simple as adding sudo apt get install python3 6 Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"shoyer,gunan,shoyer",2018-02-08 20:36:22,2018-02-12 22:46:23
PR,Remove header dependence on cuda config h to fix opensource custom op,support Fixes 14454 Fixes 12860 PiperOrigin RevId 185194924,,"gunan,gunan",2018-02-12 22:32:17,2018-02-12 23:13:36
PR,Add documentation for s3 usage with TensorFlow,This fix adds a very preliminary documentation for s3 usage with TensorFlow as an attempt to address the comment issuecomment 364682030 Ideally I think it would be good if usage with GCS could be added to the doc page as well,,"yongtang,jhseu,jhseu,yongtang,yongtang,yongtang",2018-02-10 21:36:34,2018-02-12 23:29:08
PR,Update tb nightly dep to 1 7 0a0 1 8 0a0,Now that tf nightly is at 1 7 0 on PyPI and tb nightly has been updated to publish at 1 7 0 as well synchronize the deps so that current tf nightly depends on current tb nightly,,nfelt,2018-02-12 22:13:03,2018-02-12 23:48:05
PR,Fix some warnings with keep dims in tf contrib distributions,This fix fixes some warnings with keep dims in tf contrib distributions and math ops tests Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-02-12 12:11:05,2018-02-12 23:49:23
PR,MSVC Use explicit func pointer to static method instead of lambda func,MSVC cannot decide the common type to accept two lambda functions even though they are non capturing and have the same function signatures Since they just pass parameters to static methods just use function pointers to these static methods using EqShapeFuncType bool const Shape const Shape is really just for readability I just thought that reader might not be able to figure out the function signature if I just use auto eq shapes layout sensitive ShapeUtil Equal ShapeUtil Compatible cc 16911,,rongjiecomputer,2018-02-11 08:48:47,2018-02-12 23:51:51
IS,Please support Cuda 9 1,I tried cloning the alpha zero chess from and almost got everything to work However when I try python src chess zero run py self I get the message ImportError Could not find 'cudart64 90 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 9 0 from this URL The problem is that I have CUDA 9 1 and cannot seem to get CUDA 9 0 on the website Would it be hard to make a version of TensorFlow gpu that works with CUDA 9 1 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Installed from TensorFlow version use command below 1 5 Python version 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 1 GPU model and memory NVIDIA GeForce GTX 1050 Ti 8GB Ram Exact command to reproduce python src chess zero run py self You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION e eDownloads python c import tensorflow as tf print tf GIT VERSION tf VERSION Traceback most recent call last File C Users User Anaconda3 lib site packages tensorflow python platform self check py line 75 in preload check ctypes WinDLL build info cudart dll name File C Users User Anaconda3 lib ctypes init py line 348 in init self handle dlopen self name mode OSError WinError 126 The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File string line 1 in module File C Users User Anaconda3 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users User Anaconda3 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users User Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 30 in module self check preload check File C Users User Anaconda3 lib site packages tensorflow python platform self check py line 82 in preload check build info cudart dll name build info cuda version number ImportError Could not find 'cudart64 90 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 9 0 from this URL Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am requesting an update because I have CUDA 9 1 and can not get CUDA 9 0 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"gunan,tfboyd",2018-02-09 06:15:20,2018-02-13 00:21:04
PR,Fixed documentation formatting,,,"rmlarsen,martinwicke",2018-01-24 01:03:41,2018-02-13 00:22:53
PR,Introducing TensorRT operator,This PR introduces a new op that wraps around an highly optimized TensorRT engine and provides a seamless integration between TensorRT and TensorFlow Add a TRTEngineOp that encapsulates a TensorRT executable Add CreateInferenceGraph to contract a TensorRT compilable subgraph to a TRTEngineOp Update BUILD files to include new contrib package Add tensorflow contrib tensorrt python package to expose API to python,,"samikama,benoitsteiner,benoitsteiner,samikama,jjsjann123,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,jjsjann123,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,samikama,samikama,samikama,samikama,aaroey,samikama,samikama,samikama,jjsjann123,aaroey,zheng-xq,zheng-xq,samikama,wujingyue,wujingyue,samikama,samikama,samikama,zheng-xq,zheng-xq,zheng-xq,zheng-xq,jjsjann123,jjsjann123,jjsjann123,aaroey,aaroey,samikama,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,jjsjann123,jjsjann123,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,jjsjann123,jjsjann123,benoitsteiner,aaroey,samikama,jjsjann123,samikama,aaroey,samikama,samikama,samikama,samikama,aaroey,aaroey,jjsjann123,aaroey,samikama,jjsjann123,aaroey,aaroey,samikama,aaroey,samikama,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,samikama,aaroey,aaroey,aaroey,aaroey,aaroey,wujingyue,jjsjann123,jjsjann123,jjsjann123,aaroey,jjsjann123,samikama,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,jjsjann123,aaroey,samikama,aaroey,aaroey,aaroey,aaroey,jjsjann123,jjsjann123,samikama,jjsjann123,aaroey,aaroey,samikama,jjsjann123,aaroey,jjsjann123,jjsjann123,aaroey,jjsjann123,samikama,aaroey,jjsjann123,samikama,aaroey,jjsjann123,samikama,aaroey,samikama,aaroey,aaroey,samikama,samikama,jjsjann123,samikama,samikama,aaroey,jjsjann123,aaroey,aaroey,jjsjann123,jjsjann123,samikama,samikama,aaroey,jjsjann123,samikama,aaroey,samikama,samikama,samikama,aaroey,samikama,samikama,aaroey,samikama,aaroey,samikama,samikama,samikama,aaroey,samikama,aaroey,samikama,samikama,aaroey,samikama,samikama,aaroey,samikama,aaroey,samikama,aaroey,samikama,aaroey,samikama,aaroey,samikama,samikama,aaroey,aaroey,tadeegan",2018-01-19 23:09:29,2018-02-13 00:46:31
IS,VS2017 Windows build error tfcompile no user defined conversion for 'xla HloInstruction Identical lambda 6c9857087f6484280d6d6ec01ce267b9,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64bit TensorFlow installed from source or binary source TensorFlow version use command below afc30a0dc00e13d5f0ed522e98ba7074f21d2813 Python version Python 3 6 2 Anaconda Inc Bazel version if compiling from source 0 10 GCC Compiler version if compiling from source Microsoft R C C Optimizing Compiler Version 19 12 25835 for x64 CUDA cuDNN version none GPU model and memory none Exact command to reproduce bazel build config opt tensorflow compiler aot tfcompile Describe the problem After applying 16904 to fix 16882 compilation continues until it fails with See attached file for the complete build log,,,2018-02-10 13:10:48,2018-02-13 04:17:23
PR,Fix local path for hexagon graph execution in sample script,As Android arch is supported since r1 5 the local path must also be changed If not and error occurs that the file can not be found Signed off by MyungSung Kwak yesmung gmail com,,gunan,2018-01-09 09:17:34,2018-02-13 06:46:54
PR,Fix typo in build and run inception hexagon sh,Signed off by MyungSung Kwak yesmung gmail com,,,2018-02-13 06:48:46,2018-02-13 07:17:37
IS,Feature request Adding data format argument to lstm2d separable lstm,Since ndlstm is used for 2D data such as images I think it would be nice to include a data format argument in lstm2d separable lstm in case one decides to use the channels first format NCHW for their images i e Using CNN having NCHW data format followed by NDLSTM,,"selcouthlyBlue,selcouthlyBlue",2018-02-05 00:49:33,2018-02-13 08:29:32
IS,How show detecting image,When I start a object detection tutorial script via ipython it is did not show me any image My console image But something is starting in process because starting some python program but before it is open the program is closed image code is here,,,2018-02-09 13:57:41,2018-02-13 09:32:42
IS,ImportError libcublas so 9 0 cannot open shared object file No such file or directory when trying to run object detection,Hello I am trying to install the object detection module of tensorflow but when running the following command python3 object detection builders model builder test py I get the following error I have install CUDA 8 0 9 0 9 1 and cuDNN 6 and 7 but still have the following error I appreciate your advice thank you Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 9 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File object detection builders model builder test py line 18 in module import tensorflow as tf File usr local lib python3 5 dist packages tensorflow init py line 24 in module from tensorflow python import File usr local lib python3 5 dist packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 9 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime,,gunan,2018-02-04 07:47:48,2018-02-13 14:06:16
PR,Add complex64 and complex128 support for ApplyAdadelta kernel,This fix tries to address the issue raised in 13521 where the complex64 and complex128 support for ApplyAdadelta is missing The test cases have also been updated This fix fixes 13521 Signed off by Yong Tang yong tang github outlook com,,"yongtang,ebrevdo,yongtang,rmlarsen,rmlarsen,yongtang,yongtang",2017-12-15 18:26:56,2018-02-13 15:33:33
IS,Unsuccessful TensorSliceReader constructor Failed to find any matching files for Node save RestoreV2 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 device CPU 0 arg save Const 0 0 save RestoreV2 tensor names save RestoreV2 shape and slices,I am working on a TensorFlow Speech Recognition challenge and following tutorial The model training is completed but I'm not able to Freeze the model This is what I get after typing the required command OS Windows 10 TensorFlow version 1 4 Python version 3 6 3 GPU CUDA V 8 and cuDNN V 6 0 I came across and url where the suggested fix was to add to the model name But in this case I'm not able find the list of codes where I'm supposed to make the change How do I find the code that needs the fix Or is there another issue that I'm unaware of Please help,,,2017-12-17 12:43:29,2018-02-13 17:04:22
PR,DOCS Update the description of the fused parameter,Update the description of layers batch normalization and contrib layers python layers batch norm to reflect the fact that fused None is equivalent to fused True In fact both functions check at the beginning if fused is None and if yes they set it to True,,"codrut3,martinwicke,chrisying",2017-12-15 19:26:06,2018-02-13 17:37:22
PR,Enable no unroll for Clang on Windows,15990,,rongjiecomputer,2018-01-27 14:55:19,2018-02-13 17:49:49
PR,Fix issue 15269,A possible solution to fix issue 15269,,"drpngx,drpngx,martinwicke,fchollet,lukaszkaiser,drpngx,drpngx,fchollet",2017-12-11 11:06:48,2018-02-13 19:25:49
IS,Sampled softmax loss stops gradients on sampled classes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CUDA 8 cuDNN 6 GPU model and memory 4 x TITAN X Pascal Describe the problem The backbone of TensorFlow is sampled loss functions nce loss and sampled softmax loss is a helper function called compute sampled logits L961 L1139 compute sampled logits takes as input weights and biases of the final layer the output labels the inputs to the final layer inputs the sampled values of the output layer a few other things and returns the logits and labels of only the requested sampled labels One of the first ops executed is L1046 L1047 This line seems like it is stopping gradients flowing back through the sampled values if i'm reading it correctly Should not the gradients be stopped from flowing back through the non sampled values as opposed to the sampled values Why are gradients being stopped at the sampled values,,"drpngx,drpngx",2018-01-29 18:24:23,2018-02-13 20:40:48
IS,ParseSingleExample op is missing from op def registry get registered ops,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Pip install TensorFlow version use command below cpu 1 5 0 Python version 3 0 You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem ParseSingleSample is available as tf parse single example method call but it is not listed in the op def registry get registered ops Which cause freeze graph py call to fail with following error ValueError No op named ParseSingleExample in defined operations When converting mobilenet model with training information,,mrry,2018-02-13 19:19:42,2018-02-13 20:55:36
PR,Fix compiler error mentioned in 16960 introduced by commit 1baac78627,Addressing 16960 The commit introduced member functions MklSubAllocator AddAllocVisitor and MklSubAllocator AddFreeVisitor which respectively use allocator AddAllocVisitor and allocator AddFreeVisitor but allocator is of type Allocator which does not have these member functions I am guessing the intention was to change the type of allocator to BFCAllocator to make this work,,,2018-02-13 05:41:18,2018-02-13 21:43:14
PR,Fixes issues in tf contrib keras utils Progbar,In version 1 5 of Tensorflow if Progbar is target is set to None internally it gets set to 1 Changed code that referenced self target is not None to self target 1 self target is None to self target 1 Also ProgBar is printing twice as reported here Fixed duplicate text,,"fchollet,fchollet",2018-02-01 00:35:02,2018-02-13 22:15:56
PR,add not equal op to tf op files txt,Adding the kernel op NotEqual to tf ops list txt,,"resec,martinwicke,drpngx",2017-11-07 11:39:26,2018-02-13 22:37:55
PR,Add label wav dir py,Predicts all wave files in a directory 93ec8b84 nohash 0 wav no score 0 10860 go score 0 09965 on score 0 09433 a7545b9f nohash 1 wav off score 0 10953 right score 0 10349 unknown score 0 10015 6272b231 nohash 1 wav right score 0 10766 yes score 0 10450 left score 0 09779 439c84f4 nohash 1 wav no score 0 11556 right score 0 10160 go score 0 09805 2f813234 nohash 1 wav no score 0 12223 go score 0 11225 on score 0 10878,,"PW486,drpngx",2017-11-24 01:42:31,2018-02-13 22:38:12
PR,Branch 185565363,,,yifeif,2018-02-13 20:37:16,2018-02-13 22:47:31
IS,tf contrib estimator replicate model fn fails when a trainable variable does not have gradient,tf contrib estimator replicate model fn fails when the gradient of a trainable variable is None The error messages are,,isaprykin,2018-02-07 11:27:24,2018-02-13 22:48:05
IS,Feature Request Make lstm2d separable lstm accept Dynamic Batch Sizes,Apparently lstm2d separable lstm does not accept dynamic batch sizes number of images Whenever I set the shape of a placeholder to None height width depth to be fed into the network I get this error I guess it would be nice to have separable lstm accept dynamic batch sizes so it can be used effectively,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,facaiy,selcouthlyBlue",2018-01-28 04:46:35,2018-02-13 22:57:48
IS,TensorFlow demo keeps stopping for flowers images on Android TFlite,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary TensorFlow version use command below 1 5 0 Python version 3 6 Bazel version if compiling from source NA GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory 1080Ti 11gb Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I am following Tensorflow for poets 2 7 session8 Run the customised app So far I have successfully ran the demo by Google for Android but when I train custom flowers data and try to run the demo again by following session 8 in the tutorial in which I replace output name by final result as follows private static final String OUTPUT NAME final result Source code logs 02 08 20 48 30 Launching tfmobile adb install multiple r t C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 7 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 2 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 6 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 8 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 9 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug dep dependencies apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 5 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 4 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 3 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 1 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild intermediates split apk debug slices slice 0 apk C Users Ajinkya Tensorflow for poets tensorflow for poets 2 android tfmobile gradleBuild outputs apk debug tfmobile debug apk Split APKs installed adb shell am start n org tensorflow demo org tensorflow demo ClassifierActivity a android intent action MAIN c android intent category LAUNCHER Client not ready yet Connected to process 32013 on device motorola moto g 4 ZY223WW626 Capturing and displaying logcat messages from application This behavior can be disabled in the Logcat output section of the Debugger settings page I InstantRun starting instant run server is main process D tensorflow CameraActivity onCreate org tensorflow demo ClassifierActivity 3c0dd38 D tensorflow CameraActivity onStart org tensorflow demo ClassifierActivity 3c0dd38 D tensorflow CameraActivity onResume org tensorflow demo ClassifierActivity 3c0dd38 I Adreno QUALCOMM build 7d18700 I8ee426a9a2 Build Date 10 07 16 OpenGL ES Shader Compiler Version XE031 09 00 03 Local Branch mybranch22308589 Remote Branch quic LA BR 1 3 6 rb1 6 Remote Branch NONE Reconstruct Branch NOTHING I OpenGLRenderer Initialized EGL version 1 4 D OpenGLRenderer Swap behavior 1 I CameraManagerGlobal Connecting to camera service I tensorflow CameraConnectionFragment Desired size 640x480 min size 480x480 I tensorflow CameraConnectionFragment Valid preview sizes 1280x960 1280x720 960x720 960x540 864x480 720x480 640x480 I tensorflow CameraConnectionFragment Rejected preview sizes 768x432 320x240 176x144 I tensorflow CameraConnectionFragment Exact size match found I TensorFlowImageClassifier Reading labels from labels txt I TensorFlowInferenceInterface Checking to see if TensorFlow native methods are already loaded E art No implementation found for long org tensorflow contrib android RunStats allocate tried Java org tensorflow contrib android RunStats allocate and Java org tensorflow contrib android RunStats allocate I TensorFlowInferenceInterface TensorFlow native methods not found attempting to load via tensorflow inference I TensorFlowInferenceInterface Successfully loaded TensorFlow native methods RunStats error may be ignored D AndroidRuntime Shutting down VM E AndroidRuntime FATAL EXCEPTION main Process org tensorflow demo PID 32013 java lang RuntimeException Failed to load model from 'file' at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 100 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 130 at org tensorflow demo CameraActivity 1 onPreviewSizeChosen CameraActivity java 159 at org tensorflow demo CameraConnectionFragment setUpCameraOutputs CameraConnectionFragment java 421 at org tensorflow demo CameraConnectionFragment openCamera CameraConnectionFragment java 428 at org tensorflow demo CameraConnectionFragment access 000 CameraConnectionFragment java 64 at org tensorflow demo CameraConnectionFragment 1 onSurfaceTextureAvailable CameraConnectionFragment java 95 at android view TextureView getHardwareLayer TextureView java 387 at android view TextureView draw TextureView java 325 at android view View updateDisplayListIfDirty View java 16065 at android view View draw View java 16849 at android view ViewGroup drawChild ViewGroup java 3768 at android view ViewGroup dispatchDraw ViewGroup java 3554 at android view View updateDisplayListIfDirty View java 16060 at android view View draw View java 16849 at android view ViewGroup drawChild ViewGroup java 3768 at android view ViewGroup dispatchDraw ViewGroup java 3554 at android view View draw View java 17086 at android view View updateDisplayListIfDirty View java 16065 at android view View draw View java 16849 at android view ViewGroup drawChild ViewGroup java 3768 at android view ViewGroup dispatchDraw ViewGroup java 3554 at android view View updateDisplayListIfDirty View java 16060 at android view View draw View java 16849 at android view ViewGroup drawChild ViewGroup java 3768 at android view ViewGroup dispatchDraw ViewGroup java 3554 at android view View updateDisplayListIfDirty View java 16060 at android view View draw View java 16849 at android view ViewGroup drawChild ViewGroup java 3768 at android view ViewGroup dispatchDraw ViewGroup java 3554 at android view View draw View java 17086 at com android internal policy DecorView draw DecorView java 751 at android view View updateDisplayListIfDirty View java 16065 at android view ThreadedRenderer updateViewTreeDisplayList ThreadedRenderer java 657 at android view ThreadedRenderer updateRootDisplayList ThreadedRenderer java 663 at android view ThreadedRenderer draw ThreadedRenderer java 771 at android view ViewRootImpl draw ViewRootImpl java 2808 at android view ViewRootImpl performDraw ViewRootImpl java 2616 at android view ViewRootImpl performTraversals ViewRootImpl java 2223 at android view ViewRootImpl doTraversal ViewRootImpl java 1258 at android view ViewRootImpl TraversalRunnable run ViewRootImpl java 6348 at android view Choreographer CallbackRecord run Choreographer java 871 at android view Choreographer doCallbacks Choreographer java 683 at android view Choreographer doFrame Choreographer java 619 at android view Choreographer FrameDisplayEventReceiver run Choreographer java 857 at android os Handler handleCallback Handler java 751 at android os Handler dispatchMessage Handler java 95 at android os Looper loop Looper java 154 at android app ActivityThread main ActivityThread java 6123 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 867 at com android internal os ZygoteInit main ZygoteInit java 757 E AndroidRuntime Caused by java io IOException Not a valid TensorFlow Graph serialization NodeDef mentions attr wouldilations' not in Op name Conv2D signature input T filter T output T attr T type allowed DT HALF DT FLOAT attr strides list int attr use cudnn on gpu bool default true attr padding string allowed SAME VALID attr data format string default NHWC allowed NHWC NCHW NodeDef MobilenetV1 MobilenetV1 Conv2d 0 convolution Conv2D T DT FLOAT data format NHWC dilations 1 1 1 1 padding SAME strides 1 2 2 1 use cudnn on gpu true input MobilenetV1 Conv2d 0 weights Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary at org tensorflow contrib android TensorFlowInferenceInterface loadGraph TensorFlowInferenceInterface java 392 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 96 52 more Application terminated And the application is terminated what should I do to resolve this,,,2018-02-10 20:05:01,2018-02-13 22:59:19
PR,Add instructions for building CUDA enabled Android TensorFlow,,,"andrewharp,andrewharp,andrewharp",2018-02-12 23:29:27,2018-02-13 23:20:07
PR,Android CUDA cherrypicks for 1 6,,,andrewharp,2018-02-13 23:38:03,2018-02-13 23:42:00
IS,Estimator built with keras estimator model to estimator fails on Estimator export savedmodel,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Debian 3 16 36 TensorFlow installed from source or binary Binary TensorFlow version use command below 'v1 4 0 19 ga52c8d9' '1 4 1' Python version 2 7 9 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See gist Describe the problem If I create a model with tf keras compile it and then turn it into an estimator by simply passing it thru to tf keras estimator model to estimator I am able to train and evaluate the model just fine however when I got to export it with Estimator export savedmodel I get the following error I'm not sure what export outputs is but if I had to guess it should be a mapping of output names to output tensors from the keras model Here is the very unclean code I'm using to get to this although there is a lot of dependencies that wo not work for y'all If you need a repro I can take the time to put it together just let me know Notably the error occurs on line 300,,"tatatodd,tatatodd,fchollet,yifeif,yifeif,yifeif",2018-01-25 02:20:52,2018-02-14 00:37:53
PR,Cherrypicks for Android CUDA support in 1 6,,,andrewharp,2018-02-13 23:54:04,2018-02-14 00:53:36
PR,tflite fixed label image resize bilinear problems,1 Interpreter does not need delete anymore so cannot use std unique ptr otherwise there will be double free 2 ResizeBilinear need the align corners parameter after,,"freedomtan,freedomtan",2018-02-07 12:48:06,2018-02-14 00:53:37
IS,module 'tensorflow python pywrap tensorflow internal' has no attribute 'TFE NewContextOptions',I have followed the TensorFlow tutorial Simple Audio Recognition When I was running train py I got this error message,,,2018-02-13 11:48:22,2018-02-14 01:41:21
PR,Relu bn fix,1 Fix cifar 10 divergence issue due to MKL layout mismatch 2 Fix BatchNorm unit test failures,,,2018-02-14 00:42:55,2018-02-14 02:02:23
PR,fix a problem in tflite custom operators md,s SinResize SinPrepare Obviously it should be SinPrepare instead of SinResize,,"freedomtan,caisq,drpngx,freedomtan",2017-12-07 06:35:50,2018-02-14 02:22:19
IS,Tensorboard Error 404 path dataImageSrc not found,I am using the object detection API and training a new ssd mobilenet from scratch with my dataset I already did a successful retraining but now i want to try a complete new training without checkpoint The training and evaluation job seem to run normal but when i start tensorboard and open port 6006 in my browser the terminal where its running shows following error W0213 11 04 23 869396 Thread 2 application py 273 path dataImageSrc not found sending 404 and no scalars except of the learning rate are visualized in tensorboard In contrast to that Evaluation images the graph distributions and histogram are all shown correctly,,,2018-02-13 10:14:45,2018-02-14 08:12:05
IS,Go API graph get tensor by name,What is the equivalent of the Python graph get tensor by name in Go thanks,,"asimshankar,asimshankar",2018-02-13 08:12:55,2018-02-14 09:05:05
IS,Invoke get shape on sparse tensor leads to feeding error,If I invoke get shape method on sparse tensor the shape tensor will be added into the unfeedable tensors set of the current graph Then when I feed the sparse tensor an error occurs The codes below show this error System information I do not think this bug is related to my environment cat etc issue Darwin liqimaideMacBook Pro local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 9 0 0 clang 900 0 37 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin MacBook Pro local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 check pips numpy 1 11 3 protobuf 3 2 0 tensorflow 1 0 0 check for virtualenv False tensorflow import tf VERSION 1 0 0 tf GIT VERSION v1 0 0 rc2 15 g47bba63 dirty tf COMPILER VERSION v1 0 0 rc2 15 g47bba63 dirty Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs,,"reedwm,ebrevdo,reedwm,tatatodd,reedwm,ebrevdo,reedwm,ebrevdo",2017-10-11 16:56:27,2018-02-14 16:29:32
IS,Error in python' double free or corruption out 0x00007fc5d674d9b0,I have built the latest version of TensorFlow from github repository with the following commands bazel build s config mkl c opt copt msse4 1 copt msse4 2 tensorflow tools pip package build pip package bazel bin tensorflow tools pip package build pip package tmp tensorflow pkg pip install tmp tensorflow pkg tensorflow 1 4 0 cp36 cp36m linux x86 64 whl And get the following error after the import tensorflow command in python Python 3 6 3 Anaconda custom 64 bit default Oct 16 2017 15 28 36 GCC 4 8 2 20140120 Red Hat 4 8 2 15 on linux Type help copyright credits or license for more information Intel R Distribution for Python is brought to you by Intel Corporation Please check out import tensorflow as tf Error in python' double free or corruption out 0x00007fc5d674d9b0 Any suggestions on how to fix this issue,,"drpngx,gunan",2018-01-04 12:56:02,2018-02-14 17:17:23
PR,change cnn mnist example to use Adam optimizer added a 'loss' summary,I remember that other non estimator versions of this example used the Adam optimizer which has nicer convergence could we use it in this example Also I added a summary for loss so that it would show up on TensorBoard I would also like to add support for passing in num steps model dir etc as command line args with defaults but I will make that a separate PR unless you would like it bundled with this one,,"sb2nov,ispirmustafa,ispirmustafa,martinwicke,ispirmustafa",2017-09-09 15:43:23,2018-02-14 18:55:20
IS,Adding a custom Tensorflow Op under Windows cmake does not work with TF LoadLibrary,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I have a custom fork which is forked from r1 3 and the only modifications are some commented out lines to be able to build AVX support as described in another ticket and the recent added fix for wide strings OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit cmake TensorFlow installed from source or binary Built from source under windows with the cmake setup TensorFlow version use command below 1 3 1 Python version 3 6 Bazel version if compiling from source Does not apply GCC Compiler version if compiling from source Microsoft R Build Engine version 14 0 25420 1 CUDA cuDNN version CUDA 8 cuDNN 5 1 GPU model and memory GTX 980 Ti 6GB 64GB main memory Exact command to reproduce Does not apply Describe the problem When using the cmake setup on windows to build Tensorflow from source and using AddUserOps which was added from some time ago example like I am able to build GPU enabled tensorflow ops I can load the DLL in python with tf load op library and can actually use it there I can built GraphDefs with my custom Op and export it as protobuf file When I try to use this graph for inference in another application where I use the C API its not possible for me to get the op loaded and registered Loading the same DLL as which with the python API succeeds works on a system level with C C the DLL is loaded successfully as seen through procmon exe or dependency walker and TF LoadLibrary returns with status ok but when trying to run the Graph afterwards the custom op is not recognized from Tensorflow and Tensorflow errors with Not found Op type not registered Trying to get the OpList afterwards with the Lib handle also returns no ops So somehow the ops are not seen here even though they are recognized from python side I tried a lot of different things to circumvent this like described in my Stack Overflow Question here but none of the approaches worked It seems like that the op registration which is done after loading the DLL on python side is not properly done when performing the same operation with TF LoadLibrary from C C Since I cannot get tensorflow built with debug symbols I dont have a callstack where this registration fails unfortunately,,"guschmue,reedwm,mrry,guschmue",2017-11-15 20:38:27,2018-02-14 20:03:21
IS,Feature Request global average pooling layer in tf layers,Hello Can we add an implementation of global average pooling to tf layers or tf contrib layers It can look much like the Keras implementation here and essentially just requires calling tf reduce mean I suspect lots of people have written functions called global pooling that just call reduce mean and it would be nice to have a tf layers function that just does this for consistency readability System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary AWS Deep Learning AMI Conda TensorFlow version use command below 1 5 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory K80 Exact command to reproduce N A You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"drpngx,martinwicke,fchollet,fchollet",2018-01-29 07:36:48,2018-02-14 22:58:30
IS,Build error introduced by 1baac78627 Ca not build sources master,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Debian Jessie TensorFlow installed from source or binary Source TensorFlow version use command below Master Python version 2 7 14 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source GCC 4 9 2 10 CUDA cuDNN version Cuda8 Cudnn7 GPU model and memory 1080Ti Exact command to reproduce Class MklCPUAllocator has a member allocator which is of type tensorflow Allocator which does not have the member functions accessed,,,2018-02-12 23:17:52,2018-02-14 23:40:33
IS,Cannot interpret feed dict key as Tensor The name 'DecodeJpeg contents 0' refers to a Tensor which does not exist The operation 'DecodeJpeg contents' does not exist in the graph,Hello I try to get the output of each layer of my CNN Here is the full example I do not understand why this appends I looked with Tensorboard I do not know where should I get the DecodeJpeg informations of the layer Edit Have I written custom code I use deep mnist tutorial example and I modify the size of the input image OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from TensorFlow version 1 4 0 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce,,drpngx,2018-01-17 16:09:30,2018-02-15 00:07:39
PR,New roadmap,Revised Roadmap document with draft changes from Feb 2018,,byronyi,2018-02-13 16:04:56,2018-02-15 00:23:57
PR,Branch 185747281,,,yifeif,2018-02-14 22:51:50,2018-02-15 00:31:18
IS,Iterator get next documentation improvement request,System information N A Describe the problem Recently I have written some code using Dataset API and I would like to request a problem with documentation IMO Instead of hardcoding comments here L31 please move is annotation about Iterator get next and GET NEXT CALL WARNING THRESHOLD into get next method documentation I do not know why I did not get that beautiful warning on my console output but I think I'm not the first person with funny thread bomb running and consuming system resources You know about that also see comment So It would be great if you could move all critical annotation into main documentation I'm thinking now about all ML newcomers rather than me Yeah I actually found solution by myself That is all Source code logs N A,,,2018-02-12 20:20:58,2018-02-15 00:31:54
PR,Adds a check for shuffle None in numpy input fn,numpy input fn is shuffle argument is set to None by default If the argument is not provided the function raises a TypeError since shuffle is of type NoneType and not bool This is fixed by adding a simple check to see if shuffle is None and setting it to False if so From my understanding this should be the desired behavior Do let me know if this is not the case It does not seem like additional test code is needed or any existing test code needs to be changed Thanks,,,2018-02-15 00:46:23,2018-02-15 00:50:46
PR,allow 'None' as batch size for TimeFreqLSTMCell,Currently it is not allowed to have a variable batch size in TimeFreqLSTMCell as the size is casted to an int internally This patch fixes this by omitting the int cast Tested it in an audio event detection framework without problems,,"progwolff,rmlarsen,progwolff,rmlarsen,ebrevdo,rmlarsen,ebrevdo,progwolff,rmlarsen",2018-01-15 10:31:31,2018-02-15 01:16:57
PR,Refactoring by extracting duplicate code into methods,I extracted duplicate code into methods to improve maintainability,,"selcouthlyBlue,fchollet,selcouthlyBlue",2018-01-31 07:59:04,2018-02-15 01:24:08
IS,Is python 3 7 x supported with Tensorflow,Ive been trying to install Tensorflow on my computer which currently runs python 3 7 however I keep running into some common issues And each time i try to use the solutions provided nothing works Im not sure but Im guessing python 3 7 might not be supported considering the official Tensorflow page has no link to python 3 7 that maybe this is the reason I havent been able to correctly install Tensorflow,,shoyer,2018-02-15 00:00:58,2018-02-15 01:37:46
PR,Fix 16152,Please note that I have tested this fix only on Ubuntu 16 04 with python 3 5 It should in theory work for both python 2 and python 3 but I have not tested it on all major versions of python,,,2018-02-15 02:40:00,2018-02-15 02:55:29
PR,Make get placeholders accessible and add example,This is an improvement of PR 14541 This PR makes get placeholders visible in the document as tf contrib framework get placeholders and add example to the docstring x Make get placeholders accessible x Add example,,"qmick,yifeif,qmick,drpngx",2017-12-18 09:09:24,2018-02-15 03:00:38
IS,Importing graph with tf contrib resampler resampler fails,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 OSx High Sierra TensorFlow installed from source or binary pip install TensorFlow version use command below 1 5 0 Python version 3 5 4 CUDA cuDNN version CPU Bazel version if compiling from source N A GPU model and memory N A Exact command to reproduce See below Describe the problem Importing a graph def with a tf contrib resampler resampler op fails iff tf contrib is not imported first Execute,,,2018-02-13 15:16:08,2018-02-15 09:53:59
IS,TensorFlow compile from source with GPU support error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below master version or 1 6 0 Python version 3 5 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version 9 0 7 GPU model and memory NVIDIA Tesla K80 Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package action env LD LIBRARY PATH LD LIBRARY PATH Describe the problem I have tried to compile the master version from source I have added all the env variables been through stackoverflow and github issues nothing works I think it is a bug Source code logs ERROR home ubuntu work master tensorflow tensorflow contrib periodic resample BUILD 40 1 Linking of rule ' tensorflow contrib periodic resample gen gen periodic resample op py py wrappers cc' failed Exit 1 usr bin ld warning libcublas so 9 0 needed by bazel out host bin solib local U S Stensorflow Scontrib Speriodic Uresample Cgen Ugen Uperiodic Uresample Uop Upy Upy Uwrappers Ucc Utensorflow libtensorflow framework so not found try using rpath or rpath link usr bin ld warning libcudnn so 7 needed by bazel out host bin solib local U S Stensorflow Scontrib Speriodic Uresample Cgen Ugen Uperiodic Uresample Uop Upy Upy Uwrappers Ucc Utensorflow libtensorflow framework so not found try using rpath or rpath link usr bin ld warning libcurand so 9 0 needed by bazel out host bin solib local U S Stensorflow Scontrib Speriodic Uresample Cgen Ugen Uperiodic Uresample Uop Upy Upy Uwrappers Ucc Utensorflow libtensorflow framework so not found try using rpath or rpath link bazel out host bin solib local U S Stensorflow Scontrib Speriodic Uresample Cgen Ugen Uperiodic Uresample Uop Upy Upy Uwrappers Ucc Utensorflow libtensorflow framework so undefined reference to cublasGemmEx libcublas so 9 0' and a lot more going,,,2018-02-13 19:24:15,2018-02-15 12:41:38
IS,Feature request documentation operation complexity performance chart,Have I written custom code NA OS Platform and Distribution Any TensorFlow installed from NA TensorFlow version NA Bazel version NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA It would be interesting to have a complexity performance chart for different operations For example to know that tf reshape is computationally cheaper than tf transpose I did see the Performance Guide but that is not what I mean,,"drpngx,MarkDaoust",2018-01-10 03:08:58,2018-02-15 14:22:10
PR,Batch support for deterministic image ops,Based on 14854 and working on 8926 Previously I had implemented batch support for a number of image ops However performance concerns were raised and the changes were reverted I have re implemented the changes for flip left right flip up down transpose image rot90 I ran performance tests from with bazel run c opt tensorflow python image ops test benchmarks FlipImageBenchmark Operation Before s After s benchmarkFlipLeftRight 299 299 3 cpu 0 1 274 49 264 26 benchmarkFlipLeftRight 299 299 3 cpu 0 all 292 76 266 10 benchmarkFlipLeftRight 299 299 3 all 273 80 265 71 benchmarkRandomFlipLeftRight 299 299 3 cpu 0 1 242 58 241 89 benchmarkRandomFlipLeftRight 299 299 3 cpu 0 all 245 27 239 88 benchmarkRandomFlipLeftRight 299 299 3 all 252 71 241 20 There were no changes made to RandomFlipLeftRight in this PR Let me know if you would like me to add more performance tests for the other methods I do not think there should be any performance impact but I'm happy to add more if you would like,,"JoshVarty,JoshVarty,martinwicke,JoshVarty,rmlarsen,martinwicke,JoshVarty,martinwicke,JoshVarty",2017-12-30 06:18:40,2018-02-15 16:43:23
PR,change from deprecated version to a new version,,,"rmlarsen,martinwicke",2018-01-25 07:32:11,2018-02-15 17:37:07
PR,Docs fix r1 5,Docs Cherry pick Add blank lines after HTML blocks for compatibility with new markdown parser PiperOrigin RevId 185554969,,MarkDaoust,2018-02-15 11:59:55,2018-02-15 18:31:20
PR,Docs fix r1 6,Docs Cherry pick Add blank lines after HTML blocks for compatibility with new markdown parser Fix cuDNN64 dll name in windows install instructions PiperOrigin RevId 185554969,,MarkDaoust,2018-02-15 11:59:34,2018-02-15 18:31:50
PR,Indentation fix,,,martinwicke,2018-02-15 19:17:47,2018-02-15 20:07:27
PR,Updated roadmap,,,,2018-02-15 19:20:45,2018-02-15 20:25:16
PR,Branch 185878562,,,yifeif,2018-02-15 20:21:22,2018-02-15 21:16:22
PR,Update freeze graph py,If there are spaces in multiple parameters a parameter is not recognized ex hypothesis cost X hypothesis cost O So initializer nodes split initializer nodes replace ' ' '' split variable names whitelist split variable names whitelist replace ' ' '' split output node names split output node names replace ' ' '' split,,"drpngx,drpngx",2017-11-30 23:57:41,2018-02-15 21:52:12
PR,use gather nd to gather states in LSTMBlockWapper,no need for calculate mod indices and reshape data,,"drpngx,drpngx,drpngx,drpngx",2018-01-27 08:52:23,2018-02-15 21:55:48
IS,Bounding box do not remove,Hi there After I detected my tv it showed up but when i move it to other place it do not remove the bounding box even though i put my camera on the table Is this a bug 2018 01 28 00 34 50,,"drpngx,andrewharp,drpngx",2018-01-27 16:39:37,2018-02-15 23:20:35
PR,add visibility to tensorflow contrib tensor forest proto fertile stats proto,Since the proto is a public visible and TreePath depending on the proto Let is make it public,,"jhseu,jhseu",2018-01-30 03:04:18,2018-02-15 23:20:47
IS,why save model and deploy in android device the outputs are not the same as in ubuntu,OS Platform and Distribution Ubuntu 14 04 5 LTS Android 8 0 TensorFlow installed from source TensorFlow version 1 4 0 Python version 2 7 6 Bazel version 0 4 5 GCC Compiler version 4 8 4 CUDA cuDNN version 8 0 GPU model and memory GTX1080 8G Exact command to reproduce step 1 clone code from step 2 in the file src compare py add the follow code after line 90 after align detect face create mtcnn output node names 'pnet prob1' 'pnet conv4 2 BiasAdd' 'pnet conv1 BiasAdd' 'rnet prob1' 'rnet conv5 2 conv5 2' 'onet prob1' 'onet conv6 2 conv6 2' 'onet conv6 3 conv6 3' output graph def tf graph util convert variables to constants sess sess graph as graph def output node names sess graph def with tf gfile FastGFile mtcnn pb mode 'wb' as f f write output graph def SerializeToString step 3 run the command python src compare py data 20170512 110547 data images Anthony Hopkins 0001 jpg data images Anthony Hopkins 0002 jpg will create the model file mtcnn pb step 4 deploy the file mtcnn pb to android app validate with the file Anthony Hopkins 0001 jpg indeed it can fetch the results for the outputs such as 'pnet prob1' 'pnet conv4 2 BiasAdd' but the values are difference with the results from the facenet project run on ubuntu the query is what is the cause to the difference the way to create the mtcnn pb is wrong still need to optimize it to adapt android device or there is something wrong with Tensorflow for mobile device the follow is the log show the difference with the same input 00 28515625 0 24609375 0 59765625 but the output is difference Android output Line 5555 01 26 11 34 20 793 I lxr 22967 img00 28515625 0 24609375 0 59765625 Line 5795 01 26 11 34 21 326 I lxr 22967 mapWidth 70 mapHeight 70 Line 5796 01 26 11 34 21 327 I lxr 22967 outValue 0 9998832 1 16751995E 4 Line 5797 01 26 11 34 21 327 I lxr 22967 outReg 0 068167016 0 2052449 0 06884944 0 1512082 Ubuntu output img y 1 150 150 3 img y0 0 28515625 0 24609375 0 59765625 out0 shape 1 70 70 4 out1 shape 1 70 70 2 out0 0 07926445 0 20101449 0 06468102 0 16017048 out1 9 99792397e 01 2 07666759e 04,,"drpngx,drpngx",2018-01-26 05:50:11,2018-02-15 23:21:27
IS,Feature request tf nn dropout noise shape should support unspecified dimensions,It would be nice if the noise shape in tf nn dropout would support unspecified dimensions and just use the shape of the input tensor e g 1 or None This way it could be specified as noise shape 1 1 1 1 instead of noise shape k 1 1 n,,yongtang,2018-01-11 11:03:11,2018-02-15 23:21:28
PR,Add unspecified dimensions 1 support for noise shape with tf nn dropout,This fix tries to address the issue raised in 16034 where it was not possible to have unspecified dimensions for noise shape with tf nn dropout This fix adds the support so that it is possible to specify noise shape 1 1 1 1 instead of noise shape k 1 1 n This fix fixes 16034 Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,vrv,vrv,yongtang,yongtang,vrv,yongtang,vrv,vrv,yongtang,rmlarsen,vrv,yongtang,vrv,vrv,yongtang,vrv",2018-01-12 22:21:34,2018-02-15 23:21:28
PR,Adding the CMAKE GENERATOR line to all external cmake files,,,"av8ramit,gunan,mrry,martinwicke,av8ramit",2018-02-08 22:09:24,2018-02-15 23:30:17
PR,order quantized table by value for ease of reading,,,martinwicke,2018-01-02 15:11:05,2018-02-15 23:37:15
IS,tf QueueBase dequeue many returns list instead of tuple,The dequeue many operation returns a list of Tensors while the documentation states that it should be a tuple which is more sensible Returns The tuple of concatenated tensors that was dequeued Version 1 5 0 from PIP Python3 on OS X,,mrry,2018-02-12 12:55:49,2018-02-15 23:43:39
PR,Update data flow ops py,Fixes 16948,,,2018-02-12 22:04:43,2018-02-15 23:43:39
PR,Fix Intel compiler build break,Fix Intel compiler build break Windows 10 1709 Microsoft Visual Studio 2017 15 4 0 Intel Parallel Studio XE Cluster Edition for Windows 2018 Update 1,,"fo40225,jhseu,fo40225",2018-02-10 14:09:30,2018-02-16 00:00:47
PR,Tensorflow Lite demo app for Android add support for floating point models as Inception v3,Although the new Lite interface does support float models as well the current Android demo app does only support quantized models Furthermore it is not obvious to transfer the code from the quantized version to the floating point model Based on this discussion I integrated the Inception v3 slim model as an alternative to the existing MobileNet Remaining TODO The confidence scores returned by the inception net are not in 0 1 yet Besides that the inference itself seems to work So the correct results are listed on top but the confidence score is not normalized Maybe the given model does not include a Softmax layer and ends with the logits I'm not sure about this Any help is appreciated,,"Johnson145,Johnson145,freedomtan",2018-02-07 14:23:50,2018-02-16 00:04:12
PR,Added detailed discussion of non strict semantics,,,martinwicke,2018-02-09 14:19:47,2018-02-16 00:25:36
PR,Added a check for a macro to specify that an ARM device is not mobile,I have copied the existing mechanism for Raspberry Pi to allow other ARM platforms to be designated as not a mobile platform and thus get the full feature set,,yifeif,2017-11-18 13:02:58,2018-02-16 00:26:02
PR,fix that remove nodes drops input suffixes,The transform remove nodes did not take input suffixes into consideration and might make mistakes if the removed node used not 0 but 1 E g For a node of a Identity Identity a Switch 1 1 the old code will make the pb file generate completely unexpected outputs The clang format checking and tests tensorflow tools graph transforms have been passed,,,2017-12-14 14:07:53,2018-02-16 00:31:56
PR,MKL Fixing MklCPUAllocator error introduced by commit 1baac78,PR 16987 also fixes this problem Commit 1baac78 also broke,,claynerobison,2018-02-14 05:24:45,2018-02-16 00:39:32
PR,Fix raw summary metrics for Estimators in python 3,It looked for six string types in the metrics but should be six binary type since tf string returns a bytes object Also changes the test which missed this,,"borispf,martinwicke",2018-01-29 16:04:48,2018-02-16 01:19:53
PR,Export inception model after retrain,The are many issues and Stackoverflow posts asking how to export a retrained Inception model It would be nice if retrain py did this so that it is easier for newcomers to use Tensorflow Serving This PR exports the model after retrain is finished I have also added a comment on how to serve the retrained model Confirmed works for tensorflow version 1 4 1,,rmlarsen,2018-01-04 18:14:39,2018-02-16 01:20:20
PR,Move SpeechActivity animation to XML,Moved SpeechActivity animation to res animator color animation xml Specifying the animation in code is tougher to read and detracts from what is supposed to be a simple example of how to use TF in Android,,,2018-01-03 21:14:54,2018-02-16 01:20:36
IS,Feature request use padded batch with tf estimator export build parsing serving input receiver fn,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 6 TensorFlow installed from source or binary I forget TensorFlow version use command below 1 4 Python version 2 7 8 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem As far as I can tell tf estimator export build parsing serving input receiver fn does not allow you to control the way examples are batched So if I have an Estimator that I have trained by using Dataset padded batch in the input fn there does not seem to be a way for me to use that model with TensorFlow Serving Source code logs N A,,martinwicke,2018-02-01 02:33:34,2018-02-16 01:26:46
PR,Fix typos in low level introduction documentation,Remove extraneous comma Capitalize 'Loss' title Add missing space to 'minimize the',,,2018-02-16 00:59:18,2018-02-16 01:36:03
PR,Fix MKL build break on Windows,Eigen with MKL and MKL ML only no MKL DNN Windows 10 1709 Microsoft Visual Studio 2017 15 4 0 Intel Parallel Studio XE Cluster Edition for Windows 2018 Update 1 98 tests passed 7 tests failed out of 387 Total Test time real 4031 00 sec The following tests FAILED 40 C Users User Source Repos tensorflow tensorflow python debug lib session debug file test py Failed 42 C Users User Source Repos tensorflow tensorflow python debug lib stepper test py Failed 84 C Users User Source Repos tensorflow tensorflow python kernel tests conv ops test py OTHER FAULT 165 C Users User Source Repos tensorflow tensorflow python kernel tests matrix solve ls op test py Failed 182 C Users User Source Repos tensorflow tensorflow python kernel tests pooling ops test py OTHER FAULT 328 C Users User Source Repos tensorflow tensorflow contrib factorization python ops gmm ops test py Failed 353 C Users User Source Repos tensorflow tensorflow python keras impl keras layers convolutional recurrent test py Failed full build log and test log attached msbuild zip pytest zip,,fo40225,2018-02-15 16:29:50,2018-02-16 01:38:13
PR,fixed typo in docstring for unchanged shape method,,,,2018-02-15 13:52:30,2018-02-16 01:38:47
PR,conv1d doc string misnames first argument,The docs say conv2d is first argument is input which is maybe how the docstring for conv1d ended up saying input instead of value when describing the filters argument,,,2018-02-15 13:11:14,2018-02-16 01:39:23
IS,ImportError cannot import name pywrap dlopen global flags,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-16 11:37:45,2018-02-16 11:39:53
PR,fixup 1baac78627 Underlying allocator must be a VisitableAllocator too,Signed off by Sylvain Gault sylvain gault road b score com,,byronyi,2018-02-13 19:22:01,2018-02-16 11:50:41
IS,Get stuck in the process of building from sources,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 LTS TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 CPU Bazel version if compiling from source 5 0 Exact command to reproduce RUN tensorflow tools ci build builds configured CPU bazel build c opt cxxopt D GLIBCXX USE CXX11 ABI 0 tensorflow tools pip package build pip package bazel bin tensorflow tools pip package build pip package tmp pip pip no cache dir install upgrade tmp pip tensorflow whl Describe the problem I tried to build a docker image using the dockerfile provided by tensorflow repository but every time I faced with the problem it got stuck in the process repeating the output 2 615 3 437 Still waiting for 2 jobs to complete Running standalone Compiling tensorflow core kernels matrix solve ls op cc 851 s Compiling tensorflow core kernels svd op double cc 839 s 2 615 3 437 Still waiting for 2 jobs to complete The following is the first output of this layer which may be helpful Extracting Bazel installation You have bazel 0 5 0 installed Found possible Python library paths usr local lib python2 7 dist packages usr lib python2 7 dist packages Please input the desired Python library path to use Default is usr local lib python2 7 dist packages Using python library path usr local lib python2 7 dist packages No MKL support will be enabled for TensorFlow jemalloc enabled No VERBS support will be enabled for TensorFlow No OpenCL support will be enabled for TensorFlow MPI support will not be enabled for TensorFlow Configuration finished tensorflow INFO Reading istartup' options from etc bazel bazelrc batch TF BUILD INFO container type cpu command bazel build c opt cxxopt D GLIBCXX USE CXX11 ABI 0 tensorfl s pip package build pip package source HEAD b46340f40fe5e2ec9bfcd385b07cfb914055fb51 source remote origin github com tensorflow tensorflow git OS Linux kernel 4 9 41 moby architecture x86 64 processor 5550M APU with Radeon tm HD Graphics processor count 2 memory total 2027780 kB swap total 1048572 kB l version Build label 0 5 0 Java version 1 8 0 131 Python version 2 7 12 gpp version g Ubuntu 5 buntu1 16 04 5 5 4 0 20160609 swig version NVIDIA driver version CUDA device count 0 CUDA device CUDA toolkit version,,"reedwm,caisq,tatatodd,caisq",2017-09-15 19:48:45,2018-02-16 14:23:50
PR,Update guide md,Fixing grammatical errors in the Installation instructions,,,2018-02-16 12:12:57,2018-02-16 18:06:39
IS,OSError Errno 13 Permission denied TensorFlow could not install,Exception Traceback most recent call last File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip basecommand py line 215 in main status self run options args File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip commands install py line 342 in run prefix options prefix path File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip req req set py line 784 in install kwargs File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip req req install py line 1064 in move wheel files isolated self isolated File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip wheel py line 345 in move wheel files clobber source lib dir True File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip wheel py line 316 in clobber ensure dir destdir File Library Python 2 7 site packages pip 9 0 1 py2 7 egg pip utils init py line 83 in ensure dir os makedirs path File System Library Frameworks Python framework Versions 2 7 lib python2 7 os py line 157 in makedirs mkdir name mode OSError Errno 13 Permission denied ' Library Python 2 7 site packages pbr 3 1 1 dist info',,,2018-02-16 09:35:49,2018-02-16 18:29:47
PR,tensorflow lite add setUseNNAPI to the Interpreter class,add setUseNNAPI to the Interpreter class,,aselle,2018-01-08 09:30:18,2018-02-16 18:48:59
IS,imagenet distributed train using inception v3 stuck on saving check points forever,System information I ran nvidia smi and found the GPU was not working and same with other nodes The output of worker 1 15 just stucked on step 2400 and did not do any progress I tried this several time on new set of 16 machines but it all stucked on saving checkpoint forever problem at some time I guess it might be a bug in tensorflow Or does this caused network failure but it did not retrun any network failure error,,"rohan100jain,ispirmustafa,ispirmustafa",2017-08-07 22:46:08,2018-02-16 19:08:00
IS,DataLossError see above for traceback corrupted record at 12,I have a big problem I use the tfrecord file to import data for my tensorflow program But when the program run a period of time it displays the DataLossError System information OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from Anaconda TensorFlow version 1 3 0 Python version 2 7 13 CUDA cuDNN version 8 0 6 0 GPU model and memory Pascal TITAN X Describe the problem 2017 10 03 19 45 43 854601 W tensorflow core framework op kernel cc 1192 Data loss corrupted record at 12 Traceback most recent call last File east quad train backup py line 416 in module tf app run main main argv sys argv 0 unparsed File home t anaconda2 lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File east quad train backup py line 330 in main Training File east quad train backup py line 312 in Training feed dict learning rate lr File home t anaconda2 lib python2 7 site packages tensorflow python client session py line 895 in run run metadata ptr File home t anaconda2 lib python2 7 site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File home t anaconda2 lib python2 7 site packages tensorflow python client session py line 1321 in do run options run metadata File home t anaconda2 lib python2 7 site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl DataLossError corrupted record at 12 Node IteratorGetNext IteratorGetNext output shapes 512 512 3 128 128 9 output types DT UINT8 DT FLOAT device job localhost replica 0 task 0 cpu 0 Iterator Node gradients Tile grad Shape 23 HostRecv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 442 gradients Tile grad Shape tensor type DT INT32 device job localhost replica 0 task 0 gpu 0 Caused by op u'IteratorGetNext' defined at File east quad train backup py line 416 in module tf app run main main argv sys argv 0 unparsed File home t anaconda2 lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File east quad train backup py line 330 in main Training File east quad train backup py line 251 in Training batch image batch label iterator get next File home t anaconda2 lib python2 7 site packages tensorflow contrib data python ops dataset ops py line 304 in get next name name File home t anaconda2 lib python2 7 site packages tensorflow python ops gen dataset ops py line 379 in iterator get next output shapes output shapes name name File home t anaconda2 lib python2 7 site packages tensorflow python framework op def library py line 767 in apply op op def op def File home t anaconda2 lib python2 7 site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File home t anaconda2 lib python2 7 site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access DataLossError see above for traceback corrupted record at 12 Node IteratorGetNext IteratorGetNext output shapes 512 512 3 128 128 9 output types DT UINT8 DT FLOAT device job localhost replica 0 task 0 cpu 0 Iterator Node gradients Tile grad Shape 23 HostRecv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 442 gradients Tile grad Shape tensor type DT INT32 device job localhost replica 0 task 0 gpu 0 Thanks anyone to answer this question,,"reedwm,reedwm,reedwm,guillaumekln,reedwm,mrry,guillaumekln,mrry,tatatodd",2017-10-03 12:08:07,2018-02-16 19:09:07
IS,build android demo error,ERROR missing input file ' local jdk jre lib resources jar' ERROR home wangmeng cache bazel bazel wangmeng b0a6578298b02ab8f9d039326e51a46f external bazel tools tools android BUILD 104 1 tools android gen java lang extras jar missing input file ' local jdk jre lib resources jar' Target tensorflow examples android tensorflow demo failed to build Use verbose failures to see the command lines of failed build steps ERROR home wangmeng cache bazel bazel wangmeng b0a6578298b02ab8f9d039326e51a46f external bazel tools tools android BUILD 104 1 1 input file s do not exist INFO Elapsed time 22 408s Critical Path 0 03s FAILED Build did NOT complete successfully,,"asimshankar,asimshankar",2018-02-05 03:07:57,2018-02-16 19:23:34
PR,Merge branch 1 6 back to master,,,"gunan,jhseu,jhseu,av8ramit,av8ramit,av8ramit,av8ramit,gunan,av8ramit,av8ramit,gunan,drpngx,gunan,gunan",2018-02-15 21:57:33,2018-02-16 20:06:14
PR,Add clean dep to tf cc test,,,,2018-02-15 09:35:10,2018-02-16 20:55:51
PR,Add remove control dependencies graph transform,Add a graph transform that can be used to remove control dependencies from the tensorflow graph This can allow later passes such as strip unused nodes to do a better job,,"tadeegan,tadeegan,tadeegan,martinwicke,tadeegan",2018-01-29 23:42:45,2018-02-16 20:57:51
PR,Branch 186010810,,,yifeif,2018-02-16 18:50:05,2018-02-16 20:59:50
IS,DeprecationWarning The binary mode of fromstring is deprecated warning appears in some cases,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary tf nightly TensorFlow version use command below 1 7 0 dev20180214 git version b2a0f1c Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce This may not seem so bad but when running tf cnn benchmarks I get hundreds of such warnings What is very strange is that if I comment the line from tensorflow contrib image ops import gen distort image ops I do not get the warning This is the same issue as ppwwyyxx tensorpack 641 did you file a TensorFlow bug for this If so this can be marked as a duplicate Not really sure who to triage this to CC can you address this or retriage,,"reedwm,mrry,reedwm",2018-02-14 23:34:27,2018-02-16 21:00:25
IS,Get variable mapping dictionary after checkpoint restore,It is a feature request Please provide a way to get the list of Tensorflow variables restored from a checkpoint and corresponding Python variables More info Consider that you have this code,,"asimshankar,asimshankar",2018-02-16 12:50:26,2018-02-16 22:37:39
IS,tf cast can not cast string to number,OS Win10 64bit Tensorflow version 1 5 0 It looks like tf cast can not cast string to number but the documents does not explain it I found this problem when I migrated older versions of tensorflow code to a new version When I used tf cast to cast string to float I got error Unimplemented Cast string to float is not supported And when I used tf string to number instead of tf cast the problem was solved,,,2018-02-16 15:52:53,2018-02-17 03:29:54
PR,Use relative and correct path to find flatc and schema file,The path to schema file is wrong and path to flatc is only correct from the top directory The proposed change uses relative paths to the script file to find those two files which are more stable,,,2018-02-17 00:15:55,2018-02-17 05:35:03
IS,Feature request Add mode argument to discriminator function in tfgans GANEstimator,Can we add mode as an optional argument to the discriminator function in the tfgan GANEstimator This would allow the discriminator function to perform batch normalisation and dropout Posted this on stack overflow,,,2018-02-17 04:42:54,2018-02-17 05:57:29
PR,Fixes 16976,,,"byronyi,byronyi,aaroey,byronyi,aaroey,byronyi",2018-02-14 13:30:17,2018-02-17 08:01:22
IS,df982b8de Split gpu id h and GpuIdManager out from build target breaks build for verbs and GDR,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below TF not compiling master Python version 2 7 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 CUDA cuDNN version 9 1 GPU model and memory Any Exact command to reproduce 1 configure with GDR and or verbs 2 bazel build c opt config cuda tensorflow tools pip package build pip package Describe the problem Commit df982b8de breaks the build for GDR and verbs ERROR home eladw google tensorflow tensorflow contrib gdr BUILD 52 1 undeclared inclusion s in rule ' tensorflow contrib gdr gdr memory manager' this rule is missing dependency declarations for the following files included by 'tensorflow contrib gdr gdr memory manager cc' ' home eladw google tensorflow tensorflow core common runtime gpu gpu id h',,"byronyi,aaroey,aaroey",2018-02-13 09:10:01,2018-02-17 08:26:41
IS,Dataset API does not pass dimensionality information for its output tensor,SYSTEM INFO python version Python 2 7 12 tensorflow version 1 4 0 CUDA version 8 0 Ubuntu version Ubuntu 16 04 LTS UPDATE Please directly go to my third post which reproduces my issue with the minimum amount of code UPDATE FINISHED url My problem is very similar to the issue above but I did not find solution in that post I need the shape of the output tensor from dataset to be defined to feed into my graph Thanks,,facaiy,2018-02-16 07:09:31,2018-02-17 12:03:43
IS,TypeError can not pickle thread lock objects,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No using stock examples OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip TensorFlow version use command below 1 2 1 Python version 3 6 1 Anaconda 4 4 0 64 bit Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce I'm running the seq2seq example in models tutorials rnn translate verbatim You can collect some of this information using our environment capture script Collecting system information 2017 06 29 18 35 16 672194 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 06 29 18 35 16 672242 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 06 29 18 35 16 672250 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations Wrote environment to tf env txt You can review the contents of that file and use it to populate the fields in the github issue template cat tf env txt cat etc issue Linux GCRGDL171 4 8 0 58 generic 63 16 04 1 Ubuntu SMP Mon Jun 26 18 08 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux GCRGDL171 4 8 0 58 generic 63 16 04 1 Ubuntu SMP Mon Jun 26 18 08 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 12 1 numpydoc 0 6 0 protobuf 3 3 0 tensorflow 1 2 1 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda usr local cuda lib64 DYLD LIBRARY PATH is unset nvidia smi Thu Jun 29 18 35 19 2017 NVIDIA SMI 375 66 Driver Version 375 66 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Tesla K40m Off 0000 27 00 0 Off 0 N A 27C P8 21W 235W 0MiB 11439MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage No running processes found cuda libs usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I get exception TypeError can not pickle thread lock objects It happens on different machines with the same python version Just running your example code verbatim Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Traceback most recent call last File translate py line 322 in module tf app run File home t mabruc anaconda3 lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File translate py line 319 in main train File translate py line 178 in train model create model sess False File translate py line 136 in create model dtype dtype File home t mabruc models tutorials rnn translate seq2seq model py line 179 in init softmax loss function softmax loss function File home t mabruc anaconda3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 1206 in model with buckets decoder inputs bucket 1 File home t mabruc models tutorials rnn translate seq2seq model py line 178 in lambda lambda x y seq2seq f x y False File home t mabruc models tutorials rnn translate seq2seq model py line 142 in seq2seq f dtype dtype File home t mabruc anaconda3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 848 in embedding attention seq2seq encoder cell copy deepcopy cell File home t mabruc anaconda3 lib python3 6 copy py line 161 in deepcopy y copier memo File home t mabruc anaconda3 lib python3 6 site packages tensorflow python layers base py line 476 in deepcopy setattr result k copy deepcopy v memo File home t mabruc anaconda3 lib python3 6 copy py line 150 in deepcopy y copier x memo File home t mabruc anaconda3 lib python3 6 copy py line 215 in deepcopy list append deepcopy a memo File home t mabruc anaconda3 lib python3 6 copy py line 180 in deepcopy y reconstruct x memo rv File home t mabruc anaconda3 lib python3 6 copy py line 280 in reconstruct state deepcopy state memo File home t mabruc anaconda3 lib python3 6 copy py line 150 in deepcopy y copier x memo File home t mabruc anaconda3 lib python3 6 copy py line 240 in deepcopy dict y deepcopy key memo deepcopy value memo File home t mabruc anaconda3 lib python3 6 copy py line 180 in deepcopy y reconstruct x memo rv File home t mabruc anaconda3 lib python3 6 copy py line 280 in reconstruct state deepcopy state memo File home t mabruc anaconda3 lib python3 6 copy py line 150 in deepcopy y copier x memo File home t mabruc anaconda3 lib python3 6 copy py line 240 in deepcopy dict y deepcopy key memo deepcopy value memo File home t mabruc anaconda3 lib python3 6 copy py line 180 in deepcopy y reconstruct x memo rv File home t mabruc anaconda3 lib python3 6 copy py line 280 in reconstruct state deepcopy state memo File home t mabruc anaconda3 lib python3 6 copy py line 150 in deepcopy y copier x memo File home t mabruc anaconda3 lib python3 6 copy py line 240 in deepcopy dict y deepcopy key memo deepcopy value memo File home t mabruc anaconda3 lib python3 6 copy py line 180 in deepcopy y reconstruct x memo rv File home t mabruc anaconda3 lib python3 6 copy py line 280 in reconstruct state deepcopy state memo File home t mabruc anaconda3 lib python3 6 copy py line 150 in deepcopy y copier x memo File home t mabruc anaconda3 lib python3 6 copy py line 240 in deepcopy dict y deepcopy key memo deepcopy value memo File home t mabruc anaconda3 lib python3 6 copy py line 169 in deepcopy rv reductor 4 TypeError can not pickle thread lock objects,,"skye,nealwu,lukaszkaiser,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,tatatodd,ebrevdo",2017-06-30 01:38:11,2018-02-17 22:00:08
IS,Changing batch size changes output for float32 matmuls elementwise by 1e 8 at least on CPU,While developing a Hierarchical Attention Network we have discovered that changing the batch size of the input effects the output of dynamic RNNs while keeping everything else constant In other words feeding in 1 2 3 4 5 and 6 7 8 9 10 individually with batch size 1 will give a different result than feeding in 1 2 3 4 5 6 7 8 9 10 together with batch size 2 We are currently running Bidirectional Dynamic RNNs with GRUs on the CPU version of Tensorflow 1 2 While the change in output is small when a network has many layers of RNNs the differences become amplified In our case changing the batch size from 1 to 10 changes the network accuracy on our test set from 50 to 46 System information and shortened sample code below System information cat etc issue Linux pc93071 ornl gov 3 10 0 514 26 1 el7 x86 64 1 SMP Tue Jun 20 01 16 02 EDT 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 7 3 Maipo VERSION ID 7 3 REDHAT BUGZILLA PRODUCT VERSION 7 3 REDHAT SUPPORT PRODUCT VERSION 7 3 are we in docker No compiler c GCC 4 8 5 20150623 Red Hat 4 8 5 11 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux pc93071 ornl gov 3 10 0 514 26 1 el7 x86 64 1 SMP Tue Jun 20 01 16 02 EDT 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 numpydoc 0 6 0 protobuf 3 3 0 tensorflow 1 2 1 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs Source code logs,,"asimshankar,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-07-19 14:41:54,2018-02-17 22:02:26
IS,TF Lite example segmentation fault,System information OS Platform and Distribution Ubuntu 16 04 2 LTS TensorFlow installed from TensorFlow version last commit f66e9f92820804b7c2b4698147d07d5d2277c62f Bazel version Build label 0 8 1 non git CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build verbose failures config opt cxxopt std c 11 config monolithic tensorflow contrib lite examples label image label image label image compiler c Ubuntu Linaro 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 uname a Linux qds101 4 4 65 SMP PREEMPT Mon Sep 18 13 34 00 CDT 2017 aarch64 aarch64 aarch64 GNU Linux check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc1 1607 gbe4e5ef tf COMPILER VERSION v1 3 0 rc1 1607 gbe4e5ef Describe the problem I compile example label image nad when I run it I get segmentation fault Error comes from the following line in resize bilinear c called from label image c resize float interpreter typed tensor float input in image height image width image channels wanted height wanted width wanted channels s type ResizeBilinear GetTensorData float input GetTensorDims input GetTensorData int32 size GetTensorDims size GetTensorData float output GetTensorDims output params align corners because params is NULL I looked at code and i do not believe that this variable builtin data ever initialized in this case because resize is called not within graph Source code logs user qds101 ml tf lite tensorflow tensorflow contrib lite examples label image exec label image v 1 nnapi error unable to open library libneuralnetworks so Loaded model vgg16 conv1 opt tflite resolved reporter tensors size 6 nodes size 1 inputs 1 input 0 name Placeholder 0 Placeholder 602112 1 0 0 1 conv1 1 12845056 1 0 0 2 conv1 1 Conv2D bias 256 1 0 0 3 conv1 1 weights 6912 1 0 0 len 150666 width height channels 224 224 3 input 0 number of inputs 1 number of outputs 1 Interpreter has 6 tensors and 1 nodes Inputs 0 Outputs 1 Tensor 0 kTfLiteFloat32 kTfLiteArenaRw 602112 bytes 0 6 MB 1 224 224 3 Tensor 1 kTfLiteFloat32 kTfLiteArenaRw 12845056 bytes 12 2 MB 1 224 224 64 Tensor 2 kTfLiteFloat32 kTfLiteMmapRo 256 bytes 0 0 MB 64 Tensor 3 kTfLiteFloat32 kTfLiteMmapRo 6912 bytes 0 0 MB 64 3 3 3 Tensor 4 kTfLiteFloat32 kTfLiteArenaRw 5419008 bytes 5 2 MB 1 224 224 27 Tensor 5 kTfLiteFloat32 kTfLiteDynamic 6912 bytes 0 0 MB 27 64 Node 0 Operator Builtin Code 3 Inputs 0 3 2 Outputs 1 params nil my print Segmentation fault,,"freedomtan,jart",2018-02-17 06:51:31,2018-02-18 07:05:49
IS,Tensorflow 1 5 issue on ipython notebook,I recently upgrade tensorflow using the command py 3 6 m pip install upgrade tensorflow and after that why i run python on command prompt windows 10 tensorflow works like charm but when i open ipython notebook for python3 and try to import tensorflow i get this error NameError Traceback most recent call last ipython input 1 64156d691fe5 in module 1 import tensorflow as tf C ProgramData Anaconda3 lib site packages tensorflow init py in module 39 pylint disable undefined variable 40 del python 41 del core 42 pylint enable undefined variable NameError name 'core' is not defined,,jart,2018-02-18 06:50:54,2018-02-18 07:06:56
IS,tensorflow lite converter toco build error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64bit TensorFlow installed from source or binary binary TensorFlow version use command below tensorflow 1 5 0 Python version Python 2 7 3 6 Bazel version if compiling from source bazel 0 9 0 GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory No GPU model Describe the problem I try to build the toco that is tensorflow lite converter But I can not success to build please see below for the details Source code logs C tensorflow bazel build tensorflow contrib lite toco toco The following error message appears ERROR Skipping ' tensorflow contrib lite toco toco' error loading package 'tensorflow contrib lite toco' Encountered error while reading extension file 'protobuf bzl' no such package ' protobuf archive ' Traceback most recent call last File C tensorflow third party repo bzl line 88 apply patch ctx ctx attr patch file File C tensorflow third party repo bzl line 59 in apply patch execute and check ret code ctx cmd File C tensorflow third party repo bzl line 44 in execute and check ret code fail Non zero return code 1 when Non zero return code 3 when executing 'C tools msys64 usr bin bash exe c patch p1 d C users r3pc appdata local temp bazel r3pc x1e5egqw external protobuf archive i C tensorflow third party protobuf add noinlines patch' Stdout patching file src google protobuf compiler cpp cpp file cc Stderr Assertion failed hunk file patch 2 5 9 src patch c line 354 This application has requested the Runtime to terminate it in an unusual way Please contact the application is support team for more information WARNING Target pattern parsing failed ERROR error loading package 'tensorflow contrib lite toco' Encountered error while reading extension file 'protobuf bzl' no such package ' protobuf archive ' Traceback most recent call last File C tensorflow third party repo bzl line 88 apply patch ctx ctx attr patch file File C tensorflow third party repo bzl line 59 in apply patch execute and check ret code ctx cmd File C tensorflow third party repo bzl line 44 in execute and check ret code fail Non zero return code 1 when Non zero return code 3 when executing 'C tools msys64 usr bin bash exe c patch p1 d C users r3pc appdata local temp bazel r3pc x1e5egqw external protobuf archive i C tensorflow third party protobuf add noinlines patch' Stdout patching file src google protobuf compiler cpp cpp file cc Stderr Assertion failed hunk file patch 2 5 9 src patch c line 354 This application has requested the Runtime to terminate it in an unusual way Please contact the application is support team for more information INFO Elapsed time 27 852s FAILED Build did NOT complete successfully 0 packages loaded currently loading tensorflow contrib lite toco plus info The following message appears when I input like this in command line for test patch p1 d C users r3pc appdata local temp bazel r3pc x1e5egqw external protobuf archive i C tensorflow third party protobuf add noinlines patch patching file src google protobuf compiler cpp cpp file cc Assertion failed hunk file patch 2 5 9 src patch c line 354 This application has requested the Runtime to terminate it in an unusual way Please contact the application is support team for more information patch p1 d C users r3pc appdata local temp bazel r3pc x1e5egqw external protobuf archive i C tensorflow third party protobuf add noinlines patch binary patching file src google protobuf compiler cpp cpp file cc Hunk 1 succeeded at 750 with fuzz 1 offset 193 lines Hunk 2 succeeded at 825 offset 169 lines Hunk 3 succeeded at 906 with fuzz 2 offset 169 lines I do not know how to add binary option to script ref,,,2018-02-12 12:21:13,2018-02-18 11:09:25
PR,Updating layers md fixing typo,Fixing typo Changing 'ans calling' to 'and calling',,,2018-02-17 16:14:20,2018-02-18 14:44:13
PR,Add NumPy style warning when casting complex to float,,,"carlthome,carlthome,carlthome",2018-02-18 15:58:13,2018-02-18 15:59:17
IS,Typ it,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-18 09:20:25,2018-02-18 16:24:29
IS,Error while using cuda 9 1 libcublas so 8 0 cannot open shared object file No such file or directory,Hi I am having the import problem I installed cuda 9 1 and set the path as suggested Should i install cuda 8 0 for resolving this problem Issue tensorflow not supporting cuda version greater than 8 The error is import tensorflow Traceback most recent call last File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in from tensorflow python pywrap tensorflow internal import File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in pywrap tensorflow internal swig import helper File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home honeypot tensorflow lib python3 5 imp py line 242 in load module return load dynamic name filename file File home honeypot tensorflow lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File line 1 in File home honeypot tensorflow lib python3 5 site packages tensorflow init py line 24 in from tensorflow python import File home honeypot tensorflow lib python3 5 site packages tensorflow python init py line 49 in from tensorflow python import pywrap tensorflow File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 72 in raise ImportError msg ImportError Traceback most recent call last File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in from tensorflow python pywrap tensorflow internal import File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in pywrap tensorflow internal swig import helper File home honeypot tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home honeypot tensorflow lib python3 5 imp py line 242 in load module return load dynamic name filename file File home honeypot tensorflow lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime,,"drpngx,drpngx",2018-01-15 18:41:23,2018-02-18 19:30:17
PR,Fix typo,,,ManHyuk,2018-02-14 09:36:18,2018-02-18 19:33:26
IS,Row wise lookup table in Tensorflow,Currently I have a matrix in which each row is a lookup table Corresponding to it I have a coded matrix with the same number of rows as the lookup table e g LookupTable matrix size 100 32 CodedMatrix matrix size 100 1000 So the lookup table values match to the corresponding row of the coded matrix The code matrix contains numbers from 0 to 31 which have a corresponding value in the Lookup table for that specific row The final output of this should be DecodedMatrix matrix size 100 1000 In which each value of the row is replaced with it is corresponding lookup output Currently in numpy I use a for loop because at the end I sum up the decoded matrix along the row axis for the final output The code looks like this out sum C L for C L in zip CodedMatrix LookupTable which is a still inefficient But in Tensorflow I use nRows tf constant 100 name nRows n tf Variable tf constant 0 def cond n out return n nRows def body n out out out tf gather LookupTable m CodedMatrix m return n 1 out out tf while loop cond body n out 1 This execution takes a lot of time because each time a new tensor is created and using the loop is not very efficient Is there a way to do this without using while loop Does tf gather have any setup to do lookup like this Have I written custom code Yes OS Platform and Distribution Mac OS X High Sierra TensorFlow installed from Source TensorFlow version 1 5 0 rc0 Bazel version 0 5 4 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Provided aboce,,drpngx,2018-02-12 20:50:26,2018-02-18 19:58:06
IS,Ca not stop TF from printing probabilities,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using the tutorial code OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 0 Python version 3 6 4 CUDA cuDNN version GPU model and memory Exact command to reproduce python cnn mnist py You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I can not stop TF from printing the INFO tensorflow probabilities part where in the angle brackets is a list that spans for several hundred lines Trying to suppress the verbosity either does nothing or causes lines like INFO tensorflow loss 2 314889 step 2 to stop appearing as well Source code logs I used the source code from this page,,facaiy,2018-02-17 07:15:07,2018-02-18 20:41:19
PR,Added Deep Speech use,,,,2018-02-16 10:43:44,2018-02-19 02:21:38
IS,Feauture Request Multidimensional RNN,I would like to contribute a Multidimensional RNN feature in the contrib directory based on the implementation mentioned here issuecomment 194976468 Right now it is possible to implement various types of multidimensional RNNs by feeding in your data as time being one direction say x taking the output of the RNN transposing it and feeding it into a second RNN etc Alternatively feed your data its transpose into separate RNNs possibly with tied weights and depth concatenate the results And maybe feed the result into another RNN By any chance is it related to the main paper for it,,"selcouthlyBlue,selcouthlyBlue,drpngx,selcouthlyBlue,selcouthlyBlue",2018-02-09 01:19:17,2018-02-19 02:53:03
IS,Feature Request for the back propagated errors in intermediate layers,After the forward procedure one loss and one error were generated for the batch data Then according to the chain rule the error was back propagated to the previous layers to update the parameters in each layer Suppose I have the following network architecture I W1 C1 W2 C2 W3 O I is the input O is the output W1 W2 W3 is the weights for 3 layers C1 and C2 are the outputs for the first two layers With O and the ground truth we obtain the loss and the error which will be back propagated My question is In TensorFlow are there any methods to get the errors back propagated to C1 and C2 I know we could get the parameter operators as follows W1 op tf get default graph get tensor by name 'W1' W1 op My final purpose is to check if the errors are right in my network because I cannot check if the gradient in some certain layer a new user defined op of this network is computed correctly I want to check its gradient by checking the errors before and after this layer by viewing the errors and comparing the errors I know that we could use the tf test check gradient to do gradient check but it seems the output for gradient check of this new operator depends on the inputs In some cases the gradients check can be accepted i e the theoretical gradient and the numerical gradient are very close evaluated by a threshold value say 1e 3 but in some other cases the gradients check can fail which depends on the parameters of that op Thus I'm not sure if this is good or valid operator that is suitable for learning In the Caffe framework it seems those errors were saved in diff memory for each layer I want to get these back propagated errors in each layer Does anybody know how to get that,,,2018-02-19 06:22:19,2018-02-19 06:25:40
IS,fatal error cuda include cuda h No such file or directory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I followed the official documentation for custom operations OS Platform and Distribution e g Linux Ubuntu 16 04 which does not exist too This problem is not related to custom code it is related to ignore omitting files in commit 2c598e874e6a7b6b3185846ce9bac97a7d5d0169 As mention in 12860 this affects many people In fact the entire way of writing customs ops with CUDA seems to be broken Copying own source code to the TensorFlow repo was not necessary until TF1 3 Interestingly even recent NIPS paper implementations state in their readme they only support TFv1 2 I do not think the proposed workaround of downgrading to TFv1 2 should be the way to go,,"aselle,allenlavoie,gunan,gunan,gunan,gunan,gunan,gunan,gunan,av8ramit,av8ramit,gunan,martinwicke,gunan",2017-11-30 13:23:35,2018-02-19 08:36:19
IS,The method tf graph util remove training nodes is broken,On Windows 7 tensorflow 1 4 the following code tf graph util remove training nodes tf get default graph throws out the following error message File C Program Files Python3 lib site packages tensorflow python framework graph util impl py line 278 in remove training nodes input nodes input graph node AttributeError 'Graph' object has no attribute 'node',,,2018-02-17 03:15:12,2018-02-19 19:11:54
IS,Feature request make smart cond public API,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 24 g658866597 Python version 3 6 3 Bazel version if compiling from source CUDA cuDNN version None GPU model and memory None Exact command to reproduce None Describe the problem Currently tf cond does not work if predicate is a Python boolean As a result people frequently have to write conditional statements twice one with if statement and one with tf cond call There is a smart cond in tensorflow python layers utils py but it is not in the public API or searchable in documentation Petition to make it public or just integrate the smartness in tf cond altogether It is not a big change and will not impact backwards compatibility,,"drpngx,asimshankar",2017-10-22 15:04:55,2018-02-19 20:42:33
PR,make smart cond api public and reusable,Fix 13903 Move the implementation of smart cond and constant value from tensorflow python layers utils to tensorflow python ops control flow ops and add corresponding test and expose smart cond to tensorflow python ops standard ops should I implement the API in this way or not As I think ops should be lower level API than layers and smart cond should be a kind of ops It is my first time to contribute to TensorFlow Please feel free to correct me if there is any problem with the design and codes Tips I closed the former PR 13938 and create a new since there is some signature info problem with that PR,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,sguada,martinwicke,martinwicke,drpngx,drpngx,drpngx,drpngx,drpngx,martinwicke,martinwicke,martinwicke,drpngx,rmlarsen,sguada,martinwicke,martinwicke,drpngx",2017-10-24 19:07:15,2018-02-19 20:42:33
IS,Imagenet classification with VGG16 pretrained weights Keras interface doesnt seem to work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 0 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Described below in detail Describe the problem I tried to use VGG16 image net classifier which is given through keras interface in tensorflow tf keras applications VGG16 by grabbing the graph given by Keras and then using it But it does not seem to work I thought it might be issue with how I am using it but after thinking over it a lot I have concluded that this might an issue with Tensorflow I had posed about it on SO at Source code logs And below is the result I get when run Tensor input 1 0 shape 224 224 3 dtype float32 Tensor predictions Softmax 0 shape 1000 dtype float32 'n02281406' isulphur butterfly' 0 0022673723 'n01882714' 'koala' 0 0021256246 'n04325704' istole' 0 0020583202 'n01496331' 'electric ray' 0 0020416214 'n01797886' 'ruffed grouse' 0 0020229272 Clearly the classfication results are not the one expected Also If I dont run init op for global variable initializing I get an error Attempting to use uninitialized value block1 conv1 bias,,asimshankar,2018-02-19 05:56:03,2018-02-19 20:54:05
IS,MLP prediction is 3 4x slower than theano pytorch,Moving from keras team keras 9388 For a simple 2 hidden layer MLP TF is 3 4x slower than pytorch and theano This is only for prediction not training and it is only on CPU Please see this GitHub gist for timing For reproducibility the test was done on AWS EC2 c5 large Two different builds were tested and showed similar results One is the pre built AWS deep learning AMI ami e07e779a Another is installing conda on a fresh Ubuntu machine and then installing TF with pip My questions are 1 Is this performance difference expected I assume that TF should not be that slow 2 suggested that the TF installation was broken If so what is the correct way to install TensorFlow to ensure good performance I also tried other installation methods on the official docs as such native Python and pip but did not get better performance System information Have I written custom code Almost all built in functions OS Platform and Distribution Linux Ubuntu 16 04 Test env 1 AWS deep learning AMI Ubuntu Version ami e07e779a Test env 2 AWS base Ubuntu AMI ami 66506c1c TensorFlow installed from Test env 1 TensorFlow Keras PyTorch are all provided by that AMI Test env 2 Installed from binary i e pip install tensorflow and pip install keras PyTorch was installed by conda install pytorch TensorFlow version 1 5 0 Python version 3 6 Bazel version N A from binary CUDA cuDNN version CPU only GPU model and memory CPU only Exact command to reproduce Please follow this GitHub gist,,,2018-02-15 03:12:21,2018-02-19 20:56:33
PR,Update find cuda define to handle tabs,The 4 0 4 release of NvInfer h uses tabs between the version number and the comments this causes find cuda define to fail,,,2018-02-20 03:57:38,2018-02-20 03:59:28
IS,tf serving dependency optimizer Non existent input for node dynamic seq2seq decoder decoder GatherTree,I am trying to serve a tensorflow nmt model with tf serving I copied my SavedModel into the docker image and I'm serving it using bazel bin tensorflow serving model servers tensorflow model server port 9000 model name model test model base path serving SavedModel model test log Here the logs Did anyone experience this,,,2018-02-19 10:24:01,2018-02-20 08:08:23
IS,ImportError libcublas so 8 0 cannot open shared object file No such file or directory,I installed cuda 9 1 and set the path as suggested Should i install cuda 8 0 for resolving this problem Error ImportError Traceback most recent call last File opt conda lib python3 6 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File opt conda lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File opt conda lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File opt conda lib python3 6 imp py line 243 in load module return load dynamic name filename file File opt conda lib python3 6 imp py line 343 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory,,,2018-02-20 07:57:44,2018-02-20 12:02:15
IS,Can not create confusion matrix,This is my code for the network I am using tensorflow 1 4 and I am using my nvidia for training The code is working I want to create a confusion matrix and I do it like this with tf device ' device GPU 0' images tf placeholder tf float32 None IMAGE WIDTH IMAGE LENGTH 3 labels tf placeholder tf int64 None flat tf layers flatten labels logits tf layers dense flat len set train labels arr tf nn relu predicted labels tf argmax tf nn softmax logits 1 cross entropy tf nn sparse softmax cross entropy with logits logits logits labels labels loss tf reduce mean cross entropy optimizer tf train AdamOptimizer learning rate 0 001 minimize loss correct prediction tf equal predicted labels labels accuracy tf reduce mean tf cast correct prediction tf float32 init tf global variables initializer I want to create a confusion matrix and I do it like this confusion matrix tf confusion matrix labels labels predictions predicted labels num classes len set train labels arr dtype tf int64 When I call session tf Session session run init I got very weird error but if remove the line with the confusion matrix everything is ok InvalidArgumentError Cannot assign a device for operation 'confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available Node confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert Assert T DT STRING DT STRING DT STRING DT INT64 summarize 3 device device GPU 0 confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert Switch confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert data 0 confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert data 1 confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert data 2 confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert Switch 1 Caused by op u'confusion matrix 4 assert non negative assert less equal Assert AssertGuard Assert' defined at File usr lib python2 7 runpy py line 174 in run module as main main fname loader pkg name File usr lib python2 7 runpy py line 72 in run code exec code in run globals File home lachaka tensorflow lib python2 7 site packages ipykernel launcher py line 16 in module app launch new instance File home lachaka tensorflow local lib python2 7 site packages traitlets config application py line 658 in launch instance app start File home lachaka tensorflow local lib python2 7 site packages ipykernel kernelapp py line 478 in start self io loop start File home lachaka tensorflow local lib python2 7 site packages zmq eventloop ioloop py line 177 in start super ZMQIOLoop self start File home lachaka tensorflow local lib python2 7 site packages tornado ioloop py line 888 in start handler func fd obj events File home lachaka tensorflow local lib python2 7 site packages tornado stack context py line 277 in null wrapper return fn args kwargs File home lachaka tensorflow local lib python2 7 site packages zmq eventloop zmqstream py line 440 in handle events self handle recv File home lachaka tensorflow local lib python2 7 site packages zmq eventloop zmqstream py line 472 in handle recv self run callback callback msg File home lachaka tensorflow local lib python2 7 site packages zmq eventloop zmqstream py line 414 in run callback callback args kwargs File home lachaka tensorflow local lib python2 7 site packages tornado stack context py line 277 in null wrapper return fn args kwargs File home lachaka tensorflow local lib python2 7 site packages ipykernel kernelbase py line 283 in dispatcher return self dispatch shell stream msg File home lachaka tensorflow local lib python2 7 site packages ipykernel kernelbase py line 233 in dispatch shell handler stream idents msg File home lachaka tensorflow local lib python2 7 site packages ipykernel kernelbase py line 399 in execute request user expressions allow stdin File home lachaka tensorflow local lib python2 7 site packages ipykernel ipkernel py line 208 in do execute res shell run cell code store history store history silent silent File home lachaka tensorflow local lib python2 7 site packages ipykernel zmqshell py line 537 in run cell return super ZMQInteractiveShell self run cell args kwargs File home lachaka tensorflow local lib python2 7 site packages IPython core interactiveshell py line 2718 in run cell interactivity interactivity compiler compiler result result File home lachaka tensorflow local lib python2 7 site packages IPython core interactiveshell py line 2822 in run ast nodes if self run code code result File home lachaka tensorflow local lib python2 7 site packages IPython core interactiveshell py line 2882 in run code exec code obj self user global ns self user ns File ipython input 27 64238c75dfbf line 41 in module num classes len set train labels arr dtype tf int64 File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops confusion matrix py line 162 in confusion matrix labels message ' labels contains negative values' File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops check ops py line 237 in assert non negative return assert less equal zero x data data summarize summarize File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops check ops py line 443 in assert less equal return control flow ops Assert condition data summarize summarize File home lachaka tensorflow local lib python2 7 site packages tensorflow python util tf should use py line 107 in wrapped return add should use warning fn args kwargs File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops control flow ops py line 134 in Assert condition no op true assert name AssertGuard File home lachaka tensorflow local lib python2 7 site packages tensorflow python util deprecation py line 316 in new func return func args kwargs File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops control flow ops py line 1864 in cond orig res f res f context f BuildCondBranch false fn File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops control flow ops py line 1725 in BuildCondBranch original result fn File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops control flow ops py line 132 in true assert condition data summarize name Assert File home lachaka tensorflow local lib python2 7 site packages tensorflow python ops gen logging ops py line 47 in assert name name File home lachaka tensorflow local lib python2 7 site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File home lachaka tensorflow local lib python2 7 site packages tensorflow python framework ops py line 2956 in create op op def op def File home lachaka tensorflow local lib python2 7 site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access,,,2018-02-11 13:26:19,2018-02-20 12:29:17
IS,Wrong Bazel version check when building from source,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 Python version Python 2 7 6 Bazel version if compiling from source 0 10 1 GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version 8 0 7 0 GPU model and memory GeForce GTX 970 4GB VRAM Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem I am trying to build TensorFLow 1 5 with Bazel 0 10 1 from the Google apt repo The build immediately fails with a misleading error message Current Bazel version is 0 10 1 expected at least 0 5 4 because the build script is comparing strings instead of integers of the version numbers Backtrace,,"facaiy,facaiy,facaiy",2018-02-19 20:28:18,2018-02-20 14:28:11
IS,TensorFlow Installation Error on SLES 11 SP Linux,I have been trying to install tensorflow 1 3 0 1 4 1 4 1 on SLES 11 Linux I was getting GLIBC 2 14 not found an exception currently we have the GLIBC 2 11 3 version in SLES 11 SP3T Please help me to install any of tensorflow 0 8 versions on SLES 11 Linux and let me know the tensorflow compatible version for SLES 11 OR SLES 11 SP3 Linux is not compatible with TensorFlow any of the versions Thanks in Advance,,drpngx,2018-01-10 07:40:41,2018-02-20 14:33:54
IS,Build Android on Windows failed,System information Have I written custom code N A OS Platform Windows10 TensorFlow installed from source or binary pip TensorFlow version use command below 1 5 Python version 3 5 Bazel version if compiling from source N A GCC Compiler version if compiling from source 6 3 CUDA cuDNN version CUDA v9 1 GPU model and memory N A Exact command to reproduce N A Describe the problem I saw your instruction on url but I want to replace the model in the demo to my retrained model Is there anyone know how to do that If my description is not clear enough please tell me Thanks in advance Source code logs Error Execution failed for task ' buildNativeMake' A problem occurred starting process 'command 'tensorflow contrib makefile build all android sh'',,andrewharp,2018-02-17 12:50:35,2018-02-20 16:29:44
IS,Hello I am interested in collaborating with your project serving as a translator to Spanish since it is my native language I can translate any document in md,,,"drpngx,MarkDaoust,drpngx",2018-02-15 14:23:58,2018-02-20 16:37:29
PR,fix typo,,,dgboy2000,2018-02-20 01:23:39,2018-02-20 17:27:22
PR,Update to mobile intro documentation,I found a grammatical spelling error while reading this documentation,,,2018-02-19 22:35:10,2018-02-20 17:29:36
PR,Update convolutional py,Adding tf export decorators calls to TensorFlow functions and constants,,"gautam1858,carlthome,martinwicke,gautam1858,martinwicke,gautam1858,martinwicke,gautam1858",2018-02-19 07:25:15,2018-02-20 18:00:32
PR,Add clean dep to tf cc test,,,"martinwicke,gunan",2018-02-15 09:35:48,2018-02-20 18:09:02
IS,tensorflow 1 4 is 8 times slower than tensorflow 1 3 when read data,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary python wheel TensorFlow version use command below 1 4 and 1 3 Python version 3 6 1 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version None GPU model and memory None Exact command to reproduce when I run tensorflow1 4 script using estimator the script is 8 times slower than tensorflow 1 3 Source code logs main script,,"aselle,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa,mrry,ispirmustafa,jsimsa,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa",2017-11-28 14:01:08,2018-02-20 18:40:09
PR,Added custom loss logging frequency to estimator train,Fixes Added an optional parameter to log losses to tf estimator,,"martinwicke,xiejw,ispirmustafa",2018-02-19 01:35:33,2018-02-20 21:21:27
PR,Branch 186214551,Manually merged mostly formatting changes Conflicts RELEASE md configure py tensorflow contrib cmake external zlib cmake tensorflow contrib cmake python modules txt tensorflow contrib cmake tests cuda compatibility test c tensorflow contrib cmake tests cuda compatibility test cc tensorflow contrib data python ops dataset ops py tensorflow contrib gan python eval python summaries test py tensorflow contrib layers python layers layers py tensorflow contrib layers python layers layers test py tensorflow contrib tpu profiler pip package setup py tensorflow core public version h tensorflow docs src install install c md tensorflow docs src install install go md tensorflow docs src install install java md tensorflow docs src install install linux md tensorflow docs src install install mac md tensorflow docs src install install sources md tensorflow examples image retraining retrain py tensorflow python framework test util py tensorflow python keras impl keras layers lstm test py tensorflow python layers utils py tensorflow python ops bitwise ops test py tensorflow python ops distributions beta py tensorflow python ops image ops test py tensorflow python ops losses losses impl py tensorflow tools pip package setup py,,drpngx,2018-02-20 00:32:17,2018-02-20 21:33:42
IS,Distributed FIFOQueue with shared name is not shared,System information Environment Shared Cluster OS Platform and Distribution e g Linux Ubuntu 16 04 RHEL Server 7 2 TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below v1 5 0 0 g37aa430d84 1 5 0 Python version 3 6 CUDA cuDNN version 9 0 7 0 GPU model and memory N A GPU not allocated I am attempting to use a FIFOQueue to signal the parameter servers to shut down on a multi machine shared cluster based on this 40186129 example After some testing I believe that shared name simply does not seem to do anything even after removing the dequeue operations the number of elements in the FIFOQueue do not correlate to the number of workers Minimum Reproducible Code,,,2018-02-15 18:34:45,2018-02-20 21:48:03
IS,Windows installation page lists wrong cudnn version,The windows installation pages specifically asks to use cuDNN 6 link Then when running tensorflow it looks specifically for cuDNN7 build info cudnn dll name build info cudnn version number ImportError Could not find 'cudnn64 7 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Note that installing cuDNN is a separate step from installing CUDA and this DLL is often found in a different directory from the CUDA DLLs You may install the necessary DLL by downloading cuDNN 7 from this URL Would be great if the page modified this to specifically ask for cuDNN 7,,"asimshankar,gunan,MarkDaoust",2018-02-19 21:17:48,2018-02-20 22:20:18
IS,ERROR Unrecognized option python path,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below commit e5e03ef3148303b3dfed89a1492dedf92b45be25 HEAD master origin master origin HEAD Python version Python 2 7 13 Bazel version if compiling from source 0 10 1 GCC Compiler version if compiling from source 4 2 1 CUDA cuDNN version GPU model and memory Exact command to reproduce see log Describe the problem TF failed to build from source When building from source Bazel does not recognize python path set during configure Please see the log below Source code logs C02PK120FVH6 tensorflow neitan01 configure WARNING current bazel installation is not a release version Make sure you are running at least bazel 0 5 4 Please specify the location of python Default is usr local opt python bin python2 7 Found possible Python library paths usr local Cellar python 2 7 13 Frameworks Python framework Versions 2 7 lib python2 7 site packages Please input the desired Python library path to use Default is usr local Cellar python 2 7 13 Frameworks Python framework Versions 2 7 lib python2 7 site packages Do you wish to build TensorFlow with Google Cloud Platform support Y n y Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support Y n n No Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with Amazon S3 File System support Y n n No Amazon S3 File System support will be enabled for TensorFlow Do you wish to build TensorFlow with Apache Kafka Platform support y N n No Apache Kafka Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with XLA JIT support y N y XLA JIT support will be enabled for TensorFlow Do you wish to build TensorFlow with GDR support y N y GDR support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N y VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL SYCL support y N n No OpenCL SYCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N n No CUDA support will be enabled for TensorFlow Do you wish to build TensorFlow with MPI support y N n No MPI support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Would you like to interactively configure WORKSPACE for Android builds y N n Not configuring the WORKSPACE for Android builds Preconfigured Bazel build configs You can use any of the below by adding config to your build command See tools bazel rc for more details config mkl Build with MKL support config monolithic Config for mostly static monolithic build Configuration finished C02PK120FVH6 tensorflow neitan01 bazel build c opt copt mavx copt mavx2 copt mfma copt msse4 1 copt msse4 2 k tensorflow tools pip package build pip package Killed non responsive server process pid 1017 INFO Options provided by the client Inherited 'common' options isatty 1 terminal columns 181 INFO Reading options for 'build' from Users neitan01 src tensorflow tools bazel rc 'build' options define framework shared object true define use fast cpp protos true define allow oversize protos true define grpc no ares true spawn strategy standalone genrule strategy standalone c opt INFO Reading options for 'build' from Users neitan01 src tensorflow tf configure bazelrc 'build' options action env PYTHON BIN PATH usr local opt python bin python2 7 action env PYTHON LIB PATH usr local Cellar python 2 7 13 Frameworks Python framework Versions 2 7 lib python2 7 site packages force python py2 host force python py2 python path usr local opt python bin python2 7 define with gcp support true define with xla support true define with gdr support true define with verbs support true action env TF NEED OPENCL SYCL 0 action env TF NEED CUDA 0 define grpc no ares true copt DGEMMLOWP ALLOW SLOW SCALAR FALLBACK host copt DGEMMLOWP ALLOW SLOW SCALAR FALLBACK ERROR Unrecognized option python path usr local opt python bin python2 7 C02PK120FVH6 tensorflow neitan01 bazel build config opt tensorflow tools pip package build pip package INFO Options provided by the client Inherited 'common' options isatty 1 terminal columns 181 INFO Reading options for 'build' from Users neitan01 src tensorflow tools bazel rc 'build' options define framework shared object true define use fast cpp protos true define allow oversize protos true define grpc no ares true spawn strategy standalone genrule strategy standalone c opt INFO Reading options for 'build' from Users neitan01 src tensorflow tf configure bazelrc 'build' options action env PYTHON BIN PATH usr local opt python bin python2 7 action env PYTHON LIB PATH usr local Cellar python 2 7 13 Frameworks Python framework Versions 2 7 lib python2 7 site packages force python py2 host force python py2 python path usr local opt python bin python2 7 define with gcp support true define with xla support true define with gdr support true define with verbs support true action env TF NEED OPENCL SYCL 0 action env TF NEED CUDA 0 define grpc no ares true copt DGEMMLOWP ALLOW SLOW SCALAR FALLBACK host copt DGEMMLOWP ALLOW SLOW SCALAR FALLBACK ERROR Unrecognized option python path usr local opt python bin python2 7 C02PK120FVH6 tensorflow neitan01 bazel version Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Thu Jan 01 00 00 00 1970 0 Build timestamp Thu Jan 01 00 00 00 1970 0 Build timestamp as int 0 C02PK120FVH6 tensorflow neitan01 brew info bazel bazel stable 0 10 1 bottled Google is own build tool usr local Cellar bazel 0 5 1 10 files 138 0MB Poured from bottle on 2017 06 16 at 16 45 38 usr local Cellar bazel 0 10 1 12 files 93 4MB Poured from bottle on 2018 02 15 at 23 19 51 From Requirements Required java 1 8 macOS 10 10 Caveats Bash completion has been installed to usr local etc bash completion d zsh completions have been installed to usr local share zsh site functions,,,2018-02-20 12:33:28,2018-02-21 01:01:32
IS,Version 1 4 0 Ca not enable peer access between some devices,If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 RHEL 7 3 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version 3 4 5 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 3 0 CUDA cuDNN version CUDA 9 0 175 cuDNN 7 0 GPU model and memory 10 x GeForce GTX 1080 Ti 12 GB Exact command to reproduce Describe the problem System has 10 GPUs on one pci root hub but Tensorflow can not enable peer access to all devices Nvidia CUDA Example 1 Utilities p2pBandwidthLatencyTest is able to enable these Source code logs Tensorflow output 2017 11 21 13 58 12 914211 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 04 00 0 totalMemory 10 91GiB freeMemory 10 72GiB 2017 11 21 13 58 13 249428 I tensorflow core common runtime gpu gpu device cc 1030 Found device 1 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 05 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 13 574464 I tensorflow core common runtime gpu gpu device cc 1030 Found device 2 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 06 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 13 899631 I tensorflow core common runtime gpu gpu device cc 1030 Found device 3 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 07 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 14 219023 I tensorflow core common runtime gpu gpu device cc 1030 Found device 4 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 08 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 14 553864 I tensorflow core common runtime gpu gpu device cc 1030 Found device 5 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 0b 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 14 888727 I tensorflow core common runtime gpu gpu device cc 1030 Found device 6 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 0c 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 15 208341 I tensorflow core common runtime gpu gpu device cc 1030 Found device 7 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 0d 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 15 524748 I tensorflow core common runtime gpu gpu device cc 1030 Found device 8 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 0e 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 15 831437 I tensorflow core common runtime gpu gpu device cc 1030 Found device 9 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 582 pciBusID 0000 0f 00 0 totalMemory 10 91GiB freeMemory 10 74GiB 2017 11 21 13 58 15 837982 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 0 and 9 2017 11 21 13 58 15 843596 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 1 and 9 2017 11 21 13 58 15 848661 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 2 and 9 2017 11 21 13 58 15 852889 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 3 and 9 2017 11 21 13 58 15 856213 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 4 and 9 2017 11 21 13 58 15 858748 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 5 and 9 2017 11 21 13 58 15 860537 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 6 and 9 2017 11 21 13 58 15 861548 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 7 and 9 2017 11 21 13 58 15 861791 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 8 and 9 2017 11 21 13 58 15 861915 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 0 2017 11 21 13 58 15 862038 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 1 2017 11 21 13 58 15 862161 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 2 2017 11 21 13 58 15 862283 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 3 2017 11 21 13 58 15 862405 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 4 2017 11 21 13 58 15 862523 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 5 2017 11 21 13 58 15 862642 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 6 2017 11 21 13 58 15 862759 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 7 2017 11 21 13 58 15 862878 W tensorflow core common runtime gpu gpu device cc 918 Unable to enable peer access between device ordinals 9 and 8 2017 11 21 13 54 16 736201 I tensorflow core common runtime gpu gpu device cc 1045 Device peer to peer matrix 2017 11 21 13 54 16 736590 I tensorflow core common runtime gpu gpu device cc 1051 DMA 0 1 2 3 4 5 6 7 8 9 2017 11 21 13 54 16 736598 I tensorflow core common runtime gpu gpu device cc 1061 0 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736602 I tensorflow core common runtime gpu gpu device cc 1061 1 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736606 I tensorflow core common runtime gpu gpu device cc 1061 2 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736610 I tensorflow core common runtime gpu gpu device cc 1061 3 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736613 I tensorflow core common runtime gpu gpu device cc 1061 4 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736617 I tensorflow core common runtime gpu gpu device cc 1061 5 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736621 I tensorflow core common runtime gpu gpu device cc 1061 6 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736625 I tensorflow core common runtime gpu gpu device cc 1061 7 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736629 I tensorflow core common runtime gpu gpu device cc 1061 8 Y Y Y Y Y Y Y Y Y Y 2017 11 21 13 54 16 736633 I tensorflow core common runtime gpu gpu device cc 1061 9 Y Y Y Y Y Y Y Y Y Y Nvidia CUDA P2P Output P2P Peer to Peer GPU Bandwidth Latency Test Device 0 GeForce GTX 1080 Ti pciBusID 4 pciDeviceID 0 pciDomainID 0 Device 1 GeForce GTX 1080 Ti pciBusID 5 pciDeviceID 0 pciDomainID 0 Device 2 GeForce GTX 1080 Ti pciBusID 6 pciDeviceID 0 pciDomainID 0 Device 3 GeForce GTX 1080 Ti pciBusID 7 pciDeviceID 0 pciDomainID 0 Device 4 GeForce GTX 1080 Ti pciBusID 8 pciDeviceID 0 pciDomainID 0 Device 5 GeForce GTX 1080 Ti pciBusID b pciDeviceID 0 pciDomainID 0 Device 6 GeForce GTX 1080 Ti pciBusID c pciDeviceID 0 pciDomainID 0 Device 7 GeForce GTX 1080 Ti pciBusID d pciDeviceID 0 pciDomainID 0 Device 8 GeForce GTX 1080 Ti pciBusID e pciDeviceID 0 pciDomainID 0 Device 9 GeForce GTX 1080 Ti pciBusID f pciDeviceID 0 pciDomainID 0 Device 0 CAN Access Peer Device 1 Device 0 CAN Access Peer Device 2 Device 0 CAN Access Peer Device 3 Device 0 CAN Access Peer Device 4 Device 0 CAN Access Peer Device 5 Device 0 CAN Access Peer Device 6 Device 0 CAN Access Peer Device 7 Device 0 CAN Access Peer Device 8 Device 0 CAN Access Peer Device 9 Device 1 CAN Access Peer Device 0 Device 1 CAN Access Peer Device 2 Device 1 CAN Access Peer Device 3 Device 1 CAN Access Peer Device 4 Device 1 CAN Access Peer Device 5 Device 1 CAN Access Peer Device 6 Device 1 CAN Access Peer Device 7 Device 1 CAN Access Peer Device 8 Device 1 CAN Access Peer Device 9 Device 2 CAN Access Peer Device 0 Device 2 CAN Access Peer Device 1 Device 2 CAN Access Peer Device 3 Device 2 CAN Access Peer Device 4 Device 2 CAN Access Peer Device 5 Device 2 CAN Access Peer Device 6 Device 2 CAN Access Peer Device 7 Device 2 CAN Access Peer Device 8 Device 2 CAN Access Peer Device 9 Device 3 CAN Access Peer Device 0 Device 3 CAN Access Peer Device 1 Device 3 CAN Access Peer Device 2 Device 3 CAN Access Peer Device 4 Device 3 CAN Access Peer Device 5 Device 3 CAN Access Peer Device 6 Device 3 CAN Access Peer Device 7 Device 3 CAN Access Peer Device 8 Device 3 CAN Access Peer Device 9 Device 4 CAN Access Peer Device 0 Device 4 CAN Access Peer Device 1 Device 4 CAN Access Peer Device 2 Device 4 CAN Access Peer Device 3 Device 4 CAN Access Peer Device 5 Device 4 CAN Access Peer Device 6 Device 4 CAN Access Peer Device 7 Device 4 CAN Access Peer Device 8 Device 4 CAN Access Peer Device 9 Device 5 CAN Access Peer Device 0 Device 5 CAN Access Peer Device 1 Device 5 CAN Access Peer Device 2 Device 5 CAN Access Peer Device 3 Device 5 CAN Access Peer Device 4 Device 5 CAN Access Peer Device 6 Device 5 CAN Access Peer Device 7 Device 5 CAN Access Peer Device 8 Device 5 CAN Access Peer Device 9 Device 6 CAN Access Peer Device 0 Device 6 CAN Access Peer Device 1 Device 6 CAN Access Peer Device 2 Device 6 CAN Access Peer Device 3 Device 6 CAN Access Peer Device 4 Device 6 CAN Access Peer Device 5 Device 6 CAN Access Peer Device 7 Device 6 CAN Access Peer Device 8 Device 6 CAN Access Peer Device 9 Device 7 CAN Access Peer Device 0 Device 7 CAN Access Peer Device 1 Device 7 CAN Access Peer Device 2 Device 7 CAN Access Peer Device 3 Device 7 CAN Access Peer Device 4 Device 7 CAN Access Peer Device 5 Device 7 CAN Access Peer Device 6 Device 7 CAN Access Peer Device 8 Device 7 CAN Access Peer Device 9 Device 8 CAN Access Peer Device 0 Device 8 CAN Access Peer Device 1 Device 8 CAN Access Peer Device 2 Device 8 CAN Access Peer Device 3 Device 8 CAN Access Peer Device 4 Device 8 CAN Access Peer Device 5 Device 8 CAN Access Peer Device 6 Device 8 CAN Access Peer Device 7 Device 8 CAN Access Peer Device 9 Device 9 CAN Access Peer Device 0 Device 9 CAN Access Peer Device 1 Device 9 CAN Access Peer Device 2 Device 9 CAN Access Peer Device 3 Device 9 CAN Access Peer Device 4 Device 9 CAN Access Peer Device 5 Device 9 CAN Access Peer Device 6 Device 9 CAN Access Peer Device 7 Device 9 CAN Access Peer Device 8 Any idea how i can fix it,,"tatatodd,zheng-xq,tatatodd",2017-11-21 13:03:10,2018-02-21 02:18:40
PR,Do not add host copt march native on Power PC,,,"case540,case540",2018-02-20 23:49:05,2018-02-21 04:45:34
IS,tensorflow contrib lite examples label image,Build it for desktop machines tested on Ubuntu and OS X bazel build config opt cxxopt std c 11 tensorflow contrib lite examples label image label image I am not able to build the this example on my Ubuntu 16 04 Intel Desktop using the command above Using TF 1 5 and the error is related to NEON Can I run tflite models on Desktop ERROR home ashish tensorflow 1 5 tensorflow contrib lite examples label image BUILD 15 1 Linking of rule ' tensorflow contrib lite examples label image label image' failed Exit 1 bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils MatrixBatchVectorMultiplyAccumulate float const int int float const int float int error undefined reference to 'tflite tensor utils NeonMatrixBatchVectorMultiplyAccumulate float const int int float const int float int ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils VectorVectorCwiseProduct float const float const int float error undefined reference to 'tflite tensor utils NeonVectorVectorCwiseProduct float const float const int float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils VectorVectorCwiseProductAccumulate float const float const int float error undefined reference to 'tflite tensor utils NeonVectorVectorCwiseProductAccumulate float const float const int float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils VectorBatchVectorCwiseProductAccumulate float const int float const int float error undefined reference to 'tflite tensor utils NeonVectorBatchVectorCwiseProductAccumulate float const int float const int float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils BatchVectorBatchVectorDotProduct float const float const int int float int error undefined reference to 'tflite tensor utils NeonBatchVectorBatchVectorDotProduct float const float const int int float int ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils Sub1Vector float const int float error undefined reference to 'tflite tensor utils NeonSub1Vector float const int float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils ClipVector float const int float float error undefined reference to 'tflite tensor utils NeonClipVector float const int float float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils VectorShiftLeft float int float error undefined reference to 'tflite tensor utils NeonVectorShiftLeft float int float ' bazel out k8 opt bin tensorflow contrib lite kernels internal objs tensor utils tensorflow contrib lite kernels internal tensor utils o tensor utils cc function tflite tensor utils ReductionSumVector float const float int int error undefined reference to 'tflite tensor utils NeonReductionSumVector float const float int int ' collect2 error ld returned 1 exit status Target tensorflow contrib lite examples label image label image failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 194 676s Critical Path 14 43s FAILED Build did NOT complete successfully,,,2018-02-20 07:05:04,2018-02-21 05:22:40
PR,Cleaner documentation for tf confusion matrix,Also use tf stack with axis 1 instead of a stack transpose,,chrisyeh96,2018-02-19 11:57:22,2018-02-21 06:58:19
PR,Add missing override',This fixes a warning produced by clang pre tensorflow contrib tensor forest kernels v4 grow stats h 470 8 warning 'InitLeafClassStats' overrides a member function but is not marked 'override' Winconsistent missing override void InitLeafClassStats int best split index LeafStat left stats tensorflow contrib tensor forest kernels v4 grow stats h 190 16 note overridden virtual function is here virtual void InitLeafClassStats int best split index LeafStat left stats pre,,dtrebbien,2018-02-19 01:50:58,2018-02-21 06:59:51
IS,custom matrix multiplication,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-21 11:00:10,2018-02-21 11:01:01
IS,tf nn sparse softmax cross entropy with logits get error ValueError Rank mismatch Rank of labels received 1 should equal rank of logits minus 1 received 4,,,,2018-01-24 01:20:52,2018-02-21 11:55:24
IS,Tensorflow AOT examples fail to compile,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 3 0 rc1 5779 g441571a' '1 4 0' Python version 2 7 12 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source GCC 5 4 0 CUDA cuDNN version CUDA 8 0 CUDNN 6 0 21 GPU model and memory GeForce GTX 1080 8GB Exact command to reproduce cd tensorflow compiler aot tests bazel clean bazel build all tests gcc5 log Describe the problem I am trying to compile AOT examples but the compilation fails I tried to use two different compiler versions GCC 5 4 and GCC 4 8 but I get errors with both versions I also tried adding cxxopt D GLIBCXX USE CXX11 ABI 0 option when using bazel with GCC 5 4 but it does not help So the exact commands commands were bazel build all tests gcc5 log bazel build cxxopt D GLIBCXX USE CXX11 ABI 0 all tests gcc5 abi0 log bazel build all tests Using GCC 4 8 I copied the output manually to gcc 4 8 txt Tensorflow source code itself was build without any problems both with GCC 5 4 and GCC 4 8 I have built the two versions in separate python virtual environments and afterwards tried to compile aot tests with the corresponding GCC version I used cxxopt D GLIBCXX USE CXX11 ABI 0 option when building tensorflow source with GCC 5 4 Source code logs The logs are attached gcc5 log gcc5 abi0 log gcc 4 8 txt,,"sanjoy,sanjoy,sanjoy,sanjoy,sanjoy,sanjoy,sanjoy",2017-12-13 12:57:06,2018-02-21 11:59:35
PR,Remove extraneous check for Eager mode,The check is already made once at the start of the method,,chrisyeh96,2018-02-19 10:53:04,2018-02-21 13:27:18
IS,TensorBoard Projector has been blocked by CORS policy No 'Access Control Allow Origin',At website error System information Have I written custom code no OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 13 3 Safari Version 11 0 3 13604 5 6 Chrome Version 63 0 3239 132 Official Build 64 bit TensorFlow installed from source or binary no I am trying to publish my data over official projector tensorflow org website 1 Prepared config data metadata 2 Hosted them on Gist google storage my own website With and without https 3 Trying to view on projector Published config Receive error Failed to load cut Redirect from ' cut ' to ' cut ' has been blocked by CORS policy No 'Access Control Allow Origin' header is present on the requested resource Origin '' is therefore not allowed access error screen There is way to launch chrome with disable web security key but that ruins idea to share data in public,,"dsmilkov,dsmilkov",2018-02-05 11:46:31,2018-02-21 14:27:55
PR,MKL Updating performance guide with MKL info,Updating documentation wrt MKL,,"claynerobison,claynerobison,claynerobison",2018-02-17 00:23:34,2018-02-21 16:50:03
IS,Error in tfe implicit gradients loss in eager mode,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below 1 5 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source 7 2 0 CUDA cuDNN version GPU model and memory Exact command to reproduce I was trying to run MNIST model in Eager mode on Kaggle Kernels but as I am passing data to my model the optimizer is throwing this particular error ValueError No trainable variables were accessed while the function was being computed I can confirm that the data being passed to the model are non zero and are in the correct shape I do not understand why is the model is throwing the error then Here is my code python import tensorflow as tf import tensorflow contrib eager as tfe tfe enable eager execution class MNIST object def init self data format Set the input shape according to the availability of GPU if data format 'channels first' self input shape 1 1 28 28 else self input shape 1 28 28 1 self conv1 tf layers Conv2D 32 3 activation tf nn relu padding isame' data format data format self maxpool tf layers MaxPooling2D 2 2 2 2 padding isame' data format data format self conv2 tf layers Conv2D 64 3 activation tf nn relu padding isame' data format data format self dense1 tf layers Dense 1024 activation tf nn relu self dropout tf layers Dropout 0 5 self dense2 tf layers Dense 10 def predict self inputs x tf reshape inputs self input shape x self conv1 x x self maxpool x x self conv2 x x self maxpool x x tf layers flatten x x self dense1 x x self dropout x enable at training and disable at testing x self dense2 x return x Define loss functions def loss model inputs targets return tf reduce mean tf nn softmax cross entropy with logits logits model predict inputs labels targets Calculate accuracy def compute accuracy predictions labels model pred tf argmax predictions axis 1 output type tf int64 actual labels tf argmax labels axis 1 output type tf int64 return tf reduce sum tf cast tf equal model pred actual labels dtype tf float32 float predictions shape 0 value device gpu 0 if tfe num gpus else cpu 0 model MNIST 'channels first' if tfe num gpus else 'channels last' optimizer tf train AdamOptimizer learning rate 1e 4 grad tfe implicit gradients loss batch size 8 train batches len X train batch size valid batches len X valid batch size nb epochs 5 for i in range nb epochs with tf device device for j in range train batches inputs targets next train data gen optimizer apply gradients grad model inputs targets if j 10 0 print Step d Loss on training set f i loss model inputs targets numpy,,"asimshankar,asimshankar,asimshankar",2018-02-14 18:33:28,2018-02-21 16:55:08
IS,cifar 10 can not be downloaded,Hi I am trying to follow the tutorial from the source code of tensor flow model tutorials cifar10 In the cifar10 py the link DATA URL ' kriz cifar 10 binary tar gz' does not work I guess it is the problem from Canada Do you have a solution for this Thanks,,,2018-02-21 10:56:50,2018-02-21 17:24:50
IS,Bazel does not use the optimization flag specified in configuration,Hi I was compiling TensorFlow on a PowerPC machine and it kept failing with the error unrecognized command line option march native when compiling the file pcre byte order c This happened even though I specified the default flag mcpu native when running configure I also used the cxxopt mcpu native flag to no avail and the only way to solve the problem was to remove the config opt flag when invoking bazel,,"gunan,case540,gunan,gunan",2018-02-20 16:47:56,2018-02-21 18:33:01
IS,ImportError usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal so undefined symbol Py FalseStruct,I update my tensorflow to 1 5 the last version is 1 3 0 But I got a issue about numpy after lot of attempts it was solved numpy can be used But now I have a new issue when I import tensorflow Traceback most recent call last File stdin line 1 in module File usr local lib python2 7 dist packages tensorflow init py line 24 in module from tensorflow python import File usr local lib python2 7 dist packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal so undefined symbol Py FalseStruct Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help I can not get any solutions on the Internet Anyone can help me,,"martinwicke,martinwicke",2018-02-03 03:43:17,2018-02-21 20:16:49
PR,Fix table format in SECURITY md,,,MarkDaoust,2018-02-21 18:21:37,2018-02-21 20:17:23
IS,Change RELEASE md to specify CUDA version,The RELEASE md states that Prebuilt binaries are now built against CUDA 9 and cuDNN 7 says that CUDA 9 1 is not supported Could we change the RELEASE md so that it says Prebuilt binaries are now built against CUDA 9 0 and cuDNN 7 until later versions are supported,,tatianashp,2018-01-24 03:00:31,2018-02-21 20:56:54
IS,Calling variable property of DropoutWrapper gives Error AttributeError 'DropoutWrapper' object has no attribute 'trainable',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Using docker container minimaxir keras cntk cpu compiled TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 also tested on 1 4 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I was trying to access the weights and biases of an BasicLSTM cell I created The BasicLSTM cell also has a DropoutWrapper and when trying to access the variables property the below error is thrown AttributeError 'DropoutWrapper' object has no attribute 'trainable' Someone tried to help me with the error on stackoverflow second half of this answer and noticed that while variables is implemented in Layer I will quote his very helpful response below Although variables is documented for most all RNN classes it does break for DropoutWrapper The property has been documented since r1 2 but accessing the property causes an exception in 1 2 and 1 4 and looks like 1 3 but untested Specifically from tensorflow contrib import rnn lstm cell rnn BasicLSTMCell num hidden forget bias 1 0 wrapped cell rnn DropoutWrapper lstm cell outputs states rnn static rnn wrapped cell x dtype tf float32 print LSTM vars lstm cell variables print Wrapped vars wrapped cell variables will throw AttributeError 'DropoutWrapper' object has no attribute 'trainable' From the traceback or a long stare at the DropoutWrapper source I noticed that variables is implemented in DropoutWrapper is super RNNCell is super Layer Dizzy yet Indeed we find the documented variables property here It returns the documented weights property The weights property returns the documented self trainable weights self non trainable weights properties And finally the root of the problem That is variables does not work for a DropoutWrapper instance Neither will trainable weights or non trainable weights sinceself trainable is not defined One step deeper Layer init defaults self trainable to True Where that property gets removed deled unset whatever from a DropoutWrapper object I cannot tell,,"skye,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2018-01-03 10:59:59,2018-02-21 20:59:56
PR,Merge test local,,,"av8ramit,case540,av8ramit",2018-02-21 19:26:59,2018-02-21 21:19:50
IS,Question about freeze the graph,I found a model which has the checkpoint file inside pd url So do I still have to freeze the graph,,,2018-02-21 23:21:22,2018-02-21 23:25:52
PR,Disabling kmeans tests for release testing,,,av8ramit,2018-02-22 00:01:42,2018-02-22 00:54:01
IS,XLA bugs on training accuracy,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below r1 2 1 Python version 2 7 12 Bazel version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory NVIDIA TITAN Xp 12GB Exact command to reproduce At the tensorflow model inception directory bazel bin inception imagenet train num gpus 1 batch size 32 train dir tmp imagenet train data dir tmp imagenet data bazel bin inception imagenet eval checkpoint dir tmp imagenet train eval dir tmp imagenet eval cat etc issue Linux Ares 4 8 0 58 generic 63 16 04 1 Ubuntu SMP Mon Jun 26 18 08 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux Ares 4 8 0 58 generic 63 16 04 1 Ubuntu SMP Mon Jun 26 18 08 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 3 0 tensorflow 1 2 1 tensorflow tensorboard 0 1 2 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 1 2 gc996c7b tf COMPILER VERSION v1 2 1 2 gc996c7b Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda 8 0 lib64 usr local cuda 8 0 extras CUPTI lib64 usr local cuda 8 0 lib64 usr local cuda extras CUPTI lib64 DYLD LIBRARY PATH is unset nvidia smi Tue Jul 18 09 26 11 2017 NVIDIA SMI 381 09 Driver Version 381 09 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 TITAN Xp Off 0000 01 00 0 Off N A 48 75C P2 287W 250W 11771MiB 12189MiB 54 Default Processes GPU Memory GPU PID Type Process name Usage 0 1005 G usr lib xorg Xorg 18MiB 0 30938 C usr bin python 11737MiB cuda libs usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 Describe the problem I activated XLA and trained the Inception model When I verify the training results the accuracy is always 0 001 It is considered that the training is not performed normally When XLA is disabled normal accuracy is achieved Source code logs I added some codes of model inception inception inception train py to enable XLA I attached the file inception train zip,,"aselle,aselle,aselle,tatatodd,jlebar,drpngx,jlebar,drpngx,jlebar,jlebar",2017-07-18 00:42:31,2018-02-22 00:58:31
IS,1 3 0 py3 flagged by security issue CVE 2017 5754,Any chance a rebuild of the 1 3 0 py3 docker image is easy enough to pick up security patches It would save a team a lot of work Thank you,,"reedwm,gunan,gunan,gunan,gunan,martinwicke",2018-01-30 21:25:52,2018-02-22 01:04:50
IS,Error Creating Predictor from Core Estimator,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 0 Python version 3 5 3 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version 9 0 176 GPU model and memory Titan V 12288 MB Exact command to reproduce See below Describe the problem Creating a Predictor object by calling from estimator results in the following error is overridden by the function argument,,asimshankar,2018-02-22 01:38:44,2018-02-22 02:08:24
IS,Log Waiting for new checkpoint at in tf contrib training evaluate repeatedly only after the checkpoint is found,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 rc1 Python version 2 7 Bazel version if compiling from source 0 9 0 Problem description I use tf contrib training evaluate repeatedly function found here L345 The two parameters that are relevant here are timeout 1 timeout fn my timeout fn where my timeout fn is a custom function and returns True or False Basically I want to stop evaluation loop if some condition is met in which case the function will return 1 I have to set timeout to some small value in this case 1 sec so that timeout fn is triggered often The issue with this is that I get the next log message very often I set timeout 10 but still I do not want to see that useless log message every 10 seconds The message comes from here L192 One of the solutions would be to put this logging command inside the caller of wait for new checkpoint function and execute it once before while True loop on line 248 and then right after yield checkpoint path on line 264 This way we get this message only after a checkpoint is found,,asimshankar,2018-02-22 01:14:16,2018-02-22 02:12:45
IS,PermissionDeniedError when save model,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution Win7 TensorFlow installed from source or binary pip TensorFlow version use command below tensorflow gpu 1 3 0 Python version python 3 6 64bit CUDA cuDNN version 8 0 6 0 GPU model and memory GTX 1050Ti 4GB Describe the problem try to load a model and then save it same codes ran in three computers one failed when saving tensorflow gpu 1 3 0 GTX 1050Ti 4GB another two passed tensorflow 1 3 0 and tensorflow gpu 1 3 0 with GTX 780 Ti 4GB And I ran it as Administrator so should not lack of write permission here is the code def fit self training iters 1e2 learning rate 1e 4 optimizer epsilon 1e 10 max gard norm 50 display step 5 save path None restore path None self sess run tf global variables initializer self variables saver tf train Saver if restore path is not None and os path exists restore path self variables saver restore self sess restore path print arestore ok' if self batch size self mini batch size for scope in range np int training iters loss acc tp1 tp2 self sess run self train step self cost self accuracy self pondering cost self rnn cost feed dict self inputs self tmp inputs self targets self tmp targets if scope display step 0 print scope ' loss ' loss ' acc ' acc ' pondering cost ' tp1 ' rnn cost ' tp2 if save path is not None self variables saver save self sess save path and exception logs PermissionDeniedError Traceback most recent call last d anaconda3664 lib site packages tensorflow python client session py in do call self fn args 1326 try 1327 return fn args 1328 except errors OpError as e d anaconda3664 lib site packages tensorflow python client session py in run fn session feed dict fetch list target list options run metadata 1305 feed dict fetch list target list 1306 status run metadata 1307 d anaconda3664 lib contextlib py in exit self type value traceback 88 try 89 next self gen 90 except StopIteration d anaconda3664 lib site packages tensorflow python framework errors impl py in raise exception on not ok status 465 compat as text pywrap tensorflow TF Message status 466 pywrap tensorflow TF GetCode status 467 finally PermissionDeniedError Failed to create a directory e Node save 5 SaveV2 SaveV2 dtypes DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT INT64 DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save 5 Const 0 0 save 5 SaveV2 tensor names save 5 SaveV2 shape and slices act core act output linear b 939 act core act output linear b RMSProp 941 act core act output linear b RMSProp 1 943 act core act output linear w 945 act core act output linear w RMSProp 947 act core act output linear w RMSProp 1 949 act core halting linear b 951 act core halting linear b RMSProp 953 act core halting linear b RMSProp 1 955 act core halting linear w 957 act core halting linear w RMSProp 959 act core halting linear w RMSProp 1 961 global step lstm b gates 963 lstm b gates RMSProp 965 lstm b gates RMSProp 1 967 lstm w gates 969 lstm w gates RMSProp 971 lstm w gates RMSProp 1 973 lstm 1 b gates 975 lstm 1 b gates RMSProp 977 lstm 1 b gates RMSProp 1 979 lstm 1 w gates 981 lstm 1 w gates RMSProp 983 lstm 1 w gates RMSProp 1 985 lstm 2 b gates 987 lstm 2 b gates RMSProp 989 lstm 2 b gates RMSProp 1 991 lstm 2 w gates 993 lstm 2 w gates RMSProp 995 lstm 2 w gates RMSProp 1 997 During handling of the above exception another exception occurred PermissionDeniedError Traceback most recent call last ipython input 16 2f0c74b77fe4 in module 3 display step 1 4 save path e dnc model 171 ckpt 5 restore path e dnc model 17 ckpt 6 7 D PyTrade DNCore py in fit self training iters learning rate optimizer epsilon max gard norm display step save path restore path 135 136 if save path is not None 137 self variables saver save self sess save path 138 139 d anaconda3664 lib site packages tensorflow python training saver py in save self sess save path global step latest filename meta graph suffix write meta graph write state 1472 model checkpoint path sess run 1473 self saver def save tensor name 1474 self saver def filename tensor name checkpoint file 1475 model checkpoint path compat as str model checkpoint path 1476 if write state d anaconda3664 lib site packages tensorflow python client session py in run self fetches feed dict options run metadata 893 try 894 result self run None fetches feed dict options ptr 895 run metadata ptr 896 if run metadata 897 proto data tf session TF GetBuffer run metadata ptr d anaconda3664 lib site packages tensorflow python client session py in run self handle fetches feed dict options run metadata 1122 if final fetches or final targets or handle and feed dict tensor 1123 results self do run handle final targets final fetches 1124 feed dict tensor options run metadata 1125 else 1126 results d anaconda3664 lib site packages tensorflow python client session py in do run self handle target list fetch list feed dict options run metadata 1319 if handle is None 1320 return self do call run fn self session feeds fetches targets 1321 options run metadata 1322 else 1323 return self do call prun fn self session handle feeds fetches d anaconda3664 lib site packages tensorflow python client session py in do call self fn args 1338 except KeyError 1339 pass 1340 raise type e node def op message 1341 1342 def extend graph self PermissionDeniedError Failed to create a directory e Node save 5 SaveV2 SaveV2 dtypes DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT INT64 DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save 5 Const 0 0 save 5 SaveV2 tensor names save 5 SaveV2 shape and slices act core act output linear b 939 act core act output linear b RMSProp 941 act core act output linear b RMSProp 1 943 act core act output linear w 945 act core act output linear w RMSProp 947 act core act output linear w RMSProp 1 949 act core halting linear b 951 act core halting linear b RMSProp 953 act core halting linear b RMSProp 1 955 act core halting linear w 957 act core halting linear w RMSProp 959 act core halting linear w RMSProp 1 961 global step lstm b gates 963 lstm b gates RMSProp 965 lstm b gates RMSProp 1 967 lstm w gates 969 lstm w gates RMSProp 971 lstm w gates RMSProp 1 973 lstm 1 b gates 975 lstm 1 b gates RMSProp 977 lstm 1 b gates RMSProp 1 979 lstm 1 w gates 981 lstm 1 w gates RMSProp 983 lstm 1 w gates RMSProp 1 985 lstm 2 b gates 987 lstm 2 b gates RMSProp 989 lstm 2 b gates RMSProp 1 991 lstm 2 w gates 993 lstm 2 w gates RMSProp 995 lstm 2 w gates RMSProp 1 997 Caused by op isave 5 SaveV2' defined at File d anaconda3664 lib runpy py line 193 in run module as main main mod spec File d anaconda3664 lib runpy py line 85 in run code exec code run globals File d anaconda3664 lib site packages ipykernel launcher py line 16 in module app launch new instance File d anaconda3664 lib site packages traitlets config application py line 658 in launch instance app start File d anaconda3664 lib site packages ipykernel kernelapp py line 477 in start ioloop IOLoop instance start File d anaconda3664 lib site packages zmq eventloop ioloop py line 177 in start super ZMQIOLoop self start File d anaconda3664 lib site packages tornado ioloop py line 888 in start handler func fd obj events File d anaconda3664 lib site packages tornado stack context py line 277 in null wrapper return fn args kwargs File d anaconda3664 lib site packages zmq eventloop zmqstream py line 440 in handle events self handle recv File d anaconda3664 lib site packages zmq eventloop zmqstream py line 472 in handle recv self run callback callback msg File d anaconda3664 lib site packages zmq eventloop zmqstream py line 414 in run callback callback args kwargs File d anaconda3664 lib site packages tornado stack context py line 277 in null wrapper return fn args kwargs File d anaconda3664 lib site packages ipykernel kernelbase py line 283 in dispatcher return self dispatch shell stream msg File d anaconda3664 lib site packages ipykernel kernelbase py line 235 in dispatch shell handler stream idents msg File d anaconda3664 lib site packages ipykernel kernelbase py line 399 in execute request user expressions allow stdin File d anaconda3664 lib site packages ipykernel ipkernel py line 196 in do execute res shell run cell code store history store history silent silent File d anaconda3664 lib site packages ipykernel zmqshell py line 533 in run cell return super ZMQInteractiveShell self run cell args kwargs File d anaconda3664 lib site packages IPython core interactiveshell py line 2698 in run cell interactivity interactivity compiler compiler result result File d anaconda3664 lib site packages IPython core interactiveshell py line 2808 in run ast nodes if self run code code result File d anaconda3664 lib site packages IPython core interactiveshell py line 2862 in run code exec code obj self user global ns self user ns File ipython input 16 2f0c74b77fe4 line 5 in module restore path e dnc model 17 ckpt File D PyTrade DNCore py line 121 in fit self variables saver tf train Saver File d anaconda3664 lib site packages tensorflow python training saver py line 1140 in init self build File d anaconda3664 lib site packages tensorflow python training saver py line 1172 in build filename self filename File d anaconda3664 lib site packages tensorflow python training saver py line 686 in build save tensor self AddSaveOps filename tensor saveables File d anaconda3664 lib site packages tensorflow python training saver py line 276 in AddSaveOps save self save op filename tensor saveables File d anaconda3664 lib site packages tensorflow python training saver py line 219 in save op tensors File d anaconda3664 lib site packages tensorflow python ops gen io ops py line 768 in save v2 tensors tensors name name File d anaconda3664 lib site packages tensorflow python framework op def library py line 767 in apply op op def op def File d anaconda3664 lib site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File d anaconda3664 lib site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access PermissionDeniedError see above for traceback Failed to create a directory e Node save 5 SaveV2 SaveV2 dtypes DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT INT64 DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save 5 Const 0 0 save 5 SaveV2 tensor names save 5 SaveV2 shape and slices act core act output linear b 939 act core act output linear b RMSProp 941 act core act output linear b RMSProp 1 943 act core act output linear w 945 act core act output linear w RMSProp 947 act core act output linear w RMSProp 1 949 act core halting linear b 951 act core halting linear b RMSProp 953 act core halting linear b RMSProp 1 955 act core halting linear w 957 act core halting linear w RMSProp 959 act core halting linear w RMSProp 1 961 global step lstm b gates 963 lstm b gates RMSProp 965 lstm b gates RMSProp 1 967 lstm w gates 969 lstm w gates RMSProp 971 lstm w gates RMSProp 1 973 lstm 1 b gates 975 lstm 1 b gates RMSProp 977 lstm 1 b gates RMSProp 1 979 lstm 1 w gates 981 lstm 1 w gates RMSProp 983 lstm 1 w gates RMSProp 1 985 lstm 2 b gates 987 lstm 2 b gates RMSProp 989 lstm 2 b gates RMSProp 1 991 lstm 2 w gates 993 lstm 2 w gates RMSProp 995 lstm 2 w gates RMSProp 1 997,,aselle,2017-09-18 10:34:17,2018-02-22 03:38:04
PR,Fix markdown nit,Without a leading blank line it does not render properly in variable collections,,,2018-02-21 02:23:17,2018-02-22 04:13:39
PR,Make configure script runnable from external workspace,To run from external workspace you should now be able to invoke script like the following This will generate some TensorFlow specfic bazel options and import them into your project is bazelrc bazel info output base external org tensorflow configure py workspace PWD,,"case540,gunan,case540,gunan,case540",2018-02-21 17:50:24,2018-02-22 04:39:22
IS,Where is ios examples,Hi I'm trying to follow your iOS guide in the README which tells me to use tensorflow contrib ios examples But this folder is completely missing Can anyone advise,,,2017-06-17 01:32:31,2018-02-22 09:51:42
PR,XLA Fix subcomputation unification not adjusting conditionals,When the subcomputation unification finishes it calls into the module to adjust any instructions which have had their computation parameters invalidated the conditional instruction was missing from this function,,"DavidNorman,jhseu,DavidNorman,DavidNorman",2018-02-01 11:23:33,2018-02-22 17:32:18
IS,tf contrib quantize layer not quantized in absence of activation,In absence of an activation function e g tf layers Conv2D activation None the graph matcher using the activation pattern at L185 L192 wo not match the layer that has no activation function and consequently that layer wo not be quantized Maybe previously instead of no activation function tf identity was used The package tf contrib quantize searches for the identity op L35 Note that if activation None then no operation is inserted L192 L193 Example Box predictors in SSD from the TF Object Detection API L688 L689,,"suharshs,suharshs",2018-02-22 08:40:16,2018-02-22 17:48:37
PR,Documentation api reference badge added in Readme md and added new header for contribution guidelines,There is no documentation link provided in Readme md since added a nice badge with api reference link Also I have added a nice header for contribution guidelines To see how it looks please see here,,"rajendraarora16,rajendraarora16,martinwicke,gunan,rajendraarora16,rajendraarora16",2018-02-16 05:51:19,2018-02-22 18:14:43
PR,Merge pull request 1 from tensorflow master,Jan31 pull,,,2018-02-22 18:11:43,2018-02-22 18:25:00
IS,ImportError cannot import name 'checkpoint ops',keras version 2 0 8 tensorflow version 1 2 1 anconda and windows 10 install a binary python version is 3 5 64bit from tensorflow contrib framework python ops checkpoint ops import File C Users hp Anaconda3 lib site packages tensorflow contrib framework python ops checkpoint ops py line 22 in module from tensorflow python training import checkpoint ops ImportError cannot import name 'checkpoint ops',,,2017-12-31 11:13:22,2018-02-22 19:02:03
PR,Fix doc format for Sequential,see The Note is converted to an H1 in markdown The 4 space indent is interpreted as pre formatted text,,MarkDaoust,2018-02-22 17:11:23,2018-02-22 20:27:04
PR,Fix typo,It should be host C compiler not hostC compiler Compare set host cxx compiler,,,2018-02-22 09:34:51,2018-02-22 20:27:41
IS,Bug using pandas input fn with tensorflow contrib tensor forest client random forest TensorForestEstimator,System information Have I written custom code YES OS Platform and Distribution Linux Ubuntu 16 04 LTS TensorFlow installed from pip TensorFlow version use command below 1 4 1 Python version 2 7 12 Describe the problem Source code logs I am working on a simple Tensorflow programme and build input pipeline with pandas My code is below The output of print X shape and print Y shape is 53443 131 53443 respectively So I got confused why there will be 132 dimensions in input and why I got this ValueError What is more when I used tf contrib learn LinearRegressor to replace TensorForestEstimator I can train and eval model with no error So there is no problems in my train input fn and I assume this is a bug of Tensorflow,,drpngx,2018-02-02 11:21:48,2018-02-22 20:50:25
IS,Tensorflow 1 6 ALWAYS looking for libcublas so 8 0 with Cuda 9 0 Cudnn 7 0 and libcublas so 9 0,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version tensorflow 1 6 0rc0 Python version 2 7 12 Bazel version if compiling from source 0 10 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version Cuda 9 0 cuDNN 7 0 GPU model and memory Nvidia Quadro M1200 w 4GB GDDR5 Exact command to reproduce import tensorflow as tf Have I written custom code No Just trying to import tensorflow in python The only line of code I wrote is import tensorflow as tf Problem Tensorflow is looking for libcublas so 8 0 although I linked the cuda path during configuration to usr local cuda 9 0 also tried linking usr local cuda How do I run tensorflow with cuda 9 0 and cudnn 7 0 Outputs of ldconfig v libcublas so 9 0 libcublas so 9 0 176 libcudnn so 7 libcudnn so 7 0 5 import tensorflow as tf ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime Complete Traceback import tensorflow as tf Traceback most recent call last File stdin line 1 in module File home user local lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home user local lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home user local lib python2 7 site packages tensorflow python pywrap tensorflow py line 72 in module raise ImportError msg ImportError Traceback most recent call last File home user local lib python2 7 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home user local lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home user local lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime,,"gunan,gunan",2018-02-22 02:24:53,2018-02-22 21:34:43
IS,keras multi gpu model broken going from 1 6 0 rc0 to 1 6 0 rc1,Have I written custom code Yes OS Platform and Distribution Linux Ubuntu 17 04 TensorFlow installed from source TensorFlow version 1 6 0 rc1 Python version 3 6 Bazel version 0 10 GCC Compiler version 6 0 CUDA cuDNN version CUDA 9 1 cuDNN 7 0 5 GPU model and memory NVIDIA Titan Z 12GB Exact command to reproduce multi gpu model model gpus 2 Just upgraded from rc0 to rc1 of release 1 6 0 and I'm now getting the following crash when running the multi gpu model function was working fine with rc0 parallel model multi gpu model model gpus 2 File usr local lib python3 6 dist packages tensorflow python keras impl keras utils training utils py line 207 in multi gpu model return Model model inputs merged File usr local lib python3 6 dist packages tensorflow python keras impl keras engine topology py line 694 in init self init graph network args kwargs File usr local lib python3 6 dist packages tensorflow python keras impl keras engine topology py line 733 in init graph network if layer is placeholder AttributeError 'Lambda' object has no attribute 'is placeholder' I rolled back to the 1 5 branch and I'm not having any issues running multi gpu model there,,"facaiy,gunan",2018-02-17 04:01:21,2018-02-22 21:36:47
IS,Problem compiling on mac os x TF 1 6,Hello I am on Mac Os X Darwin fcamacbook dyndns cern ch 17 4 0 Darwin Kernel Version 17 4 0 Sun Dec 17 09 19 54 PST 2017 root xnu 4570 41 2 1 RELEASE X86 64 x86 64 and I have the latest gcc Configured with prefix Applications Xcode app Contents Developer usr with gxx include dir usr include c 4 2 1 Apple LLVM version 9 0 0 clang 900 0 39 2 Target x86 64 apple darwin17 4 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin Found CUDA installation usr local cuda version 8 0 I have python 3 6 4 from homebrew When I try to compile the master of TF from github with mkl support and march native I have ERROR usr local tensorflow tensorflow core BUILD 1574 1 C compilation of rule ' tensorflow core lib hash crc32c accelerate internal' failed Exit 1 clang error unsupported option ' fopenmp' Target tensorflow tools pip package build pip package failed to build Thanks for help,,"freedomtan,freedomtan,gunan,freedomtan",2018-02-15 15:26:30,2018-02-22 21:58:40
IS,Tensorflow build incorrectly complained about Bazel version,When I built Tensorflow it complained my bazel was 0 4 5 asked me to upgrade to bazel 0 5 4 or above So I upgraded to the newest bazel 0 10 1 Then when I built Tensorflow again it still complained Current Bazel version is 0 10 1 expected at least 0 5 4 So Tensorflow thinks 0 1 is less than 0 5 it did not treat that as version 10 v s 5 Please fix Thank you Jan Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-22 20:06:39,2018-02-22 23:00:54
IS,Spanish Translation,Hello I would like to translate the project into Spanish is it already translated,,"facaiy,facaiy",2018-02-17 06:04:15,2018-02-22 23:27:13
IS,FasterRCNN error,Hi friends While i am trying to execute tensor flow based faster RCNN i got the following error please help me how to solve this tensorflow python framework errors impl InternalError WhereOp Could not launch cub DeviceReduce Sum to count number of true indices temp storage bytes 2815 status invalid device function,,skye,2018-01-11 11:04:19,2018-02-22 23:32:19
IS,How to improve tensorflow model accuracy,I have created model for chair by using tensorflow But that model detecting any object as chair So how can i improve model to detect only chair We have provided 300 images of chair for training Total loss of chair model is less than 0 6 this is graph And also give me information about How to improve accuracy of model to detect only chair,,,2018-02-08 11:07:18,2018-02-22 23:38:17
IS,Feature Request Dynamic Convolution Kernels,I was wondering if it is possible to allow the kernel in conv2d and conv3d to have an additional batch dimension e g to allow the filter shape to be batch filter depth filter height filter width in channels out channels Hence the convolution kernel can depend on the input data In doing so the convolution kernels can be wouldynamic' and use prior information Currently the kernels are istatic' and therefore always look for the same patterns in the input data However it would be helpful for the kernel to be a function of some input That way a local transformation learned through back propagation can be applied to the kernels in order to look for patterns unique for that image event data sample I implemented a 3d version of this in python however all the indexing and slicing make it rather slow For the conv2d I guess one could use tf extract image patches to speed things up but something equivalent does not exist for the 3d case unless I'm missing something I tried looking into the code of conv3d and conv2d to see how much effort it would be to implement this Unfortunately I'm neither a cuda expert nor familiar with the way ops and kernels are implemented in tensorflow A feature like this would be greatly appreciated System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"skye,yzhwang",2018-02-07 13:56:05,2018-02-22 23:43:38
IS,Improve video input pipeline using TFRecord files,I am building a video input pipeline for DeepMind is Kinetics dataset using TFRecord files Since the dataset is large 200k videos my TFRecord files store the frames as compressed JPG images otherwise it would require too much space on disk Each tf train Example has the following structure 2 The number of frames in the video example seems impossible to access in TensorFlow It can be obtained using tf train Example FromString as given here but that does not help me in this case If this was possible I could just load all the video frames into a tensor at increased cost and than use tf random crop to sample a random number of frames from the video My overall question is whether the input pipeline for videos using TFRecord files can be improved This needs to consider speed of reading data and compression options to limit file size for enormous datasets It would be convenient to directly use mp4 streams with TFRecord files however decoding this is problably much slower than decoding JPG images EDIT this pull request is related Note that there are many ways to setup the data pipeline for videos I have described some of them in this post on StackOverflow and motivated why I chose for TFRecord files This post also describes the problem described here so it may be informative Have I written custom code N A OS Platform and Distribution N A TensorFlow installed from N A TensorFlow version N A Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"skye,mrry,mrry",2018-01-09 16:17:52,2018-02-22 23:46:23
IS,Consider supporting Microsoft Quantum,Please consider supporting Microsoft Quantum as a Runtime just like GPUs and TPUs Here is the same issue on Microsoft Quantum is repo It would be great to have an XLA device target for Microsoft Quantum,,,2018-02-04 06:32:27,2018-02-22 23:47:53
IS,A problem about gcc 5 5 0 It does not compile TensorFlow,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Slackware Linux 14 2 64 bit TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 Python version 3 6 4 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 5 0 CUDA cuDNN version 9 0 7 GPU model and memory 1050Ti 4Gb Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request gcc 5 5 0 does not compile TF source code First of all sorry for that I'm NOT using Ubuntu Linux for TF I know that Ubuntu Linux is the only supported Linux system for TF Instead I use an ancient distribution i e Slackware Linux Recently I got a security update for Spectre As a side effect I also got an updated gcc 5 3 0 5 5 0 I usually compile the TensorFlow source code for optimization However it can not be compiled with updated gcc 5 5 0 like this So I googled a little bit and found the following issue 10220 in the middle of the thread I saw I think the problem here is that gcc 5 5 shipped with avx512 intrin h headers that switched to using void and const void but without switching the builtins to do the same This is why 5 4 works but 5 5 breaks so I tracked down the matter that I could see All of the scatter gather intrinsics in avx512intrin h use int float double pointers which is incorrect So at first I thought this problem is about gcc but someone suggested that it is maybe related to CUDA it is the GPU CUDA code that does not support the new compiler so if you want to build that your only option is downgrade the compiler until Nvidia releases a new CUDA sdk from post5817669 To wrap up I was able to compile TF successfully with gcc 5 3 0 With gcc 5 5 0 I get error messages here and there and yet I do not know what makes this errors I suspect the combination of gcc and CUDA and also TensorFlow does not work well but I still can not figure out which of them makes this fault Thank you for your help Best regards sungjin Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2018-02-09 09:52:07,2018-02-23 00:27:37
IS,Compile from source on Skylake X Intel i9,Hello Compiling tensorflow source on Skylake X Intel i9 with config opt gives the following error in the snappy external module ERROR home armafire cache bazel bazel armafire efbef35334c587b69e16a82829bb0e2d external snappy BUILD 19 1 C compilation of rule ' snappy snappy' failed Exit 1 crosstool wrapper driver is not gcc failed error executing command cd home armafire cache bazel bazel armafire efbef35334c587b69e16a82829bb0e2d execroot org tensorflow exec env CUDA TOOLKIT PATH usr local cuda CUDNN INSTALL PATH usr local cuda 8 0 GCC HOST COMPILER PATH usr bin gcc PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 6 1 TF CUDA VERSION 8 0 TF CUDNN VERSION 6 TF NEED CUDA 1 TF NEED OPENCL 0 external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 DNDEBUG ffunction sections fdata sections ' march native' ' std c 11' ' march native' MD MF bazel out local linux opt bin external snappy objs snappy external snappy snappy pic d ' frandom seed bazel out local linux opt bin external snappy objs snappy external snappy snappy pic o' fPIC iquote external snappy iquote bazel out local linux opt genfiles external snappy iquote external bazel tools iquote bazel out local linux opt genfiles external bazel tools isystem external bazel tools tools cpp gcc3 Wno shift negative value Wno implicit function declaration no canonical prefixes Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' fno canonical system headers c external snappy snappy cc o bazel out local linux opt bin external snappy objs snappy external snappy snappy pic o cc1plus warning command line option ' Wno implicit function declaration' is valid for C ObjC but not for C external snappy snappy cc In member function 'void snappy SnappySinkAllocator Flush size t ' external snappy snappy cc 1403 23 warning comparison between signed and unsigned integer expressions Wsign compare for int i 0 i blocks size i In file included from external snappy snappy internal h 34 0 from external snappy snappy cc 30 external snappy snappy cc In instantiation of 'bool snappy SnappyScatteredWriter Allocator AppendFromSelf size t size t with Allocator snappy SnappySinkAllocator size t long unsigned int ' external snappy snappy cc 715 13 required from 'void snappy SnappyDecompressor DecompressAllTags Writer with Writer snappy SnappyScatteredWriter snappy SnappySinkAllocator ' external snappy snappy cc 799 3 required from 'bool snappy InternalUncompressAllTags snappy SnappyDecompressor Writer snappy uint32 with Writer snappy SnappyScatteredWriter snappy SnappySinkAllocator snappy uint32 unsigned int ' external snappy snappy cc 1460 78 required from here external snappy snappy cc 1316 34 warning comparison between signed and unsigned integer expressions Wsign compare if PREDICT TRUE offset 1u op ptr op base op end op limit external snappy snappy stubs internal h 80 25 note in definition of macro 'PREDICT TRUE' define PREDICT TRUE x x tmp ccxBWytY s Assembler messages tmp ccxBWytY s 389 Error no such instruction kmovq rdx k3' tmp ccxBWytY s 391 Error no such instruction kshiftrq 32 k3 k2' tmp ccxBWytY s 394 Error no such instruction kmovq k2 rdx' tmp ccxBWytY s 600 Error no such instruction kmovq rsi k1' tmp ccxBWytY s 602 Error no such instruction kshiftrq 32 k1 k0' tmp ccxBWytY s 605 Error no such instruction kmovq k0 rsi' Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 34 595s Critical Path 14 66s FAILED Build did NOT complete successfully The command I use is bazel build config opt c opt tensorflow tools pip package build pip package verbose failures j 64 If I change to config mkl then it compiles fine Therefore it seems that the problem is march native generated by config opt which forces the snappy module to generate AVX512 however the generated assembly is not correct for Skylake X Intel i9 which supports AVX512 I tried march skylake avx512 and all other AVX512 options like mavx512f and similar and all result in the same error My goal is to compile tensorflow with Eigen AVX512 Any ideas how this can be done,,"jart,drpngx,gunan",2017-09-03 18:47:27,2018-02-23 00:28:54
IS,Feature Request Create CTC loss function that Has an Optional Sequence Length Argument,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 8 1 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Since the sequence length parameter of CTC functions are each dependent on the input specifically the number of time steps why not let them determine the sequence lengths themselves Or have a separate function that determines the sequence lengths Source code logs I was thinking of adding something like this to ctc loss assuming inputs are batch major and of shape None num time steps num classes Unfortunately this throws an error TypeError Expected int32 passed to parameter wouldims' of op 'Fill' got Dimension None of type 'list' instead,,"selcouthlyBlue,selcouthlyBlue,ebrevdo,selcouthlyBlue",2018-02-22 01:31:00,2018-02-23 00:41:22
PR,persist nsync a across different platform builds,Persist nsync a across different platform builds via copying them into gen folder then later make can manage them clean or something else nsync a is required when the built tensorflow static lib is linked by other libs while currently the nsync a is cleaned from each build,,"resec,drpngx,resec,sb2nov,drpngx,resec,drpngx,resec,martinwicke,drpngx,resec,drpngx,resec,martinwicke,drpngx,resec,drpngx,resec,drpngx,resec,drpngx",2017-09-14 02:20:59,2018-02-23 01:19:35
IS,TypeError int argument must be a string a bytes like object or a number not 'Tensor',System information Have I written custom code Yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 4 1 Python version 3 5 2 Bazel version Not compiled from source GCC Compiler version Not compiled from source CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1080 8GB x 4 Exact command to reproduce N A I'm trying to convert a the initializer form from tf Variable to tf get variable for Cudnn GRU but I keep getting this error I have to convert because tensorflow does not allow initializing in loop control flow functions and only allow lambda initializers or through tf get variable I have reduced the problem into the following minimal example,,facaiy,2018-02-12 17:06:35,2018-02-23 05:37:02
IS,No package nasm,On Release version v1 5 0 In the file tensorflow workspace bzl At the line 208 The link is not exist any more,,,2018-02-13 06:40:24,2018-02-23 05:40:57
PR,Branch 186662441,,,"yifeif,drpngx,gunan",2018-02-22 21:26:02,2018-02-23 05:42:52
IS,Cannot use keras estimator from model in distributed cluster,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below tf VERSION 1 4 0 tf GIT VERSION v1 4 0 rc1 11 g130a514 Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory NVIDIA Tesla M60 8 GB Exact command to reproduce See Below Describe the problem When trying to use an estimator that is derived from Full logs tf env and more are here,,"yaroslavvb,yaroslavvb",2017-11-12 20:24:11,2018-02-23 05:43:34
IS,Dataset from generator does not release memory after recreating the session,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 rc0 Python version Python 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce see below Describe the problem After closing the session and creating new one an iterator creates the generator instance but does not free the memory of the previous one Every calling of the line session run x see below increases memory consumption of the script 519 MiB after the first 600 MiB after the second 681 MiB after the third and so on As you can see the delta is equal to 80 MiB N sizeof data dtype data dtype is float64 here Source code logs,,"aselle,mrry,mrry",2018-01-16 16:55:16,2018-02-23 05:43:34
IS,Eager tf linalg inv tf transpose mat has undefined shape in function with tfe defun,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 6 0dev20180126 GPU Python version 3 6 3 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Source code logs No problem in graph mode,,asimshankar,2018-02-10 14:26:08,2018-02-23 05:43:34
IS,Java SIGSEGV when Tensors create ing from an uninitialized array,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 13 3 JRE version Java TM SE Runtime Environment 8 0 121 b13 build 1 8 0 121 b13 TensorFlow installed from source or binary maven I'm not familiar enough with JNI in general to know if I'm expecting too much I wo not be surprised if you mark this wontfix I was just surprised to be able to crash the process with a segfault given some bad data Easy enough to work around I will size init my arrays more carefully but thought you might want to know Cheers Thanks so much for this library,,asimshankar,2018-02-19 15:01:11,2018-02-23 05:43:34
IS,TF Keras inference is way slower than Numpy,I'm working on a reinforcement learning model implemented with Keras and Tensorflow I have to do frequent calls to model predict on single inputs While testing inference on a simple pretrained model I noticed that using Keras' model predict is WAY slower than just using Numpy on stored weights Why is it that slow and how can I accelerate it Using pure Numpy is not viable for complex models import timeit import numpy as np from tensorflow python keras models import Sequential from tensorflow python keras layers import Dense w np array 1 1 0 0 0 0 1 1 T b np array 15 15 21 21 model Sequential model add Dense 4 input dim 2 activation 'linear' model layers 0 set weights w T b model compile loss 'mse' optimizer 'adam' state np array 23 5 17 8 def predict very slow return model predict state np newaxis 0 def predict slow ws model layers 0 get weights return np matmul ws 0 T state ws 1 def predict fast return np matmul w state b print timeit timeit predict very slow number 10000 timeit timeit predict slow number 10000 timeit timeit predict fast number 10000 5 168972805004538 1 6963867129435828 0 021918574168087623 5 461319456664639 1 5491559107269515 0 021502970783442876 I'm using Tensorflow for CPU version 1 5 0 installed from pypi for python 3 5 on Windows 10,,,2018-02-23 02:30:13,2018-02-23 06:22:48
IS,Expected float32 got range 0 3 of type 'range' instead,System information What is the top level directory of the model you are using C Users Administrator Documents Projects models Have I written custom code as opposed to using a stock example script provided in TensorFlow Because my previous issue I disable the argument OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 CUDA cuDNN version CUDA v9 0 GPU model and memory NVDIA GeForce GT 730 Describe the problem If my description or log is not clear enough please tell me Thanks in advance Source code logs File C Users Administrator Documents Projects models research object detection my train py line 164 in main worker job name is chief FLAGS train dir File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection trainer py line 255 in train train config optimizer File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection builders optimizer builder py line 50 in build learning rate create learning rate config learning rate File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection builders optimizer builder py line 108 in create learning rate learning rate sequence File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection utils learning schedules py line 155 in manual stepping tf constant range num boundaries dtype tf int32 File C Users Administrator AppData Local Programs Python Python35 lib site packages tensorflow python framework constant op py line 214 in constant value dtype dtype shape shape verify shape verify shape File C Users Administrator AppData Local Programs Python Python35 lib site packages tensorflow python framework tensor util py line 433 in make tensor proto AssertCompatible values dtype File C Users Administrator AppData Local Programs Python Python35 lib site packages tensorflow python framework tensor util py line 344 in AssertCompatible dtype name repr mismatch type mismatch name TypeError Expected float32 got range 0 3 of type 'range' instead,,,2018-02-23 05:22:16,2018-02-23 06:32:35
IS,How to sync worker models of KMeansClustering in distributed tensorflow,System information Have I written custom code yes OS Platform and Distribution Open SUSE Leap 42 3 TensorFlow installed from python pip TensorFlow version 1 6 0 Python version 2 7 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Hi I am trying to use distributed tensorflow over KMeansClustering I have one parameter server and two workers Training data in both the workers are different After training cluster centers in the two workers are different Is there a function in tensorflow which can be called to sync the models while training so that the cluster centers are similar if not same Source Code Your inputs will be very helpful,,,2018-02-20 14:53:47,2018-02-23 06:42:01
IS,init got an unexpected keyword argument wouldct method',System information What is the top level directory of the model you are using C Users Administrator Documents Projects models Have I written custom code as opposed to using a stock example script provided in TensorFlow Just changed the filename of 'train py' to 'my train py' OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 CUDA cuDNN version CUDA v9 0 GPU model and memory NVDIA GeForce GT 730 Describe the problem Is the new version have some bugs or my installation is incorrect because I saw the source code of the 'Image' class of tf example decoder it is no an argument named wouldec method' in the 'init' method If my description or log is not clear enough please tell me Thanks in advance Source code logs File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection trainer py line 59 in create input queue tensor dict create tensor dict fn File C Users Administrator Documents Projects models research object detection my train py line 120 in get next dataset builder build config get next File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection builders dataset builder py line 138 in build label map proto file label map proto file File C Users Administrator AppData Local Programs Python Python35 lib site packages object detection 0 1 py3 5 egg object detection data decoders tf example decoder py line 110 in init dct method dct method TypeError init got an unexpected keyword argument wouldct method',,,2018-02-23 04:49:01,2018-02-23 06:56:21
IS,enqueue inside while loop does not work as expected,VERSION 1 5 0 rc0 GIT VERSION v1 3 0 rc1 7323 g8d5741f Compiled from source,,"gaohuazuo,gaohuazuo,gaohuazuo",2018-02-17 13:20:12,2018-02-23 07:34:48
IS,TF 1 5 0 Java API broken in Ubuntu 14 04 GLIBCXX 3 4 20' not found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem The 1 5 0 Java API fails at runtime on Ubuntu 14 04 after working okay for 1 3 1 4 on the hello world example I originally noticed this behavior in CentOS 7 I'm reporting this as a bug for Ubuntu 14 04 because it is officially supported in the docs supported platforms and the error appears to be the same Possibly related to 15777 in which case the solution may just be to build libtensorflow jni so on Ubuntu 14 Thanks in advance for looking into this Source code logs 1 Optionally use docker container with Java 8 and Maven docker pull goyalzz ubuntu java 8 maven docker image docker run it goyalzz ubuntu java 8 maven docker image latest bash 2 Follow instructions in official Java API Maven example example 3 Upon Step 3 of above mvn q compile exec java observe the following error,,"asimshankar,av8ramit,asimshankar,av8ramit,gunan,av8ramit,andreas-eberle,gunan,asimshankar,andreas-eberle",2018-02-09 20:56:15,2018-02-23 08:14:58
IS,Installation Tensorflow from source stuck at Downloading grpc,Installation Tensorflow 1 4 0 rc0 from source on RHEL 7 4 Installation went fine with Python3 6 CUDA 9 1 CUDNN 7 0 5 cd tensorflow 1 4 0 rc0 configure bazel build config opt tensorflow tools pip package build pip package However it is not moving from INFO Downloading,,,2018-02-14 09:36:08,2018-02-23 08:26:44
IS,Integration of Tensor Comprehensions,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Not relevant TensorFlow installed from source or binary Not relevant TensorFlow version use command below Not relevant Python version Not relevant Bazel version if compiling from source Not relevant GCC Compiler version if compiling from source Not relevant CUDA cuDNN version Not relevant GPU model and memory Not relevant Exact command to reproduce Not relevant Describe the problem FAIR just released an initial version of their Tensor Comprehension Framework which I think is a really clever concept The Tensor comprehension library allows to define functions with a syntax similar to einstein notation and then compiles these functions into fast GPU code via evolutionary search Is this something you would consider including into the core or would you rather favor an integration as a separate framework Cheers Phil,,,2018-02-14 20:15:59,2018-02-23 08:30:11
IS,tfcompile tf cond not dominated by switch nodes,Using the following example tensorflow version 1 5 0 RHEL 7 3 64bit tensorflow built from source python 2 7 bazel 0 7 gcc 4 8 5,,,2018-02-14 17:23:34,2018-02-23 08:30:41
IS,undefined symbol PyUnicodeUCS4 FromString,I tried to install tensorflow cpu version using python 2 7 on Ubuntu16 04 under virtualenv but when I want to import tensorflow the error is My python2 yuan ubuntu python Python 2 7 13 default Feb 13 2018 14 17 11 GCC 5 4 0 20160609 on linux2 Type help copyright credits or license for more information import tensorflow Traceback most recent call last File stdin line 1 in module File home yuan Documents My python2 lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home yuan Documents My python2 lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home yuan Documents My python2 lib python2 7 site packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File home yuan Documents My python2 lib python2 7 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home yuan Documents My python2 lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home yuan Documents My python2 lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError home yuan Documents My python2 lib python2 7 site packages tensorflow python pywrap tensorflow internal so undefined symbol PyUnicodeUCS4 FromString Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help Please help Many thanks,,,2018-02-13 18:42:40,2018-02-23 08:34:30
IS,image retraining retrain py warning Op BatchNormWithGlobalNormalization is deprecated It will cease to work in GraphDef version 9 Use tf nn batch normalization,If I download and run it I get the following warning 2018 02 10 20 48 38 928435 W C tf jenkins workspace rel win M windows PY 36 tensorflow core framework op def util cc 343 Op BatchNormWithGlobalNormalization is deprecated It will cease to work in GraphDef version 9 Use tf nn batch normalization Here is a screenshot if that helps untitled After looking at some old TensorFlow issues for example these It seems that this concern has existed for quite a while and that it seems likely related to using the Inception model from 2015 L893 Can anybody update this to resolve this warning please Edit provided additional requested information in separate response below,,,2018-02-11 02:06:25,2018-02-23 08:43:06
IS,Level 3 warnings in core headers,I found some level 3 warnings in core headers This issue can be fixed using static cast I'm using VS2017 15 5 6 on Windows 10,,,2018-02-23 08:34:32,2018-02-23 08:44:40
IS,Variables disappearing when freezing graph with fused BatchNorm,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I'm using an inception resnet v2 from the slim model zoo OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 6 0rc0 Python version 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 0 5 GPU model and memory 1080 8GB Exact command to reproduce Describe the problem There seem to be a bug in handling fused BatchNorm is variables when freezing a graph Both moving mean and moving average disappear from the graph after inference graph extract sub graph input graph def output node names in graph util convert variables to constants and this breaks afterwards the optimize for inference script that searches for those two variables turned const From inspecting the input and output GraphDef what I think is the culprit is the definition of the FusedBatchNorm node details summary Node GraphDef summary details The input s do not mention neither the mean or average my suspicion is that extract sub graph does not detect them as part of the graph to be kept and strips the nodes,,,2018-02-09 17:31:52,2018-02-23 08:48:41
IS,ValueError No attr named ' XlaCompile' in name while attention cond fw CudnnRNN Enter and AttributeError 'NoneType' object has no attribute 'back prop',System information Have I written custom code Yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 4 1 Python version 3 5 2 Bazel version Not compiled from source GCC Compiler version Not compiled from source CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1080 8GB x 4 Exact command to reproduce N A I have a similar issue faced in this thread since I have started using tf while loop and the error is causing on grads self opt compute gradients self loss I'm initializing a class for gru layers outside the tf while loop since I can not initialize variables within the tf while loop without using tf get variable and then use the call of the class variable multiple times to use it within the tf while loop fn body The sample codes are provided as per below class Model object def init self ready if trainable self lr tf get variable lr shape dtype tf float32 trainable False self opt tf train AdadeltaOptimizer learning rate self lr epsilon 1e 6 Compile time ERROR over this line grads self opt compute gradients self loss gradients variables zip grads capped grads tf clip by global norm gradients config grad clip self train op self opt apply gradients zip capped grads variables global step self global step def get vP self i with tf variable scope encoding def f1 used to initialize the cudnn gru class over here but shifted outside the tf while loop due to initializing errors in tf Variable in cudnn gru init return self rnn1 c emb seq len self c len def f2 return self rnn1 c emb seq len self c len c tf cond tf equal i zero f1 f2 q self rnn1 q emb seq len self q len self q enc q with tf variable scope attention qc att dot attention c q mask self q mask hidden d keep prob config keep prob is train self is train name scope attention layer def f3 same situation as f1 return self rnn2 qc att seq len self c len def f4 return self rnn2 qc att seq len self c len att tf cond tf equal self i zero f3 f4 def f5 return att def f6 return tf concat att att axis 1 self att vP tf cond tf equal i zero f5 f6 return tf add i tf constant 1 dtype tf int64 def condition self i return tf less i self para count 0 def ready self config self config N PL QL CL d dc dg config batch size self c maxlen self q maxlen config char limit config hidden config char dim config char hidden gru cudnn gru if config use cudnn else native gru self cell fw tf contrib rnn GRUCell dg self cell bw tf contrib rnn GRUCell dg initializing here instead of within tf while loop body self rnn1 gru num layers 3 num units 150 batch size N input size 500 keep prob config keep prob is train self is train self rnn2 gru num layers 1 num units d batch size N input size 1800 keep prob config keep prob is train self is train result tf while loop self condition self get vP loop vars self i,,,2018-02-10 20:04:00,2018-02-23 09:27:26
IS,Saving the model throws op kernel cc No such file or directory error,System information Have I written custom code PTB model from official RNN tutorial using custom data and hyperparams slightly modified OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 4 14 16 1 Manjaro TensorFlow installed from pip TensorFlow version 1 5 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 GPU model and memory NVIDIA GTX 1070 Mobile 8GB driver 384 111 Exact command to reproduce just running the training file main py with default FLAG params Describe the problem Training goes fine and I can observe loss decreasing I can also run Tensorboard on the log dir and see the model graph When the max epoch is reached the code throws the above mentioned error Source code logs,,,2018-02-15 13:25:15,2018-02-23 10:51:43
IS,docs error in triplet semihard loss,Since AP alpha AN I think the docs in the following def triplet semihard loss labels embeddings margin 1 0 Computes the triplet loss with semi hard negative mining The loss encourages the positive distances between a pair of embeddings with the same labels to be smaller than the minimum negative distance among which are at least greater than the positive distance plus the margin constant called semi hard negative in the mini batch If no such negative exists uses the largest negative distance instead should be def triplet semihard loss labels embeddings margin 1 0 Computes the triplet loss with semi hard negative mining The loss encourages the positive distances between a pair of embeddings with the same labels to be smaller than the minimum negative distance among which are at least greater than the positive distance minus the margin constant called semi hard negative in the mini batch If no such negative exists uses the largest negative distance instead,,reedwm,2018-02-02 10:26:02,2018-02-23 13:13:55
IS,add hooks for mutate variables in tf Estimator,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce cat etc issue Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 8 0 0 clang 800 0 42 1 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow serving api 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 3 0 rc2 20 g0787eee' '1 3 0' Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Right now there is no elegant way we can mutate variable in the tf estimator Estimator And we do have some situation that we want to discard the checkpoints but save the variable in other format fits better with our infra Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatianashp,2018-01-24 16:21:59,2018-02-23 14:46:36
IS,Copyright on first line of LICENSE Apache 2 is incorrect,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem The LICENSE file in the tensorflow github repository has an incorrect copyright assignment The first line of the file reads Copyright 2017 The TensorFlow Authors All rights reserved This is incorrect The TensorFlow Authors are not the copyright holders for the Apache 2 0 license This line should be removed It makes a legal claim which is expressly false A separate issue is whether the line in the LICENSE file which provides an example of how to attribute the copyright for new code in the TensorFlow project which also includes a line assigning copyright to The TensorFlow Authors is incorrect as well In general I can not see how the copyright assignment works in the project Yuan Tang was recently added to the AUTHORS file Does that person now have full copyright over the entire TensorFlow work The Contributor agreement only grants a copyright license to Google and the downstream recipients of the code It does not grant copyright to the contributed code Source code logs N A,,jart,2017-07-12 21:09:32,2018-02-23 17:16:40
IS,No OpKernel was registered to support Op 'OneHot' with these attrs Tensorflow1 4,I have trained and saved a CNN model in python Tensorflow 1 3 I can successfully load and run the graph previously saved from my python model in Tensorflow 1 4 using CPU and c with no problem but when I tried to load the same graph using Tensorflow 1 4 using GPU c and I get the following error status state unique ptr code INVALID ARGUMENT 3 msg No OpKernel was registered to support Op 'OneHot' with these attrs Registered devices CPU GPU Registered kernels n no registered kernels n n t Node one hot OneHot T DT FLOAT TI DT INT32 tensorflow Status My system Windows 10 Cuda 8 0 Cudnn 6 cmake cmake 3 9 4 win64 x64 Python 3 5 2 VS2015,,"facaiy,reedwm,reedwm,mrry,reedwm",2017-12-01 21:53:16,2018-02-23 18:15:54
IS,Updated roadmap,The TensorFlow roadmap was last updated a year ago January 2017 could there be an update from the team on where TensorFlow is going in 2018,,"tatatodd,facaiy,skye,av8ramit,gunan,av8ramit",2018-01-26 11:28:52,2018-02-23 18:36:36
IS,No OpKernel was registered to support Op 'Ceil' on Android,I'm running tensorflow on android And it reports a exception of one of my op 'Ceil' The exception info is as below Caused by java lang IllegalArgumentException No OpKernel was registered to support Op 'Ceil' with these attrs Registered devices CPU Registered kernels no registered kernels Node model frame Ceil Ceil T DT DOUBLE model frame truediv at org tensorflow Session run Native Method I believe Ceil is a basic op and it should has CPU implement So maybe I miss sth I clone tensorflow master branch and build the lib and java interface on that,,"reedwm,andrewharp,andreas-eberle,tatatodd,tatatodd",2017-07-26 10:02:55,2018-02-23 18:51:56
PR,r1 5 cherry pick request Fixes issue when linking of rule ' tensorflow contrib lite toco toco,Fixes issue when linking of rule ' tensorflow contrib lite toco toco 16838,,,2018-02-23 20:40:07,2018-02-23 20:40:46
PR,Branch 186777369,push after pull,,"yifeif,drpngx",2018-02-23 18:48:55,2018-02-23 21:07:55
PR,Fix compiler error with cuda clang,segment reduction ops h requires cuda kernel helper h to be included in clang because it uses some of the helpers directly in the header e g CudaAtomicMax It works with nvcc because the usage is in a template context and nvcc checks that function is available only later at template instantiation However clang does more strict erorr checking for functions found during template instantiation and requires them to also be found either by ADL or at the point of template declaration,,"ilya-biryukov,gunan,ilya-biryukov,gunan",2018-02-21 16:37:34,2018-02-23 21:09:05
PR,Add cast functions for complex64 and complex128,Maybe the plan is to eventually remove the to float to int32 etc functions and promote calling tf cast directly but if not then it would be nice for API symmetry to have the corresponding cast functions for the complex dtypes as well,,"carlthome,martinwicke",2018-02-18 16:24:21,2018-02-23 21:58:21
IS,tf contrib layers optimize loss to support mixed precision training,ISSUE Referring to source code it is evident that mixed precision gradients is not supported in tf contrib layers optimize loss Here is the snip of assertion Description This was observed during training resnet50 this involves mixed precision batch norm Just curious to know whether there is a roadmap to have mixed precision gradients support in tf contrib layers optimize loss System information OS Platform and Distribution Linux Centos 7 2 TensorFlow installed from source or binary 1 5 0 TensorFlow version use command below v1 5 0 0 g37aa430d84 1 5 0 Python version 3 4 5 Bazel version if compiling from source No CUDA CUDAnn version CUDA 9 1 and CUDAnn 7 0 with latest Nvidia driver GPU model and memory Volta 100 16GiB,,"skye,martinwicke",2018-02-04 19:58:16,2018-02-23 22:26:14
PR,Fix typos in Operation Semantics docs,Fix MathJax beta display Update ' assuming' to ' assuming' Update 'in a the first' to 'in the first' Change 'nop' to 'no op' to match other occurrences Misc other minor updates periods hyphen etc,,,2018-02-19 22:10:27,2018-02-23 22:40:07
PR,TF Lite from six moves import xrange for Python 3,Lines 1785 and 1818 contain calls to the Python 2 only builtin function xrange which was removed in Python 3 in favor of range This PR adds the line from six moves import xrange module six moves for compatibility with both Python 2 and Python 3,,cclauss,2018-02-23 17:51:42,2018-02-23 22:40:22
PR,docker ci allows bad name user,Our server maintainer creates user name like xxx yyy which is invalid for adduser and so docker ci failed I hope tensorflow could provide a way to loose the restriction 1 use force badname for adduser 2 or we can provide CI BULID USER for ci builder sh,,facaiy,2018-02-20 14:15:13,2018-02-23 22:40:51
PR,fix Error on we feed float16 values into BeamSearchDecoder,I tried to feed float16 values into BeamSearchDecoder Then Type Error occurred The cause is that 1 mask probs in beam search decoder calls array ops one hot and the on value arg is 0 2 one hot in array ops infers the dtype of on value from the value 0 3 dtype of on value becomes tf float32 4 then raises TypeError dtype dtype 'float32' of on value does not match dtype parameter dtype 'float16' The main cause is that array ops one hot gets value 0 but the dtype is unknown so I convert the value 0 into tensor that has right dtype before it is fed to one hot Code that raises error,,,2018-02-20 09:12:01,2018-02-23 22:41:07
IS,Please add a working example for tf contrib factorization KMeansClustering in tutorial example,Describe the problem Hi I have been trying to use tf contrib factorization KMeansClustering for clustering I got the documentation in link But it did not specify how to give input There is no input argument here init num clusters model dir None initial clusters RANDOM INIT distance metric SQUARED EUCLIDEAN DISTANCE random seed 0 use mini batch True mini batch steps per iteration 1 kmeans plus plus num retries 2 relative tolerance None config None So I request you to please add a working example to train and predict using kmeansClustring in tutorial example Thank You,,byronyi,2018-02-14 06:40:22,2018-02-23 22:46:55
IS,Tensorflow or cuda not giving back gpu memory after session closes,I am tying to install tensorflow correctly and I am getting memory allocation erros I am using Ubuntu 16 04 tf 1 5 0 from pip install tensorflow gpu CUDA 9 0 CUDNN 7 0 5 starting python in a command terminal and running the following commands import tensorflow as tf sess tf Session sess close If I start a session it is fine the first time it says total memory 7 72Gib free Memory 7 50GiB The next time in the same terminal I start python again ti says freeMemory 279 44MiB and finally if I start again it says freeMemory 122 50MiB failed to allocate 72 50M from device CUDA ERROR OUT OF MEMORY What can I do to fix this I have pasted the entire sequence below teves teves python Python 2 7 12 default Dec 4 2017 14 50 18 GCC 5 4 0 20160609 on linux2 Type help copyright credits or license for more information import tensorflow import tensorflow as tf sess tf Session 2018 02 15 11 06 55 708721 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2018 02 15 11 06 55 846202 I tensorflow stream executor cuda cuda gpu executor cc 895 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 02 15 11 06 55 846656 I tensorflow core common runtime gpu gpu device cc 1105 Found device 0 with properties name GeForce GTX 1070 major 6 minor 1 memoryClockRate GHz 1 695 pciBusID 0000 01 00 0 totalMemory 7 92GiB freeMemory 7 50GiB 2018 02 15 11 06 55 846685 I tensorflow core common runtime gpu gpu device cc 1195 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1070 pci bus id 0000 01 00 0 compute capability 6 1 sess close 1 Stopped python teves teves python Python 2 7 12 default Dec 4 2017 14 50 18 GCC 5 4 0 20160609 on linux2 Type help copyright credits or license for more information import tensorflow as tf sess tf Session 2018 02 15 11 07 34 144528 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2018 02 15 11 07 34 351426 I tensorflow stream executor cuda cuda gpu executor cc 895 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 02 15 11 07 34 351699 I tensorflow core common runtime gpu gpu device cc 1105 Found device 0 with properties name GeForce GTX 1070 major 6 minor 1 memoryClockRate GHz 1 695 pciBusID 0000 01 00 0 totalMemory 7 92GiB freeMemory 279 44MiB 2018 02 15 11 07 34 351732 I tensorflow core common runtime gpu gpu device cc 1195 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1070 pci bus id 0000 01 00 0 compute capability 6 1 sess close 2 Stopped python teves teves python Python 2 7 12 default Dec 4 2017 14 50 18 GCC 5 4 0 20160609 on linux2 Type help copyright credits or license for more information import tensorflow as tf sess tf Session 2018 02 15 11 08 43 527818 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2018 02 15 11 08 43 877301 I tensorflow stream executor cuda cuda gpu executor cc 895 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 02 15 11 08 43 877577 I tensorflow core common runtime gpu gpu device cc 1105 Found device 0 with properties name GeForce GTX 1070 major 6 minor 1 memoryClockRate GHz 1 695 pciBusID 0000 01 00 0 totalMemory 7 92GiB freeMemory 122 50MiB 2018 02 15 11 08 43 877610 I tensorflow core common runtime gpu gpu device cc 1195 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1070 pci bus id 0000 01 00 0 compute capability 6 1 2018 02 15 11 08 44 047980 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 72 50M 76021760 bytes from device CUDA ERROR OUT OF MEMORY tf version '1 5 0',,"asimshankar,asimshankar,asimshankar",2018-02-15 16:24:18,2018-02-23 23:45:33
PR,TFTS Enhancements to timeseries head,Moved loss creation to create loss that satisfies Head Added namescope using self name Added loss summary identifiable reusing head lib summary key Made logits dimension always be 1 not used anyways just to satisfy Head,,"terrytangyuan,allenlavoie,terrytangyuan,allenlavoie,terrytangyuan,allenlavoie,terrytangyuan,terrytangyuan,terrytangyuan",2018-02-19 16:44:58,2018-02-24 01:05:25
PR,Add nasm mirror,Fixes 6956 nasm us serves a revoked cert for https Does not matter to us since we are checking the sha anyway but it is a little sketchy,,"martinwicke,martinwicke",2018-02-24 00:27:05,2018-02-24 03:40:27
PR,r1 5 cherry pick request Fixes issue when linking of rule ' tensorflow contrib lite toco toco,16838 Fixes issue when linking of rule ' tensorflow contrib lite toco toco' fails because LD LIBRARY PATH is not configured Check if LD LIBRARY PATH is in environ cp,,"ekelsen,gunan",2018-02-23 20:43:04,2018-02-24 05:09:36
IS,Extend tf unique with counts to multi dimensional tensors,I'm trying to solve KNN using tensorflow After I get the K neighbours for N vectors I have a N by K tensor Now for each vector in N I need to use 1,,yongtang,2018-01-27 16:43:22,2018-02-24 10:08:49
PR,Enable multi dimensional and axis support for tf unique with counts,This fix tries to address the issue raised in 16499 to bring multi dimensional and axis support for unique with counts When UniqueV2 kernel was added in 12952 it actually already implemented the multi dimensional and axis support for unique with counts as well just not registered This fix 1 Register UniqueWithCountsV2 kernel to have axis support 2 Hide both UniqueWithCounts and UniqueWithCountsV2 3 Add python unique with counts wrapper to call gen array ops unique with counts 4 If API review passes and the PR merges unique with counts will switch to gen array ops unique with counts v2 in 3 weeks 5 Add additional test cases for gen array ops unique with counts v2 This fix fixes 16499 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang",2018-01-27 20:01:54,2018-02-24 10:08:50
IS,Tensorflow,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-02-24 06:47:52,2018-02-24 15:45:01
IS,Unimplemented TensorArray has size zero but element shape 24 24 is not fully defined Currently only static shapes are supported when packing zero size TensorArrays,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary python version pip c version makefile TensorFlow version use command below r1 5 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I have tensorflow frozen graph When I read it using python api everything is good but if I do it via c api it fails with the error,,asimshankar,2018-02-23 08:43:57,2018-02-24 16:15:39
PR,Ship TF Eager header with libtensorflow tarballs,The TF Eager headers are getting excluded from nightly tarballs because they both have the same filename and output destination Looks like the core TF c header wins This PR introduces shipping the eager header in the correct location Take a look at one of the hosted tarballs here,,,2018-02-23 21:08:48,2018-02-24 19:19:22
IS,No clear documentation about how optimizer works through tf tile,If some one uses this type of code for batch learning w1 tf get variable W1 300 300 dtype tf float32 initializer init W1 tf tile tf expand dims w1 axis 0 batch size 1 1 name batch W1 x1 tf placeholder name context dtype tf float32 shape None None 300 y tf matmul x1 W1 how the optimizer will combine the gradients from W1 batch size 300 300 to w1 300 300 I asked this question in stackoverflow also but none replied,,,2018-02-23 08:46:55,2018-02-25 05:06:41
IS,TensorFlow cuInit CUDA ERROR NO DEVICE,Hi I was using TensorFlow with GPU support these past few months and it worked without any issues I have installed cuda v8 0 and also have the cudNN library Recently I started using TensorFlow for a project and noticed that it is not computing on the GPU and is using the GPU instead I'm running TensorFlow 1 2 1 on Windows 10 with CUDA v8 0 Here is the code that I ran on the Python Interpreter import tensorflow as tf sess tf Session Here is the message on the command prompt import tensorflow as tf sess tf Session 2018 02 22 13 24 51 069445 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 079084 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE2 instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 085961 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE3 instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 092933 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 102940 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 110151 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 116103 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 123166 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2018 02 22 13 24 51 705468 E c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda driver cc 406 failed call to cuInit CUDA ERROR NO DEVICE 2018 02 22 13 24 51 717633 I c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda diagnostics cc 158 retrieving CUDA diagnostic information for host Cipher 2018 02 22 13 24 51 728408 I c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda diagnostics cc 165 hostname Cipher I already tried a bunch of solutions such as changing CUDA VISIBLE DEVICES 0 and even adding cudnn to my PATH variables I have not used TensorFlow in this example to write any custom code I am running Windows 10 running TensorFlow 1 2 with GPU support which I installed from the TensorFlow website The GPU version is supported by CUDA v8 0 I have an NVIDIA 920M with a memory of 4GB,,,2018-02-22 08:01:58,2018-02-25 06:27:40
PR,Disambiguate documentation in multi class labels of losses sigmoid cross entropy,from continuous 0 1 to categorical set 0 1 according to in,,,2018-02-24 22:37:09,2018-02-25 06:41:13
IS,sigmoid cross entropy Docstring bug,Describe the problem Tf losses sigmoid cross entory parameter description of label indicates it has to be integer and in range 0 1 There are no integers between 0 1 so that seems really difficult to abide by It seems that in the code it does not need to be integer and the range should be 0 1 P S Why does softmax cross entropy assume one hot encoding For instance in distillation your labels are softmax outputs floats in 0 1,,drpngx,2018-02-14 23:49:43,2018-02-25 06:41:23
IS,TypeError Failed to convert object of type type 'list' to Tensor,I want to construct a dataset in which each element is a list of tensors with different shapes because I need a dataset to contain my parsed image informations with different shapes If I run the code like below dataset tf data Dataset from tensor slices np array 1 np array 1 2 np array 2 np array 4 5 It reports TypeError Failed to convert object of type type 'list' to Tensor How should I resolve this Thanks,,,2018-02-25 05:05:50,2018-02-25 07:44:47
PR,Fix typo,fix typo,,ManHyuk,2018-02-25 12:44:55,2018-02-25 16:09:29
IS,Keras API reproducibility,If any new option was added to ensure a reproducible results by setting some seed parameter In Keras the issue was discussed here According the issue the instability in results is due to weights random initialization,,,2017-07-18 17:41:48,2018-02-25 16:42:54
IS,DeprecationWarning The binary mode of fromstring is deprecated as it behaves surprisingly on unicode inputs Use frombuffer instead 1 6rc0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Ubuntu 16 04 Tensorflow installed from source latest HEAD from master CPU 1 6rc0 Python 3 5 2 Bazel 0 10 1 gcc 5 Describe the problem When using tensorflow I got hundred of DeprecationWarnings This message exactly home jerome local lib python3 5 site packages tensorflow python framework tensor util py 560 DeprecationWarning The binary mode of fromstring is deprecated as it behaves surprisingly on unicode inputs Use frombuffer instead return np fromstring tensor tensor content dtype dtype reshape shape EDIT fixed replacing line 560 in tensor util py by return np frombuffer tensor tensor content dtype dtype reshape shape Thanks for any kind of help,,"imsheridan,yongtang",2018-02-25 08:51:40,2018-02-25 19:34:15
IS,error in validating tensorflow installation,i installed tensorflow with cuda support on windows 10 and i'm trying to validate it i used this script and the result is 11 then i tried import tensorflow as tf from python console and 22,,"Carmezim,Carmezim,Carmezim",2018-02-21 12:34:36,2018-02-25 21:48:00
IS,A good and practical feature is removed,When training and test I want to use the different batch size But in zero state function the first parameter does not support a tensor as input To my knowledge I do not meet the error with the version of tensorflow before 1 2 Now I update tensorflow to 1 2 1 I think that using the different batch size is a practical function In stackoverflow a same problem is post but it is not solved url How can I solve this problem Thanks,,,2018-02-26 01:30:14,2018-02-26 02:05:58
IS,java lang IndexOutOfBoundsException Invalid index 0 size is 0 TensorFlow on Android,Hello Updated the following info Have I written custom code No its modification of the code from here OS Platform and Distribution Windows 10 TensorFlow installed from anaconda TensorFlow version 1 2 0 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A I created my custom model in keras to recognize happy faces and loaded the model into android and ran into this issue of java lang IndexOutOfBoundsException Invalid index 0 size is 0 at runtime and my app crashed I have modified the code from here to suit my model Is it the problem with protobuf file creation I have tested my model and it works well in python Below is the log file and the source code Please help with this issue Thanks Source code logs 01 11 16 21 12 508 18038 18078 com sridhar deepak objectdetection D OpenGLRenderer endAllStagingAnimators on 0xab6c06f0 ListView with handle 0xab7000d8 01 11 16 21 18 135 18038 18038 com sridhar deepak objectdetection E TensorFlowInferenceInterface Failed to run TensorFlow session java lang IllegalArgumentException No OpKernel was registered to support Op 'Switch' with these attrs Registered devices CPU Registered kernels device 'GPU' T in DT STRING device 'GPU' T in DT BOOL device 'GPU' T in DT INT32 device 'GPU' T in DT FLOAT device 'CPU' T in DT FLOAT device 'CPU' T in DT INT32 Node bn0 cond Switch Switch T DT BOOL bn0 keras learning phase bn0 keras learning phase 01 11 16 21 18 135 18038 18038 com sridhar deepak objectdetection D AndroidRuntime Shutting down VM 01 11 16 21 18 136 18038 18038 com sridhar deepak objectdetection E AndroidRuntime FATAL EXCEPTION main Process com sridhar deepak objectdetection PID 18038 java lang IndexOutOfBoundsException Invalid index 0 size is 0 at java util ArrayList throwIndexOutOfBoundsException ArrayList java 255 at java util ArrayList get ArrayList java 308 at org tensorflow contrib android TensorFlowInferenceInterface getTensor TensorFlowInferenceInterface java 473 at org tensorflow contrib android TensorFlowInferenceInterface readNodeIntoFloatBuffer TensorFlowInferenceInterface java 320 at org tensorflow contrib android TensorFlowInferenceInterface readNodeFloat TensorFlowInferenceInterface java 275 at com sridhar deepak objectdetection TensorFlowImageClassifier recognizeImage TensorFlowImageClassifier java 161 at com sridhar deepak objectdetection HappyFaceDetector 2 onPictureTaken HappyFaceDetector java 82 at com flurgle camerakit CameraView CameraListenerMiddleWare onPictureTaken CameraView java 296 at com flurgle camerakit Camera1 2 onPictureTaken Camera1 java 185 at android hardware Camera EventHandler handleMessage Camera java 1118 at android os Handler dispatchMessage Handler java 102 at android os Looper loop Looper java 154 at android app ActivityThread main ActivityThread java 5527 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 739 at com android internal os ZygoteInit main ZygoteInit java 629 01 11 16 21 18 136 18038 18038 com sridhar deepak objectdetection E MQSEventManagerDelegate failed to get MQSService 01 11 16 21 19 470 18038 18038 com sridhar deepak objectdetection I Process Sending signal PID 18038 SIG 9 TensorFlowImageClassifier file public List Recognition recognizeImage final Bitmap bitmap int s Log this method so that it can be analyzed with systrace Trace beginSection recognizeImage Trace beginSection preprocessBitmap Preprocess the image data from 0 255 int to normalized float based on the provided parameters if s 1 bitmap getPixels intValues 0 bitmap getWidth 0 0 bitmap getWidth bitmap getHeight for int i 0 i intValues length i final int val intValues i floatValues i 3 0 val 16 0xFF imageMean imageStd floatValues i 3 1 val 8 0xFF imageMean imageStd floatValues i 3 2 val 0xFF imageMean imageStd else bitmap getPixels intValues 0 bitmap getWidth 0 0 bitmap getWidth bitmap getHeight for int i 0 i intValues length i final int val intValues i floatValues i 3 0 val 16 0xFF imageStd floatValues i 3 1 val 8 0xFF imageStd floatValues i 3 2 val 0xFF imageStd floatValues i 3 0 floatValues i 3 0 1 floatValues i 3 1 floatValues i 3 1 1 floatValues i 3 2 floatValues i 3 2 1 Trace endSection Copy the input data into TensorFlow Trace beginSection fillNodeFloat inferenceInterface fillNodeFloat inputName new int 1 inputSize inputSize 3 floatValues Trace endSection Run the inference call Trace beginSection runInference inferenceInterface runInference outputNames Trace endSection Copy the output Tensor back into the output array Trace beginSection readNodeFloat inferenceInterface readNodeFloat outputName outputs Trace endSection MainActivity private static final int INPUT SIZE 64 private static final int IMAGE MEAN 128 private static final float IMAGE STD 128 private static final String INPUT NAME input 1 private static final String OUTPUT NAME fc Sigmoid private static final String MODEL FILE file private static final String LABEL FILE file,,,2018-01-11 21:57:03,2018-02-26 05:37:45
IS,ValueError Unknown activation function relu6 while converting MobileNet under Keras to estimator using model to estimator,Hi I try to convert a mobilenet model under tf keras application to estimator using model to estimator I get an error ValueError Unknown activation function relu6 due to relu6 is a customized activation defined in mobilenet Thanks for help System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 6r Python version 3 5 Bazel version if compiling from source 0 10 1 GCC Compiler version if compiling from source GCC CUDA cuDNN version 9 0 GPU model and memory GTX 1070 Have I written custom code No Exact command to reproduce,,,2018-02-22 08:48:34,2018-02-26 05:51:23
IS,error tf1 5 tf contrib ffmpeg decode video,I use tensorflow 1 5 on ubuntu and decodevideo with tf Session as sess summary writer tf summary FileWriter ' home xucl app tensorboard log keras training' movie bin tf read file ' home xucl app data bilibili video DongFangLieChe mp4' movie tf contrib ffmpeg decode video movie bin movie ev movie eval the link of ffmpeg tensorflow url but get an error F tensorflow contrib ffmpeg default ffmpeg lib cc 401 Non OK status ReadInfoFile stderr filename width height frames status Unknown Not enough video info returned by FFmpeg 0 0 0 3 Could not read FFmpeg stderr file tmp tmp file tensorflow 3 Bi0OjG err,,,2018-02-20 01:47:07,2018-02-26 08:05:48
PR,Update version string to 1 6 0,,,"gunan,gunan,av8ramit",2018-02-25 06:56:34,2018-02-26 18:11:44
IS,Running on DLAMI,I have got this error when running this script on Amazon aws I just want to know if this error is related to the memory space on the aws or within my installation of the project If this is possible on first sight So that I now where to ask the more specific questions ERROR OUTPUT,,yaroslavvb,2018-02-25 16:37:47,2018-02-26 19:05:15
PR,Branch 187038889,,,gunan,2018-02-26 18:22:53,2018-02-26 19:16:31
IS,C gradients for MaxPool3D AvgPool AvgPool3D,Looks like these just need to connect the gradient to an existing core op Anyone already working on it Otherwise I will sign up for these three cc,,"kbsriram,bpiel,suharshs,suharshs",2018-02-22 16:22:32,2018-02-26 19:31:29
PR,C gradients for MaxPool3D AvgPool and AvgPool3D,Resolves tensorflow tensorflow 17195 Also checked for possible flakes in the newly added tests none showed up with,,"kbsriram,protoget",2018-02-23 15:04:59,2018-02-26 19:31:29
IS,The labels do not appear on android app screen,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary Tensorflow For Poets 2 Python version 3 You can obtain the TensorFlow version with v1 5 0 0 g37aa430d84 1 5 0 Describe the problem Hello dear friends I literally followed all instructions in Tenforflow For Poets and for Tensorflow For Poets Mobile I visited all the sites blogs and forums but I could not find any solution or similar of this problem The first android application was not opened it was resolved in some way Now it opens but the labels do not appear I trained with Inception v3 I optimized it stripped it tried it on all emulators tried it on my own phone I'm adding a screenshot so you can look at it Thank you in advance for your answers screenshot from 2018 02 25 05 58 19 Source code logs 02 25 06 23 37 531 4375 4375 I zygote Not late enabling Xcheck jni already on 02 25 06 23 37 538 4375 4375 W zygote Unexpected CPU variant for X86 using defaults x86 02 25 06 23 37 582 4375 4382 I zygote Debugger is no longer active 02 25 06 23 37 810 4375 4375 I InstantRun starting instant run server is main process 02 25 06 23 37 852 4375 4375 D tensorflow CameraActivity onCreate org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 38 025 4375 4375 D tensorflow CameraActivity onStart org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 38 025 4375 4375 D tensorflow CameraActivity onResume org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 38 029 4375 4394 D OpenGLRenderer HWUI GL Pipeline 02 25 06 23 38 048 4375 4375 D tensorflow CameraActivity onPause org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 38 048 4375 4375 D tensorflow CameraActivity Requesting finish 02 25 06 23 38 119 4375 4394 I OpenGLRenderer Initialized EGL version 1 4 02 25 06 23 38 119 4375 4394 D OpenGLRenderer Swap behavior 1 02 25 06 23 38 120 4375 4394 W OpenGLRenderer Failed to choose config with EGL SWAP BEHAVIOR PRESERVED retrying without 02 25 06 23 38 120 4375 4394 D OpenGLRenderer Swap behavior 0 02 25 06 23 38 180 4375 4394 D EGL emulation eglCreateContext 0xab032640 maj 2 min 0 rcv 2 02 25 06 23 38 686 4375 4394 org tensorflow demo D EGL emulation eglMakeCurrent 0xab032640 ver 2 0 tinfo 0xab00b1d0 02 25 06 23 38 711 4375 4375 org tensorflow demo I Choreographer Skipped 35 frames The application may be doing too much work on its main thread 02 25 06 23 38 882 4375 4394 org tensorflow demo D EGL emulation eglMakeCurrent 0xab032640 ver 2 0 tinfo 0xab00b1d0 02 25 06 23 39 475 4375 4394 org tensorflow demo D EGL emulation eglMakeCurrent 0xab032640 ver 2 0 tinfo 0xab00b1d0 02 25 06 23 39 677 4375 4375 org tensorflow demo D tensorflow CameraActivity onStop org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 39 678 4375 4375 org tensorflow demo D tensorflow CameraActivity onDestroy org tensorflow demo ClassifierActivity e5ff96d 02 25 06 23 45 425 4375 4375 org tensorflow demo D tensorflow CameraActivity onCreate org tensorflow demo ClassifierActivity 186f2a1 02 25 06 23 45 436 4375 4375 org tensorflow demo I CameraManagerGlobal Connecting to camera service 02 25 06 23 45 447 4375 4375 org tensorflow demo I tensorflow CameraActivity Camera API lv2 false 02 25 06 23 45 467 4375 4375 org tensorflow demo D tensorflow CameraActivity onStart org tensorflow demo ClassifierActivity 186f2a1 02 25 06 23 45 467 4375 4375 org tensorflow demo D tensorflow CameraActivity onResume org tensorflow demo ClassifierActivity 186f2a1 02 25 06 23 45 773 4375 4375 org tensorflow demo I tensorflow CameraConnectionFragment Desired size 640x480 min size 480x480 02 25 06 23 45 774 4375 4375 org tensorflow demo I tensorflow CameraConnectionFragment Valid preview sizes 640x480 02 25 06 23 45 774 4375 4375 org tensorflow demo I tensorflow CameraConnectionFragment Rejected preview sizes 02 25 06 23 45 774 4375 4375 org tensorflow demo I tensorflow CameraConnectionFragment Exact size match found 02 25 06 23 45 844 4375 4394 org tensorflow demo D EGL emulation eglMakeCurrent 0xab032640 ver 2 0 tinfo 0xab00b1d0 02 25 06 23 46 007 4375 4375 org tensorflow demo I TensorFlowImageClassifier Reading labels from retrained labels txt 02 25 06 23 46 009 4375 4375 org tensorflow demo I TensorFlowInferenceInterface Checking to see if TensorFlow native methods are already loaded 02 25 06 23 46 009 4375 4375 org tensorflow demo E zygote No implementation found for long org tensorflow contrib android RunStats allocate tried Java org tensorflow contrib android RunStats allocate and Java org tensorflow contrib android RunStats allocate 02 25 06 23 46 009 4375 4375 org tensorflow demo I TensorFlowInferenceInterface TensorFlow native methods not found attempting to load via tensorflow inference 02 25 06 23 46 022 4375 4375 org tensorflow demo W native cpu feature guard cc 34 The TensorFlow library was compiled to use SSE instructions but these are not available on your machine 02 25 06 23 46 022 4375 4375 org tensorflow demo W native cpu feature guard cc 34 The TensorFlow library was compiled to use SSE2 instructions but these are not available on your machine 02 25 06 23 46 022 4375 4375 org tensorflow demo W native cpu feature guard cc 34 The TensorFlow library was compiled to use SSE3 instructions but these are not available on your machine 02 25 06 23 46 024 4375 4375 org tensorflow demo I TensorFlowInferenceInterface Successfully loaded TensorFlow native methods RunStats error may be ignored 02 25 06 23 46 596 4375 4375 org tensorflow demo E tensorflow CameraActivity Exception java lang RuntimeException Failed to load model from 'file' at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 113 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 113 at org tensorflow demo CameraActivity onPreviewFrame CameraActivity java 119 at android hardware Camera EventHandler handleMessage Camera java 1124 at android os Handler dispatchMessage Handler java 105 at android os Looper loop Looper java 164 at android app ActivityThread main ActivityThread java 6541 at java lang reflect Method invoke Native Method at com android internal os Zygote MethodAndArgsCaller run Zygote java 240 at com android internal os ZygoteInit main ZygoteInit java 767 Caused by java io IOException Not a valid TensorFlow Graph serialization NodeDef mentions attr wouldilations' not in Op name Conv2D signature input T filter T output T attr T type allowed DT HALF DT FLOAT attr strides list int attr use cudnn on gpu bool default true attr padding string allowed SAME VALID attr data format string default NHWC allowed NHWC NCHW NodeDef conv Conv2D Conv2D T DT FLOAT data format NHWC dilations 1 1 1 1 padding VALID strides 1 2 2 1 use cudnn on gpu true Mul conv conv2d params Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary at org tensorflow contrib android TensorFlowInferenceInterface loadGraph TensorFlowInferenceInterface java 535 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 105 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 113 at org tensorflow demo CameraActivity onPreviewFrame CameraActivity java 119 at android hardware Camera EventHandler handleMessage Camera java 1124 at android os Handler dispatchMessage Handler java 105 at android os Looper loop Looper java 164 at android app ActivityThread main ActivityThread java 6541 at java lang reflect Method invoke Native Method at com android internal os Zygote MethodAndArgsCaller run Zygote java 240 at com android internal os ZygoteInit main ZygoteInit java 767 02 25 06 23 49 350 4375 4380 org tensorflow demo I zygote Do partial code cache collection code 20KB data 21KB 02 25 06 23 49 350 4375 4380 org tensorflow demo I zygote After code cache collection code 20KB data 21KB 02 25 06 23 49 350 4375 4380 org tensorflow demo I zygote Increasing code cache capacity to 128KB 02 25 06 23 55 613 4375 4380 org tensorflow demo I zygote Do partial code cache collection code 61KB data 49KB 02 25 06 23 55 614 4375 4380 org tensorflow demo I zygote After code cache collection code 61KB data 49KB 02 25 06 23 55 614 4375 4380 org tensorflow demo I zygote Increasing code cache capacity to 256KB,,angersson,2018-02-25 03:44:55,2018-02-26 19:41:37
IS,What defines the output tensor shape of tf layers conv2d transpose,When using tf layers conv2d transpose what defines the output tensor shape For example if the input was 4x4x512 for the output to be 8x8x256 the filters can be given but how are is the height and width defined Or else is it always two times the input height and width Thanks,,angersson,2018-02-25 05:33:55,2018-02-26 19:41:51
IS,Saving large graphs to S3 fails with InternalError Unable to connect to endpoint,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes modified Tensorflow save load example code to save a few large tensors to S3 OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version Git version v1 3 0 rc1 3504 g27767d8 Tensorflow version 1 4 0 rc1 Python version 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version 8 0 GPU model and memory Nvidia Tesla K80 12 GiB RAM Exact command to reproduce Run the code in this gist in a Python shell You will need access to an S3 bucket for which you have write permissions Describe the problem I'm trying to save a large 380 MB graph to S3 but my call to tf Saver save crashes after 1 min with what appears to be an AWS SDK error InternalError Unable to connect to endpoint If the error is indeed AWS related it would be helpful to wrap it in something to indicate that the error is not coming from tensorflow Here is the stacktrace If I run the same code but checkpoint to my local filesystem the save op runs without error The error also only seems to occur for large graphs running the linked gist with smaller fewer tensors works,,yongtang,2017-10-20 01:24:35,2018-02-26 19:42:54
IS,same code tensorflow contribe android works but tensorflow contribe lite java src main native does not with error No implementation found,tensorflow r1 4 ubuntu 14 04 armv7 platform for short the same code witch can be used in tensorflow cotribe android jni when move to tensorflow contribe lite java src main native the java code cannot find the implementation use the command line bazel build c opt cxxopt ' std c 11' tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a to build an android so file it is ok and i modify the BUILD file to add my own code cc library name native framework only srcs run stats jni cc exception jni cc nativeinterpreterwrapper jni cc tensor jni cc tensorflow lite jni cc run stats lite jni cc select The Android toolchain makes jni h available in the include path For non Android toolchains generate jni h and jni md h tensorflow android conditions default jni h jni md h hdrs run stats jni h exception jni h nativeinterpreterwrapper jni h tensor jni h tensorflow lite jni h run stats lite jni h testlite h copts tflite copts includes select tensorflow android conditions default linkopts lm ldl llog tags manual deps tensorflow contrib lite context tensorflow contrib lite framework tensorflow contrib lite schema fbs version tensorflow contrib lite kernels builtin ops dlib arm v7 dlib seeta arm v7 seeta opencv jni opencv jni alwayslink 1 the file run stats jni h is just from tensorflow contribe android jni the function i want to call from native is JNIEXPORT jint RUN STATS METHOD jniSetInterval JNIEnv env jclass clazz jint interval int val int interval return JNI OK and using the command line bazel build c opt cxxopt ' std c 11' tensorflow contrib lite java libtensorflowlite jni so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a and when i using nm D command to check the libtensorflowlite jni so and libtensorflow inference so they all have the same name Java org tensorflow jniSetInterval but libtensorflow inference so works but libtensorflowlite jni so does not the error is No implementation found for int org tensorflow jniSetInterval int tried Java org tensorflow jniSetInterval and Java org tensorflow jniSetInterval I lack of document to tell us how to add own code to tensorflow lite and it is wierd may be a bug,,angersson,2018-02-26 09:24:47,2018-02-26 19:46:10
IS,Using tf estimator Estimator with save checkpoint steps leads to Tensorboard warnings,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 4 4 0 104 generic TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 4 CUDA cuDNN version 8 0 61 GPU model and memory GeForce GTX TITAN X Describe the problem When using tf estimator train and evaluate with an tf estimator Estimator configurated with tf contrib learn RunConfig save checkpoints steps 10 a CheckpointSaverHook will be created automatically This CheckpointSaverHook will save the graph and graph def to the summary writer every time it is triggered see CheckpointSaverHook before run L440 Basic code example language lang py estimator tf estimator Estimator model fn model dir params config tf estimator RunConfig save checkpoints steps 100 save summary steps 100 train spec tf estimator TrainSpec train fn eval spec tf estimator TrainSpec eval fn tf estimator train and evaluate estimator train spec eval spec When starting Tensorboard on the written summary it will output a hundreds of warnings because of multiple graph defs in the summary which I guess slows it down a lot on startup language lang none W0117 18 47 30 278879 Reloader tf logging py 86 Found more than one graph event per run or there was a metagraph containing a graph def as well as one or more graph events Overwriting the graph with the newest event W0117 18 47 30 279753 Reloader tf logging py 86 Found more than one metagraph event per run Overwriting the metagraph with the newest event I see there might be issues when using multiple graphs but for a single graph this seems unpracticable Related stack overflow discussion,,angersson,2018-02-26 11:29:31,2018-02-26 19:51:29
IS,terminate called after throwing an instance of istd system error',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 1 LTS GNU Linux3 13 0 105 generic x86 64 TensorFlow installed from source or binary binary tf nightly 1 head cp36 cp36m linux x86 64 whl TensorFlow version use command below 1 7 0 dev20180222 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CPU Intel Xeon E5 2620 v3 GPU model and memory N A Exact command to reproduce I use anaconda create a new python 3 6 enviroment for tensorflow After I downloaded the whl package I use pip install tf nightly 1 head cp36 cp36m linux x86 64 whl to install the tensorflow I have seen a similar problem and in that case his system is CentOS So is anyone having a similar experience with this problem,,angersson,2018-02-23 10:53:29,2018-02-26 19:52:07
IS,Getting ValueError setting an array element with a sequence from tf contrib keras preprocessing image ImageDatagenerator flow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 6 0 rc0 Python version 2 7 12 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source 5 4 0 I am trying to do Data Augmentation in Tensorflow I have written this code import numpy as np import tensorflow as tf import tensorflow contrib keras as keras import time random def get image data generator return keras preprocessing image ImageDataGenerator rotation range get random rotation angle width shift range get random wh shift height shift range get random wh shift shear range get random shear zoom range get random zoom horizontal flip get random flip vertical flip get random flip preprocessing function get random function def augment data image array label array print image array shape images array image array copy labels array label array copy Create a list of various datagenerators with different arguments datagenerators ndg 10 Creating 10 different generators for ndata in xrange ndg datagenerators append get image data generator Setting batch size to be equal to no of images bsize image array shape 0 print bsize Obtaining the augmented data for dgen in datagenerators dgen fit image array aug img aug label dgen flow image array label array batch size bsize shuffle True print aug img shape Concatenating with the original data images array np concatenate images array aug img axis 0 labels array np concatenate labels array aug label axis 0 return images array labels array When I run the code using augment data image array label array I get an error which says Traceback most recent call last File cnn model py line 40 in module images array labels array augment data image array label array File media siladittya d801fb13 809a 41b4 8f2e d617ba103aba ISI code 2 known object detection aug data py line 47 in augment data aug img aug label dgen flow image array label array batch size 10000 shuffle True File usr local lib python2 7 dist packages tensorflow python keras impl keras preprocessing image py line 1018 in next return self get batches of transformed samples index array File usr local lib python2 7 dist packages tensorflow python keras impl keras preprocessing image py line 991 in get batches of transformed samples batch x i x ValueError setting an array element with a sequence Edit I am getting this error even if I pass a single image as argument What am I doing wrong here I can not understand Please help,,angersson,2018-02-24 08:00:28,2018-02-26 19:52:50
IS,TF1 3 to 1 5 drastic changes apparently due to gRPC,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS Linux release 7 1 1503 Core TensorFlow installed from source or binary pip install TensorFlow version use command below 1 5 Python version 2 7 15 with TF 1 5 and 2 7 5 with TF1 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I built a distributed training system with TF1 3 and it works smoothly except that it sporadically freeze I was informed by that TF1 5 has an upgrade version of gRPC that fixes a deadlock bug that causes servers to hang So I tried to upgrade to 1 5 today but then a lot of unexpected problems came up and not sure if I am missing anything important for 1 5 version TL DR Soon after I launch a job it died right away and all of the time it is the PS showing various errors like unavailable OS Error Stream removed and Transport closed during sess run tf global variables initializer Also this problem is more likely to happen if I launched more PS So is there any important dependencies I have to check when upgrading from 1 3 to 1 5,,angersson,2018-02-22 08:18:02,2018-02-26 19:55:19
IS,How can I get kernel wait time for GPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below r1 5 Python version 2 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 0 GPU model and memory Titan XP 12GB Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I have tested the code to get kernel queue wait time for GPU but GPU kernel time is constants even though the number of operations is increased Instead the CPU kernel time is changed like below Can I get the information to analyze the results Moreover profiling of kernel queue wait time would be useful Do you have any plan to add that kind of features ops GPU kernel time us CPU kernel time us 50 1862 184 100 1746 181 150 1750 167 200 1750 173 250 1751 307 300 1756 551 350 1757 721 400 1767 859 450 1767 959 Source code logs,,angersson,2018-02-19 13:51:09,2018-02-26 19:55:42
PR,Add missing override',This fixes a warning produced by clang pre tensorflow core common runtime gpu gpu device h 70 10 warning 'FillContextMap' overrides a member function but is not marked 'override' Winconsistent missing override Status FillContextMap const Graph graph tensorflow core common runtime device h 124 18 note overridden virtual function is here virtual Status FillContextMap const Graph graph pre,,dtrebbien,2018-02-17 19:33:24,2018-02-26 21:42:08
PR,MKL Update mkl docs,,,"claynerobison,ekelsen,claynerobison,tatianashp",2018-02-21 23:21:23,2018-02-26 21:51:07
PR,R1 6,,,"gunan,gunan",2018-02-26 19:18:13,2018-02-26 22:28:26
PR,Fix bad wrong jpeg nasm mirror,,,martinwicke,2018-02-26 17:02:50,2018-02-27 02:32:37
PR,Upgrade Jenkins Docker build scripts to Bazel 0 11 0,The 0 10 0 bazel has problems with static linking on linux This PR bumps to the latest bazel that produces proper binaries w o the linking issue,,"yifeif,gunan,meteorcloudy",2018-02-26 19:16:20,2018-02-27 05:11:37
IS,Train and release quantized models for other input sizes of mobilenet,Trying to run tensorflow examples image retraining retrain py getting the following error The 1 0 220 version works but 1 0 190 does not work also Could you advise on this issue please,,"tatatodd,suharshs,suharshs,raghuraman-k,suharshs,suharshs",2017-11-30 20:28:58,2018-02-27 05:21:15
IS,Cannot run mobilenet 0 25 128 quantized image retrain,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce python tensorflow examples image retraining retrain py image dir path to image dir architecture mobilenet 0 25 128 quantized Describe the problem while trying to create a mobilenet model getting this error The url being created in the retrain py file is not accessible via browser either Source code logs tensorflow python framework errors impl NotFoundError tmp imagenet mobilenet v1 0 25 128 quantized frozen quantized frozen graph pb No such file or directory,,suharshs,2017-12-28 18:23:51,2018-02-27 05:28:42
IS,tensorflow suddenly cannot detect my GPUs,I was working with tensorflow gpu and it worked properly before But just now suddenly my Tensorflow cannot run on GPU anymore and when I query my devices with list local devices it shows that I do not have any GPU But my nvidia smi properly displayed the info of my 2 GPUs It is very weird since I did't do anything,,,2018-02-25 09:40:58,2018-02-27 05:54:23
IS,Feature Request Quantized DepthwiseConv2dNative,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below master as of post d3edb8c60ed4fd831d62833ed22f5c23486c561c Python version 2 7 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Models such as MobileNet use DepthwiseConv2dNative I could not find a quantized kernel and the quantization pass in GraphTransform does not currently support DepthwiseConv2dNative L57 Are there plans to provide a quantized version of DepthwiseConv2dNative,,"asimshankar,suharshs",2017-07-21 17:52:36,2018-02-27 06:19:10
PR,Fix some breakages in TensorFlow Windows build,Working towards,,"meteorcloudy,meteorcloudy,gunan,meteorcloudy",2018-02-26 10:24:16,2018-02-27 06:36:02
IS,after restore trained model checkpoint the prefetch capacity become 500 which is 5 during training,when I restore my trained model and do predict it out of memory problem how can I restore the original capacity or how can I reset the capacity after restore I am using python gpu 1 5 below is the operation information when training name prefetch queue op PaddingFIFOQueueV2 device device CPU 0 attr key capacity value i 5 after restore name prefetch queue op PaddingFIFOQueueV2 attr key capacity value i 500,,,2018-02-25 12:58:44,2018-02-27 10:39:25
PR,fix SRU call return type,Because many other cells such as BasicLSTMCell LSTMCell NASCell LayerNormBasicLSTMCell return h and stateTuple with c and h when call I think sru should return the same type as lstm,,"carlthome,protoget,carlthome",2018-02-15 06:20:36,2018-02-27 11:33:55
PR,Update tensor shape py,Correct two typos where 'if' were written as 'iff',,caisq,2018-02-27 04:51:02,2018-02-27 14:33:55
IS,Tensorflow 1 5 0 breaking previously built models,Hello I have recently updated to tensorflow version 1 5 0 and suddenly receive an error that I can not decipher for code that worked before in version 1 4 1 Cannot use 'transducer training while rnn strided slice' as input to 'gradients transducer training while rnn while Select 1 grad Select f acc' because 'transducer training while rnn strided slice' is in a while loop I have also tried using the softmax cross entropy with logits function but that still produced the same error Here is the stackoverflow post in case its a coding mistake on my part The model is a seq2seq variation System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 0 previous 1 4 1 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Copy paste and run the code I can try and make a smaller fail case if needed Thanks Nikita,,ebrevdo,2018-02-15 15:15:05,2018-02-27 18:11:22
IS,FileWriter instance can not invoke close normally,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 4 9 0 4 amd64 1 SMP Debian 4 9 65 3 deb9u1 2017 12 23 x86 64 GNU Linux TensorFlow installed from source or binary via pip3 for python3 5 3 TensorFlow version use command below v1 5 0 0 g37aa430d84 1 5 0 Python version 3 5 3 Bazel version if compiling from source NO GCC Compiler version if compiling from source NO CUDA cuDNN version NO GPU model and memory 256G RAM Exact command to reproduce python virtualenv and tensorboard You can collect some of this information using our environment capture script Describe the problem loggingMXNet summary data with tensorflow tensorboard but FileWriter close method can not execute successfully without any errors or warnings Source code logs in my case without any extra info but just i use minist dataset to training MXNet digits recongnition model and wrap tensorboard event writer into MXNet fit callback by location i found close method failed to exec IS there anyone faced with similar same issue if exists please share your ideas,,angersson,2018-02-27 11:08:42,2018-02-27 18:29:55
IS,retraining on gpu causing high clone loss,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 Python version 3 6 3 Bazel version if compiling from source 0 9 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 1 GPU model and memory gtx 1050 ti Exact command to reproduce Tensorflow gpu produces strange clone loss very high while retraining with resnet 50 the loss though is not produced while retraining on a cpu What could be the cause of this behaviour resnet 50,,angersson,2018-02-27 12:08:16,2018-02-27 18:30:26
IS,Why Run a short TensorFlow program print b'Hello TensorFlow',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,angersson,2018-02-27 14:45:53,2018-02-27 18:30:36
IS,Failed to load the native TensorFlow runtime,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below Python version tensorflow gpu 1 5 GCC Compiler version if compiling from source 5 4 CUDA cuDNN version CUDA 8 cuDNN v6 GPU model and memory Nvidia 920MX 2 GB Describe the problem Not able to import Tensorflow Is it because I installed CUDA 8 rather than 9 Source code logs Python 3 5 2 default Nov 23 2017 16 37 01 GCC 5 4 0 20160609 on linux Type help copyright credits or license for more information import tensorflow Traceback most recent call last File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 9 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File home scene analysis local lib python3 5 site packages tensorflow init py line 24 in module from tensorflow python import File home scene analysis local lib python3 5 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home scene analysis local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 9 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime,,angersson,2018-02-27 17:11:49,2018-02-27 18:30:48
PR,Branch 187165096,,,"caisq,caisq,gunan",2018-02-27 14:38:53,2018-02-27 22:33:35
PR,Bump the version of CUB in cmake build,We made the same upgrade for bazel build but forgot about cmake,,gunan,2018-02-27 18:21:01,2018-02-27 22:33:46
IS,XLA CHECK fails when using tf random normal op,this issue is about XLA core dump similar to 12683 code GPU cuda 9 0 cudnn 7 0 5 GPU GeForce GTX 950M Describe the problem core dump when use xla with gpu,,"jlebar,jlebar",2018-02-17 10:36:23,2018-02-27 22:34:42
PR,Pull request for fixing warm starting device placement,,,,2018-02-27 23:14:29,2018-02-28 00:05:27
PR,Bump the version of CUB in cmake build,,,gunan,2018-02-27 22:36:36,2018-02-28 00:13:09
PR,Pull request for fixing warm starting device placement 17312,Update checkpoint utils py Fix device allocation bug for warm starting op Update checkpoint utils test py Fix test,,gunan,2018-02-28 00:13:42,2018-02-28 00:53:54
IS,Dataset map KeyError from external tensors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Arch 15 Feb 2018 TensorFlow installed from source or binary binary tensorflow gpu via pip TensorFlow version use command below v1 5 0 0 g37aa430d84 1 5 0 Python version 3 6 4 CUDA cuDNN version 9 0 176 7 0 5 2 GPU model and memory NVIDIA GeForce GTX 860M 4GB Exact command to reproduce python dataset map py Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request The following script raises the subsequent KeyError I do not see anything obvious in the documentation that indicates that referencing tensors not defined in the callback function is invalid though perhaps this is a common feature limitation of library functions that call user functions to generate subgraphs such as Dataset map and tf cond This exact issue has an obvious workaround but it gets a little trickier when you are referencing something more complex than a simple tf zeros tensor The type of Dataset does not matter I'm just using from generator for brevity Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Source permalink,,mrry,2018-02-27 21:27:46,2018-02-28 01:29:09
IS,ld unknown option icf all Bazel build tensorflow lite label image Error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 max os 10 12 6 TensorFlow installed from source or binary pip TensorFlow version use command below 1 5 Python version 2 7 anaconda Bazel version if compiling from source none GCC Compiler version if compiling from source none Describe the problem,,"freedomtan,Johnson145,freedomtan,Johnson145,freedomtan,Johnson145,freedomtan,freedomtan",2018-02-24 03:12:01,2018-02-28 04:56:30
IS,Tensorflow produced HLO graphs cannot be rendered by graphviz,Have I written custom code as opposed to using a stock example script provided in TensorFlow No I'm using standard mnist softmax xla py with unmodified tensorflow cloned from master OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 4 13 0 32 generic 35 16 04 1 Ubuntu SMP Thu Jan 25 10 13 43 UTC 2018 x86 64 x86 64 x86 64 GNU Linux TensorFlow installed from source or binary Source with XLA and CUDA TensorFlow version use command below tf VERSION 1 6 0 rc0 tf GIT VERSION v1 5 0 2285 g4448430 tf COMPILER VERSION v1 5 0 2285 g4448430 Python version Python 3 5 2 Bazel version if compiling from source bazel release 0 10 0 GCC Compiler version if compiling from source gcc 5 4 0 20160609 CUDA cuDNN version cuda libs usr local cuda 9 0 doc man man7 libcudart 7 usr local cuda 9 0 doc man man7 libcudart so 7 usr local cuda 9 0 targets x86 64 linux lib libcudart static a usr local cuda 9 0 targets x86 64 linux lib libcudart so 9 0 176 usr local cuda 9 1 doc man man7 libcudart 7 usr local cuda 9 1 doc man man7 libcudart so 7 usr local cuda 9 1 targets x86 64 linux lib libcudart static a usr local cuda 9 1 targets x86 64 linux lib libcudart so 9 1 85 GPU model and memory Nvidia Titan V Driver Version 387 34 12058MiB Exact command to reproduce TF XLA FLAGS xla hlo graph path home user test hlo graphs xla generate hlo graph python3 mnist softmax xla py Describe the problem I want to run XLA JIT on the mnist softmax xla py example script and then view the generated HLO to see what was compiled To do this I run TF XLA FLAGS xla hlo graph path home user test hlo graph xla generate hlo graph python3 mnist softmax xla py This produces a lot of text omitted 2018 02 23 12 42 22 413434 I tensorflow core common runtime gpu gpu device cc 1016 Creating TensorFlow device job localhost replica 0 task 0 device GPU 0 with 10979 MB memory physical GPU device 0 name Graphics Device pci bus id 0000 01 00 0 compute capability 7 0 2018 02 23 12 42 22 743524 I tensorflow compiler xla service service cc 158 XLA service 0x7fc63c001800 executing computations on platform CUDA Devices 2018 02 23 12 42 22 743569 I tensorflow compiler xla service service cc 166 StreamExecutor device 0 Graphics Device Compute Capability 7 0 omitted 2018 02 23 12 42 22 796890 I tensorflow compiler xla service hlo graph dumper cc 1395 computation cluster 0 XlaCompiledKernel true XlaNumConstantArgs 0 XlaNumResourceArgs 0 v83 GPU ir emit prepare after copy insertion pipeline end home user test hlo graph hlo graph 47 mcrbox 6dffc700 28862 565e07de51010 dot 2018 02 23 12 42 22 973757 W tensorflow compiler xla service gpu gpu compiler cc 351 WARNING You are using ptxas 9 1 108 which is in range 9 0 0 9 0 276 9 1 0 9 1 121 These versions are known to miscompile XLA code leading to incorrect results or invalid address errors 2018 02 23 12 42 24 527632 I tensorflow stream executor dso loader cc 147 successfully opened CUDA library libcupti so 9 1 locally omitted Apart from the warning for the ptxas version which I believe there is no way for me to fix because I'm using the latest available version of CUDA that I can get from Nvidia this appears to be successful and the compiled execution can be seen in the timeline json However I want to view the HLO graph with graphviz so using the above output I try to load hlo graph hlo graph 47 mcrbox 6dffc700 28862 565e07de51010 dot However I get an error dot Tpng hlo graph hlo graph 47 mcrbox 6dffc700 28862 565e07de51010 dot o graph png Error hlo graph hlo graph 47 mcrbox 6dffc700 28862 565e07de51010 dot syntax error in line 10 near '' Line 10 is the large stylesheet definition in the dot file It is very long and I am not familiar with the syntax but it iseems' like there are no missing supernumerary quotations anywhere Is this a known problem or have I done something incorrectly Is there another renderer i e not graphviz that I can target out of the box I have attached the aforementioned dot file as a txt hlo graph 47 mcrbox 6dffc700 28862 565e07de51010 txt The graphviz version I'm using is dot graphviz version 2 38 0 20140413 2041,,"asimshankar,tatatodd,jlebar",2018-02-23 13:05:16,2018-02-28 12:46:26
IS,Build tf core kernels on With VS2015 stops with fatal error C1060 compiler is out of heap space,System information Build tf core kernels vcxproj Windows 10 Enterprise Build 1607 TensorFlow installed from source TensorFlow version Release 1 4 0 from github VS2015 Enterprise 14 0 25431 Update 3 Cannot build tf core kernels vcxproj generated with CMake because of a fatal error C1060 compiler is out of heap space Source code logs 1 Build started Project tf core kernels Configuration RelWithDebInfo x64 1 training ops cc 1 e software tensorflow tensorflow contrib cmake build external eigen archive unsupported eigen cxx11 src Tensor TensorBase h 245 fatal error C1060 compiler is out of heap space 1 INTERNAL COMPILER ERROR in 'C Program Files x86 Microsoft Visual Studio 14 0 VC bin x86 amd64 CL exe',,"rongjiecomputer,snnn",2017-12-15 11:54:16,2018-02-28 13:05:02
PR,tensorflow lite build issue,Build fails because of LICENSE is not available inside lite dir Need to remove a small line of code to keep it running File location is tensorflow tensorflow contrib lite BUILD,,,2018-02-28 13:38:36,2018-02-28 13:40:15
IS,unsupported operand type s for 'Tensor' and 'float,Tensorflow version is tensorflow gpu 1 4 1 Python version is Python 3 5 4 Anaconda custom 64 bit,,,2018-01-09 03:47:01,2018-02-28 14:27:17
IS,Resource exhausted OOM when allocating tensor with shape even when batch size is 1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I have registered a new problem for translating English to Swedish the code is pretty similar to TranslateEndeWmtBpe32k with Europarl data I'm able to train with hidden size 128 anything over 128 and I get Resource exhausted error even when batch size is 1 I'm using hparams transformer big I notice that previous posts on this issue were solved by reducing the batch size I'm posting this because reducing batch size was not helpful and I'm hoping if someone encountered a similar issue OS Platform and Distribution e g Linux Ubuntu 16 04 Linux deepnlp01 4 2 0 42 generic 49 14 04 1 Ubuntu SMP Wed Jun 29 20 22 11 UTC 2016 x86 64 x86 64 x86 64 GNU Linux 4 VERSION 14 04 5 LTS Trusty Tahr TensorFlow installed from source or binary tf VERSION 1 4 1 Installed from source Python version 2 7 6 Bazel version if compiling from source Build label 0 5 2 GCC Compiler version if compiling from source c Ubuntu 4 8 4 2ubuntu1 14 04 3 4 8 4 CUDA cuDNN version nvcc NVIDIA R Cuda compiler driver Cuda compilation tools release 8 0 V8 0 61 GPU model and memory NVIDIA TITAN X 12GB Exact command to reproduce USR DIR path python2 7 site packages tensor2tensor new module t2t trainer data dir DATA DIR problems PROBLEM model MODEL hparams set HPARAMS output dir TRAIN DIR t2t usr dir USR DIR Describe the problem The data I'm using is parallel corpus English Swedish available on I have created a dictionary myself of about 1 400 000 1 4 million words The problem persists even if I use a smaller vocab of about 10k words I'm able to train with batch size 1024 and hidden size 128 if I increase the hidden size to 256 even with batch size 1 it runs out of memory I get the following error Source code logs This is the error I'm encountering,,,2018-02-28 14:00:59,2018-02-28 15:02:50
PR,fix a typo,should be tf zeros initializer,,caisq,2018-02-28 15:13:16,2018-02-28 16:40:29
IS,OrderedEnqueuer not imported in keras utils init py,OrderedEnqueuer is not imported with the remaining util objects Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"tatianashp,tatianashp",2018-01-24 05:48:06,2018-02-28 18:17:05
PR,Fix typos in profiler h,Fixed 3 typos in profiler h,,,2018-02-11 19:55:54,2018-02-28 18:35:09
PR,Cherrypick Do not assign device for the keras part of saved first checkpoint Fi,x 14504 PiperOrigin RevId 186526175,,yifeif,2018-02-23 22:04:09,2018-02-28 18:52:32
IS,Reading tfrecords files greater than 64mb brings up errors,I have already read this thread but I am still encountering this issue with version 1 3 0 Was wondering if anyone knows why Tested on 2 systems OS Windows 10 Ubuntu 16 04 Tensorflow installed from source Tensorflow version 1 3 0 One system running tensorflow non gpu and another system running CUDA 8 and cuDNN v6 GPU model none and GTX Titan Z The error I get is File C Users benja AppData Local Programs Python Python35 lib site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl InvalidArgumentError Could not parse example input value ' 9 csv CQ M B During handling of the above exception another exception occurred Traceback most recent call last File D write to tfrecords py line 581 in module main File D write to tfrecords py line 577 in main read dataset from tfrecords File D write to tfrecords py line 554 in read dataset from tfrecords image dataset csv dataset sess run image out reshaped csv out reshaped File C Users benja AppData Local Programs Python Python35 lib site packages tensorflow python client session py line 895 in run run metadata ptr File C Users benja AppData Local Programs Python Python35 lib site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File C Users benja AppData Local Programs Python Python35 lib site packages tensorflow python client session py line 1321 in do run options run metadata File C Users benja AppData Local Programs Python Python35 lib site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Could not parse example input value ' 9 csv CQ M B When I try to read tfrecords files that are less than 64mb this error does not occur My code is here with tf Session as sess try feature 'images' tf FixedLenFeature tf string 'csv' tf FixedLenFeature tf string filename queue tf train string input producer data path num epochs 1 reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example features feature image out tf decode raw features 'images' tf uint8 csv out tf decode raw features 'csv' tf float32 image out reshaped tf reshape image out 1000 200 200 3 csv out reshaped tf reshape csv out 1000 6 sess run tf global variables initializer sess run tf local variables initializer Create a coordinator and run all QueueRunner objects coord tf train Coordinator threads tf train start queue runners coord coord image dataset csv dataset sess run image out reshaped csv out reshaped coord request stop coord join threads,,"martinwicke,mrry,martinwicke,martinwicke,martinwicke,saxenasaurabh,saxenasaurabh,angersson,martinwicke,saxenasaurabh",2017-10-09 02:47:22,2018-02-28 19:48:36
IS,gcc error unrecognized command line option ' fcolor diagnostics',The issue is similar to 1192 I am trying build Tensorflow from source on UBUNTU machine 16 04 LTS I am using following version of gcc and bazel gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 bazel Build label 0 9 0 Problem Description I get a number of build errors during the bazel build phase All errors are similar to one below I used verbose failures option for bazel build ERROR home murthy tensorflow tensorflow core BUILD 1656 1 Could not build file tensorflow core objs version lib tensorflow core util version info pic o C compilation of rule ' tensorflow core version lib' failed Exit 1 gcc failed error executing command cd home murthy cache bazel bazel murthy 72b24eaacfd1d73bef6a8acb540b8c44 execroot org tensorflow exec env PWD proc self cwd PYTHON BIN PATH home murthy virtualenvs dl4cv bin python PYTHON LIB PATH home murthy virtualenvs dl4cv lib python3 5 TF NEED CUDA 0 TF NEED OPENCL SYCL 0 usr bin gcc U FORTIFY SOURCE fstack protector Wall B usr bin B usr bin Wunused but set parameter Wno free nonheap object fcolor diagnostics fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections DGEMMLOWP ALLOW SLOW SCALAR FALLBACK ' march native' mssse3 mfma mcx16 msse4 1 msse4 2 mpopcnt mavx ' std c 0x' MD MF bazel out k8 py3 opt bin tensorflow core objs version lib tensorflow core util version info pic d ' frandom seed bazel out k8 py3 opt bin tensorflow core objs version lib tensorflow core util version info pic o' fPIC iquote iquote bazel out k8 py3 opt genfiles iquote external bazel tools iquote bazel out k8 py3 opt genfiles external bazel tools isystem external bazel tools tools cpp gcc3 DEIGEN AVOID STL ARRAY Iexternal gemmlowp Wno sign compare fno exceptions ' ftemplate depth 900' msse3 pthread fno canonical system headers Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c bazel out k8 py3 opt genfiles tensorflow core util version info cc o bazel out k8 py3 opt bin tensorflow core objs version lib tensorflow core util version info pic o gcc error unrecognized command line option ' fcolor diagnostics' Target tensorflow tools pip package build pip package failed to build What did I do I manually removed the fcolor diagnostics flag and gcc did not give an error further I looked up the man pages for gcc and was surprised to find Language Independent Options fmessage length n fdiagnostics show location once every line fdiagnostics color auto never always fno diagnostics show option fno diagnostics show caret Note the interchange in the words wouldiagnostics' and 'color' in the man pages as compared to that in flags for bazel build I am not sure if this is Tensorflow issue or bazel issue but am looking for a way to suppress the fcolor diagnostics' flag or change it to fdiagnostics color,,"reedwm,reedwm,gunan",2018-01-04 14:44:19,2018-02-28 20:22:15
PR,Windows Copy NominalCPUFrequency from Abseil,Attempt to fix Bazel build on Windows is all red since Copy from L74 Do not ever use anything from absl internal as it violates Abseil is compatibility contract cc,,"rongjiecomputer,meteorcloudy,meteorcloudy,rongjiecomputer,meteorcloudy,rongjiecomputer,meteorcloudy,meteorcloudy,meteorcloudy",2018-02-10 02:37:11,2018-02-28 20:38:30
IS,Require a c example or documents about tensorflow lite useage,because i have my own native and c code if i want to use tensorflow lite feature and put it to my android project i have to write tensorflow lite code in c but it is too hard to find out how to get the input and output i have look up the ios example because part of the code is written in c but it crashed when i have float output interpreter typed output tensor float 0 for int i 0 i output size i LOGD bkzero jni result f output i i believe it is not a bug under iOS platform this part of code in android example is written in java i cannot figure out how to write an implemetation of the tensorhandle like long outputsHandles run interpreterHandle errorHandle sizes dataTypes numsOfBytes inputs if outputsHandles null outputsHandles length 0 throw new IllegalStateException Interpreter has no outputs Tensor outputs new Tensor outputsHandles length for int i 0 i outputsHandles length i outputs i Tensor fromHandle outputsHandles i Log i bkzero java outputs 0 outputs i,,angersson,2018-02-28 10:09:56,2018-02-28 21:24:25
IS,A bug When use kmean and tensorboard,When I use the tensorboard in kmeans it cause an error if i remove the merge summary op with d idx sess run train op avg distance cluster idx feed dict X full data x it will be ok I do not know why the merge op will cause the error could anyone help me with,,angersson,2018-02-28 12:37:16,2018-02-28 21:24:53
PR,Do not use NCHW or NHCW for conv1d,Fixes deprecation warning when using tf layers conv1d,,"alanhdu,alanhdu,alanhdu",2018-03-01 00:46:04,2018-03-01 01:48:09
PR,inception tutorial added png to allowed extensions made print statements clearer,something very minor it will probably save a couple people some headaches,,protoget,2018-02-28 23:35:46,2018-03-01 01:53:54
PR,Cross ent logits,practical description for using cross entropy logits loss,,4d55397500,2018-02-28 08:00:57,2018-03-01 01:57:36
PR,Fixes 16152,Fixes 16152 Please note that I have tested this fix only on Ubuntu 16 04 with python 3 5 It should in theory work for both python 2 and python 3 but I have not tested it on all major versions of python,,protoget,2018-02-15 03:18:28,2018-03-01 03:30:31
PR,Update 1 notmnist ipynb for clarity,This adds some comments to the command matplotlib to prevent severe confusion for those of us who are familiar with python but not familiar with iron python since this page makes absolutely no mention of the fact that is the only interpreter that will work with this code,,vincentvanhoucke,2018-02-27 17:46:08,2018-03-01 16:03:05
PR,Fix some minor typos in get started docs to keep consistent,Described as the PR title,,imsheridan,2018-03-01 14:27:51,2018-03-01 16:34:37
IS,zeros not tracking shape based on input tensors,If reshape can understand the input values well enough to set a static shape for its output should not zeros be able to This is using tensorflow 1 5,,,2018-03-01 17:04:53,2018-03-01 17:21:18
IS,Interleaving multiple datasets together,mrry The current interleave functionality is basically a interleaved flat map taking as input a single dataset Given the current API what is the best way to interleave multiple datasets together Say they have already been constructed and I have a list of them I want to produce elements from them alternatively and I want to support lists with more than 2 datasets i e stacked zips and interleaves would be pretty ugly Thanks,,"eaplatanios,angersson,eaplatanios",2018-03-01 17:32:30,2018-03-01 18:59:42
IS,Distributed training Evaluation and inference best practices,I understand tensorflow distributed training and I implemented my own script What I want to do now is to integrate the possibility of assigning some workers the task of asynchronously evaluate the model Let is say we have 6 workers what I want to do is to use 4 of them to do asynchronous training one to periodically evaluate the model and another one to periodically make inference on it My intuition to achieve this goal is to do the following but this means that the evaluation is performed considering the time and not considering the global step and the only meaning that I can give to periodically is to sleep the thread What do you think about this solution Is it the correct way to asynchronously perform training evaluation and inference Alberto,,angersson,2018-03-01 15:33:26,2018-03-01 19:00:43
IS,Throw Exception instead of Crash when out of BFC memory allocation,For huge application model the memory is easy to overflow and the framework will quit after plenty of Out of memory logs Is it possible to just quickly throw an Exception in python runtime instead of killing the whole program,,"angersson,angersson",2018-03-01 13:40:49,2018-03-01 19:02:35
IS,when run bazel bin tensorflow python tools freeze graph AttributeError 'int' object attribute ' doc ' is read only,tensorflow r1 5 python2 7 followed by the tensorflow lite tutorial my command line,,angersson,2018-03-01 09:16:44,2018-03-01 19:26:58
IS,Does the size of embedding have a huge influence on the training speed,In my text classification task I use vectors to represent the words After I enlarge the size of vocabulary word dimension is still 128 from 200000 to 1000000 the training step time arise from 0 1s to 0 4s Here is the word embedding tensor creatation tf get variable 'embedding' shape dtype dtype return tf get variable 'embedding' shape dtype dtype initializer tf random normal initializer stddev 0 1 trainable True And the sentences are made of word ids and vectors will be looked up from the embedding tensor above inputs embedding tf contrib layers embedding lookup unique embedding inputs So what confused me is that why the size of vocabulary has a significant impact on the training speed Is that normal,,angersson,2018-03-01 06:36:00,2018-03-01 19:36:28
IS,can not use all the CPU cores,I'm running the ptb example on my 48 core Intel Skylake CPUs two sockets However I found only 10 of the 48 cores are being used I used the 'top' command I want to use all the cores I tried the following setting but it did not work config proto tf ConfigProto allow soft placement soft placement inter op parallelism threads 4 intra op parallelism threads 12 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 3 10 0 693 17 1 el7 x86 64 1 SMP TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version Did not use GPU GPU model and memory Did not use GPU Exact command to reproduce,,"yaroslavvb,angersson",2018-03-01 02:48:15,2018-03-01 19:37:33
IS,Could some ops assert switch be removed in inference model,I want to convert faster rcnn model to tensorRT but these ops can not be converted because invalid dtype or non data value so I want to know how to solve the question,,angersson,2018-03-01 01:59:50,2018-03-01 19:37:54
PR,MKL cifar 10 divergance fix and batchnorm unit test fix,1 Fix Cifar 10 diverging issue 2 Fix BatchNorm unit test failures,,,2018-02-14 08:28:19,2018-03-01 20:19:37
IS,Estimator WarmStartSettings Cause Extreme Training Slowdown,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary official docker image TensorFlow version use command below 1 6 0 rc1 Python version 2 7 12 Bazel version if compiling from source None GCC Compiler version if compiling from source None CUDA cuDNN version 9 0 7 0 5 15 1 GPU model and memory GeForce GTX 1060 6GB Exact command to reproduce,,"gunan,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa",2018-02-20 21:10:44,2018-03-01 20:53:19
PR,Clean up output formatting of saved model cli py,The output of saved model cli py was a bit hard to read so I added some indentation to make the variable graph information easier to take in at a glance Before I updated the documentation and unit tests accordingly I also fixed the formatting of some of the usage messages in saved model cli py,,frreiss,2018-02-24 01:04:21,2018-03-01 21:25:22
IS,Cannot import Tensorflow on a system that has anaconda installed though tensorflow installed successfully,I installed tensorflow on ubntu 16 04 by using Any help or suggestion on what should i do,,,2018-03-01 02:02:15,2018-03-01 21:30:22
PR,Scaffolding for int8 calibration in TF TRT,This PR prepares scaffolding for Int8 calibration pass for creating int8 TRTEngineOps It introduces TRTCalibOp which is used for collecting calibration information TRTInt8Calibratior implementing TRT calibration interface and forwards TF data to TRT engine TRTResourceManager and various simple resource constructs to keep data throughout op and session executions as well as steer TRT Calibration Some of these will be updated in subsequent PRs when calibration infrastructure matures This PR is intentionally kept minimal to reduce changes in upcoming PRs,,"samikama,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,samikama,samikama,samikama,aaroey,aaroey,aaroey,samikama,samikama,aaroey,aaroey,samikama,samikama,samikama,aaroey,aaroey,samikama,samikama,samikama,samikama,aaroey,samikama,samikama,samikama,aaroey,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,aaroey,samikama,aaroey,aaroey,aaroey,aaroey,samikama,aaroey,aaroey,samikama,samikama",2018-02-27 22:19:41,2018-03-02 01:20:54
IS,Very general question about tflite,Is the tensorflow lite always have quantized calculation and output Or it depends on the model is input type,,shivaniag,2018-03-01 04:53:51,2018-03-02 01:23:34
IS,Examples and tutorial missing from pip tensorflow package,After searching for and eventually posting a question on StackOverflow I was recommended to report this as a bug When installing Tensorflow e g tensorflow 1 5 0 cp36 cp36m manylinux1 x86 64 whl from from pip there is only the tutorials mnist example in tensorflow examples It would be nice to have the examples available without having to get them separately from GitHub Is there a reason why the rest of the examples are not included Can they be included in future releases,,"shivaniag,yifeif",2018-03-01 12:04:40,2018-03-02 01:27:40
PR,Added controlled logging to estimator py,Added logging every n iter argument to Estimator fit and train model to control the display of metrics e g loss and accuracy during training,,"selcouthlyBlue,selcouthlyBlue,protoget,martinwicke",2018-02-13 08:39:58,2018-03-02 01:30:21
PR,Fix markdown error in documentation,Newline in the middle of links was preventing their rendering,,,2018-02-28 22:44:57,2018-03-02 02:17:58
PR,Fix the error activation function link in custom estimators md,Described as PR title,,imsheridan,2018-03-01 18:00:31,2018-03-02 02:18:31
IS,Feature Request Training on device,Hi Tensorflow I would like to know whether Tensorflow does support on device training i e creation of model on Android device Right now Tensorflow provides Python script to generate model in the Native system and only inference we can execute on Android device Obviously i cannot execute the Python to create the model in Android does Tensorflow provides any Example Feature in C to train the model on device Android Feature Request 1 A Standalone C Application which can be cross compiled for Android to train the model from dataset 2 Training the model might be time consuming process if done on Android but at least some minimal support for smaller data set would be helpful Regards Senthil,,angersson,2018-02-28 14:58:20,2018-03-02 06:25:12
IS,Shape inference with dynamic shapes,I was wondering whether it is possible to use a variable as a placeholder for underspecified dynamic shapes Let is say the batch size is dynamic e g as a result from using tf Dataset batch which may produce an incomplete batch at the end of the dataset so we have an input of images of shape h w c Could not the shape inference procedure create an internal variable for such that it would be able to infer the other variables at least e g for functions like tf zeros like Sorry if this is off topic,,,2018-02-27 22:45:02,2018-03-02 13:57:45
IS,tf case is not allowing the computation of the default tensor when it falls in the default case,,,,2018-03-02 14:14:28,2018-03-02 14:18:59
PR,Add LINM Loop Invariant Node Motion optimization pass in GraphOptim,izer This change was inspired by LICM Loop Invariant Code Motion of compilers We observed from some public models e g seq2seq and tensor2tensor as well as some of our in house models that there are many invariant nodes including expensive MatMul nodes inside the loop body This optimization pass is to apply on Tensorflow computational graph to detect these invariant nodes and move them out of the loop body that is why we call it LINM Loop Invariant Node Motion Although there is already a LICM pass in XLA we still feel necessary to add this LINM pass in GraphOptimizer because 1 The XLA LICM pass is based on XlaWhile instruction but the conversion from loop nodes Enter Exit Switch Merge LoopCond of tf while to XlaWhile instruction is not hooked up yet topic xla dev IqLyL67cemI 2 We further found out that even if the conversion is hooked up it works only when all nodes inside the loop has XLA kernel registered It is a long way to go to get all operators supported by XLA 3 The LINM pass in GraphOptimizer is expected to work no matter whether XLA is on or off,,"benoitsteiner,benoitsteiner,eliben,eliben,ebrevdo,rmlarsen,benoitsteiner,benoitsteiner,benoitsteiner,benoitsteiner,martinwicke,benoitsteiner,benoitsteiner,martinwicke",2018-01-23 02:37:45,2018-03-02 16:26:32
IS,Memory leak in zeros like Tile,So I'm trying to figure out why my resnets are running out of memory and it seems that there is a memory leak in Tile and zeros like operations Those ops have memory allocated during each session run but there is no LOG MEMORY deallocation messages corresponding to them The sum of missing deallocations matches the amount of memory leaked as reported by allocator as max bytes in use accessed through tf contrib memory stats MaxBytesInUse op Here is a simplified repro at each sess run the memory grows by 1 15 GB until it crashes with OOM When I run it I see,,"yaroslavvb,yaroslavvb,reedwm,reedwm,yaroslavvb,yaroslavvb,yaroslavvb,reedwm,yaroslavvb,alextp,reedwm,alextp,reedwm,alextp,reedwm,yaroslavvb,dantkz,vrv,dantkz,yaroslavvb,dantkz,yaroslavvb,ebrevdo,yaroslavvb,zheng-xq,dantkz,yaroslavvb,ebrevdo,ebrevdo",2017-09-21 22:22:23,2018-03-02 16:47:27
IS,tf 1 6rc1 feed dict is slow on multi socket machines,It seems as if 1 6rc1 introduces a copy in feed dict on machines with 1 physical socket Similar to but this also happens if numpy array is aligned Fetching array from tensorflow then feeding it back in happens at single core memcpy speed Downgrading to 1 5 restores fast behavior 4x faster,,"yaroslavvb,yaroslavvb",2018-03-01 01:48:43,2018-03-02 19:42:06
PR,Branch 187471483,,,"caisq,caisq,caisq,benoitsteiner,caisq,benoitsteiner,caisq,terrytangyuan,caisq",2018-03-02 14:59:10,2018-03-02 20:04:30
IS,tensor valued seeds in tf data API can result in nondeterministic results,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary Source TensorFlow version use command below v1 5 0 11 g4588350f20 1 5 0 Python version 3 6 3 Bazel version if compiling from source 0 11 0 GCC Compiler version if compiling from source 7 2 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See code below Describe the problem The tf data API allows requires seeds to be provided that are tf tensor s This is an issue when the graph level seed has been set to 0 and the provided op level seed tensor takes on a value of 0 As noted in the comments in the code for tf get seed a 0 0 seed is problematic because the C ops assume this means nondeterminism Of course when a user is specifying these seeds they are expecting deterministic behaviour Unfortunately tf get seed only checks for this issue for the case where the seeds are ints not tensors See the code below for an example I would have been happy to submit a PR for this but I have no idea where the fix should be for this bug As I'm not especially familiar with the code base it is not apparent whether it is even possible to have the code for tf get seed to check the value of a tensor seed If not I'm guessing the tf data API would need to provide the checks Source code logs The following code reproduces the bug for me For the record I encountered this issue because I'm using an Iterator via Iterator from structure and when I use that iterator on a Dataset shuffle I get the same order for each epoch To get around this I provided the epoch number as a seed to Dataset shuffle with the first epoch being epoch 0 In my case I can avoid this bug by just starting the epoch count at 1 but it took me a while to track down and there may be other cases where the API is used in a similar way that would be problematic for those expecting deterministic results,,"angersson,mrry,mrry,mrry",2018-02-26 21:15:35,2018-03-02 20:05:14
PR,minor spelling tweaks for contrib verbs docs,,,brettkoonce,2018-03-02 05:03:11,2018-03-02 22:03:13
IS,Please explain what is going on in tf nn raw rnn function,I am trying to implement custom hidden state computation with a help of tf nn raw rnn function However using the API example provided I am receiving a strange message The line inputs ta inputs ta unstack inputs causes the message above and I wonder if this is actually a bug or am I doing something wrong completely The end result is that I am not getting the correct output shape because the next input comes as 32 100 into my linear transform function as if LSTM cell was never applied to it Please clarify whether raw rnn is usable under Tensorflow 1 5 0,,angersson,2018-03-02 13:47:49,2018-03-03 00:35:08
IS,The best way to pass the LSTM state between batches,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy System information The problem is independent of the system information I am using Tensorflow 1 5 Describe the problem I think I will be insane I am trying to find the best way to pass the LSTM state between batches I have searched everything but I could not find a solution for the current implementation Imagine I have something like Now I would like to pass the new state in each batch efficiently so without storing it back to memory and then re feed to tf using feed dict To be more precise all the solutions I found use sess run to evaluate new state and feed dict to pass it into init state Is there any way to do so without having the bottleneck of using feed dict I think I should use tf assign in some way but the doc is incomplete and I could not find any workaround I am writing this problem here since It is unsolved everywhere else and I think this should be in the doc since it is a common case scenario I want to thank everybody that will ask in advance Cheers Francesco Saverio,,angersson,2018-03-01 21:32:16,2018-03-03 00:59:51
IS,tf svd and matlab svd return different results with the same input Why,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 5 CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory Nvidia GTX 750 Ti 2G Describe the problem tf svd and matlab svd return different results with the same input Why Source code outputs TensorFlow tf svd TensorFlow demo code,,angersson,2018-03-02 06:28:26,2018-03-03 01:06:06
IS,Image retraining script memory problem and issue,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 6 gpu nightly gpu Python version 3 5 2 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 0 7 04 GPU model and memory Tesla K80 11441MiB Exact command to reproduce python retrain quantize py w certain parameters Describe the problem I was trying the new retrain script on my own model In order to fully convert quantized model to tflite 1 Different memory usage in different version I opened allow growth parameter in order to trace memory usage during training In tf gpu 1 6 0 Processes GPU Memory GPU PID Type Process name Usage 0 1673 G usr lib xorg Xorg 15MiB 0 15440 C python 302MiB But in tf nightly gpu Processes GPU Memory GPU PID Type Process name Usage 0 1673 G usr lib xorg Xorg 15MiB 0 15747 C python 4152MiB I was wondering what causes the tremendous difference in these two versions 2 Per the traceback below my retraining process could not be done in the last step Due to the feed dict issue I saw my process restart a session after 100 steps could the restart cause the loss of DecodeJPGInput tensor,,angersson,2018-03-02 05:00:35,2018-03-03 01:11:59
IS,map fn produces inconsistent results when using numpy vs tf constants,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Nope OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA 9 cudnn 7 GPU model and memory Quadro M1200 4GB Exact command to reproduce See below Describe the problem According to the map fn docs second example The output is 2 1 which is not what I expected since the input is the same numbers with the same shape The output should be the same Is there something special going on with numpy arrays Interesting read,,,2018-02-28 22:26:52,2018-03-03 03:50:00
IS,import tensorflow failed ImportError DLL load failed Even after install visual studio 2015 Microsoft Visual C 2015 Redistributable Update 3,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 win10 x64 TensorFlow installed from source or binary pip install upgrade tensorflow TensorFlow version use command below 1 6 0 Python version 3 6 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I was trying to install tensorflow cpu version on windows10 but always got error when import tensorflow I read the common installation problems common installation problems tried many solution I found on github stackoverflow etc I install visual studio 2015 visual studio 2017 Microsoft Visual C 2015 Redistributable Update 3 both 32 and 64 msvcp140 dll can find in both System32 and SysWow64 folder But still can not import tensorflow Is there something I missed out Source code logs import tensorflow error info,,gunan,2018-03-03 04:58:28,2018-03-03 08:28:08
IS,Tensorflow 1 6 0 cpu fails on import on Windows 10,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No problem appears on import import tensorflow as tf OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 x64 TensorFlow installed from source or binary binary pip no cache dir install upgrade tensorflow TensorFlow version use command below 1 6 0 install says tensorflow 1 6 0 cp36 cp36m win amd64 whl Python version 3 6 4 x64 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce import tensorflow as tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem When installing tensorflow 1 6 0 the import reports problems See log below Tried uninstalled r1 6 and reinstalled 1 5 0 to see if something else might be the problem 1 5 0 works like a charm Tried a clean install of 1 6 0 without any luck Ran the 'tensorflow self check py' script See log below Source code logs,,"angersson,gunan,fo40225,gunan",2018-03-02 21:31:05,2018-03-03 09:16:13
IS,TFLite Slice operation while using tf nn conv2d,input tf get variable input dtype tf float32 shape 1 256 256 3 kernel tf get variable kernel initializer 0 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 dtype tf float32 A tf nn conv2d input input filter kernel strides 1 1 1 1 padding SAME A tf nn softmax A output tf add A 1 name output I am trying to convert a simple model to tflite However I am hitting If you have a custom implementation for them you can disable this error with allow custom ops Here is a list of operators for which you will need custom implementations Slice Abort trap 6 Does conv2d internally calls Slice,,reedwm,2018-01-30 11:33:29,2018-03-03 14:08:32
PR,Enable validate args for all distributions based on a global parameter,The probability distributions in Tensorflow have a validate args argument that is initially set to False This PR adds a feature that initializes the value of validate args to the value of a global flag validate args default which can be set from the user program Rationale Currently when the user sets up the model incorrectly e g wrong parameter values are provided for the distributions or data values do not match the support for the distribution the program silently fails and produces nans in the output or worse wrong values The user has no way to debug this easily because validate args is False by default and manually adding validate args True while initializing each distribution can be tedious for the user Resolving 16839,,"alextp,jvdillon,alextp,jvdillon,ebrevdo,ebrevdo,jvdillon",2018-02-08 23:48:15,2018-03-03 16:48:24
IS,Improve transform graph tool dependencies,System information TensorFlow installed from source or binary source Is there any way we can improve this dependency chain The transform graph tool really shoud not need to know about kernel implementations as far as I can tell Perhaps the appropriate place to cut this is at tensorflow core tensorflow opensource Maintainer thoughts,,tadeegan,2018-02-13 01:28:33,2018-03-03 17:33:04
IS,how do TensorFlowInferenceInterface process image whose height not equal to width,I'm writing a java service using Spring boot and my tensorflow predict model was trained by python Tensorflo Object Detection API The model is FasterRCNN coco resnet the model can accept any shape whose height not equal to width such as 600x800 1280x720 of image in python while thing cannot be done like this in Java I read an example code written in Java from TensorFlowImageClassifier java the pre allocate buffers is inputSize inputSize If i changed that to inputHeight inputWidth and some other nessary code the inference process still went fine but recognize accuracy decrease dramatically Can anybody give some tips Here is my coding envirnoment Window 10 Tensorflow 1 5 build from whl CUDA 8 0 with cudnn 5 1 GPU nvidia 1080 ti 16GB Memory,,,2018-02-11 10:47:30,2018-03-03 18:06:34
IS,grappler memory optimizer fails with No output shape in Conv2DBackpropInput op Conv2DBackpropFilter op,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 5 0 0 g37aa430d84 Python version 3 5 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 1 7 GPU model and memory TITAN Xp 12196MiB Exact command to reproduce Describe the problem When I enable the memory optimizer in grappler it fails with the following errors My network is mostly a ResNet 34 I cannot share the complete code right now but I can try to come up with a reduced example if it is necessary Is this a limitation of the current memory optimizer or should the output shape always be known at this point in the code,,"reedwm,zhangyaobit,allenlavoie,allenlavoie,benoitsteiner,benoitsteiner,benoitsteiner",2018-02-01 17:53:48,2018-03-03 18:23:13
PR,Added an option to kernel to skip metropolis step,Fix 14221,,"jvdillon,jvdillon,langmore,langmore,jvdillon,martinwicke,martinwicke,martinwicke,martinwicke,yifeif,martinwicke,jvdillon,yifeif,jvdillon,jvdillon,jvdillon,yifeif,drpngx,ebrevdo,langmore,rmlarsen,langmore,langmore,martinwicke,jvdillon",2017-11-04 01:21:20,2018-03-03 20:08:46
PR,allow to run configure from a parent workspace,With this patch you can configure tensorflow directly using bazel Fixes 12761,,"Mistobaan,yifeif,angersson,case540,case540,vrv,gunan,vrv,vrv,Mistobaan,vrv,Mistobaan,gunan,yifeif,angersson,drpngx,gunan,gunan,case540,martinwicke,gunan,Mistobaan",2017-10-18 18:53:10,2018-03-04 01:14:00
IS,Dead link on versions page,On there is a link to This link is 404,,"angersson,MarkDaoust",2018-03-02 17:54:10,2018-03-04 05:17:49
PR,added CMake options to provide external zlib GRPC Eigen,Here are changes necessary to build tensorflow with different version of GRPC Protobuf Eigen zlib etc It is not possible to compile project using two different versions of protobuf for example To deal with that I have chosen approach similar to one in GRPC library Copy of issuecomment 343576192,,"mrry,mrry,gunan,drpngx,rmlarsen,drpngx,mrry,jhseu,martinwicke,drpngx",2018-01-18 03:52:23,2018-03-04 05:33:37
IS,Eager Allowing GPU memory growth,Since we do not have session in eager mode how can we allocate only as much GPU memory as needed in our program Or can we set the fraction of the overall amount of memory that each visible GPU should be allocated When will this feature be supported,,,2018-03-03 15:52:35,2018-03-04 06:42:14
PR,Branch 187691555,,,jhseu,2018-03-04 06:58:01,2018-03-04 08:20:36
PR,Allow passing Saver write version to 'evaluation once' and 'evaluatio,n loop' Thanks for the commit to add checkpoint file prefix check with default to SaverDef V2 However there are some pre trained slim models pre trained models which stored in SaverDef V1 format This will broken eval image classifier py for these models since there is no way to choose in slim evaluation py So a parameter write version is added for evaluation once and evaluation loop which allows programs like eval image classifier py could tell which format the checkpoint uses,,,2018-02-04 01:58:07,2018-03-04 11:47:39
IS,No registered 'ResizeBilinear' OpKernel for XLA CPU JIT,Similar to tf image resize images and its siblings have not been made available for XLA yet Is there a timeline for when core ops will be supported by XLA Is there a short instruction somewhere on how to implement ops kernels for the XLA bridge so we could do pull requests as needed to speed up development Related,,"carlthome,learyg,carlthome,carlthome,learyg,carlthome",2017-07-31 11:52:12,2018-03-04 12:12:30
IS,Feature request Adding scaffold parameter estimator heads,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 Python version 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem When creating custom estimators using the Heads defined here reduces an important part of the boilerplate as well as guarantee uniform evaluation against canned estimator instances However one key parameter is missing in in create estimator spec function which is the scaffold that one can pass into an EstimatorSpec One example where that is needed is if you want to initialize a large tensor with a numpy array for example for loading an embedding file from word2vec This StackOverflow question also describes the issue Source code logs This is my normal code currently impossible to use with heads Actually it might not be impossible but this seems to me like the cleaner solution I have the tiny PR ready if you think this is a valuable change Thanks a lot for your time,,"martinwicke,ispirmustafa,ispirmustafa,ispirmustafa",2018-02-13 20:21:47,2018-03-04 13:39:12
IS,Illegal instruction core dumped after running import tensorflow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 6 0 cp27 cp27mu manylinux1 x86 64 can only guess since python c import tensorflow as tf print tf GIT VERSION tf VERSION gives me an error already Python version Python 2 7 12 Exact command to reproduce import tensorflow I created a fresh virtual environment virtualenv p python2 test venv And installed tensorflow pip install upgrade no cache dir tensorflow import tensorflow gives me Illegal instruction core dumped Please help me understand what is going on and how I can fix it Thank you CPU information EDIT 2 Bazel version N A CUDA cuDNN version N A GPU model and memory N A After downgrading to an older version of tensorflow the error goes away I have been advised that my CPU see information above might not work with some improvements in the new API If this is the case I suppose there is no solution for my problem Therefore I will close this thread Feel free to correct me though Thank you for your support,,yaroslavvb,2018-03-04 10:45:05,2018-03-04 19:19:32
PR,Change repository command to valid value,When running the example command I got an error from docker saying docker invalid reference format repository name must be lowercase It seems that the repository name is written with capital letters This confused me and might confuse others By replacing TensorFlowImage with a valid repository the first command can also be run,,gunan,2018-02-24 21:23:21,2018-03-04 23:47:36
PR,Support fold batch norm for atrous conv2d,Fix 13990 As we can fold batch norm with convolution we should also fold batch norm with atrous convolution which has not been implemented,,"martinwicke,martinwicke,drpngx,drpngx,martinwicke,protoget",2017-10-26 09:42:39,2018-03-05 05:00:47
PR,Correct reporter name,,,martinwicke,2018-03-05 05:34:56,2018-03-05 05:51:29
PR,Correct capitalization,,,martinwicke,2018-03-05 06:27:58,2018-03-05 06:28:18
PR,Fix variable property of DropoutWrapper,Fix 15810,,"facaiy,ebrevdo,ebrevdo,facaiy,ebrevdo,facaiy,ebrevdo,facaiy",2018-01-09 05:59:31,2018-03-05 06:40:20
IS,OutOfRangeError see above for traceback box index has values outside 0 batch size,My issue is very similar to this one here issue 10618 I have been doing a multi GPU session and I get some weird behavior from Tensorflow My script only can finish its run in 1 out of 6 attempts and in each finished execution the result is slightly different from the single GPU execution mode unrepeatable error If the execution cannot finish most of the time it reports OutOfRangeError see above for traceback box index has values outside 0 batch size which is not supposed to appear for tensorflow 1 4 and above according to the issue above Moreover sometimes it would report InternalError see above for traceback Blas SGEMM launch failed m 14700 n 2048 k 1024 Any advice would be greatly appreciated thanks,,"angersson,angersson",2018-02-27 06:08:21,2018-03-05 07:53:59
IS,Using P100 on different generations of CPUs causes training to slow down on TF1 5,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 RedHat 7 3 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 Python version 2 7 Bazel version if compiling from source From yum installation GCC Compiler version if compiling from source 4 8 CUDA cuDNN version 7 0 5 GPU model and memory P100 PCIe 16GB Exact command to reproduce bazel build options bazel build config opt config cuda tensorflow tools pip package build pip package Source code logs Alexnet PSCPU GPU1 fp32 18 02 08 18 01 log Inception3 PSCPU GPU1 fp32 18 02 08 18 01 log Resnet50 PSCPU GPU1 fp32 18 02 08 18 01 log Hi all When I use tensorflow benchmark to the model performance will see the decreasing performance The following is the performance result of alexnet we can observe weird results in the performance will continue to decrease on Broadwell CPU Step Img sec total loss 1 images sec 2935 5 0 0 jitter 0 0 7 198 10 images sec 2934 3 0 9 jitter 2 8 7 201 20 images sec 2936 5 0 8 jitter 1 9 7 199 30 images sec 2936 5 0 6 jitter 2 2 7 201 40 images sec 2936 4 0 5 jitter 2 3 7 200 50 images sec 2935 4 1 1 jitter 2 5 7 199 60 images sec 2935 4 0 9 jitter 2 7 7 200 70 images sec 2935 4 0 8 jitter 3 0 7 202 80 images sec 2935 5 0 7 jitter 3 0 7 201 90 images sec 2935 7 0 7 jitter 3 6 7 200 100 images sec 2935 8 0 6 jitter 3 2 7 200 110 images sec 2936 0 0 6 jitter 3 7 7 198 120 images sec 2936 0 0 5 jitter 3 6 7 198 130 images sec 2936 0 0 5 jitter 3 3 7 199 140 images sec 2935 9 0 5 jitter 3 2 7 198 150 images sec 2936 2 0 4 jitter 3 2 7 198 160 images sec 2936 3 0 4 jitter 3 2 7 198 170 images sec 2936 1 0 4 jitter 3 3 7 199 180 images sec 2936 1 0 4 jitter 3 2 7 199 190 images sec 2936 1 0 4 jitter 3 2 7 199 200 images sec 2936 0 0 4 jitter 3 1 7 200 210 images sec 2936 1 0 4 jitter 3 1 7 199 220 images sec 2936 0 0 3 jitter 3 0 7 199 230 images sec 2935 9 0 3 jitter 3 1 7 199 240 images sec 2935 9 0 3 jitter 3 2 7 199 250 images sec 2935 9 0 3 jitter 3 2 7 199 260 images sec 2936 0 0 3 jitter 3 2 7 198 270 images sec 2936 0 0 3 jitter 3 1 7 199 280 images sec 2936 1 0 3 jitter 3 4 7 197 290 images sec 2936 3 0 3 jitter 3 6 7 198 300 images sec 2936 3 0 3 jitter 3 4 7 200 310 images sec 2936 4 0 3 jitter 3 4 7 199 320 images sec 2936 4 0 3 jitter 3 5 7 199 330 images sec 2936 4 0 3 jitter 3 5 7 198 340 images sec 2936 5 0 3 jitter 3 6 7 200 350 images sec 2936 5 0 3 jitter 3 7 7 200 360 images sec 2936 5 0 2 jitter 3 6 7 200 370 images sec 2936 5 0 2 jitter 3 7 7 200 380 images sec 2936 5 0 2 jitter 3 7 7 199 390 images sec 2936 6 0 2 jitter 3 7 7 199 400 images sec 2936 6 0 2 jitter 3 6 7 198 410 images sec 2936 7 0 2 jitter 3 6 7 200 420 images sec 2936 7 0 2 jitter 3 6 7 197 430 images sec 2936 7 0 2 jitter 3 6 7 198 440 images sec 2936 7 0 2 jitter 3 6 7 198 450 images sec 2936 7 0 2 jitter 3 6 7 198 460 images sec 2936 7 0 2 jitter 3 6 7 199 470 images sec 2936 6 0 2 jitter 3 5 7 200 480 images sec 2936 6 0 2 jitter 3 6 7 199 490 images sec 2936 6 0 2 jitter 3 6 7 196 500 images sec 2936 6 0 2 jitter 3 6 7 198 510 images sec 2936 6 0 2 jitter 3 6 7 199 520 images sec 2935 8 0 3 jitter 3 7 7 198 530 images sec 2933 9 0 7 jitter 3 8 7 200 540 images sec 2931 4 1 0 jitter 3 9 7 197 550 images sec 2925 7 1 9 jitter 4 0 7 197 560 images sec 2920 8 2 4 jitter 4 2 7 198 570 images sec 2916 1 2 7 jitter 4 3 7 199 580 images sec 2911 0 3 0 jitter 4 4 7 200 590 images sec 2903 0 3 7 jitter 4 6 7 196 600 images sec 2894 5 4 3 jitter 4 7 7 196 610 images sec 2887 1 4 7 jitter 4 8 7 200 620 images sec 2879 7 5 0 jitter 5 0 7 200 630 images sec 2872 6 5 3 jitter 5 2 7 199 640 images sec 2865 7 5 6 jitter 5 4 7 198 650 images sec 2852 2 6 5 jitter 5 6 7 197 660 images sec 2832 6 7 7 jitter 5 7 7 200 670 images sec 2814 1 8 6 jitter 5 8 7 198 680 images sec 2799 0 9 2 jitter 6 0 7 198 690 images sec 2785 8 9 7 jitter 6 1 7 200 700 images sec 2773 1 10 0 jitter 6 3 7 199 710 images sec 2760 9 10 4 jitter 6 5 7 198 9940 images sec 1442 7 4 2 jitter 84 0 7 197 9950 images sec 1442 6 4 2 jitter 83 8 7 196 9960 images sec 1442 6 4 2 jitter 83 6 7 197 9970 images sec 1442 6 4 2 jitter 83 4 7 197 9980 images sec 1442 6 4 2 jitter 83 3 7 197 9990 images sec 1442 6 4 2 jitter 83 0 7 197 10000 images sec 1442 3 4 2 jitter 83 0 7 198 But we test the same environment on Purley platform we could get the normal performance on training result Tensorflow img sec AlexNet InceptionV3 RenNet50 SKL P100 GPU x 1 2919 01 139 12 219 91 BWD P100GPU x 1 1441 96 77 87 120 8 What is the major problem on this strange results,,,2018-02-12 12:54:00,2018-03-05 08:25:05
IS,Get cudnn version 7005 while 7101 installed only,ubuntu 16 04 GTX 1080ti cuda 9 1 cudnn 7 1 1 libcudnn7 7 1 1 5 1 cuda9 1 amd64 deb libcudnn7 dev 7 1 1 5 1 cuda9 1 amd64 deb tensorflow 1 4 1 compiled from source with cuda 9 1 and cudnn 7 1 1 I have never downloaded or installed cudnn 7 0 5 locate libcudnn so 7 0 show nothing 2018 03 05 11 06 53 859047 E tensorflow stream executor cuda cuda dnn cc 378 Loaded runtime CuDNN library 7005 compatibility version 7000 but source was compiled with 7101 compatibility version 7100 If using a binary install upgrade your CuDNN library to match If building from sources make sure the library loaded at runtime matches a compatible version specified during compile configuration 2018 03 05 11 06 53 859249 F tensorflow core kernels conv ops cc 667 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo T algorithms Aborted core dumped,,,2018-03-05 03:34:40,2018-03-05 09:11:27
PR,fix todo make a class which constrcuts resource and provide get next,,,,2018-01-01 13:56:45,2018-03-05 12:03:03
IS,Tensorflow v1 4 0 rpc crash,I built tensorflow v1 4 0 from source code sometimes it crashed inside kernel This happened on both Linux and Windows platform Linux call stack Both indicating that tensorflow rpc framework may have some bug,,"aselle,mrry,mrry,drpngx,mrry",2017-11-24 03:08:47,2018-03-05 15:48:08
IS,CMake option for C API,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 x64 TensorFlow installed from source or binary Source TensorFlow version use command below branch r1 6 Python version 3 4 Bazel version if compiling from source 1 7 4 GCC Compiler version if compiling from source Visual Studio 2015 MSVC 14 CUDA cuDNN version Only CPU GPU model and memory Only CPU Exact command to reproduce cd tensorflow contrib cmake cmake gui Hi I'm using CMake to build the library on Windows everything works well but I would like to make a very tiny library with C API only is that possible to do this from CMake Thanks very much,,"mrry,mrry",2018-02-07 08:13:05,2018-03-05 16:02:14
PR,Add default whl file location and minor update comments,Hi after trying these dist test scripts open this PR for local test sh need a required arg WHL FILE LOCATION Add default whl file location URL Update comments and README PTAL thanks,,"ScorpioCPH,ScorpioCPH,ScorpioCPH",2018-03-01 08:30:17,2018-03-05 16:52:45
IS,Compilation error when building tfcompile on Windows Visual Studio 2017,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64bit TensorFlow installed from source or binary Source TensorFlow version use command below master 926fc13f7378d14fa7980963c4fe774e5922e336 Python version Python 3 6 2 Anaconda Inc Bazel version if compiling from source 0 10 GCC Compiler version if compiling from source Microsoft R C C Optimizing Compiler Version 19 12 25835 for x64 CUDA cuDNN version none GPU model and memory none Exact command to reproduce bazel build config opt tensorflow compiler aot tfcompile Describe the problem Trying to build tfcompile on Windows using the instructions at and results in a compilation error Source code logs See attached file for the complete bazel log,,"rongjiecomputer,rongjiecomputer",2018-02-09 00:15:40,2018-03-05 17:56:02
IS,cmake test fail on Windows,,,,2018-02-18 12:59:57,2018-03-05 20:21:06
IS,Module not found tensorflow Running Docker Jupyter OSX,After installing docker I attempted to run tensorflow in Jupyter My run command was LewIss MacBook Pro MyTensorFlow lewleib docker run it p 8888 8888 p 6006 6006 v Users lewleib MyTensorFlow notebooks tensorflow tensorflow In the Jupyter notebook I ran This resulted in ModuleNotFoundError No module named 'tensorflow' I have tried starting in different directories and added prefix gcr io with the same results Thanks,,,2017-10-13 16:17:28,2018-03-05 20:30:38
PR,Add alternative paths for CUDA installation,This detects negativo17 is CUDA packages for Fedora I tried following the feedback in 15614 so I added alternative paths and avoided adding questions to the configure script,,"pwnall,gunan,pwnall,pwnall,pwnall,pwnall,pwnall,gunan,pwnall",2018-01-23 10:29:37,2018-03-05 21:18:59
PR,Update CUDA capability to 3 5 when install from binary in documentation,This fix tries to address the issue raised in 17445 The minimal CUDA capability is 3 5 for Linux install from binary though the documentation only specifies 3 0 This fix updates the docs to 3 5 for binary install This fix fixes 17445 Signed off by Yong Tang yong tang github outlook com,,"yongtang,av8ramit",2018-03-05 19:43:38,2018-03-05 21:31:20
PR,Lite Supporting Raspberry Pi,Now we can cross compiling or native compiling libtensorflow lite a for rpi 1 Fix istring' does not name a type error by adding its namespace 2 Remove unnecessary space between CC PREFIX and gcc 3 Adding O3 DNDEBUG CFLAGS same as CXXFLAGS 4 Remove redundant lpthread link flag 5 Add Makefile for RPi,,"aselle,aselle,aselle,freedomtan,freedomtan,freedomtan,petewarden,aselle",2018-01-26 02:31:09,2018-03-05 21:41:51
PR,Branch 187892975,,,akshaym,2018-03-05 19:54:35,2018-03-05 23:51:27
PR,Deprecation of the LXD PPAs,LXD PPAs are deprecated at the end of 2017 and need to use the official backports in the Ubuntu archive Signed off by Yihong Wang yh wang ibm com,,yongtang,2018-03-05 23:36:02,2018-03-06 00:30:49
IS,Will tf Lite have GPU support if the answer is yes the compute API will be which one OpenCL or gles,,,"aselle,aselle",2018-01-17 10:44:42,2018-03-06 01:20:08
IS,Tensorflow Unit Test tensorflow python kernel tests depthtospace op test TIMEOUT,System Information Linux ppc64le GNU Linux commit id 3fe5fa08dbed8134ad400f03be474aeb39bcc922 Python 2 7 5 Bazel Build label 0 5 4 non git gcc version 4 8 5 20150623 Red Hat 4 8 5 16 GCC cuda 9 0 NVIDIA GPU driver command to reproduce bazel test tensorflow python kernel tests depthtospace op test Failure log pci bus id 0003 01 00 0 compute capability 6 0 2017 12 06 08 58 27 675099 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla P100 SXM2 16GB pci bus id 0007 01 00 0 compute capability 6 0 2017 12 06 08 58 27 699874 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla P100 SXM2 16GB pci bus id 0003 01 00 0 compute capability 6 0 2017 12 06 08 58 27 699885 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla P100 SXM2 16GB pci bus id 0007 01 00 0 compute capability 6 0 Terminated,,reedwm,2017-12-06 11:57:39,2018-03-06 06:45:08
IS,Running model failed Not found FeedInputs unable to find feed output,My platform is win10 with GPU visual studio 2015 Application tracking object My code as following auto place1 Placeholder root WithOpName Placeholder 1 tensorflow DataType DT UINT8 auto place2 Placeholder root WithOpName Placeholder 2 tensorflow DataType DT FLOAT auto place3 Placeholder root WithOpName Placeholder 3 tensorflow DataType DT INT32 unsigned unsigned char data1 6 auto mapped place1 Eigen TensorMap Eigen Tensor unsigned char 4 Eigen RowMajor MergeMatFloat data 2 outputSize outputSize 3 auto eigen place1 Eigen Tensor unsigned char 4 Eigen RowMajor mapped place1 Tensor place1 tensorflow DT UINT8 tensorflow TensorShape 2 outputSize outputSize 3 place1 tensor unsigned char 4 eigen place1 float data2 2048 0 auto mapped place2 Eigen TensorMap Eigen Tensor float 2 Eigen RowMajor data2 0 4 2 auto eigen place2 Eigen Tensor float 2 Eigen RowMajor mapped place2 Tensor place2 tensorflow DT FLOAT tensorflow TensorShape 4 2 place2 tensor float 2 eigen place2 std vector int data3 1 auto mapped place3 Eigen TensorMap Eigen Tensor int 1 Eigen RowMajor data3 0 1 auto eigen place3 Eigen Tensor int 1 Eigen RowMajor mapped place3 Tensor place3 tensorflow DT INT32 tensorflow TensorShape 1 place3 tensor int 1 eigen place3 std vector Tensor outputs Status run status session Run Placeholder 1 place1 output layer outputs which give message Running model failed Not found FeedInputs unable to find feed output Placeholder 1 what should i do my frozen pb is like this looks strange i do not know what node shold i select as the input Placeholder Placeholder 1 Placeholder 2 Placeholder 3 fifo queue fifo queue EnqueueMany fifo queue DequeueMany n fifo queue DequeueMany Reshape shape Reshape Reshape 1 shape Reshape 1 sub y sub re3 conv1 W conv Initializer random uniform shape gradients re3 Adam beta1 losses total loss tags re3 1 conv1 summaries W conv Rank save Assign 47 test robustness tags who know this appreciation,,,2018-03-05 09:21:46,2018-03-06 07:43:19
PR,Windows Enable tensorflow contrib in Bazel build,This change requires upgrading Bazel to 0 10 0 because we need cc import rule I disabled all failing tests on Windows I will send issues to their owner later and write some tips about how to reproduce and test them FYI,,"meteorcloudy,gunan,gunan,meteorcloudy,martinwicke,laszlocsomor,gunan,martinwicke,meteorcloudy,meteorcloudy,yifeif,meteorcloudy,gunan,miaout17,meteorcloudy,meteorcloudy,gunan",2018-02-01 14:03:33,2018-03-06 07:47:33
PR,add checking for input values in GANHead constructor,,,"joel-shor,caisq,caisq",2018-01-03 08:29:36,2018-03-06 09:56:10
IS,Retrain py script failing with nan error at random without any code changes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Working on a notebook with MacOS High Sierra v10 13 1 in a Docker container using Ubuntu 16 04 3 TensorFlow installed from source or binary Source TensorFlow version use command below 1 5 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version Using CPU GPU model and memory Exact command to reproduce,,angersson,2018-02-25 08:20:20,2018-03-06 13:31:20
IS,Could not find a version that satisfies the requirement tensorflow gpu from versions,Can anyone help with this I tried quite a few times even wiped the computer and started from scratch Environment CPU Intel i7 Memory 16GB OS Windows 10 64bit Nvidia GTX 1060 latest driver installed 390 77 desktop win10 64bit international whql Visual Studio Community CUDA 8 0 for Windows 10 cuDNN 5 1 for CUDA 8 0 Python 3 6 4 I have a few versions available on local hard drive but all of them are giving me the same error message tensorflow 1 5 0 cp36 cp36m win amd64 whl tensorflow 1 6 0rc1 cp35 cp35m win amd64 whl tensorflow 1 6 0rc1 cp36 cp36m win amd64 whl By running python c from pip import pep425tags print pep425tags supported tags 'cp36' 'cp36m' 'win32' 'cp36' 'none' 'win32' 'py3' 'none' 'win32' 'cp36' 'none' 'any' 'cp3' 'none' 'any' 'py36' 'none' 'any' 'py3' 'none' 'any' 'py35' 'none' 'any' 'py34' 'none' 'any' 'py33' 'none' 'any' 'py32' 'none' 'any' 'py31' 'none' 'any' 'py30' 'none' 'any',,,2018-02-23 11:14:32,2018-03-06 15:15:28
PR,Windows Use cc import to import python lib properly,Previously we put python lib in data attribute of a cc library and manually added the link option That caused the build to be non hermetic This change fixed the problem,,meteorcloudy,2018-03-06 10:21:42,2018-03-06 17:48:01
PR,Updating the cuda compute info and avx info for Windows,,,"av8ramit,av8ramit",2018-03-05 20:52:43,2018-03-06 17:49:28
PR,Branch 188037439,,,"akshaym,akshaym",2018-03-06 18:14:55,2018-03-06 18:35:15
IS,Precision in tf gradients changed in 1 6 vs 1 6,System information Try the following code using different values for the infinitesimal 1e 15 The issue is that in tf 1 6 a small infinitesimal 1e 15 was enough to avoid nan in tf gradients due to 1 sqrt 0 0 For some reason in tf 1 6 this is returning a nan for anything less than 1e 13 which produces an unacceptable error in the result OS Platform and Distribution e g Linux Ubuntu 16 04 OSX pip and pip3 tf 1 6 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 6 0 0 gd2e24b6039' '1 6 0' Python version 2 7 and 3 3 CUDA cuDNN version CPU Exact command to reproduce See script above Describe the problem In versions of tensorflow previous to 1 6 this code would not issue a nan gradient for reasonable infinitesimals 1e 26 Suddenly the way numerical precision is handled in the gradient computation has obviously changed and changed in a way which is clipping things near zero and doing so differently depending on if colocation of gradients is requested Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,yaroslavvb,2018-03-06 02:02:00,2018-03-06 18:40:05
IS,Tensorflow Lite Support for Raspberry PI,Describe the problem Are you planning to support Tensorflow Lite on Raspberry Pi Specifically Raspberry Pi 3,,"aselle,aselle",2017-11-15 17:13:20,2018-03-06 21:23:01
IS,Documentation correction,Hi I think there might be a possible documentation error in that of tf stack It is said that the numpy equivalent is np asarray But np asarray will take lists of arbitrary shapes and makes it to a ndarray whereas tf stack requires all the dimensions of objects in the list to be same So the equivalent ideally would be np stack Cheers Ramana,,"aselle,aselle",2017-09-22 20:37:06,2018-03-06 21:24:43
IS,Dataset API 'flat map' method producing error for same code which works with 'map' method,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 6 0 Python version 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 0 GPU model and memory GeForce GTX 860M Exact command to reproduce dataset dataset flat map lambda file name tf py func get data for dataset file name tf float64 You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I am trying to create a create a pipeline to read mulitple CSV files using TensorFlow Dataset API and Pandas However using the 'flat map' method is producing errors However if I am using 'map' method I am able to build the code and run it in session This is the code I am using Source code logs I get the following error map func must return a Dataset object It would also great if you could provide documentation on using Dataset API with Pandas module,,"carlthome,carlthome,carlthome,mrry",2018-03-04 16:30:06,2018-03-06 22:02:02
IS,Error while running Tensor Flow examples using Bazel build,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Ubuntu 16 04 TensorFlow installed from source TensorFlow version 1 4 0 Python 3 5 2 Bazel version 0 8 1 gcc version 5 4 1 CUDA cuDNN version GeForce GTX 980M and 8GB bazel build tensorflow examples label image I am trying to run this by using the command bazel build tensorflow examples label image but i am getting the following error,,"drpngx,drpngx",2017-12-10 07:02:16,2018-03-06 22:29:12
IS,want keras to work on GPU but actually on CPU,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from anaconda Keras installed from pip TensorFlow version 1 4 1 Bazel version None CUDA cuDNN version CUDA V7 5 17 CuDNN v6 0 GPU GeForce GeForce GTX 1050 Ti 3 94GB Code mnist mlp py When run the code it shows the following log Using TensorFlow backend 2018 01 25 17 31 16 572013 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2018 01 25 17 31 16 679268 I tensorflow stream executor cuda cuda gpu executor cc 892 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 01 25 17 31 16 679499 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name GeForce GTX 1050 Ti major 6 minor 1 memoryClockRate GHz 1 468 pciBusID 0000 01 00 0 totalMemory 3 94GiB freeMemory 3 46GiB 2018 01 25 17 31 16 679513 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1050 Ti pci bus id 0000 01 00 0 compute capability 6 1 Have no idea why it shows 2018 01 25 17 31 16 679268 I tensorflow stream executor cuda cuda gpu executor cc 892 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero And the code is actually running on the CPU although the log shows the info of GPU What have tried stackoverflow,,"tatianashp,tatianashp",2018-01-26 01:43:36,2018-03-07 00:15:45
IS,getting error while running my model tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,jart,2018-03-05 17:54:45,2018-03-07 00:49:10
IS,Expectations of MonitoredTrainingSession for saving and restoring fixes inside,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No anything discussed here is valid with the cifar10 model script OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 but should be platform independent TensorFlow installed from source or binary Binary TensorFlow version use command below 1 5 Python version 3 5 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 7 GPU model and memory Exact command to reproduce Describe the problem MonitoredTrainingSession is the simplest and to my knowledge often recommended way to run a training session that can easily be saved and restored I think there is some confusion here that could be cleared up by fixing two things 1 MonitoredTrainingSession does not restore the global step If one creates a step with tf train get or create global step and even if this is passed into the optimizer MonitoredTrainingSession will not restore the correct value in a new session Instead it starts it again from 0 This has been mentioned several times here are some references The only solution that I have found works is to extract the step from the checkpoint filename manually and add an operation to set it on restore via something like step int os path basename ckpt model checkpoint path split ' ' 1 It would be great if this could be fixed so global steps are properly restored as well 2 Instead of checkpoint dir as an argument MonitoredTrainingSession should probably have a save checkpoint dir and a restore checkpoint dir The reason why this is important is that TensorBoard does not support appending to summary files This means that a restored session to my knowledge can only be viewed in TensorBoard if a new directory is used to write the new event files instead of the directory it was restored from If that is not done TensorBoard simply strips the events away and does not display them It took me time to understand this was what was happening Unfortunately MonitoredTrainingSession does not support a different save directory at the moment so the way to make MonitoredTrainingSession work with TensorBoard on restore is to create your own summary hooks But this defeats part of what MonitoredTrainingSession is supposed to do for you I believe this would be fixed with different save and restore directory as specified above A comment about how a different save directory is needed for TensorBoard visualization would also be helpful in the MonitoredTrainingSession documentation,,jart,2018-02-27 13:06:16,2018-03-07 00:53:58
IS,Save activation map for a specific convnet in the process of tf train MonitoredTrainingSession,ADDING FEATURES System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 4 0 19 ga52c8d9' '1 4 1' Python version 2 7 anaconda Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Quadro K400 Exact command to reproduce Describe the problem I followed this tutorial from the source code of TF model tutorials image cifar10 in the tutorial you used tf train MonitoredTrainingSession to log the checkpoint or tensor for future usage with TensorBoard my question is to display the activation maps of my convnet during training process But inside the while not mon sess should stop mon sess run train op I can not add new tensor because the Graph is finalized So I want to ask you how to add something like tf summary image Pass one example image to a specific convnet after relu and save it as png for all the filters I think I can easily implement this in a normal tf Session but I am still interested if we can do it in tf train MonitoredTrainingSession I think that would be great for the newbie to understand what happened for our CNN Thanks in advance,,asimshankar,2018-02-28 13:30:35,2018-03-07 00:55:19
PR,Branch 188075262,Small merge conflict in tensorflow contrib timeseries python timeseries BUILD to disable a test for msan and on windows,,akshaym,2018-03-06 22:11:42,2018-03-07 01:15:55
IS,C api use of op Attrs methods in gradients,The generated op Attrs struct returns new instances on its chainable methods and does not change the original object L701 There are a few related issues e g L164 where the code assumes the underlying object is being mutated and the parameters do not actually pass through I guess there might be a couple of ways forward depending on how Tensorflow prefers the C API 1 Decide the Attrs chaining methods mutate the underlying object and fix the code generation 2 Decide the Attrs chaining methods return new instances and fix the uses Suggestions Fwiw if option 2 it might be nice to add TF MUST USE RESULT to the generated API Unfortunately a long standing bug in gcc means this may be unreliable as an actual error across versions of gcc that contributors may use cc,,"kbsriram,keveman,kbsriram",2018-03-01 16:26:37,2018-03-07 01:17:02
IS,tf keras estimator estimator from model does not respect options set in RunConfig,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below tf VERSION 1 4 0 tf GIT VERSION v1 4 0 rc1 11 g130a514 Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory NVIDIA Tesla M60 8 GB Exact command to reproduce See Below Describe the problem When trying to use an estimator that is derived from,,"shivaniag,yifeif,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa,yifeif,yifeif",2017-11-22 00:35:51,2018-03-07 01:17:02
PR,Tensorrt improvements,This PR improves the TF TensorRT integration and provides FP16 and INT8 TensorRT engine support Calibration mechanism for INT8 engines Expanded op support User configurable graph partition size threshold,,"samikama,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,samikama,jjsjann123,samikama,aaroey,aaroey",2018-03-02 23:52:38,2018-03-07 01:57:13
IS,Documentation for LSTMStateTuple is misleading,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No TensorFlow installed from source or binary no TensorFlow version use command below 1 5 The documentation for LSTMStateTuple states that Stores two elements c h in that order Where c is the hidden state and h is the output The property naming is very confusing It suggests that h is the h idden state but the documentation contradicts this intuition,,facaiy,2018-02-19 16:19:27,2018-03-07 10:40:49
IS,SVD gradient is unstable for non unique singular values,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 5 0 10 g5b10b34' '1 5 0' Python version Python 2 7 6 Bazel version if compiling from source 0 11 0 GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version 8 0 6 0 GPU model and memory GeForce GTX 970 4GB Exact command to reproduce Describe the problem The gradient of SVD becomes nan when singular values are not unique From the code L332 L342 it is clearly visible that f becomes inf for equal singular values I briefly skimmed through the paper but could not find an explanation for this behaviour Can someone give an intuitive example why the gradient for similar singular values should not be defined Similar singular values commonly appear for estimation of rotation matrices all singular values become 1 At the moment it is impossible to use SVD for such a case Alternative implementations of the SVD gradients based on the same paper are which circumvent this problem by simply replacing the nan s or effectively setting them to 0 Could this be used alternatively to the current implementation that just divides by 0 Or alternatively just add a small epsilon to the difference of singular values Btw I think that no gradient computation in TensorFlow should ever return faulty gradients but raise an error message to simplify debugging I do not see the point of using nan or inf gradients,,"yaroslavvb,shoyer,shoyer,yaroslavvb",2018-03-06 11:27:37,2018-03-07 12:33:55
IS,tf contrib data tf slim training pipeline raise GetNext failed because the iterator has not been initialized,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce cat etc issue Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 8 0 0 clang 800 0 42 1 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow serving api 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 3 0 rc2 20 g0787eee' '1 3 0' Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request init fn of slim learning train does not init the tf contrib data Iterator properly Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem L148,,,2017-11-30 16:29:39,2018-03-07 13:45:45
PR,Support configure help h to show possible config options,This is to fix 16518 which would start the interactive prompt immediately even when issue configure help h The fix is to show the possible bazel config options when the help h commands issued Feel free to comment if any we needs to further improve,,"imsheridan,case540,imsheridan,case540,imsheridan",2018-01-30 05:31:47,2018-03-07 14:07:39
IS,Problem with the tensorflow installation,I'm having problems installing the cpu only version of tensorflow for this I use pip3 my OS is w10 I tried it with python 3 6 4 and 3 5 2 and in no case did it work here is the error that generates me besides the response to the script whose answer I do not understand tells me that I do not have the dll is and all those things but I installed was the version of only CPU are these files required ah and yes I installed it with administrator permissions both the python and the tensorflow import tensorflow as tf Traceback most recent call last File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 994 in gcd import File frozen importlib bootstrap line 971 in find and load File frozen importlib bootstrap line 955 in find and load unlocked File frozen importlib bootstrap line 658 in load unlocked File frozen importlib bootstrap line 571 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 219 in call with frames removed ImportError DLL load failed Error en una rutina de inicializaci n de biblioteca de v nculos din micos DLL During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File pyshell 5 line 1 in module import tensorflow as tf File C Program Files Python36 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Program Files Python36 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 994 in gcd import File frozen importlib bootstrap line 971 in find and load File frozen importlib bootstrap line 955 in find and load unlocked File frozen importlib bootstrap line 658 in load unlocked File frozen importlib bootstrap line 571 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 219 in call with frames removed ImportError DLL load failed Error en una rutina de inicializaci n de biblioteca de v nculos din micos DLL During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help ERROR Failed to import the TensorFlow module WARNING This script is no longer maintained Since TensorFlow 1 4 the self check has been integrated with TensorFlow itself and any missing DLLs will be reported when you execute the import tensorflow statement The error messages printed below refer to TensorFlow 1 3 and earlier and are inaccurate for later versions of TensorFlow Python version is 3 6 TensorFlow is installed at C Program Files Python36 lib site packages tensorflow Could not load 'cudart64 80 dll' The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 8 0 from this URL Could not load 'nvcuda dll' The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Typically it is installed in 'C Windows System32' If it is not present ensure that you have a CUDA capable GPU with the correct driver installed Could not load 'cudnn64 5 dll' The GPU version of TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Note that installing cuDNN is a separate step from installing CUDA and it is often found in a different directory from the CUDA DLLs You may install the necessary DLL by downloading cuDNN 5 1 from this URL Could not find cuDNN,,,2018-03-07 06:33:34,2018-03-07 14:21:53
IS,Failed to Create Session CUDA ERROR UNKNOWN,Failed to create session Error info E tensorflow core common runtime direct session cc 170 Internal failed initializing StreamExecutor for CUDA device ordinal 0 Internal failed call to cuDevicePrimaryCtxRetain CUDA ERROR UNKNOWN Traceback most recent call last File stdin line 1 in module File home ubuntu envs tensorflow local lib python2 7 site packages tensorflow python client session py line 1482 in init super Session self init target graph config config File home ubuntu envs tensorflow local lib python2 7 site packages tensorflow python client session py line 622 in init self session tf session TF NewDeprecatedSession opts status File home ubuntu envs tensorflow local lib python2 7 site packages tensorflow python framework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl InternalError Failed to create session System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip TensorFlow version use command below tensorflow gpu 'v1 4 0 19 ga52c8d9' '1 4 1' Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory Tesla M40 24GB Exact command to reproduce N A,,qmick,2018-01-17 03:35:28,2018-03-07 15:52:53
IS,Feature Request tf assign support tuples,I have recently updated to V1 3 of Tensorflow I have some code that I use for dynamic rnn which copies the STATE of the cell so it persists to the next run I can also INIT that value as well Since the update I am getting a WARNING tensorflow tensorflow python ops rnn cell impl LSTMCell object at 0x7f278c196940 Using a concatenated state is slower and will soon be deprecated Use state is tuple True I have tried to enable state is tuple but then the assign commands fail as they do not support the tuple structures I have an open StackOverflow question with the details Since it seems like the RNN core is moving in the direction of the tuple for the state it would be nice if the assign can handle this transparently,,"ebrevdo,ebrevdo,reedwm,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-10-06 21:13:57,2018-03-07 16:33:55
IS,Documentation links for version 1 5 silently redirect to 1 6,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 Python version 3 5 2 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 0 GPU model and memory NVIDIA Titan X Exact command to reproduce Go to Describe the problem The Python and C API Documentation links at silently redirect you to documentation for version 1 6 The links are I assume correct but the URLs and redirect to and respectively I spent a while trying to diagnose a problem based on the documentation for 1 6 without realizing I was looking at 1 6 rather than 1 5 Turns out the problem was caused by an API change between 1 5 and 1 6 Source code logs N A,,MarkDaoust,2018-03-02 22:50:07,2018-03-07 18:18:48
IS,rolling window batch operation for tf data Dataset,This is a feature request For Datasets that represent a sequence or time series it can be useful to have a Dataset op that creates a rolling window batch over the given Dataset For example if I have a tf data Dataset whose elements represent a time series line breaks separate elements This operation will be extremely useful for extracting sub sequences from a time series for training RNNs and Reinforcement Learning models,,"aselle,mrry,carlthome,facaiy",2017-12-01 17:14:14,2018-03-07 19:11:07
PR,add rolling window batch operation for tf data Dataset,Resolve 15044 implementation The PR proposes a slide method for Dataset Groups elements in fixed size blocks by passing a sliding window over Dataset It behaves like batch in fact batch n slide n n I failed to move c implementation from core to contrib Any help will be appreciated how to test x add test case x pass all tests,,"facaiy,mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,carlthome,facaiy,facaiy,drpngx,facaiy,mrry,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,drpngx,facaiy,facaiy",2018-01-15 06:48:28,2018-03-07 19:11:07
IS,Not thread safe about saved model loader load latency microsecs,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce cat etc issue Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 8 0 0 clang 800 0 42 1 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin MTL PengYu 16 7 0 Darwin Kernel Version 16 7 0 Wed Oct 4 00 17 00 PDT 2017 root xnu 3789 71 6 1 RELEASE X86 64 x86 64 check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow serving api 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 3 0 rc2 20 g0787eee' '1 3 0' Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I'm having a log in tensorflow serving the number is so big so it should be wrong Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-03-07 19:22:08,2018-03-07 22:18:03
PR,Branch 188191091,o Small BUILD file change needed to be fixed,,akshaym,2018-03-07 18:43:18,2018-03-07 22:38:13
PR,Fix error ConvNDLSTMCell does not pass name parameter,If I create a ConvNDLSTMCell in tensorflow contrib rnn name parameter cannot be passed through ND ConvLSTMCell classes So simply fix it,,,2018-03-01 07:04:50,2018-03-07 22:42:05
PR,Branch 188235030,,,jhseu,2018-03-07 22:48:21,2018-03-07 23:29:57
IS,SpaceToDepth for DT HALF is not supported on GPU,space to depth can be placed on GPU for float32 but there is no a GPU kernel for float16,,yongtang,2017-11-25 00:01:43,2018-03-08 00:21:04
PR,Add DT HALF support for SpaceToDepth on GPU,This fix tries to address the issue raised in 14871 where there were no DT HALF support for SpaceToDepth on GPU This fix adds DT HALF support on GPU and adds aditional test cases This fix fixes 14871 Signed off by Yong Tang yong tang github outlook com,,"yongtang,josh11b,yongtang,yongtang,drpngx,yongtang",2017-11-25 01:40:06,2018-03-08 00:21:04
PR,MKL Removing unnecessary check for reorder,Fixes failure in tensorflow python keras pooling test F tensorflow core kernels mkl input conversion op cc 450 Check failed tf input CheckReorderToOpMem memory primitive desc output mkl md cpu engine tensor out net true 0 vs 1,,claynerobison,2018-03-02 21:12:32,2018-03-08 00:28:19
PR,Add scan command to saved model cli to check for security sensitive ops,,,yifeif,2018-03-08 00:52:21,2018-03-08 00:57:37
PR,MKL Optmized Relu by in place computations,Using OpKernelContext forward input or allocate output,,"mdfaijul,tatianashp,mdfaijul",2018-03-06 17:54:38,2018-03-08 01:15:22
PR,memmap changes,andrewharp Here is the new PR with changes as discussed in 12922,,"andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,martinwicke,martinwicke,andrewharp,drpngx,drpngx,drpngx,jhseu",2017-11-08 08:02:15,2018-03-08 02:11:53
PR,Merge r1 6 back to master,,,yifeif,2018-03-07 22:48:40,2018-03-08 02:18:30
IS,Screen goes black CUDA ERROR UNKNOWN on TensorFlow GPU 1 5,Machine specs Operating System Windows 7 64 bits TensorFlow version 1 5 0 Python version 3 6 Anaconda CUDA cuDNN version CUDA 9 0 cudNN 7 0 5 GPU model and memory Quadro K2000 2GB Note GPU is also driving the display While testing my demo runs well until the screen goes black for a short instant of time and it crashes with the following error message I tried for several days different ideas from different issues Checked carefully the video tutorial from youtube nvidia installation manual etc Reinstalled cuda cudnn Downgrade tf cuda cudnn Could you suggest any method to detect what is wrong and how to solve the problem Post data Code works fine on tensorflow without GPU,,,2018-02-27 08:59:41,2018-03-08 03:01:54
IS,An easy problem about tensorflow GPU unilization,Today I run an easy RNN model to deal with a NLP task which the traindata is just about 4000 short sentences and the iteration is 30 However the time cost about 1 hour to finish the procedure my computer GPU is nvidia 1080Ti and CPU is i7 8700K In the console the information is Total memory 10 91GiB Free memory 10 30GiB but in the terminal i use the command nvidia smi l it return another information 10713MiB 11171MiB my question are 1 Does the GPU really work 2 if work why the time cost still large Thx,,"shivaniag,reedwm",2017-12-31 09:05:20,2018-03-08 03:08:53
PR,add error message when importing contrib tensorrt without libnvinfer,,,"jjsjann123,aaroey,aaroey,aaroey,aaroey,jjsjann123,gunan,jjsjann123,aaroey,jjsjann123,yifeif,aaroey,yifeif,gunan,jjsjann123,aaroey,jjsjann123,jjsjann123,yifeif,jjsjann123",2018-03-07 19:47:03,2018-03-08 03:20:55
PR,remove annoying print of tensor for ValueError,I ran into this ValueError while using the tf data Dataset and I had to wait for my 3e6 2 shape Tensor to print out before I saw the error message I think it would be better to get rid of this and just print the shape mismatch Thanks,,,2018-03-08 05:18:52,2018-03-08 05:30:31
IS,How to add a user ops to android so file,Discription I want to add a custom op for tensorflow and use it in android app But I find it only tell us how to add an op in python I put my own cc file witch contains register code into the user ops folder and bazel build again to generate a new so file But when I test this so in android code It says the custom op is not registered and crashed How can I succeed to register a new op and build it into the android so file And I found that there are two folder named user ops tensorflow tensorflow user ops and tensorflow tensorflow core user ops witch folder should I put my ops in Hope for your answer Thank you so much System information Tensorflow r1 2 Source code logs image image image,,drpngx,2017-09-05 07:11:15,2018-03-08 06:04:06
PR,Merge 1 6 back to master,,,yifeif,2018-03-08 02:18:16,2018-03-08 06:12:11
PR,R1 6,,,,2018-03-08 03:11:37,2018-03-08 06:12:23
PR,Making dockerhub the primary installation location,,,av8ramit,2018-03-07 22:13:34,2018-03-08 06:13:06
IS,strange error on mac,here is the code,,,2018-03-08 04:02:09,2018-03-08 06:17:04
PR,Fix cmake Dockerfile issue on Linux,When running cmake on Linux with clean build with no cached docker images This fix updates the golang installation and use backported xenial 16 04 as was suggested in the link This fix also adds the missing pip install wheel Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-04 17:59:50,2018-03-08 07:22:18
IS,NotFoundError Op type not registered 'KafkaDataset' in binary,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'unknown' '1 6 0 rc1' Python version 2 7 Bazel version if compiling from source 0 8 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version GPU model and memory Exact command to reproduce python from tensorflow contrib kafka python ops import kafka dataset ops from tensorflow python data ops import iterator ops from tensorflow python framework import dtypes from tensorflow python ops import array ops topics array ops placeholder dtypes string shape None num epochs array ops placeholder dtypes int64 shape batch size array ops placeholder dtypes int64 shape repeat dataset kafka dataset ops KafkaDataset topics group test eof True repeat num epochs batch dataset repeat dataset batch batch size iterator iterator ops Iterator from structure batch dataset output types init op iterator make initializer repeat dataset init batch op iterator make initializer batch dataset get next iterator get next ENV Describe the problem Getting NotFoundError even with TF NEED KAFKA 1 and define with kafka support true NotFoundError Op type not registered 'KafkaDataset' in binary running on 68a9f992375e Make sure the Op and Kernel are registered in the binary running in this process KafkaDataset was merged into master last month Is there something missing that needs to be done in order to utilize the new op Source code logs,,"asimshankar,yongtang,yongtang,yongtang",2018-02-23 07:08:55,2018-03-08 07:22:48
PR,Fix build issue with KafkaDataset,This fix tries to address the issue raised in 17210 where error of NotFoundError Op type not registered 'KafkaDataset' in binary returned from kafka ops The issue was that the inclusion of kafka ops was removed due to the conflict merge from the other PR This fix fixes the issue This fix fixes 17210 Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry,yongtang,yongtang",2018-03-04 23:06:52,2018-03-08 07:22:48
PR,Update TrainingSpec and EvalSpec pydoc,Bring TrainingSpec and EvalSpec pydoc in line with pydoc of estimator train and evaluate,,,2018-02-23 02:03:09,2018-03-08 07:24:13
IS,Linear Model Tutorial How to extract prediction,Similar to this issue For the TensorFlow Linear Model Tutorial the project implies that it will end with a program that based on input data outputs a 0 or 1 Given census data about a person such as age gender education and occupation the features we will try to predict whether or not the person earns more than 50 000 dollars a year the target label We will train a logistic regression model and given an individual is information our model will output a number between 0 and 1 which can be interpreted as the probability that the individual has an annual income of over 50 000 dollars However it seems that the tutorial is incomplete The last steps have you calculate the accuracy of the trained model The first line of the output should be something like accuracy 0 83557522 which means the accuracy is 83 6 Feel free to try more features and transformations and see if you can do even better And then point you in the direction of the full example code If you would like to see a working end to end example you can download our example code and set the model type flag to wide When I run the final program my output looks like this accuracy 0 989583 accuracy baseline label mean 0 364583 accuracy threshold 0 500000 mean 0 989583 auc 1 0 auc precision recall 1 0 global step 3000 labels actual label mean 0 364583 labels prediction mean 0 369466 loss 0 0242721 precision positive threshold 0 500000 mean 0 972222 recall positive threshold 0 500000 mean 1 0 Only accuracy is explained in the instructions and it does not seem that there are final steps to complete the tutorial to take a set of given values and predict income bracket Can someone provide a code example or point to documentation on how to extract final predictions after training the model Thanks,,"jhseu,jhseu,imsheridan",2017-07-12 01:22:30,2018-03-08 07:24:29
PR,Supplement Linear Model Tutorial on how trained model to make predictions,This is to fix 11440 The current Linear Model Tutorial told how to train and evaluate a linear model but it does not seem that there are final steps to complete the tutorial to take a set of given values and predict income bracket This fix of the tutorial is to provide a simple code example for newbies on how to extract final predictions after training the model,,imsheridan,2018-02-26 16:38:37,2018-03-08 07:24:29
PR,Change unicode six text type for Python 3,unicode was removed in Python 3 because all str are Unicode so this PR changes four calls to unicode into calls to six text type six text type,,"cclauss,cclauss",2018-02-23 18:19:23,2018-03-08 07:25:05
PR,Fix build issues when having packed git refs,This is a workaround to fix build failure caused by packed git refs The tf git version string will be unknown in this case,,"case540,case540,ekelsen",2018-02-21 01:14:30,2018-03-08 07:28:17
PR,Fix a bug in tf strided slice,Current implementation modifies TfLiteNode builtin data every time when a loaded graph is executed The three masks in params please see the patch will continually flipping and causing the op produce incorrect result every two executions The bug can be reproduced by m Invoke twice in most axis shrinking unit tests from strided slice test cc I am not sure if I should add one extra m Invoke as it will really look like typo,,"scottcjt,aselle",2018-02-13 19:27:42,2018-03-08 07:29:19
PR,Fix typo in datasets imdb py,,,caisq,2018-02-13 08:49:12,2018-03-08 07:29:37
PR,XLA Allow 3rd party backends to subclass the generic transfer manager,I would like to subclass the generic transfer manager but it does not allow itself to be subclassed by anything but the 3 whitelisted backends This change removes that restriction,,"DavidNorman,kayzhu,DavidNorman,kayzhu",2018-02-13 09:35:00,2018-03-08 07:30:04
PR,XLA Add header and macros to allow these tests to be disabled in a manifest,Change to the XLA specific macro which allows tests to be disabled in a manifest file Without this tests which use types that are not supported by a backend cannot be run,,"DavidNorman,hawkinsp,DavidNorman",2018-02-13 09:33:48,2018-03-08 07:31:02
PR,Branch 188272354,,,"yifeif,yifeif,yifeif",2018-03-08 03:39:35,2018-03-08 07:42:51
IS,how to get tuple for tensorflow in c,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary source TensorFlow version use command below rc1 5 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 7 1 GPU model and memory Nvidia GT Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Rewrite tracking code from python to c I do not know how to get tuple in c The python and c code as following Source code logs python code lstm2 outputs state2 tf nn dynamic rnn lstm2 lstm2 inputs initial state state2 swap memory swap memory state2 is a tuple state2 0 has shape 1 1024 state2 1 has shape 1 1024 c code Status run status session Run Placeholder place Placeholder 1 place1 Placeholder 2 place2 Placeholder 3 place3 Placeholder 4 place4 Placeholder 5 place5 output tensor names outputs output tensor names re3 lstm1 rnn transpose 1 re3 lstm2 rnn transpose 1 why outputs 0 is shape is 1 1 1024 outputs 1 is shape is 1 1 1024 I think they should be 2 1 1024 according the output of python The python is the original code which is absolutely i think my c code goes wrong in python code feed dict self imagePlaceholder croppedInput0 croppedInput1 self prevLstmState lstmState self batch size 1 in c code i write it like this Status run status session Run Placeholder place Placeholder 1 place1 Placeholder 2 place2 Placeholder 3 place3 Placeholder 4 place4 Placeholder 5 place5 output tensor names outputs the shape is place 2 227 227 3 place1 place 4 1 1024 does the problem from here my model node is like node name Placeholder op Placeholder attr key dtype value type DT UINT8 attr key shape value shape dim size 1 dim size 227 dim size 227 dim size 3 node name Placeholder 1 op Placeholder attr key dtype value type DT FLOAT attr key shape value shape dim size 1 dim size 1024 node name Placeholder 2 op Placeholder attr key dtype value type DT FLOAT attr key shape value shape dim size 1 dim size 1024 some body know why Give my great appreciation to you,,tatianashp,2018-03-06 07:59:50,2018-03-08 07:46:05
IS,AVX512F is not compiled when running hello world test using Tensorflow 1 6 on Intel KNL,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No custom code TensorFlow installed from source or binary binary follow the instructions from intel comment 1919528 Linux KNL101 04 4 13 0 21 generic 24 Ubuntu SMP Mon Dec 18 17 29 16 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 17 10 Artful Aardvark VERSION ID 17 10 VERSION CODENAME artful are we in docker No compiler c Ubuntu 7 2 0 8ubuntu3 2 7 2 0 Copyright C 2017 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux KNL101 04 4 13 0 21 generic 24 Ubuntu SMP Mon Dec 18 17 29 16 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 5 2 tensorflow 1 6 0 check for virtualenv False tensorflow import tf VERSION 1 6 0 tf GIT VERSION b'unknown' tf COMPILER VERSION b'unknown' Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem It seems that AVX512F is not compiled into released tensorflow 1 6 but other KNL specific AVX512 instructions are compiled I run simple hello world test on KNL after install the tensorflow 1 6 by following the steps mentioned here it give me the message as follows 2018 03 08 13 08 26 924344 I tensorflow core platform cpu feature guard cc 140 Your CPU supports instructions that this TensorFlow binary was not compiled to use AVX512F BTW i try to compile the tensorflow 1 6 from source code and adding all of avxxxxx as copt to bazel build cmd after build tensorflow 1 6 package correctly re run above test program it seems the AVX512F is compiled Source code logs Source code simple program just print hello tensorflow using tensorflow logs 2018 03 08 13 08 26 924344 I tensorflow core platform cpu feature guard cc 140 Your CPU supports instructions that this TensorFlow binary was not compiled to use AVX512F,,gunan,2018-03-08 03:51:13,2018-03-08 08:16:35
IS,Inconsistent OMPI SKIP MPICXX define,Looks like we define OMPI SKIP MPICXX before include third party mpi mpi h in two places L32 L34 L36 L37 But it is not defined here L27 Because the first two are defined without an ifndef I can not define it in a compiler flag We should probably add it to the last one or at least make the first two no ops if it is already set,,"angersson,yongtang",2018-03-02 22:42:16,2018-03-08 08:23:01
PR,Add missing define OMPI SKIP MPICXX,This fix adds the missing define OMPI SKIP MPICXX in tensorflow contrib mpi mpi utils h so that it is consistent with other usages of mpi h includes OMPI SKIP MPICXX skip the MPI C bindings support This fix fixes 17388 and 17504 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-04 16:13:39,2018-03-08 08:23:01
IS,Unable to build tensorflow 1 5 with mpi on AWS ec2 machine,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Centos 4 9 77 31 58 amzn1 x86 64 TensorFlow installed from source or binary source TensorFlow version use command below r1 5 Python version 3 5 5 Bazel version if compiling from source GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version 9 0 7 0 GPU model and memory GRID K520 4GB aws g2 instance Exact command to reproduce Describe the problem I have installed mpi using the following steps What am I missing here Any help will be appreciated,,"yongtang,yongtang",2018-03-07 09:35:07,2018-03-08 16:46:10
IS,use tf concat get error about ExpandDims Prod Slice not supported when use toco to convert the model to tflite format,detail is describe in,,,2018-03-07 05:01:11,2018-03-08 16:55:24
IS,tf python io TFRecordWriter results in UnknownError Failed to create a NewWriteableFile,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 64 Bit TensorFlow installed from source or binary TensorFlow installed from Conda TensorFlow version use command below 1 6 0 Python version Python 3 6 3 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version 9 1 85 GPU model and memory NVIDIA GeForce 820M Exact command to reproduce import tensorflow as tf tf python io TFRecordWriter 'C Users user name Documents' import tensorflow as tf tf python io TFRecordWriter 'Any path' Problem tf python io TFRecordWriter 'path' does not create output file and returns following error UnknownError Failed to create a NewWriteableFile 'path' Access is denied Input output error Troubleshooting Tried with different folders and drives as path But error is consistent Source code logs import tensorflow as tf C Users Sethu Anaconda3 lib site packages h5py init py 34 FutureWarning Conversion of the second argument of issubdtype from float to np floating is deprecated In future it will be treated as np float64 np dtype float type from conv import register converters as register converters tf python io TFRecordWriter 'C Users Sethu Documents' UnknownError Traceback most recent call last ipython input 2 1fe0cde88225 in module 1 tf python io TFRecordWriter 'C Users Sethu Documents' Anaconda3 lib site packages tensorflow python lib io tf record py in init self path options 109 with errors raise exception on not ok status as status 110 self writer pywrap tensorflow PyRecordWriter New 111 compat as bytes path compat as bytes compression type status 112 113 def enter self Anaconda3 lib site packages tensorflow python framework errors impl py in exit self type arg value arg traceback arg 514 None None 515 compat as text c api TF Message self status status 516 c api TF GetCode self status status 517 Delete the underlying status object from memory otherwise it stays alive 518 as there is a reference to status from this from the traceback due to UnknownError Failed to create a NewWriteableFile C Users Sethu Documents Access is denied Input output error,,"mrry,mrry",2018-03-08 12:53:50,2018-03-08 17:03:16
IS,sess run returns invisible string for a tf summary merge all op,HI I have a problem to read the outpur of sess run here is the code tf summary scalar 'Loss' loss tf summary scalar 'Accuracy' accuracy write op tf summary merge all summary train sess run write op feed dict feed dict train where write op is a op from tf summary merge all The output summary train is something like n nLoss n nAccuracy Do you have any idea how I can get the numbers for the loss and accuracy from summary train Look forward to your response Hao,,mrry,2018-03-08 16:41:44,2018-03-08 17:15:25
IS,tensorflow lite cannot use my own model crashed without error log,Version Info tensorflow r1 5 ubuntu 14 04 armv7 platform android 6 0 1 and pc ndk version r14 android studio 2 3 1 Describe the problem i write the code in c it can get results when using the mobilenet model from the tutorails link but when i use my own model converted by toco it crashed without any information set input and load model seemed correct but invoke failed code network define network is defined by tf slim framework this code can read and ouput result correct when run the example mobilenet file mobilenet quant v1 224 tflite but crash when i run my own model and give the error Fatal signal 7 SIGBUS code 1 fault addr 0xdd3dd008 in tid 10528 and on PC it also crashes without more information,,freedomtan,2018-03-02 10:18:28,2018-03-08 17:23:31
PR,Revert Update external protobuf codebase version for Windows cmake b,uild This reverts commit 07bec47ba5db4c2f2e33ecb49f23253a371bfbbe I will run a cmake GPU test before we merge,,"gunan,gunan,meteorcloudy,yifeif",2018-03-08 07:40:49,2018-03-08 19:20:17
PR,Update tensorrt import exception,,,"yifeif,gunan,aaroey,yifeif,aaroey,aaroey,jjsjann123",2018-03-08 19:10:31,2018-03-08 20:33:27
PR,Exclude kafka on Windows,I tried to enable kafka on Windows but found it depends on boringssl decrepit bio base64 bio c which is not available in boringssl is Bazel build I filed an internal issue for the boringssl team For now let is excluded kafka on Windows to fix the Windows build FYI,,"meteorcloudy,yongtang",2018-03-08 10:19:39,2018-03-08 20:56:51
IS,Setting up CI jobs for Windows Bazel build,Now tensorflow contrib is enabled in the Bazel Windows build We can start working on setting up kokoro jobs for Bazel Windows build Github presubmit Github postsubmit Internal presubmit Internal postsubmit,,"meteorcloudy,meteorcloudy,gunan",2018-03-08 10:28:50,2018-03-08 21:18:29
IS,New version 1 6 pip install upgrade tensorflow installs tensorflow gpu NOT tensorflow cpu,1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead BUG OS Platform and Distribution e g Linux Ubuntu 16 04 WINDOWS 10 0 TensorFlow installed from source or binary pip binary TensorFlow version use command below 1 6 Python version tried both python 3 5 2 3 6 4 CUDA cuDNN version NO CUDA GPU model and memory NO GPU Exact command to reproduce pip install upgrade tensorflow Describe the problem import tensorflow as tf give the error No module named pywrap tensorflow Issue 42011070 on stack There it became clear that it is a cudannxx x dll i e CUDA error I have tensorflow gpu running flawlesly on NVIDIA GPU Source code logs No module named pywrap tensorflow,,"gunan,gunan,gunan",2018-03-07 22:04:16,2018-03-08 23:17:45
PR,Update version string to 1 7 0rc0 everywhere,,,yifeif,2018-03-08 21:57:49,2018-03-08 23:21:14
IS,broken Qualcomm link on tensorflow org,On tensorflow org there is a logo with a broken link to ERR TIMED OUT Looks like it should be Sorry if creating an issue was wrong but I did not find any contact possibilities,,"angersson,MarkDaoust",2018-03-02 20:42:00,2018-03-08 23:27:47
IS,LookupError gradient registry has no entry for Svd,Hello All I am using singular values of the weights at each convolution layer as a regularizer and adding it in kernel regularizer self l2 reg Where l2 reg is the function which return that I Understand that this is due to not able to calculate the gradient for SVD operation but then how do I remove this issue Nitin,,"asimshankar,asimshankar",2018-02-20 20:03:32,2018-03-09 00:35:08
IS,S3 Checkpointing fails with large graphs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 tensorflow tensorflow 1 4 0 container running on Amazon Linux TensorFlow installed from source or binary Used tensorflow tensorflow 1 4 0 image TensorFlow version use command below 'v1 4 0 rc1 11 g130a514' '1 4 0' Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce 1 Exported AWS credentials to environment variables 2 docker run it rm p 8888 8888 e AWS ACCESS KEY ID e AWS SECRET ACCESS KEY e AWS SESSION TOKEN tensorflow tensorflow 1 4 0 3 Opened Jupyter UI in browser at localhost 8888 4 Pasted code below in a new notebook modified checkpoint s3 dir variable to point to my S3 bucket and ran it,,"skye,yongtang",2018-01-05 01:33:56,2018-03-09 01:47:01
PR,Disable checkpointable utils test,failed,,"yifeif,allenlavoie,yifeif",2018-03-09 01:37:39,2018-03-09 02:06:43
IS,tf layers Layer set scope problem might cause unexpected duplicate name ValueError,OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version 1 4 1 Python version 3 5 2 CUDA cuDNN version CUDA 8 0 CUDNN 7 0 5 GPU model and memory GTX1080 8G Exact command to reproduce python3 test py Have I written custom code True Bazel version N A GCC version N A Repoduce code One solution might be using self name to setup Layer is scope not self base name,,"angersson,facaiy,facaiy,facaiy,facaiy",2017-12-11 11:05:17,2018-03-09 03:07:45
PR,Make spinn test less flaky,,,"yifeif,caisq",2018-03-09 02:13:13,2018-03-09 03:54:15
IS,Nested while loop does not work for automatic gradient derivation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I have OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 11 6 TensorFlow installed from source or binary conda forge TensorFlow version use command below 1 5 0 Python version 3 6 0 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Source code logs source code is here calling HierarchicalAttentionNetwork make graph batch graph will produce the above error,,ebrevdo,2018-03-08 14:46:59,2018-03-09 03:58:52
IS,Tensorflow finding only 9gb of free memory but 11gb total for gtx 1080 ti GPU,We found on both Windows 10 and Linux machines that Tensorflow will only find 9gb of the 11gb available for GTX 1080 ti GPUs from both EVGA and MSI Having trouble finding a fix does anyone know why it is doing this and how to fix it so it can get access to all the memory,,,2018-03-09 05:44:12,2018-03-09 06:19:34
PR,Fix pylint error in single return py,,,"yifeif,yifeif",2018-03-08 23:43:27,2018-03-09 07:56:45
PR,Fix cmake build errors for Linux,When trying to build TensorFlow with cmake for Linux as was specified This fix fixes the above issue with libcares a in cmake file Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-09 02:47:22,2018-03-09 08:14:46
PR,Hide os from docs generator,Hide os so we do not generate api docs for it,,MarkDaoust,2018-03-09 00:08:03,2018-03-09 08:14:49
PR,Hide os from docs generator,Delete os so the docs generator does not build docs for it,,MarkDaoust,2018-03-09 00:04:57,2018-03-09 08:15:06
PR,fix some compilation errors on MSVC if IS SLIM BUILD,Using MSVC 2017 the record reader cc can not be compiled successfully if IS SLIM BUILD is defined so this PR fixes it,,,2018-03-08 08:27:17,2018-03-09 08:17:14
PR,Update replicate model fn py,Added a name attribute to PerGraphState Using the TowerOptimizer throws this warning without it,,"selcouthlyBlue,gunan",2018-03-06 12:27:23,2018-03-09 08:19:27
PR,Fix broken link pointing to vulnerability reporting SECURITY md,The vulnerability reporting SECURITY md has been moved to top level directory this fix fixes the broken link inside tensorflow docs src community welcome md Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-06 00:01:25,2018-03-09 08:21:26
IS,CI TensorFlow build is failing on Windows,Before merging 16659 we should fix the TF build on Windows first Current failure Culprit is because f write 'import s n' TF BAZELRC writes backslash into bazelrc file without escaping I will send a fix FYI,,"meteorcloudy,meteorcloudy",2018-02-26 07:02:57,2018-03-09 10:05:52
IS,Windows Build of Tensorflow CMakeLists txt error,The Cmake error is displayed when check for native architecture The following change reports success for the same test on Windows,,,2018-02-16 16:41:37,2018-03-09 14:07:05
IS,Tensorflow 1 4 1 on Linux CentOS 7 4 and Tensorflow 1 4 1 on MacOSX producing very different results in image creation simulation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS 7 4 and MacOSx 10 10 5 TensorFlow installed from source or binary Both Installed from binary then built and installed from source Same behaviour on each install TensorFlow version use command below Tensorflow 1 4 0 and Tensorflow 1 4 1 Python version 2 7 14 installed from binary and then built and installed from source Bazel version if compiling from source Bazel 0 9 0 Source built and installed successfully Python whl file built installed successfully GCC Compiler version if compiling from source Xcode7 2 1 and the Gnu gFortran 5 2 needed gFortran for SciPy install All installs OK CUDA cuDNN version N A compiled and running CPU versions only for now GPU model and memory Exact command to reproduce See supplied test program based on the Laplace PDE Raindrops on Pond simulation example from Tensorflow Tutorial Description of Problem I have run into a curious situation I am getting very different behaviour in Tensorflow 1 4 1 on Linux and Tensorflow 1 4 1 on MacOSX in straightforward image generation simulation based on the Raindrops on a Pond Laplace PDE example from the Tensorflow Tutorial I must stress that both Tensorflow installations seem to be 100 correct and operate other tests correctly producing the same numeric results for simple models I have also built Tensorflow 1 4 1 completely from source and the Python 2 7 14 as well on the MacOSX MacBook machine in order to build the Python using enable unicode ucs4 since that was one difference I was able to find between the two version But even with the Macbook now running exactly the same Python 2 7 14 as the Linux box I am still getting wildly divergent evoluationary behaviour as when I iterate the simple simulation The numbers just zoom off in very different directions on each machine and the generated images show this On the MacOSX the simulation evolves very quickly to a pure white canvas all 255 s but on the Linux platform the image grows more complex with the generated numbers bifurcating between large negative and large positive and hence when np clip ed to range 0 255 show a complex moire style pattern I have confirmed all related libraries and packages seem to be the same versions The difference seems to be in the operation of Tensorflow This seems pretty serious as each platform is Intel The Linux box CentOS 7 4 is Core i3 while the Macbook is Core i5 But both are 64 bit and both Tensorflow installations seem to be correct I have tried both the binary version and then built a complete local version of Tensorflow 1 4 1 for the Macbook from source Both seem to be Ok and operate correctly The Linux version of Tensorflow 1 4 0 was installed from binary appears to be operating correctly albeit differently but just for this one program When the sample program runs it will display fourteen 400x400 images as well as the numeric values of the row 20 of the a array 400 numbers The program can be started from an Xterm shell window with python LapTest py It does not need Jupyter or IPython With SciPy loaded the images are rendered as PNG files on both platforms using Preview on the MacOSX MacBook and ImageMagick on the CentOS 7 4 Linux box Program runs fine to completion and all looks ok on both machines But the results even with the simple initial pseudo random conditions evolve completely differently and consistantly The Macbook version of Tensorflow 1 4 1 goes to a pure white screen while the LInux Tensorflow 1 4 1 configuration evolves to a complex chaotic moire pattern Leaving aside the question of even which machine is correct the expected result is of course that both machines should at least show clear evidence of similar behaviour No change was made to the test program LapTest py from one machine to the other The different behaviour is not related to how the images are displayed which is working fine on both platforms A copy of this simple program is provided I have removed or commented out the IPython Jupyter dependent code so this program can be run on plain vanilla Python 2 7 14 as long the appropriate packages tensorflow numpy scipy PIL Pillow version matplotlib imageio are available Example of Source code to demostrate behaviour LapTest py If someone could try this program on a supported version of Linux ie the Ubuntu version that TensorFlow officially supports that would be helpful I am running a recent version of the Linux kernel on the CentOS 7 4 box uname a reports kernel version 4 14 9 1 el7 elrepo x86 64 Really like to nail down what is happening I have attached images of results I am seeing on the two machines first the Linux box second is the Macbook laptest linux img 20180107 150905 sml laptest mac img 20180107 151332 sml,,"skye,MarkDaoust,martinwicke,MarkDaoust",2018-01-07 21:27:51,2018-03-09 14:25:49
IS,There is an issue with your new issue page,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information All systems system independent Describe the problem If there are documentation issues the New Issue button will direct many people to StackOverflow The notions of bugs and features are not universal in that they only apply to software not to documentation as far as some people are concerned IMHO the text above would be better if it stated that 1 It must be a bug or a feature request or a correction clarification to documentation Source code logs No source involved,,"drpngx,aselle,aselle,MarkDaoust",2018-01-24 03:53:19,2018-03-09 14:53:46
IS,input layer tf reshape features x 1 28 28 1 NameError name 'features' is not defined,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2018-03-05 11:12:24,2018-03-09 16:36:31
IS,tensorflow self check py needs updates for CUD 9 0 to look for cudnn64 7 dll,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win 7 TensorFlow installed from source or binary pip exe install upgrade tensorflow gpu TensorFlow version use command below b'unknown' '1 5 0' Python version 3 6 4 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 0 GPU model and memory NVIDIA GeForce GTX 660 Exact command to reproduce tensorflow self check py Describe the problem The current tensorflow self check py script needs updates for CUDA 9 0 for use with tensorflow 1 5 0 I followed the script error messages and suggestions and removed CUDA 9 0 and installed the older CUDA 8 0 and the requisite cudnn64 6 dll The script told me that I had all the required dll but tensorflow was still not working and to go file a bug report When I manually did import tensorflow and followed the detailed error messages I realized that tensorflow 1 5 0 really does support CUDA 9 0 and really does want cudnn64 7 dll see below ImportError Could not find 'cudnn64 7 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Note that installing cuDNN is a separate step from installing CUDA and this DLL is often found in a different directory from the CUDA DLLs You may install the necessary DLL by downloading cuDNN 7 from this URL With CUD 9 0 and cudnn64 7 dll installed tensorflow 1 5 0 is working GPU is enabled The tensorflow self check py needs an update to look for cudnn64 7 dll Maybe also get rid of code that looks for older dll versions Source code logs N A,,,2018-02-17 15:52:54,2018-03-09 16:38:43
IS,Build fails for certain GCC paths,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 rc2 Python version 2 7 Bazel version if compiling from source 5 2 CUDA cuDNN version 8 0 5 1 10 GPU model and memory Nvidia GTX 1080 Ti Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures spawn strategy standalone Describe the problem Build will fail if compiler is not located in specific paths like usr bin Also will happen by compiling with a symbolic link to compiler if the link reside there Steps to reproduce Make a symbolic link to GCC and store it somewhere like etc gcc run configure and set compiler path to etc gcc then run bazel build This is probably why builds failing on certain many Linux distributions and is related to issues like 3550 and many other abandoned ones Source code logs bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures spawn strategy standalone,,"rohan100jain,yzhwang,yzhwang",2017-08-08 12:40:24,2018-03-09 16:58:32
IS,ServingInputReceiver passes Estimator model fn only dictionary of features but model fn is allowed to take single tensor feature,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I have written custom code I have more discussion about the bug in this Jupyter notebook OS Platform and Distribution e g Linux Ubuntu 16 04 Goobuntu TensorFlow installed from source or binary PyPI TensorFlow version use command below 1 2 1 Python version 2 7 6 Bazel version if compiling from source Not relevant CUDA cuDNN version Not relevant GPU model and memory Not relevant Exact command to reproduce Check this notebook Describe the problem The tf estimator Estimator interface allows users to provide a model fn which accepts features either within a single tensor or within a dictionary mapping strings to tensors The Estimator export savedmodel method requires a serving input receiver fn argument which is a function of no arguments that produces a ServingInputReceiver The features tensors from this ServingInputReceiver are passed to the model fn for serving Upon instantiation the ServingInputReceiver wraps single tensor features into a dictionary This raises an error for estimators whose model fn expects a single tensor as its features argument Source code logs Gist You can run that notebook to see log messages etc Misc Possibly related to this stackoverflow thread,,"aselle,martinwicke,martinwicke,martinwicke,fchollet",2017-07-21 20:40:04,2018-03-09 17:15:27
PR,Intel MKL DNN added MKLDNN dilated convolution support,This PR contains the MKLDNN implementation of dilated convolution forward and backward we supported following operators forward dilated conv with and without bias backward dilated conv grad input backward dilated conv grad filter with and without bias To test MKLDNN dilated convolution environment variable TF MKL TEST 1 is needed conv op test py file was modified dilated conv test will be the tests that check the environment variable TF MKL TEST To test it run as follows bazel test action env TF MKL TEST 1 config mkl s c opt tensorflow python kernel tests conv ops test,,"jinghuangintel,rmlarsen,rmlarsen,jinghuangintel,ekelsen,claynerobison,tatianashp,tatianashp,tatianashp,jinghuangintel,rmlarsen,jinghuangintel,rmlarsen",2018-02-20 22:53:58,2018-03-09 17:20:39
IS,tf data Dataset does not provide a good workflow for generating custom samples from large files,We are given hundreds of data files each containing many gigabytes worth of sample data in a custom format As far as I can tell there are only two approaches to extract samples from this using Dataset 1 tf data Dataset from generator generator my custom reader Create a generator which produces samples This approach is not ideal because this method must be the first dataset in the chain The generator cannot accept a tensor Therefore you can not batch and shuffle your list of 100 is of filenames or anything more complex You also can not make use of interleave because the generator can not accept a tensor and this use case is begging to use interleave A solution here might be to provide a method for a generator to accept a tensor as tf py func does for functions 2 tf data Dataset map map func tf py func my custom reader The map function does allow us to shuffle and parallelize the filenames using all of the functionality of the Dataset pipeline however with map the files must be read into memory completely and these files are large Reading numerous files into memory is infeasible A solution here might be to extend the map function to support generators Unless there is an alternative approach which I did not glean from the docs or stackoverflow then this seems to be an inherent limitation and a seemingly reasonable use case on which to base a feature request,,skye,2018-01-24 01:03:55,2018-03-09 17:38:37
IS,Problem w leaky relu,Describe the problem Having problems using tf nn leaky relu Attempted to deal with the problem by trying out tf nn elu and tf nn relu but both functions resulted in a fairly significant drop in accuracy I was originally building the model in Keras but switched to TensorFlow after having a problem with the corresponding leaky relu function in Keras The TensorFlow and Keras source code and error logs are below Thank you in advance Source code logs TensorFlow Source Code Below is the TensorFlow error message img width 962 alt screen shot 2018 03 08 at 3 13 12 pm src Below is part of the Keras error message img width 850 alt screen shot 2018 03 08 at 3 23 54 pm src,,ppwwyyxx,2018-03-08 20:28:11,2018-03-09 18:09:25
PR,Fix pylint error in single return py,,,yifeif,2018-03-09 18:19:17,2018-03-09 18:29:17
PR,Including the original path to find bazel,,,av8ramit,2018-03-09 18:56:38,2018-03-09 18:59:09
PR,Disable tensorflow contrib learn monitors test for pip gpu,,,yifeif,2018-03-09 19:09:19,2018-03-09 19:26:44
IS,text manipulation in tensorflow,Hi I want to make my text files in lower case I tried following code and unfortunately I got error slice index 1 of dimension 0 out of bounds Node strided slice 1 StridedSlice Index DT INT32 T DT STRING begin mask 0 ellipsis mask 0 end mask 0 new axis mask 0 shrink axis mask 1 StringSplit 1 strided slice 1 stack strided slice 1 stack 1 strided slice 1 stack 2 Node IteratorGetNext 9 IteratorGetNext output shapes unknown output types DT INT32 DT STRING device job localhost replica 0 task 0 device CPU 0 OneShotIterator 9 I would be so grateful to help me,,"shivaniag,shivaniag",2018-02-27 05:44:01,2018-03-09 21:44:10
IS,Error while building Tensorflow model from bazel,INFO From Linking tensorflow libtensorflow framework so for host LINK warning LNK4044 unrecognized option ' Wl soname libtensorflow framework so' ignored LINK warning LNK4044 unrecognized option ' pthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lpthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lpthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' ldl' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lm' ignored Creating library bazel out host bin tensorflow libtensorflow framework ifso and object bazel out host bin tensorflow libtensorflow framework exp ERROR C courses tensorflow tensorflow cc BUILD 422 1 Linking of rule ' tensorflow cc ops array ops gen cc' failed Exit 1181 LINK warning LNK4044 unrecognized option ' pthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK fatal error LNK1181 cannot open input file 'tensorflow framework obj' Target tensorflow contrib android libtensorflow inference so failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 3434 951s Critical Path 365 14s FAILED Build did NOT complete successfully Is LNK4044 warning related to c path i have given VisualStudio exe path while installing,,"drpngx,gunan,meteorcloudy,meteorcloudy,andrewharp",2018-02-01 08:45:12,2018-03-09 22:41:08
PR,Branch 188540944,,,"akshaym,yifeif,akshaym,akshaym",2018-03-09 23:00:12,2018-03-10 01:00:16
IS,Add the structural similarity SSIM index metric as a built in loss operation,In many cases existed built in losses in TensorFlow do not satisfy needs We can add ssim or 1 ssim as the loss function into TensorFlow There is existed solution provided on StackOverflow but it is better to have the built in function with fully covered unit tests,,drpngx,2017-12-14 19:45:56,2018-03-10 01:00:58
IS,tf fake quant with min max vars returns wrong answer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below 1 5 0 Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA 8 0 CuDNN 6 0 GPU model and memory GTX 1080 8GB Exact command to reproduce Describe the problem tf fake quant with min max vars returns wrong answer Source code logs,,"aselle,suharshs",2018-02-14 00:07:44,2018-03-10 01:41:07
IS,TypeError new got an unexpected keyword argument 'output alternatives',System information OS Distribution Linux Ubuntu 16 04 3 LTS TensorFlow is installed from binary TensorFlow version v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 6 1 CUDA cuDNN version 9 0 GPU model and memory GeForce GTX 850m and OS Distribution CentOS Linux release 7 3 1611 Core TensorFlow is installed from binary TensorFlow version v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 6 0 Describe the problem TypeError new got an unexpected keyword argument 'output alternatives' is thrown on line 611 in scale tower loss function in tensorflow contrib estimator python estimator replicate model fn py It can be resolved by adding del estimator spec 'output alternatives' After running grep command I have noticed that output alternatives variable is mostly used in tensorflow contrib learn My guess is that output alternatives was forgotten to be removed from the new tf estimator Estimator as it is only used by the old tf contrib learn Estimator Source code logs Unfortunately cannot be provided,,,2018-03-10 03:27:44,2018-03-10 08:09:13
PR,Fix of issue 10479,Fixes issue 10479,,"drpngx,ebrevdo,rmlarsen,ebrevdo",2017-11-23 11:17:33,2018-03-10 19:18:39
PR,Fix incorrect python version in installation doc for Mac,This fix fixes the incorrect python version 2 vs 3 in the installation documentation for Mac This fix fixes 17614 Signed off by Yong Tang yong tang github outlook com,,"yongtang,asimshankar,yongtang",2018-03-10 20:13:19,2018-03-10 20:20:20
IS,can we compute sparse matrix gradient in TF,In tensor flow TF to compute gradients we have to pass some variable Sparse tensors cannot be used as variables Can you please tell me is there any solution for sparse matrix gradient N A,,asimshankar,2018-03-08 10:38:40,2018-03-11 00:09:42
IS,Tensorflow python framework errors impl NotFoundError No such file or directory,Hi I try to use tensorflow object detection API My computer is Mac book pro version Sierra 10 12 6 I follow this youtube '' and final step error show up MacBook Pro de Jongwun object detection jongwuni python3 train py logtostderr train dir Users jongwuni Documents Jongwunibang Neural network models object detection training pipline config path Users jongwuni Documents Jongwunibang Neural network models object detection training faster rcnn inception resnet v2 atrous coco config Traceback most recent call last File train py line 163 in module tf app run File anaconda lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File train py line 106 in main overwrite True File anaconda lib python3 6 site packages tensorflow python lib io file io py line 385 in copy compat as bytes oldpath compat as bytes newpath overwrite status File anaconda lib python3 6 site packages tensorflow python framework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl NotFoundError No such file or directory,,,2018-03-10 15:04:34,2018-03-11 02:18:05
IS,tensorflow tensorflow contrib factorization python ops gmm ops test py FAILED,System information Code tensorflow tensorflow contrib factorization python ops gmm ops test py OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from Binary TensorFlow version '1 4 0' Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory Nvidia 1080Ti Exact command to reproduce python gmm ops test py Issue gmm test is not working either gmm ops test py Error message,,,2018-02-07 13:58:57,2018-03-11 04:32:19
IS,'colocate gradients with ops' colocate with unused ops,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 GPU model and memory P100 Exact command to reproduce here If I use colocate gradients with ops False or remove the tf Print line the above code runs with expected speed Otherwise it places the gradients on CPUs resulting in 2x slow down and a lot of H2D D2H copy shown in profiling Perhaps this colocate option can be made smarter In this case Print op depends on some gradients but no other gradients depend on the Print op i e the Print op does not appear on the subgraph which grads depends on Therefore the colocation seems totally unnecessary here,,"ppwwyyxx,drpngx,ppwwyyxx",2018-03-07 07:25:15,2018-03-11 04:41:22
PR,Include links to new announce list,We have set up an announce list which only carries important announcements such as new releases and security notifications This PR links these from the README and community documentation we want to encourage as many users as possible to join the list,,,2018-03-09 23:27:01,2018-03-11 05:39:44
IS,Error command in installation guild,Please go to Stack Overflow for help and support There is an small error in the installation guild determine which tensorflow to install which is 7th step under the Installing with Virtualenv section The site give an example command of installing TensorFlow in the active Virtualenv for macOS python which is actually for py3 with pip3 command,,"yongtang,asimshankar,yongtang",2018-03-10 08:25:36,2018-03-11 05:40:26
PR,Fix mac installation documentation error,This fix tries to address 17614 where installation for python 2 was incorrectly pointing to python3 The error was fixed by f4e70be but later it has been overridden by 9dae88d This fix fixes 17614 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-10 20:43:47,2018-03-11 05:40:26
PR,SECURITY md minor sp permisisons permissions,,,brettkoonce,2018-03-09 18:39:48,2018-03-11 05:41:36
PR,Fix broken graphviz download link and change to https,The graphviz download link has been changed to This fix fixes the broken link in jit md Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-09 23:04:35,2018-03-11 05:42:10
PR,Update bazel toolchains dependency,PiperOrigin RevId 186650360,,"av8ramit,gunan,gunan",2018-03-09 22:06:27,2018-03-11 05:43:19
PR,relaxed onehot categorical py keep dims is depreciated,keep dims is deprecated use keepdims instead,,gunan,2018-02-27 21:56:17,2018-03-11 05:47:49
PR,Fix bug 17175,Fix bug reported at,,"ebrevdo,protoget",2018-02-26 21:04:56,2018-03-11 05:48:00
PR,Minor improvements to estimator predict docs,Just some grammatical and syntactical improvements,,terrytangyuan,2018-02-17 22:57:27,2018-03-11 05:48:55
PR,Add wheel dependency to cmake README,In order to run to create the pip package after compilation wheel needs to be installed This explicitly lists wheel as a prereq in the README Otherwise the user will hit a invalid command 'bdist wheel' error,,pvaneck,2018-02-16 11:13:56,2018-03-11 05:51:05
IS,AttributeError 'module' object has no attribute 'LookupTensor',,,,2018-03-11 05:52:50,2018-03-11 06:00:59
PR,Correct curly brace typo,Curly brace required instead of right bracket for code display on getting started guide,,,2018-03-08 22:36:20,2018-03-11 06:14:37
IS,TensorFlow needs a mascot,Every open source project deserves a mascot Here is Teensy the TensorFlow Pony and he is ready to serve img 20170710 073626,,"petewarden,theflofly",2017-07-10 17:27:43,2018-03-11 06:57:16
IS,undefined symbol error for dataset ops so on rasp pi,OS Platform and Distribution e g Linux Ubuntu 16 04 Describe the problem Import of slim fails with so error as described above doubt it is actually slim it was just the first import to reference dataset ops so,,"drpngx,drpngx,drpngx,drpngx",2018-03-11 01:25:04,2018-03-12 00:02:18
IS,tensorflow python framework errors impl NotFoundError No such file or directory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS Sierra 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version python3 Bazel version if compiling from source sorry I do not know GCC Compiler version if compiling from source sorry I do not know CUDA cuDNN version sorry I do not know GPU model and memory radeon pro 560 4G Describe the problem I try to use object detection using tensorflow API I follow this youtube but there is a error Source code logs MacBook Pro de Jongwun jongwuni cd Users jongwuni Documents Jongwunibang Neural network models MacBook Pro de Jongwun models jongwuni cd object detection MacBook Pro de Jongwun object detection jongwuni python3 train py logtostderr train dir Users jongwuni Documents Jongwunibang Neural network models object detection training pipline config path Users jongwuni Documents Jongwunibang Neural network models object detection training faster rcnn inception resnet v2 atrous coco config Traceback most recent call last File train py line 163 in module tf app run File anaconda lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File train py line 106 in main overwrite True File anaconda lib python3 6 site packages tensorflow python lib io file io py line 385 in copy compat as bytes oldpath compat as bytes newpath overwrite status File anaconda lib python3 6 site packages tensorflow python framework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl NotFoundError No such file or directory,,,2018-03-11 03:21:07,2018-03-12 00:17:30
IS,segmentation fault when calling help on GraphNodeProto,System information Have I written custom code Nothing beside the example code below OS Platform and Distribution e g Linux Ubuntu 16 04 Linux RBSylaptop 4 14 0 2 amd64 1 SMP Debian 4 14 7 1 2017 12 22 x86 64 GNU Linux TensorFlow installed from pip3 install tensorflow gpu TensorFlow version tf VERSION 1 4 1 tf GIT VERSION v1 4 0 19 ga52c8d9 tf COMPILER VERSION v1 4 0 19 ga52c8d9 Python version Python 3 6 4 Bazel version N A GCC Compiler version N A CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1070 8192 MB Exact command to reproduce python3 c import tensorflow as tf help tf profiler profile tf get default graph You can collect some of this information using our environment capture script Problem description Calling help on the value returned by tf profiler profile generate a segmentation fault However it might be related to the warning about the python version Source code logs Here is the full python session,,"drpngx,av8ramit,av8ramit",2018-01-16 15:13:36,2018-03-12 16:33:49
IS,What are the relation ship between TF Slim TF high level API and Keras,I am very confused What are the relationships between TF Slim TF high level API and Keras I just want to know which one has the long term evolution Fragmentation like Android OS is a very bad and dangerous thing At least for me I am not comfortable with TF Slim at all Why TF cannot have a unified and Standardized API The benefits are so obvious It should not become different political parties fight each other,,"tfboyd,tfboyd",2018-01-17 07:52:26,2018-03-12 17:37:42
IS,Parse toco generated file tflite in python,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 1 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I am using toco to optimize a frozen model pb How do I read the tflite file in python something similar to tf gfile GFile 'frozen pb' 'rb',,"reedwm,aselle,aselle,aselle",2018-01-30 00:01:56,2018-03-12 17:48:17
PR,Update RELEASE md,,,"yifeif,caisq,caisq,caisq",2018-03-09 04:03:32,2018-03-12 18:36:18
IS,How can we define different rate for different layer,Is there any API or operator supports to define different rate for different layer like caffe,,reedwm,2018-03-12 08:51:52,2018-03-12 19:18:09
PR,Fix windows gpu cmake build,,,"yifeif,gunan,jhseu",2018-03-11 07:08:26,2018-03-12 20:13:39
PR,Enable CUDNN TENSOR OP MATH for fp16 RNNs,Speeds up CUDNN RNNs with fp16 input output when possible on supported GPUs Computations will fall back to pseudo fp16 if tensor op math is not supported Enabled by default but can be disabled by setting the environment variable TF DISABLE CUDNN RNN TENSOR OP MATH 1,,"benbarsdell,benbarsdell",2018-03-01 19:40:28,2018-03-12 22:26:06
PR,Fix to tf keras utils plot model error,Fix to 17633 'Model' object has no attribute ' container nodes' error when using tf keras utils plot model Replaced if node key in model container nodes with if node key in model network nodes pylint disable protected access in tensorflow python keras impl keras utils vis utils py,,,2018-03-12 23:17:17,2018-03-12 23:22:09
IS,when i add hard example miner to faster rcnn config i face resource exhaust problem,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-03-12 15:43:09,2018-03-12 23:28:22
PR,Support NUMA aware CPU device,We noticed TensorFlow does not scale too much from single CPU socket to multiple CPU sockets From the performance profiling we found the memory traffic between NUMA nodes are very high The latency from the remote memory access prevents TensorFlow from scaling to multiple NUMA nodes To fix this performance issue we did a prototype to use data parallelism to improve the performance A NumaDevice class has been added all threads in a NumaDevice are pinned to the cores in one NUMA node each NumaDevice has its own memory allocator With the NumaDevice most of the tensor are created and accessed by the same Numa node the memory access should be local The input data are evenly distributed to all NUMA nodes the loss value and the gradient are computed on each Numa node and then the gradients from all Numa nodes are averaged and the variables are updated by these gradients The variable update is done on all CPU cores This pull request contains a prototype to support NUMA aware CPU device Some code are hacked to make it run We want to send this pull request to get the comments about what we are doing From our initial performance test ResNet 50 inference got 1 4x speedup than the master branch on two socket Skylake ResNet 50 training got 1 14x speedup which is lower than what we expected we will continue working on it To make it compile you need to copy NonBlockingThreadPool h to compile cache directory external eigen archive unsupported Eigen CXX11 src ThreadPool Also the benchmark script need be modified slightly I can send you the instructions for changing the benchmark script,,,2018-03-12 22:58:41,2018-03-12 23:29:43
IS,Error with Installing tensorflow error using Virtualenv,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No custom code was written steps followed from the installtensorflow webpage OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX El Capitan version 10 11 6 TensorFlow installed from source or binary error in installing tensorflow TensorFlow version use command below Python version Python 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source not sure CUDA cuDNN version GPU model and memory MacBook Pro 13 inch early 2011 Processor 2 3 GHz Intel Core I5 Memory 16GB 1333 MHz DDR3 Graphics Intel HD Graphics 3000 512 MB Exact command to reproduce error when using the following command virtualenv system site packages p python3 tensorflow screen shot 2018 03 10 at 12 01 49 am You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I am trying to install tensorflow for mac os El Capitan using Virtualenv as instructed in the tensorflow installation webpage these are the steps i have taken and errors recieved 1 Start a terminal a shell You will perform all subsequent steps in this shell 2 Installed pip and Virtualenv sucessfully by issuing the following commands sudo easy install pip pip install upgrade virtualenv 3 successfully Created a Virtualenv environment by issuing a command of one of the python 3 format virtualenv system site packages p python3 tensorflow the following e4 errors were displayed in terminal after step 3 ERROR The executable Users User tensorflow bin python3 is not functioning ERROR It thinks sys prefix is ' Users User' should be ' Users User tensorflow' ERROR virtualenv is not compatible with this system or executable 4 I get an error when doing step 4 Activate the Virtualenv environment by issuing one of the following commands cd targetDirectory source bin activate If using bash sh ksh or zsh source bin activate csh If using csh or tcsh the error i ger is bash bin activate No such file or directory Please help with this problem is greatly appreciated I have tried 1 other times using different methods to install tensorflow and it has not worked Next ill try native pip method i have attached a terminal screenshot of the whole process screen shot 2018 03 10 at 12 01 49 am Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2018-03-10 05:27:06,2018-03-13 00:20:41
IS,2D tf nn convolution output is inconsistent between inputs 1x1 and 2x2 with kernel 3x3 strides 2 padding 'SAME',Output of Keras Conv2D which is a passthrough to tf nn convolution is inconsistent between inputs 1x1 and 2x2 with kernel 3x3 strides 2 padding 'SAME' The following code with 2x2 input produces wrong output 8 which is inconsistent with correct output 4 if the input is 1x1,,"ozabluda,ozabluda,ppwwyyxx,ozabluda,ozabluda,ppwwyyxx,ozabluda",2018-03-12 19:40:40,2018-03-13 00:56:41
PR,Sfu2 numa,,,,2018-03-13 01:10:30,2018-03-13 01:20:59
PR,Add scan command to saved model cli to check for security sensitive ops,,,"yifeif,martinwicke,martinwicke",2018-03-08 01:00:01,2018-03-13 02:37:01
PR,contrib quantize minor spelling,,,brettkoonce,2018-03-13 00:03:34,2018-03-13 02:44:32
PR,Sfu2 numa test CLA,,,,2018-03-13 02:56:04,2018-03-13 02:56:57
PR,Fix to 'Model' object has no attribute ' container nodes' error when using tf keras utils plot model,Fix to 17633 'Model' object has no attribute ' container nodes' error when using tf keras utils plot model Replaced if node key in model container nodes with if node key in model network nodes pylint disable protected access in tensorflow python keras impl keras utils vis utils py,,"qmick,qmick",2018-03-12 23:30:59,2018-03-13 03:42:08
PR,Make tensorflow python framework importer test large,tensorflow python framework importer test sometime times out during release builds,,yifeif,2018-03-12 23:49:48,2018-03-13 04:02:38
PR,Added data format to layers,If you train a model in NCHW format but then do inference in NHWC the results are different as the reshape sets up the resulting array differently,,frankchn,2018-03-12 13:58:12,2018-03-13 04:46:52
PR,CMake Exclude duplicate tests from tf test src simple,This fixes errors caused by adding executable targets twice To reproduce tf venv tedchang teds mbp tfws tensorflow tensorflow contrib cmake build cmake DCMAKE BUILD TYPE Release Dtensorflow BUILD CC TESTS ON CMake Error at tf tests cmake 73 add executable add executable cannot create target tensorflow core profiler internal tfprof show test because another target with the same name already exists The existing target is an executable created in source directory Users tedchang tfws tensorflow tensorflow contrib cmake See documentation for policy CMP0002 for more details Call Stack most recent call first tf tests cmake 46 AddTest tf tests cmake 527 AddTests CMakeLists txt 469 include CMake Error at tf tests cmake 73 add executable add executable cannot create target tensorflow core profiler internal tfprof stats test because another target with the same name already exists The existing target is an executable created in source directory Users tedchang tfws tensorflow tensorflow contrib cmake See documentation for policy CMP0002 for more details Call Stack most recent call first tf tests cmake 46 AddTest tf tests cmake 527 AddTests CMakeLists txt 469 include CMake Error at tf tests cmake 73 add executable add executable cannot create target tensorflow core profiler internal tfprof tensor test because another target with the same name already exists The existing target is an executable created in source directory Users tedchang tfws tensorflow tensorflow contrib cmake See documentation for policy CMP0002 for more details Call Stack most recent call first tf tests cmake 46 AddTest tf tests cmake 527 AddTests CMakeLists txt 469 include CMake Error at tf tests cmake 73 add executable add executable cannot create target tensorflow core profiler internal tfprof timeline test because another target with the same name already exists The existing target is an executable created in source directory Users tedchang tfws tensorflow tensorflow contrib cmake See documentation for policy CMP0002 for more details Call Stack most recent call first tf tests cmake 46 AddTest tf tests cmake 527 AddTests CMakeLists txt 469 include CMake Error at tf tests cmake 73 add executable add executable cannot create target tensorflow core profiler internal advisor tfprof advisor test because another target with the same name already exists The existing target is an executable created in source directory Users tedchang tfws tensorflow tensorflow contrib cmake See documentation for policy CMP0002 for more details Call Stack most recent call first tf tests cmake 46 AddTest tf tests cmake 527 AddTests CMakeLists txt 469 include Configuring incomplete errors occurred,,"tedhtchang,tedhtchang,mrry",2018-03-10 02:32:25,2018-03-13 05:01:38
PR,MKL DNN fix the TF1 6 speed issue by fixing MKL DNN LRN taking the optimum path,There is a performance regression for TF 1 6 comparing to TF 1 5 for cifar 10 The root cause it cifar 10 uses depth radius 4 for which MKL DNN takes unoptimized path Thus we fix this issue by using following strategy If the depth radius of LRN is not 2 then MKL DNN takes unoptimized path The unoptimized path is slow Thus we dont rewrite the node and use default Eigen But for depth radius 2 MKL DNN optimized path is taken i e eigen LRN node is rewritten by MKl DNN LRN node,,"ashraf-bhuiyan,tatianashp,agramesh1",2018-03-09 23:24:31,2018-03-13 05:05:37
PR,jpeg BUILD Use cpu instead of android cpu,TF build is broken with Bazel HEAD see ca77fce7 7ea1 4427 a49b 1ab1305f6bfb Issue The reason is we recently change default value of android cpu to armeabi v7a That results two config setting enabled at the same time in jpeg BUILD We should better use cpu instead of android cpu to select for architecture FYI,,"meteorcloudy,meteorcloudy,gunan,meteorcloudy,angersson",2018-03-07 12:58:09,2018-03-13 05:20:15
PR,Added replicate model fn to contrib estimator,I noticed that multi gpu training in a tower like fashin in r1 4 is not supported So I copied the replicate model fn from r1 5 and applied the needed changes adding another key in ops GraphKeys METRIC VARIABLES imported replicate model fn in contrib estimator init py,,"selcouthlyBlue,frankchn",2018-03-06 02:39:05,2018-03-13 05:36:43
PR,contrib lite spelling code tweaks,,,"brettkoonce,brettkoonce,brettkoonce,brettkoonce",2018-03-08 02:12:26,2018-03-13 05:59:23
PR,Branch 188738133,,,frankchn,2018-03-12 17:32:19,2018-03-13 06:30:03
PR,Added data format to flatten,If you train a model in NCHW format but then do inference in NHWC the results are different as the reshape sets up the resulting array differently,,,2018-03-13 06:47:32,2018-03-13 06:50:48
IS,tf1 6 error,OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from binary TensorFlow version 1 6 Python version 3 5 5 GCC Compiler version GCC 4 8 4 CUDA cuDNN version cuda9 cuDNN7 GPU model and memory Tesla K20c Tesla K20m code to reproduce tf record test py import tensorflow as tf print tf GIT VERSION tf VERSION all record str abc output filename tfrecord test writer tf python io TFRecordWriter output filename example tf train Example features tf train Features feature features tf train Feature int32 list tf train Int32List value all record bytes list tf train BytesList value all record writer write example SerializeToString writer close error log python tf record test py usr local lib python3 5 dist packages h5py init py 36 FutureWarning Conversion of the second argument of issubdtype from float to np floating is deprecated In future it will be treated as np float64 np dtype float type from conv import register converters as register converters v1 6 0 0 gd2e24b6039 1 6 0 Traceback most recent call last File tf record test py line 15 in module bytes list tf train BytesList value all record TypeError 'a' has type str but expected one of bytes,,,2018-03-13 08:07:14,2018-03-13 08:07:53
IS,feature request How to return SparseTensor when custom ops,Describe the problem there exists some ops eg decode libsvm that can return SparseTensor by three dense tensor Have I written custom code OS Platform and Distribution TensorFlow installed from TensorFlow version Bazel version CUDA cuDNN version GPU model and memory Exact command to reproduce,,,2018-01-18 09:41:16,2018-03-13 08:28:22
IS,Wrong Library,,,,2018-03-13 15:29:54,2018-03-13 15:36:42
IS,Leak when creating many tf layers Conv2D with tf eager,OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 3 LTS TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 5 0 0 g37aa430d84' '1 5 0' Python version Python 3 5 2 CUDA cuDNN version cuda 9 0 GPU model and memory TITAN X Pascal Exact command to reproduce see gist for minimal reproduction run this script and watch loop times increase Describe the problem each creation of a tf layers Conv2D is slower than the one before have a project based on evolutionary algorithm that creates many instances of tf layers Conv2D for fitness evaluation and over time entire process slows down it is not expected this loop should slow down Source code logs see gist above,,"allenlavoie,allenlavoie,allenlavoie",2018-03-09 12:36:34,2018-03-13 16:06:27
PR,Fix the script entry point for freeze graph,The wrapper created by setup py calls the entry point function with no arguments freeze graph main expects the global FLAGS to be set and one argument This change adds a run main function to use as the entry point which expects no arguments and parses the flags It also adds a flags argument to freeze graph main so the flags can be passed directly without using a global FLAGS declaration,,MarkDaoust,2018-03-12 22:44:40,2018-03-13 16:13:08
PR,Sfu2 numa test 2,,,,2018-03-13 16:38:05,2018-03-13 16:38:26
IS,CudnnRNN TensorCore Support,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 1 7 0 GPU model and memory V100 Exact command to reproduce N A Describe the problem Feature Status Request Enable use of NVIDIA is TensorCores in CudnnRNN CudnnLSTM The requirements specified by NVIDIA are currently detailed at 1 1 tensor ops,,"yzhwang,protoget,protoget",2018-02-27 19:42:39,2018-03-13 18:00:52
IS,graph def ParseFromString google protobuf message DecodeError Error parsing message,I have the model fine tuned Inception model with my images set data by tensorflow examples image retraining retrain py Then running python tensorflow examples label image label image py for classification the custom image I get error graph def ParseFromString f read google protobuf message DecodeError Error parsing message Tensorflow version 1 6 0 GPU build I have other fine tuned Inception model that running without this error 95781819 Mar 12 19 37 carvajal model pb this run with Parser error 87458742 Mar 1 14 33 flow model pb 87622663 Mar 2 17 58 grocery model pb There is not a big difference the size of the model files the problem model file has size 95m and well running models have 87m Trace Traceback most recent call last File label image py line 117 in module graph load graph model file File label image py line 30 in load graph graph def ParseFromString f read google protobuf message DecodeError Error parsing message Are some advices about,,,2018-03-13 15:57:37,2018-03-13 19:47:21
PR,Cherrypicks for 1 5,182804819 not found in github,,"av8ramit,av8ramit,gunan,av8ramit,yifeif,gunan",2018-03-06 23:55:54,2018-03-13 20:31:51
PR,Fix broken links in tutorial layers,This PR is to fix As you can see in tutorial layers the below link of Training and Evaluating the CNN MNIST Classifier is actually broken which should be updated as training and evaluating the cnn mnist classifier If you are already experienced with CNNs and TensorFlow Estimators and find the above code intuitive you may want to skim these sections or just skip ahead to Training and Evaluating the CNN MNIST Classifier The below two links are broken due to new lines within the link Note For a more in depth look at configuring training ops for Estimator model functions see get started custom estimators defining the training op for the model Defining the training op for the model in the get started custom estimators Creating Estimations in tf estimator tutorial Delete the alias of the title which is format as right after the title name since it is not required according to the maner of the most md in the doc src folder,,"imsheridan,imsheridan",2018-03-12 16:09:53,2018-03-13 20:41:58
IS,TensorBoard tutorial links to the wrong MNIST tutorial and example code,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below 1 6 Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Sorry if this is better suited as an issue for TensorBoard but since it is about documentation on tensorflow org I thought it should go here The TensorBoard guide at contains example code that it says is a modification of the simple MNIST tutorial in which we have added some summary ops But the tutorial it links to is very different from the example code it gives that tutorial uses the tf layers module to create a CNN while the example code manually defines a one hidden layer fully connected network I'm not even sure what the example code is based on since it does not seem that similar to At the very least the link should be fixed to point to the correct original example code but even better would be if the tutorial could be updated to show how to use TensorBoard with a network created with tf layers,,imsheridan,2018-03-09 21:02:14,2018-03-13 20:42:26
PR,Fix TensorBoard tutorial links to the wrong MNIST tutorial example code,This PR is to fix 17600 The TensorBoard guide contains example code that it says is a modification of the simple MNIST tutorial in which we have added some summary ops But the tutorial it links to is very different from the example code it gives that tutorial uses the tf layers module to create a CNN while the example code manually defines a one hidden layer fully connected network,,imsheridan,2018-03-12 09:36:23,2018-03-13 20:42:26
PR,Fix broken link in programmers guide faq and some minor format,As we can see in programmer guide faq there are two broken links The first one See the how to documentation for reading data creating threads to prefetch using queuerunner objects using QueueRunner objects to drive queues and readers for more information on how to use them The seconde one If your data is not easily parsable with the built in TensorFlow operations consider converting it offline to a format that is easily parsable such as tf python io TFRecordWriter TFRecord format This PR is to fix the first broken link thru replace ' ' with ' ' and fix the second broken link thru replacing the begining ' ' with ' ' Besides I think there might be some format issue on the ' ' which I assume they should be used to highlight the In particular and With one exception sentence The TensorFlow Python API adheres to the PEP8 conventions In particular we use CamelCase names for classes and snake case names for functions methods and properties We also adhere to the Google Python style guide The TensorFlow C code base adheres to the Google C style guide With one exception we use 2 space indentation instead of 4 space indentation,,"imsheridan,frankchn",2018-03-12 03:36:50,2018-03-13 20:42:42
PR,Fix the broken link of tf learn is iris tutorial also some format and typo,This PR is to fix As we can see in TensorFlow Debugger the link of tflearn tf learn is iris tutorial is broken since there was no tflearn md any more in the latest master branch I tried to fix this thru linking it to previous branch doc version The format of below sentence is messed up tried to fix this messed up format with a blank line For LocalCLIDebugHook hooks tf debug LocalCLIDebugHook dump root with lots of space Make sure that the directory pointed to by dump root is empty or nonexistent tfdbg cleans up the dump directories before exiting Reduce the batch size used during the runs Use the filtering options of tfdbg isrun command to watch only specific nodes in the graph For example,,"imsheridan,frankchn,imsheridan",2018-03-09 16:23:33,2018-03-13 20:42:59
PR,Improvements for Android TV,To build for Android TV user need to modify the orientation from portrait to landscape for the four activities in tensorflow examples android AndroidManifest xml 1 Show a toast when no camera is detected 2 Game Controller L1 button and remote controller DRAP Center also triggers debug output 3 Fix the layout of Stylize app on Android TV The style selector will be on right side 4 User can use DPAD to navigate through styles in Stylize app,,"lihanchen,andrewharp,andrewharp,andrewharp,andrewharp,lihanchen,lihanchen,lihanchen,lihanchen,andrewharp,andrewharp",2018-03-08 00:01:53,2018-03-13 20:43:29
PR,Update wide md,Alphabetized races standard procedure in documentation,,,2018-03-06 15:20:24,2018-03-13 20:43:41
PR,fix typo,espected expected,,,2018-03-06 04:11:57,2018-03-13 20:43:56
IS,tf1 6 error tf contrib ffmpeg decode video,yongtang I use tensorflow 1 6on ubuntu and decodevideo with tf Session as sess movie bin tf read file ' home xucl app data bilibili video DongFangLieChe mp4' movie tf contrib ffmpeg decode video movie bin movie ev movie eval print len movie ev but get an error 2018 03 08 10 48 23 000491 F tensorflow contrib ffmpeg default ffmpeg lib cc 400 Non OK status ReadInfoFile stderr filename width height frames status Unknown Not enough video info returned by FFmpeg 106 0 640 3 Could not read FFmpeg stderr file tmp tmp file tensorflow 3 cPNCGW err,,"yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang",2018-03-08 02:58:23,2018-03-13 20:45:00
PR,Fix format issue in ffmpeg,This fix tries to address the issue raised in 17533 where some ouput generated by ffmpeg may not be parsed correctly There are two issues in the ffmpeg parser 1 The size of the frame could be rgb24 640x360 SAR 1 1 DAR 16 9 with extra after 640x360 2 The number of frames could be frame 12488 or frame 166 with or without the sapce in between frame and the number This fix fixes the parser issues in ffmpeg This fix fixes 17533 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-13 16:24:53,2018-03-13 20:45:00
PR,Fix broken link of tf train Example in recurrent quickdraw md,In recurrent quickdraw md the link tf train Example is not rendered correctly This fix fixes the broken link with correct rendering Now the link is rendered the same way as tf train Example in api guides python reading data md and extend new data formats md Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-13 14:25:26,2018-03-13 20:45:29
PR,Fix warning in embedding ops,This fix fixes the warning in embedding ops py by switching from keep dims to keepdims for tf reduce prod Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-13 15:12:11,2018-03-13 20:53:40
PR,Branch 188893722,,,"frankchn,gunan",2018-03-13 18:04:50,2018-03-13 22:33:31
PR,Fix link,Fix wrong link from to Convolution without the fix the link is kinda dangling as described in the comment here in,,ozabluda,2018-03-13 01:19:21,2018-03-13 22:41:02
PR,Run selective registration tool even if it is just been built,Follow on to 14421 when running build all ios sh g path to model pb for the first time the selective registration tool would be built but not used,,,2018-03-08 20:55:13,2018-03-13 22:41:21
PR,Fix the messed up list format in using tpu md,As you can see in using tpu md this PR is to fix below messed up format 1 Set FLAGS use tpu to True 1 Set FLAGS tpu name so the tf contrib cluster resolver TPUClusterResolver can find it 1 Set FLAGS model dir to a Google Cloud Storage bucket url gs,,"imsheridan,caisq,imsheridan",2018-03-08 16:45:10,2018-03-13 22:41:37
IS,The value changes incorrectly after assignment using tf assign,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 0 Python version Python 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 8 0 6 0 GPU model and memory GTX 960 2G Exact command to reproduce N A ISSUE data load new mat print data tf assign old data print old But old data Ex 0 081345705 0 081345707,,,2018-03-12 12:39:32,2018-03-14 02:42:11
IS,tf gfile does not understand NTFS Unicode filenames on Windows,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Server 2016 Datacenter 64 bit installed on a GCE VM TensorFlow installed from source or binary binary pip package TensorFlow version use command below 1 6 0 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce python c dir ' tmp tftest u8c37 u6b4c' import tensorflow as tf import os os makedirs dir print os path exists dir tf gfile Exists dir Describe the problem The tf gfile functions that involve file paths appear not to understand Windows with NTFS filenames that contain Unicode characters such as Google in Chinese It seems like something about the name is not translated in a way that actually results in successful lookups so everything behaves as if those files did not exist Command to repro This command run in Windows PowerShell prints True False i e os path exists returns a different result than tf gfile Exists This is true even for different ways of formulating that path in addition to tmp tftest u8c37 u6b4c I tested C tmp tftest u8c37 u6b4c and C tmp tftest u8c37 u6b4c double backslashes for the path separators to escape within a python string and they both produce the same result If you remove the unicode characters from the path it prints True True as expected In contrast on my gLinux workstation this prints True True all the time i e the results are the same I tested this with Exists IsDirectory and ListDirectory but I'm assuming it applies generally to all the tf gfile functions that take a path argument Note however that ListDirectory will return the Unicode name just fine if run in the parent directory the same as os listdir We have gotten a report about this for TensorBoard,,"nfelt,yongtang,nfelt",2018-03-13 22:52:15,2018-03-14 05:13:39
PR,Fix issue of tf gfile Exists with Unicode on Windows,This fix tries to address the issue raised in 17695 where tf gfile Exists with Unicode on Windows does not work as expected The issuse comes from the usage of access vs waccess This fix adds a test and fixes the issue This fix fixes 17695 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-14 01:34:31,2018-03-14 05:13:39
IS,ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 1 5095 3729 3,When I encountered the following error while performing the training can someone help me I am a beginner of tensorflow ssh xxx xxx xxx xxx 22 usr local python3 bin python3 u xxx xxx object detection train py logtostderr WARNING tensorflow From xxx xxx object detection trainer py 210 create global step from tensorflow contrib framework python ops variables is deprecated and will be removed in a future version Instructions for updating Please switch to tf train create global step INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow depth of additional conv before box predictor 0 INFO tensorflow Summary name clone loss is illegal using clone loss instead 2018 03 13 21 57 41 631427 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2018 03 13 21 57 42 286105 I tensorflow stream executor cuda cuda gpu executor cc 892 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2018 03 13 21 57 42 286417 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 6575 pciBusID 0000 01 00 0 totalMemory 10 91GiB freeMemory 10 75GiB 2018 03 13 21 57 42 286455 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 01 00 0 compute capability 6 1 INFO tensorflow Restoring parameters from train model ckpt 0 INFO tensorflow Starting Session INFO tensorflow Saving checkpoint to path train model ckpt INFO tensorflow Starting Queues INFO tensorflow global step sec 0 INFO tensorflow Recording summary at step 0 INFO tensorflow global step 1 loss 243 3368 9 080 sec step INFO tensorflow global step 2 loss 220 1394 0 513 sec step INFO tensorflow global step 3 loss 206 3998 0 430 sec step INFO tensorflow global step 4 loss 195 3873 0 486 sec step INFO tensorflow global step 5 loss 182 0547 0 427 sec step INFO tensorflow global step 6 loss 166 7800 0 434 sec step INFO tensorflow global step 7 loss 151 5283 0 474 sec step INFO tensorflow global step 8 loss 135 1360 0 429 sec step INFO tensorflow global step 9 loss 120 5486 0 425 sec step INFO tensorflow global step 10 loss 105 3057 0 499 sec step INFO tensorflow global step 11 loss 91 5549 0 514 sec step INFO tensorflow global step 12 loss 78 9669 0 434 sec step INFO tensorflow global step 13 loss 68 9649 0 439 sec step INFO tensorflow global step 14 loss 59 8189 0 423 sec step INFO tensorflow global step 15 loss 52 2898 0 458 sec step INFO tensorflow global step 16 loss 44 7254 0 418 sec step INFO tensorflow global step 17 loss 39 1479 0 499 sec step INFO tensorflow global step 18 loss 35 2444 0 468 sec step INFO tensorflow global step 19 loss 32 0060 0 454 sec step INFO tensorflow global step 20 loss 27 3901 0 437 sec step INFO tensorflow global step 21 loss 25 8307 0 432 sec step INFO tensorflow global step 22 loss 23 7690 0 454 sec step INFO tensorflow global step 23 loss 21 4071 0 430 sec step INFO tensorflow global step 24 loss 20 4954 0 590 sec step INFO tensorflow global step 25 loss 18 6025 0 440 sec step INFO tensorflow global step 26 loss 17 7907 0 434 sec step INFO tensorflow global step 27 loss 17 7660 0 489 sec step INFO tensorflow global step 28 loss 16 7211 0 512 sec step INFO tensorflow global step 29 loss 16 5738 0 429 sec step INFO tensorflow global step 30 loss 15 5000 0 490 sec step INFO tensorflow global step 31 loss 15 0663 0 412 sec step INFO tensorflow global step 32 loss 14 5887 0 442 sec step INFO tensorflow global step 33 loss 14 8037 0 563 sec step INFO tensorflow global step 34 loss 13 5137 0 489 sec step INFO tensorflow global step 35 loss 13 0228 0 427 sec step INFO tensorflow global step 36 loss 13 4710 0 428 sec step INFO tensorflow global step 37 loss 13 7616 0 419 sec step INFO tensorflow global step 38 loss 13 2861 0 427 sec step INFO tensorflow global step 39 loss 12 2581 0 505 sec step INFO tensorflow global step 40 loss 12 7339 0 429 sec step INFO tensorflow global step 41 loss 13 2387 0 444 sec step INFO tensorflow global step 42 loss 12 3722 0 439 sec step INFO tensorflow global step 43 loss 12 8192 0 428 sec step INFO tensorflow global step 44 loss 12 0361 0 488 sec step INFO tensorflow global step 45 loss 12 1655 0 566 sec step INFO tensorflow global step 46 loss 11 7112 0 425 sec step INFO tensorflow global step 47 loss 11 3097 0 464 sec step INFO tensorflow global step 48 loss 12 2162 0 435 sec step INFO tensorflow global step 49 loss 11 7511 0 428 sec step INFO tensorflow global step 50 loss 11 2281 0 425 sec step INFO tensorflow global step 51 loss 10 9219 0 477 sec step INFO tensorflow global step 52 loss 11 8307 0 430 sec step INFO tensorflow global step 53 loss 11 4977 0 486 sec step INFO tensorflow global step 54 loss 11 5908 0 436 sec step INFO tensorflow global step 55 loss 11 7416 0 450 sec step INFO tensorflow global step 56 loss 10 8136 0 441 sec step INFO tensorflow global step 57 loss 10 9873 0 482 sec step INFO tensorflow global step 58 loss 11 0574 0 470 sec step INFO tensorflow global step 59 loss 11 4761 0 454 sec step INFO tensorflow global step 60 loss 11 7182 0 427 sec step INFO tensorflow global step 61 loss 11 6872 0 461 sec step INFO tensorflow global step 62 loss 10 8746 0 462 sec step INFO tensorflow global step 63 loss 10 6988 0 438 sec step INFO tensorflow global step 64 loss 10 5077 0 615 sec step INFO tensorflow global step 65 loss 11 0472 0 432 sec step INFO tensorflow global step 66 loss 10 6191 0 444 sec step INFO tensorflow global step 67 loss 10 3630 0 453 sec step INFO tensorflow global step 68 loss 10 0935 0 565 sec step INFO tensorflow global step 69 loss 10 5869 0 446 sec step INFO tensorflow global step 70 loss 10 6263 0 435 sec step INFO tensorflow global step 71 loss 10 4292 0 479 sec step INFO tensorflow global step 72 loss 10 5870 0 474 sec step INFO tensorflow global step 73 loss 10 6465 0 476 sec step INFO tensorflow global step 74 loss 10 8363 0 559 sec step INFO tensorflow global step 75 loss 10 9429 0 486 sec step INFO tensorflow global step 76 loss 10 3226 0 419 sec step INFO tensorflow global step 77 loss 10 7447 0 638 sec step INFO tensorflow global step 78 loss 10 1083 0 491 sec step INFO tensorflow global step 79 loss 10 7905 0 450 sec step INFO tensorflow global step 80 loss 10 6255 0 657 sec step INFO tensorflow global step 81 loss 10 9287 0 657 sec step INFO tensorflow global step 82 loss 10 2799 0 439 sec step INFO tensorflow global step 83 loss 10 1767 0 425 sec step INFO tensorflow global step 84 loss 10 3393 0 639 sec step INFO tensorflow global step 85 loss 10 6420 0 466 sec step INFO tensorflow global step 86 loss 10 5353 1 067 sec step INFO tensorflow global step 87 loss 9 7251 0 483 sec step INFO tensorflow global step 88 loss 9 9586 0 491 sec step INFO tensorflow global step 89 loss 10 5869 0 435 sec step INFO tensorflow global step 90 loss 10 6093 0 428 sec step INFO tensorflow global step 91 loss 10 6009 1 195 sec step INFO tensorflow global step 92 loss 10 1688 0 654 sec step INFO tensorflow global step 93 loss 10 5646 0 751 sec step INFO tensorflow global step 94 loss 10 0194 0 449 sec step INFO tensorflow global step 95 loss 9 9471 0 458 sec step INFO tensorflow global step 96 loss 10 1529 0 429 sec step INFO tensorflow global step 97 loss 10 2420 0 715 sec step INFO tensorflow global step 98 loss 10 2819 0 435 sec step INFO tensorflow global step 99 loss 10 1969 0 625 sec step INFO tensorflow global step 100 loss 9 9485 0 478 sec step INFO tensorflow global step 101 loss 9 9312 0 568 sec step INFO tensorflow global step 102 loss 10 0179 0 415 sec step INFO tensorflow global step 103 loss 9 9705 0 419 sec step INFO tensorflow global step 104 loss 9 8582 0 484 sec step INFO tensorflow global step 105 loss 10 4639 0 431 sec step INFO tensorflow global step 106 loss 10 2900 0 413 sec step INFO tensorflow global step 107 loss 10 3138 0 430 sec step INFO tensorflow global step 108 loss 9 6482 0 461 sec step INFO tensorflow global step 109 loss 9 5792 0 422 sec step INFO tensorflow global step 110 loss 9 7901 0 466 sec step INFO tensorflow global step 111 loss 10 4787 0 472 sec step INFO tensorflow global step 112 loss 10 6505 0 434 sec step INFO tensorflow global step 113 loss 9 7728 0 435 sec step INFO tensorflow global step 114 loss 9 7048 0 431 sec step INFO tensorflow global step 115 loss 10 3138 0 439 sec step INFO tensorflow global step 116 loss 9 5181 0 428 sec step INFO tensorflow global step 117 loss 10 2000 0 914 sec step INFO tensorflow global step 118 loss 10 3344 0 462 sec step INFO tensorflow global step 119 loss 9 5471 0 442 sec step INFO tensorflow global step 120 loss 9 4061 0 427 sec step INFO tensorflow global step 121 loss 9 5720 0 488 sec step INFO tensorflow global step 122 loss 9 3800 0 462 sec step INFO tensorflow global step 123 loss 9 4855 0 426 sec step INFO tensorflow global step 124 loss 8 9675 0 526 sec step INFO tensorflow global step 125 loss 9 4995 0 487 sec step INFO tensorflow global step 126 loss 9 2938 0 539 sec step INFO tensorflow global step 127 loss 9 7230 0 433 sec step INFO tensorflow global step 128 loss 9 8149 0 510 sec step INFO tensorflow global step 129 loss 10 1299 0 466 sec step INFO tensorflow global step 130 loss 9 7078 0 477 sec step INFO tensorflow global step 131 loss 10 0769 1 196 sec step INFO tensorflow global step 132 loss 9 4188 0 543 sec step INFO tensorflow global step 133 loss 8 9409 0 443 sec step INFO tensorflow global step 134 loss 9 3117 0 472 sec step INFO tensorflow global step 135 loss 8 9357 0 477 sec step INFO tensorflow global step 136 loss 10 4331 0 681 sec step INFO tensorflow global step 137 loss 9 3650 0 418 sec step INFO tensorflow global step 138 loss 9 1549 0 455 sec step INFO tensorflow global step 139 loss 9 2574 0 420 sec step INFO tensorflow global step 140 loss 9 2772 0 448 sec step INFO tensorflow global step 141 loss 9 6754 0 442 sec step INFO tensorflow global step 142 loss 10 1184 0 602 sec step INFO tensorflow global step 143 loss 9 1427 0 477 sec step INFO tensorflow global step 144 loss 9 2105 0 754 sec step INFO tensorflow global step 145 loss 9 1641 0 421 sec step INFO tensorflow global step 146 loss 9 6503 0 490 sec step INFO tensorflow global step 147 loss 10 1134 0 430 sec step INFO tensorflow global step 148 loss 9 3111 0 475 sec step INFO tensorflow global step 149 loss 10 0336 0 427 sec step INFO tensorflow global step 150 loss 8 5716 0 463 sec step INFO tensorflow global step 151 loss 9 5126 0 427 sec step INFO tensorflow global step 152 loss 9 9572 0 480 sec step INFO tensorflow global step 153 loss 9 0432 0 444 sec step INFO tensorflow global step 154 loss 8 7378 0 500 sec step INFO tensorflow global step 155 loss 9 2020 0 487 sec step INFO tensorflow global step 156 loss 9 8456 0 528 sec step INFO tensorflow global step 157 loss 8 7925 0 429 sec step INFO tensorflow global step 158 loss 8 8295 0 435 sec step INFO tensorflow global step 159 loss 8 9335 0 509 sec step INFO tensorflow global step 160 loss 9 1799 0 444 sec step INFO tensorflow global step 161 loss 9 4383 0 433 sec step INFO tensorflow global step 162 loss 9 5451 0 484 sec step INFO tensorflow global step 163 loss 9 8775 0 460 sec step INFO tensorflow global step 164 loss 9 1774 0 462 sec step INFO tensorflow global step 165 loss 8 8758 0 757 sec step INFO tensorflow global step 166 loss 9 2932 0 428 sec step INFO tensorflow global step 167 loss 9 1967 0 441 sec step INFO tensorflow global step 168 loss 9 6125 0 760 sec step INFO tensorflow global step 169 loss 9 0119 0 644 sec step INFO tensorflow global step 170 loss 9 7965 0 429 sec step INFO tensorflow global step 171 loss 8 8230 0 548 sec step INFO tensorflow global step 172 loss 8 6981 0 482 sec step INFO tensorflow global step 173 loss 8 4844 0 491 sec step INFO tensorflow global step 174 loss 9 4706 0 431 sec step INFO tensorflow global step 175 loss 8 5126 0 478 sec step INFO tensorflow global step 176 loss 9 2941 0 443 sec step INFO tensorflow global step 177 loss 8 9967 0 597 sec step INFO tensorflow global step 178 loss 9 5142 0 640 sec step INFO tensorflow global step 179 loss 9 4251 0 487 sec step INFO tensorflow global step 180 loss 9 5026 0 469 sec step INFO tensorflow global step 181 loss 9 3916 0 504 sec step INFO tensorflow global step 182 loss 9 7789 0 485 sec step INFO tensorflow global step 183 loss 8 8342 0 530 sec step INFO tensorflow global step 184 loss 9 1194 0 661 sec step 2018 03 13 21 59 44 843954 W tensorflow core common runtime bfc allocator cc 273 Allocator GPU 0 bfc ran out of memory trying to allocate 217 43MiB Current allocation summary follows 2018 03 13 21 59 44 845715 I tensorflow core common runtime bfc allocator cc 627 Bin 256 Total Chunks 709 Chunks in use 709 177 2KiB allocated for chunks 177 2KiB in use in bin 6 8KiB client requested in use in bin 2018 03 13 21 59 44 845777 I tensorflow core common runtime bfc allocator cc 627 Bin 512 Total Chunks 59 Chunks in use 59 29 8KiB allocated for chunks 29 8KiB in use in bin 18 4KiB client requested in use in bin 2018 03 13 21 59 44 845822 I tensorflow core common runtime bfc allocator cc 627 Bin 1024 Total Chunks 21 Chunks in use 17 25 2KiB allocated for chunks 20 8KiB in use in bin 19 6KiB client requested in use in bin 2018 03 13 21 59 44 845941 I tensorflow core common runtime bfc allocator cc 627 Bin 2048 Total Chunks 14 Chunks in use 12 35 8KiB allocated for chunks 30 2KiB in use in bin 27 1KiB client requested in use in bin 2018 03 13 21 59 44 845986 I tensorflow core common runtime bfc allocator cc 627 Bin 4096 Total Chunks 323 Chunks in use 323 2 34MiB allocated for chunks 2 34MiB in use in bin 2 33MiB client requested in use in bin 2018 03 13 21 59 44 846031 I tensorflow core common runtime bfc allocator cc 627 Bin 8192 Total Chunks 17 Chunks in use 15 189 2KiB allocated for chunks 159 0KiB in use in bin 136 9KiB client requested in use in bin 2018 03 13 21 59 44 846103 I tensorflow core common runtime bfc allocator cc 627 Bin 16384 Total Chunks 22 Chunks in use 20 600 0KiB allocated for chunks 540 0KiB in use in bin 539 4KiB client requested in use in bin 2018 03 13 21 59 44 846149 I tensorflow core common runtime bfc allocator cc 627 Bin 32768 Total Chunks 7 Chunks in use 7 318 8KiB allocated for chunks 318 8KiB in use in bin 249 9KiB client requested in use in bin 2018 03 13 21 59 44 846193 I tensorflow core common runtime bfc allocator cc 627 Bin 65536 Total Chunks 6 Chunks in use 6 448 0KiB allocated for chunks 448 0KiB in use in bin 448 0KiB client requested in use in bin 2018 03 13 21 59 44 846304 I tensorflow core common runtime bfc allocator cc 627 Bin 131072 Total Chunks 13 Chunks in use 13 2 13MiB allocated for chunks 2 13MiB in use in bin 2 04MiB client requested in use in bin 2018 03 13 21 59 44 846346 I tensorflow core common runtime bfc allocator cc 627 Bin 262144 Total Chunks 10 Chunks in use 10 3 69MiB allocated for chunks 3 69MiB in use in bin 3 46MiB client requested in use in bin 2018 03 13 21 59 44 846388 I tensorflow core common runtime bfc allocator cc 627 Bin 524288 Total Chunks 19 Chunks in use 19 11 10MiB allocated for chunks 11 10MiB in use in bin 10 88MiB client requested in use in bin 2018 03 13 21 59 44 846449 I tensorflow core common runtime bfc allocator cc 627 Bin 1048576 Total Chunks 8 Chunks in use 8 9 67MiB allocated for chunks 9 67MiB in use in bin 9 17MiB client requested in use in bin 2018 03 13 21 59 44 846491 I tensorflow core common runtime bfc allocator cc 627 Bin 2097152 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846548 I tensorflow core common runtime bfc allocator cc 627 Bin 4194304 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846593 I tensorflow core common runtime bfc allocator cc 627 Bin 8388608 Total Chunks 2 Chunks in use 2 24 57MiB allocated for chunks 24 57MiB in use in bin 24 57MiB client requested in use in bin 2018 03 13 21 59 44 846631 I tensorflow core common runtime bfc allocator cc 627 Bin 16777216 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846668 I tensorflow core common runtime bfc allocator cc 627 Bin 33554432 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846734 I tensorflow core common runtime bfc allocator cc 627 Bin 67108864 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846771 I tensorflow core common runtime bfc allocator cc 627 Bin 134217728 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B in use in bin 0B client requested in use in bin 2018 03 13 21 59 44 846812 I tensorflow core common runtime bfc allocator cc 627 Bin 268435456 Total Chunks 1 Chunks in use 1 10 16GiB allocated for chunks 10 16GiB in use in bin 5 10GiB client requested in use in bin 2018 03 13 21 59 44 846855 I tensorflow core common runtime bfc allocator cc 643 Bin for 217 43MiB was 128 00MiB Chunk State 2018 03 13 21 59 44 846889 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00000 of size 1280 2018 03 13 21 59 44 846915 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00500 of size 256 2018 03 13 21 59 44 846938 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00600 of size 256 2018 03 13 21 59 44 846960 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00700 of size 256 2018 03 13 21 59 44 846983 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00800 of size 256 2018 03 13 21 59 44 847006 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00900 of size 256 2018 03 13 21 59 44 847031 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00a00 of size 512 2018 03 13 21 59 44 847054 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00c00 of size 256 2018 03 13 21 59 44 847077 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00d00 of size 256 2018 03 13 21 59 44 847100 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00e00 of size 256 2018 03 13 21 59 44 847122 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da00f00 of size 256 2018 03 13 21 59 44 847172 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01000 of size 256 2018 03 13 21 59 44 847199 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01100 of size 256 2018 03 13 21 59 44 847231 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01200 of size 256 2018 03 13 21 59 44 847255 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01300 of size 256 2018 03 13 21 59 44 847277 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01400 of size 512 2018 03 13 21 59 44 847300 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01600 of size 256 2018 03 13 21 59 44 847322 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01700 of size 256 2018 03 13 21 59 44 847345 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01800 of size 256 2018 03 13 21 59 44 847367 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01900 of size 256 2018 03 13 21 59 44 847390 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01a00 of size 256 2018 03 13 21 59 44 847412 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01b00 of size 256 2018 03 13 21 59 44 847435 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01c00 of size 256 2018 03 13 21 59 44 847458 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01d00 of size 512 2018 03 13 21 59 44 847480 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da01f00 of size 256 2018 03 13 21 59 44 847502 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02000 of size 512 2018 03 13 21 59 44 847525 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02200 of size 256 2018 03 13 21 59 44 847547 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02300 of size 256 2018 03 13 21 59 44 847570 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02400 of size 256 2018 03 13 21 59 44 847592 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02500 of size 256 2018 03 13 21 59 44 847614 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02600 of size 256 2018 03 13 21 59 44 847637 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02700 of size 256 2018 03 13 21 59 44 847659 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02800 of size 256 2018 03 13 21 59 44 847709 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02900 of size 512 2018 03 13 21 59 44 847735 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02b00 of size 256 2018 03 13 21 59 44 847757 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02c00 of size 256 2018 03 13 21 59 44 847781 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02d00 of size 256 2018 03 13 21 59 44 847803 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02e00 of size 256 2018 03 13 21 59 44 847826 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da02f00 of size 256 2018 03 13 21 59 44 847848 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03000 of size 256 2018 03 13 21 59 44 847872 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03100 of size 256 2018 03 13 21 59 44 847921 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03200 of size 256 2018 03 13 21 59 44 847947 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03300 of size 256 2018 03 13 21 59 44 847969 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03400 of size 256 2018 03 13 21 59 44 847991 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03500 of size 256 2018 03 13 21 59 44 848014 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03600 of size 256 2018 03 13 21 59 44 848036 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03700 of size 256 2018 03 13 21 59 44 848058 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03800 of size 512 2018 03 13 21 59 44 848081 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03a00 of size 256 2018 03 13 21 59 44 848103 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03b00 of size 512 2018 03 13 21 59 44 848125 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03d00 of size 256 2018 03 13 21 59 44 848176 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03e00 of size 256 2018 03 13 21 59 44 848200 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da03f00 of size 256 2018 03 13 21 59 44 848229 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04000 of size 256 2018 03 13 21 59 44 852565 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04100 of size 256 2018 03 13 21 59 44 852644 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04200 of size 256 2018 03 13 21 59 44 852684 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04300 of size 256 2018 03 13 21 59 44 852710 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04400 of size 512 2018 03 13 21 59 44 852742 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04600 of size 256 2018 03 13 21 59 44 852771 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04700 of size 256 2018 03 13 21 59 44 852800 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04800 of size 256 2018 03 13 21 59 44 852831 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04900 of size 256 2018 03 13 21 59 44 852866 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04a00 of size 256 2018 03 13 21 59 44 852902 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04b00 of size 256 2018 03 13 21 59 44 852934 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04c00 of size 256 2018 03 13 21 59 44 852962 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04d00 of size 512 2018 03 13 21 59 44 852988 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da04f00 of size 256 2018 03 13 21 59 44 853019 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05000 of size 256 2018 03 13 21 59 44 853049 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05100 of size 256 2018 03 13 21 59 44 853077 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05200 of size 256 2018 03 13 21 59 44 853105 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05300 of size 256 2018 03 13 21 59 44 853144 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05400 of size 256 2018 03 13 21 59 44 853177 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05500 of size 256 2018 03 13 21 59 44 853202 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05600 of size 256 2018 03 13 21 59 44 853248 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05700 of size 256 2018 03 13 21 59 44 853278 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05800 of size 256 2018 03 13 21 59 44 853305 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05900 of size 256 2018 03 13 21 59 44 853335 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05a00 of size 256 2018 03 13 21 59 44 853362 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05b00 of size 256 2018 03 13 21 59 44 853399 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05c00 of size 512 2018 03 13 21 59 44 853448 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05e00 of size 256 2018 03 13 21 59 44 853495 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da05f00 of size 256 2018 03 13 21 59 44 853537 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06000 of size 256 2018 03 13 21 59 44 853570 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06100 of size 256 2018 03 13 21 59 44 853613 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06200 of size 512 2018 03 13 21 59 44 853654 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06400 of size 256 2018 03 13 21 59 44 853696 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06500 of size 256 2018 03 13 21 59 44 853736 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06600 of size 256 2018 03 13 21 59 44 853771 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06700 of size 256 2018 03 13 21 59 44 853810 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06800 of size 512 2018 03 13 21 59 44 853848 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06a00 of size 256 2018 03 13 21 59 44 853884 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06b00 of size 256 2018 03 13 21 59 44 853918 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06c00 of size 256 2018 03 13 21 59 44 853957 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06d00 of size 256 2018 03 13 21 59 44 853988 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06e00 of size 256 2018 03 13 21 59 44 854033 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da06f00 of size 256 2018 03 13 21 59 44 854068 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07000 of size 256 2018 03 13 21 59 44 854100 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07100 of size 256 2018 03 13 21 59 44 854142 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07200 of size 256 2018 03 13 21 59 44 854179 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07300 of size 256 2018 03 13 21 59 44 854215 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07400 of size 512 2018 03 13 21 59 44 854267 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07600 of size 256 2018 03 13 21 59 44 854311 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07700 of size 256 2018 03 13 21 59 44 854351 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07800 of size 256 2018 03 13 21 59 44 854379 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07900 of size 256 2018 03 13 21 59 44 854415 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07a00 of size 256 2018 03 13 21 59 44 854444 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07b00 of size 256 2018 03 13 21 59 44 854483 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07c00 of size 256 2018 03 13 21 59 44 854524 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07d00 of size 256 2018 03 13 21 59 44 854578 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07e00 of size 256 2018 03 13 21 59 44 854621 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da07f00 of size 512 2018 03 13 21 59 44 854659 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08100 of size 256 2018 03 13 21 59 44 854704 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08200 of size 256 2018 03 13 21 59 44 854740 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08300 of size 512 2018 03 13 21 59 44 854772 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08500 of size 256 2018 03 13 21 59 44 854819 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08600 of size 256 2018 03 13 21 59 44 854856 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08700 of size 256 2018 03 13 21 59 44 854892 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08800 of size 256 2018 03 13 21 59 44 854929 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08900 of size 256 2018 03 13 21 59 44 854965 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08a00 of size 256 2018 03 13 21 59 44 855000 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08b00 of size 256 2018 03 13 21 59 44 855038 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08c00 of size 256 2018 03 13 21 59 44 855070 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08d00 of size 256 2018 03 13 21 59 44 855103 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08e00 of size 256 2018 03 13 21 59 44 855142 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da08f00 of size 256 2018 03 13 21 59 44 855187 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09000 of size 256 2018 03 13 21 59 44 855234 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09100 of size 256 2018 03 13 21 59 44 855281 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09200 of size 256 2018 03 13 21 59 44 855321 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09300 of size 512 2018 03 13 21 59 44 855362 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09500 of size 256 2018 03 13 21 59 44 855406 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09600 of size 512 2018 03 13 21 59 44 855445 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09800 of size 256 2018 03 13 21 59 44 855494 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09900 of size 256 2018 03 13 21 59 44 855535 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09a00 of size 256 2018 03 13 21 59 44 855582 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09b00 of size 256 2018 03 13 21 59 44 855616 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09c00 of size 256 2018 03 13 21 59 44 855652 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09d00 of size 256 2018 03 13 21 59 44 855691 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09e00 of size 256 2018 03 13 21 59 44 855726 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da09f00 of size 256 2018 03 13 21 59 44 855773 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a000 of size 256 2018 03 13 21 59 44 855814 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a100 of size 256 2018 03 13 21 59 44 855859 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a200 of size 256 2018 03 13 21 59 44 855895 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a300 of size 512 2018 03 13 21 59 44 855929 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a500 of size 256 2018 03 13 21 59 44 855974 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a600 of size 256 2018 03 13 21 59 44 856024 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a700 of size 256 2018 03 13 21 59 44 856066 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a800 of size 256 2018 03 13 21 59 44 856107 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0a900 of size 512 2018 03 13 21 59 44 856149 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ab00 of size 256 2018 03 13 21 59 44 856189 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ac00 of size 256 2018 03 13 21 59 44 856250 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ad00 of size 256 2018 03 13 21 59 44 856284 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ae00 of size 256 2018 03 13 21 59 44 856322 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0af00 of size 256 2018 03 13 21 59 44 856357 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b000 of size 256 2018 03 13 21 59 44 856395 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b100 of size 256 2018 03 13 21 59 44 856431 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b200 of size 256 2018 03 13 21 59 44 856471 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b300 of size 512 2018 03 13 21 59 44 856515 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b500 of size 256 2018 03 13 21 59 44 856555 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b600 of size 256 2018 03 13 21 59 44 856596 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b700 of size 256 2018 03 13 21 59 44 856643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b800 of size 256 2018 03 13 21 59 44 856681 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0b900 of size 512 2018 03 13 21 59 44 856715 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0bb00 of size 256 2018 03 13 21 59 44 856749 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0bc00 of size 256 2018 03 13 21 59 44 856790 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0bd00 of size 256 2018 03 13 21 59 44 856823 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0be00 of size 256 2018 03 13 21 59 44 856855 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0bf00 of size 256 2018 03 13 21 59 44 856896 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c000 of size 256 2018 03 13 21 59 44 856929 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c100 of size 256 2018 03 13 21 59 44 856965 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c200 of size 256 2018 03 13 21 59 44 856999 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c300 of size 256 2018 03 13 21 59 44 857036 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c400 of size 256 2018 03 13 21 59 44 857078 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c500 of size 512 2018 03 13 21 59 44 857110 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c700 of size 256 2018 03 13 21 59 44 857147 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c800 of size 256 2018 03 13 21 59 44 857193 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0c900 of size 256 2018 03 13 21 59 44 857235 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ca00 of size 256 2018 03 13 21 59 44 857280 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0cb00 of size 256 2018 03 13 21 59 44 857322 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0cc00 of size 256 2018 03 13 21 59 44 857357 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0cd00 of size 256 2018 03 13 21 59 44 857406 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0ce00 of size 256 2018 03 13 21 59 44 857438 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0cf00 of size 256 2018 03 13 21 59 44 857475 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d000 of size 256 2018 03 13 21 59 44 857510 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d100 of size 512 2018 03 13 21 59 44 857554 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d300 of size 256 2018 03 13 21 59 44 857593 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d400 of size 256 2018 03 13 21 59 44 857633 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d500 of size 256 2018 03 13 21 59 44 857669 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d600 of size 256 2018 03 13 21 59 44 857690 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d700 of size 256 2018 03 13 21 59 44 857699 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d800 of size 256 2018 03 13 21 59 44 857706 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0d900 of size 256 2018 03 13 21 59 44 857712 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0da00 of size 512 2018 03 13 21 59 44 857717 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0dc00 of size 256 2018 03 13 21 59 44 857723 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0dd00 of size 256 2018 03 13 21 59 44 857743 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0de00 of size 256 2018 03 13 21 59 44 857752 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0df00 of size 256 2018 03 13 21 59 44 857758 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e000 of size 256 2018 03 13 21 59 44 857764 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e100 of size 256 2018 03 13 21 59 44 857769 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e200 of size 256 2018 03 13 21 59 44 857775 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e300 of size 256 2018 03 13 21 59 44 857782 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e400 of size 256 2018 03 13 21 59 44 857791 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020da0e500 of size 12882432 2018 03 13 21 59 44 857798 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e657700 of size 256 2018 03 13 21 59 44 857804 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e657800 of size 7680 2018 03 13 21 59 44 857809 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e659600 of size 7680 2018 03 13 21 59 44 857815 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e65b400 of size 7680 2018 03 13 21 59 44 857820 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e65d200 of size 7680 2018 03 13 21 59 44 857826 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e65f000 of size 7680 2018 03 13 21 59 44 857835 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e660e00 of size 7680 2018 03 13 21 59 44 857842 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e662c00 of size 7680 2018 03 13 21 59 44 857847 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e664a00 of size 7680 2018 03 13 21 59 44 857853 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e666800 of size 7680 2018 03 13 21 59 44 857858 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e668600 of size 7680 2018 03 13 21 59 44 857864 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e66a400 of size 7680 2018 03 13 21 59 44 857869 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e66c200 of size 7680 2018 03 13 21 59 44 857874 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e66e000 of size 7680 2018 03 13 21 59 44 857880 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e66fe00 of size 7680 2018 03 13 21 59 44 857887 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e671c00 of size 7680 2018 03 13 21 59 44 857895 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e673a00 of size 7680 2018 03 13 21 59 44 857900 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e675800 of size 7680 2018 03 13 21 59 44 857906 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e677600 of size 7680 2018 03 13 21 59 44 857912 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e679400 of size 7680 2018 03 13 21 59 44 857918 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e67b200 of size 7680 2018 03 13 21 59 44 857923 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e67d000 of size 7680 2018 03 13 21 59 44 857929 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e67ee00 of size 7680 2018 03 13 21 59 44 857934 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e680c00 of size 7680 2018 03 13 21 59 44 857941 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e682a00 of size 7680 2018 03 13 21 59 44 857947 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e684800 of size 7680 2018 03 13 21 59 44 857952 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e686600 of size 7680 2018 03 13 21 59 44 857958 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e688400 of size 7680 2018 03 13 21 59 44 857964 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e68a200 of size 7680 2018 03 13 21 59 44 857968 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e68c000 of size 7680 2018 03 13 21 59 44 857974 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e68de00 of size 7680 2018 03 13 21 59 44 857980 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e68fc00 of size 7680 2018 03 13 21 59 44 857985 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e691a00 of size 7680 2018 03 13 21 59 44 857992 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e693800 of size 7680 2018 03 13 21 59 44 858000 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e695600 of size 7680 2018 03 13 21 59 44 858006 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e697400 of size 7680 2018 03 13 21 59 44 858012 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e699200 of size 7680 2018 03 13 21 59 44 858017 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e69b000 of size 7680 2018 03 13 21 59 44 858023 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e69ce00 of size 7680 2018 03 13 21 59 44 858028 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e69ec00 of size 7680 2018 03 13 21 59 44 858034 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6a0a00 of size 7680 2018 03 13 21 59 44 858040 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6a2800 of size 7680 2018 03 13 21 59 44 858046 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6a4600 of size 7680 2018 03 13 21 59 44 858052 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6a6400 of size 7680 2018 03 13 21 59 44 858057 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6a8200 of size 7680 2018 03 13 21 59 44 858063 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6aa000 of size 7680 2018 03 13 21 59 44 858068 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6abe00 of size 7680 2018 03 13 21 59 44 858074 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6adc00 of size 7680 2018 03 13 21 59 44 858080 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6afa00 of size 7680 2018 03 13 21 59 44 858085 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6b1800 of size 7680 2018 03 13 21 59 44 858091 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6b3600 of size 7680 2018 03 13 21 59 44 858098 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6b5400 of size 7680 2018 03 13 21 59 44 858105 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6b7200 of size 7680 2018 03 13 21 59 44 858111 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6b9000 of size 7680 2018 03 13 21 59 44 858116 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6bae00 of size 7680 2018 03 13 21 59 44 858121 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6bcc00 of size 7680 2018 03 13 21 59 44 858127 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6bea00 of size 7680 2018 03 13 21 59 44 858133 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c0800 of size 7680 2018 03 13 21 59 44 858137 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c2600 of size 7680 2018 03 13 21 59 44 858143 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c4400 of size 7680 2018 03 13 21 59 44 858151 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c6200 of size 7680 2018 03 13 21 59 44 858159 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c8000 of size 7680 2018 03 13 21 59 44 858164 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6c9e00 of size 7680 2018 03 13 21 59 44 858170 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6cbc00 of size 7680 2018 03 13 21 59 44 858175 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6cda00 of size 7680 2018 03 13 21 59 44 858180 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6cf800 of size 7680 2018 03 13 21 59 44 858186 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6d1600 of size 7680 2018 03 13 21 59 44 858191 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6d3400 of size 7680 2018 03 13 21 59 44 858197 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6d5200 of size 7680 2018 03 13 21 59 44 858204 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6d7000 of size 7680 2018 03 13 21 59 44 858210 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6d8e00 of size 7680 2018 03 13 21 59 44 858215 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6dac00 of size 7680 2018 03 13 21 59 44 858222 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6dca00 of size 7680 2018 03 13 21 59 44 858243 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6de800 of size 7680 2018 03 13 21 59 44 858248 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e0600 of size 7680 2018 03 13 21 59 44 858255 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e2400 of size 7680 2018 03 13 21 59 44 858277 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e4200 of size 7680 2018 03 13 21 59 44 858283 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e6000 of size 7680 2018 03 13 21 59 44 858288 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e7e00 of size 7680 2018 03 13 21 59 44 858294 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6e9c00 of size 7680 2018 03 13 21 59 44 858299 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6eba00 of size 7680 2018 03 13 21 59 44 858307 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6ed800 of size 7680 2018 03 13 21 59 44 858312 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6ef600 of size 7680 2018 03 13 21 59 44 858318 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6f1400 of size 7680 2018 03 13 21 59 44 858324 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6f3200 of size 7680 2018 03 13 21 59 44 858329 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6f5000 of size 7680 2018 03 13 21 59 44 858335 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6f6e00 of size 7680 2018 03 13 21 59 44 858340 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6f8c00 of size 7680 2018 03 13 21 59 44 858346 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6faa00 of size 7680 2018 03 13 21 59 44 858351 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6fc800 of size 7680 2018 03 13 21 59 44 858357 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e6fe600 of size 7680 2018 03 13 21 59 44 858364 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e700400 of size 7680 2018 03 13 21 59 44 858370 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e702200 of size 7680 2018 03 13 21 59 44 858375 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e704000 of size 7680 2018 03 13 21 59 44 858381 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e705e00 of size 7680 2018 03 13 21 59 44 858386 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e707c00 of size 7680 2018 03 13 21 59 44 858392 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e709a00 of size 7680 2018 03 13 21 59 44 858397 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e70b800 of size 7680 2018 03 13 21 59 44 858403 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e70d600 of size 7680 2018 03 13 21 59 44 858408 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e70f400 of size 7680 2018 03 13 21 59 44 858415 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e711200 of size 7680 2018 03 13 21 59 44 858422 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e713000 of size 7680 2018 03 13 21 59 44 858427 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e714e00 of size 7680 2018 03 13 21 59 44 858433 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e716c00 of size 7680 2018 03 13 21 59 44 858438 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e718a00 of size 7680 2018 03 13 21 59 44 858444 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e71a800 of size 7680 2018 03 13 21 59 44 858448 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e71c600 of size 7680 2018 03 13 21 59 44 858454 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e71e400 of size 7680 2018 03 13 21 59 44 858459 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e720200 of size 7680 2018 03 13 21 59 44 858467 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e722000 of size 7680 2018 03 13 21 59 44 858476 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e723e00 of size 7680 2018 03 13 21 59 44 858483 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e725c00 of size 7680 2018 03 13 21 59 44 858489 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e727a00 of size 7680 2018 03 13 21 59 44 858494 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e729800 of size 7680 2018 03 13 21 59 44 858500 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e72b600 of size 7680 2018 03 13 21 59 44 858506 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e72d400 of size 7680 2018 03 13 21 59 44 858511 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e72f200 of size 7680 2018 03 13 21 59 44 858519 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e731000 of size 7680 2018 03 13 21 59 44 858525 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e732e00 of size 7680 2018 03 13 21 59 44 858531 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e734c00 of size 7680 2018 03 13 21 59 44 858537 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e736a00 of size 7680 2018 03 13 21 59 44 858541 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e738800 of size 7680 2018 03 13 21 59 44 858547 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e73a600 of size 7680 2018 03 13 21 59 44 858552 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e73c400 of size 7680 2018 03 13 21 59 44 858558 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e73e200 of size 7680 2018 03 13 21 59 44 858563 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e740000 of size 7680 2018 03 13 21 59 44 858570 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e741e00 of size 7680 2018 03 13 21 59 44 858580 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e743c00 of size 7680 2018 03 13 21 59 44 858586 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e745a00 of size 7680 2018 03 13 21 59 44 858592 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e747800 of size 7680 2018 03 13 21 59 44 858597 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e749600 of size 7680 2018 03 13 21 59 44 858603 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e74b400 of size 7680 2018 03 13 21 59 44 858608 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e74d200 of size 7680 2018 03 13 21 59 44 858614 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e74f000 of size 7680 2018 03 13 21 59 44 858619 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e750e00 of size 7680 2018 03 13 21 59 44 858627 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e752c00 of size 7680 2018 03 13 21 59 44 858632 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e754a00 of size 7680 2018 03 13 21 59 44 858638 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e756800 of size 7680 2018 03 13 21 59 44 858643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e758600 of size 7680 2018 03 13 21 59 44 858649 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e75a400 of size 7680 2018 03 13 21 59 44 858654 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e75c200 of size 7680 2018 03 13 21 59 44 858659 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e75e000 of size 7680 2018 03 13 21 59 44 858665 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e75fe00 of size 7680 2018 03 13 21 59 44 858671 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e761c00 of size 7680 2018 03 13 21 59 44 858678 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e763a00 of size 7680 2018 03 13 21 59 44 858685 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e765800 of size 736256 2018 03 13 21 59 44 858690 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e819400 of size 184064 2018 03 13 21 59 44 858696 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e846300 of size 184064 2018 03 13 21 59 44 858701 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e873200 of size 184064 2018 03 13 21 59 44 858707 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8a0100 of size 184064 2018 03 13 21 59 44 858712 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8cd000 of size 30720 2018 03 13 21 59 44 858717 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4800 of size 256 2018 03 13 21 59 44 858723 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4900 of size 256 2018 03 13 21 59 44 858731 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4a00 of size 256 2018 03 13 21 59 44 858739 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4b00 of size 256 2018 03 13 21 59 44 858745 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4c00 of size 256 2018 03 13 21 59 44 858750 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4d00 of size 256 2018 03 13 21 59 44 858770 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4e00 of size 256 2018 03 13 21 59 44 858776 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d4f00 of size 256 2018 03 13 21 59 44 858785 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5000 of size 256 2018 03 13 21 59 44 858790 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5100 of size 256 2018 03 13 21 59 44 858795 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5200 of size 256 2018 03 13 21 59 44 858814 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5300 of size 256 2018 03 13 21 59 44 858819 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5400 of size 256 2018 03 13 21 59 44 858825 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5500 of size 256 2018 03 13 21 59 44 858830 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5600 of size 256 2018 03 13 21 59 44 858840 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5700 of size 256 2018 03 13 21 59 44 858846 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5800 of size 256 2018 03 13 21 59 44 858851 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5900 of size 256 2018 03 13 21 59 44 858856 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5a00 of size 256 2018 03 13 21 59 44 858862 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5b00 of size 256 2018 03 13 21 59 44 858867 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5c00 of size 256 2018 03 13 21 59 44 858873 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5d00 of size 256 2018 03 13 21 59 44 858878 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5e00 of size 256 2018 03 13 21 59 44 858884 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d5f00 of size 256 2018 03 13 21 59 44 858889 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6000 of size 256 2018 03 13 21 59 44 858895 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6100 of size 256 2018 03 13 21 59 44 858900 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6200 of size 256 2018 03 13 21 59 44 858906 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6300 of size 256 2018 03 13 21 59 44 858911 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6400 of size 256 2018 03 13 21 59 44 858916 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6500 of size 256 2018 03 13 21 59 44 858922 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6600 of size 256 2018 03 13 21 59 44 858927 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6700 of size 256 2018 03 13 21 59 44 858933 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6800 of size 256 2018 03 13 21 59 44 858939 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6900 of size 256 2018 03 13 21 59 44 858944 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6a00 of size 256 2018 03 13 21 59 44 858950 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6b00 of size 256 2018 03 13 21 59 44 858955 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6c00 of size 256 2018 03 13 21 59 44 858961 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6d00 of size 256 2018 03 13 21 59 44 858965 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6e00 of size 256 2018 03 13 21 59 44 858972 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d6f00 of size 256 2018 03 13 21 59 44 858977 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7000 of size 256 2018 03 13 21 59 44 858982 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7100 of size 256 2018 03 13 21 59 44 858988 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7200 of size 256 2018 03 13 21 59 44 858993 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7300 of size 256 2018 03 13 21 59 44 858999 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7400 of size 256 2018 03 13 21 59 44 859004 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7500 of size 256 2018 03 13 21 59 44 859010 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7600 of size 256 2018 03 13 21 59 44 859015 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7700 of size 256 2018 03 13 21 59 44 859021 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7800 of size 256 2018 03 13 21 59 44 859026 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7900 of size 256 2018 03 13 21 59 44 859031 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7a00 of size 256 2018 03 13 21 59 44 859037 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7b00 of size 256 2018 03 13 21 59 44 859043 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7c00 of size 256 2018 03 13 21 59 44 859048 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7d00 of size 256 2018 03 13 21 59 44 859053 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7e00 of size 256 2018 03 13 21 59 44 859059 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d7f00 of size 256 2018 03 13 21 59 44 859064 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8000 of size 256 2018 03 13 21 59 44 859070 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8100 of size 256 2018 03 13 21 59 44 859076 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8200 of size 256 2018 03 13 21 59 44 859081 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8300 of size 256 2018 03 13 21 59 44 859087 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8400 of size 256 2018 03 13 21 59 44 859094 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8500 of size 256 2018 03 13 21 59 44 859103 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8600 of size 256 2018 03 13 21 59 44 859109 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8700 of size 256 2018 03 13 21 59 44 859114 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8800 of size 256 2018 03 13 21 59 44 859120 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8900 of size 256 2018 03 13 21 59 44 859125 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8a00 of size 256 2018 03 13 21 59 44 859131 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8b00 of size 256 2018 03 13 21 59 44 859136 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8c00 of size 256 2018 03 13 21 59 44 859142 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8d00 of size 256 2018 03 13 21 59 44 859147 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8e00 of size 256 2018 03 13 21 59 44 859153 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d8f00 of size 256 2018 03 13 21 59 44 859158 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9000 of size 256 2018 03 13 21 59 44 859164 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9100 of size 256 2018 03 13 21 59 44 859169 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9200 of size 256 2018 03 13 21 59 44 859175 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9300 of size 256 2018 03 13 21 59 44 859180 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9400 of size 256 2018 03 13 21 59 44 859185 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9500 of size 256 2018 03 13 21 59 44 859191 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9600 of size 256 2018 03 13 21 59 44 859196 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9700 of size 256 2018 03 13 21 59 44 859202 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9800 of size 256 2018 03 13 21 59 44 859210 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9900 of size 256 2018 03 13 21 59 44 859215 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9a00 of size 256 2018 03 13 21 59 44 859224 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9b00 of size 256 2018 03 13 21 59 44 859245 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9c00 of size 256 2018 03 13 21 59 44 859250 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9d00 of size 256 2018 03 13 21 59 44 859256 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9e00 of size 256 2018 03 13 21 59 44 859261 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8d9f00 of size 256 2018 03 13 21 59 44 859280 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da000 of size 256 2018 03 13 21 59 44 859289 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da100 of size 256 2018 03 13 21 59 44 859294 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da200 of size 256 2018 03 13 21 59 44 859300 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da300 of size 256 2018 03 13 21 59 44 859305 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da400 of size 256 2018 03 13 21 59 44 859310 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da500 of size 256 2018 03 13 21 59 44 859316 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da600 of size 256 2018 03 13 21 59 44 859322 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da700 of size 256 2018 03 13 21 59 44 859326 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da800 of size 256 2018 03 13 21 59 44 859332 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8da900 of size 256 2018 03 13 21 59 44 859337 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8daa00 of size 256 2018 03 13 21 59 44 859343 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8dab00 of size 512 2018 03 13 21 59 44 859348 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8dad00 of size 1024 2018 03 13 21 59 44 859354 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8db100 of size 256 2018 03 13 21 59 44 859359 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8db200 of size 256 2018 03 13 21 59 44 859365 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8db300 of size 256 2018 03 13 21 59 44 859370 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8db400 of size 24576 2018 03 13 21 59 44 859376 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8e1400 of size 98304 2018 03 13 21 59 44 859381 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8f9400 of size 256 2018 03 13 21 59 44 859387 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8f9500 of size 24576 2018 03 13 21 59 44 859392 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e8ff500 of size 49152 2018 03 13 21 59 44 859398 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e90b500 of size 98304 2018 03 13 21 59 44 859404 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e923500 of size 524288 2018 03 13 21 59 44 859408 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a3500 of size 256 2018 03 13 21 59 44 859414 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a3600 of size 256 2018 03 13 21 59 44 859419 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a3700 of size 512 2018 03 13 21 59 44 859425 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a3900 of size 24576 2018 03 13 21 59 44 859430 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a9900 of size 256 2018 03 13 21 59 44 859436 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9a9a00 of size 9216 2018 03 13 21 59 44 859442 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9abe00 of size 18432 2018 03 13 21 59 44 859447 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9b0600 of size 256 2018 03 13 21 59 44 859453 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9b0700 of size 24576 2018 03 13 21 59 44 859458 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9b6700 of size 256 2018 03 13 21 59 44 859464 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9b6800 of size 262144 2018 03 13 21 59 44 859469 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9f6800 of size 256 2018 03 13 21 59 44 859475 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020e9f6900 of size 65536 2018 03 13 21 59 44 859480 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea06900 of size 12288 2018 03 13 21 59 44 859486 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea09900 of size 9216 2018 03 13 21 59 44 859491 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea0bd00 of size 256 2018 03 13 21 59 44 859497 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea0be00 of size 131072 2018 03 13 21 59 44 859503 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea2be00 of size 12288 2018 03 13 21 59 44 859509 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea2ee00 of size 4608 2018 03 13 21 59 44 859514 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea30000 of size 65536 2018 03 13 21 59 44 859520 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea40000 of size 4608 2018 03 13 21 59 44 859526 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea41200 of size 2048 2018 03 13 21 59 44 859531 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea41a00 of size 32768 2018 03 13 21 59 44 859539 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea49a00 of size 49152 2018 03 13 21 59 44 859547 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ea55a00 of size 524288 2018 03 13 21 59 44 859554 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ead5a00 of size 2304 2018 03 13 21 59 44 859560 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ead6300 of size 9216 2018 03 13 21 59 44 859566 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ead8700 of size 1179648 2018 03 13 21 59 44 859571 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ebf8700 of size 8192 2018 03 13 21 59 44 859577 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ebfa700 of size 1280 2018 03 13 21 59 44 859583 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ebfac00 of size 1024 2018 03 13 21 59 44 859588 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ebfb000 of size 3584 2018 03 13 21 59 44 859594 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ebfbe00 of size 430080 2018 03 13 21 59 44 859599 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ec64e00 of size 8192 2018 03 13 21 59 44 859605 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ec66e00 of size 256 2018 03 13 21 59 44 859611 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ec66f00 of size 24576 2018 03 13 21 59 44 859617 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ec6cf00 of size 1024 2018 03 13 21 59 44 859622 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ec6d300 of size 1048576 2018 03 13 21 59 44 859627 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ed6d300 of size 1280 2018 03 13 21 59 44 859632 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ed6d800 of size 65536 2018 03 13 21 59 44 859638 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ed7d800 of size 32768 2018 03 13 21 59 44 859643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ed85800 of size 430080 2018 03 13 21 59 44 859649 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020edee800 of size 262144 2018 03 13 21 59 44 859654 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ee2e800 of size 18432 2018 03 13 21 59 44 859660 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ee33000 of size 9216 2018 03 13 21 59 44 859665 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ee35400 of size 24576 2018 03 13 21 59 44 859671 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ee3b400 of size 1179648 2018 03 13 21 59 44 859676 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5b400 of size 1024 2018 03 13 21 59 44 859681 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5b800 of size 3584 2018 03 13 21 59 44 859687 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5c600 of size 2304 2018 03 13 21 59 44 859692 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5cf00 of size 2048 2018 03 13 21 59 44 859698 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5d700 of size 1792 2018 03 13 21 59 44 859703 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ef5de00 of size 1048576 2018 03 13 21 59 44 859709 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f05de00 of size 4608 2018 03 13 21 59 44 859714 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f05f000 of size 1720320 2018 03 13 21 59 44 859720 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f203000 of size 131072 2018 03 13 21 59 44 859726 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f223000 of size 65536 2018 03 13 21 59 44 859731 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f233000 of size 1024 2018 03 13 21 59 44 859736 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f233400 of size 1792 2018 03 13 21 59 44 859742 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f233b00 of size 4608 2018 03 13 21 59 44 859748 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f234d00 of size 430080 2018 03 13 21 59 44 859753 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f29dd00 of size 1792 2018 03 13 21 59 44 859758 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f29e400 of size 1024 2018 03 13 21 59 44 859764 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f29e800 of size 430080 2018 03 13 21 59 44 859770 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f307800 of size 1024 2018 03 13 21 59 44 859775 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f307c00 of size 1792 2018 03 13 21 59 44 859781 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f308300 of size 430080 2018 03 13 21 59 44 859786 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f371300 of size 1024 2018 03 13 21 59 44 859793 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f371700 of size 1024 2018 03 13 21 59 44 859803 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f371b00 of size 512 2018 03 13 21 59 44 859810 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f371d00 of size 7424 2018 03 13 21 59 44 859816 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f373a00 of size 430080 2018 03 13 21 59 44 859821 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dca00 of size 512 2018 03 13 21 59 44 859826 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dcc00 of size 2048 2018 03 13 21 59 44 859847 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dd400 of size 512 2018 03 13 21 59 44 859852 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dd600 of size 512 2018 03 13 21 59 44 859858 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dd800 of size 1024 2018 03 13 21 59 44 859864 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3ddc00 of size 4096 2018 03 13 21 59 44 859870 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dec00 of size 256 2018 03 13 21 59 44 859888 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3ded00 of size 256 2018 03 13 21 59 44 859894 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dee00 of size 256 2018 03 13 21 59 44 859899 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3def00 of size 512 2018 03 13 21 59 44 859905 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3df100 of size 256 2018 03 13 21 59 44 859910 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3df600 of size 256 2018 03 13 21 59 44 859916 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3df700 of size 256 2018 03 13 21 59 44 859921 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3df800 of size 256 2018 03 13 21 59 44 859926 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3df900 of size 256 2018 03 13 21 59 44 859931 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dfa00 of size 256 2018 03 13 21 59 44 859936 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dfb00 of size 256 2018 03 13 21 59 44 859943 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dfc00 of size 256 2018 03 13 21 59 44 859947 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dfd00 of size 256 2018 03 13 21 59 44 859953 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dfe00 of size 256 2018 03 13 21 59 44 859958 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3dff00 of size 256 2018 03 13 21 59 44 859963 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3e0000 of size 512 2018 03 13 21 59 44 859969 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3e0200 of size 256 2018 03 13 21 59 44 859974 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3e0300 of size 256 2018 03 13 21 59 44 859979 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3e0400 of size 256 2018 03 13 21 59 44 859985 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f3e0500 of size 131072 2018 03 13 21 59 44 859990 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f400500 of size 512 2018 03 13 21 59 44 859995 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f400700 of size 2048 2018 03 13 21 59 44 860001 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f400f00 of size 3584 2018 03 13 21 59 44 860006 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f401d00 of size 256 2018 03 13 21 59 44 860012 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f401e00 of size 256 2018 03 13 21 59 44 860018 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f401f00 of size 256 2018 03 13 21 59 44 860023 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f402000 of size 256 2018 03 13 21 59 44 860029 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f402100 of size 256 2018 03 13 21 59 44 860035 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f402200 of size 256 2018 03 13 21 59 44 860039 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f402300 of size 256 2018 03 13 21 59 44 860046 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f402400 of size 256 2018 03 13 21 59 44 860051 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f403300 of size 256 2018 03 13 21 59 44 860061 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f403400 of size 131072 2018 03 13 21 59 44 860068 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f423400 of size 5376 2018 03 13 21 59 44 860074 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f424900 of size 5376 2018 03 13 21 59 44 860080 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f426200 of size 677888 2018 03 13 21 59 44 860086 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4cba00 of size 2048 2018 03 13 21 59 44 860092 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4cca00 of size 4096 2018 03 13 21 59 44 860097 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4cda00 of size 10240 2018 03 13 21 59 44 860103 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d0200 of size 5120 2018 03 13 21 59 44 860108 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d1600 of size 256 2018 03 13 21 59 44 860114 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d1700 of size 7680 2018 03 13 21 59 44 860120 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d3500 of size 14592 2018 03 13 21 59 44 860125 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d6e00 of size 7680 2018 03 13 21 59 44 860130 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4d8c00 of size 7680 2018 03 13 21 59 44 860135 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4daa00 of size 7680 2018 03 13 21 59 44 860141 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4dc800 of size 7680 2018 03 13 21 59 44 860146 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4de600 of size 7680 2018 03 13 21 59 44 860152 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4e0400 of size 7680 2018 03 13 21 59 44 860158 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f4e2200 of size 1720320 2018 03 13 21 59 44 860163 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f686200 of size 1179648 2018 03 13 21 59 44 860168 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7a6200 of size 7680 2018 03 13 21 59 44 860173 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7a8000 of size 7680 2018 03 13 21 59 44 860179 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7a9e00 of size 7680 2018 03 13 21 59 44 860184 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7abc00 of size 7680 2018 03 13 21 59 44 860190 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7ada00 of size 30720 2018 03 13 21 59 44 860196 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7b5200 of size 30720 2018 03 13 21 59 44 860201 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7bca00 of size 7680 2018 03 13 21 59 44 860207 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7be800 of size 7680 2018 03 13 21 59 44 860212 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c0600 of size 7680 2018 03 13 21 59 44 860218 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c2400 of size 7680 2018 03 13 21 59 44 860240 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c4200 of size 11776 2018 03 13 21 59 44 860246 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c7000 of size 256 2018 03 13 21 59 44 860251 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c7100 of size 256 2018 03 13 21 59 44 860257 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c7200 of size 256 2018 03 13 21 59 44 860274 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c7300 of size 2816 2018 03 13 21 59 44 860280 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c8300 of size 2560 2018 03 13 21 59 44 860285 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c8d00 of size 256 2018 03 13 21 59 44 860291 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7c8e00 of size 7936 2018 03 13 21 59 44 860296 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cad00 of size 8192 2018 03 13 21 59 44 860301 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7ccd00 of size 9984 2018 03 13 21 59 44 860308 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf400 of size 256 2018 03 13 21 59 44 860318 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf500 of size 256 2018 03 13 21 59 44 860325 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf600 of size 256 2018 03 13 21 59 44 860330 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf700 of size 256 2018 03 13 21 59 44 860336 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf800 of size 256 2018 03 13 21 59 44 860341 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cf900 of size 256 2018 03 13 21 59 44 860347 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cfa00 of size 256 2018 03 13 21 59 44 860353 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cfb00 of size 256 2018 03 13 21 59 44 860358 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cfc00 of size 256 2018 03 13 21 59 44 860364 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cfd00 of size 256 2018 03 13 21 59 44 860368 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cfe00 of size 256 2018 03 13 21 59 44 860374 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7cff00 of size 256 2018 03 13 21 59 44 860379 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0000 of size 256 2018 03 13 21 59 44 860385 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0100 of size 256 2018 03 13 21 59 44 860391 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0200 of size 256 2018 03 13 21 59 44 860395 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0300 of size 512 2018 03 13 21 59 44 860401 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0500 of size 256 2018 03 13 21 59 44 860405 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0600 of size 256 2018 03 13 21 59 44 860411 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d0700 of size 7680 2018 03 13 21 59 44 860416 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d2500 of size 7680 2018 03 13 21 59 44 860422 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d4300 of size 256 2018 03 13 21 59 44 860427 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d4400 of size 768 2018 03 13 21 59 44 860433 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d4c00 of size 7680 2018 03 13 21 59 44 860438 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7d6a00 of size 15104 2018 03 13 21 59 44 860444 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7da500 of size 7680 2018 03 13 21 59 44 860449 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7dc300 of size 7680 2018 03 13 21 59 44 860454 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7de100 of size 7680 2018 03 13 21 59 44 860459 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7dff00 of size 7680 2018 03 13 21 59 44 860464 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7e1d00 of size 7680 2018 03 13 21 59 44 860470 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7e3b00 of size 7680 2018 03 13 21 59 44 860475 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7e5900 of size 60928 2018 03 13 21 59 44 860481 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7f4700 of size 30720 2018 03 13 21 59 44 860486 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f7fbf00 of size 15104 2018 03 13 21 59 44 860491 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f803700 of size 30720 2018 03 13 21 59 44 860497 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f80af00 of size 46080 2018 03 13 21 59 44 860502 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f819f00 of size 30720 2018 03 13 21 59 44 860507 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f821700 of size 30720 2018 03 13 21 59 44 860512 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f828f00 of size 30720 2018 03 13 21 59 44 860517 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f830700 of size 30720 2018 03 13 21 59 44 860522 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f837f00 of size 30720 2018 03 13 21 59 44 860528 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f846f00 of size 55552 2018 03 13 21 59 44 860533 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f854800 of size 860160 2018 03 13 21 59 44 860539 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f926800 of size 860160 2018 03 13 21 59 44 860545 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020f9f8800 of size 532224 2018 03 13 21 59 44 860550 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fa7a700 of size 262144 2018 03 13 21 59 44 860556 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020faba700 of size 30720 2018 03 13 21 59 44 860562 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fac1f00 of size 240128 2018 03 13 21 59 44 860568 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fafc900 of size 534016 2018 03 13 21 59 44 860578 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fb86700 of size 499712 2018 03 13 21 59 44 860584 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fc00700 of size 536832 2018 03 13 21 59 44 860590 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fc83800 of size 536320 2018 03 13 21 59 44 860595 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fd06700 of size 536832 2018 03 13 21 59 44 860600 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fd89800 of size 536832 2018 03 13 21 59 44 860606 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020fe0c900 of size 1067520 2018 03 13 21 59 44 860611 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ff11300 of size 536832 2018 03 13 21 59 44 860616 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1020ff94400 of size 536832 2018 03 13 21 59 44 860622 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210017500 of size 536832 2018 03 13 21 59 44 860627 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021009a600 of size 536832 2018 03 13 21 59 44 860632 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021011d700 of size 625664 2018 03 13 21 59 44 860638 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6300 of size 256 2018 03 13 21 59 44 860643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6400 of size 256 2018 03 13 21 59 44 860649 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6500 of size 256 2018 03 13 21 59 44 860655 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6600 of size 512 2018 03 13 21 59 44 860660 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6800 of size 256 2018 03 13 21 59 44 860665 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6900 of size 256 2018 03 13 21 59 44 860670 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6a00 of size 256 2018 03 13 21 59 44 860675 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6b00 of size 256 2018 03 13 21 59 44 860681 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6c00 of size 256 2018 03 13 21 59 44 860686 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6d00 of size 256 2018 03 13 21 59 44 860692 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6e00 of size 256 2018 03 13 21 59 44 860697 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b6f00 of size 256 2018 03 13 21 59 44 860703 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7000 of size 256 2018 03 13 21 59 44 860708 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7100 of size 256 2018 03 13 21 59 44 860714 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7200 of size 256 2018 03 13 21 59 44 860719 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7300 of size 512 2018 03 13 21 59 44 860725 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7500 of size 256 2018 03 13 21 59 44 860731 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7600 of size 256 2018 03 13 21 59 44 860736 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7700 of size 256 2018 03 13 21 59 44 860741 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7800 of size 256 2018 03 13 21 59 44 860747 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7900 of size 256 2018 03 13 21 59 44 860752 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7a00 of size 256 2018 03 13 21 59 44 860757 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7b00 of size 256 2018 03 13 21 59 44 860763 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7c00 of size 256 2018 03 13 21 59 44 860769 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7d00 of size 512 2018 03 13 21 59 44 860774 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b7f00 of size 256 2018 03 13 21 59 44 860780 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8000 of size 256 2018 03 13 21 59 44 860785 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8100 of size 256 2018 03 13 21 59 44 860790 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8200 of size 256 2018 03 13 21 59 44 860796 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8300 of size 256 2018 03 13 21 59 44 860801 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8400 of size 256 2018 03 13 21 59 44 860807 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8500 of size 256 2018 03 13 21 59 44 860812 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8600 of size 256 2018 03 13 21 59 44 860817 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8700 of size 256 2018 03 13 21 59 44 860823 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8800 of size 256 2018 03 13 21 59 44 860828 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8900 of size 256 2018 03 13 21 59 44 860836 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8a00 of size 512 2018 03 13 21 59 44 860845 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8c00 of size 256 2018 03 13 21 59 44 860852 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8d00 of size 256 2018 03 13 21 59 44 860857 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8e00 of size 256 2018 03 13 21 59 44 860863 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b8f00 of size 256 2018 03 13 21 59 44 860867 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102101b9000 of size 736256 2018 03 13 21 59 44 860873 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026cc00 of size 256 2018 03 13 21 59 44 860879 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026cd00 of size 256 2018 03 13 21 59 44 860884 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ce00 of size 512 2018 03 13 21 59 44 860890 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d000 of size 256 2018 03 13 21 59 44 860895 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d100 of size 256 2018 03 13 21 59 44 860901 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d200 of size 256 2018 03 13 21 59 44 860921 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d300 of size 256 2018 03 13 21 59 44 860926 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d400 of size 256 2018 03 13 21 59 44 860932 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d500 of size 512 2018 03 13 21 59 44 860937 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d700 of size 256 2018 03 13 21 59 44 860943 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d800 of size 256 2018 03 13 21 59 44 860948 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026d900 of size 256 2018 03 13 21 59 44 860954 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026da00 of size 256 2018 03 13 21 59 44 860972 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026db00 of size 256 2018 03 13 21 59 44 860978 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026dc00 of size 256 2018 03 13 21 59 44 860983 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026dd00 of size 256 2018 03 13 21 59 44 860989 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026de00 of size 256 2018 03 13 21 59 44 860995 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026df00 of size 512 2018 03 13 21 59 44 861000 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e100 of size 256 2018 03 13 21 59 44 861006 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e200 of size 256 2018 03 13 21 59 44 861011 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e300 of size 256 2018 03 13 21 59 44 861016 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e400 of size 256 2018 03 13 21 59 44 861022 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e500 of size 256 2018 03 13 21 59 44 861027 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e600 of size 256 2018 03 13 21 59 44 861033 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e700 of size 512 2018 03 13 21 59 44 861038 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026e900 of size 256 2018 03 13 21 59 44 861043 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ea00 of size 256 2018 03 13 21 59 44 861049 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026eb00 of size 256 2018 03 13 21 59 44 861054 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ec00 of size 256 2018 03 13 21 59 44 861059 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ed00 of size 256 2018 03 13 21 59 44 861065 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ee00 of size 256 2018 03 13 21 59 44 861070 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ef00 of size 256 2018 03 13 21 59 44 861076 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f000 of size 256 2018 03 13 21 59 44 861080 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f100 of size 256 2018 03 13 21 59 44 861089 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f200 of size 256 2018 03 13 21 59 44 861095 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f300 of size 256 2018 03 13 21 59 44 861101 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f400 of size 256 2018 03 13 21 59 44 861106 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f500 of size 256 2018 03 13 21 59 44 861111 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f600 of size 512 2018 03 13 21 59 44 861116 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f800 of size 256 2018 03 13 21 59 44 861121 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026f900 of size 512 2018 03 13 21 59 44 861126 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026fb00 of size 256 2018 03 13 21 59 44 861131 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026fc00 of size 256 2018 03 13 21 59 44 861137 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026fd00 of size 256 2018 03 13 21 59 44 861143 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026fe00 of size 256 2018 03 13 21 59 44 861148 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021026ff00 of size 256 2018 03 13 21 59 44 861153 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270000 of size 256 2018 03 13 21 59 44 861159 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270100 of size 256 2018 03 13 21 59 44 861164 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270200 of size 256 2018 03 13 21 59 44 861169 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270300 of size 512 2018 03 13 21 59 44 861175 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270500 of size 256 2018 03 13 21 59 44 861180 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270600 of size 256 2018 03 13 21 59 44 861186 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270700 of size 256 2018 03 13 21 59 44 861191 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270800 of size 256 2018 03 13 21 59 44 861197 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270900 of size 256 2018 03 13 21 59 44 861202 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270a00 of size 256 2018 03 13 21 59 44 861208 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270b00 of size 512 2018 03 13 21 59 44 861213 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270d00 of size 256 2018 03 13 21 59 44 861219 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270e00 of size 256 2018 03 13 21 59 44 861240 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210270f00 of size 256 2018 03 13 21 59 44 861247 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271000 of size 256 2018 03 13 21 59 44 861252 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271100 of size 256 2018 03 13 21 59 44 861258 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271200 of size 256 2018 03 13 21 59 44 861276 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271300 of size 256 2018 03 13 21 59 44 861281 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271400 of size 256 2018 03 13 21 59 44 861286 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271500 of size 256 2018 03 13 21 59 44 861292 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271600 of size 256 2018 03 13 21 59 44 861297 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271700 of size 256 2018 03 13 21 59 44 861302 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271800 of size 256 2018 03 13 21 59 44 861308 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271900 of size 512 2018 03 13 21 59 44 861313 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271b00 of size 256 2018 03 13 21 59 44 861319 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271c00 of size 256 2018 03 13 21 59 44 861324 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271d00 of size 256 2018 03 13 21 59 44 861330 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271e00 of size 256 2018 03 13 21 59 44 861335 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210271f00 of size 256 2018 03 13 21 59 44 861341 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272000 of size 512 2018 03 13 21 59 44 861347 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272200 of size 256 2018 03 13 21 59 44 861356 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272300 of size 256 2018 03 13 21 59 44 861363 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272400 of size 256 2018 03 13 21 59 44 861369 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272500 of size 256 2018 03 13 21 59 44 861375 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272600 of size 256 2018 03 13 21 59 44 861380 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272700 of size 512 2018 03 13 21 59 44 861385 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272900 of size 256 2018 03 13 21 59 44 861391 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272a00 of size 256 2018 03 13 21 59 44 861396 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272b00 of size 256 2018 03 13 21 59 44 861401 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272c00 of size 256 2018 03 13 21 59 44 861407 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272d00 of size 256 2018 03 13 21 59 44 861412 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272e00 of size 256 2018 03 13 21 59 44 861418 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210272f00 of size 256 2018 03 13 21 59 44 861423 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273000 of size 256 2018 03 13 21 59 44 861429 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273100 of size 256 2018 03 13 21 59 44 861434 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273200 of size 512 2018 03 13 21 59 44 861440 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273400 of size 256 2018 03 13 21 59 44 861444 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273500 of size 256 2018 03 13 21 59 44 861451 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273600 of size 256 2018 03 13 21 59 44 861456 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273700 of size 256 2018 03 13 21 59 44 861462 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273800 of size 256 2018 03 13 21 59 44 861466 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273900 of size 256 2018 03 13 21 59 44 861472 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273a00 of size 256 2018 03 13 21 59 44 861478 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273b00 of size 256 2018 03 13 21 59 44 861483 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273c00 of size 256 2018 03 13 21 59 44 861488 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273d00 of size 256 2018 03 13 21 59 44 861495 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273e00 of size 256 2018 03 13 21 59 44 861500 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210273f00 of size 512 2018 03 13 21 59 44 861506 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274100 of size 256 2018 03 13 21 59 44 861510 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274200 of size 256 2018 03 13 21 59 44 861516 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274300 of size 256 2018 03 13 21 59 44 861521 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274400 of size 512 2018 03 13 21 59 44 861526 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274600 of size 256 2018 03 13 21 59 44 861531 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274700 of size 256 2018 03 13 21 59 44 861537 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274800 of size 256 2018 03 13 21 59 44 861542 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274900 of size 256 2018 03 13 21 59 44 861548 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274a00 of size 256 2018 03 13 21 59 44 861553 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274b00 of size 256 2018 03 13 21 59 44 861558 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274c00 of size 256 2018 03 13 21 59 44 861564 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274d00 of size 256 2018 03 13 21 59 44 861569 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274e00 of size 256 2018 03 13 21 59 44 861575 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210274f00 of size 256 2018 03 13 21 59 44 861579 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275000 of size 256 2018 03 13 21 59 44 861585 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275100 of size 512 2018 03 13 21 59 44 861590 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275300 of size 256 2018 03 13 21 59 44 861595 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275400 of size 256 2018 03 13 21 59 44 861601 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275500 of size 256 2018 03 13 21 59 44 861606 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275600 of size 256 2018 03 13 21 59 44 861612 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275700 of size 256 2018 03 13 21 59 44 861617 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275800 of size 256 2018 03 13 21 59 44 861622 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275900 of size 512 2018 03 13 21 59 44 861628 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275b00 of size 256 2018 03 13 21 59 44 861633 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275c00 of size 256 2018 03 13 21 59 44 861639 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275d00 of size 256 2018 03 13 21 59 44 861643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275e00 of size 256 2018 03 13 21 59 44 861649 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210275f00 of size 256 2018 03 13 21 59 44 861654 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276000 of size 256 2018 03 13 21 59 44 861659 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276100 of size 256 2018 03 13 21 59 44 861665 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276200 of size 512 2018 03 13 21 59 44 861670 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276400 of size 256 2018 03 13 21 59 44 861675 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276500 of size 256 2018 03 13 21 59 44 861681 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276600 of size 256 2018 03 13 21 59 44 861687 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276700 of size 256 2018 03 13 21 59 44 861693 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276800 of size 256 2018 03 13 21 59 44 861700 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276900 of size 256 2018 03 13 21 59 44 861706 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276a00 of size 512 2018 03 13 21 59 44 861712 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276c00 of size 256 2018 03 13 21 59 44 861718 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276d00 of size 256 2018 03 13 21 59 44 861723 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276e00 of size 256 2018 03 13 21 59 44 861729 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210276f00 of size 256 2018 03 13 21 59 44 861734 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277000 of size 256 2018 03 13 21 59 44 861739 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277100 of size 256 2018 03 13 21 59 44 861745 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277200 of size 256 2018 03 13 21 59 44 861751 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277300 of size 256 2018 03 13 21 59 44 861755 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277400 of size 256 2018 03 13 21 59 44 861761 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277500 of size 512 2018 03 13 21 59 44 861767 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277700 of size 256 2018 03 13 21 59 44 861772 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277800 of size 256 2018 03 13 21 59 44 861777 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277900 of size 256 2018 03 13 21 59 44 861783 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277a00 of size 256 2018 03 13 21 59 44 861788 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277b00 of size 256 2018 03 13 21 59 44 861793 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277c00 of size 512 2018 03 13 21 59 44 861799 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277e00 of size 256 2018 03 13 21 59 44 861804 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210277f00 of size 256 2018 03 13 21 59 44 861810 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210278000 of size 7680 2018 03 13 21 59 44 861815 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210279e00 of size 7680 2018 03 13 21 59 44 861821 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021027bc00 of size 7680 2018 03 13 21 59 44 861826 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021027da00 of size 7680 2018 03 13 21 59 44 861832 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021027f800 of size 7680 2018 03 13 21 59 44 861837 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210281600 of size 7680 2018 03 13 21 59 44 861843 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210283400 of size 7680 2018 03 13 21 59 44 861848 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210285200 of size 7680 2018 03 13 21 59 44 861853 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210287000 of size 7680 2018 03 13 21 59 44 861859 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210288e00 of size 7680 2018 03 13 21 59 44 861864 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021028ac00 of size 7680 2018 03 13 21 59 44 861870 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021028ca00 of size 7680 2018 03 13 21 59 44 861875 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021028e800 of size 7680 2018 03 13 21 59 44 861881 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210290600 of size 7680 2018 03 13 21 59 44 861885 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210292400 of size 7680 2018 03 13 21 59 44 861892 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210294200 of size 7680 2018 03 13 21 59 44 861897 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210296000 of size 7680 2018 03 13 21 59 44 861902 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210297e00 of size 7680 2018 03 13 21 59 44 861908 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210299c00 of size 7680 2018 03 13 21 59 44 861913 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021029ba00 of size 7680 2018 03 13 21 59 44 861918 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021029d800 of size 7680 2018 03 13 21 59 44 861924 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021029f600 of size 7680 2018 03 13 21 59 44 861929 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102a1400 of size 7680 2018 03 13 21 59 44 861935 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102a3200 of size 7680 2018 03 13 21 59 44 861940 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102a5000 of size 7680 2018 03 13 21 59 44 861946 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102a6e00 of size 7680 2018 03 13 21 59 44 861951 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102a8c00 of size 7680 2018 03 13 21 59 44 861957 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102aaa00 of size 7680 2018 03 13 21 59 44 861962 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ac800 of size 7680 2018 03 13 21 59 44 861968 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ae600 of size 7680 2018 03 13 21 59 44 861973 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b0400 of size 7680 2018 03 13 21 59 44 861978 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b2200 of size 7680 2018 03 13 21 59 44 861999 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b4000 of size 7680 2018 03 13 21 59 44 862005 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b5e00 of size 7680 2018 03 13 21 59 44 862010 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b7c00 of size 7680 2018 03 13 21 59 44 862015 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102b9a00 of size 7680 2018 03 13 21 59 44 862021 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102bb800 of size 7680 2018 03 13 21 59 44 862038 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102bd600 of size 7680 2018 03 13 21 59 44 862044 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102bf400 of size 7680 2018 03 13 21 59 44 862050 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102c1200 of size 7680 2018 03 13 21 59 44 862055 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102c3000 of size 7680 2018 03 13 21 59 44 862060 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102c4e00 of size 7680 2018 03 13 21 59 44 862066 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102c6c00 of size 7680 2018 03 13 21 59 44 862071 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102c8a00 of size 7680 2018 03 13 21 59 44 862077 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ca800 of size 7680 2018 03 13 21 59 44 862082 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102cc600 of size 7680 2018 03 13 21 59 44 862087 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ce400 of size 7680 2018 03 13 21 59 44 862093 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d0200 of size 7680 2018 03 13 21 59 44 862098 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d2000 of size 7680 2018 03 13 21 59 44 862104 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d3e00 of size 7680 2018 03 13 21 59 44 862109 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d5c00 of size 7680 2018 03 13 21 59 44 862115 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d7a00 of size 7680 2018 03 13 21 59 44 862120 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102d9800 of size 7680 2018 03 13 21 59 44 862127 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102db600 of size 7680 2018 03 13 21 59 44 862132 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102dd400 of size 7680 2018 03 13 21 59 44 862138 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102df200 of size 7680 2018 03 13 21 59 44 862143 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102e1000 of size 7680 2018 03 13 21 59 44 862149 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102e2e00 of size 7680 2018 03 13 21 59 44 862154 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102e4c00 of size 7680 2018 03 13 21 59 44 862159 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102e6a00 of size 7680 2018 03 13 21 59 44 862165 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102e8800 of size 7680 2018 03 13 21 59 44 862170 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ea600 of size 7680 2018 03 13 21 59 44 862176 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ec400 of size 7680 2018 03 13 21 59 44 862181 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ee200 of size 7680 2018 03 13 21 59 44 862187 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f0000 of size 7680 2018 03 13 21 59 44 862191 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f1e00 of size 7680 2018 03 13 21 59 44 862197 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f3c00 of size 7680 2018 03 13 21 59 44 862202 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f5a00 of size 7680 2018 03 13 21 59 44 862208 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f7800 of size 7680 2018 03 13 21 59 44 862213 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102f9600 of size 7680 2018 03 13 21 59 44 862219 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102fb400 of size 7680 2018 03 13 21 59 44 862239 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102fd200 of size 7680 2018 03 13 21 59 44 862244 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102102ff000 of size 7680 2018 03 13 21 59 44 862250 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210300e00 of size 7680 2018 03 13 21 59 44 862255 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210302c00 of size 7680 2018 03 13 21 59 44 862274 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210304a00 of size 7680 2018 03 13 21 59 44 862279 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210306800 of size 7680 2018 03 13 21 59 44 862285 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210308600 of size 7680 2018 03 13 21 59 44 862290 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021030a400 of size 7680 2018 03 13 21 59 44 862296 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021030c200 of size 7680 2018 03 13 21 59 44 862300 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021030e000 of size 7680 2018 03 13 21 59 44 862306 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021030fe00 of size 7680 2018 03 13 21 59 44 862312 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210311c00 of size 7680 2018 03 13 21 59 44 862317 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210313a00 of size 7680 2018 03 13 21 59 44 862326 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210315800 of size 7680 2018 03 13 21 59 44 862332 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210317600 of size 7680 2018 03 13 21 59 44 862337 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210319400 of size 7680 2018 03 13 21 59 44 862343 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021031b200 of size 7680 2018 03 13 21 59 44 862348 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021031d000 of size 7680 2018 03 13 21 59 44 862353 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021031ee00 of size 7680 2018 03 13 21 59 44 862359 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210320c00 of size 7680 2018 03 13 21 59 44 862364 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210322a00 of size 7680 2018 03 13 21 59 44 862369 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210324800 of size 7680 2018 03 13 21 59 44 862375 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210326600 of size 7680 2018 03 13 21 59 44 862380 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210328400 of size 7680 2018 03 13 21 59 44 862386 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021032a200 of size 7680 2018 03 13 21 59 44 862391 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021032c000 of size 7680 2018 03 13 21 59 44 862396 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021032de00 of size 7680 2018 03 13 21 59 44 862402 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021032fc00 of size 7680 2018 03 13 21 59 44 862407 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210331a00 of size 7680 2018 03 13 21 59 44 862412 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210333800 of size 7680 2018 03 13 21 59 44 862418 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210335600 of size 7680 2018 03 13 21 59 44 862424 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210337400 of size 7680 2018 03 13 21 59 44 862429 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210339200 of size 7680 2018 03 13 21 59 44 862434 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021033b000 of size 7680 2018 03 13 21 59 44 862440 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021033ce00 of size 7680 2018 03 13 21 59 44 862446 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021033ec00 of size 7680 2018 03 13 21 59 44 862451 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210340a00 of size 7680 2018 03 13 21 59 44 862457 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210342800 of size 7680 2018 03 13 21 59 44 862462 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210344600 of size 7680 2018 03 13 21 59 44 862467 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210346400 of size 7680 2018 03 13 21 59 44 862473 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210348200 of size 7680 2018 03 13 21 59 44 862478 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021034a000 of size 7680 2018 03 13 21 59 44 862484 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021034be00 of size 7680 2018 03 13 21 59 44 862489 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021034dc00 of size 7680 2018 03 13 21 59 44 862494 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021034fa00 of size 7680 2018 03 13 21 59 44 862500 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210351800 of size 7680 2018 03 13 21 59 44 862505 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210353600 of size 7680 2018 03 13 21 59 44 862510 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210355400 of size 7680 2018 03 13 21 59 44 862516 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210357200 of size 7680 2018 03 13 21 59 44 862521 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210359000 of size 7680 2018 03 13 21 59 44 862527 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021035ae00 of size 7680 2018 03 13 21 59 44 862533 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021035cc00 of size 7680 2018 03 13 21 59 44 862538 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021035ea00 of size 7680 2018 03 13 21 59 44 862543 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210360800 of size 7680 2018 03 13 21 59 44 862549 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210362600 of size 7680 2018 03 13 21 59 44 862554 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210364400 of size 7680 2018 03 13 21 59 44 862560 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210366200 of size 7680 2018 03 13 21 59 44 862565 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210368000 of size 7680 2018 03 13 21 59 44 862570 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210369e00 of size 7680 2018 03 13 21 59 44 862577 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021036bc00 of size 7680 2018 03 13 21 59 44 862586 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021036da00 of size 7680 2018 03 13 21 59 44 862591 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021036f800 of size 7680 2018 03 13 21 59 44 862597 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210371600 of size 7680 2018 03 13 21 59 44 862602 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210373400 of size 7680 2018 03 13 21 59 44 862608 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210375200 of size 7680 2018 03 13 21 59 44 862613 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210377000 of size 7680 2018 03 13 21 59 44 862618 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210378e00 of size 7680 2018 03 13 21 59 44 862624 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021037ac00 of size 7680 2018 03 13 21 59 44 862629 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021037ca00 of size 7680 2018 03 13 21 59 44 862635 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021037e800 of size 7680 2018 03 13 21 59 44 862640 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210380600 of size 7680 2018 03 13 21 59 44 862646 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210382400 of size 7680 2018 03 13 21 59 44 862651 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210384200 of size 7680 2018 03 13 21 59 44 862657 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210386000 of size 30720 2018 03 13 21 59 44 862662 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021038d800 of size 736256 2018 03 13 21 59 44 862668 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10210441400 of size 184064 2018 03 13 21 59 44 862673 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021046e300 of size 184064 2018 03 13 21 59 44 862678 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021049b200 of size 184064 2018 03 13 21 59 44 862684 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102104c8100 of size 184064 2018 03 13 21 59 44 862689 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102104f5000 of size 256 2018 03 13 21 59 44 862694 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102104f5100 of size 256 2018 03 13 21 59 44 862699 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x102104f5200 of size 12882432 2018 03 13 21 59 44 862705 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e400 of size 256 2018 03 13 21 59 44 862710 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e500 of size 256 2018 03 13 21 59 44 862716 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e600 of size 256 2018 03 13 21 59 44 862722 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e700 of size 256 2018 03 13 21 59 44 862727 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e800 of size 256 2018 03 13 21 59 44 862733 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113e900 of size 256 2018 03 13 21 59 44 862738 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ea00 of size 256 2018 03 13 21 59 44 862744 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113eb00 of size 256 2018 03 13 21 59 44 862749 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ec00 of size 256 2018 03 13 21 59 44 862754 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ed00 of size 256 2018 03 13 21 59 44 862759 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ee00 of size 256 2018 03 13 21 59 44 862764 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ef00 of size 256 2018 03 13 21 59 44 862770 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f000 of size 256 2018 03 13 21 59 44 862775 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f100 of size 256 2018 03 13 21 59 44 862781 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f200 of size 256 2018 03 13 21 59 44 862786 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f300 of size 256 2018 03 13 21 59 44 862792 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f400 of size 256 2018 03 13 21 59 44 862797 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f500 of size 256 2018 03 13 21 59 44 862802 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f600 of size 256 2018 03 13 21 59 44 862806 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f700 of size 256 2018 03 13 21 59 44 862812 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f800 of size 256 2018 03 13 21 59 44 862817 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113f900 of size 256 2018 03 13 21 59 44 862823 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113fa00 of size 256 2018 03 13 21 59 44 862828 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113fb00 of size 256 2018 03 13 21 59 44 862834 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113fc00 of size 256 2018 03 13 21 59 44 862839 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113fd00 of size 256 2018 03 13 21 59 44 862845 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113fe00 of size 256 2018 03 13 21 59 44 862850 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021113ff00 of size 256 2018 03 13 21 59 44 862856 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140000 of size 256 2018 03 13 21 59 44 862861 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140100 of size 256 2018 03 13 21 59 44 862867 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140200 of size 256 2018 03 13 21 59 44 862872 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140300 of size 256 2018 03 13 21 59 44 862878 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140400 of size 256 2018 03 13 21 59 44 862883 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140500 of size 256 2018 03 13 21 59 44 862889 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140600 of size 256 2018 03 13 21 59 44 862894 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140700 of size 256 2018 03 13 21 59 44 862900 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140800 of size 256 2018 03 13 21 59 44 862904 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140900 of size 256 2018 03 13 21 59 44 862910 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140a00 of size 256 2018 03 13 21 59 44 862916 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140b00 of size 256 2018 03 13 21 59 44 862921 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140c00 of size 256 2018 03 13 21 59 44 862927 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140d00 of size 256 2018 03 13 21 59 44 862932 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140e00 of size 256 2018 03 13 21 59 44 862938 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211140f00 of size 256 2018 03 13 21 59 44 862943 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141000 of size 256 2018 03 13 21 59 44 862949 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141100 of size 256 2018 03 13 21 59 44 862954 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141200 of size 256 2018 03 13 21 59 44 862959 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141300 of size 256 2018 03 13 21 59 44 862964 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141400 of size 256 2018 03 13 21 59 44 862969 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141500 of size 256 2018 03 13 21 59 44 862975 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141600 of size 256 2018 03 13 21 59 44 862980 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141700 of size 256 2018 03 13 21 59 44 862985 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141800 of size 256 2018 03 13 21 59 44 862990 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141900 of size 256 2018 03 13 21 59 44 862995 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141a00 of size 256 2018 03 13 21 59 44 863000 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141b00 of size 256 2018 03 13 21 59 44 863006 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141c00 of size 256 2018 03 13 21 59 44 863010 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141d00 of size 256 2018 03 13 21 59 44 863016 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141e00 of size 256 2018 03 13 21 59 44 863021 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211141f00 of size 256 2018 03 13 21 59 44 863027 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142000 of size 256 2018 03 13 21 59 44 863032 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142100 of size 256 2018 03 13 21 59 44 863038 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142200 of size 256 2018 03 13 21 59 44 863043 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142300 of size 256 2018 03 13 21 59 44 863049 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142400 of size 256 2018 03 13 21 59 44 863053 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142500 of size 256 2018 03 13 21 59 44 863074 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142600 of size 256 2018 03 13 21 59 44 863079 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142700 of size 256 2018 03 13 21 59 44 863085 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142800 of size 256 2018 03 13 21 59 44 863091 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142900 of size 256 2018 03 13 21 59 44 863097 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142a00 of size 256 2018 03 13 21 59 44 863103 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142b00 of size 256 2018 03 13 21 59 44 863107 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142c00 of size 256 2018 03 13 21 59 44 863113 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142d00 of size 256 2018 03 13 21 59 44 863117 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142e00 of size 256 2018 03 13 21 59 44 863123 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211142f00 of size 256 2018 03 13 21 59 44 863129 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143000 of size 256 2018 03 13 21 59 44 863134 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143100 of size 256 2018 03 13 21 59 44 863139 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143200 of size 256 2018 03 13 21 59 44 863145 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143300 of size 256 2018 03 13 21 59 44 863150 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143400 of size 256 2018 03 13 21 59 44 863156 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143500 of size 256 2018 03 13 21 59 44 863161 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143600 of size 256 2018 03 13 21 59 44 863167 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143700 of size 256 2018 03 13 21 59 44 863172 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143800 of size 256 2018 03 13 21 59 44 863178 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143900 of size 256 2018 03 13 21 59 44 863183 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143a00 of size 256 2018 03 13 21 59 44 863188 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143b00 of size 256 2018 03 13 21 59 44 863193 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143c00 of size 256 2018 03 13 21 59 44 863199 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143d00 of size 256 2018 03 13 21 59 44 863204 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143e00 of size 256 2018 03 13 21 59 44 863210 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211143f00 of size 256 2018 03 13 21 59 44 863216 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144000 of size 256 2018 03 13 21 59 44 863223 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144100 of size 256 2018 03 13 21 59 44 863228 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144200 of size 256 2018 03 13 21 59 44 863234 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144300 of size 256 2018 03 13 21 59 44 863239 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144400 of size 256 2018 03 13 21 59 44 863257 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144500 of size 256 2018 03 13 21 59 44 863262 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144600 of size 256 2018 03 13 21 59 44 863268 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144700 of size 256 2018 03 13 21 59 44 863274 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144800 of size 256 2018 03 13 21 59 44 863279 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144900 of size 256 2018 03 13 21 59 44 863284 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144a00 of size 256 2018 03 13 21 59 44 863290 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144b00 of size 256 2018 03 13 21 59 44 863295 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144c00 of size 256 2018 03 13 21 59 44 863300 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144d00 of size 256 2018 03 13 21 59 44 863306 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144e00 of size 256 2018 03 13 21 59 44 863312 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211144f00 of size 256 2018 03 13 21 59 44 863317 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145000 of size 256 2018 03 13 21 59 44 863322 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145100 of size 256 2018 03 13 21 59 44 863328 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145200 of size 256 2018 03 13 21 59 44 863333 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145300 of size 256 2018 03 13 21 59 44 863339 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145400 of size 256 2018 03 13 21 59 44 863344 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145500 of size 256 2018 03 13 21 59 44 863350 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145600 of size 256 2018 03 13 21 59 44 863359 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145700 of size 256 2018 03 13 21 59 44 863366 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145800 of size 256 2018 03 13 21 59 44 863373 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145900 of size 256 2018 03 13 21 59 44 863378 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145a00 of size 256 2018 03 13 21 59 44 863383 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145b00 of size 256 2018 03 13 21 59 44 863389 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145c00 of size 256 2018 03 13 21 59 44 863394 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145d00 of size 256 2018 03 13 21 59 44 863400 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145e00 of size 256 2018 03 13 21 59 44 863405 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211145f00 of size 256 2018 03 13 21 59 44 863411 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146000 of size 256 2018 03 13 21 59 44 863416 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146100 of size 256 2018 03 13 21 59 44 863422 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146200 of size 256 2018 03 13 21 59 44 863427 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146300 of size 256 2018 03 13 21 59 44 863433 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146400 of size 256 2018 03 13 21 59 44 863438 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146500 of size 256 2018 03 13 21 59 44 863444 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146600 of size 256 2018 03 13 21 59 44 863448 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146700 of size 256 2018 03 13 21 59 44 863455 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146800 of size 256 2018 03 13 21 59 44 863460 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146900 of size 256 2018 03 13 21 59 44 863466 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146a00 of size 256 2018 03 13 21 59 44 863470 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146b00 of size 256 2018 03 13 21 59 44 863476 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146c00 of size 256 2018 03 13 21 59 44 863481 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146d00 of size 256 2018 03 13 21 59 44 863487 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146e00 of size 256 2018 03 13 21 59 44 863492 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211146f00 of size 256 2018 03 13 21 59 44 863498 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147000 of size 256 2018 03 13 21 59 44 863503 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147100 of size 256 2018 03 13 21 59 44 863509 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147200 of size 256 2018 03 13 21 59 44 863514 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147300 of size 256 2018 03 13 21 59 44 863520 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147400 of size 256 2018 03 13 21 59 44 863525 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147500 of size 256 2018 03 13 21 59 44 863531 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147600 of size 256 2018 03 13 21 59 44 863536 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147700 of size 256 2018 03 13 21 59 44 863542 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147800 of size 256 2018 03 13 21 59 44 863546 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147900 of size 256 2018 03 13 21 59 44 863553 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147a00 of size 256 2018 03 13 21 59 44 863557 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147b00 of size 256 2018 03 13 21 59 44 863562 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147c00 of size 256 2018 03 13 21 59 44 863567 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147d00 of size 256 2018 03 13 21 59 44 863573 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147e00 of size 256 2018 03 13 21 59 44 863578 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211147f00 of size 256 2018 03 13 21 59 44 863584 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148000 of size 256 2018 03 13 21 59 44 863588 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148100 of size 256 2018 03 13 21 59 44 863594 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148200 of size 256 2018 03 13 21 59 44 863600 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148300 of size 256 2018 03 13 21 59 44 863607 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148400 of size 256 2018 03 13 21 59 44 863615 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148500 of size 256 2018 03 13 21 59 44 863622 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148600 of size 256 2018 03 13 21 59 44 863627 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148700 of size 256 2018 03 13 21 59 44 863633 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148800 of size 256 2018 03 13 21 59 44 863638 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148900 of size 256 2018 03 13 21 59 44 863643 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148a00 of size 256 2018 03 13 21 59 44 863649 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148b00 of size 256 2018 03 13 21 59 44 863653 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148c00 of size 256 2018 03 13 21 59 44 863659 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148d00 of size 256 2018 03 13 21 59 44 863664 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148e00 of size 256 2018 03 13 21 59 44 863670 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211148f00 of size 256 2018 03 13 21 59 44 863675 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149000 of size 256 2018 03 13 21 59 44 863681 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149100 of size 256 2018 03 13 21 59 44 863686 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149200 of size 256 2018 03 13 21 59 44 863691 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149300 of size 256 2018 03 13 21 59 44 863697 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149400 of size 256 2018 03 13 21 59 44 863702 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149500 of size 256 2018 03 13 21 59 44 863706 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149600 of size 256 2018 03 13 21 59 44 863712 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149700 of size 256 2018 03 13 21 59 44 863718 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149800 of size 256 2018 03 13 21 59 44 863723 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149900 of size 256 2018 03 13 21 59 44 863728 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149a00 of size 256 2018 03 13 21 59 44 863734 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149b00 of size 256 2018 03 13 21 59 44 863740 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149c00 of size 256 2018 03 13 21 59 44 863744 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149d00 of size 256 2018 03 13 21 59 44 863750 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149e00 of size 256 2018 03 13 21 59 44 863755 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x10211149f00 of size 256 2018 03 13 21 59 44 863761 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a000 of size 256 2018 03 13 21 59 44 863766 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a100 of size 256 2018 03 13 21 59 44 863771 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a200 of size 256 2018 03 13 21 59 44 863777 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a300 of size 256 2018 03 13 21 59 44 863782 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a400 of size 256 2018 03 13 21 59 44 863788 I tensorflow core common runtime bfc allocator cc 661 Chunk at 0x1021114a500 of size 10910600704 2018 03 13 21 59 44 863796 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f3df200 of size 1024 2018 03 13 21 59 44 863802 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f402500 of size 3584 2018 03 13 21 59 44 863807 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f425e00 of size 1024 2018 03 13 21 59 44 863813 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f4cc200 of size 2048 2018 03 13 21 59 44 863819 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f7c7e00 of size 1280 2018 03 13 21 59 44 863825 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f7d4700 of size 1280 2018 03 13 21 59 44 863830 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f7ffa00 of size 15616 2018 03 13 21 59 44 863835 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f816300 of size 15360 2018 03 13 21 59 44 863841 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020f83f700 of size 30720 2018 03 13 21 59 44 863847 I tensorflow core common runtime bfc allocator cc 670 Free at 0x1020fb7ef00 of size 30720 2018 03 13 21 59 44 863853 I tensorflow core common runtime bfc allocator cc 676 Summary of in use Chunks by size 2018 03 13 21 59 44 863862 I tensorflow core common runtime bfc allocator cc 679 709 Chunks of size 256 totalling 177 2KiB 2018 03 13 21 59 44 863869 I tensorflow core common runtime bfc allocator cc 679 58 Chunks of size 512 totalling 29 0KiB 2018 03 13 21 59 44 863875 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 768 totalling 768B 2018 03 13 21 59 44 863881 I tensorflow core common runtime bfc allocator cc 679 10 Chunks of size 1024 totalling 10 0KiB 2018 03 13 21 59 44 863887 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 1280 totalling 3 8KiB 2018 03 13 21 59 44 863892 I tensorflow core common runtime bfc allocator cc 679 4 Chunks of size 1792 totalling 7 0KiB 2018 03 13 21 59 44 863898 I tensorflow core common runtime bfc allocator cc 679 5 Chunks of size 2048 totalling 10 0KiB 2018 03 13 21 59 44 863904 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 2304 totalling 4 5KiB 2018 03 13 21 59 44 863910 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 2560 totalling 2 5KiB 2018 03 13 21 59 44 863915 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 2816 totalling 2 8KiB 2018 03 13 21 59 44 863920 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 3584 totalling 10 5KiB 2018 03 13 21 59 44 863927 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 4096 totalling 8 0KiB 2018 03 13 21 59 44 863932 I tensorflow core common runtime bfc allocator cc 679 4 Chunks of size 4608 totalling 18 0KiB 2018 03 13 21 59 44 863938 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 5120 totalling 5 0KiB 2018 03 13 21 59 44 863944 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 5376 totalling 10 5KiB 2018 03 13 21 59 44 863950 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 7424 totalling 7 2KiB 2018 03 13 21 59 44 863956 I tensorflow core common runtime bfc allocator cc 679 312 Chunks of size 7680 totalling 2 29MiB 2018 03 13 21 59 44 863961 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 7936 totalling 7 8KiB 2018 03 13 21 59 44 863967 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 8192 totalling 24 0KiB 2018 03 13 21 59 44 863973 I tensorflow core common runtime bfc allocator cc 679 4 Chunks of size 9216 totalling 36 0KiB 2018 03 13 21 59 44 863979 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 9984 totalling 9 8KiB 2018 03 13 21 59 44 863985 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 10240 totalling 10 0KiB 2018 03 13 21 59 44 863990 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 11776 totalling 11 5KiB 2018 03 13 21 59 44 863996 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 12288 totalling 24 0KiB 2018 03 13 21 59 44 864003 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 14592 totalling 14 2KiB 2018 03 13 21 59 44 864009 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 15104 totalling 29 5KiB 2018 03 13 21 59 44 864016 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 18432 totalling 36 0KiB 2018 03 13 21 59 44 864022 I tensorflow core common runtime bfc allocator cc 679 6 Chunks of size 24576 totalling 144 0KiB 2018 03 13 21 59 44 864029 I tensorflow core common runtime bfc allocator cc 679 12 Chunks of size 30720 totalling 360 0KiB 2018 03 13 21 59 44 864035 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 32768 totalling 64 0KiB 2018 03 13 21 59 44 864041 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 46080 totalling 45 0KiB 2018 03 13 21 59 44 864047 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 49152 totalling 96 0KiB 2018 03 13 21 59 44 864053 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 55552 totalling 54 2KiB 2018 03 13 21 59 44 864058 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 60928 totalling 59 5KiB 2018 03 13 21 59 44 864064 I tensorflow core common runtime bfc allocator cc 679 4 Chunks of size 65536 totalling 256 0KiB 2018 03 13 21 59 44 864070 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 98304 totalling 192 0KiB 2018 03 13 21 59 44 864076 I tensorflow core common runtime bfc allocator cc 679 4 Chunks of size 131072 totalling 512 0KiB 2018 03 13 21 59 44 864081 I tensorflow core common runtime bfc allocator cc 679 8 Chunks of size 184064 totalling 1 40MiB 2018 03 13 21 59 44 864087 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 240128 totalling 234 5KiB 2018 03 13 21 59 44 864094 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 262144 totalling 768 0KiB 2018 03 13 21 59 44 864100 I tensorflow core common runtime bfc allocator cc 679 6 Chunks of size 430080 totalling 2 46MiB 2018 03 13 21 59 44 864106 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 499712 totalling 488 0KiB 2018 03 13 21 59 44 864111 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 524288 totalling 1 00MiB 2018 03 13 21 59 44 864117 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 532224 totalling 519 8KiB 2018 03 13 21 59 44 864123 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 534016 totalling 521 5KiB 2018 03 13 21 59 44 864129 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 536320 totalling 523 8KiB 2018 03 13 21 59 44 864149 I tensorflow core common runtime bfc allocator cc 679 7 Chunks of size 536832 totalling 3 58MiB 2018 03 13 21 59 44 864155 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 625664 totalling 611 0KiB 2018 03 13 21 59 44 864163 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 677888 totalling 662 0KiB 2018 03 13 21 59 44 864169 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 736256 totalling 2 11MiB 2018 03 13 21 59 44 864174 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 860160 totalling 1 64MiB 2018 03 13 21 59 44 864180 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 1048576 totalling 2 00MiB 2018 03 13 21 59 44 864186 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 1067520 totalling 1 02MiB 2018 03 13 21 59 44 864192 I tensorflow core common runtime bfc allocator cc 679 3 Chunks of size 1179648 totalling 3 38MiB 2018 03 13 21 59 44 864198 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 1720320 totalling 3 28MiB 2018 03 13 21 59 44 864203 I tensorflow core common runtime bfc allocator cc 679 2 Chunks of size 12882432 totalling 24 57MiB 2018 03 13 21 59 44 864209 I tensorflow core common runtime bfc allocator cc 679 1 Chunks of size 10910600704 totalling 10 16GiB 2018 03 13 21 59 44 864215 I tensorflow core common runtime bfc allocator cc 683 Sum Total of in use chunks 10 21GiB 2018 03 13 21 59 44 864228 I tensorflow core common runtime bfc allocator cc 685 Stats Limit 10968576820 InUse 10968474112 MaxInUse 10968477952 NumAllocs 779120 MaxAllocSize 10910600704 2018 03 13 21 59 44 864302 W tensorflow core common runtime bfc allocator cc 277 xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 2018 03 13 21 59 44 865043 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 2018 03 13 21 59 44 866899 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867009 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867294 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867331 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867488 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867525 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 867646 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 868072 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 868157 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 868303 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 868351 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 868670 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 869464 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 869526 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 869538 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 869852 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 870282 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 870358 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 870575 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 870704 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 870971 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 871354 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 871392 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 871426 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 871736 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 871936 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 872103 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 872924 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 872974 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 875581 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 879603 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 880900 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 880959 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 882434 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 883553 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 883996 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 884396 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 884762 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 884811 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 886082 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 887126 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 887543 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 888555 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 889075 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 890308 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 893012 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 895479 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 897031 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 897207 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 897935 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 898023 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 898068 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 898086 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 898795 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 899419 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 899428 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 899505 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 899899 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900093 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900400 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900661 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900722 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900786 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900812 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900906 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 900960 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 901567 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 902509 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 902827 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 903117 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 903427 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 903817 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 904486 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 904768 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 905273 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 906383 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 906688 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 907023 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 907185 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 907518 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 908547 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 909451 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 909776 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 909979 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911313 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911635 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911738 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911775 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911849 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911860 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911893 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 911933 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912020 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912103 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912264 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912579 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912669 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 912776 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913080 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913158 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913218 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913334 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913411 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913490 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913875 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 913895 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914029 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914081 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914315 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914388 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914504 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914577 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914618 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914699 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914702 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914749 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914750 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 914958 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 2018 03 13 21 59 44 915987 W tensorflow core framework op kernel cc 1192 Resource exhausted OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl ResourceExhaustedError' OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 Node FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read 5248 Send T DT FLOAT client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 13633 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read device job localhost replica 0 task 0 device CPU 0 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read Caused by op 'unstack 2' defined at File xxx xxx object detection train py line 163 in module tf app run File usr local python3 lib python3 5 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File xxx xxx object detection train py line 159 in main worker job name is chief FLAGS train dir File xxx xxx object detection trainer py line 228 in train clones model deploy create clones deploy config model fn input queue File xxx xxx slim deployment model deploy py line 194 in create clones outputs model fn args kwargs File xxx xxx object detection trainer py line 153 in create losses train config merge multiple label boxes File xxx xxx object detection trainer py line 112 in get inputs read data list input queue dequeue File xxx xxx object detection core batcher py line 116 in dequeue unbatched tensor list tf unstack batched tensor File usr local python3 lib python3 5 site packages tensorflow python ops array ops py line 1027 in unstack return gen array ops unpack value num num axis axis name name File usr local python3 lib python3 5 site packages tensorflow python ops gen array ops py line 5868 in unpack Unpack value value num num axis axis name name File usr local python3 lib python3 5 site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File usr local python3 lib python3 5 site packages tensorflow python framework ops py line 2956 in create op op def op def File usr local python3 lib python3 5 site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 Node FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read 5248 Send T DT FLOAT client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 13633 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read device job localhost replica 0 task 0 device CPU 0 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read Traceback most recent call last File usr local python3 lib python3 5 site packages tensorflow python client session py line 1323 in do call return fn args File usr local python3 lib python3 5 site packages tensorflow python client session py line 1302 in run fn status run metadata File usr local python3 lib python3 5 site packages tensorflow python framework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl ResourceExhaustedError OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 Node FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read 5248 Send T DT FLOAT client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 13633 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read device job localhost replica 0 task 0 device CPU 0 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read During handling of the above exception another exception occurred Traceback most recent call last File xxx xxx object detection train py line 163 in module tf app run File usr local python3 lib python3 5 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File xxx xxx object detection train py line 159 in main worker job name is chief FLAGS train dir File xxx xxx object detection trainer py line 332 in train saver saver File usr local python3 lib python3 5 site packages tensorflow contrib slim python slim learning py line 763 in train sess train op global step train step kwargs File usr local python3 lib python3 5 site packages tensorflow contrib slim python slim learning py line 487 in train step run metadata run metadata File usr local python3 lib python3 5 site packages tensorflow python client session py line 889 in run run metadata ptr File usr local python3 lib python3 5 site packages tensorflow python client session py line 1120 in run feed dict tensor options run metadata File usr local python3 lib python3 5 site packages tensorflow python client session py line 1317 in do run options run metadata File usr local python3 lib python3 5 site packages tensorflow python client session py line 1336 in do call raise type e node def op message tensorflow python framework errors impl ResourceExhaustedError OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 Node FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read 5248 Send T DT FLOAT client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 13633 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read device job localhost replica 0 task 0 device CPU 0 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read Caused by op 'unstack 2' defined at File xxx xxx object detection train py line 163 in module tf app run File usr local python3 lib python3 5 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File xxx xxx object detection train py line 159 in main worker job name is chief FLAGS train dir File xxx xxx object detection trainer py line 228 in train clones model deploy create clones deploy config model fn input queue File xxx xxx slim deployment model deploy py line 194 in create clones outputs model fn args kwargs File xxx xxx object detection trainer py line 153 in create losses train config merge multiple label boxes File xxx xxx object detection trainer py line 112 in get inputs read data list input queue dequeue File xxx xxx object detection core batcher py line 116 in dequeue unbatched tensor list tf unstack batched tensor File usr local python3 lib python3 5 site packages tensorflow python ops array ops py line 1027 in unstack return gen array ops unpack value num num axis axis name name File usr local python3 lib python3 5 site packages tensorflow python ops gen array ops py line 5868 in unpack Unpack value value num num axis axis name name File usr local python3 lib python3 5 site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File usr local python3 lib python3 5 site packages tensorflow python framework ops py line 2956 in create op op def op def File usr local python3 lib python3 5 site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 1 5095 3729 3 Node unstack 2 Unpack T DT FLOAT axis 0 num 24 device job localhost replica 0 task 0 device GPU 0 prefetch queue Dequeue 3249 Node FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read 5248 Send T DT FLOAT client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 13633 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read device job localhost replica 0 task 0 device CPU 0 FeatureExtractor MobilenetV1 Conv2d 13 pointwise 1 Conv2d 2 1x1 256 BatchNorm gamma read Process finished with exit code 1,,,2018-03-13 06:15:10,2018-03-14 05:26:37
IS,Windows Compile Issue absl is not a class or namespace name,Hi I am trying to compile tensorflow from source in windows using bazel 0 11 0 and vc14 and I am getting the following error igwos0gz execroot org tensorflow tensorflow core platform windows port cc 153 error C2653 'absl' is not a class or namespace name Have I written custom code no OS Platform and Distribution windows 10 x64 TensorFlow installed from git repo TensorFlow version current master branch 1 7rc Bazel version 0 11 0 CUDA cuDNN version 9 1 7 GPU model and memory nvidia 960m Exact command to reproduce bazel build c opt action env USE MSVC WRAPPER 1 tensorflow tools pip package build pip package,,"angersson,angersson,mrry,meteorcloudy,meteorcloudy",2018-02-27 07:40:49,2018-03-14 13:30:25
IS,Eager mode in multithreaded environment v1 6 generates All graphs are building functions and no eager context was previously active,The problem Scope initialization assumes that the 'context stack' must be in the same stacktrace thread while in some cases the user might use the eager context from a different thread For example the code below fails in version 1 6 but not in 1 5 Also in version 1 6 it does not fail if foo is called from main thread or if enable eager execution is called from the child thread Source code System information Have I written custom code no OS Platform and Distribution Linux Ubuntu 16 TensorFlow installed from binary TensorFlow version v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 5,,"asimshankar,akshayka,akshayka",2018-03-11 14:21:12,2018-03-14 14:05:58
PR,Support other dtypes in BeamSearchDecoder initialization,The BeamSearchDecoder initialization failed when other dtypes were used e g tf float16 This PR correctly converts the scalar values to tensors with the current dtype,,guillaumekln,2018-03-09 13:19:55,2018-03-14 15:14:40
PR,Fix broken link of TensorFlow Debugger tfdbg in layers tutorials,Described as PR tile Just follow the similar format of linking to debugger md to fix current broken link issue in layer md tutorial programmers guide debugger which explains how to use the TensorFlow debugger tfdbg,,imsheridan,2018-03-14 16:16:04,2018-03-14 16:38:21
PR,1 7 0rc1 cherry pick request Fixes a race condition in function instantiation,This cherry pick fixes a bug that was discovered independently by multiple TPU users after the release branch was cut The main consequence of not including this change in the release would be flaky crash failures segmentation faults in the input pipeline Previously if the same function was being concurrently instantiated and released 1 Thread one could begin to instantiate the function determine that it already existed in the runtime then be preempted 2 Thread two could release the handle on the function causing it to be freed and removed from the FunctionLibraryRuntime items map 3 Thread one could then incorrectly assume that the function still existed and fail to find it in the FunctionLibraryRuntime items map causing a segfault when it attempted to increment the refcount on an uninitialized object PiperOrigin RevId 188661500,,"mrry,caisq,mrry,caisq,mrry,yifeif,mrry,mrry,mrry,mrry",2018-03-13 15:03:00,2018-03-14 17:37:34
PR,improvement in the tf nn raw rnn documentation,PR for 14963 This exposes the advanced use case of the raw rnn where the user can project the cell output into logits as a part of the loop fn computations Earlier it mislead the users that it is mandatory for the loop fn to return emit output such that it matches the cell output size,,"drpngx,raghuraman-k,ebrevdo,ebrevdo,ebrevdo,drpngx,drpngx,drpngx",2017-11-30 04:24:09,2018-03-14 18:40:17
PR,Branch 189041421,,,jpienaar,2018-03-14 17:05:05,2018-03-14 20:23:40
PR,New rolling window batch operation for tf data Dataset 15044,This is a new feature For help pre processing datasets creates a transformation function that can be applied to a tf data Dataset Object to create a new Dataset by rolling a window across the initial Dataset to create the batches for the new Dataset Fails if Dataset is too large to fit in memory possible future work,,mrry,2017-12-15 22:24:21,2018-03-14 21:04:02
PR,Branch 189071037,,,jpienaar,2018-03-14 21:02:29,2018-03-14 21:48:18
IS,GPU issue,Hi I am new to TensorFlow and I installed everything as instructed However I get the error below after successfully importing tf Does anyone know how to fix this I am using a Surface Book 2 with a 1060 NVIDIA GPU Thanks import tensorflow as tf hello tf constant 'Hello TensorFlow ' sess tf Session 2018 03 14 12 19 36 435333 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core platform cpu feature guard cc 140 Your CPU supports instructions that this TensorFlow binary was not compiled to use AVX2 2018 03 14 12 19 37 605256 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime gpu gpu device cc 1212 Found device 0 with properties name GeForce GTX 1060 major 6 minor 1 memoryClockRate GHz 1 569 pciBusID 0000 02 00 0 totalMemory 6 00GiB freeMemory 4 97GiB 2018 03 14 12 19 37 611418 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime gpu gpu device cc 1312 Adding visible gpu devices 0 2018 03 14 12 19 39 295420 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime gpu gpu device cc 993 Creating TensorFlow device job localhost replica 0 task 0 device GPU 0 with 4744 MB memory physical GPU device 0 name GeForce GTX 1060 pci bus id 0000 02 00 0 compute capability 6 1,,"gunan,gunan",2018-03-14 17:24:17,2018-03-14 23:58:21
IS,Performance dropped in cifar10 in TF 1 6 0 compiled with MKL,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary source TensorFlow version use command below 1 6 0 Python version 2 7 3 6 Bazel version if compiling from source Build label 0 7 0 GCC Compiler version if compiling from source 5 4 0 20160609 Ubuntu 5 4 0 6ubuntu1 16 04 9 CUDA cuDNN version V9 0 176 GPU model and memory N A Exact command to reproduce Hardware information Model Name Intel R Xeon R Platinum 8124M CPU 3 00GHz CPU s 72 Architecture x86 64 Describe the problem I work with an AWS C5 18xlarge instance With TensorFlow 1 5 0 compiled with MKL and setting MKL parameters shown above I can get a 2000 examples sec speed when running cifar10 train py But for TensorFlow 1 6 0 with exactly same building steps I can only get speed of 300 examples sec,,"frreiss,agramesh1,tatianashp,tatianashp",2018-03-02 19:38:52,2018-03-15 00:00:49
PR,Updating version for 1 5 1 patch release,,,av8ramit,2018-03-06 23:45:41,2018-03-15 00:42:42
IS,docker image for 1 6 0 is missing CUPTI libraries,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 4 4 0 104 generic TensorFlow installed from source or binary binary TensorFlow version v1 6 0 0 gd2e24b6 1 6 0 Bazel version N A CUDA cuDNN version 9 0 176 from docker image GPU model and memory GeForce GTX TITAN X Exact command to reproduce see below Describe the Error CUPTI library is missing in docker image tensorflow tensorflow 1 6 0 gpu py3 This is required when using trace level tf RunOptions FULL TRACE and run metadata in session run Source code logs To reproduce language lang py run py import tensorflow as tf with tf Session as default as sess test op tf no op run options tf RunOptions trace level tf RunOptions FULL TRACE run metadata tf RunMetadata sess run test op options run options run metadata run metadata And run nvidia docker run volume path to run py run py rm it tensorflow tensorflow 1 6 0 gpu py3 python run py The error message is language lang none 2018 03 05 00 00 00 000000 I tensorflow stream executor dso loader cc 141 Could not open CUDA library libcupti so 9 0 LD LIBRARY PATH usr local cuda extras CUPTI lib64 usr local nvidia lib usr local nvidia lib64 2018 03 05 00 00 00 000000 F tensorflow stream executor lib statusor h 212 Non OK status status status Failed precondition could not dlopen DSO libcupti so 9 0 dlerror libcupti so 9 0 cannot open shared object file No such file or directory Additional information from within the docker image language lang bash echo LD LIBRARY PATH usr local cuda extras CUPTI lib64 usr local nvidia lib usr local nvidia lib64 ll usr local cuda extras CUPTI lib64 ls cannot access ' usr local cuda extras CUPTI lib64' No such file or directory find name libcupti not found The library seems to be missing in this build Worked with tensorflow tensorflow 1 4 0 gpu py3,,"flx42,gunan,flx42",2018-03-05 09:01:46,2018-03-15 01:14:42
PR,Pin the version of cuDNN used in Dockerfile gpu,Related 17566 Fixes 17431 Signed off by Felix Abecassis fabecassis nvidia com,,"flx42,flx42",2018-03-14 23:49:45,2018-03-15 01:14:42
PR,Fix broken link in kernel method tutorial,As we can see in Kernel Methods tutorial the reference links in Note section have not generated valid links Note This document uses a deprecated version of tf estimator which has a tf contrib learn estimator different interface It also uses other contrib methods whose version compat not covered API may not be stable This PR is a simple fix just replace the begining to to fix above broken links,,imsheridan,2018-03-11 14:12:16,2018-03-15 01:15:59
PR,set default values of args in print tensors in checkpoint file,set default values of args in function print tensors in checkpoint file to avoid backwards compatibility problems detail in issue 17498,,frankchn,2018-03-07 09:18:18,2018-03-15 01:17:14
PR,TensorRT support for ARM architectures,i e without this modification Tensorflow under Nvidia Jetpack 3 2 is not compiling Else condition in if then else block generates a path s include which results in usr lib include but it must be usr include aarch64 linux gnu So this fix targets ARM architectures and with this fix Tensorflow 1 6rc compiles fine with TensorRT support,,,2018-03-04 09:07:20,2018-03-15 01:17:27
PR,updating documentation,Fix for 16555,,,2018-03-04 02:06:37,2018-03-15 01:17:40
PR,Add missing spaces in multiline strings,Came across a missing space in a ValueError exception and I run quick grep to find other instances of the same issue in the codebase It is not a big deal but I figured it would not hurt to submit a fix Hope it helps,,,2018-03-03 21:48:08,2018-03-15 01:17:57
PR,Fix nsync build issue,,,,2018-03-02 11:30:10,2018-03-15 01:18:09
PR,gofmt with tensorflow go genop internal genop go,By default golang use gofmt s to format the code though it looks like tensorflow go genop internal genop go is not formattted with gofmt This fix updates with gofmt Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-03-14 15:47:50,2018-03-15 01:18:52
PR,contrib tpu minor spelling tweaks,,,brettkoonce,2018-03-14 03:23:35,2018-03-15 01:24:54
PR,Fix typo,,,,2018-03-05 11:07:22,2018-03-15 01:28:04
PR,Add index to plugin name of Tags table,Added index to plugin name of Tags table in TensorBoard DB schema to potentially help query performance e g SELECT 1 FROM Tags WHERE Tags plugin name in histograms plugin,,,2018-02-26 04:18:02,2018-03-15 04:02:34
IS,the new parameter in print tensors in checkpoint file breaks old code,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip TensorFlow version use command below v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 6 Describe the problem The function print tensors in checkpoint file in tensorflow python tools inspect checkpoint py is changed in this commit diff fb7984719b22f01a7748ef847e9eb731 a new parameter all tensor names is added This change breaks the old code using this function including the examples in the Programmer is Guide inspect variables in a checkpoint I believe an elegant solution is setting the default value of the new parameter all tensor names to False,,,2018-03-07 06:26:03,2018-03-15 07:12:14
IS,Error C compilation of rule ' protobuf archive protobuf lite' failed,I am trying to build tensorflow inference library using the instructions here System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 4 LTS TensorFlow installed from source or binary Source TensorFlow version use command below Master 10be1f2377bf7aad1a4cfa306277c53e44493a57 Python version Python 3 6 3 Anaconda custom 64 bit Bazel version if compiling from source 0 11 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 0 GPU model and memory Tesla K80 12GB Exact command to reproduce,,,2018-03-14 13:16:27,2018-03-15 09:21:43
IS,pb tflite is ok,bazel run config opt tensorflow contrib lite toco toco input file home ubuntu Desktop code tensorflow graph opt pb output file home ubuntu Desktop code tensorflow graph opt pb tflite input format TENSORFLOW GRAPHDEF output format TFLITE inference type FLOAT input shape 1 128 128 3 input array image output arrays Openpose concat stage7 WARNING Config values are not defined in any rc file opt WARNING home ubuntu cache bazel bazel ubuntu bb7db75967eaf264207472309623127f external protobuf archive WORKSPACE 1 Workspace name in home ubuntu cache bazel bazel ubuntu bb7db75967eaf264207472309623127f external protobuf archive WORKSPACE com google protobuf does not match the name given in the repository is definition protobuf archive this will cause a build error in future versions INFO Analysed target tensorflow contrib lite toco toco 0 packages loaded INFO Found 1 target Target tensorflow contrib lite toco toco up to date bazel bin tensorflow contrib lite toco toco INFO Elapsed time 0 643s Critical Path 0 01s INFO Build completed successfully 1 total action INFO Running command line bazel bin tensorflow contrib lite toco toco ' input file home ubuntu Desktop code tensorflow graph opt pb' ' output file home ubuntu Desktop code tensorflow graph opt pb tflite' ' input format TENSORFLOW GRAPHDEF' ' output format TFLITE' ' inference type FLOAT' ' input shape 1 128 128 3' ' input array image' ' output arrays Openpose concat stage7' 2018 03 14 17 06 23 573744 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before Removing unused ops 426 operators 649 arrays 0 quantized 2018 03 14 17 06 23 590727 I INFO Running command line bazel bin tensorflow contrib lite toco toco ' input file home ubuntu Desktop code tensorflow graph opt pb' ' output file home ubuntu Desktop code tensorflow graph opt pb tflite' ' input format TENSORFLOW GRAPHDEF' ' output format TFLITE' ' inference type FLOAT' ' input shape 1 128 128 3' ' input array image' ' output arrays Openpose concat stage7' 2018 03 14 17 06 23 573744 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before Removing unused ops 426 operators 649 arrays 0 quantized 2018 03 14 17 06 23 590727 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 426 operators 649 arrays 0 quantized 2018 03 14 17 06 23 608262 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 151 operators 438 arrays 0 quantized 2018 03 14 17 06 23 614578 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before dequantization graph transformations 151 operators 438 arrays 0 quantized 2018 03 14 17 06 23 620831 I tensorflow contrib lite toco allocate transient arrays cc 311 Total transient array allocated size 3400704 bytes theoretical optimal value 1886208 bytes 2018 03 14 17 06 23 621951 I tensorflow contrib lite toco toco tooling cc 309 Estimated count of arithmetic ops 1 03065 billion note that a multiply add is counted as 2 ops but i run the tflite get the error 03 15 10 26 22 109 14024 14074 android example com tflitecamerademo E AndroidRuntime FATAL EXCEPTION CameraBackground Process android example com tflitecamerademo PID 14024 java lang IllegalArgumentException Failed to get input dimensions 0 th input should have 196608 bytes but found 406272 bytes at org tensorflow lite NativeInterpreterWrapper getInputDims Native Method at org tensorflow lite NativeInterpreterWrapper run NativeInterpreterWrapper java 82 at org tensorflow lite Interpreter runForMultipleInputsOutputs Interpreter java 112 at org tensorflow lite Interpreter run Interpreter java 93 at com example android tflitecamerademo ImageClassifierQuantizedMobileNet runInference ImageClassifierQuantizedMobileNet java 95 at com example android tflitecamerademo ImageClassifier classifyFrame ImageClassifier java 110 at com example android tflitecamerademo Camera2BasicFragment classifyFrame Camera2BasicFragment java 663 at com example android tflitecamerademo Camera2BasicFragment wrap0 Camera2BasicFragment java at com example android tflitecamerademo Camera2BasicFragment 4 run Camera2BasicFragment java 559 at android os Handler handleCallback Handler java 815 at android os Handler dispatchMessage Handler java 104 at android os Looper loop Looper java 207 at android os HandlerThread run HandlerThread java 61 03 15 10 26 22 119 1125 1823 E ActivityManager Invalid thumbnail dimensions 0x0,,,2018-03-15 02:32:42,2018-03-15 09:51:18
IS,sparse variable request or any alternate,In tensor flow TF to compute gradients we have to pass some variable Sparse tensors cannot be used as variables Can you please tell me is there any solution for sparse matrix gradient N A Tensorflow version 1 4,,,2018-03-09 03:13:11,2018-03-15 17:26:00
IS,Building TensorFlow v1 5 0 from sources does not detect bazel v0 10 0 correctly,It looks like build script uses strings for version comparison i e tuple 0 10 0 0 4 5 hence Bazel version 0 10 0 is considered less then required version 0 4 5 OS Platform and Distribution SuSE Linux 12 3 TensorFlow installed from this source TensorFlow version 1 5 0 Bazel version 0 10 0 compiled from this source CUDA cuDNN version N A was not enabled GPU model and memory N A was not enabled Exact command to reproduce bazel build config opt tensorflow java tensorflow tensorflow java libtensorflow jni,,,2018-02-09 16:58:17,2018-03-15 17:33:01
PR,contrib gan minor spelling tweaks,,,brettkoonce,2018-03-15 01:15:17,2018-03-15 17:51:03
PR,Update ios md,brew install commonly fails on modern versions of OSX where the symlink needs to be manually added I added instructions to chown usr local which will allow for this,,,2018-03-15 00:05:33,2018-03-15 17:51:21
PR,Update README md,Fixed location of download models sh in the iOS Demo App section,,,2018-03-14 22:34:46,2018-03-15 17:51:35
PR,Elaborate on documentation for using tf layers batch normalization,This PR adds details about a gotcha not previously documented related to batch normalization See topic discuss Y0BSYDRQ BU,,,2018-03-14 19:55:08,2018-03-15 17:52:28
PR,Patch release notes,,,av8ramit,2018-03-15 00:51:20,2018-03-15 17:52:30
PR,update doc for tf train Saver max to keep argument to resolve 17554,Currently if max to keep is set to 0 all checkpoints are kept but only the last one is kept in the 'checkpoint' file This was not previously clear in the docs See 17554,,,2018-03-14 16:31:01,2018-03-15 17:52:44
PR,atrous conv2d doc fix newline,fix newline in docs for tf nn atrous conv2d,,4d55397500,2018-03-14 07:25:11,2018-03-15 17:52:57
PR,contrib lite add missing include assert h spectrogram cc,tensorflow contrib lite build ios universal lib sh fails with error use of undeclared identifier 'assert',,,2018-03-08 22:21:12,2018-03-15 17:53:17
IS,tf train Saver protocol buffer saving issue,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 gpu Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version Cuda 8 0 Cudnn 6 0 GPU model and memory Titan xp Exact command to reproduce tf train Saver Describe the problem When using tf train Saver if you set max to keep None to keep all checkpoint files created then the protocol buffer saved at 'checkpoint' will only save the name of the latest checkpoint created and not all created checkpoints When you set max to keep N to be any other value then it will save the latest N checkpoint names as intended,,,2018-03-08 13:36:33,2018-03-15 17:53:32
PR,Modify a typo for the HandwrittenConv of conv ops test,A typo is fixed for the 'HandwrittenConv' test in the conv ops test cc For the following input and filter the output 4 4 should be evaluated by 1 7 4 8 7 0 2 11 5 12 8 0 3 0 6 0 9 0 not 1 7 4 11 7 0 2 8 5 12 8 0 3 0 6 0 9 0 121 The image matrix is 1 2 3 4 5 6 7 8 9 10 11 12 The filter matrix is 1 4 7 2 5 8 3 6 9,,,2018-03-07 09:42:25,2018-03-15 17:53:41
PR,Adds a check for shuffle None in numpy input fn,numpy input fn is shuffle argument is set to None by default If the argument is not provided the function raises a TypeError since shuffle is of type NoneType and not bool This is fixed by adding a simple check to see if shuffle is None and setting it to False if so From my understanding this should be the desired behavior Do let me know if this is not the case It does not seem like additional test code is needed or any existing test code needs to be changed Thanks,,,2018-02-15 01:04:57,2018-03-15 17:58:59
PR,Update kernel methods to fix failing build docs test,,,frankchn,2018-03-15 17:49:04,2018-03-15 19:33:02
PR,Updated Session run documentation,For session run ops order in which ops are evaluated is undefined but that information is not specified anywhere in documentation It is quite natural to assume that ops are evaluated in order provided especially since that is what cpu version of Tensorflow does at least on every implementation I tried GPU versions do not always follow FIFO evaluation order though If needed I can provide a test that shows different behavior with tensorflow and tensorflow gpu purely due to different order of evaluation inside session run ops In this pull request I added a single sentence to documentation to make it clear that order of ops evaluation inside session run is undefined Discussion of the issue can be found here issuecomment 373198596,,"PuchatekwSzortach,frankchn,PuchatekwSzortach",2018-03-15 02:30:47,2018-03-15 19:47:22
IS,How leave only 1 app and how edit drawing boxes,System information Windows 10 x64 Installed from binary TensorFlow 1 3 0 Python 3 6 3 CuDNN 6 4 6 CUDA 8 0 NVIDIA GeForce 940M Describe the problem 1 How I can leave only 1 app Example TF Detect I wanna when I install TF on my Android smartphone installed only TF Detect Thanks 2 How I can edit during detection boxes,,andrewharp,2018-01-24 07:43:22,2018-03-15 20:15:56
PR,Fix broken link of performance guide for the tf data API,As you can see in the Performance Guide the below here did not link to the correct place with datasets performance due to datasets performance md is another file instead of an anchor inside current file The tf data API utilizes C multi threading and has a much lower overhead than the Python based queue runner that is limited by Python is multi threading performance A detailed performance guide for the tf data API can be found here This PR is to fix the above broken link of performance guide for the tf data API,,imsheridan,2018-03-15 16:09:36,2018-03-15 22:15:57
PR,README cmd typo,Just a typo on README cmd,,,2018-03-15 13:20:17,2018-03-15 22:16:10
PR,minor edit,based off my understanding of the source code here is the stackoverflow post I made about my confusion,,caisq,2018-03-12 07:01:08,2018-03-15 22:16:34
IS,Could not open CUDA library cublas64 80 dll,tensorflow just run hello world it is work but alarms appear is this ok it is run by gpu or cpu os win10 GPU Toolkit version v9 0 cudnn verson v7 1 anaconda3 version v5 1 image easy to view text for more detail tensorflow C Users yi Anaconda3 Scripts python Python 3 5 5 Anaconda Inc default Mar 9 2018 12 39 44 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor dso loader cc 126 Could not open CUDA library cublas64 80 dll I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor cuda cuda blas cc 2294 Unable to load cuBLAS DSO I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor dso loader cc 126 Could not open CUDA library cudnn64 5 dll I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor cuda cuda dnn cc 3517 Unable to load cuDNN DSO I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor dso loader cc 126 Could not open CUDA library cufft64 80 dll I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor cuda cuda fft cc 344 Unable to load cuFFT DSO I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor dso loader cc 135 successfully opened CUDA library nvcuda dll locally I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor dso loader cc 126 Could not open CUDA library curand64 80 dll I c tf jenkins home workspace release win device gpu os windows tensorflow stream executor cuda cuda rng cc 338 Unable to load cuRAND DSO import tensorflow as tf hello tf constant 'hello TensorFlow ' sess tf Session I c tf jenkins home workspace release win device gpu os windows tensorflow core common runtime gpu gpu device cc 885 Found device 0 with properties name GeForce GTX 1050 major 6 minor 1 memoryClockRate GHz 1 493 pciBusID 0000 01 00 0 Total memory 2 00GiB Free memory 1 62GiB I c tf jenkins home workspace release win device gpu os windows tensorflow core common runtime gpu gpu device cc 906 DMA 0 I c tf jenkins home workspace release win device gpu os windows tensorflow core common runtime gpu gpu device cc 916 0 Y I c tf jenkins home workspace release win device gpu os windows tensorflow core common runtime gpu gpu device cc 975 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 1050 pci bus id 0000 01 00 0 print sess run hello E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op BestSplits device type CPU ' for unknown op BestSplits E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op CountExtremelyRandomStats device type CPU ' for unknown op CountExtremelyRandomStats E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op FinishedNodes device type CPU ' for unknown op FinishedNodes E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op GrowTree device type CPU ' for unknown op GrowTree E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op ReinterpretStringToFloat device type CPU ' for unknown op ReinterpretStringToFloat E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op SampleInputs device type CPU ' for unknown op SampleInputs E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op ScatterAddNdim device type CPU ' for unknown op ScatterAddNdim E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op TopNInsert device type CPU ' for unknown op TopNInsert E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op TopNRemove device type CPU ' for unknown op TopNRemove E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op TreePredictions device type CPU ' for unknown op TreePredictions E c tf jenkins home workspace release win device gpu os windows tensorflow core framework op kernel cc 943 OpKernel 'op UpdateFertileSlots device type CPU ' for unknown op UpdateFertileSlots b'hello TensorFlow ',,,2018-03-14 08:11:48,2018-03-15 23:03:18
PR,using finally in tf record iterator,Hi this is to handle the case when generator throw new generator method throw type value none traceback none or generator close new generator method close is called on a tfrecord iterator It will raise an exception like GeneratorExit in the generator is stack and using finally will promptly release the resources in such cases without relying on garbage collection Please let me know if I'm missing something,,,2018-03-16 00:38:05,2018-03-16 01:27:36
PR,MKL DNN fix the TF1 6 speed issue by fixing MKL DNN LRN taking the optimum path 17605,MKL DNN fix the TF1 6 speed issue by fixing MKL DNN LRN fixed typos in the doc for LrnRewrite Requesting a pull to tensorflow r1 7 to fix MKL performance regression described in issue 17383,,tatianashp,2018-03-16 00:43:15,2018-03-16 05:04:33
PR,Cast return value that caused warning,The member function num runs returns an int however the return value from run total us count is an int64 Casting the value to an int allows for the compiler to know that the intended return value should be an int,,,2018-03-15 20:34:12,2018-03-16 05:05:31
PR,make the TfLiteCameraDemo apk built with bazel work again,Current bazel build rule needs labels txt Build with current head you get Uninitialized Classifier or invalid context as shown in the figure below failed,,"freedomtan,freedomtan",2018-02-17 15:44:01,2018-03-16 05:17:37
PR,Fix minor typo in saved model md,Described as PR title,,"imsheridan,frankchn,frankchn,frankchn",2018-03-07 17:36:14,2018-03-16 06:49:16
IS,freeze graph py of tensorflow1 5 without restore op name function,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary binary TensorFlow version use command below Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 7 1 GPU model and memory navidia GTX 1080Ti Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I use freeze graph py of tensorflow1 5 to convert model but i want to use restore op name Is there this function for this version or any other method recommended Thanks Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem My convert command as following python freeze graph py input graph D mywork Re3 demo simple as binary pb input binary True input checkpoint D mywork Re3 demo simple ckpt data 00000 of 00001 output node names re3 fc output add re3 lstm1 rnn while Exit 3 re3 lstm1 rnn while Exit 4 re3 lstm2 rnn while Exit 3 re3 lstm2 rnn while Exit 4 restore op name re3 conv1 W conv re3 conv1 b conv re3 conv1 skip W conv re3 conv1 skip b conv re3 conv1 skip prelu re3 conv2 W conv re3 conv2 b conv re3 conv2 skip W conv re3 conv2 skip b conv re3 conv2 skip prelu re3 conv3 W conv re3 conv3 b conv re3 conv4 W conv re3 conv4 b conv re3 conv5 W conv re3 conv5 b conv re3 conv5 skip W conv re3 conv5 skip b conv re3 conv5 skip prelu re3 fc6 W fc re3 fc6 b fc re3 fc output W fc re3 fc output b fc re3 lstm1 rnn LSTM block input biases re3 lstm1 rnn LSTM block input weights re3 lstm1 rnn LSTM forget gate biases re3 lstm1 rnn LSTM forget gate weights re3 lstm1 rnn LSTM input gate biases re3 lstm1 rnn LSTM input gate weights re3 lstm1 rnn LSTM output gate biases re3 lstm1 rnn LSTM output gate weights re3 lstm2 rnn LSTM block input biases re3 lstm2 rnn LSTM block input weights re3 lstm2 rnn LSTM forget gate biases re3 lstm2 rnn LSTM forget gate weights re3 lstm2 rnn LSTM input gate biases re3 lstm2 rnn LSTM input gate weights re3 lstm2 rnn LSTM output gate biases re3 lstm2 rnn LSTM output gate weights output graph frozen model pb,,,2018-03-15 02:57:19,2018-03-16 08:49:05
IS,tf summary scalar error despairing,Strange error While i was trying to tf summary scalar 'content loss' self content loss there came an error InvalidArgumentError see above for traceback Cannot assign a device for operation 'auto loss' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available Seems strange However the code can be trained on GPU without the tf summary scalar operation,,,2018-03-15 04:33:03,2018-03-16 09:39:01
IS,TF Lite README md lacks link to the mentioned mobilenet v1 224 pb file,,,,2017-11-22 07:35:36,2018-03-16 09:57:16
PR,Changed sparse column with vocabulary file to estimate vocab size,Prior to this change the function required vocab size to be explicitly specified by the user which made the API inconsistent with categorical column with vocabulary file,,"ispirmustafa,ispirmustafa",2018-03-14 09:44:50,2018-03-16 12:05:39
PR,Branch 189319553,,,jpienaar,2018-03-16 11:36:02,2018-03-16 12:38:47
IS,map and batch tensor shape does not match value of tensor in the same way that calling map and batch individually does,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Happens with stock code OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu Server 17 10 1 TensorFlow installed from source or binary Source TensorFlow version use command below b'v1 6 0 0 gd2e24b6039' 1 6 0 Python version 3 6 Bazel version if compiling from source 0 11 0 GCC Compiler version if compiling from source gcc Ubuntu 6 4 0 8ubuntu1 6 4 0 20171010 CUDA cuDNN version 9 1 7 0 5 GPU model and memory not applicable Exact command to reproduce not applicable When I create a tf data Dataset from tfrecord files that utilizes a call to map to parse the tfrecord file and a call to batch to batch the dataset I am able to filter out the last small batch utilizing a straight forward call to filter This same function does not work correctly when utilizing the combined map and batch function The filter function in question is Any help on this issue is greatly appreciated,,"mrry,mrry",2018-03-14 20:05:55,2018-03-16 12:39:52
IS,SSD Resnet50 FPN ValueError Dimensions must be equal,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow custom config file see below OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 7 rc0 and also tried on 1 6 Python version Tried 2 7 and 3 5 Bazel version if compiling from source 0 11 1 GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 9 5 4 0 20160609 CUDA cuDNN version 8 0 6 0 GPU model and memory GeForce GTX 1060 6GB Exact command to reproduce model builder test py and ssd resnet v1 fpn feature extractor test py passes on Python2 7 Tried TF 1 6 and 1 7 Python 2 7 and 3 5 tried different input resolutions All the same Seems like a bug ssd resnet 50 fpn drone config zip,,,2018-03-16 14:22:37,2018-03-16 14:29:17
IS,android Semantic segmentation,if i want to use my code and model network on pc to run it in mobile android for semantic segmentation that is possible and how thank you System information Have I written custom code No OS Platform and Distribution windows 10 TensorFlow installed from binary TensorFlow version 1 6 Python version 3 Bazel version N A CUDA cuDNN version cuda 9 cudnn 7 GPU model and memory geforce gtx 960 4 GB Exact command to reproduce N A,,,2018-03-16 00:34:18,2018-03-16 16:53:38
IS,train on new dataset,i want to detect people wearing a hat can i directly label those people wearing hats as a class and train on this dataset can cnn distinguish people wearing hats from those who do not,,drpngx,2018-03-08 12:41:43,2018-03-16 17:25:18
IS,android Semantic segmentation,Hello can tensorflow for android be used for semantic segmentation Thank you Lafi,,angersson,2018-03-07 16:15:27,2018-03-16 17:28:09
IS,TypeError Expected binary or unicode string got None,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,av8ramit,2018-03-16 14:39:24,2018-03-16 17:31:16
IS,FEATURE REQUEST Kindly provide the gradient for tf assign,Hi i am trying to connect a CNN to another custom layer i have created However the custom layer that i have created requires the variables in my custom layer to be assigned from the outputs of CNN One may think why i need variables if its assigned from CNN at every iteration Reason for variable creation is to calculate explicit gradients via Register gradient and pyFunc that involves sparse linear equations so that i can apply these gradients on my variables so that the error is back propagated all the way into CNN However when i call tf gradients all the values are None for CNN I found a link over stackoverflow stating that gradients are not defined for tf assign Could you please provide gradient for tf assign so that i can go for an end to end training Thanks Source code logs with tf variable scope xyz reuse tf AUTO REUSE as scope F tf get variable FXT initializer ''' B tf get variable BXT initializer '' lambda tf tf get variable lamda tf initializer 100 0 dtype tf float32 assign op1 tf assign F Fx assign op2 tf assign B Bx op custom layer F B grads tf gradients op tf all trainables Here Fx and Bx are values from CNN In my backprop i have custom gradients that i have explicitly calculated and over riden with tf RegisterGradient and gradient overide When i apply calculate grads i get None None None None None values returned for variables in CNN Defined Gradients Defined Gradients returned for variables in Custom Layer,,"angersson,vrv,yaroslavvb,alextp,alextp",2018-03-15 11:02:38,2018-03-16 18:01:29
PR,Update documentation,This PR updates Readme file with instructions to help installation of external packages,,"samikama,samikama,MarkDaoust,aaroey,yifeif,aaroey",2018-03-13 23:41:37,2018-03-16 18:51:07
IS,how to set sample weight for binary classfication,I Know tf losses sparse softmax cross entropy could set weights for different samples But I don not know how to use it in my custom model for example in the ctr predicition I want set 10 weights for the order samples and the weight of click samples and the unclick sample is still 1 Here is my unweighted code def my custom model features labels mode params net tf feature column input layer features params 'feature columns' for units in params 'hidden units' net tf layers dense net units units activation params activation logits tf layers dense net params 'n classes' activation None if mode tf estimator ModeKeys PREDICT predictions 'probabilities' tf nn softmax logits 'logits' logits return tf estimator EstimatorSpec mode predictions predictions loss tf losses sparse softmax cross entropy labels labels logits logits metrics 'auc' tf metrics auc labels labels predictions tf nn softmax logits 1 if mode tf estimator ModeKeys EVAL return tf estimator EstimatorSpec mode loss loss eval metric ops metrics assert mode tf estimator ModeKeys TRAIN optimizer tf train AdagradOptimizer learning rate 0 1 train op optimizer minimize loss global step tf train get global step return tf estimator EstimatorSpec mode loss loss train op train op train input fn tf estimator inputs pandas input fn x data train y data train click batch size 1024 num epochs 1 shuffle False classifier train input fn train input fn Here data train click is a Series which the click samples are 1 and the unclicked samples are 0 And in the weight Series data train weight the order samples are 10 and the others are 1 However I do not known how to use data train weight in my model,,asimshankar,2018-03-16 11:17:47,2018-03-16 19:40:42
IS,How to update columns in tf Values,OS Platform and Distribution windows 10 TensorFlow installed from anconda TensorFlow version tensorflow gpu 1 1 0 Bazel version N A CUDA cuDNN version 8 GPU model and memory GTX860m 2GB Exact command to reproduce N A I use tf scatter nd update method to update lines but I not find any method to update columns So I was wondering whether has a convenient way to update columns For example data tf Values tf zeros 10 100 and I want to update data with data 0 tf ones 10 or other methods like tf scatter nd update I will appreciate it if anyone can help me,,angersson,2018-03-16 12:40:36,2018-03-16 19:59:34
PR,Fix two small issues of XLA,1 In Tensorflow conventionally INT32 ops are regarded as shape or control ops and are registered on CPU only XLA should follow the same rule to avoid the potential data transfer between TF CPU ops and in GPU XLA ops which result into performance degradation when XLA is turned on 2 Any OpKernel with more than 500 inputs is excluded This is a temp workaround to avoid an potential issue that the cuda drive do not accept a compiled PTX kernel with parameter space larger than 4352 bytes The data type of PTX kernel parameter is u64 An OpKernel with 500 inputs are more likely to exceed the limit,,"hawkinsp,hawkinsp,jlebar,jlebar,rmlarsen,jlebar,rmlarsen",2018-01-20 15:01:24,2018-03-16 20:48:01
PR,1 7 0rc2 cherry pick request Fixes a bug in tf contrib data map and batch shape inference,This backports a fix for issue 17720 to the release branch It would not be the end of the world if this change was not cherry picked but I'm sending it opportunistically in case it is be possible to fix the bug in the new release,,mrry,2018-03-16 20:19:57,2018-03-16 21:03:59
PR,CMake Extract more file lists,like 14877 cc,,"Androbin,mrry,Androbin,drpngx,Androbin,gunan,martinwicke,Androbin,Androbin,Androbin,rmlarsen,Androbin,gunan",2017-12-22 18:36:03,2018-03-16 21:30:11
IS,No documentation on the order of eigenvalues returned by tf self adjoint eig,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 4 0 rc1 11 g130a514' '1 4 0' Python version 2 7 14 Describe the problem From the documentation of tf self adjoint eig I cannot see what the order of eigenvalues is I tried with several examples and found they were sorted in ascending order Does this always hold,,"qmick,skye,annarev,skye",2018-02-04 06:48:59,2018-03-16 22:33:45
PR,Add doc on the order of eigenvalues returned by tf self adjoint eig,Resolves 16747 As discussed in 16747 I think we can add doc on the order of eigenvalues returned by tf self adjoint eig But further discussion may be required Any opinions will be appreciated Eigen doc says The eigenvalues are repeated according to their algebraic multiplicity so there are as many eigenvalues as rows in the matrix The eigenvalues are sorted in increasing order a3df8721abcc71132f7f02bf9dfe78e41 And CUDA doc says a real array of dimension n The eigenvalue values of A in ascending order ie sorted so that W i W i 1 cuds lt t gt syevd The key point is whether we should add this order constraint to TensorFlow itself Will tf self adjoint eig move to other implementation that does not guarantee ascending order one day,,"qmick,rmlarsen,qmick",2018-02-10 09:47:29,2018-03-16 22:33:45
IS,r1 6 broken link to nasm package in workspace bzl,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 6 0 Python version 2 7 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 GPU model and memory NVidia GeForce 1060 6GB Exact command to reproduce The build is unable to continue at this point I have run it multiple times all with the same error I have found that this is because there is only one working mirror link for the nasm package inside of the bazel config I can confirm that link is dead 403 response Adding another mirror such as to tensorflow workspace bzl allowed the build to continue This is all done on the r1 6 branch Note this is a duplicate of 16862 In order to repro just try to build tensorflow from source using the instructions at while working on the r1 6 branch Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2018-03-12 13:50:36,2018-03-16 23:55:25
IS,Feature request Increase kMaxEagerParentSize or make it python version dependent,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A problem occurs on startup OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Source TensorFlow version use command below tip of tree Python version 3 6 from source Bazel version if compiling from source 0 10 1 GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version unused GPU model and memory n a Exact command to reproduce import tensorflow Describe the problem We wanted to evaluate our patches in Valgrind so we made a custom build of python 3 6 from source it is more valgrind friendly then compiled TensorFlow against that When this done 'import tensorflow' fails on a python exception because the size of the base class of EagerTensor in Python 3 6 is greater than kMaxEagerParentSize Issue 16836 was opened on this a month ago but closed by its creator When we encountered this problem we found that we could simply set the value of kMaxEagerParentSize to 48 and everything would run with no obvious issues Is there a reason that kMaxEagerParentSize must always equal 32 or can it be increased or possibly even adjusted depending on which version of python TensorFlow is being compiled for Source code logs,,"aselle,alextp",2018-03-08 01:32:24,2018-03-17 00:06:57
IS,Should this error message be a bracket instead of parentheses,Received a label value of 1 which is outside the valid range of 0 1 Am I reading it wrong or it should be 0 1 insteado fo 0 1 L45,,mrry,2018-03-16 19:20:19,2018-03-17 00:10:53
IS,Feature request Provide API to test whether a copy of TensorFlow has MKL support,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 5 0 9 gc959ec7 Python version 3 5 Bazel version if compiling from source 0 10 0 GCC Compiler version if compiling from source c Ubuntu 5 4 0 6ubuntu1 16 04 9 5 4 0 20160609 CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce n a Describe the problem I have built a copy of TensorFlow with MKL DNN support The MKL convolution operators work much better with the channels first NCHW data format On non MKL non GPU builds the channels first data format does not work for me because a CPU version of average pooling is not implemented for that data format I would like to have my scripts test whether the current copy of TensorFlow has either MKL or GPU support and if so to use the channels first data format I can easily test for GPU support with tf test is built with cuda However there does not seem to be a corresponding API to test for MKL DNN support Would it be possible to add one,,"frreiss,asimshankar,tatianashp,tatianashp,frreiss,tatianashp",2018-02-21 20:14:12,2018-03-17 01:17:28
PR,add reflexive method for Dimension,Fix 17482,,"facaiy,shoyer,facaiy,shoyer,facaiy,facaiy,facaiy",2018-03-08 08:24:07,2018-03-17 01:50:58
IS,TensorFlowInferenceInterface feed fails to accept multi dimensional input,Describe the problem My understanding is that TensorFlowInferenceInterface feed takes a 1D float array float as input Source code logs,,,2018-03-17 01:54:57,2018-03-17 02:14:02
PR,Fix incorrect link of checkpoint files in CNN tutorials,This PR is to fix the incorrect link of checkpoint files in CNN tutorials As we can see in CNN tutorials launching and training the model below checkpoint files links to saving and restoring which is not correct cifar10 train py periodically saves all model parameters in checkpoint files but it does not evaluate the model The correct intended link should be instead,,imsheridan,2018-03-16 19:02:35,2018-03-17 02:14:20
PR,Fix typo,fix typo,,ManHyuk,2018-03-16 07:04:16,2018-03-17 02:44:41
PR,Add missing linking libs for iOS,When creating a new iOS app in Xcode with Tensorflow we need to add these references to fix linking errors,,frankchn,2018-03-16 10:55:28,2018-03-17 03:33:27
IS,Unable to match the last equations from the nmt paper in the nmt implementation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 4 0 Python version 3 5 2 Bazel version if compiling from source not compiled from source GCC Compiler version if compiling from source not compiled from source CUDA cuDNN version 8 0 6 GPU model and memory 8GB x 4 GTX 1080 Exact command to reproduce N A I have already asked the question over tensorflow nmt but also asking here to maybe grab some traction In the NMT paper pg 13 14 they have defined the model architecture In the Decoder section A 2 2 they have proposed probability of a target word w r t the deep output ti with a single maxout hidden layer But if I look at the source code where the graph is built L274 it calls the build decoder L358 function where the decoder section is built I could not find the implementation of these equations image Can someone clarify as to how those equations are included in the nmt implementation,,tatianashp,2018-03-13 18:02:10,2018-03-17 04:21:32
IS,Quantize to TFLITE mode how to change the graph to contain min max information for relu layer,cat etc issue Linux xxxx 4 13 0 36 generic 40 16 04 1 Ubuntu SMP Fri Feb 16 23 25 58 UTC 2018 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 9 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux xxxxx 4 13 0 36 generic 40 16 04 1 Ubuntu SMP Fri Feb 16 23 25 58 UTC 2018 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 14 1 numpydoc 0 7 0 protobuf 3 5 2 tensorflow 1 7 0rc0 tensorflow tensorboard 1 5 1 check for virtualenv False tensorflow import tf VERSION 1 7 0 rc0 tf GIT VERSION b'v1 7 0 rc0 2 ga6f8b22' tf COMPILER VERSION b'v1 7 0 rc0 2 ga6f8b22' Sanity check array 1 dtype int32 env LD LIBRARY PATH home user software install TensorRT 3 0 4 lib usr local cuda lib64 DYLD LIBRARY PATH is unset nvidia smi Fri Mar 16 11 28 51 2018 NVIDIA SMI 384 111 Driver Version 384 111 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 1080 Off 00000000 01 00 0 On N A 0 38C P8 9W 200W 253MiB 8110MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 1132 G usr lib xorg Xorg 139MiB 0 3053 G compiz 111MiB cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 Problem I try to quantize my model Computation is as follow pointwise conv2d relu depthwise conv2d x Then I use tf contrib quantize create eval graph to quantize graph However there is an error when I use lite toco convert to convert model into tflite I want to konw how to change the graph to contain min max information for relu layer MSG Array conv2 depthwise relu which is an input to the Conv operator producing the output array conv2 is lacking min max data which is necessary for quantization Either target a non quantized output format or change the input graph to contain min max information or pass default ranges min and default ranges max if you do not care about the accuracy of results quant zip,,tatianashp,2018-03-16 03:46:25,2018-03-17 04:32:40
IS,Raspberry Pi 3 C compiling issue,System information Raspberry Pi 3 running a clean install of latest Raspbian version November 2017 Have I written custom code No OS Platform and Distribution Raspbian version November 2017 TensorFlow installed from git cloned the latest version TensorFlow version git cloned the latest version Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Tensorflow Makefile for Raspberry Pi raspberry pi Problem I am having a problem building the C library of Tensorflow First I use a USB as a swap by follwing the instructions here 2 install a memory drive as swap for compiling Then continued on building tensorflow with the instructions below raspberry pi I followed all the steps and believed that everything went successfull until I build the library and example using the command below The rest of the log can be seen here output log txt,,tatianashp,2018-03-11 00:40:12,2018-03-17 04:35:54
PR,fix the bug that all string fields in protobuf share same memory location in the monolithic build,All string fields in protobuf share same memory location in the monolithic build This problem is described in 16291 Export protobuf related symbols in the library to fix it,,"gunan,allenlavoie,allenlavoie",2018-03-16 12:06:53,2018-03-17 05:58:32
PR,Update version strings for 1 7 0 rc1,,,yifeif,2018-03-16 23:25:33,2018-03-17 05:58:51
IS,The multiply operator of type Dimension has a bug,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code OS Win10 64bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 Python version 3 6 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 GPU model and memory GTX 1080Ti Exact command to reproduce See codes below Describe the problem Suppose A is a tensor L A shape 0 I found that L 3 works while 3 L lead to a TypeError Can someone fix this Source code logs Output is image,,"shoyer,facaiy",2018-03-06 15:21:08,2018-03-17 07:37:52
PR,Fix to 'Model' object has no attribute ' container nodes' error when using tf keras utils plot model,Fix to 17633 Duplicate of 17658 'Model' object has no attribute ' container nodes' error when using tf keras utils plot model Replaced if node key in model container nodes with if node key in model network nodes pylint disable protected access in tensorflow python keras impl keras utils vis utils py,,,2018-03-13 03:49:44,2018-03-17 10:43:29
IS,add broadcasting to softmax cross entropy with logits,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yeah OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary pip3 binary TensorFlow version use command below,,"aselle,facaiy,reedwm,ebrevdo",2018-01-17 20:33:07,2018-03-17 15:45:08
IS,LSTMBlockFusedCell does not support using DropoutWrapper,I am trying to use DropoutWrapper with LSTMBlockFusedCell as follows I get an exception that the LSTMBlockFusedCell is not an RNNCell Message The parameter cell is not a RNNCell Which is raised form like rnncell during DropoutWrapper initialization It is checking for those proprieties on the cell Checks that a given object is an RNNCell by using duck typing conditions hasattr cell output size hasattr cell state size hasattr cell zero state callable cell LSTMBlockFusedCell does not have output size state size or zero state properties Should LSTMBlockFusedCell act like RNNCell to allow using various wrappers,,"reedwm,ebrevdo,ebrevdo,facaiy,ebrevdo,facaiy,ebrevdo",2017-10-12 01:33:52,2018-03-17 15:46:23
PR,Added training parameter to batch normalization,According to the docs the batch normalization layer does not work properly if the parameter is not set correctly,,"rmlarsen,rmlarsen",2018-01-15 16:36:51,2018-03-17 18:16:22
PR,contrib minor spelling tweaks,packages model pruning rnn solvers tensorrt,,brettkoonce,2018-03-17 00:00:33,2018-03-17 19:22:24
PR,Fix typo in dataset ops py datset dataset,Tested This is a noop,,joel-shor,2018-03-17 19:14:18,2018-03-17 19:46:55
IS,got Nan when powered float32 tensors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Windows 10 Pro TensorFlow installed from prebuild version here with avx2 TensorFlow version 1 6 0 Python version 3 6 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA 9 1 85 cuDNN 1 7 1 version GPU Nvidia MX150 2GB Exact command to reproduce Describe the problem On my setup tensorflow get nan when I powered tensors with float32 type but with float64 it is ok But if just product tensors by itself in float32 it is ok too Source code logs Scenario 1 So on more serious or complicated tasks this give unpredictable behavior and optimizers do not optimize losses get NaN everything going crazy or just NaN everywhere So I exactly had the same problem on tensorflow version 1 5 0 with CuDNN 7 0 5 And I can not understand is it my setup and maybe videocard just bad or is it really bug,,"tatianashp,fo40225",2018-03-11 21:18:53,2018-03-17 19:48:08
PR,MKL Fixed timeline test unit test failure changed the test so that,Fixed timeline test unit test fails changed the test so that it can take cpu name changed with MKLDNN naming conversion,,,2018-03-16 18:24:32,2018-03-17 20:17:14
IS,Would a vector field layer be a welcome addition,Here is a paper I stumbled upon yesterday It describes an interesting visual approach of separation of mixed set of points in high dimensional spaces into linearly separable set of points by learning a vector field that carries input points to new locations Coupled with Tensorboard such a layer would provide intuition as to what the network is doing We would see how it warps the space to provide linear separability I have started coding up such a layer to run some visualizations Note that this would be a first contribution to the code base so excuse any dumb things as I am learning the code base and I am wondering if anyone wants to collaborate on the implementation and if upon successful implementation and tests such a layer could be accepted into the code base,,,2018-02-24 15:26:13,2018-03-18 01:16:16
IS,Link error on compile android protobuf sh,TensorFlow version use command below r1 6 Hi I'm trying to use Makefile to compile android library following this guideline but having an issue with compile android protobuf sh I tried with both NDKr16b and NDKr15c but getting this error DL tensorflow tensorflow tensorflow contrib makefile compile android protobuf sh c a x86 64 DL tensorflow tensorflow tensorflow contrib makefile downloads protobuf src libs libprotobuf a common o common cc function google protobuf internal DefaultLogHandler google protobuf LogLevel char const int std string const error undefined reference to istderr' DL tensorflow tensorflow tensorflow contrib makefile downloads protobuf src libs libprotobuf a common o common cc function google protobuf internal DefaultLogHandler google protobuf LogLevel char const int std string const error undefined reference to istderr' collect2 error ld returned 1 exit status I also modified sh to add SYSROOT usr include as include path but still getting same error,,angersson,2018-03-01 18:02:25,2018-03-18 04:30:49
IS,wrapping op in while loop makes it run faster even with single iteration,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 5 0 0 g37aa430 1 5 0 Python version 3 5 2 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source CUDA cuDNN version CUDA 9 1 CuDNN 7 GPU model and memory GeForce GTX 1050 4042MiB Exact command to reproduce See below Describe the problem I am working on an object detector I have one entry point to my code that detects objects in a single image and another that reads in a batch of images The batch version uses tf while loop to apply the same inference code to each image in the batch I can not put all the images into a single tensor because they are all likely to be different dimensions so I am using a TensorArray The final results work as expected but the timing behavior is odd The first sess run call in the loop over the dataset is always slower than the rest presumably due to caching memory allocation etc However the first call in the non batch version is WAY slower than the first call in the batch version I distilled this down to the minimal examples below The first version does a dot product in a straightforward way On my machine it takes about 13 seconds to run The second version does the same dot product but wrapped in a while loop and writing the result to an intermediate TensorArray and then reading it out again On my machine it takes about 4 seconds to run Presumably version 2 has to do the same data copying memory allocation etc as version 1 in addition to the overhead of the while loop and TensorArray calls So the timing behavior is unexpected Version 2 can even be modified to compute the same dot product 10 or more times and it will still run faster This behavior holds even if the loop body is modified to use a random vector every time so I do not think it is due to caching It also holds even if parallel iterations is held to 1 so I do not think it is due to parallelism Is this a bug or is something else going on under the hood Source code logs,,,2018-02-12 06:28:02,2018-03-18 16:34:03
PR,Controlled logging for Estimator,Added logging every n iter argument for Estimator fit This controls the frequency of the display of metrics,,"selcouthlyBlue,martinwicke",2018-02-12 15:39:32,2018-03-18 17:45:32
PR,Added controlled logging for estimator py,Added extra argument logging every n iter to the fit function of Estimator in estimator py to control logging display,,"selcouthlyBlue,martinwicke",2018-02-13 01:00:35,2018-03-18 17:46:42
PR,Add EvalResultsExporter for writing the results of evaluation to a file,Previously you could capture the return value of estimator train and evaluate which was a dictionary of the final evaluation results like accuracy AUC Since estimator train and evaluate no longer returns a value it looks like there is no way to get the eval results dictionary directly This is the solution I wrote for getting and storing that dictionary Since the solution is generalizable I thought it would be useful to include it for others to use,,"xiejw,rmlarsen,martinwicke",2018-01-05 23:28:40,2018-03-18 17:50:39
PR,add a simple tensorflow model safety check tool,Check whether a TensorFlow model contains security sensitive ops Output related info This script is designed to take a checkpoint or SavedModel model file and detect whether it contains security ops and output the check result Traditionally a TensorFlow model is considered as data files this leads people to ignore the fact that the TensorFlow model graph is actual program code which contains kinds of ops and runs under the TensorFlow runtime Therefore it is possibile to use legitimate ops to do some malicious things in a model file This script just checks some predefined sensitive ops do not rely on its result completely For security risks of TensorFlow model your can refer to this,,"martinwicke,martinwicke,yifeif,martinwicke,yifeif,martinwicke,frankchn,martinwicke",2018-03-06 01:58:07,2018-03-18 18:03:01
IS,Feature Request Support grayscale images for classifier on Android,How can one modify ClassifierActivity java to convert images obtained from the camera to grayscale and then pass them to the inferenceInterface Have I written custom code I want to use the ClassifierActivity with another neural network that was trained on grayscale images OS Platform and Distribution N A TensorFlow installed from pip TensorFlow version 1 2 0 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,,2018-02-15 20:15:06,2018-03-18 18:51:46
PR,minor formatting fix in random uniform documentation,,,,2018-03-18 12:15:16,2018-03-18 21:35:25
IS,BeamSearchDecoder should support an AttentionWrapper cell with alignment history enabled,System information Have I written custom code yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 3 0 Python version 2 7 Exact command to reproduce see the code snippet below Describe the problem Currently setting tf contrib seq2seq AttentionWrapper is alignment history argument to True and using this cell in a tf contrib seq2seq BeamSearchDecoder does not work for 2 reasons 1 In this configuration the tf contrib seq2seq AttentionWrapper state size property is invalid as it does not have the same structure as zero state see the code below The decoder state initialization L193 is failing because of this 2 tf contrib seq2seq BeamSearchDecoder raises an error L123 when the state contains a TensorArray which is the type currently used to gather alignments I believe this configuration should be supported as it is a standard use case for sequence to sequence models To address both of these limitations it seems this alignment history could be a Tensor on which alignments are repeatedly concatenated Would it work Source code logs This code sample reproduces 1 which is the error directly visible when using this configuration,,"guillaumekln,ebrevdo,ebrevdo,guillaumekln,ebrevdo,ebrevdo",2017-09-19 13:51:06,2018-03-18 22:18:47
PR,Support TensorArray in BeamSearchDecoder state,13208 attempted to fix 13154 by representing the alignment history field with a Tensor instead of a TensorArray However pointed out that this approach led to a quadratic time and space overhead This PR fixes the issue by directly adding the support for TensorArray in the BeamSearchDecoder state as proposed by Let me know what you think of this implementation Thanks,,"guillaumekln,ebrevdo,guillaumekln,ebrevdo,guillaumekln,ebrevdo,ebrevdo,ebrevdo,guillaumekln,guillaumekln,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,guillaumekln,guillaumekln,guillaumekln,ebrevdo,ebrevdo,ebrevdo,ebrevdo,guillaumekln,ebrevdo,ebrevdo,ebrevdo,ebrevdo,guillaumekln,ebrevdo,guillaumekln,ebrevdo,sb2nov,sb2nov,ebrevdo,ebrevdo,ebrevdo,guillaumekln,guillaumekln,martinwicke,guillaumekln,guillaumekln,martinwicke,ebrevdo,ebrevdo,guillaumekln,ebrevdo,ebrevdo,guillaumekln,guillaumekln,ebrevdo,rmlarsen,ebrevdo,rmlarsen,guillaumekln,guillaumekln,rmlarsen,rmlarsen,guillaumekln,rmlarsen,ebrevdo",2017-09-26 13:07:16,2018-03-18 22:18:48
IS,Logging frequency hardcoded in tf estimator,Describe the problem The logging frequency of the default LoggingTensorHook of tf Estimator is hardcoded to 100 steps see lines 828 837 in It would really help me to unclutter my logs if I had access to this value my training is fast,,"facaiy,ispirmustafa",2018-03-13 13:12:19,2018-03-18 22:21:44
IS,Wrong object and switch,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug a feature request or a significant problem with documentation for small docs fixes please send a PR instead 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2018-03-18 14:08:26,2018-03-18 23:25:51
PR,layers py spatial softmax activation can be selected by user,Allow user specified activation functions to be selected when calling spatial softmax I wanted to keep the changes minimal but it may be worth considering a rename of the layer to spatial activation with softmax as the default spatial softmax could simply call spatial activation or be removed Thoughts,,"ahundt,sguada,ahundt,sguada,sguada,ahundt,ahundt,ahundt,sguada,ahundt,drpngx,sb2nov,ahundt,ahundt,sguada,drpngx,ahundt,ahundt,drpngx,ahundt,drpngx,ahundt,drpngx,ahundt,drpngx,ahundt,ahundt",2017-08-24 07:26:02,2018-03-19 00:16:00
IS,tf1 6 error tf train BytesList string expected one of bytes,OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from binary TensorFlow version 1 6 Python version 3 5 5 GCC Compiler version GCC 4 8 4 CUDA cuDNN version cuda9 cuDNN7 GPU model and memory Tesla K20c Tesla K20m code to reproduce,,,2018-03-13 08:11:51,2018-03-19 01:38:37
IS,Convert SavedModel files into TFLite file with toco convertor,Feature request System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem TensorFlow Lite is great and we can use the toco tools to convert freeze graph And we can specify the input and output tensors for this model However we use SavedModel a lot for TensorFlow Serving It has all the weights of the model and described the model signature in the better way It would be great if we can convert SavedModel file format into the final TFLite so that we do not need to export the model in many ways,,asimshankar,2017-11-15 03:41:12,2018-03-19 01:40:14
PR,Add resize image aspect with pad method,This method adds the ability to resize the image to specified size with padding without distortions by preserving the aspect ratio,,,2018-03-19 01:52:51,2018-03-19 01:58:31
IS,i not understand what matter is my code about beamsearchdecoder,decoder cell for in range n layers decoder c tf nn rnn cell BasicLSTMCell num units if train state decoder c tf contrib rnn DropoutWrapper decoder c input keep prob decoder cell append decoder c decoder cell tf nn rnn cell MultiRNNCell decoder cell state is tuple True attention mechanism tf contrib seq2seq BahdanauAttention num units encoder outputs attention cell tf contrib seq2seq AttentionWrapper decoder cell attention mechanism helper tf contrib seq2seq TrainingHelper decoder embedded decoder length initial state attention cell zero state dtype tf float32 batch size 50 initial state initial state clone cell state encoder state training decoder tf contrib seq2seq BasicDecoder attention cell helper initial state output layer None train decoder outputs train decoder state tf contrib seq2seq dynamic decode training decoder start tokens tf placeholder dtype tf int32 shape None end token tf placeholder dtype tf int32 shape tiled encoder outputs tf contrib seq2seq tile batch encoder outputs multiplier beam width tiled encoder state tf contrib seq2seq tile batch encoder state multiplier beam width tiled sequence length tf contrib seq2seq tile batch encoder length multiplier beam width attention mechanism tf contrib seq2seq BahdanauAttention num units tiled encoder state 1 0 attention cell tf contrib seq2seq AttentionWrapper decoder cell attention mechanism initial state attention cell zero state dtype tf float32 batch size 50 beam width initial state initial state clone cell state tiled encoder state predicting decoder tf contrib seq2seq BeamSearchDecoder attention cell embeddings start tokens end token initial state initial state beam width beam width output layer None predict decoder ouputs tf contrib seq2seq dynamic decode predicting decoder ndexError Traceback most recent call last ipython input 43 08de1520bc78 in module 1 predict decoder ouputs tf contrib seq2seq dynamic decode predicting decoder anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops decoder py in dynamic decode decoder output time major impute finished maximum iterations parallel iterations swap memory scope 284 285 parallel iterations parallel iterations 286 swap memory swap memory 287 288 final outputs ta res 1 anaconda3 lib python3 6 site packages tensorflow python ops control flow ops py in while loop cond body loop vars shape invariants parallel iterations back prop swap memory name 2814 loop context WhileContext parallel iterations back prop swap memory pylint disable redefined outer name 2815 ops add to collection ops GraphKeys WHILE CONTEXT loop context 2816 result loop context BuildLoop cond body loop vars shape invariants 2817 return result 2818 anaconda3 lib python3 6 site packages tensorflow python ops control flow ops py in BuildLoop self pred body loop vars shape invariants 2638 self Enter 2639 original body result exit vars self BuildLoop 2640 pred body original loop vars loop vars shape invariants 2641 finally 2642 self Exit anaconda3 lib python3 6 site packages tensorflow python ops control flow ops py in BuildLoop self pred body original loop vars loop vars shape invariants 2588 structure original loop vars 2589 flat sequence vars for body with tensor arrays 2590 body result body packed vars for body 2591 if not nest is sequence body result 2592 body result body result anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops decoder py in body time outputs ta state inputs finished sequence lengths 232 233 next outputs decoder state next inputs 234 decoder finished decoder step time inputs state 235 next finished math ops logical or decoder finished finished 236 if maximum iterations is not None anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops beam search decoder py in step self time inputs state name 456 self maybe merge batch beams 457 cell state self cell state size 458 cell outputs next cell state self cell inputs cell state 459 cell outputs nest map structure 460 lambda out self split batch beams out out shape 1 cell outputs anaconda3 lib python3 6 site packages tensorflow python ops rnn cell impl py in call self inputs state scope 181 with vs variable scope vs get variable scope 182 custom getter self rnn get variable 183 return super RNNCell self call inputs state 184 185 def rnn get variable self getter args kwargs anaconda3 lib python3 6 site packages tensorflow python layers base py in call self inputs args kwargs 573 if in graph mode 574 self assert input compatibility inputs 575 outputs self call inputs args kwargs 576 577 if outputs is None anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops attention wrapper py in call self inputs state 1322 attention alignments compute attention 1323 attention mechanism cell output previous alignments i 1324 self attention layers i if self attention layers else None 1325 alignment history previous alignment history i write 1326 state time alignments if self alignment history else anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops attention wrapper py in compute attention attention mechanism cell output previous alignments attention layer 971 Computes the attention and alignments for a given attention mechanism 972 alignments attention mechanism 973 cell output previous alignments previous alignments 974 975 Reshape from batch size memory time to batch size 1 memory time anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops attention wrapper py in call self query previous alignments 531 with variable scope variable scope None bahdanau attention query 532 processed query self query layer query if self query layer else query 533 score bahdanau score processed query self keys self normalize 534 alignments self probability fn score previous alignments 535 return alignments anaconda3 lib python3 6 site packages tensorflow contrib seq2seq python ops attention wrapper py in bahdanau score processed query keys normalize 425 dtype processed query dtype 426 Get the number of hidden units from the trailing dimension of keys 427 num units keys shape 2 value or array ops shape keys 2 428 Reshape from batch size to batch size 1 for broadcasting 429 processed query array ops expand dims processed query 1 anaconda3 lib python3 6 site packages tensorflow python framework tensor shape py in getitem self key 519 return TensorShape self dims key 520 else 521 return self dims key 522 else 523 if isinstance key slice IndexError list index out of range,,,2018-03-19 08:00:35,2018-03-19 09:16:02
IS,feature request in examples image retraining retrain py,Hi all This script is working great but please add projector embedding and images in tensorboard,,,2017-11-17 19:50:48,2018-03-19 12:54:27
IS,Bazel build missing dependencies error with MPI,OS SLES12 Python version 3 6 Bazel version Build label 0 11 0 non git gcc version 7 2 0 GCC No GPU No CUDA With MPI enabled in configure everything else disabled When I run the command bazel build config mkl copt DEIGEN USE VML copt mavx copt mavx2 copt mfma copt msse4 1 copt msse4 2 s c opt tensorflow tools pip package build pip package verbose failures I get the error below I guess I could modify the build file to include the additional dependencies ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow contrib mpi collectives BUILD 40 1 undeclared inclusion s in rule ' tensorflow contrib mpi collectives python ops mpi ops so' this rule is missing dependency declarations for the following files included by 'tensorflow contrib mpi collectives kernels mpi ops cc' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor lib statusor h' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor platform port h' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor lib error h' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor lib status h' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor lib stringpiece h' ' home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow stream executor platform logging h' tensorflow contrib mpi collectives kernels mpi ops cc 128 6 warning 'bool tensorflow contrib mpi collectives anonymous IsGPUDevice with T Eigen GpuDevice ' defined but not used Wunused function bool IsGPUDevice GPUDevice Target tensorflow tools pip package build pip package failed to build,,,2018-03-05 12:43:49,2018-03-19 13:02:27
IS,iOS does not support a simple tensorflow network,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra 10 13 1 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 1 Python version 2 7 10 Bazel version if compiling from source 0 9 0 homebrew GCC Compiler version if compiling from source Apple LLVM version 9 0 0 clang 900 0 39 2 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Steps I followed I have trained resnet v2 50 using slim I created a script just to run inference so the input image is a placeholder with name input 1 and the output is the softmax with name softmax I exported the pb graph then I ran You can see the node names and the operations of resnet 50 below here the output node is v tower 0 resnet v2 50 predictions Reshape 1 input 1 Placeholder v tower 0 Reshape shape Const v tower 0 Reshape Reshape v tower 0 split split dim Const v tower 0 split Split v tower 0 sub y Const v tower 0 sub Sub v tower 0 sub 1 y Const v tower 0 sub 1 Sub v tower 0 sub 2 y Const v tower 0 sub 2 Sub v tower 0 concat axis Const v tower 0 concat ConcatV2 v tower 0 Reshape 1 shape Const v tower 0 Reshape 1 Reshape v tower 0 resnet v2 50 Pad paddings Const v tower 0 resnet v2 50 Pad Pad v resnet v2 50 conv1 weights quantized max Const v resnet v2 50 conv1 weights quantized min Const v resnet v2 50 conv1 weights quantized const Const v resnet v2 50 conv1 weights Dequantize v tower 0 resnet v2 50 conv1 Conv2D Conv2D v resnet v2 50 conv1 biases Const v tower 0 resnet v2 50 conv1 BiasAdd BiasAdd v tower 0 resnet v2 50 pool1 MaxPool MaxPool v resnet v2 50 block1 unit 1 bottleneck v2 preact gamma Const v resnet v2 50 block1 unit 1 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 preact Relu Relu v resnet v2 50 block1 unit 1 bottleneck v2 shortcut weights quantized max Const v resnet v2 50 block1 unit 1 bottleneck v2 shortcut weights quantized min Const v resnet v2 50 block1 unit 1 bottleneck v2 shortcut weights quantized const Const v resnet v2 50 block1 unit 1 bottleneck v2 shortcut weights Dequantize v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 shortcut Conv2D Conv2D v resnet v2 50 block1 unit 1 bottleneck v2 shortcut biases Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 shortcut BiasAdd BiasAdd v resnet v2 50 block1 unit 1 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block1 unit 1 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block1 unit 1 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block1 unit 1 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block1 unit 1 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block1 unit 1 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv1 Relu Relu v resnet v2 50 block1 unit 1 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block1 unit 1 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block1 unit 1 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block1 unit 1 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block1 unit 1 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block1 unit 1 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv2 Relu Relu v resnet v2 50 block1 unit 1 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block1 unit 1 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block1 unit 1 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block1 unit 1 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block1 unit 1 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block1 unit 1 bottleneck v2 add Add v resnet v2 50 block1 unit 2 bottleneck v2 preact gamma Const v resnet v2 50 block1 unit 2 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 preact Relu Relu v resnet v2 50 block1 unit 2 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block1 unit 2 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block1 unit 2 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block1 unit 2 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block1 unit 2 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block1 unit 2 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv1 Relu Relu v resnet v2 50 block1 unit 2 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block1 unit 2 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block1 unit 2 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block1 unit 2 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block1 unit 2 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block1 unit 2 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv2 Relu Relu v resnet v2 50 block1 unit 2 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block1 unit 2 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block1 unit 2 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block1 unit 2 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block1 unit 2 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block1 unit 2 bottleneck v2 add Add v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 shortcut MaxPool MaxPool v resnet v2 50 block1 unit 3 bottleneck v2 preact gamma Const v resnet v2 50 block1 unit 3 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 preact Relu Relu v resnet v2 50 block1 unit 3 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block1 unit 3 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block1 unit 3 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block1 unit 3 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block1 unit 3 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block1 unit 3 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv1 Relu Relu v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 Pad paddings Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 Pad Pad v resnet v2 50 block1 unit 3 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block1 unit 3 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block1 unit 3 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block1 unit 3 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block1 unit 3 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block1 unit 3 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv2 Relu Relu v resnet v2 50 block1 unit 3 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block1 unit 3 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block1 unit 3 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block1 unit 3 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block1 unit 3 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block1 unit 3 bottleneck v2 add Add v resnet v2 50 block2 unit 1 bottleneck v2 preact gamma Const v resnet v2 50 block2 unit 1 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 preact Relu Relu v resnet v2 50 block2 unit 1 bottleneck v2 shortcut weights quantized max Const v resnet v2 50 block2 unit 1 bottleneck v2 shortcut weights quantized min Const v resnet v2 50 block2 unit 1 bottleneck v2 shortcut weights quantized const Const v resnet v2 50 block2 unit 1 bottleneck v2 shortcut weights Dequantize v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 shortcut Conv2D Conv2D v resnet v2 50 block2 unit 1 bottleneck v2 shortcut biases Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 shortcut BiasAdd BiasAdd v resnet v2 50 block2 unit 1 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block2 unit 1 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block2 unit 1 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block2 unit 1 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block2 unit 1 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block2 unit 1 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv1 Relu Relu v resnet v2 50 block2 unit 1 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block2 unit 1 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block2 unit 1 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block2 unit 1 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block2 unit 1 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block2 unit 1 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv2 Relu Relu v resnet v2 50 block2 unit 1 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block2 unit 1 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block2 unit 1 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block2 unit 1 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block2 unit 1 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block2 unit 1 bottleneck v2 add Add v resnet v2 50 block2 unit 2 bottleneck v2 preact gamma Const v resnet v2 50 block2 unit 2 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 preact Relu Relu v resnet v2 50 block2 unit 2 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block2 unit 2 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block2 unit 2 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block2 unit 2 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block2 unit 2 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block2 unit 2 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv1 Relu Relu v resnet v2 50 block2 unit 2 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block2 unit 2 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block2 unit 2 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block2 unit 2 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block2 unit 2 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block2 unit 2 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv2 Relu Relu v resnet v2 50 block2 unit 2 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block2 unit 2 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block2 unit 2 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block2 unit 2 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block2 unit 2 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block2 unit 2 bottleneck v2 add Add v resnet v2 50 block2 unit 3 bottleneck v2 preact gamma Const v resnet v2 50 block2 unit 3 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 preact Relu Relu v resnet v2 50 block2 unit 3 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block2 unit 3 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block2 unit 3 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block2 unit 3 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block2 unit 3 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block2 unit 3 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv1 Relu Relu v resnet v2 50 block2 unit 3 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block2 unit 3 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block2 unit 3 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block2 unit 3 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block2 unit 3 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block2 unit 3 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv2 Relu Relu v resnet v2 50 block2 unit 3 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block2 unit 3 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block2 unit 3 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block2 unit 3 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block2 unit 3 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block2 unit 3 bottleneck v2 add Add v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 shortcut MaxPool MaxPool v resnet v2 50 block2 unit 4 bottleneck v2 preact gamma Const v resnet v2 50 block2 unit 4 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 preact Relu Relu v resnet v2 50 block2 unit 4 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block2 unit 4 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block2 unit 4 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block2 unit 4 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block2 unit 4 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block2 unit 4 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv1 Relu Relu v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 Pad paddings Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 Pad Pad v resnet v2 50 block2 unit 4 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block2 unit 4 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block2 unit 4 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block2 unit 4 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block2 unit 4 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block2 unit 4 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv2 Relu Relu v resnet v2 50 block2 unit 4 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block2 unit 4 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block2 unit 4 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block2 unit 4 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block2 unit 4 bottleneck v2 conv3 biases Const v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block2 unit 4 bottleneck v2 add Add v resnet v2 50 block3 unit 1 bottleneck v2 preact gamma Const v resnet v2 50 block3 unit 1 bottleneck v2 preact beta Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 1 bottleneck v2 shortcut weights quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut weights quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut weights quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut weights Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 shortcut Conv2D Conv2D v resnet v2 50 block3 unit 1 bottleneck v2 shortcut biases quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut biases quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut biases quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 shortcut biases Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 shortcut BiasAdd BiasAdd v resnet v2 50 block3 unit 1 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 1 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 1 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv1 Relu Relu v resnet v2 50 block3 unit 1 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 1 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 1 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 1 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 1 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 1 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 1 bottleneck v2 add Add v resnet v2 50 block3 unit 2 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 preact gamma Dequantize v resnet v2 50 block3 unit 2 bottleneck v2 preact beta quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 preact beta quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 preact beta quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 2 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 2 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 2 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv1 Relu Relu v resnet v2 50 block3 unit 2 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 2 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 2 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 2 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 2 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 2 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 2 bottleneck v2 add Add v resnet v2 50 block3 unit 3 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 preact gamma Dequantize v resnet v2 50 block3 unit 3 bottleneck v2 preact beta quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 preact beta quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 preact beta quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 3 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 3 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 3 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv1 Relu Relu v resnet v2 50 block3 unit 3 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 3 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 3 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 3 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 3 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 3 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 3 bottleneck v2 add Add v resnet v2 50 block3 unit 4 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 preact gamma Dequantize v resnet v2 50 block3 unit 4 bottleneck v2 preact beta quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 preact beta quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 preact beta quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 4 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 4 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 4 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv1 Relu Relu v resnet v2 50 block3 unit 4 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 4 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 4 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 4 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 4 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 4 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 4 bottleneck v2 add Add v resnet v2 50 block3 unit 5 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 preact gamma Dequantize v resnet v2 50 block3 unit 5 bottleneck v2 preact beta quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 preact beta quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 preact beta quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 5 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 5 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 5 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv1 Relu Relu v resnet v2 50 block3 unit 5 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 5 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 5 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 5 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 5 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 5 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 5 bottleneck v2 add Add v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 shortcut MaxPool MaxPool v resnet v2 50 block3 unit 6 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 preact gamma Dequantize v resnet v2 50 block3 unit 6 bottleneck v2 preact beta quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 preact beta quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 preact beta quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 preact Relu Relu v resnet v2 50 block3 unit 6 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block3 unit 6 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block3 unit 6 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv1 Relu Relu v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 Pad paddings Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 Pad Pad v resnet v2 50 block3 unit 6 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block3 unit 6 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block3 unit 6 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv2 Relu Relu v resnet v2 50 block3 unit 6 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block3 unit 6 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block3 unit 6 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block3 unit 6 bottleneck v2 add Add v resnet v2 50 block4 unit 1 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 preact gamma Dequantize v resnet v2 50 block4 unit 1 bottleneck v2 preact beta quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 preact beta quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 preact beta quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 preact Relu Relu v resnet v2 50 block4 unit 1 bottleneck v2 shortcut weights quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut weights quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut weights quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut weights Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 shortcut Conv2D Conv2D v resnet v2 50 block4 unit 1 bottleneck v2 shortcut biases quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut biases quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut biases quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 shortcut biases Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 shortcut BiasAdd BiasAdd v resnet v2 50 block4 unit 1 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block4 unit 1 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block4 unit 1 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv1 Relu Relu v resnet v2 50 block4 unit 1 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block4 unit 1 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block4 unit 1 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv2 Relu Relu v resnet v2 50 block4 unit 1 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block4 unit 1 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block4 unit 1 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block4 unit 1 bottleneck v2 add Add v resnet v2 50 block4 unit 2 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 preact gamma Dequantize v resnet v2 50 block4 unit 2 bottleneck v2 preact beta quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 preact beta quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 preact beta quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 preact Relu Relu v resnet v2 50 block4 unit 2 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block4 unit 2 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block4 unit 2 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv1 Relu Relu v resnet v2 50 block4 unit 2 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block4 unit 2 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block4 unit 2 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv2 Relu Relu v resnet v2 50 block4 unit 2 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block4 unit 2 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block4 unit 2 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block4 unit 2 bottleneck v2 add Add v resnet v2 50 block4 unit 3 bottleneck v2 preact gamma quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 preact gamma quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 preact gamma quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 preact gamma Dequantize v resnet v2 50 block4 unit 3 bottleneck v2 preact beta quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 preact beta quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 preact beta quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 preact beta Dequantize v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 preact Const Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 preact Const 1 Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 preact FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 preact Relu Relu v resnet v2 50 block4 unit 3 bottleneck v2 conv1 weights quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 conv1 weights quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 conv1 weights quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 conv1 weights Dequantize v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv1 Conv2D Conv2D v resnet v2 50 block4 unit 3 bottleneck v2 conv1 BatchNorm gamma Const v resnet v2 50 block4 unit 3 bottleneck v2 conv1 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv1 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv1 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv1 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv1 Relu Relu v resnet v2 50 block4 unit 3 bottleneck v2 conv2 weights quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 conv2 weights quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 conv2 weights quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 conv2 weights Dequantize v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv2 Conv2D Conv2D v resnet v2 50 block4 unit 3 bottleneck v2 conv2 BatchNorm gamma Const v resnet v2 50 block4 unit 3 bottleneck v2 conv2 BatchNorm beta Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv2 BatchNorm Const Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv2 BatchNorm Const 1 Const v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv2 BatchNorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv2 Relu Relu v resnet v2 50 block4 unit 3 bottleneck v2 conv3 weights quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 weights quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 weights quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 weights Dequantize v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv3 Conv2D Conv2D v resnet v2 50 block4 unit 3 bottleneck v2 conv3 biases quantized max Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 biases quantized min Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 biases quantized const Const v resnet v2 50 block4 unit 3 bottleneck v2 conv3 biases Dequantize v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 conv3 BiasAdd BiasAdd v tower 0 resnet v2 50 block4 unit 3 bottleneck v2 add Add v resnet v2 50 postnorm gamma quantized max Const v resnet v2 50 postnorm gamma quantized min Const v resnet v2 50 postnorm gamma quantized const Const v resnet v2 50 postnorm gamma Dequantize v resnet v2 50 postnorm beta quantized max Const v resnet v2 50 postnorm beta quantized min Const v resnet v2 50 postnorm beta quantized const Const v resnet v2 50 postnorm beta Dequantize v tower 0 resnet v2 50 postnorm Const Const v tower 0 resnet v2 50 postnorm Const 1 Const v tower 0 resnet v2 50 postnorm FusedBatchNorm FusedBatchNorm v tower 0 resnet v2 50 postnorm Relu Relu v tower 0 resnet v2 50 pool5 reduction indices Const v tower 0 resnet v2 50 pool5 Mean v resnet v2 50 logits weights quantized max Const v resnet v2 50 logits weights quantized min Const v resnet v2 50 logits weights quantized const Const v resnet v2 50 logits weights Dequantize v tower 0 resnet v2 50 logits Conv2D Conv2D v resnet v2 50 logits biases quantized max Const v resnet v2 50 logits biases quantized min Const v resnet v2 50 logits biases quantized const Const v resnet v2 50 logits biases Dequantize v tower 0 resnet v2 50 logits BiasAdd BiasAdd v tower 0 resnet v2 50 SpatialSqueeze Squeeze v tower 0 resnet v2 50 predictions Reshape shape Const v tower 0 resnet v2 50 predictions Reshape Reshape v tower 0 resnet v2 50 predictions Softmax Softmax v tower 0 resnet v2 50 predictions Shape Const v tower 0 resnet v2 50 predictions Reshape 1 Reshape,,,2018-01-23 15:26:45,2018-03-19 14:13:52
PR,Simplify rejection resample test to remove unnecessary iterator initialization,Tested bazel test resample test,,joel-shor,2018-03-18 12:40:51,2018-03-19 14:54:05
IS,TensorFlowLite pod iOS linker does not find GetSegmentPredictions function,Hi I added the 0 0 2 version of TensorFlowLite pod to my project I try to experiment with the Smart Reply demo I used the Android demo code to start from I can find the related function GetSegmentPredictions in one of the pod headers but the linker does not find the appropriate code segment at build time Is there any body who could try out the Smart Reply on iOS When will this be added to the TensorFlowLite pod thanks,,,2018-03-19 15:04:51,2018-03-19 15:09:14
PR,Fix typos in resampling py,Correct initial dist target dist variabes variables,,joel-shor,2018-03-19 15:39:40,2018-03-19 15:58:28
IS,tensorflow upgrade made the spyder ide editor auto complite fail in python 3 6 4,the enviroment is in the python 3 6 4 with the tensorflow upgrade to the new version 1 5 0 The function in spyder editor auto complitation was failed After I uninstall the package future and futures the function was work again I also made a test in python 3 5 4 and there was no problem,,"reedwm,reedwm",2018-01-31 03:24:15,2018-03-19 17:19:55
IS,macOS mnist download error,,,"reedwm,reedwm",2018-01-26 16:28:06,2018-03-19 17:20:59
PR,Fix internal breakage caused by 16659,Due to copybara modification we cannot put tensorflow contrib ffmpeg ffmpeg ops py into if not windows This is to address the breakage caused by I believe with this fix we do not have to rollback it anymore Tested internally cl 189559607,,"meteorcloudy,gunan,meteorcloudy",2018-03-19 17:23:37,2018-03-19 17:27:17
PR,Update README md,Correct MobilenetV1 variable,,"rmlarsen,rmlarsen",2018-01-22 23:22:46,2018-03-19 17:30:06
PR,Add int64 support of axis Tidx for ConcatV2,In array ops cc it was specified that ConcatV2 support both int32 and int64 data types of axis Tidx However in actual kernel implementations only int32 is supported as there is an unnecessary TypeConstraint int32 Tidx specified This fix tries to address the discrepancy between the ops declaration and kernel registration by adding the int64 axis Tidx support for ConcatV2 This fix removes the TypeConstraint and adds additional processing so that differnt types int32 or int64 of axis could be processed correctly Additional test cases have been added to cover the changes as well Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,drpngx,drpngx,yongtang,yongtang",2017-11-04 22:31:04,2018-03-19 17:31:34
IS,Support truly pluggable protocol transport for distributed mode,At this moment Distributed TensorFlow supports only one type of transport protocol which is gRPC however it does seem to be configurable cluster server session So there are at least three things that need to be covered 1 Document the intercommunication protocol session to a server i e what session sends to a server what server should respond etc The good example here would some kind of swagger spec 2 Make protocol configurable from Python 3 Give all a Python interface to implement new types of protocols The whole idea is to let developers an ability to implement the protocol that would let distributed TensorFlow spin up and talk a number compute units serverless containers VMs etc instead of having a bunch of processes cluster servers running during computations within the session Please note I was not able to find any corresponding issues related to given topic,,"skye,mrry,byronyi",2017-12-25 17:51:11,2018-03-19 17:41:25
IS,No gradient for argmax,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary pip TensorFlow version use command below 1 5 0 dev20171210 nightly from today Python version 3 6 2 ArgMax crashes with no gradient error I had a working version before I made slight adjustments to my code I am very confused how this error can happen Stacktrace,,"facaiy,joel-shor,facaiy,facaiy,facaiy,joel-shor,martinwicke,angersson,martinwicke,martinwicke,facaiy",2017-12-11 16:00:03,2018-03-19 18:58:21
IS,Bazel Build fails after updating,After updating my local copy of TensorFlow from the github repository the Bazel build failed with the following error see below However the same command successfully built version 1 5 of TensorFlow OS SLES12 Python version 3 6 Bazel version Build label 0 7 0 non git gcc version 7 2 0 GCC No GPU No CUDA build command bazel build config mkl copt DEIGEN USE VML s c opt tensorflow tools pip package build pip package verbose failures ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow BUILD 399 12 Label ' tensorflow tools integration tests gcs smoke test gcs smoke py' crosses boundary of subpackage 'tensorflow tools integration tests gcs smoke test' perhaps you meant to put the colon here ' tensorflow tools integration tests gcs smoke test gcs smoke py' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow BUILD 399 12 Label ' tensorflow tools integration tests gcs smoke test setup sh' crosses boundary of subpackage 'tensorflow tools integration tests gcs smoke test' perhaps you meant to put the colon here ' tensorflow tools integration tests gcs smoke test setup sh' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow BUILD 399 12 Label ' tensorflow tools integration tests gcs smoke test BUILD bazel' crosses boundary of subpackage 'tensorflow tools integration tests gcs smoke test' perhaps you meant to put the colon here ' tensorflow tools integration tests gcs smoke test BUILD bazel' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow BUILD 399 12 Label ' tensorflow tools integration tests gcs smoke test teardown sh' crosses boundary of subpackage 'tensorflow tools integration tests gcs smoke test' perhaps you meant to put the colon here ' tensorflow tools integration tests gcs smoke test teardown sh' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow BUILD 399 12 Label ' tensorflow tools integration tests gcs smoke test test wrapper sh' crosses boundary of subpackage 'tensorflow tools integration tests gcs smoke test' perhaps you meant to put the colon here ' tensorflow tools integration tests gcs smoke test test wrapper sh' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow tools pip package BUILD 134 1 Target ' tensorflow windows' contains an error and its package is in error and referenced by ' tensorflow tools pip package build pip package' ERROR home hpc pr28fa di72giz TENSORFLOW tensorflow tensorflow tools pip package BUILD 134 1 Target ' tensorflow windows msvc' contains an error and its package is in error and referenced by ' tensorflow tools pip package build pip package' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted Loading failed,,"jbobba,tatianashp",2018-02-27 10:33:37,2018-03-19 19:24:33
IS,Suggestion Tensor add the finalize method to close tensor object after GC,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu TensorFlow installed from source or binary source TensorFlow version use command below Master Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version None GPU model and memory None Exact command to reproduce Run the snippet below Describe the problem Tensor object should initiative call close method to release native memory but the document do not have any reference to mention this important function To avoid some guy to forget call this method suggest invoke close method in the finalize method that let GC try compensate it at last Public void finalize close,,"tatianashp,tatianashp,asimshankar",2018-03-14 11:49:07,2018-03-19 19:45:12
PR,Adds missing protobuf dep to tf contrib data ops,I think this will help resolve the following Or at least I was experiencing a similar issue and this change resolved it for me in my local repo See also cl 189580464,,,2018-03-19 18:18:24,2018-03-19 20:20:12
PR,R1 7,,,,2018-03-17 16:14:56,2018-03-19 21:42:54
PR,Do not use NCHW or NHCW in tf layers conv1d,Fixes deprecation warning when using tf layers conv1d,,"alanhdu,reedwm,alanhdu,alanhdu,alanhdu,reedwm,gunan",2018-03-06 00:13:53,2018-03-19 22:42:09
PR,update TensorRT converter,fixed FusedBatchNorm to support broadcast remove fp16 conversion for type int const add Snapshot in conversion treated as identity,,"jjsjann123,aaroey,aaroey,aaroey,aaroey,aaroey,aaroey,jjsjann123,jjsjann123,jjsjann123,jjsjann123,aaroey,aaroey,jjsjann123,gunan,jjsjann123,yifeif,aaroey,jjsjann123,aaroey",2018-03-16 16:16:24,2018-03-19 23:35:30
PR,Disable kmeans test on mac,,,av8ramit,2018-03-19 23:05:39,2018-03-19 23:36:16
IS,import error cudnnSetRNNDescriptor v6 in tensorflow,hi I have installed tensorflow gpu on ubuntu server at the beginning my tensorflow work well but recently it gives an error when I logging to the python console and import tensorflow as tf server has python 3 5 tensor,,"qmick,qmick,qmick",2018-01-16 19:16:42,2018-03-20 09:11:25
IS,tf estimator RunConfig return worker is not a valid task type in the cluster spec job,System information os ubuntu1604 x86 64 Exact command to reproduce config tf estimator RunConfig docker image tensorflow tensorflow 1 4 0 gpu Describe the problem tf estimator RunConfig return worker is not a valid task type in the cluster spec job Source code logs os environ 'TF CONFIG' json dumps 'cluster' cluster 'cluster' chief chief node ps hosts ps hosts worker hosts worker hosts 'task' 'type' FLAGS job name 'index' FLAGS task index config tf estimator RunConfig LOG File usr local lib python3 5 dist packages tensorflow python estimator run config py line 464 in init self init distributed setting from environment var tf config File usr local lib python3 5 dist packages tensorflow python estimator run config py line 480 in init distributed setting from environment var self cluster spec task env TaskType CHIEF File usr local lib python3 5 dist packages tensorflow python estimator run config py line 188 in validate task type and task id 'variable ' task type cluster spec ValueError worker is not a valid task type in the cluster spec ClusterSpec 'chief' '10 0 0 5 2223' 'ps hosts' '10 0 0 5 2222' 'worker hosts' '10 0 0 6 2222' '10 0 0 4 2222',,,2018-03-20 07:21:46,2018-03-20 10:21:29
IS,Does TensorFlow 1 1 support CUDA 9 1,Does TensorFlow 1 5 support CUDA 9 1 if not shoud i degrade my cuda or upgrade tensorflow,,,2018-03-11 04:01:44,2018-03-20 10:36:58
IS,tensorflow build failure on windows,,,,2018-02-18 14:02:47,2018-03-20 10:54:05
PR,Adds missing protobuf dep to tf contrib data ops 17840,Adds missing protobuf dep to tf contrib data ops I think this will help resolve the following Or at least I was experiencing a similar issue and this change resolved it for me in my local repo,,"gunan,mrry,allenlavoie",2018-03-19 21:17:05,2018-03-20 16:42:22
IS,Fix deprecated api call in NonAtrousConvolution,System information I am using tf version 1 7 0 dev20180317 v1 6 0 rc1 1580 gc941c087a9 on OSX in standard non eager mode Describe the problem Lines 151 156 in class NonAtrousConvolution in tensorflow python ops nn ops py set nhwc as data format when conv dims is 1,,imsheridan,2018-03-19 20:09:49,2018-03-20 17:01:17
IS,Apparent Segmentation Violation with Go API,Hi I am trying to build a project that will take multiple URLs download their images and then use TensorFlow and the InceptionV3 pre trained model to perform image recognition For this I am using the Go API Most of the time this process occurs without an issue but every now and again an error occurs I think this may be caused by a bug in TensorFlow as it appears to being thrown from the c code A sample of the code that I am using is below In case it is relevant I run ProcessImage from different workers concurrently This obviously means that the tfSession variable is shared between different threads However I do not think this is the problem as I have tried having each worker create and use its own session and the error still occurs,,"asimshankar,drpngx,drpngx",2017-09-05 16:25:36,2018-03-20 18:47:48
IS,Segmentation fault when using cuDNN LSTMs orthogonal initializer,On TF 1 4 0 with CUDA 8 0 and cuDNN 7 I get a segmentation fault if I use an orthogonal initializer for the kernel initializer argument of cudnn rnn CudnnLSTM the layers version not the op I'm aware of 14306 but since I'm running into this problem with the cuDNN LSTMs and not the native TF ones I suspect the underlying cause is different,,"drpngx,drpngx",2017-12-30 15:09:00,2018-03-20 18:48:38
IS,Pyinstaller with Tensorflow takes incorrect path for checkpoint ops so file,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 Pyinstaller TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 0 Python version 2 7 6 CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory 3x nVidia GEForce 1080 Describe the problem As Tensorflow is load op library finds paths according to the OS it is being run on I believe this is a problem with Tensorflow in Pyinstaller environment I am trying to make an executable of my Python code which uses Tensorflow The executable gets generated correctly but when I try to run it I get the following error If we look carefully Pyinstaller is expecting the file checkpoint ops so in directory tensorflow contrib util tensorflow contrib framework python ops but there is no directory like this checkpoint ops so is located at tensorflow contrib framework python ops How can this be fixed,,"drpngx,drpngx",2017-09-15 09:29:05,2018-03-20 18:48:46
IS,Segmentation fault when using bidirectional dynamic rnn orthogonal initializer,System information Have I written custom code Yes OS Platform and Distribution Ubuntu 14 04 LTS kernel 3 16 0 77 generic TensorFlow installed from source TensorFlow version 1 4 0rc1 ae04712e3b74bc85445e12c90e375f980a907e2d Python version 2 7 10 Bazel version 0 7 0 GCC Compiler version 4 8 5 CUDA cuDNN version 8 0 6 0 21 GPU model and memory Maxwell Titan X with 12 GiB memory Exact command to reproduce see Describe the problem I recently upgraded from 1 4 0 rc0 to 1 4 0 rc1 and found that a number of my model architectures fail to compile After a bit of a detective work I tracked the issue down to the use of bidirectional dynamic rnn in conjunction with a VariableScope in which initializer orthogonal initializer See for example the test program at Running this will result in a segfault with 1 4 0 rc1 but not with earlier versions The problem is specific to the combination of orthogonal initializer and bidirectional dynamic rnn and does not replicate with other initializers e g uniform unit scaling initializer or dynamic rnn Nor does the choice of RNN cell appear to matter,,"drpngx,drpngx",2017-11-07 00:47:34,2018-03-20 18:48:54
IS,Memory Overhead Leak in Android lib,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Nexus 6p Android v7 1 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 rc2 Python version 2 7 10 Bazel version if compiling from source 0 4 5 homebrew CUDA cuDNN version N A GPU model and memory Exact command to reproduce Selective Headers bazel build c opt copt DSELECTIVE REGISTRATION copt DSUPPORT SELECTIVE REGISTRATION tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a Added tensorflow core kernels random shuffle queue op cc and tensorflow core kernels random shuffle op cc to tf op files txt file Removed unused nodes bazel build tensorflow tools graph transforms transform graph bazel bin tensorflow tools graph transforms transform graph in graph model pb out graph optimized model pb inputs 'input' outputs 'output' transforms ' strip unused nodes type float shape 1 299 299 3 ' Describe the problem The Tensorflow Android library is using a lot more memory than I expected It almost seems like it is maintaining a reference to all input arrays as memory usage balloons the longer the model is used Here is an example of the memory usage with feed run fetch commented out source code below no tensorflow Here is the same timeframe with the only difference being that feed run fetch is enabled tensorflow Memory usage is over three times worse The longer I leave the model running the more memory usage increases it eventually gets to 110 mb The below method is being called at a rate of 4 419011933 per sec i e it is processing 4 412 input arrays per second where each input array is of size 96 96 3 27648 This is being run on a Nexus 6p running stock 7 1 2 The model is a conv net with inception batch norm and dropout trained using tensorflow slim Source code logs Commented out Please let me know if there is any other information I can provide,,"andrewharp,asimshankar,asimshankar,andrewharp,drpngx,drpngx",2017-07-06 20:31:54,2018-03-20 18:49:13
IS,How to load a metagraph via C,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Python version 2 7 Describe the problem I want to load a metagraph via C code and later the checkpoint weights To load the metagraph I first generate a pb file from it How can I load the metagraph The motivation of this is that I want to continue training the model on my Android device,,"mrry,drpngx,drpngx",2017-12-28 09:50:09,2018-03-20 18:49:33
PR,Branch 189641833,,,sb2nov,2018-03-19 22:09:28,2018-03-20 19:02:51
IS,optimizer apply gradients fails inside tfe defun,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 colab TensorFlow installed from source or binary colab TensorFlow version use command below unknown 1 6 0 Python version 3 6 3 Exact command to reproduce Colab Describe the problem optimizer apply gradients does not seem to work inside eager mode is tfe defun The colab contains full details but the relevant part of the exception is usr local lib python3 6 dist packages tensorflow python training optimizer py in get processor v 180 if context in eager mode 181 return DenseResourceVariableProcessor v 182 if v op type VarHandleOp 183 return DenseResourceVariableProcessor v 184 if isinstance v variables Variable usr local lib python3 6 dist packages tensorflow python ops resource variable ops py in op self 601 def op self 602 The op for this variable 603 return self handle op 604 605 def eval self session None usr local lib python3 6 dist packages tensorflow python framework ops py in op self 836 837 def op self 838 raise AttributeError op not supported for Eager Tensors 839 840 AttributeError op not supported for Eager Tensors The problem is presumably that optimizer py is eager mode logic is disabled by defun is graph mode Source code logs Reproducing colab,,"girving,girving,alextp,akshayka,girving",2018-03-17 05:10:25,2018-03-20 19:04:52
IS,TF 1 5 fails on Windows 10 with Security check failure or stack buffer overrun,The error is reproducible on simple MNIST tutorial from I can upload the minidump if necessary TF version python c import tensorflow as tf print tf GIT VERSION tf VERSION b'unknown' 1 5 0 The TF log is Extracting MNIST data train images idx3 ubyte gz Extracting MNIST data train labels idx1 ubyte gz Extracting MNIST data t10k images idx3 ubyte gz Extracting MNIST data t10k labels idx1 ubyte gz INFO tensorflow Using default config INFO tensorflow Using config ' model dir' ' mnist convnet model' ' tf random seed' None ' save summary steps' 100 ' save checkpoints steps' None ' save checkpoints secs' 600 ' session config' None ' keep checkpoint max' 5 ' keep checkpoint every n hours' 10000 ' log step count steps' 100 ' service' None ' cluster spec' tensorflow python training server lib ClusterSpec object at 0x000001F02AEF5860 ' task type' 'worker' ' task id' 0 ' master' '' ' is chief' True ' num ps replicas' 0 ' num worker replicas' 1 INFO tensorflow Create CheckpointSaverHook 2018 01 28 19 09 17 733213 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime gpu gpu device cc 1105 Found device 0 with properties name GeForce GTX 770 major 3 minor 0 memoryClockRate GHz 1 1105 pciBusID 0000 01 00 0 totalMemory 2 00GiB freeMemory 1 64GiB 2018 01 28 19 09 17 733455 I C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core common runtime gpu gpu device cc 1195 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 770 pci bus id 0000 01 00 0 compute capability 3 0 2018 01 28 19 09 19 732272 E C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda dnn cc 385 could not create cudnn handle CUDNN STATUS NOT INITIALIZED 2018 01 28 19 09 19 732452 E C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda dnn cc 389 error retrieving driver version Unimplemented kernel reported driver version not implemented on Windows 2018 01 28 19 09 19 732900 E C tf jenkins workspace rel win M windows gpu PY 36 tensorflow stream executor cuda cuda dnn cc 352 could not destroy cudnn handle CUDNN STATUS BAD PARAM 2018 01 28 19 09 19 733034 F C tf jenkins workspace rel win M windows gpu PY 36 tensorflow core kernels conv ops cc 717 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo T algorithms Exception analysis from WinDbg 42f0 1198 Security check failure or stack buffer overrun code c0000409 second chance WARNING Unable to verify checksum for C Users nobody Anaconda3 lib site packages tensorflow python pywrap tensorflow internal pyd ERROR Symbol file could not be found Defaulted to export symbols for C Users nobody Anaconda3 lib site packages tensorflow python pywrap tensorflow internal pyd ucrtbase abort 0x4e 00007ffc d74eb70e cd29 int 29h 0 034 analyze v WARNING Unable to verify checksum for C Users nobody Anaconda3 python36 dll WARNING Unable to verify checksum for python exe WARNING Unable to verify checksum for C Users nobody Anaconda3 lib site packages numexpr interpreter cp36 win amd64 pyd ERROR Symbol file could not be found Defaulted to export symbols for C Users nobody Anaconda3 lib site packages numexpr interpreter cp36 win amd64 pyd ERROR Symbol file could not be found Defaulted to export symbols for C WINDOWS SYSTEM32 nvcuda dll GetUrlPageData2 WinHttp failed 12002 KEY VALUES STRING 1 TIMELINE ANALYSIS 1 Timeline analyze Start Name blank Time 2018 01 28T17 19 28 120Z Diff 120 mSec Timeline Dump Current Name blank Time 2018 01 28T17 19 28 0Z Diff 0 mSec Timeline Process Start Name blank Time 2018 01 28T17 18 34 0Z Diff 54000 mSec Timeline OS Boot Name blank Time 2018 01 12T10 16 05 0Z Diff 1407803000 mSec DUMP CLASS 2 DUMP QUALIFIER 0 FAULTING IP ucrtbase abort 4e 00007ffc d74eb70e cd29 int 29h EXCEPTION RECORD exr 1 ExceptionAddress 00007ffcd74eb70e ucrtbase abort 0x000000000000004e ExceptionCode c0000409 Security check failure or stack buffer overrun ExceptionFlags 00000001 NumberParameters 1 Parameter 0 0000000000000007 Subcode 0x7 FAST FAIL FATAL APP EXIT FAULTING THREAD 00004cb0 PROCESS NAME python exe ERROR CODE NTSTATUS 0xc0000409 The system detected an overrun of a stack based buffer in this application This overrun could potentially allow a malicious user to gain control of this application EXCEPTION CODE NTSTATUS 0xc0000409 The system detected an overrun of a stack based buffer in this application This overrun could potentially allow a malicious user to gain control of this application EXCEPTION CODE STR c0000409 EXCEPTION PARAMETER1 0000000000000007 WATSON BKT PROCSTAMP 5a5e439a WATSON BKT PROCVER 3 6 4150 1013 PROCESS VER PRODUCT Python WATSON BKT MODULE ucrtbase dll WATSON BKT MODSTAMP 70f70cc4 WATSON BKT MODOFFSET 6b70e WATSON BKT MODVER 10 0 16299 15 MODULE VER PRODUCT Microsoft Windows Operating System BUILD VERSION STRING 10 0 16299 15 WinBuild 160101 0800 MODLIST WITH TSCHKSUM HASH d39c6bc550850a285511eb4ca73187e2bfcc8d5c MODLIST SHA1 HASH c6d888e2558848c801875139c919412641504368 NTGLOBALFLAG 70 APPLICATION VERIFIER FLAGS 0 PRODUCT TYPE 1 SUITE MASK 272 DUMP TYPE fe ANALYSIS SESSION HOST DESKTOP V7DQHVH ANALYSIS SESSION TIME 01 28 2018 19 19 28 0120 ANALYSIS VERSION 10 0 17061 1000 amd64fre THREAD ATTRIBUTES OS LOCALE ENU PROBLEM CLASSES ID 0n277 Type FAIL FAST Class Primary Scope DEFAULT BUCKET ID Failure Bucket ID prefix BUCKET ID Name Add Data Omit PID Unspecified TID Unspecified Frame 0 ID 0n266 Type FATAL APP EXIT Class Addendum Scope DEFAULT BUCKET ID Failure Bucket ID prefix BUCKET ID Name Add Data Omit PID Unspecified TID Unspecified Frame 0 BUGCHECK STR FAIL FAST FATAL APP EXIT DEFAULT BUCKET ID FAIL FAST FATAL APP EXIT PRIMARY PROBLEM CLASS FAIL FAST LAST CONTROL TRANSFER from 00007ffc623b447f to 00007ffcd74eb70e STACK TEXT 000000be c3a3da80 00007ffc 623b447f 000000be 00000003 00000000 00000003 000000be c3a3dbf0 000001f6 6f45afa0 ucrtbase abort 0x4e 000000be c3a3dab0 00007ffc 62dd4ea9 000000be c3a3e640 00000000 00000000 00000000 00000000 000001f6 00000001 pywrap tensorflow internal tensorflow internal LogMessageFatal LogMessageFatal 0x4f 000000be c3a3daf0 00007ffc 62db3d62 00000000 00000001 000000be c3a3ec50 000001f6 8ebb94e8 000000be c3a3f6f0 pywrap tensorflow internal tensorflow LaunchConv2DOp Eigen GpuDevice float operator 0x18c9 000000be c3a3eb50 00007ffc 6251e5b4 000001f6 6f942d30 000001f6 6f461900 000001f6 6f461900 000000be c3a3f0a0 pywrap tensorflow internal tensorflow Conv2DOp Eigen GpuDevice float Compute 0x742 000000be c3a3eda0 00007ffc 6251ddca ffffffff fffffffe 000000be c3a3f050 000001f6 6f3ddc80 000001f6 6fcd2db0 pywrap tensorflow internal tensorflow BaseGPUDevice ComputeHelper 0x4f4 000000be c3a3ef70 00007ffc 623edaa5 00000000 00000000 00000000 00000000 000000be c3a3f100 00000000 00000000 pywrap tensorflow internal tensorflow BaseGPUDevice Compute 0x18a 000000be c3a3f000 00007ffc 623f1068 000001f6 6f8dde30 00007ffc 62384a75 000001f6 6f8dde30 000001f6 6f4635c0 pywrap tensorflow internal tensorflow NewLocalExecutor 0x1065 000000be c3a3f9c0 00007ffc 62384e79 000001f6 6f8dde30 00000000 00000000 000000be c3a3fa58 000001f6 6f4633f0 pywrap tensorflow internal Copy Func impl V Binder U Unforced std P8ExecutorState A0x4f36ba0d tensorflow EAAXUTaggedNode 345 J ZQEAV345 AEBU6345 AEA J std V allocator H 2 X V std EEBAPEAV Func base X V 2 PEAX Z 0x78 000000be c3a3fa10 00007ffc 62385020 000001f6 6f8dde30 00007ffc 00001198 00007ffc aa528b40 00000000 00000000 pywrap tensorflow internal Eigen NonBlockingThreadPoolTempl tensorflow thread EigenEnvironment WorkerLoop 0x3d9 000000be c3a3faa0 00007ffc 623b6ab5 000001f6 6f480000 00007ffc 00000000 000001f6 6f4843c0 00000000 00000000 pywrap tensorflow internal Eigen NonBlockingThreadPoolTempl tensorflow thread EigenEnvironment WorkerLoop 0x580 000000be c3a3fae0 00007ffc 623b6a09 000001f6 6f4845b0 00000000 00000000 00000000 00000000 00000000 00000000 pywrap tensorflow internal tensorflow WindowsFileSystem Utf8ToWideChar 0x175 000000be c3a3fb20 00007ffc d749d885 00000000 fc960000 000001f6 6f4845b0 00000000 00000000 00000000 00000000 pywrap tensorflow internal tensorflow WindowsFileSystem Utf8ToWideChar 0xc9 000000be c3a3fb50 00007ffc d9c21fe4 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 ucrtbase thread start unsigned int cdecl void ptr64 0x35 000000be c3a3fb80 00007ffc da2eef91 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 KERNEL32 BaseThreadInitThunk 0x14 000000be c3a3fbb0 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000 ntdll RtlUserThreadStart 0x21 THREAD SHA1 HASH MOD FUNC a995353e639442c8476b335aedd6ecded1b41211 THREAD SHA1 HASH MOD FUNC OFFSET b900a9e6afe48f2fd80e72effda8ef8748a73296 THREAD SHA1 HASH MOD 216c770e1f463298a8482ae892957bad45a82609 FOLLOWUP IP ucrtbase abort 4e 00007ffc d74eb70e cd29 int 29h FAULT INSTR CODE 15ba29cd SYMBOL STACK INDEX 0 SYMBOL NAME ucrtbase abort 4e FOLLOWUP NAME MachineOwner MODULE NAME ucrtbase IMAGE NAME ucrtbase dll DEBUG FLR IMAGE TIMESTAMP 70f70cc4 STACK COMMAND 34s cxr kb BUCKET ID FAIL FAST FATAL APP EXIT ucrtbase abort 4e FAILURE EXCEPTION CODE c0000409 FAILURE IMAGE NAME ucrtbase dll BUCKET ID IMAGE STR ucrtbase dll FAILURE MODULE NAME ucrtbase BUCKET ID MODULE STR ucrtbase FAILURE FUNCTION NAME abort BUCKET ID FUNCTION STR abort BUCKET ID OFFSET 4e BUCKET ID MODTIMEDATESTAMP 70f70cc4 BUCKET ID MODCHECKSUM fbc7a BUCKET ID MODVER STR 10 0 16299 15 BUCKET ID PREFIX STR FAIL FAST FATAL APP EXIT FAILURE PROBLEM CLASS FAIL FAST FAILURE SYMBOL NAME ucrtbase dll abort FAILURE BUCKET ID FAIL FAST FATAL APP EXIT c0000409 ucrtbase dll abort WATSON STAGEONE URL TARGET TIME 2018 01 28T17 19 44 000Z OSBUILD 16299 OSSERVICEPACK 15 SERVICEPACK NUMBER 0 OS REVISION 0 OSPLATFORM TYPE x64 OSNAME Windows 10 OSEDITION Windows 10 WinNt SingleUserTS USER LCID 0 OSBUILD TIMESTAMP 1976 06 22 09 45 20 BUILDDATESTAMP STR 160101 0800 BUILDLAB STR WinBuild BUILDOSVER STR 10 0 16299 15 ANALYSIS SESSION ELAPSED TIME 9166 ANALYSIS SOURCE UM FAILURE ID HASH STRING um fail fast fatal app exit c0000409 ucrtbase dll abort FAILURE ID HASH e31753ac c98a 8055 3663 47e707543d20,,"drpngx,yzhwang",2018-01-28 17:47:48,2018-03-20 19:07:43
PR,improve fp16 tftrt prediction,delay fp32 to fp16 conversion to reduce accumulated rounding error,,"jjsjann123,aaroey,jjsjann123,jjsjann123,aaroey,gunan,aaroey",2018-03-20 10:55:13,2018-03-20 19:45:54
PR,Disable one more flaky test on mac,,,av8ramit,2018-03-20 19:47:05,2018-03-20 19:51:34
IS,gradient back propagation through image transforms,As we know from the description of tf contrib image transform images transforms Note that gradients are not backpropagated into transformation parameters Here I would like to know whether gradients can be correctly backpropagated into images If yes whether it is automatic Do I need to explicitly define the gradient using gradient map override Any suggestions would be helpful Thanks Have I written custom code N A OS Platform and Distribution Ubuntu 15 04 TensorFlow installed from pip TensorFlow version 1 6 0 Bazel version N A CUDA cuDNN version 9 0 GPU model and memory 24G Quadro P6000 Exact command to reproduce N A,,,2018-03-05 16:51:04,2018-03-20 20:33:37
PR,Add training parameter to dropout to make it work,I think that without this parameter set dropout is disabled all the time At least this is what I read in the documentation besides adding this improves training,,"qmick,rmlarsen,rmlarsen,qmick,rmlarsen,rmlarsen",2018-01-15 16:26:56,2018-03-20 21:20:21
PR,Revert Adds missing protobuf dep to tf contrib data ops 17840,This reverts commit 36ec749ec79c2313924666a1c5324620e493d0c4,,,2018-03-20 16:54:40,2018-03-20 21:52:59
PR,Fix dataset resampling bug introduced by a bug in datasets itself fixes 16606,Fixes github issue 16606 The core issue is that in the case of certain random Tensors the following two lines are not the same Note that this does NOT fix the underlying issue of drawing multiple sampes from the underlying distribution Tested With the new test bazel test resample test fails before and succeeds after,,"joel-shor,mrry,ebrevdo,joel-shor,joel-shor,gunan",2018-03-20 11:21:33,2018-03-20 22:13:39
IS,tf contrib data rejection resample not balancing class freq on random crops,randomly sampling cropping data seems to break rejection resample meaning it wo not do any re balancing of the class probability see these two simple feeders as example The first randomly samples data with tf random uniform and breaks rejection resample the second with static random data having the same distribution is correctly resampled output has p class 0 0 This creates issues when trying to real time sample crop data augment and at the same time rebalance classes with on the same pipeline python def get data breaks self batch size iihook this set 'train' def sample data label sample detection window inside chunk xx tf cast tf random uniform 1 self class num tf int32 0 with tf control dependencies xx tf Print xx xx 'xx ' return xx xx initial dist 1 0 self class num for cc in range self class num classes np random choice self class num 20000 p initial dist data ph tf placeholder classes dtype classes shape labels ph tf placeholder classes dtype classes shape dataset tf data Dataset from tensor slices data ph labels ph dataset dataset map sample num parallel calls 1 target dist 1 0 self class num for cc in range self class num target dist 1 target dist 0 target dist 0 0 print 'target dist ' target dist initial dist None dataset dataset apply tf contrib data rejection resample class func lambda c c target dist target dist initial dist initial dist seed 42 map lambda a b b dataset dataset repeat None iterator dataset make initializable iterator iihook iterator initializer func lambda sess sess run iterator initializer feed dict data ph classes labels ph classes return iterator get next def get data works self batch size iihook this set 'train' initial dist 1 0 self class num for cc in range self class num classes np random choice self class num 20000 p initial dist data ph tf placeholder classes dtype classes shape labels ph tf placeholder classes dtype classes shape dataset tf data Dataset from tensor slices data ph labels ph target dist 1 0 self class num for cc in range self class num target dist 1 target dist 0 target dist 0 0 print 'target dist ' target dist initial dist None dataset dataset apply tf contrib data rejection resample class func lambda c c target dist target dist initial dist initial dist seed 42 map lambda a b b dataset dataset repeat None iterator dataset make initializable iterator iihook iterator initializer func lambda sess sess run iterator initializer feed dict data ph classes labels ph classes return iterator get next,,"ebrevdo,joel-shor",2018-01-30 22:22:56,2018-03-20 22:14:26
PR,Branch 189799697,,,sb2nov,2018-03-20 20:44:50,2018-03-20 22:19:38
IS,Importing a meta graph which contains a SummaryWriter does not work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary binary via pip TensorFlow version use command below v1 6 0 0 gd2e24b6039 1 6 0 Python version 3 6 4 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 0 7 0 GPU model and memory GTX 1080ti 11G Exact command to reproduce First run this,,"asimshankar,alextp,alextp,alextp",2018-03-18 03:24:59,2018-03-20 22:20:23
IS,Feature Request Let Estimator take custom every n iter for LoggingTensorHook,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Amazon Deep Learning AMI TensorFlow version use command below 1 5 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 GPU model and memory NVIDIA K80 Exact command to reproduce N A Describe the problem Currently tf estimator Estimator functions automatically log every 100 steps from this line L760 Can there be an optional argument something like train loss logging frequency 100 passed in instead PR here,,,2018-02-19 01:24:46,2018-03-20 22:41:46
PR,LoggingTensorHook to read from runconfig in Estimator,Fixes Based on the suggestion made in this pull request,,"xiejw,xiejw,xiejw,xiejw",2018-02-20 20:33:13,2018-03-20 22:41:46
PR,Branch 189819449,,,sb2nov,2018-03-20 22:53:47,2018-03-20 23:31:24
PR,Branch 189819449,,,benoitsteiner,2018-03-20 22:48:12,2018-03-21 00:09:47
IS,TypeError broadcast takes 1 positional argument but 2 were given,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below b'v1 3 0 rc1 6044 g0b80606' 1 4 0 2 days ago Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Source code logs I ran tensorflow benchmarks and got the following error The reason is that the invocation of nccl broadcast is different from its signature L748 L173 L182 Problems still exists in current HEAD,,"ppwwyyxx,jart,benbarsdell,ppwwyyxx",2017-12-17 10:31:02,2018-03-21 01:27:50
PR,Revert Fix dataset resampling bug introduced by a bug in datasets itself fixes 16606,Reverts tensorflow tensorflow 17858 Breaks sanity checks,,gunan,2018-03-20 23:18:40,2018-03-21 03:28:36
PR,Fix windows GPU build scripts,PiperOrigin RevId 188629017,,av8ramit,2018-03-20 22:42:38,2018-03-21 03:28:39
PR,Revert Windows Enable tensorflow contrib in Bazel build 16659,This reverts commit c6a12c77a50778e28de3590f4618bc2b62f3ecab,,gunan,2018-03-16 17:25:00,2018-03-21 03:28:59
IS,I am unable to install the latest tensorflow version from pip It always show me the following error,Please go to Stack Overflow for help and support tensorflow 1 0 0 cp35 cp35m win amd64 whl is not a supported wheel on this platform I am running python3 6 64 bit on windows 10,,,2018-03-20 23:17:48,2018-03-21 06:05:01
PR,Update TF Lite android demo,del Duplication,,,2018-03-21 10:29:52,2018-03-21 10:30:21
IS,onv1d,,,,2018-03-21 12:35:43,2018-03-21 12:35:59
IS,cannot decode FixedLenFeature with decode raw,I try to parse data from tfrecord file with Dataset and when I try to parse image with decode raw it throws an error I use tf1 6 the code is as following,,,2018-03-20 06:47:41,2018-03-21 14:20:53
IS,bug segmentation fault happens with nested higher order function,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 11 6 TensorFlow installed from source or binary VirtualEnv TensorFlow version use command below 1 6 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A CPU only GPU model and memory N A CPU only Exact command to reproduce see the following Describe the problem segmentation fault happens when the computation graph contains scan with bidirectional rnn embedded Source code logs,,"ebrevdo,ebrevdo,ebrevdo",2018-03-16 03:53:33,2018-03-21 16:37:55
PR,update TensorRT converter,fixed FusedBatchNorm to support broadcast remove fp16 conversion for type int const add Snapshot in conversion treated as identity,,"jjsjann123,jjsjann123,aaroey,jjsjann123",2018-03-16 20:07:09,2018-03-21 18:40:40
PR,Branch 189913309,,,benoitsteiner,2018-03-21 16:15:20,2018-03-21 19:26:49
IS,Tensorflow distributed training CPU usage difference,Hi Good day I have a question that I hope someone could help Please forgive my grammar errors and missing words I have tried to combine the Cifar10 training examples and example in Distributed TensorFlow website to do the cifar10 distributed training I am a little bit confused on the tf train MonitoredTrainingSession implementation Servers are ok to communicate with each other System information Linux Ubuntu 16 04 Python3 CPU Describe the problem I used two servers each of them are used as 1 PS and 1 Worker and no other programs So total 2 PS and 2 Workers are trained in this experiment What I expected is 2 Workers have the same CPU percentage usage when the training is going on But I found that only one of the server with PS 1 and Worker 1 was running with 100 CPU usage the other server with PS 2 and Worker 2 only used 3 CPU Source code logs The commands I used are python3 cifar10 train py ps hosts Server IP1 2222 Server IP2 2222 worker hosts Server IP1 2223 Server IP2 2000 job name ps task index 0 python3 cifar10 train py ps hosts Server IP1 2222 Server IP2 2222 worker hosts Server IP1 2223 Server IP2 2000 job name ps task index 1 python3 cifar10 train py ps hosts Server IP1 2222 Server IP2 2222 worker hosts Server IP1 2223 Server IP2 2000 job name worker task index 0 python3 cifar10 train py ps hosts Server IP1 2222 Server IP2 2222 worker hosts Server IP1 2223 Server IP2 2000 job name worker task index 1 The f train MonitoredTrainingSession is set as with tf train MonitoredTrainingSession master server target is chief FLAGS task index 0 checkpoint dir tmp train logs hooks hooks as mon sess while not mon sess should stop mon sess run train op,,"tatianashp,yaroslavvb",2018-03-12 19:22:43,2018-03-21 20:28:52
PR,Update the doc of StagingArea put to a tuple or list of Tensors,This PR is to fix 13288 As described in the above issue considering the following two pieces of codes Snippet 1 import tensorflow as tf from tensorflow contrib import staging staging StagingArea dtypes tf int32 put tf constant 1 Snippet 2 import tensorflow as tf from tensorflow contrib import staging staging StagingArea dtypes tf int32 put tf constant 1 The Snippet 1 wo not work while the Snippet 2 works It obviously currently can only support a tuple or a list of tensors instead of single tensor Thus this PR is firstly to fix the doc of StagingArea put Next step I will try to continue working on how to support a single Tensor in a StagingArea put,,"imsheridan,sb2nov",2018-03-20 16:19:48,2018-03-21 21:22:41
IS,how to write the objectives function roc auc score in tflearn by keras,Dear everyone I found the roc auc score function in Now I want to write this function by keras But failed The following is the code The problem is the following 1 ValueError Traceback most recent call last ipython input 3 cc3e34fe5d20 in module 149 epochs epochs 150 validation data validation generator 151 validation steps validation samples batch size 152 153 model save weights 'models basic cnn 30 epochs h5' usr local lib python2 7 dist packages keras legacy interfaces pyc in wrapper args kwargs 85 warnings warn 'Update your ' object name 86 ' call to the Keras 2 API ' signature stacklevel 2 87 return func args kwargs 88 wrapper original function func 89 return wrapper usr local lib python2 7 dist packages keras models pyc in fit generator self generator steps per epoch epochs verbose callbacks validation data validation steps class weight max queue size workers use multiprocessing initial epoch 1119 workers workers 1120 use multiprocessing use multiprocessing 1121 initial epoch initial epoch 1122 1123 legacy generator methods support usr local lib python2 7 dist packages keras legacy interfaces pyc in wrapper args kwargs 85 warnings warn 'Update your ' object name 86 ' call to the Keras 2 API ' signature stacklevel 2 87 return func args kwargs 88 wrapper original function func 89 return wrapper usr local lib python2 7 dist packages keras engine training pyc in fit generator self generator steps per epoch epochs verbose callbacks validation data validation steps class weight max queue size workers use multiprocessing shuffle initial epoch 1924 1925 do validation bool validation data 1926 self make train function 1927 if do validation 1928 self make test function usr local lib python2 7 dist packages keras engine training pyc in make train function self 958 training updates self optimizer get updates 959 params self collected trainable weights 960 loss self total loss 961 updates self updates training updates 962 Gets loss and metrics Updates weights at each call usr local lib python2 7 dist packages keras legacy interfaces pyc in wrapper args kwargs 85 warnings warn 'Update your ' object name 86 ' call to the Keras 2 API ' signature stacklevel 2 87 return func args kwargs 88 wrapper original function func 89 return wrapper usr local lib python2 7 dist packages keras optimizers pyc in get updates self loss params 235 for p g a in zip params grads accumulators 236 update accumulator 237 new a self rho a 1 self rho K square g 238 self updates append K update a new a 239 new p p lr g K sqrt new a self epsilon usr local lib python2 7 dist packages keras backend tensorflow backend pyc in square x 1356 A tensor 1357 1358 return tf square x 1359 1360 usr local lib python2 7 dist packages tensorflow python ops math ops pyc in square x name 447 indices x indices values x square dense shape x dense shape 448 else 449 return gen math ops square x name name 450 451 usr local lib python2 7 dist packages tensorflow python ops gen math ops pyc in square x name 4565 if ctx in graph mode 4566 op op def lib apply op helper 4567 Square x x name name 4568 result op outputs 4569 inputs flat op inputs usr local lib python2 7 dist packages tensorflow python framework op def library pyc in apply op helper self op type name name keywords 526 raise ValueError 527 Tried to convert ' s' to a tensor and failed Error s 528 input name err 529 prefix Input ' s' of ' s' Op has type s that does not match 530 input name op type name observed ValueError Tried to convert 'x' to a tensor and failed Error None values not supported Finally Anyone can check this problem Looking forward to reply Thanks advanced System information Operating System Ubuntu 16 04 LTS Graphics card Tesla K40 Installed version of CUDA 8 0 Installed version of cuDNN v5 for CUDA 8 0 pip version 9 0 1 pip 9 0 1 from usr local lib python2 7 dist packages python 2 7 pip install tensorflow gpu Name tensorflow gpu Version 1 4 1,,reedwm,2018-03-17 14:08:40,2018-03-21 22:07:29
PR,Fix dataset resampling bug introduced by a bug in datasets itself fixes 16606,Fixes github issue 16606 This is a correctly formatted version of PR 17858 The core issue is that in the case of certain random Tensors the following two lines are not the same Tested With the new test bazel test resample test fails before and succeeds after,,joel-shor,2018-03-21 14:59:03,2018-03-21 22:11:34
PR,Fix broken internal anchor link in rnn quickdraw tutorial,This PR is to fix the two broken internal anchor link in the rnn quick draw tutorial as highlighted below 3 Download the data in TFRecord format from here and unzip it More details about how to obtain the original Quick Draw data and how to convert that to TFRecord files is available below This PR is to fix the above two internal anchor link with separated instead of,,imsheridan,2018-03-18 13:34:48,2018-03-21 22:38:04
PR,Fix two external anchor link in kernel method tutorial,This PR is to fix The link of tf contrib learn Estimator As we can see in the note section of kernel method tutorial the two below highlighted link was broken and I can see from the latest source code the second one was fixed while the first one was not pointed to the correct place Note This document uses a deprecated version of tf estimator which has a tf contrib learn estimator different interface It also uses other contrib methods whose version compat not covered API may not be stable The accurate link of input function section It should be get started premade estimators create input functions this section on input functions instead of input fn,,imsheridan,2018-03-18 16:06:27,2018-03-21 22:38:15
PR,Branch 189962437,,,sb2nov,2018-03-21 21:07:49,2018-03-21 22:41:05
PR,Add Scaled Exponential Linear Unit activation Klambauer et al 2017,,,vrv,2018-03-21 18:39:07,2018-03-21 22:53:27
PR,Fix a variable name typo in the python api example,This PR is to fix a small typo in the python api example,,imsheridan,2018-03-21 17:12:32,2018-03-22 01:22:42

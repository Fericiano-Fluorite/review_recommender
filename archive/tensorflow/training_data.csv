PR,Fixed typo in code comment,,,lakshayg,2017-06-02 12:32:15,2017-06-02 20:54:50
PR,fix quotes in example code from to,,,caisq,2017-06-02 19:43:18,2017-06-02 20:55:41
PR,Fix windows tests,,,"gunan,gunan",2017-06-02 21:52:56,2017-06-02 22:42:03
PR,Fix TensorBoard SHA256 in cmake,,,jart,2017-06-03 01:07:44,2017-06-03 01:16:20
PR,Branch 155393864,Pushing internal commits,,"andrewharp,yifeif,gunan,yifeif,andrewharp,andrewharp",2017-06-02 21:11:04,2017-06-03 04:26:09
PR,Branch 157903115,Pushing internal commits,,"andrewharp,andrewharp,andrewharp,andrewharp,yifeif",2017-06-03 04:01:35,2017-06-03 07:46:00
PR,Expose canned estimators in core,I know this is still WIP but it would be good to expose this for adventurous external users,,"terrytangyuan,martinwicke,terrytangyuan",2017-06-03 17:42:48,2017-06-04 00:11:25
PR,Fixed typo in code,,,"lakshayg,caisq",2017-06-04 07:24:00,2017-06-05 13:18:50
PR,group generated functions for registered ops into separate files configurable,wrappers go is currently 15k LOC The lack of organization code generated from TF GetAllOpList is stored in a single file makes it difficult to grok which functions exist and can work together Also there doesn t appear to be any tests for the funcs in wrappers go This PR is a proof of concept that maps groups of functions to smaller wrapper files Funcs are mapped using the wrap opslist json config file Here is an example of the mapping The result of the work in this PR files are organized into individual files under the op pkg There is still a large amount of source in wrappers go but more mappings can be done I m certainly willing to change how functions are grouped and make this more configurable e g add a func level mapping I wanted to see what you thoughts are Does this PR moving things in the right direction If so do you have any suggestions for how to organize functions or know someone with whom we should talk to about organizing TF wrapper funcs If not could you kindly provide direction as to how to make the go functions that wrap the tensorflow operations to be more approachable,,"ctava,asimshankar,ctava",2017-06-05 00:18:10,2017-06-05 13:51:22
PR,Branch 158034419,,,"caisq,caisq,caisq",2017-06-05 18:18:37,2017-06-05 20:54:18
PR,Branch 158053084,,,"av8ramit,av8ramit",2017-06-05 20:48:37,2017-06-06 00:04:36
PR,Cherrypicks for 1 1 0 rc2,,,av8ramit,2017-06-06 00:56:51,2017-06-06 02:05:32
PR,Updating tag to 1 2 0 rc2,,,av8ramit,2017-06-06 02:09:19,2017-06-06 02:34:52
PR,Fix misspells on comments,,,chris-chris,2017-06-06 10:16:43,2017-06-06 13:37:42
PR,configure Fix default path when enabling MPI,A minor fixup Correct showing what the default path is when mpi is installed,,"darrengarvey,caisq,darrengarvey",2017-06-03 15:15:38,2017-06-06 16:18:04
PR,Fix linking errors of lmdb on Windows,The error was introduced in,,"meteorcloudy,meteorcloudy,meteorcloudy,gunan",2017-06-06 12:02:09,2017-06-06 16:55:02
PR,Fix patching issue on Windows,Fix the issue in,,"meteorcloudy,gunan,meteorcloudy",2017-06-06 09:32:15,2017-06-06 17:09:02
PR,Fix test failures on windows,,,"gunan,meteorcloudy",2017-06-06 17:09:25,2017-06-06 18:33:36
PR,BasicRNNCell comment fix,,,jhseu,2017-06-06 16:40:32,2017-06-06 20:37:38
PR,Revert Fix patching issue on Windows,Reverts tensorflow tensorflow 10452 Breaks windows bazel build,,"gunan,gunan,gunan",2017-06-06 20:45:01,2017-06-06 21:58:28
PR,Severin configure without user interaction,configure step without user interaction using defaults and additional build target,,,2017-06-06 22:32:57,2017-06-06 22:33:36
PR,Revert Map Staging Area 9686,This reverts commit 1705b099df0fd7c2ea4abf83cfee896febeb8309,,"jhseu,jhseu,jhseu,jhseu",2017-06-06 21:28:42,2017-06-06 22:46:28
PR,OpenCL Improves device reporting,Prints id type name vendor and profile of the device,,"lukeiwanski,benoitsteiner",2017-06-06 14:53:16,2017-06-06 23:43:15
PR,Fix defect shuffle batch gives ZeroDivisionError when computing capacity stat,bug fix for 1853,,"jhseu,jhseu",2017-06-05 00:36:25,2017-06-06 23:55:55
PR,Fix unaligned args in api docs python tf contrib learn Evaluable,This commit fixes unaligned args in api docs python tf contrib learn Evaluable by removing the extra line in arg metrics This fix fixes 9313 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu",2017-06-03 22:40:20,2017-06-06 23:56:19
PR,Fix unbatch for Datasets with multiple elements,The current implementation of Dataset unbatch gives an error for datasets with multiple data elements e g Ideally we would expect data0 to be equivalent to data2 But data0 will produce scalars and data2 will produce elements with shape 1 I do not think there is any way around this because there is no way within the map function to tell if the function was called with a single element as input or a list with length one Both will just appear as a single argument to the map function So a more thorough fix might require changing how Dataset map works but in the meantime this behaviour seemed the best option might be able to comment on whether that larger change would be worthwhile or if he sees a better fix for this issue,,"drasmuss,mrry,mrry,jhseu",2017-06-02 17:11:33,2017-06-06 23:56:31
PR,Support for dtype keyword in tf layers,This pull request introduces the dtype keyword in functional interfaces for core layers to solve 9898 All the unit tests seem to run fine on my machine after incorporating the changes The default value has been kept as tf float32 in order to ensure compatibility,,"lakshayg,fchollet,jhseu",2017-06-05 18:28:22,2017-06-07 00:00:58
PR,Export C API symbols in pywrap tensorflow internal so,This PR exports C API symbols so that python extension libraries can use the C API As noted in 7541 there is currently a conflict between pywrap tensorflow internal so and libtensorflow so This conflict prevents use of the tensorflow C API and the python API in the same process This PR attempts to implement a workaround suggested by by exporting the C API symbols in the python library so that the Python and C APIs are both available from the single pywrap tensorflow internal so,,"fritzo,jhseu,jhseu,fritzo,fritzo,fritzo,jhseu,jhseu,fritzo",2017-06-06 17:03:05,2017-06-07 00:16:41
PR,Update configure script sample,The configure script was changed regularly since the generation of the sample This PR updates the sample to reflect those changes,,"Androbin,jhseu,jhseu",2017-06-06 10:48:39,2017-06-07 01:01:15
PR,Fix CMD in Dockerfile,Currently Notebook fails execution because default user for this container is root and unless explicitly allowed jupyter notebook will not start,,"vincentvanhoucke,vincentvanhoucke,jhseu,jhseu",2017-06-05 23:00:32,2017-06-07 02:57:08
PR,Branch 158212897,,,"jhseu,gunan,jhseu",2017-06-07 03:40:44,2017-06-07 17:00:10
PR,Branch 158278922,,,jhseu,2017-06-07 17:10:46,2017-06-07 17:42:19
PR,Branch 158282834,,,jhseu,2017-06-07 17:42:09,2017-06-07 18:29:08
PR,Support channel groups in convolutional layers,This PR implements the channel groups in convolutional layers Conv1D Conv2D Conv3D Conv2DTransposed The grouped convolution was firstly implemented in AlexNet as a way to share filter parameters across feature maps A detailed discussion on this feature can be found on here This feature is supported by Caffe doc and used in its reference caffenet L128 Adding this feature to TensorFlow makes it easier to compare models on two different frameworks and migrate from Caffe to TensorFlow,,"bowang,jhseu,fchollet,jhseu,bowang,bowang,fchollet,bowang,bowang",2017-06-07 05:56:48,2017-06-07 18:32:02
PR,Open up visibility of tf imports,This is a very simple change that unblocks our friend Hasty merge appreciated This change was previously done in but got undone by mistake,,"jart,jhseu,jhseu",2017-06-07 19:12:57,2017-06-07 19:56:17
PR,Recognize CPU core count in FreeBSD,At the moment FreeBSD can not recognize the CPU count however FreeBSD uses the same method as OS X does so provided PR fixes that If this could be included in the 1 2 0 release that would be great,,"blodan,jhseu,gunan",2017-06-07 12:24:44,2017-06-07 22:01:15
PR,A few changes to kernel tests,meteorcloudy FYI,,"gunan,gunan,jhseu,gunan",2017-06-07 21:27:11,2017-06-08 00:09:59
PR,Fix numpy 1 13 incompatibilities,Fixes the CPU build,,jhseu,2017-06-07 21:08:50,2017-06-08 00:21:44
PR,Printdhruv deep cnn md,Typo,,jhseu,2017-06-08 00:06:09,2017-06-08 01:57:41
PR,Disable stage op test and map stage op test due to timeouts,For example Also reverted the size to medium since switching to large did not fix the issue,,jhseu,2017-06-08 01:49:22,2017-06-08 05:20:44
PR,Delete non deterministic testEmpty test,Causing flaky Windows cmake tests because np empty may return a singular matrix,,"jhseu,jhseu,gunan,gunan",2017-06-08 00:06:14,2017-06-08 06:29:40
PR,Bash Prefer p q over p a q,As proposed by static analysis tool,,"Androbin,jhseu,gunan,gunan",2017-06-07 22:11:23,2017-06-08 06:30:45
PR,Bash Prefer read a to split path,As proposed by static analysis tool,,"Androbin,jhseu,gunan",2017-06-07 22:22:09,2017-06-08 06:32:49
PR,Bash Simplify Conditional,,,"Androbin,jhseu,gunan",2017-06-07 21:42:25,2017-06-08 06:42:02
PR,Windows Make TensorFlow build without cpu x64 windows msvc,Since from Bazel 0 5 0 MSVC toolchain became the default toolchain on Windows So cpu x64 windows msvc is not required as long as we adjust the BUILD files in TensorFlow cpu x64 windows msvc is also supported for now but should be depracated The configuration for cpu value x64 windows msvc is a duplicate of x64 windows which should be removed in the future,,"meteorcloudy,gunan,meteorcloudy,gunan,jhseu,jhseu,gunan,gunan",2017-06-06 16:17:00,2017-06-08 06:43:22
PR,Fix AttributeError in resnet py,There is no function tf softmax in Tensorflow 1 x When running the old code Python interpreter complains File resnet py line 152 in res net model prediction loss res net x y File resnet py line 148 in res net return tf softmax logits loss AttributeError 'module' object has no attribute isoftmax',,jhseu,2017-06-06 16:02:06,2017-06-08 16:05:35
PR,Merging rc2 back into master,,,"av8ramit,gunan",2017-06-07 18:01:07,2017-06-08 16:09:45
PR,Bash Remove unquoting quotes,As proposed by static analysis tool,,"Androbin,jhseu,gunan,gunan",2017-06-07 22:06:50,2017-06-08 16:50:23
PR,Bash Declare and assign separately,As proposed by static analysis tool,,"Androbin,jhseu,gunan,gunan,gunan",2017-06-07 22:37:57,2017-06-08 16:50:38
PR,Bash read with r to not mangle backslashes,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:47:41,2017-06-08 16:53:24
PR,Bash Move multiple parameters out of shebang,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:52:53,2017-06-08 16:53:32
PR,Bash Use instead of legacy,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:46:11,2017-06-08 16:53:42
PR,Bash Use instead of legacy,As proposed by static analysis tool,,"Androbin,gunan,gunan",2017-06-08 16:43:30,2017-06-08 16:53:57
PR,Bash Use instead of legacy,As proposed by static analysis tool,,"Androbin,gunan,jhseu",2017-06-08 16:40:41,2017-06-08 16:54:07
PR,Bash Use cd exit in case cd fails,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:38:02,2017-06-08 16:54:16
PR,Bash Moving multiple parameters out of shebang,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:34:43,2017-06-08 16:54:32
PR,Bash Use cd exit in case cd fails,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:20:10,2017-06-08 16:55:44
PR,Bash Instead of 'echo cmd ' just use 'cmd',As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:11:22,2017-06-08 16:55:57
PR,Bash A B C is not if then else,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:08:39,2017-06-08 16:56:07
PR,Bash Put 2 1 behind the redirect,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:05:16,2017-06-08 16:56:25
PR,Bash Prefer variable search replace over sed,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 16:01:56,2017-06-08 16:56:38
PR,Bash Use instead of legacy,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:57:31,2017-06-08 16:56:47
PR,Bash Use instead of to concatenate,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:54:40,2017-06-08 16:57:05
PR,Bash Remove unnecessary,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:47:44,2017-06-08 16:57:15
PR,Bash A B C is not if then else,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:44:46,2017-06-08 16:57:25
PR,Bash Instead of echo cmd just use cmd,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:38:58,2017-06-08 16:57:39
PR,Bash Prefer read a to split exit codes,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:17:19,2017-06-08 16:57:49
PR,Bash Prefer grep E over deprecated egrep,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:11:52,2017-06-08 16:57:58
PR,Bash Use grep q instead of n,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 15:00:35,2017-06-08 16:58:29
PR,Bash read with r to not mangle backslashes,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:52:11,2017-06-08 16:58:37
PR,Bash Removed unnecessary,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:47:26,2017-06-08 16:58:47
PR,Bash Put 2 1 behind the redirect,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:42:25,2017-06-08 16:58:55
PR,Bash Instead of echo cmd just use cmd,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:35:31,2017-06-08 16:59:49
PR,Bash Fix bad string array concat behaviour,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:24:03,2017-06-08 16:59:59
PR,Bash Variable used as array not string,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 14:18:11,2017-06-08 17:00:08
PR,Re enable some python tests in Windows Bazel build,These tests are passing on Windows and not flaky,,"meteorcloudy,meteorcloudy",2017-06-08 11:36:20,2017-06-08 17:01:53
PR,Bash Fix misspellings of architecture,,,"Androbin,jhseu,gunan",2017-06-08 16:26:49,2017-06-08 17:10:41
PR,Bash Group commands to redirect,As proposed by static analysis tool,,"Androbin,jhseu",2017-06-08 10:34:51,2017-06-08 17:10:51
PR,Bash read with r to not mangle backslashes,As proposed by static analysis tool,,"Androbin,jhseu,gunan",2017-06-07 21:46:14,2017-06-08 17:10:55
PR,Bash Fix misspelling ERRORS FLIE ERRORS FILE,,,"Androbin,jhseu",2017-06-08 14:38:11,2017-06-08 17:10:59
PR,Bash Use instead of legacy,As proposed by static analysis tool,,"Androbin,jhseu,gunan,jhseu",2017-06-07 22:01:11,2017-06-08 17:11:00
PR,Try both python and python3,Used configure script for reference,,"Androbin,aselle,Androbin",2017-06-08 10:47:59,2017-06-08 17:11:01
PR,Fix AttributeError in resnet py,There is no function tf softmax in Tensorflow 1 x When running the old code Python interpreter complains File resnet py line 152 in res net model prediction loss res net x y File resnet py line 148 in res net return tf softmax logits loss AttributeError 'module' object has no attribute isoftmax',,caisq,2017-06-08 16:36:52,2017-06-08 18:03:40
PR,Branch 158391996,,,"jhseu,jhseu",2017-06-08 17:34:19,2017-06-08 19:33:48
PR,Fix typos,,,"taehoonlee,gunan,Androbin",2017-06-08 13:19:56,2017-06-08 19:54:35
PR,Testing 1 2 branch,,,av8ramit,2017-06-08 20:57:12,2017-06-08 22:03:25
PR,Implemented sinh and cosh,These commits contains the implementation of the sinh and cosh functions for CPU and GPU with gradients This solves 7531 partially The supported datatypes are float double complex64 and complex128 Compilation went through successfully on my system CPU only and the following test script seems to be running fine on Python 2 7,,"lakshayg,rmlarsen,rmlarsen,lakshayg,rmlarsen,rmlarsen,rmlarsen,lakshayg,rmlarsen,lakshayg,rmlarsen,rmlarsen",2017-06-04 11:30:50,2017-06-09 03:16:08
PR,fixed minor formatting issues for tfprof docs,fixes some minor issues headings displayed correctly timeline visualization is now shown correctly,,jhseu,2017-06-08 13:42:05,2017-06-09 15:52:17
PR,R1 1,,,jhseu,2017-06-09 09:47:22,2017-06-09 15:52:50
PR,Testing branch 1 2,,,"av8ramit,av8ramit",2017-06-08 22:06:16,2017-06-09 16:23:41
PR,Fixing the broken 1 2 branch tests,,,av8ramit,2017-06-09 16:24:21,2017-06-09 17:02:42
PR,Remove RewriterConfig from the Python API,RewriterConfig has not made it into a release and so is not subject to semantic versioning The API needs a bit of work so it is not going into 1 2 In order to minimize disruption to non Google users some using tf RewriterConfig from master and hold up the 1 2 release as little as possible the plan is to only remove RewriterConfig from the 1 2 release but leave it in master We will then develop a more permanent way to configure Grappler graph rewriting,,"allenlavoie,benoitsteiner,av8ramit,gunan,gunan,av8ramit",2017-06-07 23:12:16,2017-06-09 18:00:24
PR,Revert the new non max suppression v2 op for the 1 2 release so we can do API review,,,"jhseu,jhseu,jhseu,jhseu",2017-06-09 18:25:01,2017-06-09 20:59:15
PR,Merge pull request 1 from tensorflow master,from origin,,,2017-06-11 06:16:49,2017-06-11 06:17:43
PR,fix javadoc issues,,,"caisq,caisq",2017-06-11 08:57:53,2017-06-11 16:59:45
PR,Fix typos,,,"taehoonlee,caisq,caisq,caisq",2017-06-11 05:24:30,2017-06-11 18:04:42
PR,Change np array to tf constant,np array fails with no 'module' get shape,,caisq,2017-06-11 02:54:24,2017-06-11 18:09:39
PR,fix typos,some spelling mistakes,,,2017-06-11 17:12:01,2017-06-11 18:12:54
PR,Use correct sort of dtype,This completes 10623,,Androbin,2017-06-11 23:06:43,2017-06-12 01:31:07
PR,Add link that helps explain feed dict parameter,The current tutorial mentions using feed dict parameter but there is not further mention The example code does not explain where feed dict is used By linking to the run documentation the reader can see it is the second parameter to the run command,,"caisq,caisq,caisq",2017-06-11 17:30:01,2017-06-12 13:21:22
PR,Skip configure bazel version check on empty version string,Fix 10587,,"yifeif,gunan,yifeif",2017-06-09 22:35:41,2017-06-12 17:04:32
PR,Remove deprecated functions,Remove deprecated classes and functions marked for removal until May 2017 This PR does not touch deprecated parameters nor deprecations for June 15,,"Androbin,martinwicke",2017-06-09 12:16:49,2017-06-12 18:23:02
IS,TF BINARY URL,Would be so grateful for some guidance Please advise on the appropriate TF BINARY URL for compiling Tensor Flow on an Odroid XU4 which uses a Samsung Exynos5422 Cortex A15 2Ghz and Cortex A7 Octa core CPUs and a Mali T628 MP6 OpenGL ES 3 1 2 0 1 1 and OpenCL 1 2 Full profile Please advise on the TF BINARY URL to use for Ubuntu Linux 64 bit CPU only Python 2 7 Ubuntu Linux 64 bit CPU only Python 3 5 Is there a GPU version that supports the Mali T628 MP6 OpenGL ES 3 1 2 0 1 1 and OpenCL 1 2 Full profile on the Odroid XU4 Thank you,,"aselle,aselle,aselle",2017-06-12 22:10:02,2017-06-12 22:30:25
IS,Forcing symmetric quantization,,,aselle,2017-06-13 03:13:46,2017-06-13 08:26:18
IS,Get strange results by running sparse tensor dense matmul op test py,When I run sparse tensor dense matmul op test py with large n m k I get,,aselle,2017-06-13 07:33:32,2017-06-13 08:38:19
IS,Build with Bazel on Windows missing input file ' local config cuda cuda cuda extras,System information Have I written custom code No OS Platform Windows 10 TensorFlow installed from source TensorFlow version v1 2 0 rc2 Bazel version git master CUDA cuDNN version 8 0 5 1 GPU model Nvidia GTX 1080 Exact command to reproduce bazel build c opt config win cuda cpu x64 windows msvc host cpu x64 windows msvc copt w host copt w tensorflow tools pip package build pip package Describe the problem I try to compile TensorFlow on Windows with Bazel without GPU support at first But i run into a error see down below Does anyone have a idea how i can fix this or what the problem is Error log,,,2017-06-13 14:03:05,2017-06-13 14:05:29
PR,Apply correct filter tags to two tests,session clusterspec prop test session list devices test Should fix ongoing breakage in nightly GPU builds,,"caisq,caisq,caisq",2017-06-13 15:06:15,2017-06-13 15:54:28
PR,Branch 158779483,Complex merge in FFT ops Estimator tests LMDB reader,,"martinwicke,rryan,martinwicke,rryan,martinwicke,martinwicke,martinwicke,martinwicke,caisq",2017-06-13 05:16:04,2017-06-13 16:07:05
PR,Fix incorrect references of tf learn tf contrib learn,This fix fixes the incorrect references in docs linear md where tf learn was used should be tf contrib learn This fix fixes 8718 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke",2017-06-12 19:17:00,2017-06-13 16:46:21
IS,Linux CPU smoke tests failing due to merged API change,This commit appears to break the Linux CPU tests at least for me It seems that when the smoke tests passed for this commit the Linux CPU tests did not include the api compatibility test but now they do However the golden API and the real API have already diverged so there is not any possibility of successful passing any more,,"DavidNorman,aselle,gunan",2017-06-13 09:20:09,2017-06-13 18:01:18
PR,Note that the cuDNN version must match exactly on Windows,Fixes 10594,,"girving,girving,girving",2017-06-12 16:02:11,2017-06-13 19:34:37
IS,DSP process time investigation,Hello I am evaluating the DSP process time by the bellows source code And The result was short process time As one factor I think that the reason is quantization to input data of DSP Could you please tell me a change procedure for quantization And Could I please have the pb file NOT quantizate before the bellows quantization pb file tensorflow inception v3 stripped optimized quantized pb I want to compare between DSP process time quantizate input data and CPU process time NOT quantizate input data,,aselle,2017-06-13 11:29:45,2017-06-13 20:11:22
PR,R1 1,,,"caisq,martinwicke",2017-06-11 03:19:07,2017-06-13 20:14:31
PR,Cherrypicks,Tensorboard cherrypicks while reverting tensorboard to previous hash Please review properly Doc and release file updates,,"av8ramit,av8ramit,gunan",2017-06-13 20:59:11,2017-06-13 23:20:32
PR,Updating the version from 1 2 0rc2 to 1 2 0,,,"av8ramit,av8ramit",2017-06-13 21:13:45,2017-06-13 23:42:24
PR,Various Bash Improvements,Sorry about the previous spamming I did not expect it to sum up that quickly,,"Androbin,gunan,Androbin,Androbin,jhseu,jhseu,jhseu,gunan,jhseu",2017-06-08 17:52:02,2017-06-13 23:55:52
PR,Fix defect shuffle batch gives ZeroDivisionError when computing capacity stat,Fixes 1853,,"mrry,mrry",2017-06-07 01:09:42,2017-06-13 23:58:22
PR,Solution to non context words due to wrap around,Due to wrap around non context words also appear in the window for skip gram which degrades the quality for word vectors Simple patch to avoid appearance of non context words,,"girving,girving,girving,girving,girving,girving,jhseu,girving,girving,girving,girving",2017-06-03 09:50:40,2017-06-13 23:59:31
PR,Fix minor typos in lookup ops code samples,,,"guillaumekln,martinwicke",2017-06-13 09:00:14,2017-06-14 01:46:03
PR,Fix typos,This PR fixes some typos the the Classs classs currrently and apppropriate,,"taehoonlee,martinwicke",2017-06-13 04:33:20,2017-06-14 01:47:08
PR,Minor fix typo,minor fix typo in tf contrib learn,,"ScorpioCPH,martinwicke",2017-06-09 07:55:39,2017-06-14 01:48:16
PR,Fix typo as far as is in doc,The word is looks unnecessary in these sentences,,martinwicke,2017-06-11 03:07:05,2017-06-14 01:49:57
PR,tensorflow go simplify 'range' on ishape',Found via 'gofmt',,jhseu,2017-06-10 06:11:28,2017-06-14 01:50:39
PR,CONTRIBUTING md include basic Docker CI command,This quick one liner CI test via Docker should be enough so many users do not even have to follow the more details link,,"ahundt,gunan,martinwicke",2017-06-09 20:33:53,2017-06-14 01:52:25
PR,Fixes python doc for tanh Resolves 10376,,,"lakshayg,martinwicke",2017-06-09 16:20:48,2017-06-14 02:02:40
PR,Fix typo in bazel command,,,"Androbin,martinwicke",2017-06-08 21:45:49,2017-06-14 02:03:35
PR,Remove an unused typedef,,,martinwicke,2017-06-08 17:46:58,2017-06-14 03:23:40
PR,Branch 158919724,,,"yifeif,yifeif,martinwicke,martinwicke",2017-06-14 02:59:22,2017-06-14 03:55:59
PR,Partly revert 10533,,,"Androbin,martinwicke",2017-06-08 20:23:12,2017-06-14 03:58:23
PR,Added store intermediate graph feature,,,"petewarden,martinwicke",2017-06-03 07:46:00,2017-06-14 03:59:53
PR,Fix the f16 implementation of Literal and LiteralUtil,Adjust the implementation of Literal to do the right thing for F16 The new Literal class is nice in that it is just a std vector of half types which is nice and simple The Proto version still has to have a bit of munging around due to protobuf limitations,,"DavidNorman,hawkinsp,hawkinsp",2017-06-13 22:34:35,2017-06-14 04:04:34
PR,Added uint8 registration for addition operation Fixes 10447,,,"lakshayg,martinwicke,lakshayg,martinwicke,lakshayg,martinwicke",2017-06-09 06:34:57,2017-06-14 07:08:31
IS,Cannot build tensorflow at all,OS X building on a branch not master After pulling the repo this morning previous pull 12 hours ago I can no longer build at all ERROR Users davidn workspace tensorflowview tensorflow tensorflow core BUILD 1394 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by Users davidn workspace tensorflowview tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted,,"DavidNorman,DavidNorman",2017-06-14 09:47:29,2017-06-14 10:00:03
IS,seq2seq dynamic rnn decoder not working for multilayered encoder in TF 1 0,I am trying to implement Multilayer Bidirectional Attention based seq2seq in TF 1 0 using tf contrib seq2seq library This is my implementation It works perfectly fine for single layered encoder and decoder but gives error with multi layer Error ValueError Shape must be rank 2 but is rank 4 for 'Decoder dynamic rnn decoder Decoder attention decoder concat' op 'ConcatV2' with input shapes 10 2 2 20 The problem is when running single layer the encoder just returns LSTM state tuple for 1 layer but in multi layer it returns an array of LSTMStateTuple i e one for each layer which is fed into the decoder and creating problem I guess So is not seq2seq dynamic rnn decoder made to work MultiRNNCell i e multilayered decoder Encoder part is running perfectly fine for multi layers and returning encoder states for each layer If u want to run my implementation 1 clone repo 2 switch to tf 1 0 env 3 python generate questions py This will just create computation graph In case of num layer 1 graph is created is successfully but fails with num layer 1,,,2017-06-12 19:47:20,2017-06-14 14:12:36
PR,Improve docs for parallel stack,For 10036,,"Androbin,ahundt,ahundt,martinwicke,martinwicke,martinwicke,Androbin,Androbin",2017-06-09 10:50:20,2017-06-14 14:31:51
IS,NotFoundError see above for traceback Key conv13 weights not found in checkpoin,Caused by op u isave RestoreV2 4' defined at File test go py line 140 in module tf app run File usr local lib python2 7 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File test go py line 137 in main evaluate File test go py line 119 in evaluate saver tf train Saver File usr local lib python2 7 dist packages tensorflow python training saver py line 1139 in init self build File usr local lib python2 7 dist packages tensorflow python training saver py line 1170 in build restore sequentially self restore sequentially File usr local lib python2 7 dist packages tensorflow python training saver py line 691 in build restore sequentially reshape File usr local lib python2 7 dist packages tensorflow python training saver py line 407 in AddRestoreOps tensors self restore op filename tensor saveable preferred shard File usr local lib python2 7 dist packages tensorflow python training saver py line 247 in restore op spec tensor dtype 0 File usr local lib python2 7 dist packages tensorflow python ops gen io ops py line 680 in restore v2 dtypes dtypes name name File usr local lib python2 7 dist packages tensorflow python framework op def library py line 767 in apply op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 2336 in create op original op self default original op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 1228 in init self traceback extract stack NotFoundError see above for traceback Key conv13 weights not found in checkpoint Node save RestoreV2 4 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 4 tensor names save RestoreV2 4 shape and slices,,"aselle,aselle",2017-06-14 09:22:12,2017-06-14 16:02:55
IS,import Tensorflow not working,I get following error when installing under anaconda python 2 7 environment,,"aselle,aselle",2017-06-14 10:19:47,2017-06-14 16:04:55
IS,how can combining cnn with convlutional lstm,Hi i want to process a image in cnn convolutinal lstm in the connection point between to network shape None 100 100 64 for cnn the should insert to convolution lstm network but not match output cnn with input convlutinal lstm is any example for this combination,,aselle,2017-06-14 12:48:29,2017-06-14 16:07:20
IS,Ignoring visible gpu device,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux with linux kernel version 4 11 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 rc2 Bazel version if compiling from source 0 5 0 1 CUDA cuDNN version 8 0 61 2 6 0 21 1 GPU model and memory Quadro M1200 32Gig of RAM Exact command to reproduce running sess tf session inside the python interactive shell Describe the problem I have followed the official document to install from source The build process and the install process shows no issues but when I run the command But when I visit the nvidia website it says that the Quadro M1200 have Compute Capability 5 2,,"aselle,aselle,aselle",2017-06-12 17:17:08,2017-06-14 16:32:57
IS,Feature Request can tfdbg support printing or writing into file the whole complete tensor,Describe the problem I used tensorflow is new debugger named tfdbg to debug tensorflow is application which I need to see some intermediate tensors but for example I tried to debug wide n deep tutorial py when I type command like print tensor linear linear native country native country weights embedding lookup sparse 0 it gives me following lines,,"aselle,caisq,caisq,caisq",2017-06-14 14:53:05,2017-06-14 16:43:35
PR,Avoid upgrading tensorFlow dependencies when running windows tests,,,gunan,2017-06-14 18:06:00,2017-06-14 18:28:46
PR,Avoid upgrading tensorFlow dependencies when running windows tests,10709,,av8ramit,2017-06-14 18:31:08,2017-06-14 19:02:07
PR,Improve docs for parallel stack,Partly solves 10036 Moves 10593 to master,,"Androbin,girving",2017-06-14 14:31:30,2017-06-14 21:38:23
PR,Merge pull request 1 from tensorflow master,Updated on 2017 6 14,,"byronyi,martinwicke",2017-06-14 13:43:37,2017-06-14 21:40:07
PR,Update quantization docs to new tool,,,Androbin,2017-06-09 10:33:01,2017-06-14 21:57:35
PR,Fix incorrect documentation in SliceHelper 10494,Fixes 10494,,"Androbin,martinwicke,Androbin,martinwicke",2017-06-09 10:22:41,2017-06-14 21:59:22
PR,Make stage tests less sensitive to timeouts,Previously staging tests used the number of failed token dequeues with 50 ms timeouts on a signalling queue to indicate blocked puts This was probably too sensitive on highly contended testing systems Basically there is no good way to distinguish between a put that took too long and a blocking put Staging tests now simply count the number of iterations before a timeout of 1s occurs on the signalling queue This should mean that 1 The test case is less brittle around what is considered a block vs the putting thread not being able to keep up 2 Both stage op test and map stage op test take slightly longer 2 5s vs 1s to run on an uncontended system Also simplified the tests cases in general cc I saw 10516 and the duration of test runs 30s on your test systems vs 1s on my laptop made me reconsider the duration on the blocking timeout I have upped it 20X from 50ms to 1s In an ideal world the test cases would not depend on a timeout when running if you can suggest a different method of testing blocking puts and gets please let me know I also relooked at the multi threaded code in the StagingArea but I think the standard producer consumer queue has been implemented correctly I hope this helps,,"sjperkins,ekelsen,ekelsen,ekelsen,sjperkins,gunan,sjperkins,ekelsen,sjperkins,martinwicke,martinwicke,sjperkins,jhseu,jhseu,sjperkins,gunan",2017-06-08 12:33:23,2017-06-14 22:01:16
PR,Try both python and python3,Used configure script for reference Reopens mistakenly closed 10525,,"Androbin,martinwicke,Androbin,martinwicke,martinwicke",2017-06-14 13:27:19,2017-06-14 22:18:44
IS,MemoryError when freezing large model,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 rc2 Bazel version if compiling from source 0 5 1 CUDA cuDNN version CUDA8 CuDNN6 GPU model and memory Tesla K80 11439MiB Exact command to reproduce,,"aselle,aselle,petewarden,aselle",2017-06-12 23:33:45,2017-06-15 02:36:49
PR,Add jni methods to support creating string Tensors from string bytes,Here are native methods to support creating string Tensors by string bytes The implement of Tensor class and test will be soon available,,asimshankar,2017-06-13 12:30:10,2017-06-15 02:37:30
PR,To fix link error when building tensorflow cc tutorials example trainer,The local environment is centos release 6 8 Final gcc 4 9 2 bazel 0 5 0 Error detail opt rh devtoolset 3 root usr bin ld bazel out local linux opt bin tensorflow cc objs tutorials example trainer tensorflow cc tutorials example trainer o undefined reference to symbol 'clock gettime GLIBC 2 2 5',,martinwicke,2017-06-15 02:32:05,2017-06-15 15:18:50
IS,in the test dataset the use of different batch size will get different results why,When I used kears and tensorflow training after the checkpoint after stopping the process when I was found in the test the use of different batch size will get different results The When batch size 1 when the error rate is high but when the batch size 128 the error rate is not so high The The The Why is this The So what about my online service,,aselle,2017-06-15 08:51:08,2017-06-15 16:49:14
PR,Merge pull request 1 from tensorflow master,update,,byronyi,2017-06-15 07:33:00,2017-06-15 17:34:44
IS,The current makefile builds incomplete Tensorflow,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux TensorFlow installed from source or binary source TensorFlow version use command below 1 1 Bazel version if compiling from source not using bazel CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I have managed to cross compile using the Makefile approach but the API is are incomplete I think it is because not all source files are included in the Makefile and the text files Can someone provides a Makefile that is equivalent to bazel build tensorflow libtensorflow cc so I want to cross compile a library and use that on my custom platform Source code logs,,gunan,2017-06-15 20:33:29,2017-06-15 20:35:54
IS,Public head of master is failing windows CMAKE tests,The following tests are failing for several of the public pull requests I suggest that the current head of master would also fail in the same way,,"DavidNorman,DavidNorman,aselle,yifeif",2017-06-13 09:39:55,2017-06-15 20:36:05
IS,Redundant Computation of tf cond,System information Runs all right Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Linux Ubuntu 14 04 01 TensorFlow installed from pip TensorFlow version use command below 'v1 0 0 65 g4763edf dirty' '1 0 1 CUDA cuDNN version CUDA8 0 cuDNN5 1 GPU model and memory GTX1060 6GB Describe the problem tf cond pred fn1 fn2 have redundant computation when fn1 and fn2 have dependencies on other tensors See the example code you will know Source code logs,,aselle,2017-06-15 09:37:52,2017-06-15 21:32:27
IS,freeze graph problem,When I use freeze graph the input checkpoint model ckpt 8361242 the data is V1 version But I use the tensorflow v1 1 the data save as model ckpt 569500 data 00000 of 00001 model ckpt 569500 index model ckpt 569500 meta How can I deal with,,"aselle,concretevitamin",2017-06-15 03:27:26,2017-06-15 21:38:07
PR,Merging r1 2 back into master,A bit confused with some of the resolutions on non max suppression op cc,,"av8ramit,av8ramit",2017-06-16 01:44:50,2017-06-16 01:46:01
IS,Timeline incorrectly show most ops on gpu 0,Timeline show most ops on gpu 0 which disagree with nvidia smi and device placement log TF version v1 2 0 rc0 735 gf48673b less than two weeks ago Attachments remove txt suffix chrome tracing pdf trace json txt jupyter log txt run metadata pb txt,,gaohuazuo,2017-06-15 13:06:52,2017-06-16 10:39:03
PR,OpenCL Fixes grpc test failure for SYCL devices 87,The test constructs a graph containing an IdentityOp on strings which does not exist on CUDA and SYCL devices The test expects to fail for CUDA devices so add the same expectation for SYCL devices,,"lukeiwanski,gunan,caisq,caisq,caisq,jwlawson,lukeiwanski",2017-06-14 12:50:03,2017-06-16 11:07:06
PR,OpenCL Fixes device name comparison stage op test 85,Changes the fixed ' device GPU 0' expected device name string to the name returned by 'test gpu device name ' as the device name could be ' device SYCL 0' or ' device GPU 0',,"lukeiwanski,lukeiwanski,jwlawson,benoitsteiner,lukeiwanski,gunan,jwlawson,lukeiwanski",2017-06-13 14:58:13,2017-06-16 11:18:25
PR,OpenCL Fixes grpc test failure for SYCL devices,The test constructs a graph containing an IdentityOp on strings which does not exist on CUDA and SYCL devices The test expects to fail for CUDA devices so add the same expectation for SYCL devices Resubmission of 10698,,"jwlawson,caisq",2017-06-16 10:54:13,2017-06-16 13:35:23
IS,bazel build error no such package ' protobuf ',Build from master 0d2f691 but encounter with the error of tensorflow tools pip package BUILD 94 1 no such package ' protobuf ' Traceback most recent call last They are operated in virtualenv with bazel 0 5 1 on a centos 7 3 1611 The package can be downloaded in a browser from the url I'm in China where it is difficult to access the google service I have no idea about whether the network is the problem Here is the terminal log of brach version configure and bazel build tf source huwh1 huwh1 centos tensorflow git branch v master 0d2f691 ahead 16 Create tf env collect sh tf source huwh1 huwh1 centos tensorflow configure You have bazel 0 5 1 installed Please specify the location of python Default is home huwh1 virtualenv tf source bin python Found possible Python library paths home huwh1 virtualenv tf source lib python2 7 site packages Please input the desired Python library path to use Default is home huwh1 virtualenv tf source lib python2 7 site packages Using python library path home huwh1 virtualenv tf source lib python2 7 site packages Do you wish to build TensorFlow with MKL support y N No MKL support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Do you wish to use jemalloc as the malloc implementation Y n jemalloc enabled Do you wish to build TensorFlow with Google Cloud Platform support y N No Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support y N No Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with the XLA just in time compiler experimental y N No XLA support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N No VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL support y N No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N y CUDA support will be enabled for TensorFlow Do you want to use clang as CUDA compiler y N nvcc will be used as CUDA compiler Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 8 0 Please specify the location where CUDA 8 0 toolkit is installed Refer to README md for more details Default is usr local cuda Please specify which gcc should be used by nvcc as the host compiler Default is usr bin gcc Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 5 Please specify the location where cuDNN 5 library is installed Refer to README md for more details Default is usr local cuda Please specify a list of comma separated Cuda compute capabilities you want to build with You can find the compute capability of your device at Please note that each additional compute capability significantly increases your build time and binary size Default is 3 5 5 2 3 0 Do you wish to build TensorFlow with MPI support y N MPI support will not be enabled for TensorFlow Configuration finished tf source huwh1 huwh1 centos tensorflow bazel clean INFO Starting clean this may take a while Consider using async if the clean takes more than several minutes tf source huwh1 huwh1 centos tensorflow bazel build config opt config cuda tensorflow tools pip package build pip package tee Loading package tensorflow tools pip package Loading package tools cpp Loading package tensorflow contrib specs Loading package Loading package third party eigen3 Downloading 87 161 bytes Downloading 311 205 bytes Downloading 1 475 383 bytes Downloading 1 957 187 bytes Downloading 4 274 206 bytes Downloading 2 138 182 bytes Downloading 1 875 852 bytes Downloading 4 264 858 bytes ERROR home huwh1 git tensorflow tensorflow tools pip package BUILD 94 1 no such package ' protobuf ' Traceback most recent call last File home huwh1 git tensorflow tensorflow workspace bzl line 122 apply patch repo ctx repo ctx attr patch file File home huwh1 git tensorflow tensorflow workspace bzl line 113 in apply patch execute and check ret code repo ctx cmd File home huwh1 git tensorflow tensorflow workspace bzl line 97 in execute and check ret code fail Non zero return code 1 when 2 more arguments Non zero return code 256 when executing 'patch p1 d home huwh1 cache bazel bazel huwh1 571d325cc1cf529816d64b96c622cea4 external protobuf i home huwh1 git tensorflow third party protobuf add noinlines patch' Stdout Stderr java io IOException Cannot run program patch in directory home huwh1 cache bazel bazel huwh1 571d325cc1cf529816d64b96c622cea4 external protobuf error 2 No such file or directory and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted Elapsed time 3 457s Here is the system information cat etc issue Linux huwh1 centos 3 10 0 514 21 1 el7 x86 64 1 SMP Thu May 25 17 04 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 7 Core VERSION ID 7 CENTOS MANTISBT PROJECT VERSION 7 REDHAT SUPPORT PRODUCT VERSION 7 are we in docker No compiler c GCC 4 8 5 20150623 Red Hat 4 8 5 11 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux huwh1 centos 3 10 0 514 21 1 el7 x86 64 1 SMP Thu May 25 17 04 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 0 protobuf 3 3 0 check for virtualenv True tensorflow import Traceback most recent call last File string line 1 in module File tensorflow init py line 24 in module from tensorflow python import File tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import ImportError No module named pywrap tensorflow internal Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help env LD LIBRARY PATH opt intel compilers and libraries 2017 4 196 linux compiler lib intel64 opt intel compilers and libraries 2017 4 196 linux compiler lib intel64 lin opt intel compilers and libraries 2017 4 196 linux tbb lib intel64 lin gcc4 7 opt intel compilers and libraries 2017 4 196 linux compiler lib intel64 lin opt intel compilers and libraries 2017 4 196 linux mkl lib intel64 lin usr local cuda 8 0 lib64 DYLD LIBRARY PATH is unset nvidia smi Thu Jun 15 10 28 42 2017 NVIDIA SMI 375 26 Driver Version 375 26 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Quadro K420 Off 0000 01 00 0 Off N A 25 44C P8 N A N A 9MiB 1998MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 6899 C home huwh1 virtualenv tf gpu bin python 7MiB cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7,,,2017-06-15 02:53:38,2017-06-16 15:58:21
IS,Embedding visualizer of tensorboard is a blank page,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below master c007ee2c1f8701effb410f632e9d8c4cd120f9c0 Bazel version if compiling from source 0 5 0 CUDA cuDNN version 8 0 44 7 0 GPU model and memory Titan X Pascal Exact command to reproduce tensorboard logdir path to model Describe the problem Similarily to this stackoverflow question I have completely blank page without any controls when I'm trying to use the tensorboard embedding visualizer from the latest master There is nothing in logs at least on default log level Tensorboard from 1 0 1 1 1 2 binaries is working,,"dandelionmane,dsmilkov,dsmilkov",2017-06-16 08:34:31,2017-06-16 18:20:47
IS,go bug in Shape size for dim NumDimensions,System information This does not matter Describe the problem go when dim equals s NumDimensions the function should return 1 instead it panics Source code logs In shape go L62 Shape Size method func s Shape Size dim int int64 if dim 0 dim s NumDimensions return 1 should be func s Shape Size dim int int64 if dim 0 dim s NumDimensions return 1,,aselle,2017-06-15 20:21:34,2017-06-16 18:21:30
PR,Fix shape go is Size function,Fixes 10741,,aselle,2017-06-15 21:56:43,2017-06-16 18:21:30
PR,Fix a bug in topk op cc,307df7080a8fe0538e05754170695b9925e2cea2 is causing failures in But when running the test locally I saw capture topk failure This change fixed them,,"meteorcloudy,meteorcloudy,ebrevdo",2017-06-16 12:22:41,2017-06-16 18:21:59
PR,Fix sanity status reporting,,,yifeif,2017-06-16 00:52:28,2017-06-16 18:22:48
PR,add support for android sdk version 18,Alternatively the trace calls could be removed completely or replaced by simple Log calls,,"Johnson145,andrewharp,Johnson145,martinwicke",2017-06-14 15:29:30,2017-06-16 18:23:20
PR,Upgrade to protobuf 3 3 1,Have not tested letting Jenkins try it out,,"jhseu,jhseu,martinwicke,jhseu,martinwicke,jhseu,jart,martinwicke,jhseu,jart,jhseu,martinwicke",2017-06-12 19:52:30,2017-06-16 18:28:40
IS,PIP Markdown version locked to 2 2 0,This markdown version lock could cause versioning conflict for downstream e g if requirements are compiled and resolved by pip compile Wondering If there is a reason to lock this version And it is already not sync with the CI install script those upgrade with locked version also does not seem right to me,,dandelionmane,2017-06-15 21:07:38,2017-06-16 18:52:21
IS,PIP Do not lock markdown version to 2 2 0,This markdown version lock could cause versioning conflict for downstream e g if requirements are compiled and resolved by pip compile Wondering If there is a reason to lock this version And it is already not sync with the CI install script those upgrade with locked version also does not seem right to me,,"dandelionmane,dandelionmane",2017-06-16 18:53:00,2017-06-16 18:54:41
PR,To fix link error,To fix link error when building tensorflow cc tutorials example trainer The local environment is centos release 6 8 Final gcc 4 9 2 bazel 0 5 0 Error detail opt rh devtoolset 3 root usr bin ld bazel out local linux opt bin tensorflow cc objs tutorials example trainer tensorflow cc tutorials example trainer o undefined reference to symbol 'clock gettime GLIBC 2 2 5',,"martinwicke,martinwicke,martinwicke,martinwicke",2017-06-15 02:45:42,2017-06-16 19:05:18
PR,Update docker rebuilding instructions,Fixes,,caisq,2017-06-16 19:01:40,2017-06-16 19:14:39
PR,Link to TensorBoard repo in ISSUES TEMPLATE md,Any new TensorBoard issues should be filed against the TensorBoard repository not on core TensorFlow,,"dandelionmane,martinwicke,dandelionmane",2017-06-16 19:03:12,2017-06-16 20:04:54
IS,Building Java Tensorflow for GPU from Source Does not Work as Described,First of all I will not address this in Stackoverflow This question belongs here I tried going to Stackflow but nobody responded I need to build tensorflow for Java from source with GPU support in Windows How can I do this successfully I need to build the JNI DLLs Please advise I get Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows TensorFlow installed from source or binary r1 2 TensorFlow version use command below r1 2 Bazel version if compiling from source 0 5 0 CUDA cuDNN version 8 0 5 1 GPU model and memory Nvidia Quadro K5200 Exact command to reproduce bazel build config opt tensorflow java tensorflow tensorflow java libtensorflow jni You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"aselle,asimshankar,aselle,aselle",2017-06-14 17:20:24,2017-06-16 20:13:37
PR,Add input interfaces required by the Java Ops API,Those interfaces are at the base of the upcoming Java Ops API please consult for more details,,"karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar",2017-06-14 12:20:24,2017-06-16 20:13:53
PR,fix iOS example README,fix iOS example README The iOS example got moved to a different directory This PR fixes that Test plan x test it by following the readme to set up the new project for iOS,,martinwicke,2017-06-09 05:10:06,2017-06-16 20:14:28
IS,Docker build issues libcuda so 1 cannot be found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I'm using baidu is warp ctc which has custom code OS Platform and Distribution e g Linux Ubuntu 16 04 N A using docker TensorFlow installed from source or binary provided docker image TensorFlow version use command below 1 2 0 Bazel version if compiling from source CUDA cuDNN version Provided GPU model and memory N A Exact command to reproduce See below Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Unable to install warp ctc with tensorflow in version 1 2 while it works in version 1 0 0 This is screenshot of dockerfile for version 1 0 For newer tensorflow versions e g 1 1 and 1 2 have the same issue problems occur That is libcuda so 1 cannot be found I have opened similar issue on nvidia docker since I have used their images and installed tensorflow via pip with same exact issues Only change is tensorflow verions while everything else remains the same I'm unable to test this outside docker contained due to machine permissions or lack thereof no admin and cannot install newer CUDA cuDNN etc Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Here is dockerfile used in the reproduction,,"gunan,gunan,gunan,gunan",2017-06-16 19:07:08,2017-06-16 20:40:59
IS,1 2 release python pip version is incorrect,The python pip package still has the version label 1 2 0 rc2 even though 1 2 0 was released proper today Can you change please L32,,"caisq,aselle",2017-06-16 20:45:34,2017-06-16 21:04:58
IS,Mac Python 3 6 1 Attempting to download mnist data results in CERTIFICATE VERIFY FAILED error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 5 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Bazel version if compiling from source n a CUDA cuDNN version none GPU model and memory n a Exact command to reproduce This does not reproduce with TensorFlow 1 1,,"aselle,aselle",2017-06-16 20:23:16,2017-06-16 21:07:44
IS,Error map fn tf python functional ops map fn AttributeError module 'tensorflow' has no attribute 'python',Error on System py3 5 win7 tf 1 2 cpu version map fn tf python functional ops map fn AttributeError module 'tensorflow' has no attribute 'python',,aselle,2017-06-16 19:12:29,2017-06-16 21:18:54
PR,Fix 9392,,,gunan,2017-06-16 21:38:52,2017-06-16 22:23:43
PR,Update performance guide md,,,"tfboyd,gunan,tfboyd",2017-06-16 21:05:41,2017-06-16 23:03:43
PR,Update performance guide md,,,"tfboyd,tfboyd,gunan",2017-06-16 21:50:55,2017-06-16 23:03:55
PR,Merging r1 2 back into master,,,"av8ramit,jhseu,jhseu,martinwicke",2017-06-16 19:55:23,2017-06-16 23:38:55
IS,Poor Scalability of TensorFlow MultiGPU Training on a Single Machine Performance Bug,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 3 16 7 TensorFlow installed from source or binary source hash b1e174e TensorFlow version use command below v1 1 0 rc2 119 gb1e174e 1 1 0 rc2 Bazel version if compiling from source 0 4 5 jdk7 CUDA cuDNN version CUDA 8 0 cudnn v5 1 GPU model and memory Titan X with 12 GiB Exact command to reproduce tf multiGPU py tensorflow benchmark version source hash 9165a70 Describe the problem Recently we are testing the TensorFlow scalability on multiGPU machines We use the official scripts provided in the benchmarks using codes from GitHub repository tensorflow benchmark We execute the script according to the official website to test the scalability of TensorFlow on the machine equipped with 8 Titan X GPUs We test the model VGG16 with batch size equaling to 64 The results are shown in the following table Num of GPUs Throughput images sec 1 83 13 2 155 06 3 211 8 4 278 51 5 265 53 6 268 19 7 272 8 8 302 27 We are surprised to find that the total throughput of 5 GPUs is smaller than 4 GPUs which means TensorFlow incurs significant overheads when the number of GPU is larger than 4 Because I do not know whether this performance issue belongs to the tensorflow tensorflow repository or tensorflow benchmark repository I submit this issue here looking forward to the official response The script for reproducing this issue can be found in Source code logs section with the results The scalability is strongly related to the topology of GPU interconnection In our machine we have a tree topology for GPUs The topology details can be found at the nv topo matrix txt We believe this is a performance bug since if more GPUs can not achieve higher throughput at least they should obtain similar throughput Source code logs Source code tf multiGPU py The log after executing the script above,,"aselle,tfboyd,ppwwyyxx,tfboyd,tfboyd,byronyi,tfboyd",2017-06-15 07:14:49,2017-06-17 00:01:37
IS,build fails for r1 2 on linux,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Ubuntu 16 04 2 LTS I have cloned tensorflow from github checked out release r1 2 I have rune the configure script configure Please specify the location of python Default is usr bin python usr bin python3 Found possible Python library paths usr lib python3 dist packages usr local lib python3 5 dist packages Please input the desired Python library path to use Default is usr lib python3 dist packages usr lib python3 dist packages Do you wish to build TensorFlow with MKL support y N N No MKL support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native march native Do you wish to use jemalloc as the malloc implementation Y n Y jemalloc enabled Do you wish to build TensorFlow with Google Cloud Platform support y N N No Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support y N N No Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with the XLA just in time compiler experimental y N N No XLA JIT support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N N No VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL support y N N No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N N No CUDA support will be enabled for TensorFlow INFO Starting clean this may take a while Consider using async if the clean takes more than several minutes Configuration finished shaeffer ip 10 164 47 27 srv projects c tfgit1 2 bazel build config opt tensorflow tools pip package build pip package ERROR srv projects c tfgit1 2 third party py python configure bzl 285 20 unexpected keyword 'environ' in call to repository rule implementation function attrs dict or NoneType None local bool False ERROR com google devtools build lib packages BuildFileContainsErrorsException error loading package '' Extension file 'third party py python configure bzl' has errors INFO Elapsed time 3 281s The tensorflow r1 2 build fails as described directly above OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary GitHub clone of source code TensorFlow version use command below r1 2 Bazel version if compiling from source bazel version Build label 0 4 4 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Wed Feb 1 18 54 21 2017 1485975261 Build timestamp 1485975261 Build timestamp as int 1485975261 Exact command to reproduce bazel build config opt tensorflow tools pip package build pip package,,aselle,2017-06-16 22:31:59,2017-06-17 01:14:25
IS,quantize graph,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-06-17 01:27:42,2017-06-17 01:27:57
PR,Docs Clarify Python requirement,Explicitly state Python target arch on Windows Reference issuecomment 309187925,,Carmezim,2017-06-17 03:05:51,2017-06-17 03:35:21
IS,Unable to install tenser flow on python 3 6 1 on windows 10 x64,pip Unable to install tenserflow,,"Carmezim,martinwicke,Carmezim",2017-06-17 00:30:28,2017-06-17 03:38:19
IS,conv1d not in tf contrib layers,As of tensorflow 1 2 conv1d can be found under tf layers and not tf contrib layers where you find conv2d Should not it be available under the contrib namespace By the way what is the conceptual difference between both submodules,,martinwicke,2017-06-17 02:47:47,2017-06-17 03:44:19
IS,The issue of compling from source code undeclared inclusion s in rule ' nccl archive nccl',Hey guys I can compile the cpu version of tensorflow 1 2 0 rc2 without any problem however i am blocked when i try to compile the gpu version I spend almost the whole day to install tensorflow 1 2 0 rc2 gpu version in our cluster however there is no lucky Here is the error from the terminal ERROR home hpc xin cache bazel bazel hpc xin c5e302e32d7acb9c3e4fce8142d1cd66 external nccl archive BUILD 33 1 undeclared inclusion s in rule ' nccl archive nccl' this rule is missing dependency declarations for the following files included by 'external nccl archive src libwrap cu cc' ' gpfs gpfs1 apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include fixed limits h' ' gpfs gpfs1 apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include fixed syslimits h' ' gpfs gpfs1 apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include stddef h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 new' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 x86 64 unknown linux gnu bits c config h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 x86 64 unknown linux gnu bits os defines h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 x86 64 unknown linux gnu bits cpu defines h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 exception' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 bits atomic lockfree defines h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 bits exception ptr h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 bits exception defines h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 bits nested exception h' ' gpfs gpfs1 apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include stdarg h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 cmath' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 bits cpp type traits h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 ext type traits h' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 cstdlib' ' gpfs gpfs1 apps2 gcc 5 4 0 include c 5 4 0 cstdio' Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 22 226s Critical Path 5 20s OS Information Red Hat Enterprise Linux Workstation release 6 7 Santiago Modules I loaded gcc 5 4 0 cuda 8 0 61 cudnn 6 0 java 1 8 0 31 sqlite 3 18 0 tcl 8 6 6 8606 python 3 6 1 Here is how i make the configuration gcc v5 4 0 apps2 gcc 5 4 0 customized path enabled cuda v8 0 apps2 cuda 8 0 61 customized path enabled cudnn apps2 cudnn 6 0 customized path python v3 6 1 which is compiled with gcc 5 4 0 apps2 python 3 6 1 customized path Other options are disabled such as hadoop google cloud Here are some files i modified manually before compiling 1 tensorflow 1 2 0 rc2 third party gpus crosstool CROSSTOOL clang tpl tensorflow 1 2 0 rc2 third party gpus crosstool CROSSTOOL nvcc tpl Add the following contents in all of toolchain cxx builtin include directory apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include cxx builtin include directory apps2 gcc 5 4 0 lib gcc x86 64 unknown linux gnu 5 4 0 include fixed cxx builtin include directory apps2 gcc 5 4 0 include c 5 4 0 cxx builtin include directory apps2 gcc 5 4 0 include cxx builtin include directory apps2 cuda 8 0 61 include cxx builtin include directory apps2 cudnn 6 0 include 2 home hpc xin cache bazel bazel hpc xin c5e302e32d7acb9c3e4fce8142d1cd66 external protobuf protobuf bzl Add the following content in ctx action env ctx configuration default shell env 3 home hpc xin cache bazel bazel hpc xin c5e302e32d7acb9c3e4fce8142d1cd66 external nccl archive Makefile Some modification as below CUDA HOME usr local cuda CUDA HOME apps2 cuda 8 0 61 I noticed that some of people said this issue could be bypassed by delete the nccl dependence in tensorflow 1 2 0 rc2 tensorflow contrib BUILD However i do not think this is the correct way to solve this issue I wanna keep this dependence Thanks so much for your help Any comments are appreciated Best Regards Xin,,"aselle,gunan,gunan,gunan,gunan,gunan,gunan",2017-06-13 03:19:37,2017-06-17 05:26:54
IS,SparseMatmulOpTest BroadcastPacketTest is failing on ppc64le,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source v1 0 1 TensorFlow version use command below 'v1 0 1 0 ge895d5c dirty' '1 0 1' Bazel version if compiling from source 0 4 4 2017 05 26 80a07b5 CUDA cuDNN version CUDA 8 0 and cuDNN 5 1 GPU model and memory GPU 0 Tesla P100 SXM2 16GB GPU 1 Tesla P100 SXM2 16GB Exact command to reproduce bazel test config opt config cuda tensorflow core kernels sparse matmul op test gpu Describe the problem This is regarding failure of test case SparseMatmulOpTest BroadcastPacketTest in tensorflow core kernels sparse matmul op test cc file While executing this test case on ppc64le it was observed that following line returns unexpected results L255,,"sandipmgiri,aselle,gunan,sandipmgiri",2017-06-16 09:25:26,2017-06-17 06:11:58
PR,do not lock markdown version and bring CI deps install script in sync with setup py,This markdown version lock could cause versioning conflict for downstream e g if requirements are compiled and resolved by pip compile Wondering If there is a reason to lock this version Seems someone pushed 1 2 0 to PYPI and it cause some dependency conflict,,"gunan,gunan",2017-06-15 21:05:52,2017-06-17 06:33:21
IS,BUG Get different image value each feed,System information OS Centos 7 TensorFlow installed from source Tensorflow version both 1 1 0rc1 and 1 2 0rc1 Bazel version 0 4 5 jdk7 CUDA 8 0 cuDNN 5 1 GeForce GTX 1080 8G Describe the problem Get different values of the same feeded image Source code Below is a minimal script that reproduce the problem,,"ppwwyyxx,aselle",2017-06-15 13:33:03,2017-06-17 07:41:30
IS,TF Detect to work with the new Object Detection API model,Hi there if I replace the current TF Detect model with the new Object Detection API model will it still work,,"andrewharp,andrewharp",2017-06-17 18:06:05,2017-06-17 19:10:46
IS,Failed to load the native TensorFlow runtime,I tried 10026 but I wo not work for me ImportError Traceback most recent call last ipython input 21 32e52670ef8f in module 6 import pattern 7 from bs4 import BeautifulSoup as bs 8 import tensorflow as tf Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,aselle,2017-06-17 11:27:09,2017-06-17 19:43:00
IS,Enable sparse matmul a b when a and b are sparse conformable,Current tf sparse matmul a b requires both a and b to be dense apparently,,"lakshayg,aselle",2017-06-17 04:55:03,2017-06-17 19:45:30
IS,How to update the variable list for which the optimizer need to train in tensorflow,How to update the list of variables for the optimizer to train in tensorflow In other words if we have the following optimizer optimizer tf train AdamOptimizer learning rate minimize cost scalar var list my var list I need to update my var list for example while fine tuning the network That is I am going to remove the variable which I no longer need to train and keep the others Example fine tuning the dense layer in a convolutional neural network Any help is much appreciated,,aselle,2017-06-17 13:45:24,2017-06-17 19:56:39
IS,tf reshape fails for Tensor with valid shape parameter,I do not know if my problem is truly a bug with TensorFlow but I think it is My problem is that tf reshape x shape sequence length 4 fails even when x is a tensor and the shape provided is valid Reshape returns the following error TypeError List of Tensors when single Tensor expected Some background I have a number of CSVs that I converted to SequenceExample s and stored as TFRecord s to use to train dynamic RNNs The length of each sequence can vary I can successfully read the SequenceExamples using parse single sequence example which returns a tensor of shape for each of my four feature tensors and each of my four label tensors I then stack the four feature tensors to create x with shape 4 and type class 'tensorflow python framework ops Tensor' I create a similar tensor of labels y with shape 4 and type class 'tensorflow python framework ops Tensor' Everything is good Then I would like to create minibatches based on similar length sequences using tf contrib training bucket by sequence length but if I pass in input length x shape 0 I receive the following error ValueError Cannot convert an unknown Dimension to a Tensor Since I know the sequence length when creating the SequenceExample s I modified my code to add the sequence length an integer as a context feature Then when I read my features and labels I try to reshape them as follows where sequence length has type class 'tensorflow python framework ops Tensor' and shape This raises the following error TypeError List of Tensors when single Tensor expected However x is a Tensor not a list of Tensors This is why I think there may be a bug in TensorFlow is tf reshape function My TensorFlow version TensorFlow version v1 2 0 rc0 24 g94484aa 1 2 0 rc1 If it helps I could post one of my tfrecord files and the code necessary to create this error,,aselle,2017-06-17 22:29:43,2017-06-18 14:09:58
IS,Decoding images in a given shape from TF records,I am trying to read images from TFrecords file The images vary in shapes After reading I want to preserve their shape which is why I pass the height width and depth parameters appropriately But the code just does not print anything after the set shape command The sess run calls do not respond I initialized the session in the main function and passed the object Is there a way to get the values of height w d tensors so that I can pass it to set shape How do I fix this Any suggestions are welcome Thanks in advance def read and decode sess filename queue reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example Defaults are not specified since both keys are required features 'height' tf FixedLenFeature tf int64 'width' tf FixedLenFeature tf int64 wouldepth' tf FixedLenFeature tf int64 'image raw' tf FixedLenFeature tf string 'label' tf FixedLenFeature tf int64 image tf decode raw features 'image raw' tf uint8 image set shape sess run features 'height' sess run features 'width' sess run features wouldepth',,aselle,2017-06-17 23:35:53,2017-06-18 14:19:02
IS,Compiler is out of heap space,I am compiling tensorflow on windows 10 laptop i7 6700hq 16GB ram with Visual Studio 2015 and all dependencies are ok as it is explained on readme However at the end of compilation I get the following error How can I solve this problem,,aselle,2017-06-17 19:23:11,2017-06-18 21:15:20
PR,Merge pull request 1 from tensorflow master,merge from master,,,2017-06-17 15:06:50,2017-06-18 21:19:06
IS,py func returning string leaks memory,TF version 1 2 0,,"gaohuazuo,caisq",2017-06-19 11:20:13,2017-06-19 14:57:27
IS,Error compiling in Linux Mint,I am trying to compile this from source but currently getting the following issue sudo bazel build config opt tensorflow tools pip package build pip package verbose failures WARNING home dan tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' Use SavedModel Builder instead WARNING home dan tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle gc' Use SavedModel instead INFO Found 1 target ERROR home dan cache bazel bazel root 113acdcc7c9d2b1e2c757002415fbd3e external io bazel rules closure java io bazel rules closure webfiles server BUILD 48 1 error executing shell command 'JAR 'external local jdk bin jar' OUTPUT 'bazel out host bin external io bazel rules closure java io bazel rules closure webfiles server libbuild info java proto srcjar srcjar' PROTO COMPILER 'exter ' failed bash failed error executing command cd home dan cache bazel bazel root 113acdcc7c9d2b1e2c757002415fbd3e execroot tensorflow exec env PATH usr local sbin usr local bin usr sbin usr bin sbin bin snap bin bin bash c 'JAR ' ''external local jdk bin jar' '' OUTPUT ' ''bazel out host bin external io bazel rules closure java io bazel rules closure webfiles server libbuild info java proto srcjar srcjar' '' PROTO COMPILER ' ''external com google protobuf protoc bin protoc' '' SOURCE ' ''external io bazel rules closure java io bazel rules closure webfiles server build info proto' '' INCLUDES ' '' I Iexternal io bazel rules closure' '' bazel out host bin external io bazel rules closure closure private gensrcjar' com google devtools build lib shell BadExitStatusException Process exited with status 1 external com google protobuf protoc bin protoc 1 external com google protobuf protoc bin protoc cannot create Directory nonexistent external com google protobuf protoc bin protoc 1 external com google protobuf protoc bin protoc ELF not found external com google protobuf protoc bin protoc 2 external com google protobuf protoc bin protoc Syntax error unexpected gensrcjar proto compiler failed Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 339 557s Critical Path 54 04s Can anyone help on this Thanks,,gunan,2017-06-18 20:59:04,2017-06-19 16:29:28
IS,load csv with header,When I run iris monitors py file It has an error File C software Python Python35 lib site packages tensorflow contrib learn python learn datasets base py line 47 in load csv with header header next data file StopIteration,,aselle,2017-06-19 03:17:10,2017-06-19 16:48:49
PR,Variable name typo,In the Working example Tracking Multiple Metrics the variable name name to updates names to updates,,yifeif,2017-06-19 12:25:46,2017-06-19 16:57:12
IS,how to compile tensorflow for sse4 1 sse 4 2 avx and sycl,how can i compile tensorflow for sse4 1 sse 4 2 avx and sycl is there some guide available online,,"byronyi,byronyi",2017-06-19 10:14:56,2017-06-19 17:02:41
PR,Tutorial Pass train file name instead of train file,Change read csv argument from train file to train file name in tutorial for Linear model Passing train file to read csv does not load any data into dataframe and the dataframe remains empty It works when changed to file name,,yifeif,2017-06-17 16:53:19,2017-06-19 17:03:36
PR,Fix typos,This PR revises the sample usages for lookup and fixes some typos contants Opeartor squeee nulll Contant and Tranpose,,"taehoonlee,yifeif",2017-06-16 02:33:53,2017-06-19 17:16:17
IS,Broken Link for CIFAR 10 tutorial,On the main page of Tensorflow tutorial for CIFAR 10 i e model inputs url the links in the Code Organisation code organization section are ALL broken To be precise the on clicking them Github page says ' Page not found ' Please remove this bug ASAP,,aselle,2017-06-14 19:38:03,2017-06-19 18:29:00
IS,Could a 3 7 alpha wheel of tensorflow be provided on pip,Python 3 7 alpha exists I would like to be able to install a wheel Any idea when tensorflow could be added on pypi for 3 7,,"aselle,gunan",2017-06-18 21:22:54,2017-06-19 18:33:31
IS,Documentation cifar10 input py is referenced but missing on master,Describe the problem File cifar10 input py is referenced in documentation but is missing on master Documentation piece r0 7 version,,aselle,2017-06-14 21:46:22,2017-06-19 18:35:35
IS,TensorBoard Histogram Dashboard link broken,The link to the TensorBoard Histogram Dashboard documentation is broken 404 If that section is currently in the process of being written perhaps add a dummy page saying so,,aselle,2017-06-18 00:23:19,2017-06-19 18:36:08
IS,TensorFlow C library now available for Windows,Does anyone know where to find the available TensorFlow C library for Windows I only get the information about C library on Linux and MacOs,,asimshankar,2017-06-19 08:19:46,2017-06-19 18:49:17
IS,tf Summary comparison operator overloading,So I was trying to use a comparison operation with a tf Summary object It does not throw an error but the results are incorrect I could not find any help for this on the official documentation Here are my logs The objects were created using tf Summary value tf Summary Value tag tag simple value value What do you think,,dandelionmane,2017-06-19 01:27:54,2017-06-19 19:52:22
PR,Documentation fix Referencing correct pip in installation examples,The examples are supposed to be for Python2 7 so it makes sense that they refer to the correct pip pip instead of pip3 to avoid any potential confusion,,"gunan,gunan",2017-06-19 18:55:18,2017-06-19 20:43:54
IS,I am New To Tensorflow How To learn can anyone Provide Step by Step Process,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2017-06-19 19:53:21,2017-06-19 20:44:32
IS,Tensorflow Android API version 1 2 not in JCenter,The freshly released version 1 2 of the tensorflow APIs is not yet fully available in JCenter There is a version 1 2 0 but it does not contain any files Can you push these files to the repository,,"andreas-eberle,aselle,andrewharp,andrewharp",2017-06-19 10:08:42,2017-06-19 22:21:35
PR,Remove TensorBoard codebase from TensorFlow,TensorBoard can now be found in its own repo,,dandelionmane,2017-06-19 19:43:51,2017-06-19 23:25:44
IS,No OpKernel was registered to support Op 'Maximum' with these attrs iOS,Consult excuse me write own model file called collapse iOS snip20170613 6,,"aselle,aselle,aselle,aselle,aselle,aselle,tatatodd",2017-06-13 12:02:46,2017-06-20 00:52:24
IS,GPU CPU Memcpy failed Error or InternalError c2c fft failed Error when using FFT2D,The problem I wrote a python script that used FFT2D from tensorflow you can find the Python script attached TestFFT2D py using GPU In this script I first create a convolution apply to a tensor and than compute a loss between a reference input tensor and a variable one with ftt2d and ifft2d operations When I launch my script I get a GPU CPU Memcpy failed Error or an InternalError c2c fft failed Error I do not know why the error change when I run again my script I test my code on two differents machine with Ubuntu 16 04 one with a GeForce GTX 680 GPU and one with a GeForce GTX 1080 In both case I can randomly get both of the error messages Abandon txt InternalError txt Sometimes my machine just crashes and I need to reboot it Source code logs You can find the terminal messages errors attached This is the TestFFT2D py code TestFFT2D py import tensorflow as tf import numpy as np def get loss sess net img ref layer total loss 0 sess run net 'input' assign img ref x net layer a sess run net layer x tf transpose x 0 3 1 2 a tf transpose a 0 3 1 2 N a shape F x tf fft2d tf complex x 0 F x conj tf conj F x F a tf fft2d tf complex a 0 F a conj tf conj F a for i in range N inter corr x tf multiply F x F x conj inter corr a tf multiply F a F a conj ifft2 corr x tf ifft2d inter corr x ifft2 corr a tf ifft2d inter corr a R x tf real ifft2 corr x R a tf real ifft2 corr a style loss tf nn l2 loss tf subtract R x R a total loss style loss Shift the tensor from on 1 unit on the dimension 1 F x tf concat tf expand dims F x 1 0 F x 1 axis 1 F a tf concat tf expand dims F a 1 0 F a 1 axis 1 return total loss def main args Definition of the first operations height width numberChannels 400 300 3 net current tf Variable np zeros 1 height width numberChannels dtype np float32 net 'input' current kernel tf constant np random uniform low 1 high 1 size 400 300 3 64 dtype np float32 conv tf nn conv2d current kernel strides 1 1 1 1 padding 'SAME' name 'conv' bias tf constant np random uniform low 1 high 1 size 64 dtype np float32 conv add bias tf nn bias add conv bias net 'conv1 1' conv add bias img ref np random uniform low 128 high 128 size 1 height width numberChannels init img np random uniform low 128 high 128 size 1 height width numberChannels sess tf Session sess run net 'input' assign img ref Definition of the loss loss get loss sess net img ref 'conv1 1' Preparation of the assignation operation placeholder tf placeholder tf float32 shape init img shape assign op net 'input' assign placeholder sess run tf global variables initializer sess run assign op placeholder init img print Before loss evaluation loss evaluation sess run loss print loss evaluation loss evaluation return 0 if name ' main ' import sys sys exit main sys argv System information Have I written custom code TestFFT2D py OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from Source TensorFlow version v1 0 0 65 g4763edf dirty 1 0 1 CUDA cuDNN version Cuda compilation tools release 7 5 V7 5 17 and cuDNN 5 with the GeForce GTX 680 Cuda compilation tools release 8 0 V8 0 61and cuDNN 5 with the GeForce GTX 1080 GPU model and memory Tested on GeForce GTX 680 with 2Go and on GeForce GTX 1080 with 12Go Python version Python 3 6 1 Anaconda 4 4 0 64 bit Exact command to reproduce python TestFFT2D py copy paste the code above and run it with python 3,,tatatodd,2017-06-16 10:59:45,2017-06-20 01:06:56
IS,New changes in tf 1 2 and the seq2seq model,In the change log it reads The strictness described in the TensorFlow 1 1 release is gone The first time an RNNCell is used it caches its scope All future uses of the RNNCell will reuse variables from that same scope Based on which the seq2seq model with UNtied decoder weights no longer remain untied Can you confirm that this is addressed I do not see anywhere in the seq2seq model that this is addressed,,"tatatodd,tatatodd",2017-06-18 22:46:26,2017-06-20 02:10:18
PR,Pin Java bindings to 1 7,The android library bazel rule currently enforces Java 7 L73 More generally to enable broader use we pin the source and artifacts to 1 7 till Java 8 gains wider adoption across Android,,"kbsriram,kbsriram,asimshankar",2017-06-15 13:20:12,2017-06-20 16:02:12
PR,DirectSession Run Variable name typo,In core common runtime direct session cc end of DirectSession Run name correction parition graph defs partition graph defs,,caisq,2017-06-20 00:17:15,2017-06-20 17:18:28
IS,new release for tensorflow 1 2 release,Any plans for a 1 2 release,,,2017-06-20 17:46:00,2017-06-20 17:46:39
PR,Fix Java OperationBuilder documentation example,Constant is not a registered Op type Const is,,asimshankar,2017-06-20 13:00:01,2017-06-20 18:14:40
PR,Fix references,This PR fixes deprecated URLs,,"taehoonlee,yifeif",2017-06-20 02:07:27,2017-06-20 18:22:50
PR,correctly vulcanize link rel import type css,,,"yifeif,dandelionmane",2017-06-20 17:20:25,2017-06-20 18:45:13
IS,Feature Request Sequence to Sequence Bucketing Batching,System information OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra Version 10 12 5 TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Describe the feature tf contrib training bucket by sequence length and tf contrib training bucket are useful for creating batches of similar length sequences for training dynamic RNNs I would like to be able to create batches of similar length input sequence output sequence pairs to train Sequence to Sequence models with dynamic encoders and dynamic decoders I may be wrong but as far as I can tell there is no easy way to adapt either of the current bucketing functions to create batches like this The seq2seq translate tutorial relies on a method def get batch self data bucket id to get such batches but I think it would be nicer if TensorFlow had a built in function that did not rely on a custom implementation and that integrated nicely with FIFOQueues for reading data,,,2017-06-20 18:42:08,2017-06-20 19:53:48
IS,ValueError Attempt to reuse RNNCell reuse flag does not work,System information Linux Ubuntu 16 04 tensorflow gpu 1 1 0 I am getting this error in quite a complex graph but I can reproduce it with a minimal but hopefully representative example below For the new tensorflow version I have tried to add a reuse True flag as per 9401 when defining the LSTM cell but then I get another error ValueError Variable shape inference basic lstm cell weights does not exist or was not created with tf get variable Did you mean to set reuse None in VarScope Any help would be greatly appreciated Best Francesco,,tatatodd,2017-06-20 15:01:52,2017-06-20 20:16:29
IS,Differentiate Variable Model Parameters and Mutable Tensor,In the current tensorflow the concept of variables is about same as model parameters and mutable tensors I would like to see them separate out For example it seems perfect legit to me to use tf scatter nd update to update a tensor However all scatter APIs require mutable tensor That made operations on tensors with batch parameter close to impossible Having the concept of mutable tensor will help a lot,,tatatodd,2017-06-20 16:40:46,2017-06-20 20:32:30
PR,Changing context search for BiasAddGrad rewrite from BFS to stricter check,Current approach for rewriting BiasAddGrad node searches the backward data flow of BiasAddGrad for MatMul or Conv2D node whatever is found earlier is considered as the context for rewriting BiasAddGrad We discovered that this approach is not robust so we are changing it to rely on a much stricter and robust check for context search,,"nhasabni,nhasabni,vivek-rane",2017-06-16 17:52:51,2017-06-20 21:42:10
PR,orthogonal initializer bug fix,Fixed a bug in orthogonal initializer function in init ops py file The original way of generating a random matrix random uniform is not scaled to make the mean value to 0 This will cause the value in the first block of the returned matrix which is corresponding to the largest singular value very close to each other In convolutional neural network if the initial parameters of a kernel are similar to each other then all the parameters will update very similarly which is a really bad thing for training The bug is fixed by simply using the random normal function to generate the random matrix This will work because the default parameters for random normal are mean 0 0 stddev 1 0,,yifeif,2017-06-15 03:07:43,2017-06-20 21:57:14
PR,Pass rate and other settings to parent classes,See,,yifeif,2017-06-20 14:26:54,2017-06-20 21:57:36
PR,Cifar10,,,yifeif,2017-06-15 22:01:03,2017-06-20 22:04:20
IS,GPU option allow growth and CUDA ERROR OUT OF MEMORY,Hi I tried to build a LSTM model on 30G data with a aws machine p2 xlarge with 60G memory and a gpu with 12G memory The performance is inconsistent Sometimes we get it to work but sometimes we encounter CUDA ERROR OUT OF MEMORY The answer at suggests setting a gpu option allow growth to False It refers to the source code where the change could be made But in the code I notice the only line containing allow growth is this bool allow growth 4 It looks strange to me Could you explain why allow growth is assigned a integer value 4,,tatatodd,2017-06-20 22:09:57,2017-06-21 00:24:57
IS,Training LSTM RNN model after restoration starting again with high loss,I have an LSTM based RNN language model where in after the initial training for 1000 iterations the model is saved as follows saver tf train Saver saver save sess 'rnn model ckpt' global step 1000 I have restored the model by saver tf train import meta graph rnn model ckpt 1000 meta saver restore self sess tf train latest checkpoint ' ' graph tf get default graph restore the operations and placeholder as required from the graph perform retraining so far everything looks good the model is restored but however when I plot the loss summary while training with the same input data as previous training the loss again starts with high value as if it is training from start again freshly I have tried to search all means to find the relevant forums but could not find a proper solution please advise on the corrective steps related links,,,2017-06-19 07:58:02,2017-06-21 05:01:02
IS,Something error when I run iris monitors py,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 0 1 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce import tensorflow Describe the problem When I run iris monitors py in Pycharm file It has an error Traceback most recent call last File F temp Python temp py line 92 in module tf app run File C software Python Python35 lib site packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File F temp Python temp py line 35 in main filename IRIS TRAINING target dtype np int features dtype np float File C software Python Python35 lib site packages tensorflow contrib learn python learn datasets base py line 47 in load csv with header header next data file StopIteration Source code logs C software Python Python35 python exe F temp Python temp py Traceback most recent call last File F temp Python temp py line 92 in module tf app run File C software Python Python35 lib site packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File F temp Python temp py line 35 in main filename IRIS TRAINING target dtype np int features dtype np float File C software Python Python35 lib site packages tensorflow contrib learn python learn datasets base py line 47 in load csv with header header next data file StopIteration Process finished with exit code 1,,tatatodd,2017-06-20 13:08:43,2017-06-21 07:19:51
IS,Feature Request for BitwiseXOR for Tensor,My project requests a new layer which needs the new operator of Tensor to compute bitwiseXOR between input x and constant Key k E g x 4 bit form 100 k 7 111 the bitwiseXOR x k expects as 3 011 As far as I know Tensor only has LogicXOR operator for bool type Luckily Tensorflow has the extended ability to have a new Op However I read the document in I can get the basic idea but that is far from the implementation maybe because of the lack of c knowledge If you guys could help to implement the new operator that will be helpful Then I can use that new Op of Tensor to build the new layers,,asimshankar,2017-06-21 14:29:34,2017-06-21 15:46:14
IS,where is a complete API document,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-06-21 06:07:11,2017-06-21 15:48:17
IS,Cannnot convert Graphs Models via DarkFlow,L69 flow model cfg tiny yolo voc cfg load bin tiny yolo voc weights savepb verbalise True I already reported about this on darkflow git but still did not get any reply I shows next error ERROR Invalid argument verbalise True,,,2017-06-21 14:17:06,2017-06-21 17:53:38
IS,RunMetadata giving inconsistent RAM values,When viewing the GPU memory usage of a run metadata in TensorBoard it shows for example one node model with 9 99 GB and another node optimization with 14 1 GB The sum of these values exceeds the available memory on the GPU 12 GB by far,,"dandelionmane,mrry,yaroslavvb",2017-06-16 16:19:31,2017-06-21 18:04:39
IS,Splitting model and using threads,Hello everyone I am new to tensorflow and had a doubt How can I split a pre trained model into two parts and then load it onto the GPU simultaneously using different threads Is it possible if yes please guide me for the same Thanks,,tatatodd,2017-06-21 04:58:36,2017-06-21 18:16:44
PR,R0 11,,,,2017-06-21 14:15:55,2017-06-21 18:18:40
IS,how do i retrain net after quantization,i had used tensorflow tool quantization graph py to quantize my graph successfully how do i retrain this net after quantization since the tool requires using freeze graph py to convert variables in graph to constant BTW can i set up my graph using quantize ops and train from the scratch if can is there any example,,tatatodd,2017-06-21 06:22:19,2017-06-21 18:32:50
IS,Mismatched delete in mkl tfconv op cc,tensorflow core kernels mkl tfconv op cc line 120 delete in sizes should be delete in sizes,,"tatatodd,yongtang",2017-06-20 15:37:59,2017-06-21 20:12:09
PR,Fix mismatched delete in mkl tfconv op cc,This fix fixes mismatched new delete in mkl tfconv op cc This fix fixes 10853 the file went through clang format so there are some additional changes Signed off by Yong Tang yong tang github outlook com,,"yongtang,tatatodd",2017-06-21 15:49:06,2017-06-21 20:12:09
PR,Fixed path to seq2seq py and minor formatting,,,"tfboyd,gunan",2017-06-21 16:24:18,2017-06-21 20:12:33
IS,Installation Fails,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary binary TensorFlow version use command below latest from pip Bazel version if compiling from source CUDA cuDNN version 8 5 1 GPU model and memory Quadro K620 Exact command to reproduce import tensorflow Describe the problem Have installed CUDA 8 cuDNN 5 1 get the below error when attempting to import tensorflow Have seen other threads on here that all describe this as a PATH issue I have ensured the cuDNN CUDA necessities are in the path and have used installation check script it returned ERROR Failed to import the TensorFlow module Python version is 3 5 TensorFlow is installed at c users rhalabi appdata local programs python python35 lib site packages tensorflow All required DLLs are present Please open an issue on the TensorFlow GitHub page An exception has occurred use tb to see the full traceback SystemExit 1 Source code logs In 4 import tensorflow ImportError Traceback most recent call last c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py in swig import helper 17 try 18 return importlib import module mname 19 except ImportError c users rhalabi appdata local programs python python35 lib importlib init py in import module name package 125 level 1 126 return bootstrap gcd import name level package level 127 c users rhalabi appdata local programs python python35 lib importlib bootstrap py in gcd import name package level c users rhalabi appdata local programs python python35 lib importlib bootstrap py in find and load name import c users rhalabi appdata local programs python python35 lib importlib bootstrap py in find and load unlocked name import c users rhalabi appdata local programs python python35 lib importlib bootstrap py in load unlocked spec c users rhalabi appdata local programs python python35 lib importlib bootstrap py in module from spec spec c users rhalabi appdata local programs python python35 lib importlib bootstrap external py in create module self spec c users rhalabi appdata local programs python python35 lib importlib bootstrap py in call with frames removed f args kwds ImportError DLL load failed The specified procedure could not be found During handling of the above exception another exception occurred ImportError Traceback most recent call last c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow py in module 40 sys setdlopenflags default dlopen flags ctypes RTLD GLOBAL 41 from tensorflow python pywrap tensorflow internal import 42 from tensorflow python pywrap tensorflow internal import version c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py in module 20 return importlib import module ' pywrap tensorflow internal' 21 pywrap tensorflow internal swig import helper 22 del swig import helper c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py in swig import helper 19 except ImportError 20 return importlib import module ' pywrap tensorflow internal' 21 pywrap tensorflow internal swig import helper c users rhalabi appdata local programs python python35 lib importlib init py in import module name package 125 level 1 126 return bootstrap gcd import name level package level 127 ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred ImportError Traceback most recent call last ipython input 4 a649b509054f in module 1 import tensorflow c users rhalabi appdata local programs python python35 lib site packages tensorflow init py in module 22 23 pylint disable wildcard import 24 from tensorflow python import 25 pylint enable wildcard import 26 c users rhalabi appdata local programs python python35 lib site packages tensorflow python init py in module 47 import numpy as np 48 49 from tensorflow python import pywrap tensorflow 50 51 Protocol buffers c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow py in module 50 for some common reasons and solutions Include the entire stack trace 51 above this error message when asking for help traceback format exc 52 raise ImportError msg 53 54 pylint enable wildcard import g import not at top unused import line too long ImportError Traceback most recent call last File c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File c users rhalabi appdata local programs python python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 914 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified procedure could not be found During handling of the above exception another exception occurred Traceback most recent call last File c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File c users rhalabi appdata local programs python python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File c users rhalabi appdata local programs python python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help In 5,,,2017-06-19 20:49:40,2017-06-21 21:00:23
PR,Improve docs for tf nn depthwise conv2d native,Hi In depthwise conv2d native docs the formula to calculate the output tensor is not written inside code tag for markdown Screenshot of the docs screenshot from 2017 06 21 21 38 21,,"AnishShah,yifeif",2017-06-21 16:10:52,2017-06-21 22:01:07
PR,R1 1,,,,2017-06-21 22:48:10,2017-06-21 22:51:50
PR,Branch 159575817,,,"yifeif,yifeif,yifeif",2017-06-20 17:42:48,2017-06-21 23:56:03
PR,OpenCL Registers AdjustContrastv2,Registers AdjustContrastv2 for SYCL Extends adjust contrast op benchmark test to cover SYCL,,"lukeiwanski,benoitsteiner",2017-06-21 12:38:27,2017-06-21 23:59:55
PR,OpenCL Registers RGBToHSV and HSVToRGB 91,OpenCL Added RGBToHSV and HSVToRGB Aligning,,"lukeiwanski,lukeiwanski,benoitsteiner",2017-06-20 13:39:38,2017-06-22 00:00:44
PR,Branch 159649743,,,yifeif,2017-06-21 17:26:25,2017-06-22 00:34:24
IS,tf contrib data Dataset filter kernel error on excluded element,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary nightly build TensorFlow version use command below 1 2 0 rc2 git version v1 2 0 rc0 1066 g4c0052d CUDA cuDNN version 8 0 GPU model and memory GTX 970 Exact command to reproduce See script Describe the problem I am trying to use Dataset is filter function to exclude certain examples but when the iterator hits the index of the first excluded example a kernel error occurs and the program crashes Source code logs This example creates a data set of 100 integers and filters out every third one by checking x 3 2 The first two calls to sess run produce the digits 0 and 1 and they get printed correctly At the third sess run call the program crashes Running this,,"aselle,vrv,vrv",2017-06-15 08:20:06,2017-06-22 00:34:52
PR,Update WorkerCacheLogger RecordRecvTensor to let future improvements,to tracing tools Add a placeholder for more details about a RecvTensor call Custom title to possibly distinguish between control and data flow RecvTensor calls,,,2017-06-22 08:53:16,2017-06-22 09:10:29
IS,Tensorflow Android how to set multi input for my own model,Beside the images that I need to transform into the classifier I also need to put another input named phase train and set as False How to make it,,,2017-06-22 06:26:04,2017-06-22 09:37:20
IS,Implementation of algorithms like longest commom subsequence and editting distance,Hi everyone I am wondering if there are some shortcuts to implement an new API of algorithms like lcs Should I implement it from scratch using C or C It seems not efficient to do it in Python How can I just get started Thanks Best lerner,,,2017-06-22 03:14:22,2017-06-22 09:58:05
IS,freeze graph script error google protobuf text format ParseError,I am trying to run the freeze graph script on my own pb and ckpt file However I am getting this error,,,2017-06-22 13:00:38,2017-06-22 13:06:52
PR,fix error string format,I just got this helpful error message and I'm submitting a fix for the format ValueError 'num outputs should be int or long got s ' tf Tensor 'mul 0' shape dtype int32 becomes ValueError num outputs should be int or long got Tensor mul 0 shape dtype int32,,"dgboy2000,caisq,dgboy2000,caisq,caisq,caisq",2017-06-21 10:09:56,2017-06-22 13:23:24
PR,Java API to get the size of specified input list of operations,This opens up access to the TF OperationInputListLength C API from java for operations that return specified input lists,,"asimshankar,yifeif,asimshankar",2017-06-20 18:54:38,2017-06-22 14:11:45
PR,Correct the learning rate as per the code snippet,The training step train step tf train GradientDescentOptimizer 0 05 minimize cross entropy states the learning rate as 0 05 whereas the documentation states 0 5 This needs to be corrected,,caisq,2017-06-22 02:45:58,2017-06-22 14:16:42
IS,What should be my output node names for freeze graph py,I am trying to freeze graph a pb and ckpt file of a trained Inception model I cannot understand what shall by my output node names,,asimshankar,2017-06-22 13:43:27,2017-06-22 14:52:03
IS,run on gpu in tensorflow backend,Hi How can be sure that the tensorflow keras run on GPU i use tensorflow keras with backend Although in keras manual Written If you are running on the TensorFlow or CNTK backends your code will automatically run on GPU if any available GPU is detected How can this be checked Thanks,,rohan100jain,2017-06-22 16:06:17,2017-06-22 16:14:04
IS,undefined symbol error when loading zero out custom op,System information Implement zero out custom op as defined in tensorflow tutorial no custom code at all OS Platform and Distribution Ubuntu 16 04 2 LTS Xenial Xerus 4 4 0 75 generic 96 Ubuntu SMP Thu Apr 20 09 56 33 UTC 2017 x86 64 x86 64 x86 64 GNU Linux TensorFlow installed from source or binary source TensorFlow version use command below 1 1 0 rc2 v1 1 0 rc2 817 geb11d6b Bazel version if compiling from source 0 4 5 CUDA cuDNN version None GPU model and memory None The problem Undefined symbol error when using zero out custom op It appears after I follow the tensorflow tutorial bazel build config opt tensorflow core user ops zero out so is OK Loading complete Analyzing Found 1 target Building 0 1 BazelWorkspaceStatusAction stable status txt Target tensorflow core user ops zero out so up to date bazel bin tensorflow core user ops zero out so Elapsed time 0 464s Critical Path 0 01s python zero output op test py ERROR testZeroOut main ZeroOutTest Traceback most recent call last File zero out op test py line 5 in testZeroOut zero out module tf load op library ' srv workspace tensorflow bazel bin tensorflow core user ops zero out so' File usr local lib python2 7 dist packages tensorflow python framework load library py line 64 in load op library None None error msg error code NotFoundError srv workspace tensorflow bazel bin tensorflow core user ops zero out so undefined symbol ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringB5cxx11Ev Ran 2 tests in 0 040s FAILED errors 1 Source code logs zero out cc,,aselle,2017-06-14 22:21:29,2017-06-22 16:17:51
IS,seq2seq BasicDecoder incompatible with seq2seq ScheduledOutputTrainingHelper,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below b'v1 1 0 0 g1ec6ed5' 1 1 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 5 1 3 GPU model and memory TitanX 12GB Exact command to reproduce See script below Describe the problem seq2seq ScheduledOutputTrainingHelper sample outputs a tf bool tensor but seq2seq BasicDecoder output dtype assumes tf int32 output Source code logs Minimal case script,,rohan100jain,2017-06-15 16:30:52,2017-06-22 16:25:03
PR,Fix typos,This PR fixes some typos intialized be be by by in in tranformation new new constaint and mean square error,,"taehoonlee,caisq",2017-06-22 05:03:44,2017-06-22 16:44:03
PR,Add the shared libraries in the quickstart,When following the quickstart steps of the golang README md below issue is found uname a Linux ubuntu 16 4 4 0 57 generic 78 Ubuntu SMP Fri Dec 9 23 50 32 UTC 2016 x86 64 x86 64 x86 64 GNU Linux go test github com tensorflow tensorflow tensorflow go tmp go build828413616 github com tensorflow tensorflow tensorflow go test go test error while loading shared libraries libtensorflow so cannot open shared object file No such file or directory FAIL github com tensorflow tensorflow tensorflow go 0 001s It is due to the env variable after adding the LIBRARY PATH and LD LIBRARY PATH it became ok go test github com tensorflow tensorflow tensorflow go ok github com tensorflow tensorflow tensorflow go 0 246s so I updated the README md file,,"asimshankar,asimshankar",2017-06-21 02:59:08,2017-06-22 16:44:54
PR,Added 7 comments on core rnn cell test,I added 7 comments on core rnn cell test Thanks,,"chris-chris,yifeif",2017-06-16 16:48:59,2017-06-22 17:21:46
PR,Improve RDMA rendezvous speed,This PR fixes Tested with RoCE setting Mellanox Technologies MT27620 Family Before this PR TODO memcpy is still slow and need to improved,,"llhe,llhe,llhe,byronyi,llhe,byronyi,llhe,byronyi,llhe",2017-06-08 12:53:20,2017-06-22 17:58:14
PR,add log softmax c gradient,,,"yifeif,yifeif",2017-06-19 16:19:23,2017-06-22 17:59:11
PR,expand inline for debug builds to limit number of symbols,debug build does not expand inlines which will generate lots of unused symbols that result in too many entries in the def file for python wrapper dll Change debug build to expand inlines,,"guschmue,yifeif,yifeif",2017-06-21 19:54:37,2017-06-22 18:21:36
PR,XLA Add override of Permute to fix compile errors,This is an attempted fix for older compilers that can not deduce the template args,,"tatatodd,yifeif,tatatodd,yifeif,tatatodd,tatatodd",2017-06-20 21:21:46,2017-06-22 19:30:13
IS,Compiling tensorflow fails with error no matching function for call to 'Permute tensorflow gtl ArraySlice long long int const std vector llvm Value std allocator llvm Value ',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary Trying to compile from source TensorFlow version use command below 1 2 0 release Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory 1080 Ti 11 GB Exact command to reproduce The PKGBUILD If you are not familiar with this format basically just execute prepare and then build Describe the problem I'm the packager for the official tensorflow package in Arch Linux and I was trying to update 1 1 0 to 1 2 0 and it fails to build Full build log attached We always build in clean chroots llvm 4 0 gcc 7 1 1 Source code logs log txt,,"tatatodd,tatatodd,tatatodd,tatatodd",2017-06-20 08:49:07,2017-06-22 19:41:26
PR,OpenCL Fixes run metadata test for SYCL,This test is designed to test CUDA specific behavior,,"lukeiwanski,yifeif",2017-06-22 18:34:49,2017-06-22 19:59:33
PR,OpenCL Fixes CUDA specific test run on SYCL 56,The testBadParentValuesOnGPU should only be run on CUDA devices as the test checks for particular CUDA behaviour We do not actually provide a SYCL kernel for GatherTree and so it is not a problem that the tests do not target SYCL,,"lukeiwanski,yifeif",2017-06-22 15:26:38,2017-06-22 20:09:18
PR,OpenCL REGISTER REGISTER6,Fixes compilation error for the SYCL target,,"lukeiwanski,yifeif",2017-06-22 12:04:05,2017-06-22 20:09:31
IS,resize images Alignment of upsampled image seems incorrect with method NEAREST NEIGHBOR and align corners True,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS Linux release 7 2 1511 Core TensorFlow installed from source or binary source TensorFlow version use command below 'v1 1 0 0 g1ec6ed5' '1 1 0' Bazel version if compiling from source 0 4 5 non git CUDA cuDNN version 7 5 5 1 GPU model and memory M40 12GB Exact command to reproduce Describe the problem My understanding of the behaviour of tf image resize images with align corners True is that it would resize Note that the nearest neighbor of the third 0 in the actual result is the element with value 3 Source code logs I have attached a simple example that demonstrates this effect nearest py zip,,ppwwyyxx,2017-06-22 15:53:26,2017-06-22 20:18:20
PR,Updated link to use HTTPS,Howdy I just updated a link to use https instead of http Thanks,,,2017-06-22 22:21:00,2017-06-22 22:25:38
IS,bayesflow w higher order functions loops endlessly,Environment TensorFlow v1 2 0 rc2 21 g12f033d 1 2 0 running on Mac OS X v10 12 5 Issue Use of tensorflow contrib bayesflow stochastic tensor StochasticTensor in conjunction with higher order functions such as tf map fn and tf while loop results in a seemingly endless loop during construction of the associated stochastic graph is surrogate loss Within the source code the aforementioned loop occurs here L85 A minimal example is provided below Example,,jvdillon,2017-06-22 05:07:59,2017-06-23 00:03:27
IS,Original error was DLL load failed The specified procedure could not be found,Hello I have been getting 'Original error was DLL load failed The specified procedure could not be found' error when attempting to import tensorflow I'm on Windows 10 with python 3 6 00 I have checked some issues like mine but I already have visual studio c 2017 I attempted to download 2015 however I was told I already have it I installed tensorflow with Have I written custom code as opposed to using a stock example script provided in TensorFlow No TensorFlow installed from source or binary binary TensorFlow version Ca not do version because I the error when importing Bazel version if compiling from source NA CUDA cuDNN version 8 0 I think GPU Model and Memory Nvidia 1080 4gb Exact command to reproduce pip3 install upgrade tensorflow gpu Here is the full error Traceback most recent call last File stdin line 1 in module File C Users David AppData Local Programs Python Python36 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users David AppData Local Programs Python Python36 lib site packages tensorflow python init py line 47 in module import numpy as np File C Users David AppData Local Programs Python Python36 lib site packages numpy init py line 142 in module from import add newdocs File C Users David AppData Local Programs Python Python36 lib site packages numpy add newdocs py line 13 in module from numpy lib import add newdoc File C Users David AppData Local Programs Python Python36 lib site packages numpy lib init py line 8 in module from type check import File C Users David AppData Local Programs Python Python36 lib site packages numpy lib type check py line 11 in module import numpy core numeric as nx File C Users David AppData Local Programs Python Python36 lib site packages numpy core init py line 26 in module raise ImportError msg ImportError Importing the multiarray numpy extension module failed Most likely you are trying to import a failed build of numpy If you are working with a numpy git repo try git clean xdf removes all files not under version control Otherwise reinstall numpy Original error was DLL load failed The specified procedure could not be found I tried reinstalling numpy too same error,,,2017-06-18 21:46:44,2017-06-23 00:12:42
IS,ModuleNotFoundError No module named 'tensorflow tensorboard tensorboard',Tensorboard not working on Tensorflow built from sources System information Linux Ubuntu 16 04 TensorFlow installed from sources using Bazel TensorFlow version v1 2 0 1126 gb7acb6a Bazel version 0 51 CUDA cuDNN version 8 0 6 0 Found device 0 with properties name GeForce GTX 1070 major 6 minor 1 memoryClockRate GHz 1 683 pciBusID 0000 01 00 0 Total memory 7 92GiB Free memory 5 15GiB Exact command to reproduce tensorboard Installed into fresh anaconda3 environment 'tensorflow' environment is activated when performing command Description The TensorBoard visualization does not work Source code logs,,"tatatodd,tatatodd,dandelionmane,dandelionmane",2017-06-21 16:31:44,2017-06-23 00:59:22
PR,OpenCL Registers SquaredDifference,,,"lukeiwanski,yifeif,lukeiwanski,yifeif",2017-06-22 15:06:45,2017-06-23 04:46:03
PR,Moved tpu config RunConfig check to beginning,This is necessary because wrapped model fn calls create infeed enqueue ops and dequeue fn which requires a TPU Config Though the actual call is delayed to a later time it would be better to raise this error earlier Also this check is only necessary inside use tpu block,,terrytangyuan,2017-06-23 02:17:51,2017-06-23 05:55:24
IS,TensorFlow 1 2 0 update still not supporting Python 3 6 1 on Windows 10,System information Windows 10 64 bit Python 3 6 1 Even with the new update the command pip install tensorflow gpu 1 2 0 cp36 cp36m win amd64 whl OR as in the official documentation pip3 install upgrade tensorflow returns tensorflow gpu 1 2 0 cp36 cp36m win amd64 whl is not a supported wheel on this platform AND Could not find a version that satisfies the requirement tensorflow from versions No matching distribution found for tensorflow respectively,,"mrry,mrry",2017-06-22 07:19:34,2017-06-23 07:31:06
IS,port AlignedMalloc may cause a memory leak,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra Version 10 12 5 TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 0 Darwin cpu Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem When developing Perfect TensorFlow a Swift Class Wrapper of C api I found there might be a memory leak when performing such a test testing script L153 L167 currently I am using libtensorflow 1 1 0 CPU version on both macOS Ubuntu 16 04 LTS and found the same leakage on the both systems hope to get solution once 1 2 released Using Xcode Instruments may find the trace as screen shot below p img src '' AlignedMalloc leak Screenshot img p Source code logs Tensor Creation Testing Script L153 L167,,"mrry,mrry,mrry,mrry",2017-06-22 21:10:43,2017-06-23 14:04:55
PR,Windows Fix CUDNN INSTALL PATH in configure,Convert CUDNN INSTALL PATH from path style like c tools cuda to c tools cuda Did not notice this before debugging because on CI we set CUDNN INSTALL PATH directly,,"meteorcloudy,zasdfgbnm",2017-06-23 14:54:47,2017-06-23 17:32:27
IS,tf TensorArray stack name aname bug,System information Code Interpreter Notice the print out is stackme stackme 0 instead of stackme 0 This is a really minor error But I had spent at least half an hour wondering why my operation was called twice Would be really nice to be fixed OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 1 0 rc0 61 g1ec6ed5 1 1 0,,tatatodd,2017-06-21 20:30:44,2017-06-23 18:07:41
IS,Not able to import tensorflow,Os Windows 10 Python version 3 5 2 Installed the CPU only version of TensorFlow and via native pip not anaconda succesfully installed tensorflow But while importing tensorflow below error is coming import tensorflow as tf Traceback most recent call last File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Santanu AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Santanu AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File pyshell 2 line 1 in module import tensorflow as tf File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Santanu AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Santanu AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Santanu AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help How to resolve this,,tatatodd,2017-06-22 11:25:04,2017-06-23 18:22:22
IS,TensorArray name using a Tensor,System information python version 'v1 2 0 rc1 24 gce1d6ec' '1 2 0 rc2' Describe the problem Looks like the name of the TensorArray is a Tensor and that Tensor is being treated as a boolean in a call to name scope Source code logs,,,2017-06-23 19:23:50,2017-06-23 19:28:18
IS,TF AddGradients incorrectly reports Add has no gradient,System information OS X with a CPU libtensorflow so built off master 2336cdf Describe the problem TF AddGradients reports,,"asimshankar,suharshs,suharshs",2017-06-23 02:35:56,2017-06-23 19:51:58
IS,provide project ide setting support,I'm trying to debug the c source code to figure out the function call relation But I find it is very difficult to import the code to any existing ide on Mac I had to use the bazel command to build and test using gdb to debug is a bit frustrating If there are some useful tool chains would you please give some tips which will make it easily for developers to try such great tensorflow Thanks so much,,tatatodd,2017-06-23 09:37:41,2017-06-23 19:59:51
IS,Install tensorflow with virtualenv failed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary with virtualenv TensorFlow version use command below 1 2 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce virtualenv system site packages p python3 tensorflow Describe the problem On my Ubuntu 16 04 I'm trying to install tensorflow with virtualenv for python3 under the guide of But I got the error message at the step2 virtualenv system site packages p python3 tensorflow Running virtualenv with interpreter usr local anaconda3 bin python3 Using base prefix ' usr local anaconda3' New python executable in home lab tensorflow bin python3 Also creating executable in home lab tensorflow bin python home lab tensorflow bin python3 error while loading shared libraries libpython3 6m so 1 0 cannot open shared object file No such file or directory ERROR The executable home lab tensorflow bin python3 is not functioning ERROR It thinks sys prefix is ' home lab' should be ' home lab tensorflow' ERROR virtualenv is not compatible with this system or executable Notice that I have install anaconda3 Is anaconda3 incompatible with tensorflow or virtualenv Should I uninstall my anaconda3 before installing tensorflow Thanks to everybody first,,tatatodd,2017-06-23 12:11:26,2017-06-23 20:05:09
PR,Build Reduces build time for SYCL target,,,"lukeiwanski,benoitsteiner",2017-06-22 20:32:23,2017-06-23 21:44:32
IS,AttributeError module 'tensorflow' has no attribute 'constant',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,rohan100jain,2017-06-23 10:05:25,2017-06-23 22:49:52
IS,Adding new classes,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0rc2 Bazel version if compiling from source 0 5 0 CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I want to retrain the inception model with 1003 classes where the first 1000 classes are same as imagenet So I took with inception model and extracted the final layer weights and added 3 more columns to it I popped the final layer created another layer with 1003 classes and with the weights i have changed as the weights of first 1000 classes remains same as inception but while training the accuracy is starting from 0 which i did not expect What is going wrong Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,rohan100jain,2017-06-22 09:29:00,2017-06-23 23:14:10
IS,Please modify the tensorflow workspace bzl is eigen version to make Nvidia TX2 compilation successful,Hi all I just managed to compile Tensorflow 1 2 successfully in Nvidia TX2 Despite the patches made by this article the workspace bzl file needs to be modified to use the latest eigen version Specifically you need to change the following lines native new http archive name eigen archive urls sha256 ca7beac153d4059c02c8fc59816c82d54ea47fe58365e8aded4082ded0b820c4 strip prefix eigen eigen f3a22f35b044 build file str Label third party eigen BUILD to native new http archive name eigen archive urls sha256 the sha256 value you used to verify strip prefix eigen eigen 5a0156e40feb build file str Label third party eigen BUILD Since I'm not sure if the newest eigen works well in other platform I do not have confidence to ask for a PR I just post this issue in case some of you guys can not compile tensor flow 1 2 in nvidia TX2,,rohan100jain,2017-06-22 06:43:07,2017-06-23 23:16:30
PR,Fix issue template tensorboard issues link,Reported in 10975,,"tatatodd,tatatodd",2017-06-23 18:15:16,2017-06-23 23:34:14
IS,The issue template has an incorrect link,Ironically I think the issue template is wrong I presume that point 3 below is meant to point to the tensorboard repo issue tracker but as you can see it just points back to the main repo issue tracker Judging by the activity on that issue tracker perhaps this is on purpose but I doubt it 3 It should not be a TensorBoard issue Those go here 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Cheers,,"tatatodd,tatatodd",2017-06-22 09:23:43,2017-06-24 00:57:02
IS,bazel does not co operate with Ubuntu is update alternatives,System information TF 1 2 Ubuntu 17 04 on GCE CUDA 8 0 gcc 4 9 4 Describe the problem bazel fails to compile tensorflow when multiple versions of gcc are present and the default points to etc alternatives gcc Specifically it fails to find the C and C header files However all works well when configure is set to use usr bin gcc,,"caisq,tatatodd",2017-06-23 20:40:50,2017-06-24 01:04:05
PR,Update momentum py,fixed a typo in the documentation,,,2017-06-24 12:17:02,2017-06-25 00:51:52
PR,test session fix doc formatting,This is a blind fix following create local cluster example below See broken doc formatting here test session,,caisq,2017-06-24 07:56:49,2017-06-25 14:44:29
PR,fix get started custom model,Original file does not run because eval input fn is undefined,,caisq,2017-06-25 20:24:22,2017-06-26 00:17:35
IS,A custom model of Getting Started,In the section A custom model of Getting Started With TensorFlow on Tensorflow Website a custom model The eval input fn is not defined here,,,2017-06-26 02:40:29,2017-06-26 02:47:18
PR,Update documentation regarding ishape' parameters,These functions are documented to take lists but perfectly accept tuples Explicitly documented this case,,yifeif,2017-06-26 03:32:52,2017-06-26 06:12:45
PR,Update get started md,The eval input fn is not defined here,,yifeif,2017-06-26 02:53:08,2017-06-26 06:16:28
PR,Removed unnecessary row in estimators extension tutorial,,,"terrytangyuan,yifeif",2017-06-24 14:51:27,2017-06-26 06:22:52
PR,Adjust doc MNIST learning rate,The gradient descent learning rate specified in the MNIST beginner tutorial should be 0 5 instead of 0 05 to stay consistent with the actual code in the repo A learning rate of 05 will actually decrease accuracy Code in repo L59,,"pvaneck,yifeif,MarkDaoust",2017-06-23 23:52:23,2017-06-26 06:30:49
PR,Typo fix in Dataset API is README,,,,2017-06-23 08:27:40,2017-06-26 06:37:07
PR,docs add eval input fn in custom model code,,,yifeif,2017-06-23 09:36:36,2017-06-26 06:48:39
PR,Arbitrary dim for tile,Add arbitrary dim support for Tile Op,,"yanchen036,girving,girving,girving,girving,girving,girving,girving,girving,girving,girving,girving,girving,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,girving,girving,girving,girving,yanchen036,girving,girving,yanchen036,yanchen036,girving,girving,girving,yanchen036,yifeif,yanchen036,girving,girving,yanchen036,girving,yanchen036,girving,yanchen036,girving,girving,yanchen036,girving,girving,yanchen036,girving,drpngx,drpngx,drpngx",2017-06-17 05:36:22,2017-06-26 16:30:50
PR,Fix typos,This PR fixes some typos as as is is for for not not and are are,,"taehoonlee,yifeif",2017-06-26 01:10:54,2017-06-26 16:32:55
PR,Performance improvements for hessians,This PR improves the performance of hessians by using while loop instead of using a for loop in python This improves both the build time to create the graph and the evaluation time Full details are here image,,"tillahoffmann,yifeif,alextp",2017-06-19 18:11:26,2017-06-26 16:37:19
PR,Use native compute capabilities as default,Instead of using 3 5 and 5 2 would it be better to use compute capabilities of native GPUs,,"zasdfgbnm,gunan,zasdfgbnm,gunan,meteorcloudy,zasdfgbnm,zasdfgbnm,meteorcloudy,gunan",2017-06-22 20:04:00,2017-06-26 16:57:32
PR,Java equality semantics for Operation and Output,Add equals hashCode and toString for value objects Operation and Output Annotate these value objects for compile time validation,,"kbsriram,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,kbsriram,kbsriram,kbsriram,kbsriram,asimshankar,asimshankar,kbsriram,yifeif,asimshankar",2017-06-20 13:51:19,2017-06-26 17:19:37
PR,coerce dict keys to strings when sorting for python3 compat,When tensor dicts have heterogeneous key types python 3 blows up due to the way sorted is being used In python 2 you can sort dicts with heterogeneous types BTW I ran into this issue when using the train script in the new object detection model API,,drpngx,2017-06-25 04:44:07,2017-06-26 18:00:08
PR,python configure bzl Add python import library on Windows,When building a Python C C extension on Windows we need to link to the python import library v vs 85 aspx pythonXY lib eg C Program Files Anaconda3 libs python35 lib See Previously TensorFlow relies on Bazel adding L324 the python lib path C Program Files Anaconda3 libs into LIB environment variable the build will break after Bazel stop doing so To solve this problem we generate a python import lib rule Ideally it should be a cc library but when building a dll Bazel add WHOLEARCHIVE to python35 lib because it cannot tell it is a static library or import library they have the same extension lib This will cause a linking error As a workaround we put it into linkopts if python headers See more details at,,"meteorcloudy,meteorcloudy,meteorcloudy,gunan,meteorcloudy,meteorcloudy",2017-06-22 11:41:13,2017-06-26 19:26:13
IS,Bug tf version 1 2 dropout layer reject tensor type rate,version 1 2 The following code The same code run successfully on tf version 1 1 0 I check the documents are not changed keep prob A scalar Tensor with the same type as x The probability that each element is kept It accepts tensor so I guess this should be a bug,,"tatatodd,tatatodd,av8ramit,tatatodd",2017-06-23 09:09:00,2017-06-26 20:46:24
PR,Changed default evalution master to also use cluster information,When using the standard Estimator during evaluation in distributed setting a cluster spec was supplied I encountered the following error message In short The evaluation graph is looking for Variables on job localhost but they are on job ps as is intended To fix this I changed the default settings of placing the evaluation master on localhost to the same as for master This means that when instancing a RunConfig with no evaluation master given it will check if there is a cluster spec If so it will get the evaluation master based on the cluster spec This fixes the problem for me and leads to correct behaviour,,xiejw,2017-06-08 20:47:29,2017-06-26 20:48:39
IS,Feature Request How to Access Attention Weights of Attention Wrapper,OS macOS Sierra version 10 12 5 TensorFlow Version v1 2 0 rc2 21 g12f033d 1 2 0 This is a two part request related to tensorflow contrib seq2seq I would like the ability to visualize the attention weights of the AttentionWrapper but I'm hampered by the lack of examples and I'm struggling to infer the input for BahdanauAttention is call method is argument previous alignments First could someone clarify how to access the attention weights Second would it be possible to add some tool that visualizes the attention weights possibly to TensorBoard,,"aselle,ebrevdo",2017-06-26 20:55:10,2017-06-26 21:16:02
IS,seq2seq for dynamic length sequences,The seq2seq model is based on the static rnn what should I do if my sequence lengths is not known,,aselle,2017-06-18 23:20:18,2017-06-26 21:19:04
IS,ResourceExhaustedError OOM when allocating tensor with shape,The problem I try to compute a very costly loss function using FFT2D rolling of the tensor and neural network with 3 layers You can find the Python script here TestFFT2D 2 py My loss function is the sum of 448 terms Each of this term is computed with a rolling of the initial tensor FFT2D a multiply of two tensor and a IFFT2D That is why it is very costly and why it needs a lot of memory You can find the end of the error message here MemoryError txt Do you know why the GPU is not able to deal with a memory demanding code Do you know a way to avoid this error message even if we need to pay a computing time cost Do you think I need to do a feature request for a better management of the GPU memory System information Have I written custom code TestFFT2D py OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from Source TensorFlow version 1 2 CUDA cuDNN version Cuda compilation tools release 7 5 V7 5 17 and cuDNN 5 with the GeForce GTX 680 GPU model and memory Tested on GeForce GTX 680 with 2Go Python version Python 3 6 1 Anaconda 4 4 0 64 bit Exact command to reproduce python TestFFT2D 2 py,,aselle,2017-06-19 12:34:13,2017-06-26 21:23:44
PR,Non determinism Docs 2732,Fixes Wrote a short tutorial on non determinism in TensorFlow due to GPU reductions,,"zheng-xq,ekelsen,ekelsen,drpngx,ekelsen,ekelsen",2017-06-11 17:27:22,2017-06-26 21:46:48
PR,XLA Add a unary ops cosine test to the standard tests,Add an XLA cosine python test,,"DavidNorman,yifeif,DavidNorman,DavidNorman,DavidNorman,drpngx,DavidNorman,DavidNorman,tatatodd",2017-06-23 14:22:54,2017-06-26 22:14:21
PR,variable name change and documentation clarification,Addressing 9927,,"jalammar,caisq,drpngx,jalammar,drpngx,drpngx,drpngx,jalammar,drpngx,jalammar",2017-06-25 22:30:03,2017-06-26 22:17:48
PR,Allow 1 0 to be compatible with tf bool,This fix tries to address the issue raised in 5407 where will raise an exception of type mismatch This fix updated the AssertCompatible so that 1 0 is compatible with tf bool types Additional test cases have been added This fix fixes 5407 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,drpngx,martinwicke",2017-06-13 16:31:34,2017-06-26 23:02:48
PR,Expose TFRecordWriter Flush in Python,This fix tries to address the issue raised in 10644 where it was not possible to call TFRecordWriter Flush in Python The C interface already has the Flush so this fix exposes it to python level This fix is related to 10644 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,martinwicke,yongtang,drpngx,martinwicke,drpngx",2017-06-13 19:17:22,2017-06-26 23:10:27
PR,added blocks option for lstm2d,,,"lukaszkaiser,lukaszkaiser,lukaszkaiser,lukaszkaiser,drpngx",2017-06-14 07:29:13,2017-06-26 23:13:13
PR,Update WorkerCacheLogger RecordRecvTensor,Update WorkerCacheLogger RecordRecvTensor to let future improvements to tracing tools Add a placeholder for more details about a RecvTensor call Custom title to possibly distinguish between control and data flow RecvTensor calls,,"mrry,mrry,drpngx",2017-06-22 09:17:45,2017-06-26 23:15:42
PR,bugfix summaries variable was undefined,The definition of var summaries was missing in the first code example,,"drpngx,drpngx,drpngx",2017-06-26 07:55:13,2017-06-26 23:16:03
PR,Support specify the user name when writing data to HDFS You can spec,When I write data to HDFS I can not specify username This scenario is used by multiple users using the same client as a local user You can specify the environment variable TF HDFS USER to modify the username e g export TF HDFS USER username,,"yifeif,drpngx,drpngx",2017-06-23 10:21:31,2017-06-27 06:31:35
IS,Error building bazel gcc unrecognized option ' no canonical prefixes',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Description SUSE Linux Enterprise Server 11 x86 64 TensorFlow installed from source or binary source TensorFlow version use command below master branch Bazel version if compiling from source 0 5 1 CUDA cuDNN version 7 5 GPU model and memory Tesla K20Xm Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures Describe the problem Ca not build bazel Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem screen shot 2017 06 24 at 7 49 54 pm,,skye,2017-06-24 10:54:06,2017-06-27 16:03:16
IS,Update logging in DNNClassifier to use tf summary scalar,System information I am using the stock DNNClassifier in contrib learn The warning is present in every instance where DNNClassifier is called Present in OSX Mac OS 10 12 5 and Linux Ubuntu 16 04 TensorFlow installed from source or binary Present both on binary and when compiled from source TensorFlow version use command below v1 2 0 release and v1 2 0 1371 g97af82d53 1 2 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Call the DNN classifier as indicated in Describe the problem A warning for a deprecated feature is cluttering the logs when using the DNNClassifier It is due to the use of the deprecated feature scalar summary while logging While this has been deprecated in 2016 11 30 it is still used in tensorflow contrib learn python learn estimators head py 642 This bug report request for updating the the current tf summary scalar as indicated The usability of the product is much improved as a consequence Logs,,"skye,ispirmustafa",2017-06-25 14:59:04,2017-06-27 16:24:12
IS,what is the different between tf sub a b and a b if i can Subsitute each other,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,skye,2017-06-26 09:07:05,2017-06-27 16:24:17
IS,tensorboard display nothing after update to v1 2 0,I update to tensorflow 1 2 0 by building from source after that tensorboard show nothing Is the tensorboard changed I use command tensorboard logdir log,,"zasdfgbnm,skye,dandelionmane",2017-06-24 17:51:13,2017-06-27 18:27:54
PR,Fix for contrib layers test that was raising an IndexError,Following the discussion at Running the This seems to be due to inconsistent behaviour from numpy nonzero when operating on an array of over 4 dimensions Reducing the size of the array in the test seems to eliminate the problem Note As the problem would only arise in some test runs and not others It is important that this commit be tested several times to ensure elimination of the issue,,"jalammar,drpngx,drpngx",2017-06-27 01:37:10,2017-06-27 20:07:05
IS,Gradient of reduce prod does not support negative axis,The gradient of reduce prod does not support negative axis unlike reduce prod itself It is apparently caused by gather not supporting negative axes This code illustrates the problem,,"tatatodd,tatatodd,ebrevdo,tatatodd,AnishShah,ebrevdo,AnishShah,AnishShah,AnishShah",2017-06-19 20:46:21,2017-06-27 20:34:04
PR,Negative axis support for gradient of reduce prod,Fixes 10835,,"AnishShah,AnishShah,drpngx,AnishShah,drpngx,AnishShah,drpngx",2017-06-23 19:08:53,2017-06-27 20:34:04
PR,1 2 1 PR,Patch release PR Updating versions to 1 2 1 Updating the release notes Updating markdown version Patching Github issue 11005,,"av8ramit,gunan,av8ramit",2017-06-27 20:41:35,2017-06-27 21:37:24
PR,Fixed some warnings related to signed unsigned comparison,This fix tries to fix some warning related to by address some easy fix in changing int size t in case of loop index This fix is related to 10838 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,yongtang,drpngx",2017-06-27 18:36:20,2017-06-28 00:00:27
PR,Fix import in documentation documentation,,,"martinwicke,MarkDaoust,drpngx",2017-06-27 16:18:29,2017-06-28 00:49:37
IS,Checkpoint restore problem with version 1 1 0,saving import tensorflow as tf v1 tf Variable 1 2 3 name v1 v2 tf Variable 4 5 6 name v2 init op tf global variables initializer saver tf train Saver with tf Session as sess sess run init op save path saver save sess home abc Documents tensorflow tmp model ckpt print Model saved in file s save path restore v1 tf Variable 1 1 1 name v1 v2 tf Variable 1 1 1 name v2 saver tf train Saver with tf Session as sess saver restore sess home abc Documents tensorflow tmp model ckpt print Model restored print sess run v1 NotFoundError Key v1 5 not found in checkpoint Node save 4 RestoreV2 4 RestoreV2 dtypes DT INT32 device job localhost replica 0 task 0 cpu 0 recv save 4 Const 0 save 4 RestoreV2 4 tensor names save 4 RestoreV2 4 shape and slices Caused by op isave 4 RestoreV2 4' defined at File home abc conda envs tfenv lib python3 5 runpy py line 193 in run module as main main mod spec File home noor conda envs tfenv lib python3 5 runpy py line 85 in run code exec code run globals File home abc conda envs tfenv lib python3 5 site packages ipykernel launcher py line 16 in module app launch new instance File home abc conda envs tfenv lib python3 5 site packages traitlets config application py line 658 in launch instance app start,,,2017-06-28 03:28:22,2017-06-28 03:38:52
IS,something wrong with attentionwrapper,I am trying to write a seq2seq model with attention But it gets the following error cell inputs self cell input fn inputs state attention AttributeError 'tuple' object has no attribute 'attention' It seems the state which initialize by the encoder state that does't has the attribute 'attention' How should I call AttentionWrapper Here is my code cell list for layer i in xrange hps num layers cell list append tf contrib rnn LSTMCell hps num hidden with tf variable scope 'encoder d' layer i cell list append tf contrib rnn LSTMCell hps num hidden enc cell tf contrib rnn MultiRNNCell cell list encoder outputs encoder state tf contrib rnn static rnn enc cell enc inp dtype dtype cell list for layer i in xrange hps num layers with tf variable scope wouldecoder d' layer i cell list append tf contrib rnn LSTMCell hps num hidden dec cell tf contrib rnn MultiRNNCell cell list new enc out tf reshape encoder outputs hps batch size 30 256 attn mech tf contrib seq2seq BahdanauAttention num units 128 depth of query mechanism memory new enc out hidden states to attend output of RNN normalize False normalize energy term name 'BahdanauAttention' attn cell tf contrib seq2seq AttentionWrapper cell dec cell Instance of RNNCell attention mechanism attn mech Instance of AttentionMechanism name attention wrapper if hps mode train TrainingHelper does no sampling only uses inputs helper tf contrib seq2seq TrainingHelper inputs dec inp decoder size decoder inputs sequence length 1 decoder size decoder input length name decoder training helper decoder tf contrib seq2seq BasicDecoder cell attn cell helper helper A Helper instance initial state encoder state initial state of decoder output layer None instance of tf layers Layer like Dense decoder outputs final state tf contrib seq2seq dynamic decode decoder,,skye,2017-06-27 07:33:11,2017-06-28 08:26:19
IS,Keras Dropout layer changes results with dropout 0 0,I am using the current version pypi 1 2 0 but also found this problem in the master I compiled about two weeks ago I am running Gentoo linux and tensorflow is installed in an virtualenv Maybe I am misunderstanding the concept of a dropout layer but when I add a Dropout Layer with 0 dropout it still alters my results from reuters classification example,,tatatodd,2017-06-20 12:59:07,2017-06-28 10:12:18
PR,Feature implement setAttrStringList method in Operation Builder with java api,Implement setAttrStringList method in Operation Builder with java api,,,2017-06-28 10:46:13,2017-06-28 10:54:43
PR,change an error in annotation,there is an error in annotation of ops py in tensorflow tensorflow python ops I think it is just a spelling mistake,,caisq,2017-06-28 12:13:24,2017-06-28 13:22:15
PR,Fix some typos in doc strings of Conv3D of keras,,,"Kongsea,drpngx,drpngx",2017-06-27 08:37:22,2017-06-28 13:29:29
IS,What is the possible substitute of cc ops for android mobile environment,OS Ubuntu 16 04 64bits Android Version 7 1 Nougat NDK Version android ndk r12b Development develop shared library that exposes op is to NDK CPP application I am aware that there is no explicit support for cc ops on android mobile env I am using few methods in my application I am not sure whether libtensorflow inference so can be used with this Is there any possible substitute for above op is in android mobile please provide pointers thanks,,andrewharp,2017-06-28 14:01:11,2017-06-28 15:43:33
PR,Fix typos,This PR fixes some typos to to of of that that and this this,,"taehoonlee,caisq",2017-06-28 06:46:32,2017-06-28 15:50:38
IS,How can i use saved model api to save chatbot model,Rencently i train a chatbot model based on seq2seq model but i failed to save the model use saved model api So i wonder to know where i can get some demo about this task,,asimshankar,2017-06-28 11:33:19,2017-06-28 16:00:03
PR,minor fix to TF slim README,Removing duplicated parameter in TensorFlow Slim documentation,,,2017-06-28 16:54:23,2017-06-28 17:42:57
PR,Branch 160346151,,,"yifeif,yifeif,yifeif,yifeif,drpngx,drpngx",2017-06-28 00:09:49,2017-06-28 18:07:45
PR,Fix broken link in programmers guide embedding md,This fix fixes broken link in programmers guide embedding md tensorflow tensorboard tensorflow contrib tensorboard Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx",2017-06-28 10:37:28,2017-06-28 18:10:03
PR,Fix 10823 moving vlog to higher level,This PR contains fix for moving VLOG level to higher level as specified in the issue VLOG is moved to level 3 as suggested in the comments,,drpngx,2017-06-27 13:10:36,2017-06-28 18:12:45
IS,Excessive chatter in VLOG 1,IMO tensorflow core framework op cc 82 is rather a chatty and specific output to be included at VLOG 1 Could it be changed to VLOG 2 or better still VLOG 3 one person is useful output is 100 is of peoples noise,,"DavidNorman,byronyi,vincentvanhoucke",2017-06-19 12:06:00,2017-06-28 18:13:08
PR,extract common functions,1 extract common function ComputeStride which used both in Transpose and Tile ops 2 merge same code in Transpose related to and,,"yanchen036,drpngx",2017-06-28 16:22:48,2017-06-28 18:52:09
PR,Fix to TensorFlow Slim README,Same TF Slim README fix as earlier today This is a resubmit with my email added to git config to pass your CLA check,,"drpngx,drpngx,drpngx,drpngx",2017-06-28 17:46:35,2017-06-28 19:08:51
PR,Bug fixes to input function tutorial,I tried running this example today and hit a few issues This PR fixes the issues I found DNNRegressor is located within tf contrib learn DNNRegressor not tf estimator DNNRegressor the method train does not exist it is fit returning p instead of p 'predictions' With the above fixes I was able to get the example running as expected,,"drpngx,MarkDaoust",2017-06-28 09:05:10,2017-06-28 20:02:44
PR,fix link in README md in Using TensorFlow via Docker,correctly link parameterized docker build sh to its actual location instead of README md,,caisq,2017-06-28 19:41:13,2017-06-28 21:11:02
IS,Link to README md is broken in NativeLibrary java,I'm trying to run TensorFlow in Java following this instructions I'm using Ubuntu 16 and java 8 I'm not sure what did I wrong but error message says java cp libtensorflow 1 2 0 jar Djava library path jni HelloTF Exception in thread main java lang UnsatisfiedLinkError Cannot find TensorFlow native library for OS linux architecture x86 64 See for possible solutions such as building the library from source at org tensorflow NativeLibrary load NativeLibrary java 66 at org tensorflow TensorFlow init TensorFlow java 36 at org tensorflow TensorFlow clinit TensorFlow java 40 at org tensorflow Graph clinit Graph java 194 at HelloTF main HelloTF java 8 But following gets 404 page not found,,"asimshankar,tatatodd,tatatodd,asimshankar",2017-06-23 16:09:45,2017-06-28 23:34:13
PR,Adding Swift Language Bindings,Supports Swift 3 1 4 0 on both macOS Ubuntu Linux with full documentation and example,,"drpngx,drpngx",2017-06-27 04:31:02,2017-06-28 23:46:50
IS,RDMA transport should support variable sized tensor,RDMA transport disabled variable size tensor L738 and L759 However in the embedding lookup model the tensor has variable size It is a common model parallelism case,,"llhe,llhe,llhe",2017-06-14 12:51:02,2017-06-29 00:42:50
PR,Allow variable sized tensor for RDMA transport,This PR fixes Q Should we make aggressive buffer extension,,"llhe,drpngx,drpngx,drpngx,drpngx,drpngx",2017-06-14 12:55:17,2017-06-29 00:42:50
PR,Remove implicit iteration from third party toolchains cpu CROSSTOOL,Bazel will stop supporting implicit iteration soon and will require explicit 'iterate over' message This cl updates the only affected Tensorflow crosstool,,"drpngx,drpngx",2017-06-28 13:59:37,2017-06-29 01:07:49
PR,fixing a single typo,,,drpngx,2017-06-28 11:32:48,2017-06-29 01:08:00
PR,Update sample distorted bounding box to use Tensor Input for min object covered,This fix tries to address the issue raised in 10715 where it was not possible to use dynamic values for min object covered in sample distorted bounding box This fix created an Op of SampleDistortedBoundingBoxV2 so that min object covered takes input SampleDistortedBoundingBox remains the same min object covered as attr Additional test cases have been added Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,martinwicke,vrv,drpngx,martinwicke,martinwicke,drpngx,drpngx,drpngx,drpngx,vrv,yongtang,yongtang,yongtang,yifeif,yongtang,vrv,drpngx,yongtang,drpngx,drpngx,yongtang,drpngx,yongtang,yongtang,drpngx,yongtang,drpngx",2017-06-20 01:44:24,2017-06-29 02:59:49
PR,Java Add support for list string attributes in OperationBuilder,Feature implement setAttrStringList method in Operation Builder with Java api,,"asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,drpngx,asimshankar",2017-06-28 11:23:30,2017-06-29 03:00:13
PR,Implements inverse hyperbolic operations fix for 7531,fixes 7531,,"lakshayg,drpngx,lakshayg,lakshayg,caisq,lakshayg,rmlarsen,lakshayg,martinwicke,martinwicke,lakshayg,martinwicke,lakshayg,martinwicke,martinwicke,lakshayg,lakshayg,rmlarsen,lakshayg,lakshayg,rmlarsen,lakshayg,rmlarsen,rmlarsen,lakshayg,rmlarsen,lakshayg,rmlarsen,rmlarsen,rmlarsen,lakshayg,rmlarsen,jhseu,lakshayg,jhseu,rmlarsen,drpngx,martinwicke,gunan,drpngx,lakshayg,drpngx",2017-06-09 15:00:46,2017-06-29 03:00:52
IS,error running object detection samples TypeError unorderable types tuple str,I cannot run any of the examples from the new object detection api I followed the documented prepare inputs and run locally but when I run the below command I get the following error python3 train py pipeline config path home chris tensorflow models object detection samples configs ssd inception v2 pets config train dir Traceback most recent call last File train py line 199 in module tf app run File usr local lib python3 5 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File train py line 195 in main worker job name is chief FLAGS train dir File home chris tensorflow models object detection trainer py line 184 in train data augmentation options File home chris tensorflow models object detection trainer py line 77 in create input queue prefetch queue capacity prefetch queue capacity File home chris tensorflow models object detection core batcher py line 93 in init num threads num batch queue threads File usr local lib python3 5 dist packages tensorflow python training input py line 924 in batch name name File usr local lib python3 5 dist packages tensorflow python training input py line 698 in batch tensor list as tensor list tensors File usr local lib python3 5 dist packages tensorflow python training input py line 386 in as tensor list return tensors k for k in sorted tensors TypeError unorderable types tuple str I get the feeling this error is because it is not processing the record file correctly or something along those lines is wrong However as far as I can tell I followed everything correctly I edited the paths in the config file and triple checked that they point to real files,,,2017-06-27 08:03:27,2017-06-29 09:45:25
PR,Add bazel build configs for cpu type 'x64 windows msvc',Without this fix the final generated whl file will contain a ' pywrap tensorflow internal so' instead of ' pywrap tensorflow internal pyd',,"snnn,meteorcloudy,snnn",2017-06-29 05:42:56,2017-06-29 12:24:46
PR,Added initial support to ROCm,1 Changed configure to ask for enabling ROCm if XLA is enabled 2 Changed bazel rc so that bazel config can take rocm as a value,,"drpngx,drpngx",2017-06-20 18:38:02,2017-06-29 13:37:34
IS,No module named ' pywrap tensorflow internal',ImportError Traceback most recent call last D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py in swig import helper 17 try 18 return importlib import module mname 19 except ImportError D Users laiyi Anaconda3 lib importlib init py in import module name package 125 level 1 126 return bootstrap gcd import name level package level 127 D Users laiyi Anaconda3 lib importlib bootstrap py in gcd import name package level D Users laiyi Anaconda3 lib importlib bootstrap py in find and load name import D Users laiyi Anaconda3 lib importlib bootstrap py in find and load unlocked name import D Users laiyi Anaconda3 lib importlib bootstrap py in load unlocked spec D Users laiyi Anaconda3 lib importlib bootstrap py in module from spec spec D Users laiyi Anaconda3 lib importlib bootstrap external py in create module self spec D Users laiyi Anaconda3 lib importlib bootstrap py in call with frames removed f args kwds ImportError DLL load failed During handling of the above exception another exception occurred ModuleNotFoundError Traceback most recent call last D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow py in module 40 sys setdlopenflags default dlopen flags ctypes RTLD GLOBAL 41 from tensorflow python pywrap tensorflow internal import 42 from tensorflow python pywrap tensorflow internal import version D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py in module 20 return importlib import module ' pywrap tensorflow internal' 21 pywrap tensorflow internal swig import helper 22 del swig import helper D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py in swig import helper 19 except ImportError 20 return importlib import module ' pywrap tensorflow internal' 21 pywrap tensorflow internal swig import helper D Users laiyi Anaconda3 lib importlib init py in import module name package 125 level 1 126 return bootstrap gcd import name level package level 127 ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred ImportError Traceback most recent call last ipython input 1 a649b509054f in module 1 import tensorflow D Users laiyi Anaconda3 lib site packages tensorflow init py in module 22 23 pylint disable wildcard import 24 from tensorflow python import 25 pylint enable wildcard import 26 D Users laiyi Anaconda3 lib site packages tensorflow python init py in module 47 import numpy as np 48 49 from tensorflow python import pywrap tensorflow 50 51 Protocol buffers D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow py in module 50 for some common reasons and solutions Include the entire stack trace 51 above this error message when asking for help traceback format exc 52 raise ImportError msg 53 54 pylint enable wildcard import g import not at top unused import line too long ImportError Traceback most recent call last File D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File D Users laiyi Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File D Users laiyi Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File D Users laiyi Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,,2017-06-29 14:15:59,2017-06-29 15:06:56
PR,Fix typos,This PR fixes some typos succesfully optimzations unecessary accross trainning beacuse and dont,,"taehoonlee,caisq",2017-06-29 05:01:08,2017-06-29 16:42:14
IS,Parameter server of distributed Tensorflow computes unexpected training operations when using Estimator,Hi I am trying to use multi GPUs for the Google is seq2seq training through distributed Tensorflow data parallelism I launched a parameter server PS and three worker processes on a machine equipped with 4 GPUs I have each process including PS to run on separate GPU through the CUDA VISIBLE DEVICES I successfully trained the model faster than the single node version however I noticed a weird behavior The way of enabling data parallelism was to set the ClusterConfig like below ps hosts worker hosts job name and task index are given as program arguments ps hosts FLAGS ps hosts split worker hosts FLAGS worker hosts split cluster ps ps hosts worker worker hosts os environ 'TF CONFIG' json dumps 'cluster' cluster 'task' 'type' FLAGS job name 'index' FLAGS task index config run config RunConfig estimator tf contrib learn Estimator config config experiment tf contrib learn Experiment estimator estimator learn runner run experiment experiment I profiled the training of this machine using nvprof and noticed that the parameter server process also uses its GPU for training I looked into the device placement log messages and there is no MatMul ops associated with the job ps but for some reason GPU calls many gemm calls I think this issue is not specific to GPU because I also ran the same experiment with PS mapped to CPU but the PS also computes training operations Is there anybody else who has experienced this Is this the Estimator is bug get replica device setter L201 seems to pass job ps task d as worker device and maybe this makes this problem I also thought about the possibility that I did something wrong in deploying distributed Tensorflow but as mentioned earlier the model is trained successfully with higher performance so I am confused if this is a bug or a feature I would really appreciate any feedback comments help Please let me know if I am misunderstanding anything,,,2017-06-29 16:33:37,2017-06-29 16:53:37
IS,Error with building clang unknown argument,I configured project for building and execute next command in project directory bazel build c opt config cuda tensorflow cc tutorials example trainer After that i get this error ERROR home eugeny Git tensorflow tensorflow core kernels BUILD 3614 1 C compilation of rule ' tensorflow core kernels multinomial op gpu' failed clang failed error executing command usr bin clang MD MF bazel out local linux py3 opt bin tensorflow core kernels objs multinomial op gpu tensorflow core kernels multinomial op gpu cu d remaining 142 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 clang error unknown argument ' nvcc options relaxed constexpr' clang error unknown argument ' nvcc options ftz true' clang error cannot find libdevice for sm 35 Provide path to different CUDA installation via cuda path or pass nocudalib to build without linking with libdevice clang error cannot find CUDA installation Provide its path via cuda path or pass nocudainc to build without CUDA includes clang error cannot find libdevice for sm 52 Provide path to different CUDA installation via cuda path or pass nocudalib to build without linking with libdevice clang error cannot find CUDA installation Provide its path via cuda path or pass nocudainc to build without CUDA includes clang error cannot find CUDA installation Provide its path via cuda path or pass nocudainc to build without CUDA includes Target tensorflow cc tutorials example trainer failed to build I'm trying to build it with gpu support by using next libs Bazel 0 5 1 gcc 7 1 1 Cuda 8 version of cuda bin gcc is 5 4 0 CUDNN 6 protobuf 3 3 1 What shall i change for normal building,,"skye,gunan,gunan,gunan,gunan,ilya-biryukov,ilya-biryukov,skye,skye,ilya-biryukov",2017-06-25 16:10:49,2017-06-29 18:17:28
PR,Fix for contrib layers test that was raising an IndexError 11069,variable name change and documentation clarification Updated a test to eliminate an error it raises,,av8ramit,2017-06-29 17:37:54,2017-06-29 18:19:07
PR,WIP Multi bus support with NUMA aware allocator,As the title suggests this is a WIP to partially address issues brought by in 5986 In our testbed we have a multi bus topology where 4 K40m GPUs are connected by different PCI e root as shown with the following command Current TF always allocates the host memory used to transfer from to GPU on NUMA node 0 which is sub optimal for GPUs with other CPU affinity This could be further validated by adjusting CUDA VISIBLE DEVICES and numactl m numa node N numa node prepended to TF process The basic idea is simple use numa alloc onnode and other related functions available in libnuma to allocate memory for CUDA host allocator There are some pieces of code e g here L669 there L951 and there L855 to identify bus id and numa node for each device and I plan to reuse those as much as possible I am wondering if anyone in the TF team could give me some advice so I can start to implement it,,"byronyi,byronyi,drpngx,byronyi,byronyi,byronyi,reedwm",2017-06-11 07:25:55,2017-06-29 18:42:07
IS,Batch normalization layer has new name for each call to init,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX 10 12 5 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 1 0 CUDA cuDNN version no GPU Exact command to reproduce,,"skye,fchollet",2017-06-28 08:45:32,2017-06-29 20:06:10
IS,how use tensorflow model in optimization model,hi i know how to save restore and feed a tensorflow model but how can i use tf model in optimization model like the genetic algorithm python deep package my problem is in transforming convert tf value to python if I want to use python variable sess run tf variable or python variable tf variable eval for each population genetic run I should initialize sess and this process is very time consuming what is the solution is there any better solution or tensorflow have any optimization algorithm,,skye,2017-06-29 08:06:26,2017-06-29 23:54:34
PR,Branch 160538962,,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-06-29 18:03:30,2017-06-30 00:18:46
PR,np float64 np inf astype np int32 is negative on x86 but positive on ppc64le,np float64 np inf astype np int32 is negative on x86 but positive on ppc64le that is the reason we added this special case for ppc64le Discussed with numpy community and they mentioned as follows 1 Doing this cast incurs undefined behaviour so it is hard to say which platform is incorrect here I would argue that we should just issue a warning and leave the platform specific behaviour 2 This is also true of any C program that tries to cast float to int If the author of a python package included a C extension that does this cast they still have the problem The same argument you use for we should fix this is numpy not in the user package can be applied to we should fix this in C not in numpy Presumably for speed reasons that argument was rejected during the design of C Having said that we already diverge from C behaviour in some place eg integer promotion for arithmetic and comparison so it would not be unreasonable to add special casing here Numpy link to relevant discussion Also discussed this on Tensorflow link to relevant discussion,,"sandipmgiri,drpngx,drpngx,sandipmgiri,sandipmgiri,martinwicke,sandipmgiri,sandipmgiri,drpngx,drpngx",2017-06-08 08:46:11,2017-06-30 00:19:15
PR,Printdhruv patch 2,Update ISSUE TEMPLATE md,,drpngx,2017-06-29 22:06:47,2017-06-30 00:19:50
PR,Fix typos,,,"Kongsea,drpngx",2017-06-29 01:26:45,2017-06-30 00:20:19
PR,Updating release md,,,av8ramit,2017-06-30 01:32:53,2017-06-30 01:34:25
IS,Problem with operating system allocated ports in distributed Tensorflow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes simple test case to reproduce OS Platform and Distribution e g Linux Ubuntu 16 04 Reproduced on Ubuntu 16 04 1 and MacOS Sierra 10 12 5 TensorFlow installed from source or binary Binary TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See source code below Describe the problem When using operating system allocated ports specifying port zero in the cluster spec distributed Tensorflow seems to wait forever with the message CreateSession still waiting for response from worker job ps replica 0 task 0 when initializing variables on the parameter server The same code works fine with explicitly allocated ports See below for code to reproduce the issue Source code logs This code works fine above which may indicate the source of the problem,,"skye,saeta",2017-06-27 09:33:12,2017-06-30 01:42:04
PR,Add Sublime Tensorflow project in welcome md,Sublime Tensorflow is a Sublime Text plugin It offers you Autocompletion from a list scrapped from official Tensorflow API documentation Shortcut to check the official doc,,"drpngx,drpngx",2017-06-29 08:52:08,2017-06-30 01:48:53
PR,Make consistent author information format,This PR makes formatting consistent All the other formats for author information are described as et al not et al,,"taehoonlee,drpngx,drpngx",2017-06-29 04:35:57,2017-06-30 01:49:23
PR,Make TensorFlow build with wrapper free MSVC CROSSTOOL,With the latest Bazel release 0 5 2 we can now build C code on Windows without the python wrapper scripts This gives faster and more reliable build but gcc flags in BUILD file wo not be translated This change removes gcc flags mostly warning flags that will cause an error if passed to cl exe The protobuf change is to get not sure if there is a requirement to use release version of protobuf,,"meteorcloudy,meteorcloudy,drpngx,gunan,gunan,meteorcloudy,jhseu,meteorcloudy,gunan,meteorcloudy",2017-06-28 15:18:43,2017-06-30 02:47:31
IS,GTX 1080 Ti Cuda Launch Failed,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 1 0 rc2 9 gb7f85a7' '1 1 0 rc1' Bazel version if compiling from source Bazel Release 0 5 0 CUDA cuDNN version Cuda 8 0 cuDNN 8 0 GPU model and memory GTX 1080Ti 11GB memory Exact command to reproduce bazel bin inception flowers train train dir TRAIN DIR data dir DATA DIR pretrained model checkpoint path MODEL PATH fine tune True initial learning rate 0 001 input queue memory factor 2 You can collect some of this information using our environment capture script tf env txt You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request When fine tuning inception v3 model using the flowers data script on custom data during retraining I see the following error 2017 06 19 23 46 32 549857 step 5300 loss 1 40 61 9 examples sec 0 517 sec batch 2017 06 19 23 46 39 510009 step 5310 loss 1 43 64 2 examples sec 0 499 sec batch 2017 06 19 23 46 44 667435 step 5320 loss 1 55 64 3 examples sec 0 498 sec batch 2017 06 19 23 46 46 691129 E tensorflow stream executor cuda cuda driver cc 1067 could not synchronize on CUDA context CUDA ERROR LAUNCH FAILED No stack trace available 2017 06 19 23 46 46 691129 E tensorflow stream executor cuda cuda event cc 49 Error polling for event status failed to query event CUDA ERROR LAUNCH FAILED 2017 06 19 23 46 46 691162 F tensorflow core common runtime gpu gpu event mgr cc 203 Unexpected Event status 1 2017 06 19 23 46 46 691165 F tensorflow core common runtime gpu gpu util cc 370 GPU sync failed start image sh line 60 27406 Aborted core dumped bazel bin inception flowers train train dir TRAIN DIR data dir DATA DIR pretrained model checkpoint path MODEL PATH fine tune True initial learning rate 0 001 input queue memory factor 2 I changed the num classes and num examples per epoch as follows 7 def num classes self 8 Returns the number of classes in the data set 9 return 5 10 return 21 11 12 def num examples per epoch self 13 Returns the number of examples in the data subset 14 if self subset 'train' 15 return 3170 16 return 6342 17 if self subset 'validation' 18 return 500 19 return 1576 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"gunan,gunan,gunan,gunan",2017-06-20 15:32:28,2017-06-30 04:47:54
IS,How to run the program coding by python in the Android phone,I already wrote a pretrain vgg16 on my computer python Linux now I want to run this program using my android phone s CPU GPU the outcome could show in terminal However I cannot find any hint in this situation so I want some hint and hope you can update the Readme,,,2017-06-30 08:32:01,2017-06-30 10:08:13
IS,Only use weakref finalize from backports in Python 3 4,System information Arch Linux up to date TensorFlow installed from binary with pacman Arch package manager TensorFlow version 1 2 0 No GPU or CUDA Describe the problem tensorflow python util tf should use py is doing from backports import weakref introduced by cf238e1f2f68309822e1adb3f86dd439c0b87441 though I guess this is only useful for Python 2 In Python 3 we could simply import weakref This bug has been observed by other people and reported on the Arch Linux bug tracker Traceback,,,2017-06-27 12:39:44,2017-06-30 14:10:41
IS,having problem to identify porn images especaly with penises NO its not a joke,i m running a website where a mass on photos are uploaded upload without registration so i get aaaaa lot of penis trolls or whatever makes them post their private parts anyhow i tried to train inception model with tensorflow newest version 1 x so i made a folder with penises approx 160 pics and one with different images with person how dont show their penis approx 160 pics training accuracy is quit good over 90 but testing the model with other pictures it fails really bad on detecting penises hmmmm i know 160 pics are not that much for training but i thing the problem is guy on the beach in shorts is ok guy on the beach with penis lurking out of his pants is not okay but the difference is quite small between the pictures because a penis is mostly quite a small part of the human body so hard to detect anybody could help and no its sounds funny buts no joke i suffering under all the uploads i have to review manualy it is really not funny to see over 1000 penises a day cheers puck,,,2017-06-29 18:48:26,2017-06-30 15:35:55
PR,Windows Add missing source files declaration for Bazel build,Fix,,"meteorcloudy,gunan,meteorcloudy,meteorcloudy",2017-06-29 09:59:20,2017-06-30 17:23:48
IS,IOS Expected namespace tensorflow ops,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 OS X 10 11 6 TensorFlow installed from source or binary binary pip install TensorFlow version use command below 1 1 0 CPU Only Bazel version if compiling from source 0 4 5 Describe the problem I want to use pb file in IOS And I must use tensorflow ops reshape and tensorflow ops argmax api But when I add using namespace tensorflow ops I get a error Expected namespace name My TensorFlow experimental come from Pod How to add namespace tensorflow ops,,,2017-06-21 07:39:44,2017-06-30 17:31:09
IS,win7 64bit Anaconda tensorflow 1 2 0 chrome Tensorboard No scalar was found,I can not see any data It turned out to be No scalar was found when I run the tensorboard there is no error or warning Environment info Windows 7 64 bit Anaconda Python 3 5 Tensoflow installed from binary pip package tensorflow version 1 2 0 Browser Chrome 58 About the code I just run the example code mnist with summries py it is in D Anaconda Lib site packages tensorflow examples tutorials mnist mnist with summaries py What have you tried I can see a log file called events out tfevents in the folder I set The file is about 16Mb big I call tensorboard logdir tmp tensorflow mnist logs mnist with summaries debug and I can verify the log dir is correct On the browser I can not see any data or graph is shown If I call tensorboard inspect logdir tmp tensorflow mnist logs mnist with summaries It shows how the tfevent file contains,,,2017-06-21 04:52:38,2017-06-30 17:32:06
IS,control dependencies possibly broken,Hi all I have been playing with control dependencies in the latest stable version and I get different results to version 1 0 1 The code below is adapted from the TF Adam optimiser which might be affected as well The code I ran is suggesting that the control dependencies are not used as expected in version 1 2 0 Can anyone spot any mistakes in the way I use the control dependencies Cheers Yarin,,ppwwyyxx,2017-06-20 17:43:44,2017-06-30 17:48:57
IS,Support unknown dimension in tf SparseTensor,In doing development calling API tf SparseTensor on release 1 1 I got the following error It appears to be caused by unknown dimension batch which is present in n indices n val obj ref get shape Additionally I wonder if we could have a list of APIs not supporting unknown dimension,,,2017-06-20 16:57:55,2017-06-30 17:49:31
IS,attribute error when setting PredictionType MULTIPLE VALUE in Dynamic RNN Estimator,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-06-20 15:50:26,2017-06-30 17:51:15
IS,compiling tensorflow cc example example cc with error You must define TF LIB GTL ALIGNED CHAR ARRAY for your compiler in Windows 10 Visualstudio 2015,Hi I am newbie of tensorflow I wanna use tensorflow through C C api on visual studio 2015 I have built tensorflow library described in below link with Cmake after Cmake I tried to build tensorflow cc example example cc but occured error C1189 error You must define TF LIB GTL ALIGNED CHAR ARRAY for your compiler tensortest d temp tensorflow tensorflow core lib gtl manual constructor h 97 then failed to build example What is that mean and how to define TF LIB GTL ALIGNED CHAR ARRAY in Visualstudio 2015 thank you in advance GS GL analyze W3 Gy Zc wchar t I D temp tensorflow tensorflow contrib cmake build protobuf src protobuf src I D temp tensorflow I D temp tensorflow tensorflow contrib cmake build eigen src eigen I D temp tensorflow tensorflow contrib cmake build Zi Gm O2 sdl Fd Release vc140 pdb Zc inline fp precise D WIN32 D NDEBUG D CONSOLE D UNICODE D UNICODE errorReport prompt WX Zc forScope Gd Oy Oi MD Fa Release EHsc nologo Fo Release Fp Release tensortest pch,,,2017-06-20 12:56:54,2017-06-30 17:54:28
IS,tf cond should be evaluated lazily,It should be possible to statically analyze the following graph such that the execution of the one branch is stopped early if the other branch is determined to be chosen Am I missing some different function in TensorFlow that allows to do this Perhaps using control dependencies In the following code the identity matrix is multiplied many times and a placeholder threshold determines whether the second multiplication or the last is chosen as output of the graph Both runs take roughly the same time even though the second run only depend on the first two matrix multiplications at least if one accounts for the warm up phase which give the first run a slight disadvantage I hope I am not missing something obvious Thanks,,"aselle,yaroslavvb,yaroslavvb,yaroslavvb,yaroslavvb",2017-06-17 21:41:08,2017-06-30 18:11:07
PR,Merging 1 2 1 back into master,,,"av8ramit,drpngx,drpngx,av8ramit",2017-06-30 17:27:31,2017-06-30 18:32:34
PR,Adding support for s390x for boringssl,Adding support for s390x for boringssl through patched http archive rule,,"Nayana-ibm,gunan,drpngx,gunan,drpngx,Nayana-ibm,martinwicke,Nayana-ibm,gunan,Nayana-ibm",2017-06-30 08:34:19,2017-06-30 18:35:24
IS,ios compile failed checking whether the C compiler works no,pls help my config log file This file contains any messages produced by compilers while running configure to aid debugging if configure makes a mistake It was created by Protocol Buffers configure 3 2 0 which was generated by GNU Autoconf 2 69 Invocation command line was configure host i386 apple darwin14 0 0 disable shared enable cross compile with protoc Users jakie tensorflow master tensorflow contrib makefile gen protobuf host bin protoc prefix Users jakie tensorflow master tensorflow contrib makefile gen protobuf ios lib iossim 386 exec prefix Users jakie tensorflow master tensorflow contrib makefile gen protobuf ios lib iossim 386 CFLAGS DNDEBUG Os pipe fPIC fno exceptions mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk CXX CXXFLAGS DNDEBUG Os pipe fPIC fno exceptions std c 11 stdlib libc mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk LDFLAGS arch i386 fembed bitcode mios simulator version min 8 0 stdlib libc L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib system LIBS lc lc abi Platform hostname jakiedeMac local uname m x86 64 uname r 14 0 0 uname s Darwin uname v Darwin Kernel Version 14 0 0 Fri Sep 19 00 26 44 PDT 2014 root xnu 2782 1 97 2 RELEASE X86 64 usr bin uname p i386 bin uname X unknown bin arch unknown usr bin arch k unknown usr convex getsysinfo unknown usr bin hostinfo Mach kernel version Darwin Kernel Version 14 0 0 Fri Sep 19 00 26 44 PDT 2014 root xnu 2782 1 97 2 RELEASE X86 64 Kernel configured for up to 4 processors 4 processors are physically available 4 processors are logically available Processor type x86 64h Intel x86 64h Haswell Processors active 0 1 2 3 Primary memory available 8 00 gigabytes Default processor set 102 tasks 394 threads 4 processors Load average 2 19 Mach factor 1 88 bin machine unknown usr bin oslevel unknown bin universe unknown PATH usr local bin PATH usr bin PATH bin PATH usr sbin PATH sbin Core tests configure 2601 checking whether to enable maintainer specific portions of Makefiles configure 2610 result yes configure 2685 checking build system type configure 2699 result x86 64 apple darwin14 0 0 configure 2719 checking host system type configure 2732 result i386 apple darwin14 0 0 configure 2752 checking target system type configure 2765 result i386 apple darwin14 0 0 configure 2808 checking for a BSD compatible install configure 2876 result usr bin install c configure 2887 checking whether build environment is sane configure 2942 result yes configure 3001 checking for i386 apple darwin14 0 0 strip configure 3031 result no configure 3041 checking for strip configure 3057 found usr bin strip configure 3068 result strip configure 3093 checking for a thread safe mkdir p configure 3132 result install sh c d configure 3139 checking for gawk configure 3169 result no configure 3139 checking for mawk configure 3169 result no configure 3139 checking for nawk configure 3169 result no configure 3139 checking for awk configure 3155 found usr bin awk configure 3166 result awk configure 3177 checking whether make sets MAKE configure 3199 result yes configure 3228 checking whether make supports nested variables configure 3245 result yes configure 3334 checking whether UID '501' is supported by ustar format configure 3337 result yes configure 3344 checking whether GID '20' is supported by ustar format configure 3347 result yes configure 3355 checking how to create a ustar tar archive configure 3366 tar version bsdtar 2 8 3 libarchive 2 8 3 configure 3369 0 configure 3409 tardir conftest dir eval tar format ustar chf tardir conftest tar configure 3412 0 configure 3416 tar xf conftest tar configure 3419 0 configure 3421 cat conftest dir file GrepMe configure 3424 0 configure 3437 result gnutar configure 3515 checking for i386 apple darwin14 0 0 gcc configure 3545 result no configure 3555 checking for gcc configure 3571 found usr bin gcc configure 3582 result gcc configure 3811 checking for C compiler version configure 3820 gcc version 5 Apple LLVM version 6 1 0 clang 602 0 53 based on LLVM 3 6 0svn Target x86 64 apple darwin14 0 0 Thread model posix Configured with prefix Applications Xcode app Contents Developer usr with gxx include dir usr include c 4 2 1 configure 3831 0 configure 3820 gcc v 5 Configured with prefix Applications Xcode app Contents Developer usr with gxx include dir usr include c 4 2 1 Apple LLVM version 6 1 0 clang 602 0 53 based on LLVM 3 6 0svn Target x86 64 apple darwin14 0 0 Thread model posix configure 3831 0 configure 3820 gcc V 5 clang error argument to ' V' is missing expected 1 value clang error no input files configure 3831 1 configure 3820 gcc qversion 5 clang error unknown argument ' qversion' clang error no input files configure 3831 1 configure 3851 checking whether the C compiler works configure 3873 gcc DNDEBUG Os pipe fPIC fno exceptions mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk arch i386 fembed bitcode mios simulator version min 8 0 stdlib libc L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib system conftest c lc lc abi 5 clang error unknown argument ' fembed bitcode' clang error unknown argument ' fembed bitcode' configure 3877 1 configure 3915 result no configure failed program was confdefs h define PACKAGE NAME Protocol Buffers define PACKAGE TARNAME protobuf define PACKAGE VERSION 3 2 0 define PACKAGE STRING Protocol Buffers 3 2 0 define PACKAGE BUGREPORT protobuf googlegroups com define PACKAGE URL define PACKAGE protobuf define VERSION 3 2 0 end confdefs h int main return 0 configure 3920 error in Users jakie tensorflow master tensorflow contrib makefile downloads protobuf' configure 3922 error C compiler cannot create executables See config log' for more details Cache variables ac cv build x86 64 apple darwin14 0 0 ac cv env CCC set ac cv env CCC value ac cv env CC set ac cv env CC value ac cv env CFLAGS set set ac cv env CFLAGS value ' DNDEBUG Os pipe fPIC fno exceptions mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk' ac cv env CPPFLAGS set ac cv env CPPFLAGS value ac cv env CPP set ac cv env CPP value ac cv env CXXCPP set ac cv env CXXCPP value ac cv env CXXFLAGS set set ac cv env CXXFLAGS value ' DNDEBUG Os pipe fPIC fno exceptions std c 11 stdlib libc mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk' ac cv env CXX set set ac cv env CXX value ac cv env DIST LANG set ac cv env DIST LANG value ac cv env LDFLAGS set set ac cv env LDFLAGS value ' arch i386 fembed bitcode mios simulator version min 8 0 stdlib libc L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib system' ac cv env LIBS set set ac cv env LIBS value ' lc lc abi' ac cv env LT SYS LIBRARY PATH set ac cv env LT SYS LIBRARY PATH value ac cv env OBJCFLAGS set ac cv env OBJCFLAGS value ac cv env OBJC set ac cv env OBJC value ac cv env build alias set ac cv env build alias value ac cv env host alias set set ac cv env host alias value i386 apple darwin14 0 0 ac cv env target alias set ac cv env target alias value ac cv host i386 apple darwin14 0 0 ac cv path install ' usr bin install c' ac cv prog AWK awk ac cv prog ac ct CC gcc ac cv prog ac ct STRIP strip ac cv prog make make set yes ac cv target i386 apple darwin14 0 0 am cv make support nested variables yes am cv prog tar ustar gnutar Output variables ACLOCAL ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf missing aclocal 1 15' AMDEPBACKSLASH '' AMDEP FALSE '' AMDEP TRUE '' AMTAR ' TAR tar ' AM BACKSLASH ' ' AM DEFAULT V ' AM DEFAULT VERBOSITY ' AM DEFAULT VERBOSITY '1' AM V ' V ' AR '' AUTOCONF ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf missing autoconf' AUTOHEADER ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf missing autoheader' AUTOMAKE ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf missing automake 1 15' AWK 'awk' BUILD EXEEXT '' BUILD OBJEXT '' CC 'gcc' CCDEPMODE '' CC FOR BUILD '' CFLAGS ' DNDEBUG Os pipe fPIC fno exceptions mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk' CFLAGS FOR BUILD '' CPP '' CPPFLAGS '' CPPFLAGS FOR BUILD '' CPP FOR BUILD '' CXX '' CXXCPP '' CXXCPPFLAGS FOR BUILD '' CXXCPP FOR BUILD '' CXXDEPMODE '' CXXFLAGS ' DNDEBUG Os pipe fPIC fno exceptions std c 11 stdlib libc mios simulator version min 8 0 arch i386 fembed bitcode isysroot Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk' CXXFLAGS FOR BUILD '' CXX FOR BUILD '' CYGPATH W 'echo' DEFS '' DEPDIR '' DIST LANG 'all' DLLTOOL '' DSYMUTIL '' DUMPBIN '' ECHO C ' c' ECHO N '' ECHO T '' EGREP '' EXEEXT '' FGREP '' GCC FALSE '' GCC TRUE '' GREP '' HAVE CXX11 '' HAVE PTHREAD FALSE '' HAVE PTHREAD TRUE '' HAVE ZLIB FALSE '' HAVE ZLIB TRUE '' INSTALL DATA ' INSTALL m 644' INSTALL PROGRAM ' INSTALL ' INSTALL SCRIPT ' INSTALL ' INSTALL STRIP PROGRAM ' install sh c s' ISAINFO '' LD '' LDFLAGS ' arch i386 fembed bitcode mios simulator version min 8 0 stdlib libc L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib L Applications Xcode app Contents Developer Platforms iPhoneSimulator platform Developer SDKs iPhoneSimulator8 4 sdk usr lib system' LDFLAGS FOR BUILD '' LIBOBJS '' LIBS ' lc lc abi' LIBTOOL '' LIPO '' LN S '' LTLIBOBJS '' LT SYS LIBRARY PATH '' MAINT '' MAINTAINER MODE FALSE ' ' MAINTAINER MODE TRUE '' MAKEINFO ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf missing makeinfo' MANIFEST TOOL '' MKDIR P ' install sh c d' NM '' NMEDIT '' OBJC '' OBJCDEPMODE '' OBJCFLAGS '' OBJC CONFORMANCE TEST FALSE '' OBJC CONFORMANCE TEST TRUE '' OBJDUMP '' OBJEXT '' OTOOL64 '' OTOOL '' PACKAGE 'protobuf' PACKAGE BUGREPORT 'protobuf googlegroups com' PACKAGE NAME 'Protocol Buffers' PACKAGE STRING 'Protocol Buffers 3 2 0' PACKAGE TARNAME 'protobuf' PACKAGE URL '' PACKAGE VERSION '3 2 0' PATH SEPARATOR ' ' POW LIB '' PROTOBUF OPT FLAG '' PROTOC '' PTHREAD CC '' PTHREAD CFLAGS '' PTHREAD LIBS '' RANLIB '' SED '' SET MAKE '' SHELL ' bin sh' STRIP istrip' USE EXTERNAL PROTOC FALSE '' USE EXTERNAL PROTOC TRUE '' VERSION '3 2 0' ac ct AR '' ac ct CC 'gcc' ac ct CC FOR BUILD '' ac ct CXX '' ac ct CXX FOR BUILD '' ac ct DUMPBIN '' ac ct OBJC '' acx pthread config '' am EXEEXT FALSE '' am EXEEXT TRUE '' am fastdepCC FALSE '' am fastdepCC TRUE '' am fastdepCXX FALSE '' am fastdepCXX TRUE '' am fastdepOBJC FALSE '' am fastdepOBJC TRUE '' am include '' am isrc '' am leading dot ' ' am nodep '' am quote '' am tar 'tar format ustar chf tardir ' am untar 'tar xf ' bindir ' exec prefix bin' build 'x86 64 apple darwin14 0 0' build alias '' build cpu 'x86 64' build os wouldarwin14 0 0' build vendor 'apple' datadir ' datarootdir ' datarootdir ' prefix share' docdir ' datarootdir doc PACKAGE TARNAME ' dvidir ' docdir ' exec prefix ' Users jakie tensorflow master tensorflow contrib makefile gen protobuf ios lib iossim 386' host 'i386 apple darwin14 0 0' host alias 'i386 apple darwin14 0 0' host cpu 'i386' host os wouldarwin14 0 0' host vendor 'apple' htmldir ' docdir ' includedir ' prefix include' infodir ' datarootdir info' install sh ' SHELL Users jakie tensorflow master tensorflow contrib makefile downloads protobuf install sh' libdir ' exec prefix lib' libexecdir ' exec prefix libexec' localedir ' datarootdir locale' localstatedir ' prefix var' mandir ' datarootdir man' mkdir p ' MKDIR P ' oldincludedir ' usr include' pdfdir ' docdir ' prefix ' Users jakie tensorflow master tensorflow contrib makefile gen protobuf ios lib iossim 386' program transform name is x x ' psdir ' docdir ' sbindir ' exec prefix sbin' sharedstatedir ' prefix com' subdirs '' sysconfdir ' prefix etc' target 'i386 apple darwin14 0 0' target alias '' target cpu 'i386' target os wouldarwin14 0 0' target vendor 'apple' confdefs h confdefs h define PACKAGE NAME Protocol Buffers define PACKAGE TARNAME protobuf define PACKAGE VERSION 3 2 0 define PACKAGE STRING Protocol Buffers 3 2 0 define PACKAGE BUGREPORT protobuf googlegroups com define PACKAGE URL define PACKAGE protobuf define VERSION 3 2 0 configure exit 77,,,2017-06-29 02:18:12,2017-06-30 18:35:29
IS,using output layer in seq2seq model,Os liunx version v1 2 0 i am writing a seq2seq model using tensorflow my problem is helper TrainingHelper decoder BasicDecoder decoder outputs final state seq len tf contrib seq2seq dynamic decode decoder rnn out sample ids decoder outputs in traing period we should calculate the loss loss tf contrib seq2seq sequence loss rnn out targets weights the rnn out is shape should be batch size seq len target vocab size but batch size seq len cell hidden size how to change the shape should i add a output layer in decoder if add how to define a output layer i found tf layers dense has two params inputs units units may be target vocab size but what about inputs In addition is the output layer is same as the beamSearcheDecoder when decoding,,,2017-06-28 08:45:30,2017-06-30 18:43:55
PR,Branch 160665742,,,"drpngx,drpngx",2017-06-30 18:53:26,2017-06-30 19:57:17
IS,map func of tf contrib data Dataset map gets dict keys instead of values when the nested structure of Dataset is dict,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below b'0 5 0 12520 g1111e06d9' 1 2 0 rc2 Bazel version if compiling from source 0 4 5 CUDA cuDNN version 8 0 6 GPU model and memory Describe the problem If the nested structure of Dataset is dict MapDataset will call map func nested args L1463 and pass the keys of nested args instead of components in the dataset to map func It seems that nested args or nested args values need to be passed to map func so that map func could transform the elements in the dataset Source code logs,,"rohan100jain,mrry,mrry",2017-06-23 17:16:38,2017-06-30 19:58:01
IS,LSTMBlockCell variable names changed old checkpoints cannot be restored,In TF 1 1 and earlier bias and weights had the variable names biases and weights in the LSTMBlockCell Since TF 1 2 they have the variable names bias and kernel Why was that changed It makes all checkpoint files incompatible but for no real reason,,,2017-06-30 08:28:48,2017-06-30 20:36:16
IS,Documentation Error in TenserFlow website,On website page a custom model There is a missing line in the sample code provide for Custom Model After this line input fn tf contrib learn io numpy input fn x x train y train 4 num epochs 1000 in sample code there should be one more line for variable eval input fn which is missing right now in the docs single line of code to be added in sample code is eval input fn tf contrib learn io numpy input fn x x eval y eval 4 num epochs 1000,,,2017-06-25 15:03:38,2017-06-30 20:42:23
IS,tensorflow gpu aborts with CuDNN v6,System information The code can be found from the notebook here OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from pip TensorFlow version 'v1 2 0 rc2 21 g12f033d' '1 2 0' Bazel version None CUDA cuDNN version CUDA v8 CuDNN v6 GPU GeForce GTX 950M 2GB Exact command to reproduce Run the notebook I was trying out some code for a convolutional network using tensorflow gpu but the following messages appear The code runs smoothly if I'm only using CPU Is it a bug or feature of tensorflow How do I get around it,,,2017-06-25 21:04:20,2017-06-30 20:44:53
IS,standard tensorboard wsgi missing 1 required positional argument 'plugins',how set plugins thanks,,,2017-06-26 02:18:35,2017-06-30 20:45:35
IS,Unsupported CPU features cause runtime errors,I'm having runtime errors when running Tensorflow programs I tracked down the problem and the source seems to be that the shared object I have compiled includes CPU features that are not supported by my processor That causes some pointers pointing to invalid addresses Right now there are 37 CPU feature defined in tensorflow core platform cpu info h My question is how to not include some of those when compiling Tensorflow is source code,,,2017-06-26 14:02:35,2017-06-30 20:52:04
IS,Can we disable tensorflow is theading,I'm running tensorflow in a simulator that does not support mult threading Is it possible to disable tensorflow is multi threading,,"alextp,alextp,alextp,alextp",2017-06-26 18:49:34,2017-06-30 20:52:50
PR,Fixed 404 page in the docs install c md,When following the current link to c api h the link will results in a 404 page see,,"drpngx,drpngx,caisq",2017-06-30 13:34:31,2017-06-30 20:54:14
IS,Global Variables of graph not loaded on different computer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow l MacOSx TensorFlow installed from binary pip install Tensorflow version 1 1 0 Describe the problem I have been having issues trying to load a model from a checkpoint file When trying to access any of the global variables created in our tensorflow model for example print sess run W we get an error NameError global name 'W' is not defined We expect W and other global variables to be present but none are Thanks for the help Source code logs,,,2017-06-26 23:09:51,2017-06-30 20:54:19
IS,how use tensorflow distributed use mpi version,how use tensorflow distributed use mpi version how use tensorflow distributed use mpi version how use tensorflow distributed use mpi version how use tensorflow distributed use mpi version how use tensorflow distributed use mpi version,,,2017-06-27 02:58:35,2017-06-30 20:57:10
IS,Threading example at programmers guide threading and queues broken,Dear TF folks I am trying to reproduce the example listed at 1 1,,,2017-06-29 22:34:01,2017-06-30 23:32:31
IS,tf check numerics does not raise error when used in tf control dependencies,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 4 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Bazel version if compiling from source none CUDA cuDNN version none GPU model and memory none Exact command to reproduce run the code below Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request tf check numerics does not raise error when used in tf control dependencies The code below should raise error but it does not in TensorFlow 1 2 0 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-06-28 03:53:51,2017-06-30 23:50:00
IS,Rank mismatch error when using contrib seq2seq AttentionWrapper in a dynamic rnn with sequence length,System information Linux Ubuntu 16 04 TensorFlow installed from pip binary TensorFlow version 1 2 0 v1 2 0 rc2 21 g12f033d Python 3 6 1 Anaconda 4 4 0 CUDA 8 0 cuDNN 5 1 TITAN X Pascal 11 9GB Describe the problem Error Shapes must be equal rank but are 0 and 1 for 'rnn while Select 4' op 'Select' with input shapes 10 when using tf contrib seq2seq AttentionWrapper in a dynamic rnn with seqence length provided Code to reproduce,,,2017-06-30 03:51:30,2017-06-30 23:54:58
IS,High variance in training convergence between keras with tf backend and tf contrib keras,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Python version 3 6 Describe the problem I started to move my keras Keras 2 0 4 scripts to tf contrib keras tf version 1 2 but I am achieving worse performance though the porting was seamless Not sure why there is such huge discrepancy in training performance Source code logs Original Keras 2 0 4 code This model struggles to achieve 58 accuracy after 1 epoch and 61 after 2 epochs Is there something different in terms of hyper parameter settings that is required when switching between the 2 versions,,,2017-06-30 02:15:34,2017-06-30 23:55:28
IS,AttributeError module areader' has no attribute 'ptb producer',I use anaconda2 python3 5 with tensorflow1 2 I want to test tensorflow on the PennTree bank ptb dataset Referring to the ptb codes provided at I run the code reader test py but got the error ERROR testPtbProducer main PtbReaderTest Traceback most recent call last File ipython input 15 5eff201b8159 line 34 in testPtbProducer x y reader ptb producer raw data batch size num steps AttributeError module areader' has no attribute 'ptb producer' FAIL testPtbRawData main PtbReaderTest Traceback most recent call last File ipython input 15 5eff201b8159 line 28 in testPtbRawData self assertEqual len output 4 AssertionError 5 4 Ran 3 tests in 0 344s FAILED failures 1 errors 1 An exception has occurred use tb to see the full traceback SystemExit sitecustomize IPyTesProgram object at 0x000001FF9FADC630 C Users yl Anaconda2 envs tensorflow gpu lib site packages IPython core interactiveshell py 2870 UserWarning To exit use 'exit' 'quit' or Ctrl D warn To exit use 'exit' 'quit' or Ctrl D stacklevel 1 Then running the code ptb word lm py also produces errors File C Users yl Anaconda2 envs tensorflow gpu lib argparse py line 1506 in handle conflict error raise ArgumentError action message conflict string ArgumentError argument model conflicting option string model Did I do something wrong or miss some steps,,"skye,nealwu,nealwu,nealwu,nealwu",2017-06-24 00:46:08,2017-07-01 00:26:10
PR,fix typo SYC SYCL,,,lakshayg,2017-07-01 06:20:57,2017-07-01 13:34:24
PR,fix typo of map structure doc,,,"caisq,drpngx",2017-07-01 12:51:33,2017-07-01 17:12:15
PR,Added assertion error in reset default graph,See 11121,,"drpngx,drpngx,caisq,drpngx",2017-06-30 01:38:53,2017-07-01 18:04:52
PR,doc update the conv1 shape,Update the conv1 shape from 5 5 32 32 to 5 5 1 32 1 means gray image Although this is irrelevant with the key content in the chapter one might be confused when looking at this detail,,"drpngx,MarkDaoust,drpngx",2017-06-27 04:48:18,2017-07-01 18:05:16
PR,Branch 160731226,,,"caisq,drpngx,drpngx,caisq,gunan,drpngx,caisq,caisq,drpngx,caisq,caisq,caisq,gunan,damienmg,gunan",2017-07-01 15:25:48,2017-07-01 23:00:57
IS,quantify the mobilenet,I try to quantify the mobilenet but I do not decide the out node,,aselle,2017-07-01 03:26:03,2017-07-02 04:13:20
IS,Android TF Classify Multi label output example,What would you have to change to the existing tensorflow android TFClassify app demo to output multiple labels For instance I have a multi output model trained in keras with multiple softmax output nodes The current TFClassify example has one output node so would the solution be to merely add additional output nodes in the java files,,aselle,2017-06-30 22:24:34,2017-07-02 04:46:39
IS,How to create our own dataset,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2017-07-01 09:22:17,2017-07-02 04:59:01
IS,Building from source MAC OS invalid command 'bdist wheel',I'm having a problem when building tensorflow from source on MAC OS Does anyone encounter this problem or know how to fix it Thank you,,aselle,2017-06-27 03:54:44,2017-07-02 05:02:05
PR,TensorFlow,,,drpngx,2017-06-30 14:13:29,2017-07-02 05:23:28
PR,OpenCL Fixes device name comparison stage op test,Changes the fixed ' device GPU 0' expected device name string to the name returned by 'test gpu device name ' as the device name could be ' device SYCL 0' or ' device GPU 0' Resubmission of 10682,,"jwlawson,benoitsteiner,yifeif,drpngx,benoitsteiner",2017-06-16 11:11:30,2017-07-02 05:32:34
IS,ValueError Shape 1 5 must have rank at least 3,CODE I AM TRYING TO RUN from future import print function division import numpy as np import tensorflow as tf import matplotlib pyplot as plt num epochs 100 total series length 50000 truncated backprop length 15 state size 4 num classes 2 echo step 3 batch size 5 num batches total series length batch size truncated backprop length def generateData x np array np random choice 2 total series length p 0 5 0 5 y np roll x echo step y 0 echo step 0 x x reshape batch size 1 The first index changing slowest subseries as rows y y reshape batch size 1 return x y batchX placeholder tf placeholder tf float32 batch size truncated backprop length batchY placeholder tf placeholder tf int32 batch size truncated backprop length cell state tf placeholder tf float32 batch size state size hidden state tf placeholder tf float32 batch size state size init state tf nn rnn cell LSTMStateTuple cell state hidden state W2 tf Variable np random rand state size num classes dtype tf float32 b2 tf Variable np zeros 1 num classes dtype tf float32 unstack columns inputs series tf split batchX placeholder truncated backprop length 1 labels series tf unstack batchY placeholder axis 1 Forward passes cell tf contrib rnn BasicLSTMCell state size state is tuple True states series current state tf nn dynamic rnn cell inputs series initial state init state logits series tf matmul state W2 b2 for state in states series Broadcasted addition predictions series tf nn softmax logits for logits in logits series losses tf nn sparse softmax cross entropy with logits logits labels for logits labels in zip logits series labels series total loss tf reduce mean losses train step tf train AdagradOptimizer 0 3 minimize total loss def plot loss list predictions series batchX batchY plt subplot 2 3 1 plt cla plt plot loss list for batch series idx in range 5 one hot output series np array predictions series batch series idx single output series np array 1 if out 0 0 5 else 0 for out in one hot output series plt subplot 2 3 batch series idx 2 plt cla plt axis 0 truncated backprop length 0 2 left offset range truncated backprop length plt bar left offset batchX batch series idx width 1 color blue plt bar left offset batchY batch series idx 0 5 width 1 color red plt bar left offset single output series 0 3 width 1 color green plt draw plt pause 0 0001 with tf Session as sess sess run tf initialize all variables plt ion plt figure plt show loss list for epoch idx in range num epochs x y generateData current cell state np zeros batch size state size current hidden state np zeros batch size state size print New data epoch epoch idx for batch idx in range num batches start idx batch idx truncated backprop length end idx start idx truncated backprop length batchX x start idx end idx batchY y start idx end idx total loss train step current state predictions series sess run total loss train step current state predictions series feed dict batchX placeholder batchX batchY placeholder batchY cell state current cell state hidden state current hidden state current cell state current hidden state current state loss list append total loss if batch idx 100 0 print Step batch idx Batch loss total loss plot loss list predictions series batchX batchY plt ioff plt show But I have the following error ValueError Shape 1 5 must have rank at least 3,,,2017-07-02 08:53:34,2017-07-02 09:17:29
IS,MultivariateNormalDiag probability gradient fails,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 12 5 TensorFlow installed from source or binary source TensorFlow version use command below v1 2 0 rc2 0 gce1d6ec49 1 2 0 rc2 Bazel version if compiling from source 0 5 1 homebrew CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce python test diag py Describe the problem The gradients for the tensorflow contrib distributions MultiVariateNormalDiag throw an error This might be related to 10149 Notice that the tensorflow contrib distributions Normal works as expected so I think this is a bug in the gradient implementation of the MultiVarateNormalDiag Source code,,"langmore,langmore",2017-06-16 14:29:34,2017-07-02 11:22:33
PR,updated for Estimators and input fn,,,,2017-07-02 12:42:09,2017-07-02 12:47:20
IS,iOS Bug No OpKernel was registered to support Op 'LessEqual',System information Running OS macOS Sierra building for iOS specifically,,,2017-06-28 23:57:14,2017-07-02 17:03:46
PR,fallback to find if locate is not used,Related to 11029 and discussion in 9580 Locate is non standard and not installed on every system It is much faster than 'find' but 'find' should be on every system Find is even in busybox On extremely large systems it can potentially run for a long period of time This fix will first attempt to use the locate command piping any error messages to dev null If locate did not generate output the script will warn that it will attempt to use 'find' and then use 'find' When using find piping stderr to dev null is required since 'find' will generate errors when it cannot access a file for instance if permissions are enforced Piping the output from 'find' into head n1 will complete the line of code and thus stop 'find' from running longer,,,2017-07-01 16:19:52,2017-07-02 20:01:36
PR,Add wget to be installed in docker images,same as 11215 but changes suggested for all docker files System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using scripts provided with tensorflow to download and build imagenet from scratch OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 12 Bazel version if compiling from source NA CUDA cuDNN version 8 0 GPU model and memory Nvidia GRID M6 8Q 8GB Exact command to reproduce bazel bin inception download and preprocess imagenet DATA DIR Describe the problem I am trying to train inception v3 net for imagenet dataset using instructions at getting started After setting the download path using following command Running above command fails saying it cannot find wget root docker container data workspace models inception bazel bin inception download and preprocess imagenet DATA DIR In order to download the imagenet data you have to create an account with image net org This will get you a username and an access key You can set the IMAGENET USERNAME and IMAGENET ACCESS KEY environment variables or you can enter the credentials here Username my username Access key my password Saving downloaded files to data imagenet data raw data Downloading bounding box annotations bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 58 wget command not found bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 64 wget command not found I have reported this as bug 11214 as well,,drpngx,2017-07-02 07:36:02,2017-07-02 21:03:27
PR,Disable flaky cwise ops test due to broken acosh on windows,,,"gunan,guschmue,drpngx,gunan,guschmue",2017-07-02 05:57:35,2017-07-02 21:04:56
IS,bazel build causes Kernel Panic on clean Ubuntu 16 04,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Trying for source TensorFlow version use command below 1 2 Python version 2 7 12 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 5 1 GPU model and memory Nvidia GTX 750 Ti Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem I get through a fair chunk of the build process then I get hit with Kernel panic not syncing Timeout Not all cpus entered broadcast exception handler The computer then reboots after about 30 seconds This is on a fresh install of Ubuntu Source code logs Development tensorflow configure You have bazel 0 5 2 installed Please specify the location of python Default is usr bin python Found possible Python library paths usr local lib python2 7 dist packages usr lib python2 7 dist packages Please input the desired Python library path to use Default is usr local lib python2 7 dist packages Using python library path usr local lib python2 7 dist packages Do you wish to build TensorFlow with MKL support y N No MKL support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Do you wish to use jemalloc as the malloc implementation Y n jemalloc enabled Do you wish to build TensorFlow with Google Cloud Platform support y N Y Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support y N y Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with the XLA just in time compiler experimental y N No XLA support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N y VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL support y N No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N y CUDA support will be enabled for TensorFlow Do you want to use clang as CUDA compiler y N nvcc will be used as CUDA compiler Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 Please specify the location where CUDA toolkit is installed Refer to README md for more details Default is usr local cuda Please specify which gcc should be used by nvcc as the host compiler Default is usr bin gcc Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 5 Please specify the location where cuDNN 5 library is installed Refer to README md for more details Default is usr local cuda Please specify a list of comma separated Cuda compute capabilities you want to build with You can find the compute capability of your device at Please note that each additional compute capability significantly increases your build time and binary size Default is 5 0 5 0 6 1 Do you wish to build TensorFlow with MPI support y N MPI support will not be enabled for TensorFlow Configuration finished,,,2017-07-01 03:03:08,2017-07-02 21:11:09
PR,Add 'wget' to be installed in docker image,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using scripts provided with tensorflow to download and build imagenet from scratch OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 12 Bazel version if compiling from source NA CUDA cuDNN version 8 0 GPU model and memory Nvidia GRID M6 8Q 8GB Exact command to reproduce bazel bin inception download and preprocess imagenet DATA DIR Describe the problem I am trying to train inception v3 net for imagenet dataset using instructions at getting started After setting the download path using following command Running above command fails saying it cannot find wget root docker container data workspace models inception bazel bin inception download and preprocess imagenet DATA DIR In order to download the imagenet data you have to create an account with image net org This will get you a username and an access key You can set the IMAGENET USERNAME and IMAGENET ACCESS KEY environment variables or you can enter the credentials here Username my username Access key my password Saving downloaded files to data imagenet data raw data Downloading bounding box annotations bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 58 wget command not found bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 64 wget command not found I have reported this as bug 11214 as well,,"drpngx,drpngx",2017-07-02 07:20:44,2017-07-02 23:07:22
PR,Update gradients impl py,Corrected documentation of hessians function,,"AndreiCostinescu,drpngx,drpngx",2017-07-02 17:44:57,2017-07-02 23:08:30
PR,Updating Java doc formatting issues,Updating Java doc formatting issues,,"drpngx,drpngx",2017-07-02 18:05:11,2017-07-02 23:09:04
PR,Fix typos,This PR fixes some typos the the Dont Initalized Dimenson and resuts,,"taehoonlee,gunan,drpngx",2017-06-30 06:21:30,2017-07-03 00:34:38
PR,R1 2,,,,2017-07-02 13:30:56,2017-07-03 04:29:35
IS,32 bit build failure in tensorflow contrib tensor forest kernels stats ops cc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 5 i386 TensorFlow installed from source or binary source TensorFlow version use command below Git revision 744120fd8a0c3be0a90cca5a971459894c90b859 Python version 2 7 6 Bazel version if compiling from source 0 4 5 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See log below Describe the problem Building tensorflow contrib tensor forest stats ops lib for a 32 bit architecture fails Source code logs git checkout 744120fd8a0c3be0a90cca5a971459894c90b859 export PYTHON BIN PATH usr bin python export USE DEFAULT PYTHON LIB PATH 1 export CC OPT FLAGS march native export TF NEED MKL 0 export TF NEED JEMALLOC 1 export TF NEED GCP 0 export TF NEED HDFS 0 export TF ENABLE XLA 0 export TF NEED OPENCL 0 export TF NEED CUDA 0 export TF NEED VERBS 0 export TF NEED MPI 0 export COMPUTE 0 configure bazel build c opt verbose failures tensorflow contrib tensor forest stats ops lib removed unimportant log output ERROR home codeplay tensorflow tensorflow contrib tensor forest BUILD 277 1 C compilation of rule ' tensorflow contrib tensor forest stats ops lib' failed gcc failed error executing command cd home codeplay cache bazel bazel codeplay 552bd1ca300856cf615cf243a9219401 execroot tensorflow exec env PATH usr local sbin usr local bin usr sbin usr bin sbin bin usr games usr local games PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF NEED CUDA 0 TF NEED OPENCL 0 usr bin gcc U FORTIFY SOURCE fstack protector Wall B usr bin B usr bin Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections ' std c 0x' MD MF bazel out local opt bin tensorflow contrib tensor forest objs stats ops lib tensorflow contrib tensor forest kernels stats ops pic d ' frandom seed bazel out local opt bin tensorflow contrib tensor forest objs stats ops lib tensorflow contrib tensor forest kernels stats ops pic o' fPIC DEIGEN MPL2 ONLY iquote iquote bazel out local opt genfiles iquote external bazel tools iquote bazel out local opt genfiles external bazel tools iquote external eigen archive iquote bazel out local opt genfiles external eigen archive iquote external local config sycl iquote bazel out local opt genfiles external local config sycl iquote external protobuf iquote bazel out local opt genfiles external protobuf isystem external bazel tools tools cpp gcc3 isystem external eigen archive isystem bazel out local opt genfiles external eigen archive isystem external protobuf src isystem bazel out local opt genfiles external protobuf src fno canonical system headers Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c tensorflow contrib tensor forest kernels stats ops cc o bazel out local opt bin tensorflow contrib tensor forest objs stats ops lib tensorflow contrib tensor forest kernels stats ops pic o com google devtools build lib shell BadExitStatusException Process exited with status 1 In file included from tensorflow contrib tensor forest kernels v4 leaf model operators h 19 0 from tensorflow contrib tensor forest kernels v4 decision tree resource h 21 from tensorflow contrib tensor forest kernels stats ops cc 18 tensorflow contrib tensor forest kernels v4 input target h In member function 'virtual float tensorflow tensorforest TensorInputTarget GetTargetWeight int const' tensorflow contrib tensor forest kernels v4 input target h 70 47 warning comparison between signed and unsigned integer expressions Wsign compare return num weights 0 example index num weights In file included from tensorflow contrib tensor forest kernels v4 split collection operators h 20 0 from tensorflow contrib tensor forest kernels v4 fertile stats resource h 24 from tensorflow contrib tensor forest kernels stats ops cc 19 tensorflow contrib tensor forest kernels v4 grow stats h In member function 'bool tensorflow tensorforest GrowStats IsInitialized const' tensorflow contrib tensor forest kernels v4 grow stats h 80 49 warning comparison between signed and unsigned integer expressions Wsign compare return weight sum 0 splits size num splits to consider tensorflow contrib tensor forest kernels stats ops cc In function 'void tensorflow tensorforest UpdateStats tensorflow tensorforest FertileStatsResource const std unique ptr tensorflow tensorforest TensorDataSet const tensorflow Tensor const tensorflow Tensor int const std vector int const std vector int std unordered map int std unique ptr tensorflow mutex tensorflow mutex tensorflow int32 tensorflow int32 std unordered set int ' tensorflow contrib tensor forest kernels stats ops cc 176 72 error no matching function for call to 'tensorflow tensorforest TensorInputTarget TensorInputTarget const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer const tensorflow Tensor int ' TensorInputTarget target labels weights input labels num targets tensorflow contrib tensor forest kernels stats ops cc 176 72 note candidates are In file included from tensorflow contrib tensor forest kernels v4 leaf model operators h 19 0 from tensorflow contrib tensor forest kernels v4 decision tree resource h 21 from tensorflow contrib tensor forest kernels stats ops cc 18 tensorflow contrib tensor forest kernels v4 input target h 57 3 note tensorflow tensorforest TensorInputTarget TensorInputTarget const SingleDimStorageType const SingleDimStorageType const tensorflow Tensor int TensorInputTarget const SingleDimStorageType t tensorflow contrib tensor forest kernels v4 input target h 57 3 note no known conversion for argument 1 from 'const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer ' to 'const SingleDimStorageType aka const Eigen TensorMap Eigen Tensor const float 1 1 long int 0 ' tensorflow contrib tensor forest kernels v4 input target h 55 7 note tensorflow tensorforest TensorInputTarget TensorInputTarget const tensorflow tensorforest TensorInputTarget class TensorInputTarget public StoredInputTarget SingleDimStorageType tensorflow contrib tensor forest kernels v4 input target h 55 7 note candidate expects 1 argument 4 provided tensorflow contrib tensor forest kernels v4 input target h 55 7 note tensorflow tensorforest TensorInputTarget TensorInputTarget tensorflow tensorforest TensorInputTarget tensorflow contrib tensor forest kernels v4 input target h 55 7 note candidate expects 1 argument 4 provided tensorflow contrib tensor forest kernels stats ops cc In function 'void tensorflow tensorforest UpdateStatsCollated tensorflow tensorforest FertileStatsResource tensorflow tensorforest DecisionTreeResource const std unique ptr tensorflow tensorforest TensorDataSet const tensorflow Tensor const tensorflow Tensor int const std unordered map int std vector int const std vector int tensorflow mutex tensorflow int32 tensorflow int32 std unordered set int ' tensorflow contrib tensor forest kernels stats ops cc 226 72 error no matching function for call to 'tensorflow tensorforest TensorInputTarget TensorInputTarget const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer const tensorflow Tensor int ' TensorInputTarget target labels weights input labels num targets tensorflow contrib tensor forest kernels stats ops cc 226 72 note candidates are In file included from tensorflow contrib tensor forest kernels v4 leaf model operators h 19 0 from tensorflow contrib tensor forest kernels v4 decision tree resource h 21 from tensorflow contrib tensor forest kernels stats ops cc 18 tensorflow contrib tensor forest kernels v4 input target h 57 3 note tensorflow tensorforest TensorInputTarget TensorInputTarget const SingleDimStorageType const SingleDimStorageType const tensorflow Tensor int TensorInputTarget const SingleDimStorageType t tensorflow contrib tensor forest kernels v4 input target h 57 3 note no known conversion for argument 1 from 'const Eigen TensorMap Eigen Tensor const float 1 1 int 0 Eigen MakePointer ' to 'const SingleDimStorageType aka const Eigen TensorMap Eigen Tensor const float 1 1 long int 0 ' tensorflow contrib tensor forest kernels v4 input target h 55 7 note tensorflow tensorforest TensorInputTarget TensorInputTarget const tensorflow tensorforest TensorInputTarget class TensorInputTarget public StoredInputTarget SingleDimStorageType tensorflow contrib tensor forest kernels v4 input target h 55 7 note candidate expects 1 argument 4 provided tensorflow contrib tensor forest kernels v4 input target h 55 7 note tensorflow tensorforest TensorInputTarget TensorInputTarget tensorflow tensorforest TensorInputTarget tensorflow contrib tensor forest kernels v4 input target h 55 7 note candidate expects 1 argument 4 provided Target tensorflow contrib tensor forest stats ops lib failed to build,,gunan,2017-07-02 21:42:27,2017-07-03 04:52:13
PR,remove some warning,remove some warning for master branch,,horance-liu,2017-07-03 08:33:18,2017-07-03 09:29:34
PR,Update gradients impl py,Corrected documentation of hessians function,,"AndreiCostinescu,caisq",2017-07-03 02:58:58,2017-07-03 14:36:54
IS,On Network with Shared Weights Optimizer minimize has no effect,I have a simple siamese network a network with two branches that share weights and a script to train it on some very simple data The loss and gradients are both non zero but executing an optimizer minimize loss operation has no effect on the weights Executing it in two steps with compute gradients and apply gradients also has no effect I have tried multiple optimizers and settings and explored StackOverflow without finding relevant information I have included both scripts they are small with the relevant debug statements so that you can easily inspect the weights and gradients as well You will see that the accuracy weights gradients do not change loss changes because new batches are being computed each iteration System information Windows 10 up to date Tensorflow 1 2 0 CPU only mode Python 3 5 Executing from Windows terminal Network constructor,,,2017-06-30 18:25:49,2017-07-03 15:30:42
PR,fix incorrect usage of num gpus num workers 7312,Removed unnecessarily restrictive check as discussed in in 7312 and validated the change using 2 single GPU VMs,,"drpngx,drpngx,drpngx,gunan",2017-06-30 18:59:09,2017-07-03 17:56:55
PR,install cub under external cub archive to fix windows gpu build,Fix cmake windows gpu build install cub under external cub archive so where op gpu cu cc will find it for cmake and bazel in the same place,,"guschmue,drpngx",2017-07-03 14:20:08,2017-07-03 21:07:26
PR,OpenCL Fixes transpose operation,,,"lukeiwanski,drpngx",2017-06-30 14:47:09,2017-07-04 03:23:49
PR,OpenCL Fixes warning caused by half type,half requires opencl extension that might not be avaiable on all platforms extends cast operation to cover int8 int16 uint8 uint16,,"lukeiwanski,drpngx",2017-06-30 14:59:57,2017-07-04 03:31:08
PR,Update Dockerfile gpu with python3,There is already Dockerfile gpu with gpu version but it is for python2 users so I make a Dockerfile gpu py3 with python3 users There is no different this from Dockerfile of Image that is on Docker hub,,,2017-07-04 03:59:10,2017-07-04 04:14:21
PR,Update Dockerfile gpu with python3,There is already Dockerfile gpu with gpu version but it is for python2 users so I make a Dockerfile gpu py3 with python3 users There is no different this from Dockerfile of Image that is on Docker hub,,,2017-07-04 04:15:25,2017-07-04 04:47:07
IS,pip or package issues,Over the past few hours I have tried to run pip install upgrade tensorflow gpu roughly 20 times and keep getting read time out from pypi python org I finally added the verbose and timeout 10000 to troubleshoot Now I get this Using version 1 2 1 newest of versions 1 2 0 1 2 1 Looking up in the cache No cache entry available Starting new HTTPS connection 1 pypi python org GET packages 47 81 2b8020393615b06af06e0d7c32d74b9a844ebebf4385f9eb00cfdfdbdd92 tensorflow gpu 1 2 1 cp36 cp36m win amd64 whl HTTP 1 1 200 51299687 Downloading tensorflow gpu 1 2 1 cp36 cp36m win amd64 whl 51 3MB Downloading from URL md5 46bb283df033c7fb7c233346eb26d40f from 12 6 3MB 6 4kB s eta 1 57 37 Cleaning up THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE If you have updated the package versions please update the hashes Otherwise examine the package contents carefully someone may have tampered with them tensorflow gpu from md5 46bb283df033c7fb7c233346eb26d40f Expected md5 46bb283df033c7fb7c233346eb26d40f Got 7ba60530da51fdc733b89f9dd3b660fc Exception information Traceback most recent call last File c users roger envs tensorflow attention ocr lib site packages pip basecommand py line 215 in main status self run options args File c users roger envs tensorflow attention ocr lib site packages pip commands install py line 335 in run wb build autobuilding True File c users roger envs tensorflow attention ocr lib site packages pip wheel py line 749 in build self requirement set prepare files self finder File c users roger envs tensorflow attention ocr lib site packages pip req req set py line 386 in prepare files raise hash errors pip exceptions HashErrors THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE If you have updated the package versions please update the hashes Otherwise examine the package contents carefully someone may have tampered with them tensorflow gpu from md5 46bb283df033c7fb7c233346eb26d40f Expected md5 46bb283df033c7fb7c233346eb26d40f Got 7ba60530da51fdc733b89f9dd3b660fc,,gunan,2017-07-03 22:50:05,2017-07-04 06:00:59
PR,OpenCL Adds Wno c 11 narrowing to ComputeCpp device compiler,Adds Wno c 11 narrowing to ComputeCpp device compiler flags to avoid build errors on 32 bit targets 109,,"lukeiwanski,benoitsteiner",2017-07-03 10:05:43,2017-07-04 06:05:02
PR,Updating DNNRegressor module directory,The model is now located at tf contrib learn DNNRegressor and the code will not run without this change Documentation of the module is available here,,,2017-07-04 06:37:56,2017-07-04 06:40:16
IS,wide n deep tutorial not work,Run the wide n deep tutorial py I got the msg like that File wide n deep tutorial py line 147 in build estimator m tf estimator DNNLinearCombinedClassifier AttributeError 'module' object has no attribute 'DNNLinearCombinedClassifier' it shows that DNNLinearCombinedClassifier not in estimator In the previous version it seems in tf contrib learn is it a bug,,"ScorpioCPH,ScorpioCPH,ScorpioCPH,ScorpioCPH",2017-07-04 02:36:28,2017-07-04 08:52:35
IS,wide n deep Tutorial example not working,cd tensorflow tensorflow examples learn python wide n deep tutorial py it shows that Traceback most recent call last File wide n deep tutorial py line 36 in module gender tf feature column categorical column with vocabulary list AttributeError 'module' object has no attribute 'feature column' My tensorflow is '1 0 0 rc2' and do i need to upgrade thank you,,"terrytangyuan,terrytangyuan",2017-06-29 09:59:48,2017-07-04 08:53:19
IS,how to trace the training time of the layers,I am training the CNN I have embedding layer conv layer fc layer and etc I can get the training time per batch but how can I get the training time of each layer per batch,,,2017-07-04 08:03:46,2017-07-04 10:02:04
IS,error in freeze graph py,System information Ubuntu 16 04 Python 2 7 12 Tensorflow 1 2 1 installed using pip GPU Nvidia Quadro M2000M 4GB CUDA V 8 0 4 Issue I am trying to recreate the frozen graph using freeze graph py from the ssd mobilenet pretrained model available here I printed the output nodes using the following command for n in detection graph as graph def node print n name I tried running freeze graph with different output nodes such as add 6 Postprocessor BatchMultiClassNonMaxSuppression stack with following command freeze graph py input graph ssd mobilenet v1 coco graph pbtxt input checkpoint ssd mobilenet v1 coco model ckpt output graph frozen graph pb output node names add 6 This is the error that I get Traceback most recent call last File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 202 in module app run main main argv sys argv 0 unparsed File home adminloc local lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 134 in main FLAGS variable names blacklist File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 99 in freeze graph importer import graph def input graph def name File home adminloc local lib python2 7 site packages tensorflow python framework importer py line 283 in import graph def raise ValueError 'No op named s in defined operations ' node op ValueError No op named SSTableReaderV2 in defined operations When I try feeding the old frozen graph pb file as input graph with input binary true to freeze graph I get the following error Traceback most recent call last File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 202 in module app run main main argv sys argv 0 unparsed File home adminloc local lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 134 in main FLAGS variable names blacklist File usr local lib python2 7 dist packages tensorflow python tools freeze graph py line 112 in freeze graph sess run restore op name filename tensor name input checkpoint File home adminloc local lib python2 7 site packages tensorflow python client session py line 789 in run run metadata ptr File home adminloc local lib python2 7 site packages tensorflow python client session py line 945 in run e args 0 TypeError Cannot interpret feed dict key as Tensor The name isave Const 0' refers to a Tensor which does not exist The operation isave Const' does not exist in the graph I do not know if this is a bug or lack of documentation but it would be nice to add some documentation such as the output nodes P S I am trying to recreate the frozen graph to be able to create a new frozen graph after fine tuning the model,,,2017-07-03 17:04:18,2017-07-04 13:04:27
PR,Spelling,,,carlthome,2017-07-04 12:39:19,2017-07-04 15:35:42
PR,R1 2,,,"caisq,av8ramit",2017-07-04 15:33:22,2017-07-04 15:37:37
PR,Add Edward and GPflow to community page,Edward is a library for probabilistic programming with a few thousand active users GPflow is a library for Gaussian processes which also has an active user base,,"dustinvtran,drpngx",2017-07-04 04:37:13,2017-07-04 18:15:45
PR,remove some warning,remove some c compiler warning,,"horance-liu,drpngx",2017-07-03 09:39:00,2017-07-04 18:16:07
IS,Inconsistent default value,In this doc the default value for validate shape and use locking is different between the method signature and the explanation below it,,drpngx,2017-07-04 08:26:07,2017-07-04 19:39:37
IS,ImportError No module named google protobuf,hello there when i use C to call python program that use tensorflow report this error Traceback most recent call last File string line 1 in module File root anaconda2 lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File root anaconda2 lib python2 7 site packages tensorflow python init py line 54 in module from tensorflow core framework graph pb2 import File root anaconda2 lib python2 7 site packages tensorflow core framework graph pb2 py line 6 in module from google protobuf import descriptor as descriptor ImportError No module named google protobuf code is here PyRun SimpleString sys path append ' root anaconda2 lib python2 7 site packages' PyRun SimpleString sys path append ' root pythoncode vgg' PyRun SimpleString import tensorflow as tf PyRun SimpleString print sys path have anyone meet this question please help thank you very much,,drpngx,2017-07-04 08:46:19,2017-07-04 21:01:38
IS,error in tensorflow tensorflow examples tutorials word2vec word2vec basic py,System information cat etc issue Linux ai 2 6 32 642 11 1 el6 x86 64 1 SMP Fri Nov 18 19 25 05 UTC 2016 x86 64 x86 64 x86 64 GNU Linux LSB VERSION base 4 0 amd64 base 4 0 noarch core 4 0 amd64 core 4 0 noarch graphics 4 0 amd64 graphics 4 0 noarch printing 4 0 amd64 printing 4 0 noarch are we in docker No compiler c GCC 4 9 3 Copyright 2015 Free Software Foundation Inc uname a Linux ai 2 6 32 642 11 1 el6 x86 64 1 SMP Fri Nov 18 19 25 05 UTC 2016 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 0 protobuf 3 3 0 tensorflow 1 1 0 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local lib64 usr local lib DYLD LIBRARY PATH is unset nvidia smi newfile sh line 85 nvidia smi command not found cuda libs Describe the problem I change the data set and encounter error which is TypeError sequence index must be integer not islice' in line 117 Source code logs The code what i have changed is as below image What I Do Change buffer data span To buffer extend data span in line 117 and work well Please check the code Thank you for your attention,,drpngx,2017-07-04 14:04:03,2017-07-04 21:06:02
IS,Failed to load the native TensorFlow runtime,Describe the problem I'm not sure what I did incorrectly I opened up the anaconda prompts and followed the steps here Source code logs Traceback most recent call last File ipython input 2 41389fad42b5 line 1 in module import tensorflow as tf File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow init py line 24 in module from tensorflow python import File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File sscc home s snu8359 conda envs tensorflow lib python3 5 imp py line 242 in load module return load dynamic name filename file File sscc home s snu8359 conda envs tensorflow lib python3 5 imp py line 342 in load dynamic return load spec ImportError lib64 libc so 6 version GLIBC 2 14' not found required by sscc home s snu8359 conda envs tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal so Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,drpngx,2017-07-04 20:52:52,2017-07-04 21:09:28
PR,grappler swap bug fix,I have already solved the problem mentioned in the following issue and tested in my local environment The code change is actually trivial and could you please take a look to see whether it is ready for being merged BTW I am already applying for the CLA Thanks,,,2017-07-05 02:51:03,2017-07-05 03:14:42
IS,tensorboard fetching sprite image parsing metadata takes forever,When i study tensorboard embedding My code refers 6322 Whatever my datasets size is I modify batch size epoches and embedding data szie but it does not works localhost 6006 embedding takes forever and the browser shows always fetching sprite image parsing metadata What should i do Could someone give me any ideas,,,2017-07-05 03:59:50,2017-07-05 08:57:07
PR,R0 12,,,drpngx,2017-07-05 10:13:54,2017-07-05 15:07:27
PR,Fix 11152 Adding import for pythons threading library,State in the programmers guide threading and queues example where the threading Thread is coming from This fixes 11152 This is based on the comment by in issuecomment 312393705,,"drpngx,drpngx,drpngx",2017-07-02 19:52:49,2017-07-05 15:20:42
IS,reset default graph awkwardly breaks graph nesting,System information Linux Ubuntu 16 04 TF version 1 1 0 though it should still be present in master Bug Running this This bug causes a confusing error message The stack should either include the new default graph created by reset default graph or a warning error message should happen when you reset the default within nested graphs,,"mrry,skye,skye",2017-06-28 19:45:17,2017-07-05 15:43:49
PR,Fix typos,This PR fixes some typos parition partiton grpah excuted definitons and operaiton,,"taehoonlee,drpngx",2017-07-05 05:14:48,2017-07-05 15:59:12
PR,fix beam search for windows and enable seq2seq unit tests,fix for all unit tests under contrib seq2seq are now enabled and passing,,"guschmue,drpngx,drpngx,caisq",2017-07-05 14:05:02,2017-07-05 15:59:36
IS,L Op and R Op in Tensorflow,Are there currently equivalents of theano gradient Lop l operator and theano gradient Rop r operator implemented in Tensorflow If not is this a feature that is in the pipeline I'm trying to port some code over but can not seem to find a way to do this yet Thank you,,,2017-07-01 04:49:05,2017-07-05 16:29:00
IS,tf reverse does not support tensor with unknown shape,System information ubuntu 14 04 tensorflow installed from binary tensorflow version tensorflow gpu 1 2 1 python version python 2 7 CUDA CuDNN version cuda 8 0 CUDNN 5 1 GPU model You can collect some of this information using our environment capture script Describe the problem Hey tensorflow community I want to feed an unknown shape tensor into tf placeholder Then it is reversed But it reports errors a tf placeholder dtype tf int64 shape None b tf reverse a axis 0 Source code logs 1 2,,mrry,2017-07-05 12:38:13,2017-07-05 17:04:09
IS,building gexagon graph execution for hexagon DSP failed,I have followed the build and run script for HVX here after installing the protobuf and downloading the pre built libraries the code has failed at error undefined reference to isoc interface AllocateInOutNodeBuffers' here is the related file could you help me out here about the linking problem Running on Ubuntu 16 04 02,,,2017-07-04 03:29:06,2017-07-05 17:21:56
IS,Tensorflow execution with HVX failed on Qualcomm 820 Board,satok16 could you have a look at this error I have built the libs and am using Intrinsys 820 Qualcomm board Tried your troubleshooting procedure to sign as well and put the so file in system lib rfsa adsp Running hexagon graph gives me the same error I have attached my adblogcat output as well here Thanks logcat txt,,,2017-07-01 22:10:32,2017-07-05 17:23:15
IS,word2vec error sequence index must be integer not islice',Im tring to run the code L117 But get the exception on the Line 117 as sequence index must be integer not islice' I want to ask if this really a problem in the tensorflow file or its just me facing this error,,rohan100jain,2017-06-20 20:09:23,2017-07-05 18:49:46
IS,Matrix Inverse in TensorFlow,I have a problem related to calculating matrix inverse in TensorFlow python interface version 1 1 0 on Linux What I'm now trying to do is that I have an input vector as tensorflow float64 say S and a value V I augment the vector S to be polynomial fashion in the form A 1 S S 2 S 3 and want to do a regression on V I choose to compute the linear regression myself instead of using the infrastructure from tensorflow where the regression is conducted as beta A TA 1 A T times V The problem occurs at the A TA 1 step where the inverse multiply the original matrix does not give an identity However if I feed the A TA as a constant matrix containing the same value as the preprocessed input the result is really the inverse of itself The code below is a runnable version with parameter control True turns on the constant input matrix version where the inverse behaves correctly Three matrices are output by running the program the original matrix the inverse by tf matrix inverse and the multiplication of the inverse with the original matrix aiming to recover an identify control False gives the same original matrix as control True run however the recovered identity is not correct with control False I suspect something wrong with the data flow during preprocessing However limited by my experience with TensorFlow I cannot spot it Would you mind a help why the tf matrix inverse does not work as expected import tensorflow as tf import pprint def matrixInverse control False '''Compute inverse of a matrix Parameters control bool whether to use control group or not ''' X tf constant 100 100 100 100 101 75497118 92 84824314 95 09528336 103 24955959 92 33287485 95 86868862 84 70664178 107 9505686 85 86109085 99 05621029 94 24396596 119 60257907 dtype tf float64 extract input X s tf slice X 2 0 1 4 s tf squeeze s s1 tf multiply tf ones 4 dtype tf float64 s s2 tf multiply s s s3 tf multiply tf multiply s s s A tf concat tf ones 4 dtype tf float64 s1 s2 s3 0 A tf reshape A 4 4 filter only the first element in the selected row itm tf constant True False False False dtype tf bool A tf boolean mask tf transpose A itm if control ATA tf constant 1 00000000e 00 9 23328748e 01 8 52535978e 03 7 87170977e 05 9 23328748e 01 8 52535978e 03 7 87170977e 05 7 26817593e 07 8 52535978e 03 7 87170977e 05 7 26817593e 07 6 71091579e 09 7 87170977e 05 7 26817593e 07 6 71091579e 09 6 19638148e 11 dtype tf float64 else ATA tf matmul tf transpose A A inverseATA tf matrix inverse ATA sess tf Session pprint pprint sess run ATA inverseATA tf matmul ATA inverseATA,,,2017-07-05 13:50:52,2017-07-05 19:32:34
IS,argument learning rate conflicting option string learning rate,Hi everyone I'm currently learning how to user Tensorflow but when I'm running the fully connected feed py file from tensorflow website It returns the following error argument learning rate conflicting option string learning rate Does someone know how to fix the issue This is the entire Error message File ipython input 8 db6c9214eb7b line 1 in module debugfile 'C Users X188068 Desktop Merck Vevey Deviation fully connected feed Mechanics 101 py' wdir 'C Users X188068 Desktop Merck Vevey Deviation' File C Users X188068 AppData Local Continuum Anaconda3 lib site packages spyder utils site sitecustomize py line 888 in debugfile debugger run runfile r args r wdir r filename args wdir File C Users X188068 AppData Local Continuum Anaconda3 lib bdb py line 431 in run exec cmd globals locals File string line 1 in module File C Users X188068 AppData Local Continuum Anaconda3 lib site packages spyder utils site sitecustomize py line 866 in runfile execfile filename namespace File C Users X188068 AppData Local Continuum Anaconda3 lib site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File c users x188068 desktop merck vevey deviation fully connected feed mechanics 101 py line 25 in module flags DEFINE float 'learning rate' 0 01 'Initial learning rate ' File C Users X188068 AppData Local Continuum Anaconda3 lib site packages tensorflow python platform flags py line 132 in DEFINE float define helper flag name default value docstring float File C Users X188068 AppData Local Continuum Anaconda3 lib site packages tensorflow python platform flags py line 65 in define helper type flagtype File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1348 in add argument return self add action action File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1711 in add action self optionals add action action File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1552 in add action action super ArgumentGroup self add action action File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1362 in add action self check conflict action File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1501 in check conflict conflict handler action confl optionals File C Users X188068 AppData Local Continuum Anaconda3 lib argparse py line 1510 in handle conflict error raise ArgumentError action message conflict string ArgumentError argument learning rate conflicting option string learning rate,,,2017-07-05 08:29:55,2017-07-05 19:36:02
IS,solved solution is on the bottom link libtensorflow core a to c cross comple project,Hi all i followed and successfully got ios android linux lib files in contrib makefile gen lib i'm developing a cross platform sdk lib which is written by c my plan is using my sdk c code to call tensorflow lib here is my question where are the h files according to the tensorflow lib file commenly a lib project is out put is not only a binary file but also h files,,,2017-07-03 03:15:29,2017-07-05 19:45:34
IS,The data type conversion between int32 and float32,My project require convert the data type of tensor dtype float32 to int32 and then I need turn the dtype back from int32 to float32 after some operations The code is y tf to int32 x bitwiseXor tf bitwise bitwise xor y key z tf to float bitwiseXor But following errors appears how to solve it Traceback most recent call last File usr local lib python3 4 dist packages tensorflow python framework op def library py line 490 in apply op preferred dtype default dtype File usr local lib python3 4 dist packages tensorflow python framework ops py line 675 in internal convert to tensor ret conversion func value dtype dtype name name as ref as ref File usr local lib python3 4 dist packages tensorflow python framework constant op py line 121 in constant tensor conversion function return constant v dtype dtype name name File usr local lib python3 4 dist packages tensorflow python framework constant op py line 102 in constant tensor util make tensor proto value dtype dtype shape shape verify shape verify shape File usr local lib python3 4 dist packages tensorflow python framework tensor util py line 364 in make tensor proto raise ValueError None values not supported ValueError None values not supported During handling of the above exception another exception occurred Traceback most recent call last File usr local lib python3 4 dist packages tensorflow python framework op def library py line 504 in apply op values as ref input arg is ref dtype name File usr local lib python3 4 dist packages tensorflow python framework ops py line 675 in internal convert to tensor ret conversion func value dtype dtype name name as ref as ref File usr local lib python3 4 dist packages tensorflow python framework constant op py line 121 in constant tensor conversion function return constant v dtype dtype name name File usr local lib python3 4 dist packages tensorflow python framework constant op py line 102 in constant tensor util make tensor proto value dtype dtype shape shape verify shape verify shape File usr local lib python3 4 dist packages tensorflow python framework tensor util py line 364 in make tensor proto raise ValueError None values not supported ValueError None values not supported During handling of the above exception another exception occurred Traceback most recent call last File win1 Ubuntu App RemotePython EncNN My EncML py line 134 in module model fit x train y train batch size batch size epochs epochs verbose 1 validation data x test y test File usr local lib python3 4 dist packages keras engine training py line 1458 in fit self make train function File usr local lib python3 4 dist packages keras engine training py line 1002 in make train function self total loss File usr local lib python3 4 dist packages keras optimizers py line 326 in get updates new a self rho a 1 self rho K square g File usr local lib python3 4 dist packages keras backend tensorflow backend py line 1225 in square return tf square x File usr local lib python3 4 dist packages tensorflow python ops math ops py line 428 in square return gen math ops square x name name File usr local lib python3 4 dist packages tensorflow python ops gen math ops py line 2544 in square result op def lib apply op Square x x name name File usr local lib python3 4 dist packages tensorflow python framework op def library py line 508 in apply op input name err ValueError Tried to convert 'x' to a tensor and failed Error None values not supported Process finished with exit code 1,,,2017-07-03 11:53:36,2017-07-05 20:30:41
IS,Different batch size different result with inception v2,I user inception v2 as a base network for classification During training the batchsize 128 During testing if the batchsize 128 everything is ok However if the batchsize is smaller than 128 the results are different And the precision declines as the batchsize drops If the batchsize 1 the network will failed I also used inception v3 and inception v1 the same problems appered However if the base network is replaced with Alex network tensorflow everything goes well I also replace the inception v2 with vgg slim and everything goes well The bug is associated with inception v1 v3 I think I have not used inception v2 properly Did anyone encounter similar problems,,,2017-07-05 13:11:59,2017-07-05 20:35:25
IS,Bug placeholder input to tf one hot leads to hang,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 0 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory GTX 1080 Ti 11GB Exact command to reproduce see below Describe the problem I'm not sure if you are not supposed to feed in a placeholder to tf one hot but if you do it hangs and chews up 100 CPU Source code logs Minimal example to reproduce bug The expected result should be either 1 it works and prints 0 0 0 1 0 0 0 0 0 0 or 2 it produces some kind of error,,,2017-06-23 22:42:49,2017-07-05 22:22:04
IS,why use x is dict to check y,In tensorflow contrib learn python learn learn io data feeder py On L325 self y None if y is None else dict k check array v v dtype for k v in list y items if x is dict else check array y y dtype I happened to have a implementation where x is a dict but y is a numpy array so I got an error I wonder why we do not use y is dict here,,,2017-06-30 20:43:31,2017-07-05 23:53:29
IS,No OpKernel was registered to support Op 'LesseEqual' with these attrs on Android,On Android I am trying to load a tensorflow graph which I have frozen by using convert variables to constants however I am getting com example trio tensordemo E TensorflowDebug java lang IllegalArgumentException No OpKernel was registered to support Op 'LessEqual' with these attrs Registered devices CPU Registered kernels no registered kernels Node bidirectional rnn fw fw LessEqual LessEqual T DT INT32 device device GPU 0 bidirectional rnn fw fw Max bidirectional rnn fw fw LessEqual y This is what the node looks like name bidirectional rnn fw fw LessEqual 1 op LessEqual input bidirectional rnn fw fw Max input bidirectional rnn fw fw LessEqual 1 y device device CPU 0 attr key T value type DT INT32 The tensorflow version I trained and loaded in Android are both r1 2,,,2017-07-05 13:32:15,2017-07-06 00:29:02
IS,TensorFlow on Kieler Open Source und Linux Tage,Hi I did not find any contact information for the TensorFlow project so I try it here We are organising our 15th Kieler Open Source und Linux Tage northern of Germany www kielux de a conference with 4 parallel tracks with talks and workshops and a smal exhibition for open source community projects and companies Is there anybody who would like to hold a talk and or give a TensorFlow workshop and or make a booth on our event 14th 16th September Please answer by eMail to kontakt kilux de Cu Hauke,,,2017-07-05 17:09:18,2017-07-06 00:39:15
PR,Fixes to the getting started documentation,Removed some unneeded code streamlined the code fixed a broken example corrected output for example code minor grammar fix,,"alanyee,alanyee,drpngx,drpngx,alanyee,drpngx,drpngx,gunan,caisq,drpngx,drpngx,drpngx",2017-06-29 23:40:34,2017-07-06 01:00:00
IS,Import tensorflow with error information KeyError Could not find field google protobuf FileOptions php class prefix,here is the error information import tensorflow Traceback most recent call last File stdin line 1 in module File home shaoyn anaconda2 lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home shaoyn anaconda2 lib python2 7 site packages tensorflow python init py line 52 in module from tensorflow core framework graph pb2 import File home shaoyn anaconda2 lib python2 7 site packages tensorflow core framework graph pb2 py line 10 in module from google protobuf import descriptor pb2 File home shaoyn anaconda2 lib python2 7 site packages google protobuf descriptor pb2 py line 1003 in module options None File home shaoyn anaconda2 lib python2 7 site packages google protobuf descriptor py line 498 in new return message default pool FindFieldByName full name KeyError Could not find field google protobuf FileOptions php class prefix,,ScorpioCPH,2017-07-04 01:47:13,2017-07-06 01:48:14
IS,TF API r1 2 Keras TimeDistributed wrapper error,import tensorflow contrib keras as K model K models Sequential model add K layers LSTM 150 batch input shape batch size n in encoded length stateful True model add K layers RepeatVector n out model add K layers LSTM 150 return sequences True stateful True model add K layers TimeDistributed K layers Dense encoded length activation isoftmax' model compile loss 'categorical crossentropy' optimizer 'adam' metrics 'acc' AttributeError module 'tensorflow contrib keras api keras layers' has no attribute 'TimeDistributed' Is there way to avoid that error System info Windows 10 TensorFlow r1 2 Python 3 6 Miniconda3 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"skye,fchollet,skye,martinwicke",2017-06-29 09:21:27,2017-07-06 01:52:20
PR,Branch 160981881 DO NOT MERGE YET,,,caisq,2017-07-05 19:54:22,2017-07-06 01:56:15
IS,There is no work sharder file in tensorflow core framework,I am reading the Add a new op section in official website There is a link work sharder h and this link is 404 not found Then i tried to find the work shader h in tensorflow tensorlfow core framework and i failed where can i find work sharder h file and detailed documentation of it Thx,,,2017-07-06 03:25:12,2017-07-06 03:31:39
IS,tf nn embedding lookup sparse behaves not as expected,Simple repeated code This is documented in the previous link I provided But I have printed all the sparse indices and values using tf Print Everything seems fine So my question is does tf concat apply any special rules,,,2017-07-06 02:23:48,2017-07-06 05:07:02
IS,order of execution of functions in cond statement is inconsistent,Inconsistency and or feature request Tensorflows control flow method tf cond condition fn1 fn2 executes both functions fn1 and fn2 and returns only one depending on the evaluation of condition In addition the order in which the two functions are evaluated varies or is undefined as the following code shows For the lines with 10 87 and 98 the order of execution apparently was 1 update var1 2 evaluate and return var1 10 var2 3 update var2 while for the lines with 22 33 44 55 66 77 and 110 the order of execution must have been 1 update var1 2 update var2 3 evaluate and return var1 10 var2 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow See code in description OS Platform and Distribution e g Linux Ubuntu 16 04 Linux TensorFlow installed from source or binary from binary TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version Python 2 7 13 Anaconda 4 3 1 64 bit Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce,,mrry,2017-07-06 04:52:44,2017-07-06 05:30:00
IS,AttributeError 'Tensor' object has no attribute 'assign add',I'm trying to use assign add my code accum ops tf assign add accum grad grad name name Output AttributeError 'Tensor' object has no attribute 'assign add' Has the name changed,,"ScorpioCPH,ScorpioCPH,mrry",2017-07-06 01:32:17,2017-07-06 05:32:29
IS,Image Retrain Inception only check the own specific category not tensor dataset,I have retrained the inception model from my data set of traffic sign Its working fine but when I am trying to check other image e g panda it is resulting with the name of traffic sign with some probabilities I do not understand why its doing it I need both tensor flow data set and my own category too My steps I have installed the python 3 5 2 in windows 7 I installed tensor flow with pip install tensorflow I download these two files retrain py to train my data and label image py to check image files downloaded from,,,2017-07-04 06:34:20,2017-07-06 07:24:51
IS,Is 'tf concat' is API is wrong,According 'tf concat' is API 0 12 t1 1 2 3 4 5 6 t2 7 8 9 10 11 12 tf concat 0 t1 t2 while console returns tf concat 0 t1 t2 Traceback most recent call last File ipython input 65 5990b998f0fa line 1 in module tf concat 0 t1 t2 File E SDK Anaconda2 envs py3 lib site packages tensorflow python ops array ops py line 1044 in concat assert is compatible with tensor shape scalar File E SDK Anaconda2 envs py3 lib site packages tensorflow python framework tensor shape py line 732 in assert is compatible with raise ValueError Shapes s and s are incompatible self other ValueError Shapes 2 2 3 and are incompatible BUT I try to swap the params' position it is well t1 1 2 3 4 5 6 t2 7 8 9 10 11 12 tf concat t1 t2 0,,ScorpioCPH,2017-07-06 10:25:15,2017-07-06 13:52:40
IS,tf gfile FastGFile filename 'r' read error 'utf 8' codec can not decode byte 0xff,Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request TensorFlow 1 2 0 image data tf gfile FastGFile filename 'r' read python2 7 is good but Python3 5 error 'utf 8' codec can not decode byte 0xff in position 0 invalid start byte why,,mrry,2017-07-06 02:00:42,2017-07-06 16:15:41
IS,TypeError concat got an unexpected keyword argument 'concat dim',I got this error message regarding to tf concat Code Please advice Thank you,,mrry,2017-07-06 13:08:00,2017-07-06 16:17:36
IS,Tensorflow Windows Bug with BeamSearchDecoder,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Pip Binary TensorFlow version use command below 1 2 1 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version 5 1 GPU model and memory Nvidia Gtx 1080 8 GB Describe the problem Tensorflow on Windows gives an error Multiple OpKernel registrations match NodeDef when I try to use BeamSearchDecoder in the seq2seq module The same code works well on Ubuntu Someone else on stackoverflow also had the same issue I have attached a snippet of code that generates the same error on my computer original code is much bigger Source code to reproduce the problem,,"drpngx,ebrevdo,ebrevdo,drpngx,guschmue,ebrevdo,drpngx,guschmue,mrry,martinwicke,guschmue",2017-07-04 19:37:55,2017-07-06 16:36:28
IS,faster rcnn incompatible shapes randomly during training custom dataset,I'm trying to train faster rcnn with resnet101 on a custom dataset which I have formatted appropriately for tf When I run training it can run anywhere from 30 1000 steps before it gives me an error like this The dimension mismatch is from what I can tell from from looking in losses py the number of anchors but I really do not know how to try debug this FWIW the training on ssd runs without issue so far A bit of info about the dataset the images all contain multiple likely crowded of the same object,,,2017-07-04 07:27:08,2017-07-06 16:53:13
IS,gridlstm,Hello 1 where can find an example for GRIDLSTM 2D or multi diagonal i search in net but not found 2 known that tensorflow support from keras how can insert a tensorflow layer in keras THANKS,,,2017-07-02 10:25:50,2017-07-06 17:03:03
IS,AttributeError 'module' object has no attribute 'prepare attention',Tensorflow Version I'm not sure what why the tf contrib seq2seq cannot find prepare attention any clue to why that is would be appreciated,,,2017-07-01 00:21:25,2017-07-06 17:05:05
PR,OpenCL Fixes SYCL registration for MapStageOp 117,OpenCL Fixes SYCL registration for MapStageOp As the MapStageOp is actually run on the host we need to ensure that both the 'key' and 'indices' tensors are in host memory This now mirrors what CUDA is doing OpenCL Fixes device name comparison map stage op test Changes the expected device name string as the device name could be ' device SYCL 0' or ' device GPU 0' The CUDA device name reported by test util is in the form ' gpu 0' while the device name used in the nodes looks like ' device GPU 0' When running on CUDA we need to change the expected device name accordingly however this is not a problem on SYCL,,"lukeiwanski,caisq,caisq",2017-07-06 11:01:50,2017-07-06 17:10:42
IS,Memory leak when using tf layers,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 5 Exact command to reproduce Describe the problem There is some kind of memory leak when repeatedly building graphs containing tf layers elements The example above shows the memory usage comparing what I think should be roughly equivalent implementations one using tf layers dense and the other using manually created kernels matmul ops When using tf layers dense the memory usage continually increases whereas the manual approach shows memory being periodically cleaned up by garbage collection So my guess would be that there is some internal reference to the tf layers elements that is preventing them from being garbage collected not using tf layers dense non layer using tf layers dense with layer,,"drasmuss,drasmuss",2017-07-04 14:24:07,2017-07-06 17:11:18
PR,Fix memory leak when using tf layers,Uses weakref so that PER GRAPH LAYER NAME UIDS does not prevent Graphs from being garbage collected Fixes 11273,,"drasmuss,drpngx",2017-07-04 15:56:58,2017-07-06 17:11:18
IS,BeamSearchDecoder Bug on beam width,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Pip Binary TensorFlow version use command below 1 2 1 Python version 3 4 My coustom code,,,2017-07-06 09:56:00,2017-07-06 17:21:15
IS,tf image rgb to grayscale Bug,Hi I have the same problem with this one with the current version of tensorflow under python 3 5 It seems that tf image rgb to grayscale cannot accept RGB input Wonder if anyone could check this Many thanks,,mrry,2017-07-06 16:43:49,2017-07-06 17:31:31
PR,Fix an error,Fix an error or the if statement will never be true,,"Kongsea,drpngx,drpngx,caisq,caisq",2017-06-30 02:21:15,2017-07-06 18:12:23
IS,ImportError No module named ' pywrap tensorflow' while trying to run TensorFlow,Traceback most recent call last File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File c Python35 32 lib imp py line 296 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File c Python35 32 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File c Python35 32 lib site packages tensorflow init py line 24 in module from tensorflow python import File c Python35 32 lib site packages tensorflow python init py line 60 in module raise ImportError msg ImportError Traceback most recent call last File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File c Python35 32 lib imp py line 296 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File c Python35 32 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File c Python35 32 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ImportError No module named ' pywrap tensorflow' Error importing tensorflow Unless you are using bazel you should not try to import tensorflow from its source directory please exit the tensorflow source tree and relaunch your python interpreter from there SYSTEM DETAILS 1 NVIDIA GeForce 920M 2 Cuda Toolkit 8 0 3 cudNN 5 1 version 4 Visual Studio 2015 also Visual Studio C Redistributable 2015 5 Windows 10,,,2017-06-29 09:07:13,2017-07-06 20:18:34
PR,XLA Add scaffolding to allow XLA unit tests to run for other devices,This is an indentical change to the one in the compiler tests directory It allows devices other than the CPU and GPU to be available targets when running the tests in compiler xla tests,,"DavidNorman,tatatodd,tatatodd,drpngx,drpngx,DavidNorman,DavidNorman,drpngx,tatatodd,DavidNorman,DavidNorman,drpngx",2017-07-04 06:29:56,2017-07-06 20:44:11
PR,Branch 161124799,,,"av8ramit,caisq,caisq,av8ramit",2017-07-06 21:14:44,2017-07-06 23:03:49
IS,TensorFlow 1 2 0 depends on a 5 year old release of the Markdown package,System information This is an installation problem Windows 10 64 bit Tensorflow installed from pip Version 1 2 0 Bazel version None CUDA v8 CuDNN v6 GTX980Ti and Pascal TITAN X python m pip install tensorflow gpu 1 2 0 Describe the problem TensorFlow 1 2 0 has added a new dependency on the markdown 2 2 0 package This package is being actively maintained and the latest version of it is 2 6 8 However Tensorflow 1 2 0 has a strict dependency on version 2 2 0 which was released July 2012 almost 5 years ago As such the package no longer installs cleanly on all modern distributions of python I am attempting to use the Windows python 3 6 1 embed amd64 release but when attempting to install either Tensorflow 1 2 0 or markdown 2 2 0 on this environment installation fails due to a syntax issue in the Markdown package I have not delved deep into the issue but have included log output from trying to use pip to install tensorflow on this system However the most recent version of markdown 2 6 8 installs fine under this environment Is there a good reason for why Tensorflow specifically requires the old version Can the dependency be upgraded to a later version that will support the embedded 3 6 1 Windows release of python Surely taking on a legacy dependency like this is not ideal and should hopefully be fixed Source code logs,,"aselle,gunan,dandelionmane,gunan,av8ramit,av8ramit",2017-06-26 10:56:18,2017-07-06 23:23:15
IS,Error when build tfprof bazel version 0 5 2,Hi I want to try with tfprof but failed to build the tool The error information is as follow System information OS Platform and Distribution Linux Ubuntu 14 04 Bazel version if compiling from source 0 5 2 Exact command to reproduce,,"ScorpioCPH,ScorpioCPH",2017-07-05 03:36:13,2017-07-06 23:40:51
PR,Branch 161140653,,,"av8ramit,av8ramit,av8ramit",2017-07-06 23:05:32,2017-07-07 01:10:07
IS,Go SIGABRT when executing the same node more than once,Problem In Go when we pass the same node to the fetches list more then once SIGABRT is raised Source code logs as expected System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Archlinux TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version cuda 8 cudnn 5 1 GPU model and memory GeForce GTX 1080 Exact command to reproduce go test,,asimshankar,2017-06-29 08:49:31,2017-07-07 01:10:24
IS,Tfdbg does not work with Coordinator QueueRunners,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem The Tensorflow debugger does not seem to be working with Queues data never seems to be fetched by the QueueRunner threads be it from a file using tf TFRecordReader and tf parse single example or preloaded using tf train slice input producer Instead the coordinator should stop is True right away This is only the case after wrapping the session in a tf python debug LocalCLIDebugWrapperSession The example should make things clearer Moreover another error occurs at coordinator join threads I am aware of the FAQ entry on Threads but that does not explain why the data fetching threads would not be working Source code logs To make it easiest to replicate I simply took the example on working with preloaded data and wrapped the session in there with the debugger I uploaded the gist with two lines added to file fully connected preloaded debug py L92 To reproduce run the file Once you drop in the debugger run once It then exits The full output is below The stacktrace is about coord join threads but this is only possible because coord should stop never seems to be False which would indicate there is data to load Without the added debugger lines the example simply works,,"caisq,caisq,caisq,caisq",2017-06-23 17:18:55,2017-07-07 01:10:24
PR,c fix a possible segmentfault,We also need allocation for output values when updating output or we will get a segment fault on,,"caisq,caisq",2017-07-06 09:47:37,2017-07-07 01:38:51
PR,Fix broken link for reader base proto,This fix fixes broken links for reader base proto in version compat md and version semantics md tensorflow core kernels reader base proto tensorflow core framework reader base proto Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,caisq",2017-07-02 00:23:39,2017-07-07 01:45:54
PR,Use mcpu instead of march for ppc64le,march is not support by gcc on ppc64le,,caisq,2017-07-06 18:14:18,2017-07-07 01:55:34
IS,Does tensorflow support mfcc now,Is mfcc support in tensorflow now I found this but I can not find this op in Python API in tensorflow So is that not open yet Or it is wrapped in some other Python api,,asimshankar,2017-07-07 04:38:45,2017-07-07 06:00:20
IS,can not find some header files when i'm using c c API eg tensorflow core example example pb h,TF version 1 1 0 ubuntu 14 04 install by pip In many examples about c or c API in tensorflow i can find some codes like include tensorflow core example example pb h include tensorflow core example feature pb h include tensorflow core framework graph pb text h but in the folder where tensorflow is intalled i can not find these file someone knows why,,asimshankar,2017-07-07 07:04:38,2017-07-07 07:13:50
PR,Use custom BUILD file for protobuf,This change wo not be needed after updating protobuf to a version containing google protobuf 0b059a3,,"meteorcloudy,meteorcloudy,meteorcloudy",2017-07-03 09:53:04,2017-07-07 07:57:14
PR,Fixed typo in docstring,,,,2017-07-07 04:17:50,2017-07-07 13:49:29
PR,Fix misspells,Fix misspells on comments,,"chris-chris,caisq",2017-07-07 12:23:10,2017-07-07 14:31:50
PR,Minor fix typo,Minor fix comments typo,,"ScorpioCPH,caisq,caisq,ScorpioCPH,caisq,ScorpioCPH,ScorpioCPH",2017-07-06 11:19:27,2017-07-07 14:56:41
PR,Remove unnecessary empty BUILD file DO NOT MERGE,,,caisq,2017-07-07 16:08:10,2017-07-07 16:09:44
IS,Feature are incompatible with given information in evaluate using contrib learn SVM,Code is as follows I cannot find any relevant questions online and therefore is very lost Please help Thanks in advance,,,2017-07-05 22:27:19,2017-07-07 16:13:29
IS,About if tensorflow can use flask to mount in IIS use like as an web API to use,I set up a tensorflow system use flask grammar to set up And in local computer all run ok no error But when I mount it in IIS as Web API to use It always show FASTCGI error Does tensorflow incompatiable with IIS,,,2017-07-03 06:30:22,2017-07-07 16:28:16
IS,Use pretrained model VGG16 for android app demo example,I download demo example which uses tensorflow inception graph pb from the google tensorflow download page What I want to do is to replace it with vgg 16 pb The same demo app only difference is the model' But I need a help for replacing those with new ones In ClassifierActivity java,,,2017-07-07 16:12:41,2017-07-07 16:29:02
IS,ValueError Variable vgg 16 conv1 conv1 1 weights already exists disallowed,I got this kind of error message when trying use existing weight Code Please advice Thank you,,,2017-07-06 20:09:33,2017-07-07 16:36:10
IS,quantify the mobilenet,I try to quantify the mobilenet in the ssd mobilenet v1 coco the tensorflow I use is v1 2 bazel build tensorflow tools quantization quantize graph bazel bin tensorflow tools quantization quantize graph input bazel build tensorflow tools quantization quantize graph bazel bin tensorflow tools quantization quantize graph input ssd mobilenet v1 coco 11 06 2017 frozen inference graph pb output node names print nodes output tmp quantized graph pb mode eightbit logtostderr but I do not decide the out node names,,,2017-07-03 07:00:34,2017-07-07 16:39:06
IS,wide n deep AttributeError master and ValueError r1 2,I'm using TensorFlow 1 2 1 When I run python wide n deep tutorial py model type wide from the Linear Model tutorial I get the following AttributeError,,,2017-07-06 15:33:32,2017-07-07 17:13:56
PR,Adapt TensorFlowTestCase setUp to new reset default graph semantics,Avoid calling reset default graph directly to prevent exceptions in cases where test methods error out from within nested graph contexts which can leave default graph stack non empty in certain Python versions This should address the test failures tensorflow python session test and tensorflow contrib session bundle exporter test introduced by 11158 in certain Python versions e g Mac Python 3 5 cc,,"caisq,mrry,caisq,caisq,drpngx,caisq,drpngx,caisq,av8ramit,caisq,mrry",2017-07-07 03:27:25,2017-07-07 17:18:44
IS,feature request Inconsistency of new Decoder api and Dense layer,TF 1 1 has released new seq2seq API tf contrib seq2seq BasicDecoder etc and Decoders have output layer parameter which must be subclass of tf layers Layer If one wants to use dense projection it has to do from tensorflow python layers core import Dense which seems a bit inconvenient Maybe the better way is to include Dense and Dropout classes into tf layers After that one could write just tf layers Dense or tf layers Dropout,,,2017-07-06 19:42:19,2017-07-07 17:47:00
IS,Examples in 'Getting started with tensor flow' use deprecated methods,Basic Usage example output WARNING tensorflow Using temporary folder as model directory C Users pocherka AppData Local Temp tmpaq48b 3u WARNING tensorflow From C Users pocherka AppData Local Programs Python Python35 lib site packages tensorflow contrib learn python learn estimators head py 625 scalar summary from tensorflow python ops logging ops is deprecated and will be removed after 2016 11 30 Instructions for updating Please switch to tf summary scalar Note that tf summary scalar uses the node name instead of the tag This means that TensorFlow will automatically de duplicate summary names based on the scope they are created in Also passing a tensor or list of tags to a scalar summary op is no longer supported WARNING tensorflow From C Users pocherka AppData Local Programs Python Python35 lib site packages tensorflow contrib learn python learn estimators head py 625 scalar summary from tensorflow python ops logging ops is deprecated and will be removed after 2016 11 30 Instructions for updating Please switch to tf summary scalar Note that tf summary scalar uses the node name instead of the tag This means that TensorFlow will automatically de duplicate summary names based on the scope they are created in Also passing a tensor or list of tags to a scalar summary op is no longer supported WARNING tensorflow From C Users pocherka AppData Local Programs Python Python35 lib site packages tensorflow contrib learn python learn estimators head py 625 scalar summary from tensorflow python ops logging ops is deprecated and will be removed after 2016 11 30 Instructions for updating Please switch to tf summary scalar Note that tf summary scalar uses the node name instead of the tag This means that TensorFlow will automatically de duplicate summary names based on the scope they are created in Also passing a tensor or list of tags to a scalar summary op is no longer supported train loss 'global step' 1000 'loss' 2 3828899e 11 eval loss 'global step' 1000 'loss' 0 0025255322 sic usage,,drpngx,2017-07-04 19:39:48,2017-07-07 18:04:10
IS,Cannot run example in tensorflow docker due to missing dependency,Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary running in official docker container TensorFlow version use command below 1 1 0 Python version 2 7 CUDA cuDNN version CUDA 8 0 GPU model and memory Titan X Exact command to reproduce docker run it p 8888 8888 gcr io tensorflow tensorflow Describe the problem The official tensorflow docker container does not include h5py This might be intentional However this breaks an example tensorflow tensorflow examples learn hdf5 classification py This also causes a number of contrib methods to raise exceptions tensorflow tensorflow contrib learn python learn learn io data feeder test py a numbert of keras contrib files,,caisq,2017-07-07 16:41:26,2017-07-07 18:25:42
PR,add h5py to dockerfile,Add h5py to dockerfile Fixes 11356,,"caisq,caisq,caisq",2017-07-07 17:58:38,2017-07-07 18:25:42
PR,Revert Added assertion error in reset default graph 11158,This reverts commit 3db38f15877457c8c2a5c92d66afc0df29fe1f66 Appears to fail on Mac see TF BUILD IS PIP NO PIP TF BUILD PYTHON VERSION PYTHON3 label mac slave 537 consoleFull See PR thread for more information,,"drpngx,drpngx,drpngx,caisq,caisq,caisq",2017-07-03 17:36:34,2017-07-07 18:35:46
IS,tf assert equal throws object was never used error in v1 2 x,The following code is copied from some tensorflow repository outside tf assert equal tf size x tf constant 1 While running in tensorflow v1 2 0 or v1 2 1 it throws the following log ERROR tensorflow Object was never used type class 'tensorflow python framework ops Operation' tf Operation 'update hyper cond assert equal Assert Assert' type Assert If you want to mark it as used call its mark used method It was originally created here 'File usr lib64 python3 5 runpy py line 193 in run module as main n main mod spec ' 'File usr lib64 python3 5 runpy py line 85 in run code n exec code run globals ' 'File usr lib python3 5 site packages ipykernel launcher py line 16 in module n app launch new instance ' 'File usr lib python3 5 site packages traitlets config application py line 658 in launch instance n app start ' 'File usr lib python3 5 site packages ipykernel kernelapp py line 477 in start n ioloop IOLoop instance start ' 'File usr lib64 python3 5 site packages zmq eventloop ioloop py line 177 in start n super ZMQIOLoop self start ' 'File usr lib64 python3 5 site packages tornado ioloop py line 888 in start n handler func fd obj events ' 'File usr lib64 python3 5 site packages tornado stack context py line 277 in null wrapper n return fn args kwargs ' 'File usr lib64 python3 5 site packages zmq eventloop zmqstream py line 440 in handle events n self handle recv ' 'File usr lib64 python3 5 site packages zmq eventloop zmqstream py line 472 in handle recv n self run callback callback msg ' 'File usr lib64 python3 5 site packages zmq eventloop zmqstream py line 414 in run callback n callback args kwargs ' 'File usr lib64 python3 5 site packages tornado stack context py line 277 in null wrapper n return fn args kwargs ' 'File usr lib python3 5 site packages ipykernel kernelbase py line 283 in dispatcher n return self dispatch shell stream msg ' 'File usr lib python3 5 site packages ipykernel kernelbase py line 235 in dispatch shell n handler stream idents msg ' 'File usr lib python3 5 site packages ipykernel kernelbase py line 399 in execute request n user expressions allow stdin ' 'File usr lib python3 5 site packages ipykernel ipkernel py line 196 in do execute n res shell run cell code store history store history silent silent ' 'File usr lib python3 5 site packages ipykernel zmqshell py line 533 in run cell n return super ZMQInteractiveShell self run cell args kwargs ' 'File usr lib python3 5 site packages IPython core interactiveshell py line 2698 in run cell n interactivity interactivity compiler compiler result result ' 'File usr lib python3 5 site packages IPython core interactiveshell py line 2802 in run ast nodes n if self run code code result ' 'File usr lib python3 5 site packages IPython core interactiveshell py line 2862 in run code n exec code obj self user global ns self user ns ' 'File ipython input 13 85a15e405d64 line 1 in module n h1 m1 fit nn train x nn train y epochs epochs batch size batch size verbose 0 ' 'File usr lib python3 5 site packages keras models py line 870 in fit n initial epoch initial epoch ' 'File usr lib python3 5 site packages keras engine training py line 1490 in fit n self make train function ' 'File usr lib python3 5 site packages keras engine training py line 1014 in make train function n self total loss ' 'File ipython input 5 1252bd787625 line 7 in get updates n opt update self optimizer apply gradients grads ' 'File data jupyter yellowfin yellowfin py line 223 in apply gradients n update hyper op self update hyper param ' 'File data jupyter yellowfin yellowfin py line 191 in update hyper param n lambda self mu var ' 'File usr lib python3 5 site packages tensorflow python util deprecation py line 289 in new func n return func args kwargs ' 'File usr lib python3 5 site packages tensorflow python ops control flow ops py line 1814 in cond n orig res t res t context t BuildCondBranch true fn ' 'File usr lib python3 5 site packages tensorflow python ops control flow ops py line 1689 in BuildCondBranch n original result fn ' 'File data jupyter yellowfin yellowfin py line 190 in lambda n self mu tf identity tf cond self do tune lambda self get mu tensor ' 'File data jupyter yellowfin yellowfin py line 180 in get mu tensor n tf assert equal tf size root tf constant 1 ' 'File usr lib python3 5 site packages tensorflow python ops check ops py line 318 in assert equal n return control flow ops Assert condition data summarize summarize ' 'File usr lib python3 5 site packages tensorflow python util tf should use py line 170 in wrapped n return add should use warning fn args kwargs ' 'File usr lib python3 5 site packages tensorflow python util tf should use py line 139 in add should use warning n wrapped TFShouldUseWarningWrapper x ' 'File usr lib python3 5 site packages tensorflow python util tf should use py line 96 in init n stack s strip for s in traceback format stack ' What I expect would be an exception thrown only when the assertion evaluates to false Why is it a must to use object returned from assert statement,,"ilya-edrenkin,ebrevdo",2017-07-06 04:45:41,2017-07-07 18:42:05
IS,Feature request do not reload latest checkpoint on each DNNRegressor predict call,Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Each DNNRegressor predict or predict scores call reloads model parameters from the latest saved model checkpoint even if the checkpoint has not changed between predict calls This slows down generation of predictions It will be helpful to be able to disable reloading of model parameters after the initial loading and or to be able to reload the latest checkpoint manually via a separate function call,,"martinwicke,martinwicke",2017-07-04 01:55:49,2017-07-07 20:13:55
PR,Allowing the PIP TEST ROOT variable to be set,PiperOrigin RevId 161087696,,av8ramit,2017-07-07 20:09:33,2017-07-07 22:26:32
IS,Variables in Dataset functions not always initialized,System information OS MacOS 10 12 4 TensorFlow stock cpu tensorflow 1 2 from pip Python Python 2 7 13 Describe the problem When using a Dataset function containing tf Variables needing initialization it succeeds sometimes but fails other times I have not managed to pin point it further using sleep s or tf control dependencies Source code logs,,alextp,2017-07-03 08:49:22,2017-07-07 22:41:10
IS,Correction to Getting Started,Hello I would like to submit that there is a programming bug on line 29 of the custom model tutorial within Getting Started with Tensorflow The line should read input fn tf contrib learn io numpy input fn x x train y train batch size 4 num epochs 1000 Best regards Jeff,,"skye,aselle",2017-06-28 20:49:21,2017-07-08 00:03:51
PR,adds missing pass to empty method in tf contrib learn DNNClassifier doc,adds missing pass to empty method in tf contrib learn DNNClassifier doc,,caisq,2017-07-05 21:01:19,2017-07-08 01:36:30
IS,TypeError Input istrides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin',I just want to get a slice of a tensor It works for int32 but not for int64,,"vrv,vrv,vrv",2017-07-06 09:06:48,2017-07-08 11:50:59
IS,tensorflow ValueError Operation 'init' has been marked as not fetchable Plz Help,I started working with LSTMs for conversation modelling I have got a sample piece of code with a persistent error The code is given below ''' A Dynamic Recurrent Neural Network LSTM implementation example using TensorFlow library This example is using a toy dataset to classify linear sequences The generated sequences have variable length Long Short Term Memory paper Author Aymeric Damien Project ''' from future import print function import tensorflow as tf import random data path C Users AnacondaProjects Convmodels CleanedData embeddings TOY DATA GENERATOR class ToySequenceData object def init self n samples 100 max seq len 10 min seq len 2 self data self labels self seqlen dummy vector float 0 0 for i in range 300 for i in range n samples with open data path str i txt r encoding utf 8 as inp input line float i for i in line split for line in inp current input for j in range min 10 len input line 1 current input append input line j temp data current input temp data temp data dummy vector for k in range max seq len j 1 current input temp data self data append temp data self labels append input line j 1 self seqlen append j 1 i i min 10 len input line 1 1 self batch id 0 def next self batch size Return a batch of data When dataset end is reached start over if self batch id len self data self batch id 0 batch data self data self batch id min self batch id batch size len self data batch labels self labels self batch id min self batch id batch size len self data batch seqlen self seqlen self batch id min self batch id batch size len self data self batch id min self batch id batch size len self data return batch data batch labels batch seqlen MODEL Parameters learning rate 0 01 training iters 1000 batch size 128 display step 10 Network Parameters seq max len 10 Sequence max length n hidden 64 hidden layer num of features n classes 300 linear sequence or not trainset ToySequenceData n samples 100 max seq len seq max len testset ToySequenceData n samples 20 max seq len seq max len tf Graph input x tf placeholder float None seq max len n classes y tf placeholder float None n classes A placeholder for indicating each sequence length seqlen tf placeholder tf int32 None Define weights Weights 'out' tf Variable tf random normal n hidden n classes Biases 'out' tf Variable tf random normal n classes def dynamicRNN x seqlen Weights Biases Prepare data shape to match rnn function requirements Current data input shape batch size n steps n input Required shape 'n steps' tensors list of shape batch size n input Unstack to get a list of 'n steps' tensors of shape batch size n input x tf unstack x seq max len 1 Define a lstm cell with tensorflow with tf variable scope 'lstm cell def' lstm cell tf contrib rnn BasicLSTMCell n hidden Get lstm cell output providing isequence length' will perform dynamic calculation with tf variable scope 'rnn cell def' reuse True outputs states tf contrib rnn static rnn lstm cell x dtype tf float32 sequence length seqlen When performing dynamic calculation we must retrieve the last dynamically computed output i e if a sequence length is 10 we need to retrieve the 10th output However TensorFlow does not support advanced indexing yet so we build a custom op that for each sample in batch size get its length and get the corresponding relevant output 'outputs' is a list of output at every timestep we pack them in a Tensor and change back dimension to batch size n step n input outputs tf stack outputs outputs tf transpose outputs 1 0 2 Hack to build the indexing and retrieve the right output batch size tf shape outputs 0 Start indices for each sample index tf range 0 batch size seq max len seqlen 1 Indexing outputs tf gather tf reshape outputs 1 n hidden index Linear activation using outputs computed above return tf matmul outputs Weights 'out' Biases 'out' pred dynamicRNN x seqlen Weights Biases Define loss and optimizer cos dist tf losses cosine distance predictions pred labels y dim 1 cost tf reduce mean tf nn softmax cross entropy with logits logits pred labels y optimizer tf train GradientDescentOptimizer learning rate learning rate minimize cos dist Evaluate model correct pred tf equal tf argmax pred 1 tf argmax y 1 normalize pred tf nn l2 normalize pred 1 normalize y tf nn l2 normalize y 1 correct pred 1 tf reduce sum tf multiply normalize pred normalize y 2 accuracy tf reduce mean tf cast correct pred tf float32 Initializing the variables init tf global variables initializer Launch the graph with tf Session as sess sess run init step 1 Keep training until reach max iterations while step batch size training iters batch x batch y batch seqlen trainset next batch size Run optimization op backprop sess run optimizer feed dict x batch x y batch y seqlen batch seqlen if step display step 0 Calculate batch accuracy acc sess run accuracy feed dict x batch x y batch y seqlen batch seqlen Calculate batch loss loss sess run cost feed dict x batch x y batch y seqlen batch seqlen print Iter str step batch size Minibatch Loss 6f format loss Training Accuracy 5f format acc step 1 print Optimization Finished Calculate accuracy test data testset data test label testset labels test seqlen testset seqlen print Testing Accuracy sess run accuracy feed dict x test data y test label seqlen test seqlen When I run this it get ValueError Operation 'init' has been marked as not fetchable and pointing to line sess run init Please kindly help Thanks in advance,,,2017-07-08 14:06:39,2017-07-08 14:10:53
PR,Disable more timeseries py tests failing under GPU PIP,,,caisq,2017-07-08 14:53:54,2017-07-08 15:07:41
PR,test for partial run setup with no feeds passed,,,,2017-07-08 15:36:11,2017-07-08 15:38:13
PR,Improve examples for Python 3 compatibility,This PR improves examples in docstrings for Python 3 compatibility,,"taehoonlee,caisq",2017-07-07 08:55:52,2017-07-08 22:24:53
IS,Feature Request Tensor DebugString for GPU backed tensors,Currently it crashes when calling Tensor SummarizeValue and Tensor DebugString in GPU backed tensors I am wondering if there is a better way to debug when writing GPU code,,"byronyi,byronyi",2017-07-09 04:31:30,2017-07-09 04:41:04
IS,py func does not properly,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version Cudnn v5 1 GPU model and memory Pascal Titan X Exact command to reproduce,,,2017-07-08 14:34:58,2017-07-09 05:01:16
IS,Error while executing the imagenet train model,bazel bin inception imagenet train num gpus 4 batch size 256 train dir tmp data dir root kits dataset Traceback most recent call last File root models inception bazel bin inception imagenet train runfiles inception inception imagenet train py line 41 in module tf app run File root anaconda2 envs tensor lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File root models inception bazel bin inception imagenet train runfiles inception inception imagenet train py line 37 in main inception train train dataset File root models inception bazel bin inception imagenet train runfiles inception inception inception train py line 217 in train num preprocess threads num preprocess threads File root models inception bazel bin inception imagenet train runfiles inception inception image processing py line 136 in distorted inputs num readers FLAGS num readers File root models inception bazel bin inception imagenet train runfiles inception inception image processing py line 490 in batch inputs example serialized File root models inception bazel bin inception imagenet train runfiles inception inception image processing py line 397 in parse example proto bbox tf concat 0 ymin xmin ymax xmax File root anaconda2 envs tensor lib python3 6 site packages tensorflow python ops array ops py line 1029 in concat dtype dtypes int32 get shape File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework ops py line 639 in convert to tensor as ref False File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework ops py line 704 in internal convert to tensor ret conversion func value dtype dtype name name as ref as ref File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework constant op py line 113 in constant tensor conversion function return constant v dtype dtype name name File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework constant op py line 102 in constant tensor util make tensor proto value dtype dtype shape shape verify shape verify shape File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework tensor util py line 370 in make tensor proto AssertCompatible values dtype File root anaconda2 envs tensor lib python3 6 site packages tensorflow python framework tensor util py line 302 in AssertCompatible dtype name repr mismatch type mismatch name TypeError Expected int32 got list containing Tensors of type ' Message' instead Using Tensorflow 1 1 inside Anaconda Python version 3 6 1 Machine Power 8 OS Ubuntu 16 04 Can someone tell me why am I getting this error,,skye,2017-06-29 15:05:40,2017-07-09 05:48:57
IS,saver will cause crash error message InvalidArgumentError Shape xx has negative dimensions,It should be a bug of tensorflow add the saver will cause the procedure crash error message is strange as following InvalidArgumentError see above for traceback Shape 1 32 32 3 has negative dimensions Node x Placeholder dtype DT FLOAT shape 32 32 3 device job localhost replica 0 task 0 cpu 0 the added part is if i 1000 0 or i num iterations 1 Save all variables of the TensorFlow graph to a checkpoint Append the global step counter to the filename so we save the last several checkpoints saver save sess save path save dir global step train step System information cat etc issue Darwin zhangdeMacBook Pro local 16 6 0 Darwin Kernel Version 16 6 0 Fri Apr 14 16 21 16 PDT 2017 root xnu 3789 60 24 6 RELEASE X86 64 x86 64 Mac OS X 10 12 5 are we in docker No compiler Apple LLVM version 8 1 0 clang 802 0 42 Target x86 64 apple darwin16 6 0 Thread model posix InstalledDir Library Developer CommandLineTools usr bin uname a Darwin zhangdeMacBook Pro local 16 6 0 Darwin Kernel Version 16 6 0 Fri Apr 14 16 21 16 PDT 2017 root xnu 3789 60 24 6 RELEASE X86 64 x86 64 check pips numpy 1 13 0 protobuf 3 3 0 tensorflow 1 2 1 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi cuda libs Tensorflow version v1 2 0 5 g435cdfc 1 2 1 Source code logs source code,,,2017-07-08 03:48:21,2017-07-09 08:18:50
IS,I used TensorFlow to build a deep learning training network and test network and I was going to use the weights in the training network to use as the weight of the test network where the training network and the test network were not the same how should I solve,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-07-09 08:16:09,2017-07-09 08:55:38
PR,fix broken link in adding an op md,,,"zasdfgbnm,zasdfgbnm",2017-07-09 13:50:30,2017-07-09 15:13:21
PR,Fix typos,This PR fixes some typos Acccumulate represnting and implictly,,taehoonlee,2017-07-10 00:13:32,2017-07-10 01:23:46
IS,Feature Tensorflow works on ubuntu12 04,Hi all I have a computing cluster with a master and some slaves I want to tran the AI model on master and then send to slaves for calculation But for some reason part of slaves works on ubuntu12 04 and i can not update them to 14 04 so how can i get a lite tensorflow or a saved model lib than can be restored on ubuntu12 04 slaves Many thanks,,gunan,2017-07-08 07:23:40,2017-07-10 15:48:49
IS,My problem tensor flow connect with Windows IIS Hello i just ask a question three days ago but no response can you spend some time to reply me,I set up a tensorflow system use flask grammar to set up And in local computer all run ok no error But when I mount it in IIS as Web API to use It always show FASTCGI error Does tensorflow incompatiable with IIS,,"ScorpioCPH,gunan,gunan",2017-07-06 00:59:57,2017-07-10 15:52:58
IS,undefined reference to isoc interface AllocateInOutNodeBuffers' Hexagon build failed with latest commit,OS Ubuntu 16 04 64bits Android Version 7 1 Nougat NDK Version android ndk r12b HEXAGON SDK 3 1 nnlib source I have cloned to git commit id 43a819e1386195f7010f8ca9c74ed96ab81913d8 when I try to build executable for hexagon CC PREFIX CC PREFIX NDK ROOT NDK ROOT BUILD ALL ANDROID PATH x GEN LIBS DIR s TF ROOT DIR tensorflow contrib makefile sub makefiles hexagon graph execution Makefile in t hexagon graph execution I am getting build error build changes are moved partially out of tensorflow contrib makefile sub makefiles hexagon graph execution Makefile in is this the possible cause for error I am not sure I can pull out latest commit and build over that but right now I am stuck at build fail Help me with a fix,,,2017-07-05 14:15:40,2017-07-10 16:54:38
IS,Upgrading to 1 2 Causes Issue with CUDA,I do not know how to describe my problem any better than that unfortunately Previously I was running TensorFlow 1 0 and I could successfully use CUDA What can I do to fix this problem,,"aselle,gunan",2017-07-08 18:37:00,2017-07-10 17:09:37
PR,XLA Ensure that the 2 data types chosen by the test are both valid for the device,Simple change The test previously assumed that all devices support float64 which is not true for our device Now the test will find 2 different floating point types and use those Does not execute if there are not 2 floating point types to choose from,,"DavidNorman,drpngx,DavidNorman,DavidNorman,DavidNorman,drpngx,drpngx,DavidNorman,drpngx,caisq,DavidNorman,DavidNorman,DavidNorman,DavidNorman,caisq,DavidNorman,DavidNorman,drpngx,DavidNorman,DavidNorman,drpngx,DavidNorman,drpngx",2017-06-30 12:57:28,2017-07-10 17:39:50
IS,Slim Training accuracy is increasing very slowly,Hi I feel something odd is happening with my Inception Resnet v2 training I am what I'm seeing is correct but it seems the training will take forever at the current rate I am training slim against the full Imagenet dataset approx 14M images The training is running on 8GPUs and the batch size is the default 32 If my calculations are correct this means that each epoch should consist of approximately 54 000 steps 14 000 000 8 32 The training has been running for 800 000 steps so far approx 15 epochs yet the accuracy just reached 22 I have been evaluating the model after each 100 000 steps and at the start the accuracy used to increase by 5 after each 100 000 step up until 500 000 steps yet now it seems to be rapidly slowing down as now I am getting in approximate 0 8 increase every 100 000 steps after reaching the 500 000 steps mark I am not sure if this is expected as I do not have any data to compare it with but at this rate it can take several months maybe even years to reach a viable accuracy rate I am trying to reach somewhere above 70 at least Now is this expected Are there any ways to speed up training beside adding GPUs And if the latter is my only option is it possible to continue training on the same checkpoints once the number of GPUs has increased,,,2017-07-08 12:14:26,2017-07-10 18:03:48
PR,Fix minor docstring formatting issue,,,"guillaumekln,frankchn",2017-07-10 15:21:11,2017-07-10 18:41:57
PR,update folder link in docs,,,"brettkoonce,brettkoonce,frankchn",2017-07-09 20:16:51,2017-07-10 18:43:20
PR,R1 2,,,frankchn,2017-07-10 18:39:27,2017-07-10 19:22:04
PR,MPI path updates,This commit contains two updates Fixes a problem with uniquely identifying processes Simplifies tensor receive call selection and prevents problems with too eagerly freeing resources,,"jbedorf,frankchn",2017-07-10 13:11:10,2017-07-10 19:22:27
PR,Only use weakref finalize from backports in Python 3 4,The backports module should not be forced as a dependency for Python 3 4 as weakref finalize has been introduced in Python 3 4 This solves 11082 and an Arch Linux bug,,"ebrevdo,drpngx,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,caisq,ebrevdo,caisq",2017-06-30 14:01:46,2017-07-10 19:26:19
PR,Changed to correct version,,,,2017-07-10 19:47:04,2017-07-10 19:54:48
IS,KL divergence not in tf contrib distributions as of 1 2 0,Apparently KL divergence is no longer in contrib distributions This page is broken and this file is removed tensorflow contrib distributions python ops kullback leibler py but I could not find it being mentioned in the changelog Did I miss it,,,2017-07-10 20:14:17,2017-07-10 20:30:22
PR,WAV encoding decoding fixes,Hi This PR contains two WAV related fixes Fixes WAV encoding decoding for multi channel data DecodeLin16WaveAsFloatVector was failing for multi channel data with Bad bytes per second due to it expecting the byte rate to be that for a single channel whereas the header specifies the byte rate for all channels EncodeAudioAsS16LEWav was incorrectly encoding the byte rate as that for a single channel instead of for all channels Fixes shape function for the DecodeWav op The function was returning a non ok status when either desired samples channels attributes were default now we use the unknown dim instead Cheers,,"andykernahan,frankchn,andykernahan,rryan",2017-07-10 16:45:22,2017-07-10 22:22:31
PR,Daily Pull Request July 10th 2017,,,"frankchn,frankchn,frankchn,drpngx,jhseu,frankchn",2017-07-10 22:50:50,2017-07-11 00:12:45
IS,ModuleNotFoundError No module named ' pywrap tensorflow internal',Windows 10 Home Python 3 6 CUDA 8 0 7 5 cuDNN 5 1 for both 8 0 and 7 5 CUDA path variables set to 8 0 GeForce GTX 970 tensorflow installed from I also have Theano and CNTK installed and they both work the error happens when importing tensorflow import tensorflow as tf,,"mrry,mrry,mrry,mrry,mrry",2017-07-06 14:29:03,2017-07-11 01:59:07
PR,Fix sparse placeholder error when int is passed in shape argument,This fix tries to address the issue raised in 6749 where and error is thrown out in case int is passed in the shape argument This fix fixes the issue and adds test cases for it This fix fixes 6749 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,frankchn",2017-06-29 22:35:52,2017-07-11 04:14:22
IS,State of GPU support for commercial Android devices,Question has been asked in this thread but got no answer Just curious what is the plans of TF team to support Android GPUs or no plan at all for commercial devices such as Nexus I understand OpenCL is not included in Android now but we still have RenderScript And some work has already been put to this end It would be great to know it from TF developers,,"andrewharp,andrewharp",2017-07-05 15:43:23,2017-07-11 08:32:16
PR,modify SaverDef default version with v2,SaverDef V1 has been deprecated so modify default version with V2,,"horance-liu,frankchn,horance-liu,frankchn",2017-07-10 07:42:35,2017-07-11 10:59:26
IS,My CNN is not learning who can help me fix this porblem,import tensorflow as tf import Transform Data New as td import numpy as np max accuracy 0 timer 0 Epoch 300 learning rate 1e 3 training batch size 100 validation batch size 40 test batch size 40 len training data validation test td Initialization validation batch size test batch size iteration time int len training data training batch size 1 sess tf InteractiveSession def weight variable shape Name initial tf random normal shape stddev 0 2 mean 0 5 return tf Variable initial name Name def bias variable shape Name initial tf constant 0 1 shape shape return tf Variable initial name Name def conv2d x w return tf nn conv2d x w strides 1 1 1 1 padding 'SAME' def max pool 2x2 x return tf nn max pool x ksize 1 2 2 1 strides 1 2 2 1 padding 'SAME' with tf name scope 'Input' with tf name scope 'Input x' x tf placeholder tf float32 shape None 1024 with tf name scope 'Input y' y tf placeholder tf float32 shape None 7 with tf name scope 'Conv 1' with tf name scope 'W conv1' w conv1 weight variable 3 3 1 8 'w conv1' with tf name scope 'B conv1' b conv1 bias variable 8 'b conv1' with tf name scope 'x image' x image tf reshape x 1 32 32 1 with tf name scope 'H conv1' h conv1 tf nn relu tf nn bias add conv2d x image w conv1 b conv1 with tf name scope 'Conv 2' with tf name scope 'W conv2' w conv2 weight variable 3 3 8 16 'w conv2' with tf name scope 'B conv2' b conv2 bias variable 16 'b conv2' with tf name scope 'H conv2' h conv2 tf nn relu tf nn bias add conv2d h conv1 w conv2 b conv2 with tf name scope 'H pool2' h pool2 max pool 2x2 h conv2 with tf name scope 'Conv 3' with tf name scope 'W conv3' w conv3 weight variable 3 3 16 32 'w conv3' with tf name scope 'B conv3' b conv3 bias variable 32 'b conv3' with tf name scope 'H conv3' h conv3 tf nn relu tf nn bias add conv2d h pool2 w conv3 b conv3 with tf name scope 'Conv 4' with tf name scope 'W conv4' w conv4 weight variable 3 3 32 64 'w conv4' with tf name scope 'B conv4' b conv4 bias variable 64 'b conv4' with tf name scope 'H conv4' h conv4 tf nn relu tf nn bias add conv2d h conv3 w conv4 b conv4 with tf name scope 'H pool4' h pool4 max pool 2x2 h conv4 with tf name scope 'Conv 5' with tf name scope 'W conv5' w conv5 weight variable 3 3 64 128 'w conv5' with tf name scope 'B conv5' b conv5 bias variable 128 'b conv5' with tf name scope 'H conv5' h conv5 tf nn relu tf nn bias add conv2d h pool4 w conv5 b conv5 with tf name scope 'Conv 6' with tf name scope 'W conv6' w conv6 weight variable 3 3 128 256 'w conv6' with tf name scope 'B conv6' b conv6 bias variable 256 'b conv6' with tf name scope 'H conv6' h conv6 tf nn relu tf nn bias add conv2d h conv5 w conv6 b conv6 with tf name scope 'H pool6' h pool6 max pool 2x2 h conv6 with tf name scope 'Full Connected Layer 1' with tf name scope 'W fc1' w fc1 weight variable 4 4 256 1024 'w fc1' with tf name scope 'B fc1' b fc1 bias variable 1024 'b fc1' with tf name scope 'H pool flat' h pool flat tf reshape h pool6 1 4 4 256 with tf name scope 'H fc1' h fc1 tf nn relu tf matmul h pool flat w fc1 b fc1 with tf name scope 'Full Connected Layer 2' with tf name scope 'W fc2' w fc2 weight variable 1024 7 'w fc2' with tf name scope 'B fc2' b fc2 bias variable 7 'b fc2' with tf name scope 'Y conv' y conv tf nn softmax tf matmul h fc1 w fc2 b fc2 with tf name scope 'Cross Entropy' cross entropy tf reduce sum y tf log tf clip by value y conv 1e 10 1 0 tf summary scalar 'Cross Entropy' cross entropy with tf name scope 'Train Step' train step tf train AdamOptimizer learning rate minimize cross entropy with tf name scope 'Correct prediction' distribution tf arg max y 1 tf arg max y conv 1 correct prediction tf equal distribution 0 distribution 1 with tf name scope 'Accuracy' accuracy tf reduce mean tf cast correct prediction float tf summary scalar 'Accuracy' accuracy merged tf summary merge all writer tf summary FileWriter 'D Log' sess graph epoch 0 saver tf train Saver First training True checkpoint dir 'D Checkpoint model ckpt' if First training False ckpt tf train get checkpoint state checkpoint dir if ckpt and ckpt model checkpoint path saver restore sess checkpoint dir else sess run tf global variables initializer for i in range Epoch iteration time 1 Batch Size batch td next batch training batch size train step run feed dict x batch 0 y batch 1 if i iteration time 0 and i 0 epoch 1 train accuracy accuracy eval feed dict x batch 0 y batch 1 validation accuracy resultSet for j in range len validation validation accuracy accuracy eval feed dict x validation j 0 y validation j 1 validation accuracy resultSet append validation accuracy validation accuracy int np sum validation accuracy resultSet len validation accuracy resultSet if validation accuracy 0 7 learning rate 1e 3 if validation accuracy 0 7 and validation accuracy 0 8 learning rate 5e 4 if validation accuracy 0 8 and validation accuracy 0 9 learning rate 1e 4 if validation accuracy 0 9 learning rate 5e 5 print Epoch d training accuracy g Validation Accuracy g epoch train accuracy validation accuracy result sess run merged feed dict x batch 0 y batch 1 writer add summary result epoch saver save sess checkpoint dir global step epoch if validation accuracy max accuracy max accuracy validation accuracy timer 0 else timer 1 if timer 10 10 break confusion matrics np zeros 7 7 dtype int test accuracy resultSet for j in range len test matrix row matrix col sess run distribution feed dict x test j 0 y test j 1 for m n in zip matrix row matrix col confusion matrics m n 1 test accuracy accuracy eval feed dict x test j 0 y test j 1 test accuracy resultSet append test accuracy test accuracy np sum test accuracy resultSet len test accuracy resultSet print Test Accuracy test accuracy print np array confusion matrics tolist That is the whole code of my CNN the data for training validation test are all organized myself which is not the problem While training this CNN the result in Console showed that all weights and biases did not change If I replace the RELU in six convolutional layers with Sigmoid the CNN performed well Who can help me fix this problem Thanks anyway,,,2017-07-11 13:42:18,2017-07-11 13:42:50
PR,Branch 161478803,,,"caisq,caisq,frankchn,frankchn,caisq,caisq",2017-07-11 03:13:47,2017-07-11 14:04:32
IS,Error while slicing with int64,This is similar to 11318 but with a slice instead of an individual index I upgraded to the latest version using pip3 install user upgrade tensorflow gpu,,"aselle,vrv,vrv",2017-07-08 15:05:58,2017-07-11 14:04:53
IS,Resource exhausted error for translate py Seq2seq model CPU,Windows 10 Tensorflow 1 0 0 Python version 3 5 I get the following error when i try to run translate py for Seq2seq model Resource exhausted OOM when allocating tensor with shape 576 1024 Is there any way i could reduce the size in translate py so that the error does not occur Thanks,,,2017-07-11 08:38:35,2017-07-11 15:22:29
IS,My CNN is not learning who can help me fix this problem Thx,CNN txt That is the whole code of my CNN the data for training validation test are all organized myself which is not the problem While training this CNN the result in Console showed that all weights and biases did not change If I replace the RELU in six convolutional layers with Sigmoid the CNN performed well Who can help me fix this problem Thanks anyway,,,2017-07-11 13:45:08,2017-07-11 15:30:55
PR,Enable building grpc verbs runtime on any Linux box,I do not have a Windows machine so it is probably broken on Windows Currently I do not have an idea on how to achieve cross platform portability Any suggestions,,byronyi,2017-07-11 12:38:48,2017-07-11 17:07:37
IS,Crash F tensorflow core kernels conv ops cc 659 Check failed stream parent GetConvolveAlgorithms algorithms,E tensorflow stream executor cuda cuda dnn cc 352 Loaded runtime CuDNN library 6021 compatibility version 6000 but source was compiled with 5110 compatibility version 5100 If using a binary install upgrade your CuDNN library to match If building from sources make sure the library loaded at runtime matches a compatible version specified during compile configuration 2017 14 02 30 167164 F tensorflow core kernels conv ops cc 659 Check failed stream parent GetConvolveAlgorithms algorithms System information OS Platform and Distribution CentOS 7 TensorFlow installed from source TensorFlow version 1 1 0 CUDA cuDNN version CUDA v8 0 cuDNN v6 GPU model and memory TITAN X 12 GB Describe the problem When I run the program I am getting this error Any idea what may cause this error,,,2017-06-25 11:41:32,2017-07-11 17:24:15
IS,NameError name 'eval input fn' is not defined,OS MacOS 10 12 TensorVersion 1 2 PythonVersion 2 7 Run the example of 'A custom model' in the document ' Getting Started With TensorFlow a custom model ' occur the exception Traceback most recent call last File linear regression tf contrib learn custom model py line 35 in module eval loss estimator evaluate input fn eval input fn NameError name 'eval input fn' is not defined Fix Need to add the code eval input fn tf contrib learn io numpy input fn x x eval y eval 4 num epochs 1000 at line 30,,,2017-07-11 09:41:43,2017-07-11 18:24:12
PR,Fix secure urls and typos,Replaced with to prevent expired website security certificate NET ERR CERT DATE INVALID warning,,frankchn,2017-07-11 01:45:00,2017-07-11 18:27:41
PR,Imply default argument in docstring properly,Since the default is as text True the current docstring is a real gotcha IMO Clearer to flip the explanation around,,"carlthome,frankchn",2017-07-11 07:55:18,2017-07-11 18:27:59
PR,modify SaverDef default version with v2,SaverDef V1 has been deprecated so modify default version with V2,,"horance-liu,frankchn",2017-07-11 11:15:16,2017-07-11 18:28:16
PR,Point protobuf to 0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66,This change wo not be needed after updating protobuf to a version containing google protobuf 0b059a3,,"meteorcloudy,meteorcloudy,jhseu,jhseu,meteorcloudy,meteorcloudy,jhseu",2017-07-06 08:15:32,2017-07-11 18:44:14
PR,Third party Scala API Links in the Documentation,I added a couple links to my Scala API repository in the documentation pages I'm not sure if it is in the expected format but feel free to rephrase if needed It would be great if we could also add a link in the following page I could not find it in the documentation sources Thanks EDIT will take care of adding a link to so we are good with that one Thanks,,"eaplatanios,asimshankar,asimshankar,eaplatanios,asimshankar",2017-07-09 18:43:21,2017-07-11 18:45:00
IS,argument unused ' mcpu native' makes logs 3 times larger,System information macOS 10 12 4 Building from source according to the docs 'v1 2 0 1874 g75f56f0bd' 1 2 1 Python 3 6 1 Anaconda 4 4 0 x86 64 bazel stable 0 5 2 no cuda clang Apple LLVM version 8 1 0 clang 802 0 42 Description When building TF on macOS I get lots of these warnings It makes the log three times larger Is it clang only issue How to fix it Is it enough just to check here L301 L306 if compiler is clang,,,2017-07-09 09:23:06,2017-07-11 19:00:08
IS,TF binary incompatible to protobuf,I tried with TensorFlow 1 1 0 and 1 2 0 on Python 2 7 and 3 5 Note that I also asked about this on StackOverflow but I think this might actually be a bug either in the pip packaging of TF or protobuf or sth else so I post it here Summary I think the protobuf pip package is binary incompatible with the TF pip package but I'm not exactly sure on this I try to write some own operator which creates some own tf resource I use the C header files from the TF pip install and I link it to the message so file from the protobuf 3 3 0 pip package because anything tf resource related will need linking to protobuf My current code For Eigen ThreadPoolDevice define EIGEN USE THREADS 1 include tensorflow core framework op h include tensorflow core framework shape inference h include tensorflow core framework op kernel h include tensorflow core framework resource mgr h include tensorflow core framework resource op kernel h include tensorflow core framework tensor h include tensorflow core framework tensor shape h include tensorflow core framework types h include tensorflow core platform macros h include tensorflow core platform mutex h include tensorflow core platform types h using namespace tensorflow REGISTER OP ArrayContainerCreate Attr T type Attr container string '' Attr shared name string '' Output resource resource SetIsStateful SetShapeFn shape inference ScalarShape Doc R doc Array container random index access doc REGISTER OP ArrayContainerGetSize Input handle resource Output out int32 SetShapeFn shape inference ScalarShape struct ArrayContainer public ResourceBase ArrayContainer const DataType dtype dtype dtype string DebugString override return ArrayContainer int64 MemoryUsed const override return 0 mutex mu const DataType dtype int32 get size mutex lock l mu return int32 42 class ArrayContainerCreateOp public ResourceOpKernel ArrayContainer public explicit ArrayContainerCreateOp OpKernelConstruction context ResourceOpKernel context OP REQUIRES OK context context GetAttr T dtype private virtual bool IsCancellable const return false virtual void Cancel Status CreateResource ArrayContainer ret override EXCLUSIVE LOCKS REQUIRED mu ret new ArrayContainer dtype if ret nullptr return errors ResourceExhausted Failed to allocate return Status OK Status VerifyResource ArrayContainer ar override if ar dtype dtype return errors InvalidArgument Data type mismatch expected DataTypeString dtype but got DataTypeString ar dtype return Status OK DataType dtype REGISTER KERNEL BUILDER Name ArrayContainerCreate Device DEVICE CPU ArrayContainerCreateOp class ArrayContainerGetSizeOp public OpKernel public using OpKernel OpKernel void Compute OpKernelContext context override ArrayContainer ar OP REQUIRES OK context GetResourceFromContext context handle ar core ScopedUnref unref ar int32 size ar get size Tensor tensor size nullptr OP REQUIRES OK context context allocate output 0 TensorShape tensor size tensor size flat int32 setConstant size REGISTER KERNEL BUILDER Name ArrayContainerGetSize Device DEVICE CPU ArrayContainerGetSizeOp I compile that Note that I first got some undefined symbol ZN6google8protobuf8internal26fixed address empty stringE error but I resolved that by adding these additional compiler flags from google protobuf pyext import message as msg lib msg file extra compiler flags Xlinker rpath Xlinker os path dirname lib L os path dirname lib l os path basename lib I read about that here I end up with flags like these shared O2 std c 11 I u zeyer local lib python2 7 site packages tensorflow include I usr local cuda 8 0 include L usr local cuda 8 0 lib64 x cu DGOOGLE CUDA 1 Xcompiler fPIC D GLIBCXX USE CXX11 ABI 0 TFArrayContainer cc o TFArrayContainer so Xlinker rpath Xlinker u zeyer local lib python2 7 site packages google protobuf pyext L u zeyer local lib python2 7 site packages google protobuf pyext l message so Then I load that as a module via tf load op library Then I have this Python code handle mod array container create T tf int32 size mod array container get size handle handle When I try to evaluate size I get the error InvalidArgumentError see above for traceback Trying to access resource located in device 14ArrayContainer from device job localhost replica 0 task 0 cpu 0 Node ArrayContainerGetSize ArrayContainerGetSize device job localhost replica 0 task 0 cpu 0 array container The device name 14ArrayContainer somehow seem to be messed up Why is that What is the problem with the code For some more testing I added this additional code in the ArrayContainerCreateOp ResourceHandle rhandle MakeResourceHandle ArrayContainer context cinfo container cinfo name printf created device s n rhandle device c str printf container s n rhandle container c str printf name s n rhandle name c str printf actual device s n context device attributes name c str printf actual name s n cinfo name c str This gives me the output created device 14ArrayContainer container 14ArrayContainer name 14ArrayContainer actual device job localhost replica 0 task 0 cpu 0 actual name 2 array container So clearly there is some of the problem This looks like something is messed up with the protobuf Maybe I am linking the wrong lib But I have not found which lib to link instead,,"martinwicke,jhseu,jhseu",2017-06-21 12:58:47,2017-07-11 19:04:16
PR,Temporarily disable barrier ops test on Mac,,,caisq,2017-07-10 20:22:42,2017-07-11 21:05:59
PR,Fix unpickling copying tf app flags FLAGS,pickle load and copy copy check for the presence of setstate The problem is that this check is made in the freshly allocated instance which has not been init ed Thus it is dict is completely empty and getattr fail with KeyError The fix is to check if parsed is in the dict and raise AttributeError if it is not,,frankchn,2017-07-11 14:42:51,2017-07-11 21:09:05
PR,Branch 161598138,,,"frankchn,frankchn",2017-07-11 23:49:30,2017-07-12 01:03:28
IS,No clue to inform what wouldimension' arg of argmin or argmax means in API docs,In documentation of TF API 1 2 tf argmin and tf argmax have dimension argument tf argmin tf argmax However there is no any explanation for what it means,,mrry,2017-07-11 00:47:30,2017-07-12 01:03:47
IS,RecordInput blocks if file pattern returns no files,The tensorflow python ops data flow ops RecordInput blocks forever if the first input argument with keyword file pattern is a pattern that does not point to an existing file s It does not seem to be waiting for that file to appear either because if I make it appear after the launch it is still blocked leading me to believe this is a bug Reproduce,,ekelsen,2017-07-08 11:18:34,2017-07-12 01:03:47
IS,Java API does not include quantize operations,When trying to run a quantized model with the Tensorflow Java API in version 1 2 rc0 I get the following exception in Java It seams the kernels for quantized graphs are not included in the Java API binary of tensorflow Can you add these kernels Note The frozen model I used to create the quantized model runs perfect with the same code Note2 I quantized the graph with the current r1 2 branch of tensorflow,,"andreas-eberle,aselle,asimshankar,asimshankar",2017-06-19 17:40:50,2017-07-12 04:46:07
IS,Unable to install Tensorflow on Windows Anaconda error trace,I posted this issue on Stack Overflow I seem to always have problems related to Anaconda dependencies even related to my Mac I'm on Python 3 6 which came with an auto install when I installed Visual Studio Do I just need to downgrade to get this to work I'm also on the latest version of CUDA cuDNN and have a TitanX I'm on a new PC deep learning rig now and installed CUDA afterward I ran some of the pip install commands I received the error below python m pip install upgrade pip Then this printed out Successfully built protobuf markdown html5lib Installing collected packages protobuf backports weakref html5lib bleach ma rkdown tensorflow Exception Traceback most recent call last File C Program Files Anaconda3 lib site packages pip basecommand py line 2 15 in main status self run options args File C Program Files Anaconda3 lib site packages pip commands install py l ine 342 in run prefix options prefix path File C Program Files Anaconda3 lib site packages pip req req set py line 7 84 in install kwargs File C Program Files Anaconda3 lib site packages pip req req install py li ne 851 in install self move wheel files self source dir root root prefix prefix File C Program Files Anaconda3 lib site packages pip req req install py li ne 1064 in move wheel files isolated self isolated File C Program Files Anaconda3 lib site packages pip wheel py line 345 in move wheel files clobber source lib dir True File C Program Files Anaconda3 lib site packages pip wheel py line 323 in clobber shutil copyfile srcfile destfile File C Program Files Anaconda3 lib shutil py line 115 in copyfile with open dst 'wb' as fdst PermissionError Errno 13 Permission denied 'C Program Files Anaconda3 Li b site packages protobuf 3 3 0 py3 6 nspkg pth',,"gunan,gunan,gunan",2017-07-08 22:48:33,2017-07-12 05:02:59
PR,Update initializers py,According to Understanding the difficulty of training deep feedforward neural networks and the codes it is sqrt 2 in out,,"zhongzyd,drpngx,sguada,zhongzyd,frankchn,sguada,zhongzyd,sguada,zhongzyd,frankchn",2017-06-22 13:16:10,2017-07-12 05:31:38
IS,Feature request possible bug cannot take second derivative of a MaxPool,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX El Capitan TensorFlow installed from source or binary Binary TensorFlow version use command below v1 0 0 65 g4763edf dirty 1 0 1 but I have tested it on later versions too and looking at the source code in master it does not seem like it is available Python version 3 5 1 but I have reproduced it on 2 7 Describe the problem If I understand correctly MaxPool operations should be many times differentiable but in Tensorflow you can only differentiate them once which makes it impossible to inspect second derivatives for CNNs or do double backpropogation Source code logs You can reproduce it very simply this way,,lakshayg,2017-07-11 13:54:56,2017-07-12 06:05:38
PR,Fixed 32 bit build error in tensor forest,This patch fixes the build error described in 11229,,,2017-07-05 16:49:03,2017-07-12 09:51:13
PR,For deep learning,,,frankchn,2017-07-12 05:33:07,2017-07-12 17:38:54
PR,Add CODEOWNERS,Added what we know about contrib mainly and some well separated components The list of names behind each component is not perfect I took this from a partially definitely outdated doc but I suggest we maintain it here instead of in that doc,,"martinwicke,jhseu,jhseu,jhseu,martinwicke,aselle",2017-07-11 14:03:02,2017-07-12 17:54:43
PR,Java Add base classes and utilities for operation wrappers,This pull requests includes a set of basic classes interfaces and utilities useful for the automatic generation of operations by the upcoming C module They are meant to be used more as internal tools than being part of the public API,,"karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,asimshankar,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,asimshankar,karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,asimshankar,drpngx,asimshankar,asimshankar,frankchn,karllessard,frankchn,karllessard,frankchn",2017-06-30 18:14:06,2017-07-12 18:10:53
PR,Fix typos,This PR fixes some typos Compatble objets overriden reseting an an libraryh and a a,,"taehoonlee,frankchn",2017-07-12 05:44:54,2017-07-12 18:11:52
PR,Fix linking options issued by bazel in order to make gradients register,Link issuecomment 313956256 to the discussion,,frankchn,2017-07-12 09:43:07,2017-07-12 18:31:01
PR,Branch 161686867,,,"frankchn,frankchn",2017-07-12 18:19:18,2017-07-12 18:32:28
PR,Deleted unnecessary repetition of the same text,The same text was repeated two times I deleted the repetition,,frankchn,2017-07-12 15:47:51,2017-07-12 18:34:59
PR,Windows Build TensorFlow with wrapper less CROSSTOOL,After is merged we can now build TF with the wrapper less CROSSTOOL,,meteorcloudy,2017-07-12 12:32:37,2017-07-12 19:53:01
PR,Disable nn test on Windows,Disable tensorflow python nn test util it is fixed Related issue,,"meteorcloudy,meteorcloudy,gunan",2017-07-12 08:37:46,2017-07-12 19:53:06
IS,Is tf split not create a new object Using tf split and tf concat will has some bugs,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version use command below 1 2 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version 8 0 GPU model and memory Exact command to reproduce Describe the problem tf split is not create a new object Using tf split and tf concat will has some bugs For example I has a 64 20 tensor and split to 64 15 and then concat it with a 64 1 tensor but I obtain a 64 21 tensor instead 64 16 Source code logs Result python test py 64 21,,carlthome,2017-07-12 08:44:02,2017-07-12 21:38:53
IS,Link to Benchmarks not working,The link to Benchmarks on the page is not working,,,2017-07-12 10:16:44,2017-07-12 22:52:42
IS,How to use pre trained models for fine tuning on different dataset,Hi I have downloaded a pre trained model for inception v3 inception v3 2016 08 28 tar gz file from Pretrained url which contains the file inception v3 ckpt Could anyone please help me how to use this file to fine tune on a different dataset Thanks in advance,,"carlthome,jart",2017-07-12 14:39:27,2017-07-12 23:35:18
IS,python create model and c uses model without bazel,I just have used python to create ckpt model But i have to use c to test my picture without bazel Some one can help me I am so eager to solve this problem Thanks,,carlthome,2017-07-12 12:21:36,2017-07-12 23:36:06
IS,wide n deep Tutorial processing large data,I am a freshman of tensorflow and want to use the wide deep network I see the code of wide n deep tutorial find that in def train and eval function reading the total data using pandas at once I confuse if the data is large maybe 5 GB or more and I cannot read all the data in memory and how can I processing it Thank you,,jart,2017-07-12 03:16:10,2017-07-12 23:42:26
IS,wrong with tf norm it will produce nan,I use version 1 0 0 in server in my code the result will be nan if i use everything will be ok and result is some float between 0 and 1,,"lakshayg,lakshayg,jart",2017-07-11 09:35:51,2017-07-12 23:43:33
IS,Apache License header does not include HTTPS link,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 15 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Python version 2 7 13 Describe the problem Various code files have instead of Not sure if this is the result of bazel or simply that needs to be explicitly written Source code logs,,"alanyee,jart,alanyee",2017-07-10 18:50:02,2017-07-12 23:47:52
IS,Request genuine consecutive scheme batch generation for RNN Trainning,The concept of genuine consecutive scheme can be seen at here 5 4 Batch My scenario is as follows I have some files with different sequence lengths First do buckecting to generate file batches with parameter batch size Then split each file batch with parameter seq len to generate trainning sample batches Last use each sample batch for one step of trainning Following is my test code See the document of batch sequences with states I found that 1 it seems only support only one sequence and do not support multiple sequences 2 it do not support the situation of Shape for sequence inputs is not fully defined which means bucket by sequence length can not be followed with batch sequences with states What more I have tried Solution 2 but I failed because of thread synchronization problem between tf train string input producer and tf train range input producer So how to relize my request Hope for your help,,jart,2017-07-10 17:20:17,2017-07-12 23:52:39
IS,how I upgrade my code build on Tensorflow 1 0 1 python3 to compatible with TF1 2,Please go to Stack Overflow for help and support,,,2017-07-10 08:33:17,2017-07-12 23:57:21
IS,Finding position of detected object,Is it possible to find the position of detected object with accuracy in given image using tensor flow I am using label image py to test my trained data how can I get the position of detected object as I am getting the accuracy of detected object Reference comment76982154 44942587,,jart,2017-07-10 07:26:55,2017-07-12 23:58:08
PR,Update optimize for inference test py,These two should be interchanged self assertNotEqual ResizeBilinear node op with self assertNotEqual MirrorPad node op,,"gautam1858,drpngx,drpngx,drpngx,frankchn",2017-06-24 04:18:07,2017-07-13 00:06:04
PR,Return output graph def in tools freeze graph py,It makes sense that def freeze graph works with files for both the input graph and frozen output graph It does not make sense that def freeze graph with def protos only uses a tf GraphDef for the input but does not actually return the frozen graph and instead only writes it to a file This pull request changes freeze graph with def protos to optionally write the output to file for backwards compatibility when output graph is set as usual but also returns the GraphDef protobuf to make the API more symmetric Otherwise you have to write and read from a tempfile just to use freeze graph which is a hassle,,"carlthome,drpngx",2017-07-05 11:57:44,2017-07-13 00:06:19
IS,Feature request explicit state interfaces,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 Python version 2 7 12 Description The current API is immensely stateful Each function and object creation affects and is affected by countless mutable global states Running a declaration of Variable or summary mutates the graph and collections and may return different results based on the current NameScope or VariableScope or control dependencies A function running twice can easily return wildly different result even though it looks pure but it is not because almost no tensorflow function is pure Declaring something and then deleting it wo not restore the global state as it may or may not be added somewhere in the graph or the collections or some other hidden objects Reasoning about what changes what is incredibly difficult What I would like to see is a API where all state mutations are explicit When I declare a variable it is just a variable and not added to anything unless I call add The current entangled interfaces can be built on top of that preserving convenience functions such as global variable initializers for those who prefer,,jart,2017-07-10 03:24:41,2017-07-13 00:06:43
IS,TFrecord reading time very high,I have divided a dataset into 10 tfrecords files and I want to read 100 data points from each to create a batch of 10 sequence of 100 data points I use the following function to do that The data loading time from the tfrecords start off slow and then reaches to around 0 65s and after 100 200 sess run calls it increases to around 10s Can you please point out any mistake or suggestion which might help to reduce the read time Also the behaviour I mentioned becomes more erratic sometimes def get data mini batch size data for i in range mini batch size filename queue tf train string input producer data path 'Features' str i ' tfrecords' reader tf TFRecordReader serialized example reader read filename queue batch serialized example tf train batch serialized example batch size step size num threads 8 capacity step size features tf parse example batch serialized example features 'feature raw' tf VarLenFeature dtype tf float32 feature features 'feature raw' values feature tf reshape feature step size ConvLSTM H ConvLSTM W ConvLSTM Di data append feature return tf stack data,,jart,2017-07-08 14:59:30,2017-07-13 00:41:09
PR,Configure script code reduction no merge please,Please do not merge yet The configure script has a lot of repetition Adding functions can reduce the number of lines of code help prevent errors and make life easier I noticed it was kind of long when editing another part This adds two functions build with and get path And have it iterate over fields instead of having an entire section of the script that has the same install process as TF NEED HDFS,,"gunan,caisq,yifeif",2017-07-02 20:00:46,2017-07-13 02:44:29
IS,Fine tuning tutorial without Bazel,I am using this tutorial provided by Google Research to fine tune the Inception model fro my own images how to fine tune a pre trained model on a new task I have access to a GPU provided by my institution The problem is that the GPU does not have Bazel installed Is it possible to complete this tutorial without using Bazel,,jart,2017-07-13 03:27:05,2017-07-13 03:38:30
IS,20 minutes for compiling a single file conv grad ops 3d cc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below 2533ada7dd45b84d60677b8735e013d21044651a Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem It took about 20 minutes to compile conv grad ops 3d cc The whole build took INFO Elapsed time 2241 764s Critical Path 1509 12s Therefore this file took about 50 compile time Why Source code logs,,"snnn,martinwicke,meteorcloudy",2017-07-12 11:18:52,2017-07-13 09:15:56
IS,Does inception model detect multiple object in one image,I have use retrain py to train tensorflow with my own dataset of traffic sign but it seems it does not capture multi object in one image I am using the label image py to detect the object in my image I have an image of two road sign which exists in my dataset but i get only one sign with high accuracy It does not detect other sign,,vincentvanhoucke,2017-07-13 12:48:40,2017-07-13 14:26:43
PR,update word2vec basic py Fix TSNE invocation in Udacity word2vec assignment,Update 5 word2vec ipnb Fix TSNE invocation in Udacity word2vec assignment add method 'exact' fix ValueError num points 400 tsne TSNE perplexity 30 n components 2 init 'pca' n iter 5000 method 'exact' two d embeddings tsne fit transform final embeddings 1 num points 1,,"frankchn,vincentvanhoucke,vincentvanhoucke,vincentvanhoucke,vincentvanhoucke",2017-07-12 12:42:02,2017-07-13 15:16:42
IS,Custom Beam Search Decoder with sampling,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 0 Python version 3 4 3 Bazel version if compiling from source CUDA cuDNN version 7 5 GPU model and memory Exact command to reproduce Describe the problem I want to incorporating sampling into the beam search decoder for seq2seq model Is there any example or document on how to implement it,,,2017-07-13 02:58:58,2017-07-13 16:09:23
IS,Sorry to Reply you My problem is tensor flow un incompatible with windows IIS,Sorry i just have time to reply you Thanks for replying me I means I use Flask to call tensor flow py And mount Flask to windows IIS Local run ok But in IIS will show FastCgi error Check local run is ok no error But when in IIS when i import keras it will show fastcgi error but when do not import keras it will ok If tensor flow isun incompatible with IIS image image image image,,,2017-07-13 09:19:32,2017-07-13 16:10:55
IS,cuDNN version issues,I am trying to train a ConvNet on my Windows laptop and I got this error Loaded runtime CuDNN library 5005 compatibility version 5000 but source was compiled with 5105 compatibility version 5100 If using a binary install upgrade your CuDNN library to match If building from sources make sure the library loaded at runtime matches a compatible version specified during compile configuration I am already using cudnn v5 1 so I have no clue why this is happening,,"jart,guschmue",2017-07-09 22:16:44,2017-07-13 16:21:04
PR,Fix TSNE invocation in Udacity word2vec assignment,Default TSNE method recently changed to the approximate method 'barnes hut' which fails to converge per,,vincentvanhoucke,2017-07-13 15:44:48,2017-07-13 17:27:10
PR,update word2vec basic py,Fix TSNE invocation in tutorials word2vec assignment,,frankchn,2017-07-13 16:00:57,2017-07-13 18:10:33
PR,Adding a comma to a Python snippet,,,"ChrisAntaki,frankchn",2017-07-13 13:54:12,2017-07-13 18:11:03
IS,seq2seq AttentionWrapper cannot implement Bahdanau model RNNsearch,Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes but there is no stock example script OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 12 5 TensorFlow installed from source or binary source via virtualenv pip3 TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 6 1 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem RNNsearch has two different RNN cells in it the encoder and decoder At a given time step the inputs to the attention mechanism are all the encoder is outputs the annotations in the Bahdanau paper aka the memory of the BahdanauAttention constructor and the decoder is previous state Crucially AttentionWrapper call is running its input through the passed in cell before applying AttentionMechanism to the cell is output Docstring call source confirms this This precludes the encoder cell from being passed to AttentionWrapper because AttentionWrapper depends on BahdanauAttention whose memory depends on the encoder cell is output So you would need to run the encoder once to get the memory and AttentionWrapper would run it again But the decoder cell can also not be the cell passed in because in the Bahdanau paper the decoder is output is not used by the attention mechanism at all Moreover neither cell takes the previous step is attention in Bahdanau I'm hoping I have misunderstood but currently the API does not seem like it can be made to align with the paper which would be sort of curious but perhaps intentional Source code logs bahdanau tf contrib seq2seq BahdanauAttention num units params 'ATTENTION SIZE' memory annotations annotations tf nn static rnn encoder time major input normalize False name 'BahdanauAttention' decoder tf nn rnn cell BasicLSTMCell params 'DECODER SIZE' forget bias 1 0 attn cell tf contrib seq2seq AttentionWrapper cell decoder attention mechanism bahdanau output attention False name AttentionWrappedDecoder,,"jart,ebrevdo",2017-07-08 01:58:59,2017-07-13 19:12:20
IS,Not able to install tensflow on Windows 7,Hi I am not able to tensor flow on Windows7 machine I searched it and found it seems to b a proxy server problem which is trying to connect to pypi python org I configured it also tried to install tensorflow it is still not working Can anyone tell me how can I install it without compromising the security Thanks Yugank Narula,,jart,2017-07-13 13:04:20,2017-07-13 20:10:13
PR,Update CODEOWNERS add owners to Windows TPU components,,,frankchn,2017-07-13 18:05:54,2017-07-13 20:19:09
PR,Update github link in roadmap md,Update github link with latest labels,,"ScorpioCPH,frankchn,frankchn",2017-07-13 10:14:35,2017-07-13 20:19:27
IS,No graph definition files were found,hello I was learn to use the tensorflow Now I can run softmax nn cnn and other model on it this is a really good framework but now I suffered some problem I want to use the tensorboard this is my code you can see the result is very good to celebrate that I want to show them in graph You see I use writer tf summary FileWriter 'board ' graph graph in line 56 and define the graph in line 53 then I run the tensorboard by tensorboard logdir 'board ' qq 20170713125732 but the page shows No graph definition files were found 2017 07 13t04 58 05 105z I use tensorflow on windows10 and by python3 5 and tensorflow1 2 I hope you can help me find out what is the problem,,"jart,jart",2017-07-13 04:59:33,2017-07-13 20:23:54
IS,Placeholder with shape None 1024 gives an error when used with tf cond,I'm using TensorFlow v1 2 0 Here is a simple example that shows the problem If a dimension of a placeholder is None I get the following error,,"jart,jart,Mistobaan",2017-07-08 09:59:04,2017-07-13 20:49:06
IS,Link for iOS doc does not work,,,,2017-07-13 19:21:14,2017-07-13 20:56:56
IS,areturn state' in keras rnn layers,Im using tensorflow r1 2 In the original Keras There is an option to get the last hidden state of a rnn layer L99 And it disappeared in tensorflow version of the keras L89 Is there any reason for this I think the areturn state' option is quite useful,,"jart,fchollet",2017-07-13 20:42:14,2017-07-13 21:00:26
PR,Print default when CUDA and CuDNN versions are not specified,Fix 10456,,"yifeif,caisq,caisq,yifeif,gunan,caisq,yifeif,yifeif",2017-07-12 17:12:09,2017-07-13 21:23:45
PR,datset md Fix minor typo in code,Change tf contrib data Dataset TextLineDataset filename to tf contrib data TextLineDataset filename,,frankchn,2017-07-13 20:57:28,2017-07-13 22:09:57
PR,Updating install golang sh bumping to 1 8 3,,,"ctava,frankchn,asimshankar,asimshankar,ctava,frankchn",2017-07-12 09:18:22,2017-07-13 22:10:39
PR,Branch 161868747,,,"frankchn,frankchn",2017-07-13 22:08:51,2017-07-13 22:46:06
IS,Building Tensorflow from source with XLA enabled and without GPU,Hi I built and installed tensorflow from source with XLA enabled and GPU disabled basically I opted N for everything while configuring via config except XLA enabling as Y There were lot of warnings regrding deprecated syntax while building but the build was successful I am able to import tensorflow and run basic print command in session But while I try to do some computation for eg simple addition it gives me following error 2017 06 28 15 09 22 366052 F tensorflow compiler xla statusor cc 41 Attempting to fetch value instead of handling error Not found could not find registered computation placer for platform Executor check target linkage Aborted I did a bit of debugging and this error comes just after the call from client sessions py 1262 to pywrap tensorflow tf session TF Run session options feed dict fetch list target list status run metadata so I believe it is because it is unable to link to pywrap tensorflow internal so Can you please provide any fix to this or is there something am doing wrong here This is blocking my further task so any kind of help is appreciated Thanks Regards,,"suiyuan2009,suiyuan2009,darrengarvey,kayzhu,kayzhu,kayzhu",2017-06-28 20:15:47,2017-07-14 01:12:53
IS,tf parse single example parses labels incorrectly,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes but only slightly I'm using the Inception v3 framework but made some minor modifications to the inception eval py code none around the image processing script OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 1 0 Python version 3 5 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 61 GPU model and memory Cirrus Logic GD 5446 16GB Exact command to reproduce bazel bin inception imagenet eval checkpoint dir HOME train eval dir HOME eval You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem The parse single example function in parsing ops py seems to be incorrectly parsing encoded protobufs written into a TFRecord Specifically I have been trying to classify images into categories labelled 1 2 3 and 4 Up until the point in my neural network where the images and associated label are turned into a protobuf serialized image the labels associated with the images are correct tf train Feature successfully turns each label into an associated integer consistently matching the label However after being serialized and then written to a TFRecord and compressed and then decoded through tf parse single example the label for each image becomes some random integer between 1 and 9 and no longer matches the label number with no discernable pattern I have traced the issue through the Inception code and this problem is not happening in Inception the bug is somewhere between my images are converted from a jpeg with labels to a serialized protobuf through tf train Example features tf train Features features and when the protobuf is decoded through tf parse single example The label in outputs created by outputs parse single example raw within tf parse single example is already incorrect and the int64 object for each label created by passing label values into tf train Feature int64 list tf train Int64List value label that is passed into tf train Example features tf train Features features to create the serialized protobuf that is parsed by tf parse single example still correctly matches the original labels Therefore the problem must be happening somewhere between the serialization and the parsing both of which occur within tensorflow EDIT UPDATE Upon further examination the bug seems to occur in some combination of when the image is serialized and when it is written to a TFRecord I used protoc to manually compile example proto and used that to manually parse parse the protobufs created by calling tf train Example on a Features tensor and encoding them with the SerializeToString method of the example proto and while the image class text and filename seemed to be correct the label was missing After the encoded protobufs are written to a TFRecord compressed and then parsed from the TFRecord through tf parse single example and they are incorrect the image class label seems to be missing the image class text is no longer correct either even though it was correct before being passed in and the beginning of the protobuf has some really wonky encoding going on that example proto is ParseFromString does not seem to be able to read and convert into a string Additionally I tried decoding the protobufs parsed from the TFRecord with tf parse single example from latin1 manually and the labels were still incorrect and matched the incorrect labels from using example proto is ParseFromString indicating that the problem is not happening in the decoding The parsed protobufs created by image processing py have been attached below FURTHER EDIT Issue has been updated to reflect new information Source code logs The relevant inception code that calls the aformentioned tensorflow functions is shown below For serializing images labels into a protobuf,,"jart,jart,jart",2017-07-07 20:34:57,2017-07-14 04:20:57
IS,Feeding TensorArray when running a session using feed dict,Currently there is no way to define a placeholder for a tf TensorArray A solution is to zero pad a tf Tensor and then unstack and slice it into a tf TensorArray However this adds unpadding overhead which would have to be done for every batch A possible change would be to add a new placeholder type for feeding a tf TensorArray to the graph for example called tf tensor array placeholder This could work as follows,,"jart,ebrevdo,ebrevdo,ebrevdo",2017-07-08 16:37:35,2017-07-14 06:11:09
IS,The window in tf contrib rnn AttentionCellWrapper,It is very strange to have a fixed sized window in the implementation of AttentionCellWrapper because there is no description about it in the Bahdanau paper Of course the behave of the window is not clear which makes me confused Can anyone explain it,,ebrevdo,2017-07-12 04:48:02,2017-07-14 06:18:31
PR,Fix on 'Use mcpu instead of march for ppc64le',Use of around 'if is ppc64le then' makes it always return true causing deprecated mcpu gcc warnings on every other arch This fixes commit 9f57dc8,,"caisq,caisq,caisq,caisq",2017-07-13 14:20:44,2017-07-14 14:30:07
IS,Turning on XLA JIT Compilation during session crashes computer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 Python version 2 7 12 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 5 1 GPU model and memory Titan X Pascal 12GB Exact command to reproduce Running any code with the following configuration passed to a supervisor managed session Describe the problem No idea why but when I tried to turn on the XLA JIT compilation according to this guide My computer crashes immediately and I have no way of diagnosing the problem Note that I installed TF from source and enabled the XLA JIT option Does this option consume more power than normal Previously I encountered a similar problem when I ran the TF slim VGG model with a pip installed TensorFlow gpu r1 2 and the computer crashes simply I could not find any issue until I ran the exact same code in another computer a laptop with weaker power supply with source compiled tensorflow which works I then replaced the pip installed TensorFlow with a source compiled one and everything works fine this led me to think there might be some issue with either my installation or the source code although I can not verify Has anyone faced a similar problem Also is XLA activated by default if I configured it to be enabled during the source installation i e it could be because I called the compilation twice when it was already activated by default causing the system failure Is there a way to verify whether XLA is activated so far the only indication I see are the messages XLA service 0x62bb180 executing computations on platform Host and XLA service 0x62a43b0 executing computations on platform CUDA Is this sufficient i e to say I do not have to manually activate XLA,,,2017-07-14 08:42:07,2017-07-14 16:54:34
IS,Error reading filenames with special characters on Windows,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 6 Describe the problem My tensorflow script on Ubuntu 16 04 works with the following code Note pythons open read works well on both platforms This error occurs for other file names with special characters on windows too I moved my data readers from python to tf api and data readers the pipeline works on ubuntu but breaks in windows,,mrry,2017-07-14 05:03:58,2017-07-14 17:00:23
PR,The previous commit attempted to fix a problem for PowerPC,architectures which require a different gcc optimization argument However this addition had two implementation errors which caused all architectures to receive this deprecated compiler flag and therefore produce a non optimized tensorflow compilation Specifically the introduced 'is ppc ' used a syntactically incorrect variable identification ' ' in the statement where command substitution ' ' should have been used This caused the command to always silently fail and the function to always return true regardless of architecture Additionally where the function was called the return value should be controlling the if statement but by encapsulating the call with ' ' the resulting expression evaluation was also always true,,,2017-07-14 17:03:53,2017-07-14 17:08:26
PR,R1 2,,,frankchn,2017-07-14 03:51:18,2017-07-14 17:16:44
PR,Branch 161949540,,,"caisq,alextp,jhseu,jhseu,caisq,caisq,caisq,caisq,allenlavoie",2017-07-14 16:56:58,2017-07-14 20:07:54
IS,AttributeError when calling train in tf estimator DNNClassifier,System information I wrote a custom script using the tf estimator DNNclassifier Source code below OS Platform and Distribution MacOS 10 12 5 TensorFlow installed from source TensorFlow version v1 2 0 1741 g88633a8eb 1 2 1 Python version 3 6 Bazel version if compiling from source 0 5 2 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Additional libraries numpy 1 13 0 protobuf 3 3 0 tensorflow tensorboard 0 1 2 Describe the problem When using tf estimator DNNClassifier train function I get the an AttributeError listed below in the logs relate to the definition of values tuple six itervalues features in dnn model fn Note when using tensorflow contrib learn DNNClassifier instead with fit instead of train no error occurs Source code logs clf train input fn lambda input fn A Cl2 steps dnntfDef trainingSteps File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages tensorflow python estimator estimator py line 241 in train loss self train model input fn input fn hooks hooks File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages tensorflow python estimator estimator py line 616 in train model model fn lib ModeKeys TRAIN File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages tensorflow python estimator estimator py line 601 in call model fn features features labels labels kwargs File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages tensorflow python estimator canned dnn py line 265 in model fn config config File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages tensorflow python estimator canned dnn py line 84 in dnn model fn values tuple six itervalues features File opt local Library Frameworks Python framework Versions 3 6 lib python3 6 site packages six py line 578 in itervalues return iter d values kw AttributeError 'Tensor' object has no attribute 'values',,"jhseu,jhseu,jhseu,jhseu,jhseu",2017-07-03 22:27:57,2017-07-14 20:08:39
PR,Change as cluster spec to cluster spec,,,terrytangyuan,2017-07-14 18:57:08,2017-07-14 21:57:02
PR,R1 2,,,frankchn,2017-07-14 17:33:57,2017-07-14 21:57:34
PR,Adding a link and fixing up two titles,This should make it easier to find the newest documentation,,"ChrisAntaki,frankchn",2017-07-14 02:59:39,2017-07-14 21:57:59
PR,Fix broken AttentionMechanism docstrings,Currently for all AttentionMechanisms the memory sequence length arg does not get formatted correctly in the docs making it easy to miss I believe this is because the optional modifier is not preceded by a colon as in the other working args,,"frankchn,frankchn,frankchn,frankchn,frankchn,frankchn,frankchn",2017-07-12 21:43:03,2017-07-14 22:06:00
PR,Branch 162017464,,,av8ramit,2017-07-14 22:51:21,2017-07-14 23:34:35
PR,Updating the version to 1 3 0 rc0,,,av8ramit,2017-07-14 23:43:28,2017-07-14 23:44:29
PR,Enable bitcode compilation,In order to enable bitcode compilation it is necessary more than adding fembed bitcode The MACOSX DEPLOYMENT TARGET variable must be defined and exported as well In this commit the variable is defined grabbing the version of the underlying running macOS,,"drpngx,drpngx,drpngx,drpngx",2017-06-30 22:49:45,2017-07-15 00:34:38
PR,add a new config option sycl nodouble for SYCL build,When TF is built with SYCL enabled the SYCL device code is generated at build time Currently all the data types such as float and double are registered to generate the device code The SYCL device code is compiled into SPIR at build time and then passed to OpenCL implemenation at runtime Since double precision is an optional feature in the OpenCL spec it is possible that an OpenCL implemenation does not support double To make some platforms without double support work this new config option disables double register for SYCL device code This patch just changes the cwise add operation as an example and other operations will be changed in future small patches one by one,,"drpngx,lukeiwanski,lukeiwanski,lukeiwanski,caisq,drpngx,drpngx,drpngx,jwlawson,drpngx,drpngx",2017-07-03 06:40:47,2017-07-15 01:05:19
PR,Remove RTLD GLOBAL when loading pywrap tensorflow,Note I'm making this a pull request to test it I do not propose merging as is and this will likely need to be split up to be reviewed sensibly Splits TensorFlow into tensorflow core framework and tensorflow core lib shared objects Custom ops will be able to rely on these shared objects e g for op registration rather than relying on the global symbol table Should enable custom ops in languages other than Python among other things,,"allenlavoie,allenlavoie,allenlavoie",2017-07-15 00:55:10,2017-07-15 01:50:49
IS,tf gather axis argument,It would be nice to have an axis argument to tf gather This would bring it closer to the numpy equivalent np take This would also pave the way to supporting Numpy array indexing index arrays e g t 0 2 3 2 Based on discussion in 9236 and all the remedies provided on this StackOverflow thread there would be a lot of use for it The most common workaround of tf transpose tf gather tf transpose is super inefficient,,"rryan,rryan,rryan",2017-07-02 15:44:42,2017-07-15 02:09:58
IS,Retrieving LLVM IR from AOT tfcompile,Is it possible to get LLVM intermediate representation ll files from tfcompile instead of object code If so how can it be done Alternatively can one get source code instead of object code from tfcompile,,"tatatodd,tatatodd",2017-07-12 19:18:17,2017-07-15 06:23:02
IS,how to feed more than one input into my tensorflow model,i want to use python code to feed more than one input and then use concat method how can i do it by using more placeholder,,,2017-07-15 10:52:45,2017-07-15 17:19:30
PR,Fix syntax error in sample code,This would have otherwise caused a non keyword arg after keyword arg,,frankchn,2017-07-14 22:17:44,2017-07-15 20:43:33
PR,dequeue or dequeue many will fail immediately after close the queue,After close the queue subsequent dequeue and dequeue many operations that wo not block waiting for more elements to be enqueued and will fail immediately,,"horance-liu,frankchn,horance-liu,frankchn",2017-07-13 11:45:27,2017-07-15 23:49:16
PR,Update variables py,Changed ValueError messages to format the passed parameter in the error message,,"AndreiCostinescu,frankchn",2017-07-15 04:59:17,2017-07-15 23:51:10
PR,Fixing a typo in a README,,,"ChrisAntaki,frankchn",2017-07-15 14:17:14,2017-07-16 00:03:13
PR,Add white spaces,This PR adds white spaces on docstrings,,"taehoonlee,frankchn",2017-07-15 10:35:44,2017-07-16 00:04:22
PR,Fixes 'batch size' may be used uninitialized,clang 3 6 warning 'batch size' may be used uninitialized in this function,,"lukeiwanski,frankchn",2017-07-15 20:01:12,2017-07-16 00:07:42
PR,Adding generics to the Java API Phase 1,Here is an initial cut at enhancing the Java API with generics,,"andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,andrewcmyers,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,asimshankar,andrewcmyers,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,andrewcmyers,andrewcmyers,asimshankar,drpngx,drpngx,asimshankar,andrewcmyers,karllessard,kbsriram,drpngx,andrewcmyers,andrewcmyers,asimshankar,asimshankar",2017-07-03 20:40:03,2017-07-16 00:08:12
PR,tf app flags support required,add required support for tf app flags flags DEFINE bool bool required None HelpString required True,,,2017-07-16 07:58:25,2017-07-16 07:59:25
PR,R0 10,,,frankchn,2017-07-14 09:13:55,2017-07-16 13:12:30
IS,Not able to import tensorflow,import tensorflow as tf Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Program Files Python35 lib site packages tensorflow init py lin e 24 in module from tensorflow python import File C Program Files Python35 lib site packages tensorflow python init p y line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation probl ems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,gunan,2017-07-16 04:37:30,2017-07-16 13:35:28
IS,tf where outputs the wrong tensor dtype,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution Ubuntu 14 04 TensorFlow installed from Source TensorFlow version 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 13 Bazel version N A CUDA cuDNN version Cuda 8 0 GPU model and memory N A Exact command to reproduce Describe the problem In the documentation for tf where py it states that it returns A Tensor with the same type and shape as x y if they are non None In the example above we see that x and y are both dtype tf float32 Yet the output is tf int64 Was this intended or a bug This bug is a bit problematic for me as I use tf where in my loss function so I need to ensure that all my tensors are tf float32 since tf cast is not a differentiable ops,,,2017-07-16 01:57:10,2017-07-16 20:36:54
IS,Feature Request Feed tensors to feed dict,I think that a nice step towards dynamic computation graphs is the possibility to feed tensors to placeholders I am building an application which creates a network I create my training and testing batches with tf train batch However the training batches are unlimited so no epoch limit to the tf train slice input producer but I would like to also test during training so to only test one epoch on the testing data For both the training and testing images I have a preprocessing pipeline which also uses a computation graph but is different for testing and for training Now the problem is that I have to create the testing batch every time I want to test because I want to test for 1 epoch and I cannot otherwise limit the input producing So it would definitely help to be able to feed the training and testing batch respectively to the network input My current solution is to create the network every time I make the switch from training to testing with the new network inputs But this takes quite an unnecessary long amount of time Is there perhaps another way to link two graphs in tensorflow,,"AndreiCostinescu,yaroslavvb",2017-07-16 18:39:26,2017-07-16 20:53:25
PR,Added missing marital status assignment,,,terrytangyuan,2017-07-16 19:27:32,2017-07-16 21:24:38
IS,MultiRNNCell fails like rnncell check,Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS Sierra 10 12 5 TensorFlow installed from source or binary binary pip3 install TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 5 2 CUDA cuDNN version N A GPU model and memory N A Describe the problem I believe this is a bug When initializing a MultiRNNCell like MultiRNNCell lstm 3 this subsequently may be passed into something like tf nn bidirectional dynamic rnn and it will pass the like rnncell check and everything proceeds normally When initializing a MultiRNNCell like MultiRNNCell lstm factory for in range num layers such as in this code stacking multiple lstms the like rnncell check on line 393 of this code will fail If you trace it back to where that function is defined there are 4 qualifiers the qualifiers that fail are hasattr cell 'output size' and hasattr cell istate size' The preferred way of initializing multi cell rnns that do not share input size which lead to later dimension mismatch seem to be this way Initially I wrote my code with the former implementation but the former initialization leads to input dimension sharing and then mismatches later on which is another issue and why I can not use that one Also this probably fails anywhere a like rnncell check is used I know for a fact my AttentionWrapper in my decoder fails for the same reason not just in the bidirectional dynamic rnn Source code logs This is my encoder copied from my seq2seq model class Trace File execute py line 168 in module main File execute py line 91 in main steps 10000 File Users panda Desktop aura ml aura model lib python3 5 site packages tensorflow python estimator estimator py line 241 in train loss self train model input fn input fn hooks hooks File Users panda Desktop aura ml aura model lib python3 5 site packages tensorflow python estimator estimator py line 560 in train model model fn lib ModeKeys TRAIN File Users panda Desktop aura ml aura model lib python3 5 site packages tensorflow python estimator estimator py line 545 in call model fn features features labels labels kwargs File execute py line 134 in model wrapper keep prob params 'encode' 'keep probability' File Users panda Desktop aura ml model 1 model py line 42 in encode time major time major File Users panda Desktop aura ml aura model lib python3 5 site packages tensorflow python ops rnn py line 364 in bidirectional dynamic rnn raise TypeError cell fw must be an instance of RNNCell TypeError cell fw must be an instance of RNNCell,,,2017-07-16 22:20:24,2017-07-16 22:40:52
PR,support required for tf app flags,support required for tf app flags,,"frankchn,vrv,vrv",2017-07-16 08:01:46,2017-07-17 04:15:46
IS,Doc tf abs complex numbers,TF 1 2 0 tf abs already supports complex numbers but this is not documented,,rryan,2017-07-07 09:16:45,2017-07-17 05:14:24
PR,Update head py,Use tf losses instead of deprecated contrib,,"alanyee,frankchn,frankchn,alanyee,terrytangyuan,frankchn,frankchn,frankchn,frankchn,alanyee,alanyee",2017-07-16 02:46:09,2017-07-17 06:39:15
PR,Update head py,Switching to tf summary scalar,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,alanyee,frankchn,frankchn,frankchn,frankchn,alanyee",2017-06-30 02:08:12,2017-07-17 07:00:29
IS,Tensorflow serving CPU for xbox one ps4 switch,Hello First of all I would like to thank the developer of tensorflow for this great library Can tensorflow serving CPU works on xbox1 or ps4 i mean to compile it Thank you,,asimshankar,2017-07-14 09:13:46,2017-07-17 07:36:22
IS,Build fails on FreeBSD 11,,,"byronyi,asimshankar",2017-07-16 00:44:11,2017-07-17 07:42:47
IS,Tensorflow feed dict issue,I am new to tensorflow I understand that we need to create the tensorflow graph and then call sess run to get the values I want However I am confused by how the feed dict works For example Will 1 be the same as 2 Since training weights require we fill the placeholder X and Y with values but here I saw no feed dict So how exactly feed dict works,,asimshankar,2017-07-17 04:17:04,2017-07-17 07:45:25
IS,ImportError No module named pbr version,Hi everybody I have this problem also when i run openstack version Solutions,,asimshankar,2017-07-15 13:42:09,2017-07-17 07:46:04
IS,Tensorflow runs matmul bincount and other heavy funcions only on cpu,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux virgo wn100 roma1 infn it 3 10 0 514 el7 x86 64 1 SMP Thu Nov 3 15 10 49 CDT 2016 x86 64 x86 64 x86 64 GNU Linux VERSION 7 3 Nitrogen VERSION ID 7 3 REDHAT BUGZILLA PRODUCT VERSION 7 3 REDHAT SUPPORT PRODUCT VERSION 7 3 TensorFlow installed from source or binary from pip3 TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version Python 3 5 2 CUDA cuDNN version CUDA 8 0 cuDNN 5 GPU model and memory Tesla K20m memory 4742MiB Describe the problem Everytime i run a code with simple operations and heavy computation functions the simple ones like add or reshape run on the gpu while the heavy ones like matmul bincount tensordot run always on cpu This is very strange because tensorflow sees the gpu but uses it only for simple functions while i expect the inverse behavior I noticed it when i used Timeline to profile my codes Source code logs A simple example of the code i use I attach the json generated change txt to json and open it with chrome timeline txt,,"rryan,rryan,rryan,asimshankar",2017-07-14 10:40:45,2017-07-17 07:47:36
IS,AttributeError 'module' object has no attribute 'LinearClassifier',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-07-16 04:14:37,2017-07-17 07:52:17
IS,PyImport Import crash while using bazel to build the project,I recently ran into a problem while using bazel to build a project This project is compiled as a dynamic linking library using PyImport Import to import python module when there is import tensorflow as tf in the python file application who calls the dynamic linking library crashed everytime but when it s not there everything works just fine where is the problem my tensorflow version is 1 0 0 python 2 7 0 bazel 0 4 3 here is the console information when the application crashes F tensorflow core framework function cc 1015 Check failed GetOpGradFactory insert op func second Duplicated gradient for Softmax here is the test python file looks like from future import print function import tensorflow as tf import os import time from itertools import izip import numpy as np import wrapt import cv2 def get int a 10 b 20 return a b def get str s1 s2 return s1 s2 return 'Hello TY' return 'Hello World' 10 20 here is the source code of so file Py Initialize if Py IsInitialized return 1 PyEval InitThreads PyThreadState mainThreadState NULL save a pointer to the main PyThreadState object mainThreadState PyThreadState Get release the lock PyEval ReleaseLock char mockargv 1 char PySys SetArgv 1 mockargv PyRun SimpleString import sys PyRun SimpleString sys path append ' ' pName PyString FromString test py displayPyObject pName if pName NULL return 1 pModule PyImport Import pName displayPyObject pModule and here is the dynamic linking library part of my BUILD file cc binary name test so linkshared 1 deps test lib cc library name test lib visibility visibility subpackages srcs glob test cpp includes test h linkopts lm lpthread L usr lib python2 7 lpython2 7 lopencv core lopencv imgproc lopencv highgui lopencv ml lfreeimage deps tensorflow cc cc ops tensorflow core framework tensorflow core framework internal tensorflow core tensorflow,,asimshankar,2017-07-17 07:06:42,2017-07-17 07:55:25
PR,Change if x86 to if linux x86 64,VC does not have msse3 and msse4 2 options,,"snnn,gunan,meteorcloudy",2017-07-13 03:18:10,2017-07-17 14:21:34
PR,Use Windows Threadpool for SchedClosure,Before this change the distributed runtime will create a new thread for each mini batch Quite wasteful,,"snnn,mrry",2017-07-13 01:53:30,2017-07-17 14:48:19
IS,Tensorflow installation issue,Hi Team I have anaconda with python 2 7 in my windows 7 machine i tried to install tensorflow with the below command c conda create n tensorflow python 2 7 it has installed successfully activate tensorflow it changed the prompt to tensorflow C I have visual studio 2015 and selected the environment as python 2 7 and ran a sample program it is giving the below error please suggest from keras models import Sequential File D Anaconda2 Lib site packages keras init py line 3 in module from import utils File D Anaconda2 Lib site packages keras utils init py line 6 in mod ule from import conv utils File D Anaconda2 Lib site packages keras utils conv utils py line 3 in m odule from import backend as K File D Anaconda2 Lib site packages keras backend init py line 83 in module from tensorflow backend import File D Anaconda2 Lib site packages keras backend tensorflow backend py lin e 1 in module import tensorflow as tf ImportError No module named tensorflow Press any key to continue,,"shreyneil,gunan",2017-07-17 09:20:01,2017-07-17 14:50:33
IS,Variable values are not present in Java when saving a model in python and restoring in Java,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes Provided bellow OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS 10 12 5 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 2 1 Python version 2 7 Bazel version if compiling from source No compiled CUDA cuDNN version No GPU model and memory No Exact command to reproduce Describe the problem I have a script where a graph and variables are being saved using add meta graph and variables and tried to load it in Java but the weights seems that not are present I have created two mini examples of what it seems to me a bug Source code logs Here it is how I have saved the things I have checked the content of some Tensor variables and in the python side the values are correct but the same variable in the Java side have another values I can paste the code if needed as a result the predictions are always wrong I can provide the model saved or any other thing that is needed Thanks,,"asimshankar,asimshankar",2017-07-13 06:38:21,2017-07-17 15:09:38
IS,MultiGPU multi session,It would be nice if there is an official way to do limit devices initialised by tensorflow other than the os level environment variable settings specifically as in this answer posted by in stackoverflow As of my understanding the setup mentioned in another answer by will not prevent tensorflow from grabbing all the GPU resources available on a same workstation at initialization as it is in by tf train Server It would be essentially helpful for those sharing a machine among multiple users so that they could independently initiate tensorflow graphs in different GPU units Although this could be achieved via nvidia docker or other resource orchestration tools a native API would be a great addition to tensorflow Please ignore this if there is already an official way or my understanding is wrong,,"mrry,drpngx",2017-07-14 07:22:07,2017-07-17 15:41:41
IS,tf nn elu incorrect second derivative,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory GTX 1080 Ti 11GB Exact command to reproduce see below tf nn elu gives incorrect second derivatives Consider the graph y 2 elu x Looks like second derivatives work with that,,"skye,alextp,alextp,alextp",2017-06-27 20:57:44,2017-07-17 16:04:54
IS,initial state in keras rnn,I'm trying to put different initial hidden state into recurrent layers I saw many issues about initializing states using keras and most of the solutions were using layer reset state state But in my application I have to set stateful False and I cannot use reset state As it is written in the document I tried initial state argument in calling layers Using the code below I compared the outputs and the resulting outputs were always the same I tried different initializers and different initial states but the both outputs were the same When the stateful is False is there other possible way to set initial hidden state for size in dimension 1 initial tf ones shape batchnum size recurrent layer GRU units size return sequences True kernel initializer one recurrent initializer one recurrent layertest GRU units size return sequences True kernel initializer one recurrent initializer one x recurrent layer inputs x xtest recurrent layertest inputs xtest initial state initial,,drpngx,2017-07-17 15:19:24,2017-07-17 16:39:19
PR,Add required argument for DEFINE APIs and warning information f,Add required argument for DEFINE APIs and warning information for unparsed args 11195,,"nolanliou,nolanliou,vrv,nolanliou",2017-07-17 06:37:15,2017-07-17 16:42:00
PR,Fix contrib learn testcases,Fix contrib learn regex in testcases for Windows build,,,2017-07-17 22:27:02,2017-07-17 22:27:32
IS,TF Keras RNN initial state with stateful false,I'm trying to put different initial hidden state into recurrent layers I saw many issues about initializing states using keras and most of the solutions were using layer reset state state But in my application I have to set stateful False and I cannot use reset state As it is written in the document I tried initial state argument in calling layers Using the code below I compared the outputs and the resulting outputs were always the same I tried different initializers and different initial states but the both outputs were the same When the stateful is False is there other possible way to set initial hidden state for size in dimension 1 initial tf ones shape batchnum size recurrent layer GRU units size return sequences True kernel initializer one recurrent initializer one recurrent layertest GRU units size return sequences True kernel initializer one recurrent initializer one x recurrent layer inputs x xtest recurrent layertest inputs xtest initial state initial In my last issue there was a suggestion to put inputs as state initial state and It did not work saying GRU has no attribute istates' I think this happens because the stateful is False,,"drpngx,fchollet",2017-07-17 19:48:32,2017-07-17 23:36:07
IS,DecodeCSV outputs an unexpectedly result,I recently feel confused while using DecodeCSV operator The meaning of record defaults is different from that described in the documentation Here is the description in documentation Maybe I understand it in a wrong way Any comment is appreciated Thanks,,"drpngx,asimshankar,asimshankar",2017-07-17 11:55:47,2017-07-18 01:16:26
IS,PyImport Import crash,I recently ran into a problem while using bazel to build a project This project is compiled as a dynamic linking library using PyImport Import to import python module when there is import tensorflow as tf in the python file application who calls the dynamic linking library crashed everytime but when it s not there everything works just fine where is the problem my tensorflow version is 1 0 0 python 2 7 0 bazel 0 4 3 here is the console information when the application crashes F tensorflow core framework function cc 1015 Check failed GetOpGradFactory insert op func second Duplicated gradient for Softmax here is the test python file looks like from future import print function import tensorflow as tf import os import time from itertools import izip import numpy as np import wrapt import cv2 def get int a 10 b 20 return a b def get str s1 s2 return s1 s2 return 'Hello TY' return 'Hello World' 10 20 here is the source code of so file Py Initialize if Py IsInitialized return 1 PyEval InitThreads PyThreadState mainThreadState NULL save a pointer to the main PyThreadState object mainThreadState PyThreadState Get release the lock PyEval ReleaseLock char mockargv 1 char PySys SetArgv 1 mockargv PyRun SimpleString import sys PyRun SimpleString sys path append ' ' pName PyString FromString test py displayPyObject pName if pName NULL return 1 pModule PyImport Import pName displayPyObject pModule and here is the dynamic linking library part of my BUILD file cc binary name test so linkshared 1 deps test lib cc library name test lib visibility visibility subpackages srcs glob test cpp includes test h linkopts lm lpthread L usr lib python2 7 lpython2 7 lopencv core lopencv imgproc lopencv highgui lopencv ml lfreeimage deps tensorflow cc cc ops tensorflow core framework tensorflow core framework internal tensorflow core tensorflow,,"shreyneil,asimshankar",2017-07-17 08:56:26,2017-07-18 04:38:51
PR,Add mark flag as required functions to be compatible with python gfla,Add mark flag as required functions to make the APIs compatible with python gflags 11195,,nolanliou,2017-07-18 07:42:34,2017-07-18 07:57:12
IS,Unclear about how to make AttentionWrapper work,Hello I am using the TensorFlow 1 2 1 and I want to implement a Seq2Seq model with Attention through tf contrib seq2seq I did not find enough information of how to use I have also tried using GRU instead of LSTM the error still exists,,ebrevdo,2017-07-17 02:55:54,2017-07-18 08:50:06
IS,tf matrix inverse does not support complex tensor,I'm trying to run the next code Code x tf placeholder tf float64 2 2 y tf matrix inverse x Result OK tf Tensor 'MatrixInverse 2 0' shape 2 2 dtype float64 Code x tf placeholder tf complex64 2 2 y tf matrix inverse x Result Error Traceback most recent call last File ipython input 163 f259114be54a line 2 in module y tf matrix inverse x File c python python35 lib site packages tensorflow python ops gen linalg ops py line 330 in matrix inverse name name File c python python35 lib site packages tensorflow python framework op def library py line 585 in apply op param name input name File c python python35 lib site packages tensorflow python framework op def library py line 61 in SatisfiesTypeConstraint join dtypes as dtype x name for x in allowed list TypeError Value passed to parameter 'input' has DataType complex64 not in list of allowed values float64 float32 It seems that complex matrix inverse is not supported Any idea for workaround,,"shreyneil,shreyneil",2017-07-11 12:02:58,2017-07-18 09:13:12
IS,The same code for tensorboard test generate mm file which should be user file,I use my classmate is file for tensorboard test But this py file generate mm file not a user file Codes are as follows import tensorflow as tf import math from tensorflow examples tutorials mnist import input data mnist input data read data sets 'MNIST data' one hot True def conv layer input channels in channels out strides name conv with tf name scope name w tf Variable tf truncated normal 5 5 channels in channels out stddev 0 1 name W b tf Variable tf ones channels out 10 name B conv tf nn conv2d input input filter w strides 1 strides strides 1 padding SAME print conv act tf nn relu conv b tf summary histogram weight w tf summary histogram bias b tf summary histogram activations act print act return act def fc layer input channels in channels out name fc with tf name scope name w tf Variable tf truncated normal channels in channels out stddev 0 1 name W b tf Variable tf ones channels out 10 name B print input act tf nn relu tf matmul input w b act tf matmul input w b return act def compatible convolutional noise shape Y noiseshape tf shape Y noiseshape noiseshape tf constant 1 0 0 1 tf constant 0 1 1 0 return noiseshape x tf placeholder dtype tf float32 shape None 784 name x y tf placeholder dtype tf float32 shape None 10 name lables learning rate lr tf placeholder tf float32 dropout pkeep tf placeholder tf float32 pkeep conv tf placeholder tf float32 batch normal tst tf placeholder tf bool iter tf placeholder tf float32 x image tf reshape x shape 1 28 28 1 tf summary image input x image 6 creat net conv1 conv layer x image 1 4 1 conv 1 conv1 dr tf nn dropout conv1 pkeep conv compatible convolutional noise shape conv1 pool1 tf nn max pool value conv1 ksize 1 2 2 1 strides 1 2 2 1 padding SAME conv2 conv layer conv1 4 8 2 conv 2 conv1 dr tf nn dropout conv1 pkeep conv compatible convolutional noise shape conv1 pool2 tf nn max pool value conv2 ksize 1 2 2 1 strides 1 2 2 1 padding SAME conv3 conv layer conv2 8 16 2 conv 3 flattened tf reshape conv3 1 7 7 16 fc1 fc layer flattened 7 7 16 200 fc1 fc1 dr tf nn dropout fc1 pkeep w5 tf Variable tf truncated normal 200 10 stddev 0 1 b5 tf Variable tf ones 10 10 logits tf matmul fc1 w5 b5 with tf name scope loss cross entropy tf reduce mean tf nn softmax cross entropy with logits labels y logits logits tf summary scalar loss cross entropy with tf name scope BP train step tf train AdamOptimizer lr minimize cross entropy with tf name scope accuracy correct prediction tf equal tf argmax logits 1 tf argmax y 1 accuracy tf reduce mean tf cast correct prediction dtype tf float32 tf summary scalar accuracy accuracy writer tf summary FileWriter workspace TensorFlow Test 1 with tf Session as sess sess run tf global variables initializer merged summary tf summary merge all writer tf summary FileWriter tmp mnist demo writer add graph sess graph learning rate decay max learning rate 0 02 min learning rate 0 001 decay speed 2000 for i in range 2001 batch mnist train next batch 100 learning rate min learning rate max learning rate min learning rate math exp 1 decay speed if i 5 0 s sess run merged summary feed dict x batch 0 y batch 1 lr learning rate pkeep 0 9 pkeep conv 0 9 writer add summary s i if i 100 0 train accuracy sess run accuracy feed dict x mnist test images y mnist test labels lr learning rate pkeep 1 0 pkeep conv 1 0 print step d test accuracy is g i train accuracy sess run train step feed dict x batch 0 y batch 1 lr learning rate pkeep 0 9 pkeep conv 0 9 This file runs well on my classmate is machine,,,2017-07-18 12:04:05,2017-07-18 12:43:28
PR,Fix typos,This PR fixes some typos tranposed observaiton the the implementaton and concurently,,"taehoonlee,caisq",2017-07-18 07:10:31,2017-07-18 16:57:01
PR,Fix typo in exception,Title says it all,,"caisq,caisq",2017-07-18 12:50:12,2017-07-18 16:57:20
PR,Revert commits 1 3 0rc0,Reverting non max suppression v2 op and tfdbg change for cloudml gpu build,,"av8ramit,av8ramit,av8ramit,av8ramit",2017-07-18 17:22:57,2017-07-18 18:23:36
PR,Merge pull request 1 from tensorflow master,Updated on 2017 07 18,,jhseu,2017-07-18 13:02:14,2017-07-18 19:22:40
PR,update tf inspect py,DeprecationWarning inspect getargspec is deprecated use inspect signature or inspect getfullargspec if d decorator argspec is not None inspect getargspec target,,jhseu,2017-07-18 05:03:59,2017-07-18 19:36:05
PR,Update get started md,Fix various errors in print out statements and unnecessary lines of code,,"alanyee,frankchn,frankchn,alanyee,frankchn,alanyee,frankchn,alanyee,frankchn,frankchn,alanyee,frankchn",2017-07-16 22:56:41,2017-07-18 19:38:52
PR,Correct learning rate in code snippet,Correct the learning rate in code snippet such that it reflects the expected outcome 92 instead of 90 If this discrepancy is intentional feel free to close this request It is such a small fix I figured I would submit the request just in case the change was accidental I would note that the change is fixed in the master brach however the problem is currently reflected in the production docs which is confusing to beginners like myself,,jhseu,2017-07-17 18:17:11,2017-07-18 19:39:27
IS,LSTM with Projection issue,I wanna build a multi layer LSTM CTC network with projection in LSTM cell tf nn rnn cell LSTMCell FLAGS n hidden initializer tf contrib layers variance scaling initializer factor 1 0 mode 'FAN AVG' uniform True num proj FLAGS n hidden 2 state is tuple True init stat cell zero state FLAGS batch size dtype tf float32 inputs output conv for layer in range FLAGS recur layer with tf name scope 'LSTM ' format layer 1 as scope outputs tf nn dynamic rnn cell inputs seq len initial state init stat dtype tf float32 inputs tf nn relu outputs tf summary histogram 'LSTM ' format layer 1 inputs inputs tf contrib layers batch norm inputs center True scale True is training is training updates collections None tf summary histogram 'LSTM bn' format layer 1 inputs outputs inputs the inputs size is 1024 FLAGS n hidden 1024 but when I run it there is an error outputs tf nn dynamic rnn cell inputs seq len initial state init stat dtype tf float32 File usr local lib python2 7 dist packages tensorflow python ops rnn py line 574 in dynamic rnn dtype dtype File usr local lib python2 7 dist packages tensorflow python ops rnn py line 737 in dynamic rnn loop swap memory swap memory File usr local lib python2 7 dist packages tensorflow python ops control flow ops py line 2770 in while loop result context BuildLoop cond body loop vars shape invariants File usr local lib python2 7 dist packages tensorflow python ops control flow ops py line 2599 in BuildLoop pred body original loop vars loop vars shape invariants File usr local lib python2 7 dist packages tensorflow python ops control flow ops py line 2549 in BuildLoop body result body packed vars for body File usr local lib python2 7 dist packages tensorflow python ops rnn py line 720 in time step skip conditionals True File usr local lib python2 7 dist packages tensorflow python ops rnn py line 206 in rnn step new output new state call cell File usr local lib python2 7 dist packages tensorflow python ops rnn py line 708 in lambda call cell lambda cell input t state File usr local lib python2 7 dist packages tensorflow python ops rnn cell impl py line 180 in call return super RNNCell self call inputs state File usr local lib python2 7 dist packages tensorflow python layers base py line 441 in call outputs self call inputs args kwargs File usr local lib python2 7 dist packages tensorflow python ops rnn cell impl py line 542 in call lstm matrix linear inputs m prev 4 self num units bias True File usr local lib python2 7 dist packages tensorflow python ops rnn cell impl py line 1017 in linear initializer kernel initializer File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 1065 in get variable use resource use resource custom getter custom getter File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 962 in get variable use resource use resource custom getter custom getter File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 360 in get variable validate shape validate shape use resource use resource File usr local lib python2 7 dist packages tensorflow python ops rnn cell impl py line 183 in rnn get variable variable getter args kwargs File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 352 in true getter use resource use resource File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 669 in get single variable found var get shape ValueError Trying to share variable rnn lstm cell kernel but specified shape 1024 4096 and found shape 1536 4096 How can I fix it Using the num proj is there any example of it Many thanks Xin q,,asimshankar,2017-07-18 09:12:52,2017-07-18 20:02:22
PR,python remove the TRAINABLE RESOURCE VARIABLES graph key,The graph key TRAINABLE RESOURCE VARIABLES seems to have been removed drop the lines in this PR,,"alextp,alextp,alextp,alextp",2017-07-18 13:48:54,2017-07-18 20:14:24
PR,XLA Add DT HALF to the list of floating point types,This should not affect the existing CPU and GPU devices as they do not claim support for D HALF and the final registration for each device is the intersection of their advertised list and the global lists This merely adds DT HALF as a kind of floating point number which will allow MatMul to work with DT HALF Lots of other arithmetic ops do not restrict themselves to any specific types so they accept DT HALF by default Why is not Convolution restricted to kFloatTypes I do not see why convolution and matmul are not very similar in backend implementation I can not imagine why I had not spotted this before,,"DavidNorman,DavidNorman,frankchn,DavidNorman,frankchn,DavidNorman,frankchn",2017-07-08 20:26:52,2017-07-18 20:32:40
PR,Branch 162383623,,,"jhseu,jhseu",2017-07-18 19:51:51,2017-07-18 20:50:14
PR,Show usage when no arguments passed to import pb to tensorboard py,It seems like model dir and log dir should be required arguments After adding at least one required argument then parseargs handles no arguments cleanly TESTING Running it before the fix OTHER THOUGHTS It seems like model dir should maybe be renamed to model path assuming that it should link the file not the directory which it is in,,"daj,frankchn",2017-07-15 18:53:28,2017-07-18 22:17:17
PR,Reverted NHWC workarounds,This commit removes the NHWC workarounds we had created earlier,,,2017-07-18 22:58:57,2017-07-18 23:00:05
PR,Branch 162404670,,,jhseu,2017-07-18 21:37:43,2017-07-18 23:24:45
IS,tf device with function leads to incompatible device names,System information OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version 2 When using device function ' gpu 0' does not get translated to ' device GPU 0' This can lead to very confusing warning messages when used together with colocate,,"ppwwyyxx,vrv,ppwwyyxx",2017-07-13 17:51:18,2017-07-18 23:25:05
PR,Update workspace bzl to use latest farmhash commit to support s390x,Update workspace bzl to use latest farmhash commit to support s390x Please review,,"Nayana-ibm,Nayana-ibm,jhseu,jhseu",2017-07-18 13:31:53,2017-07-18 23:28:11
PR,Fixes ArgMax test deprecation warnings,The recent commit cbe1ef0 marks the dimension argument of argmax and argmin as deprecated which are used in the corresponding tests and so this brings up warnings when the tests are run The tests should be using the axis argument instead,,"jwlawson,jhseu",2017-07-17 11:47:08,2017-07-18 23:28:49
PR,fix broken links add links check to sanity,,,"zasdfgbnm,yifeif,zasdfgbnm,yifeif,jhseu,zasdfgbnm,jhseu",2017-07-09 15:13:02,2017-07-19 01:14:36
IS,Segmentation fault occured when I install tensorflow r1 2 with bazel,Hi when I builded tensorflow r1 2 I got following error tensorflow 1 2 mkl tensorflow contrib framework BUILD 108 1 Executing genrule tensorflow contrib framework gen variable ops pygenrule failed bash failed error executing command bin bash c remaining 1 argument s skipped com google devtools build lib shell AbnormalTerminationException Process terminated by signal 11 bin bash line 1 133735 Segmentation fault core dumped bazel out host bin tensorflow contrib framework gen gen variable ops py wrappers cc 0 bazel out local opt genfiles tensorflow contrib framework python ops gen variable ops py Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps System information System Red Hat 4 8 5 Python 2 7 5 bazel 0 5 2 Tensorflow r1 2 Commands Are there any mistakes,,"asimshankar,asimshankar",2017-07-17 10:17:48,2017-07-19 01:29:18
PR,Remove unittest import and duplicate logic from sparse ops test,,,jhseu,2017-07-19 00:25:19,2017-07-19 02:40:39
IS,Cannot restore faster rcnn checkpoint,I want to reload faster rcnn resnet101 model parameters and run as follows python export inference graph py input type image tensor pipeline config path samples configs faster rcnn resnet101 coco config checkpoint path checkpoints faster rcnn resnet101 coco checkpoint model ckpt inference graph path checkpoints faster rcnn resnet101 coco checkpoint test pb But it poses OutOfRangeError OutOfRangeError see above for traceback Read less bytes than requested Node save RestoreV2 408 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 408 tensor names save RestoreV2 408 shape and slices Node save RestoreV2 528 1 Recv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 1164 save RestoreV2 528 tensor type DT FLOAT device job localhost replica 0 task 0 gpu 0 What can I do for this error,,"shreyneil,shreyneil",2017-07-13 11:36:15,2017-07-19 07:56:23
IS,Cannot use AdamOptimizer in C when running graph defined from Python,Running Ubuntu 14 04 with r1 2 Tensorflow I have defined a graph in Python,,,2017-07-03 07:58:49,2017-07-19 11:55:55
PR,Fix issue 10399,Because of the bytes compatibility this function is returning bytes when it should be returning strings Fixes issue TypeError Ca not mix strings and bytes in path components when using tf contrib learn learn runner with experiments with an export strategy See issue 10399 for a code example reference I did not find obvious mistakes but this is my first contribution and I may have missed something,,"xiejw,xiejw",2017-07-18 22:48:27,2017-07-19 16:08:21
IS,There is a input sequence how to calculate probability for a special output sequence,,,asimshankar,2017-07-19 09:16:07,2017-07-19 16:57:00
IS,pre trained weights,can i use the tensorflow pre trained weight model in keras and Vice versa,,asimshankar,2017-07-19 15:41:58,2017-07-19 16:57:14
IS,TypeError init got an unexpected keyword argument ishape',I read these codes from a book but it can not work and after I searched for a couple of days have not similar ishape' problem how can I fix it Is anybody have ideas plz thanks coding utf 8 import tensorflow as tf g1 tf Graph with g1 as default v tf get variable v initializer tf zeros initializer shape 1,,asimshankar,2017-07-19 16:35:37,2017-07-19 17:02:35
PR,Revert Add GradientsDebugger to tfdbg,This reverts commit 31f1375c01782f53cf12ce2aa4efa584483c14ea,,"av8ramit,av8ramit",2017-07-19 17:01:12,2017-07-19 17:03:22
IS,allocate output can result in OOM error,TF commit 7f008453ca1c7b Describe the problem When implementing custom operations allocating output twice as a bug should give at least a warning The following code gives a nearly un debuggable OOM error after many iterations during runtime Is it possible to prevent allocate output i being called with the same i twice,,,2017-07-14 11:23:45,2017-07-19 17:09:07
PR,Update README md,Update readability in example replaced HTTP link to HTTPS links and added a link,,"alanyee,alanyee,caisq,caisq,caisq,alanyee,jhseu",2017-07-07 17:26:34,2017-07-19 19:05:58
IS,Improve exception safety with smart pointers,Would you like to wrap any pointer data members L105 Update candidate RecordioTest class with the template class std unique ptr unique ptr Description for usage of smart pointers,,asimshankar,2017-07-19 18:42:13,2017-07-19 19:49:58
PR,Updating the RELNOTES for 1 3 0rc0,,,"av8ramit,drpngx,caisq,drpngx,caisq,av8ramit,av8ramit,av8ramit,av8ramit,caisq,av8ramit",2017-07-19 17:50:51,2017-07-19 20:17:36
IS,Distributed Tensorflow Cannot assign a device for operation,I am trying to use a distributed version of Self Normalizing Networks on MNIST The full code is provided here class DNN forward MC object def init self num data num test dim input dim output num hidden layers num hidden dims keep prob num minibatch X train Y train X test Y test cluster specification parameter servers localhost 2222 workers localhost 2223 localhost 2224 localhost 2225 cluster tf train ClusterSpec ps parameter servers worker workers input flags tf app flags DEFINE string job name Either 'ps' or 'worker' tf app flags DEFINE integer task index 0 Index of task within the job FLAGS tf app flags FLAGS start a server for a specific task server tf train Server cluster job name FLAGS job name task index FLAGS task index is chief FLAGS task index 0 if FLAGS job name ps server join elif FLAGS job name worker with tf device tf train replica device setter worker device job worker task d cpu 0 FLAGS task index cluster cluster ps device job ps cpu 0 global step tf Variable 0 name global step trainable False self initialize model num data num test dim input dim output num hidden layers num hidden dims keep prob num minibatch predictions self predict training tip aredus' predictions training full self predict training tip 'full' predictions testing full self predict testing cost tf reduce mean tf nn sigmoid cross entropy with logits labels self Y train logits predictions opt tf train GradientDescentOptimizer 1e 3 opt tf train SyncReplicasOptimizer opt replicas to aggregate 3 total num replicas 3 train op opt minimize cost global step global step init op tf global variables initializer grads and vars optimizer compute gradients cost tf trainable variables local init op opt local step init op if is chief local init op opt chief init op ready for local init op opt ready for local init op Initial token and chief queue runners required by the sync replicas mode chief queue runner opt get chief queue runner sync init op opt get init tokens op train dir tempfile mkdtemp sv tf train Supervisor logdir train dir is chief FLAGS task index 0 init op init op local init op local init op recovery wait secs 1 ready for local init op ready for local init op if is chief print Worker d Initializing session FLAGS task index else print Worker d Waiting for session to be initialized FLAGS task index sess config tf ConfigProto allow soft placement True log device placement False device filters job ps job worker task d FLAGS task index with sv prepare or wait for session server target config sess config as sess with tf train MonitoredTrainingSession master server target is chief is chief checkpoint dir ' logs ' save checkpoint secs 60 save summaries steps 1 as sess while True lista np arange self num data np random shuffle lista current index lista self num minibatch likelihood now step now self sess run cost train op global step feed dict self X train X train current index self Y train Y train current index printare 'nll for minibatch at iteration ' str i ' is ' str likelihood now print printare predictions now self sess run predictions training full feed dict self X train full X train print 'accuracy is ' str self sess run tf reduce mean tf cast tf equal tf argmax Y train 1 tf argmax tf nn softmax predictions now 1 tf float32 if step now 10 break print ' training last iteration ' if is chief predictions now self sess run predictions testing full feed dict self X test X test print ' testing ' print 'accuracy at testing time is ' str self sess run tf reduce mean tf cast tf equal tf argmax Y test 1 tf argmax tf nn softmax predictions now 1 tf float32 sv stop def initialize model self num data num test dim input dim output num hidden layers num hidden dims keep prob num minibatch model using just Hinton is Dropout self sess tf Session self num minibatch num minibatch self num data num data self num test num test self dim input dim input self dim output dim output self num hidden layers num hidden layers self num hidden dims num hidden dims self keep prob keep prob self alpha p 1 7580993408473766 q 1 0 keep prob prod q np power self alpha p 2 q 1 q self a affine np power prod 0 5 self b affine self a affine self alpha p 1 q self X train full tf placeholder shape self num data dim input dtype tf float32 self X train tf placeholder tf float32 shape num minibatch dim input self Y train tf placeholder tf float32 shape num minibatch dim output self X test tf placeholder tf float32 shape num test dim input self Y test tf placeholder tf float32 shape num test dim output self weights self biases create parameters for Global DNN for j in range self num hidden layers 1 self weights append tf Variable tf random normal shape num hidden dims j 1 self num hidden dims j stddev 1 0 num hidden dims j 1 dtype tf float32 name 'weights ' str j self biases append tf Variable tf random normal shape self num hidden dims j dtype tf float32 name 'biases' str j self weights append tf Variable tf random normal shape self num hidden dims self num hidden layers self num hidden dims self num hidden layers 1 stddev 1 0 self num hidden dims self num hidden layers dtype tf float32 name 'weights ' str self num hidden layers 1 self biases append tf Variable tf random normal shape self num hidden dims self num hidden layers 1 dtype tf float32 name 'biases ' str self num hidden layers 1 def selu self x alpha 1 6732632423543772848170429916717 lamb 1 0507009873554804934193349852946 return lamb tf where x 0 0 x alpha tf nn elu x def alpha dropout self x mask tf cast tf random uniform shape x get shape 1 0 self keep prob dtype tf float32 x masked tf multiply x mask out x masked self a affine self b affine return out def model self input apply dropout True for j in range 1 self num hidden layers 1 input self selu tf add tf matmul input self weights j self biases j if apply dropout input self alpha dropout input final output tf add tf matmul input self weights self num hidden layers 1 self biases self num hidden layers 1 return final output def predict training self tip if tip 'full' prediction DNN global self model input self X train full apply dropout False else prediction DNN global self model input self X train apply dropout True return prediction DNN global def predict testing self prediction DNN global self model input self X test apply dropout False return prediction DNN global if name ' main ' training data np genfromtxt ' home spopescu mnist train csv' dtype np float64 delimiter ' ' testing data np genfromtxt ' home spopescu mnist test csv' dtype np float64 delimiter ' ' X training training data 1 X testing testing data 1 Y training one hot encoder training data 0 reshape X training shape 0 1 Y testing one hot encoder testing data 0 reshape X testing shape 0 1 obiect DNN forward MC num data X training shape 0 num test X testing shape 0 dim input X training shape 1 dim output Y training shape 1 num hidden layers 3 num hidden dims X training shape 1 200 50 20 Y training shape 1 keep prob 0 80 num minibatch 20 X train X training Y train Y training X test X testing Y test Y testing I am using the following Slurm bash script to send an array job bin sh SBATCH mem 20G SBATCH J SNN SBATCH array 0 3 SBATCH o slurm A a out SBATCH e slurm A a err SBATCH nodelist compute 2 3 task type ps worker worker worker task index array 0 0 1 2 srun exclusive N1 n1 home spopescu anaconda bin python2 7 DNN forward MC py job name task type SLURM ARRAY TASK ID task index task index array SLURM ARRAY TASK ID I am using the latest version of Tensorflow as of today I am getting the following error on my chief worker 2017 07 19 14 49 14 087646 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 2222 2017 07 19 14 49 14 087702 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 2223 1 localhost 2224 2 localhost 2225 2017 07 19 14 49 14 091606 I tensorflow core distributed runtime rpc grpc server lib cc 316 Started server with target grpc 2223 2017 07 19 14 49 15 137109 I tensorflow core distributed runtime master session cc 999 Start master session 4b5afb77d3aa2b77 with config device filters job ps device filters job worker task 0 allow soft placement true Traceback most recent call last File DNN forward MC py line 221 in module obiect DNN forward MC num data X training shape 0 num test X testing shape 0 dim input X training shape 1 dim output Y training shape 1 num hidden layers 3 num hidden dims X training shape 1 200 50 20 Y training shape 1 keep prob 0 80 num minibatch 20 X train X training Y train Y training X test X testing Y test Y testing File DNN forward MC py line 108 in init likelihood now step now self sess run cost train op global step feed dict self X train X train current index self Y train Y train current index File home spopescu local lib python2 7 site packages tensorflow python client session py line 789 in run run metadata ptr File home spopescu local lib python2 7 site packages tensorflow python client session py line 997 in run feed dict string options run metadata File home spopescu local lib python2 7 site packages tensorflow python client session py line 1132 in do run target list options run metadata File home spopescu local lib python2 7 site packages tensorflow python client session py line 1152 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Cannot assign a device for operation isave RestoreV2 10' Operation was explicitly assigned to job ps task 0 device CPU 0 but available devices are job localhost replica 0 task 0 cpu 0 Make sure the device specification refers to a valid device Node save RestoreV2 10 RestoreV2 dtypes DT FLOAT device job ps task 0 device CPU 0 save Const save RestoreV2 10 tensor names save RestoreV2 10 shape and slices Caused by op u isave RestoreV2 10' defined at File DNN forward MC py line 221 in module obiect DNN forward MC num data X training shape 0 num test X testing shape 0 dim input X training shape 1 dim output Y training shape 1 num hidden layers 3 num hidden dims X training shape 1 200 50 20 Y training shape 1 keep prob 0 80 num minibatch 20 X train X training Y train Y training X test X testing Y test Y testing File DNN forward MC py line 90 in init sv tf train Supervisor logdir train dir is chief FLAGS task index 0 init op init op local init op local init op recovery wait secs 1 ready for local init op ready for local init op File home spopescu local lib python2 7 site packages tensorflow python training supervisor py line 300 in init self init saver saver saver File home spopescu local lib python2 7 site packages tensorflow python training supervisor py line 448 in init saver saver saver mod Saver File home spopescu local lib python2 7 site packages tensorflow python training saver py line 1139 in init self build File home spopescu local lib python2 7 site packages tensorflow python training saver py line 1170 in build restore sequentially self restore sequentially File home spopescu local lib python2 7 site packages tensorflow python training saver py line 691 in build restore sequentially reshape File home spopescu local lib python2 7 site packages tensorflow python training saver py line 407 in AddRestoreOps tensors self restore op filename tensor saveable preferred shard File home spopescu local lib python2 7 site packages tensorflow python training saver py line 247 in restore op spec tensor dtype 0 File home spopescu local lib python2 7 site packages tensorflow python ops gen io ops py line 640 in restore v2 dtypes dtypes name name File home spopescu local lib python2 7 site packages tensorflow python framework op def library py line 767 in apply op op def op def File home spopescu local lib python2 7 site packages tensorflow python framework ops py line 2506 in create op original op self default original op op def op def File home spopescu local lib python2 7 site packages tensorflow python framework ops py line 1269 in init self traceback extract stack InvalidArgumentError see above for traceback Cannot assign a device for operation isave RestoreV2 10' Operation was explicitly assigned to job ps task 0 device CPU 0 but available devices are job localhost replica 0 task 0 cpu 0 Make sure the device specification refers to a valid device Node save RestoreV2 10 RestoreV2 dtypes DT FLOAT device job ps task 0 device CPU 0 save Const save RestoreV2 10 tensor names save RestoreV2 10 shape and slices I have mostly seen the cannot assign a device for operation error in the case of people using GPU without specifying allow soft placement True but in my case I am using just CPUs I have seen another instance of this error when users were not specifying server target as the device of a session thereby creating a local session but this is not the case in my code Any help would be much appreciated,,mrry,2017-07-19 14:06:22,2017-07-19 21:26:06
PR,Support placeholder for parameter k in tf nn in top k,This fix tries to address the issue raised in 9717 where it was not possible to have tensor for k in nn in top k This fix adds the implementation of InTopKV2Op adds addition test cases and following similiar workflow in 10840 1 Register new kennel InTopKV2Op 2 Hide InTopK and InTopKV2 in python tensorflow python ops hidden ops txt 3 Add a wrapper in top k in tensorflow python ops nn ops py pointing to gen nn ops in top k Another PR will be created after 3 weeks once this PR is merged 1 Change the implementation of the wrapper in top k in tensorflow python ops nn ops py pointing to gen nn ops in top kv2 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,yongtang,drpngx,girving,girving,girving,girving,yongtang,yongtang,yongtang,yongtang,yongtang,drpngx",2017-06-30 22:37:42,2017-07-19 21:34:04
PR,CoordinatedSessionCreator should inherit from SessionCreator,CoordinatedSessionCreator should inherit from SessionCreator,,"horance-liu,jhseu",2017-07-19 14:27:52,2017-07-19 22:08:06
PR,Adding documentation about contrib losses,Add information for update from tf contrib losses hinge loss to tf losses hinge loss Add more notes of deprecation Other minor corrections and updates,,"alanyee,alextp,jhseu,alanyee,jhseu",2017-07-19 07:09:28,2017-07-19 22:08:44
PR,Fixes 'window size' may be used uninitialized,,,"lukeiwanski,jhseu,jhseu",2017-07-17 21:54:31,2017-07-19 22:08:59
PR,Add a code of conduct,,,martinwicke,2017-07-12 14:45:15,2017-07-19 22:10:34
PR,Tidy up MKL configuration,Also only use config mkl to build with MKL support,,"gunan,drpngx,gunan,gunan,gunan,drpngx,drpngx,drpngx,agramesh1,gunan,jart,jart,jart,gunan,gunan,gunan,gunan,gunan,drpngx,agramesh1,gunan,drpngx,drpngx,gunan,gunan,gunan,agramesh1,gunan,gunan,gunan,agramesh1,jhseu",2017-07-02 04:00:33,2017-07-19 22:11:14
IS,Different results from scipy imread and tensorflow decode jpeg,Problem Description Image decoded using decode jpeg from tensor flow is visually similar but numerically different from one returned by scipy imread Minimal Example System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Python version 3 5,,"drpngx,drpngx",2017-07-19 20:45:08,2017-07-19 22:46:34
IS,estimators SVM test py included in test suite,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No custom code OS Platform and Distribution e g Linux Ubuntu 16 04 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus TensorFlow installed from source or binary Installed from source master branch TensorFlow version use command below print tensorflow VERSION 1 2 1 print tensorflow GIT VERSION b'v1 2 0 2149 gf092326' Python version Python 2 7 12 default Nov 19 2016 06 48 10 GCC 5 4 0 20160609 on linux2 Bazel version if compiling from source bazel release 0 5 2 CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce bazel test tensorflow python test verbose timeout warnings Describe the problem I am troubleshooting my usage of estimators SVM and along the way it seems like svm test py is not executed when running the bazel test command above I'm a tensorflow newb so it would be super helpful for me to understand what I'm missing here Source code logs tensorflow python decorator utils test cached PASSED in 1 2s WARNING tensorflow python decorator utils test Test execution time 1 2s excluding execution overhead outside of range for MODERATE tests Consider setting timeout short or size small tensorflow python deprecation test cached PASSED in 1 1s WARNING tensorflow python deprecation test Test execution time 1 1s excluding execution overhead outside of range for MODERATE tests Consider setting timeout short or size small tensorflow python dequantize op test cached PASSED in 1 1s tensorflow python device lib test cached PASSED in 1 1s tensorflow python device setter test cached PASSED in 1 2s tensorflow python estimator dnn linear combined test cached PASSED in 19 0s Stats over 4 runs max 19 0s min 11 8s avg 15 4s dev 2 5s tensorflow python estimator dnn test cached PASSED in 22 8s tensorflow python estimator estimator test cached PASSED in 9 5s tensorflow python estimator export output test cached PASSED in 1 2s tensorflow python estimator export test cached PASSED in 5 3s tensorflow python estimator feeding functions test cached PASSED in 1 3s tensorflow python estimator feeding queue runner test cached PASSED in 2 5s tensorflow python estimator head test cached PASSED in 7 2s tensorflow python estimator linear test cached PASSED in 35 3s tensorflow python estimator model fn test cached PASSED in 1 2s tensorflow python estimator numpy io test cached PASSED in 1 3s tensorflow python estimator optimizers test cached PASSED in 1 0s tensorflow python estimator pandas io test cached PASSED in 1 5s tensorflow python estimator parsing utils test cached PASSED in 1 5s tensorflow python estimator run config test cached PASSED in 1 2s tensorflow python estimator util test cached PASSED in 1 0s WARNING tensorflow python estimator util test Test execution time 1 0s excluding execution overhead outside of range for MODERATE tests Consider setting timeout short or size small tensorflow python events writer test cached PASSED in 0 9s tensorflow python feature column feature column test cached PASSED in 5 2s WARNING tensorflow python feature column feature column test Test execution time 5 2s excluding execution overhead outside of range for MODERATE tests Consider setting timeout short or size small tensorflow python file io test cached PASSED in 1 9s,,drpngx,2017-07-19 15:26:39,2017-07-19 22:51:42
IS,who can tell me where is gru backward code i want modify it,who can tell me where is gru backward code i want modify it i want implete reduce gru size,,"rryan,drpngx",2017-07-19 07:26:57,2017-07-19 22:52:22
PR,XLA Fix plugin example buffer address for tuples,Currently the returned se DeviceMemoryBase buf size uses the incremented buf which may cause deallocation error,,jhseu,2017-07-18 23:13:04,2017-07-19 22:52:35
IS,Not able to import tensorflow python3 5 2 Tensorflow installation from PIP3 on window machine,import tensorflow as tf Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Program Files Python35 lib site packages tensorflow init py lin e 24 in module from tensorflow python import File C Program Files Python35 lib site packages tensorflow python init p y line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation probl ems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,drpngx,2017-07-16 04:38:45,2017-07-20 05:12:26
IS,how to load my pretrain model in ckpt file v2 format,Hi when I use ckpt v1 format the command line as follows python faster rcnn test net py gpu 0 weights models VGGnet fast rcnn iter 150000 ckpt imdb voc 2007 test cfg experiments cfgs faster rcnn end2end yml network VGGnet test it works but I train my model in voc 2007 dataset the output like this 2017 07 20 21 27 37 the test net py code as follows the output is Waiting for output faster rcnn end2end pva voc voc 2007 trainval PVAnet iter 10000 ckpt to exist I have read some issues but can not solve it I need some help about this question how to load my pretrain model in ckpt file v2 format modify my test net py thanks,,asimshankar,2017-07-20 13:33:14,2017-07-20 14:40:35
PR,Sort shuffled indices before indexing NumpyFeed,It is possible to use h5py datasets with tf estimator inputs numpy input fn as there is a high level of compatibility However with shuffle True one can no longer do so due to the following error TypeError Indexing elements must be in increasing order This small change allows for one to use large HDF5 datasets via h5py with shuffled batch indices,,"xiejw,xiejw,drpngx,drpngx,drpngx,drpngx,frankchn,xiejw,xiejw,jhseu,allenlavoie,xiejw",2017-06-23 11:21:17,2017-07-20 15:58:01
IS,Missing file,The file named node def pb2 is missing from tensorflow core framework The file is required when I try to load the MNIST data as part of the tensorflow tutorial,,asimshankar,2017-07-19 21:42:16,2017-07-20 16:23:44
IS,Why are tensorboard removed after r1 2,Previously it was located in tensorflow tensorboard Is it removed or moved to somewhere else What if I want to add new features in tensorboard Any suggestion is appreciated,,dandelionmane,2017-07-20 08:56:05,2017-07-20 16:55:52
IS,when connect mnist download mnist data show network connection error,image I know if the error show just our company can not connect to mnist can i manual download mnist data and use it how can i do this,,,2017-07-20 06:50:25,2017-07-20 16:56:16
IS,mnist with summaries py kills gpu,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Antergos GNU Linux x86 64 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 6 1 CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory Nvidia GeForce 840m Optimus 2GB memory Exact command to reproduce python mnist with summaries py Description Running the following tutorial code produces an error see below and renders the gpu unusable until the system is rebooted If we comment out line 167 run options tf RunOptions trace level tf RunOptions FULL TRACE and line 171 options run options then the code runs fine without error Source code logs 2017 07 20 11 55 43 203763 I tensorflow stream executor dso loader cc 129 Could not open CUDA library libcupti so 8 0 LD LIBRARY PATH usr lib nvidia usr lib32 nvidia usr lib usr lib32 usr lib 2017 07 20 11 55 43 203810 F tensorflow stream executor lib statusor h 205 Non OK status status status Failed precondition could not dlopen DSO libcupti so 8 0 dlerror libcupti so 8 0 cannot open shared object file No such file or directory,,asimshankar,2017-07-20 11:19:03,2017-07-20 18:52:47
PR,Updating RELEASE notes,,,av8ramit,2017-07-20 18:07:38,2017-07-20 19:59:24
IS,Feature request tensordot GPU kernel,Hi I have two placeholder tensors with some matching axes that I would like to multiply element wise and sum across Implementation with tf tensordot works perfectly on cpu but it looks like there is no gpu kernel available for this op Would it be possible to have one added Or is there a workaround using simpler operations such as multiply and reduce sum that are currently gpu supported Specifically I would like to be able to run something equivalent to the following on gpu a tf placeholder shape None 16 17 18 e g b tf placeholder shape 5 17 18 20 c tf tensordot a b axes 2 3 1 2 shape of c None 16 5 20 When I run c in a session using tf device ' gpu 0' I get the following error InvalidArgumentError see above for traceback Cannot assign a device for operation 'Tensordot ListDiff' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available Node Tensordot ListDiff ListDiff T DT INT32 out idx DT INT32 device device GPU 0 Tensordot range Tensordot add 1,,"drpngx,yaroslavvb",2017-07-19 18:11:30,2017-07-20 20:26:17
PR,Repo Update,,,,2017-07-20 23:07:16,2017-07-20 23:07:28
PR,Merge1 3 0rc0 back to master,,,av8ramit,2017-07-20 21:08:44,2017-07-21 00:42:41
PR,Branch 162681705,,,"jhseu,jhseu,jhseu",2017-07-21 00:47:56,2017-07-21 01:39:29
PR,Branch 162658391,,,"jhseu,jhseu,ebrevdo,ebrevdo,jvdillon",2017-07-20 20:43:31,2017-07-21 01:39:38
IS,can not import data utils from tensorflow models rnn translate No module name tensorflow models,i encountered this while trying to import data utils from tensorflow models rnn translate in the end NO module named tensorfow models was my output,,asimshankar,2017-07-20 19:48:44,2017-07-21 02:11:50
IS,Is there a way to visualise the hidden layer during the Seq2Seq translation in translate py,Is there any way I could visualise the hidden layer process during the translation process in Sequence to Sequence Modelling using Tensorflow Tensorflow version 1 0 CPU version Python 2 7 Windows,,"caisq,asimshankar",2017-07-20 14:12:06,2017-07-21 02:12:06
IS,Build error in Windows 10,My environment is Windows 10 64bit Lenovo P50 workstation notebook NVIDIA Quadro M2000M 4GB Intel HD Graphics P530 Build environment is Microsoft Visual Studio Enterprise 2015 with Visual C 2015 Anaconda 4 1 1 Python 3 5 64 bit Git for Windows version 2 9 2 windows 1 swigwin 3 0 10 NVidia CUDA Toolkit 8 0 NVidia CUDNN 5 1 CMake 3 6 In building process two errors were fixed by myself 1 C2001 error is caused by D workspace tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc D workspace tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc I do isave as' two files with unicode and LS options I am in Korea it might be language diffence 2 C1071 error is caused by D workspace tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc I eliminated an empy line and ' namespace re2 at the end of the code However I have not clear this error after I put command MSBuild p Configuration Release tf tutorials example trainer vcxproj I think it is a kind of link errors There is a full log from command window What is the problem please forgive me some instructions are written in Korean D workspace tensorflow tensorflow contrib cmake build MSBuild p Configuration Release tf tutorials example trainer vcxproj Microsoft R Build Engine 14 0 25420 1 Copyright C Microsoft Corporation All rights reserved 2017 07 21 10 27 34 1 D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer v cxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj 1 1 D workspace tensorflow tensorflow contrib cmake build ZERO CHECK vcxproj 2 InitializeBuildStatus AlwaysCreate x64 Release ZERO CHECK ZERO CHECK tlog unsuccessfulbuild CustomBuild FinalizeBuildStatus x64 Release ZERO CHECK ZERO CHECK tlog unsuccessfulbuild x64 Release ZERO CHECK ZERO CHECK tlog ZERO CHECK lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build ZERO CHECK vcxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj 1 1 D workspace tensorflow tensorflow contrib cmake build tf cc framework vc xproj 3 D workspace tensorflow tensorflow contrib cmake build tf cc framework vcxproj 3 1 D workspace tensorflow tensorflow contrib cmake build tf core framework vcxproj 4 D workspace tensorflow tensorflow contrib cmake build tf core framework vcxproj 4 1 D workspace tensorflow tensorflow contrib cmake build proto text vcxproj 5 D workspace tensorflow tensorflow contrib cmake build proto text vcxproj 5 1 D workspace tensorflow tensorflow contrib cmake build grpc vcxproj 6 D workspace tensorflow tensorflow contrib cmake build grpc vcxproj 6 1 D wo rkspace tensorflow tensorflow contrib cmake build protobuf vcxproj 7 D workspace tensorflow tensorflow contrib cmake build protobuf vcxproj 7 1 D workspace tensorflow tensorflow contrib cmake build zlib vcxproj 8 InitializeBuildStatus AlwaysCreate x64 Release zlib zlib tlog unsuccessfulbuild CustomBuild Performing update step for 'zlib' FinalizeBuildStatus x64 Release zlib zlib tlog unsuccessfulbuild x64 Release zlib zlib tlog zlib lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build zlib vcxproj InitializeBuildStatus AlwaysCreate x64 Release protobuf protobuf tlog unsuccessfulbuild CustomBuild Performing update step for 'protobuf' FinalizeBuildStatus x64 Release protobuf protobuf tlog unsuccessfulbuild x64 Release protobuf protobuf tlog protobuf lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build protobuf vcxproj InitializeBuildStatus AlwaysCreate x64 Release grpc grpc tlog unsuccessfulbuild CustomBuild Performing update step for 'grpc' FinalizeBuildStatus x64 Release grpc grpc tlog unsuccessfulbuild x64 Release grpc grpc tlog grpc lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build grpc vcxproj D workspace tensorflow tensorflow contrib cmake build proto text vcxproj 5 1 D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build cub vcxproj 10 InitializeBuildStatus AlwaysCreate x64 Release cub cub tlog unsuccessfulbuild FinalizeBuildStatus x64 Release cub cub tlog unsuccessfulbuild x64 Release cub cub tlog cub lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build cub vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build eigen vcxproj 11 InitializeBuildStatus AlwaysCreate x64 Release eigen eigen tlog unsuccessfulbuild FinalizeBuildStatus x64 Release eigen eigen tlog unsuccessfulbuild x64 Release eigen eigen tlog eigen lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build eigen vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build farmhash copy headers to destinatio n vcxproj 12 D workspace tensorflow tensorflow contrib cmake build farmhash copy headers to destination vcxproj 12 1 D workspace tensorflow tensorflow contrib cmake build farmhash create destination dir vcxproj 13 D workspace tensorflow tensorflow contrib cmake build farmhash create destination dir vcxp roj 13 1 D workspace tensorflow tensorflow contrib cmake build farmhash vcxpr oj 14 InitializeBuildStatus AlwaysCreate x64 Release farmhash farmhash tlog unsuccessfulbuild FinalizeBuildStatus x64 Release farmhash farmhash tlog unsuccessfulbuild x64 Release farmhash farmhash tlog farmhash lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build farmhash vcxproj InitializeBuildStatus AlwaysCreate x64 Release farmhash create destination dir farmhash 8BF8255 3 tlog unsuccessfulbuild FinalizeBuildStatus x64 Release farmhash create destination dir farmhash 8BF82553 tlog unsuccessfulbuild x64 Release farmhash create destination dir farmhash 8BF82553 tlog farmhash create destin ation dir lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build farmhash create destination dir vcxp roj InitializeBuildStatus AlwaysCreate x64 Release farmhash copy headers to destination farmhash 6D ED34F1 tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build farmhash src farmhash src farmhash h D workspace tensorflow tens orflow contrib cmake build external farmhash archive D workspace tensorflow tensorflow co ntrib cmake build external farmhash archive util if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release farmhash copy headers to destination farmhash 6DED34F1 tlog unsuccessfulbuild x64 Release farmhash copy headers to destination farmhash 6DED34F1 tlog farmhash copy hea ders to destination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build farmhash copy headers to destination vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build fft2d vcxproj 15 InitializeBuildStatus AlwaysCreate x64 Release fft2d fft2d tlog unsuccessfulbuild FinalizeBuildStatus x64 Release fft2d fft2d tlog unsuccessfulbuild x64 Release fft2d fft2d tlog fft2d lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build fft2d vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build gemmlowp vcxproj 16 InitializeBuildStatus AlwaysCreate x64 Release gemmlowp gemmlowp tlog unsuccessfulbuild FinalizeBuildStatus x64 Release gemmlowp gemmlowp tlog unsuccessfulbuild x64 Release gemmlowp gemmlowp tlog gemmlowp lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build gemmlowp vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build gif copy headers to destination vcx proj 17 D workspace tensorflow tensorflow contrib cmake build gif copy headers to destination vcxp roj 17 1 D workspace tensorflow tensorflow contrib cmake build gif create des tination dir vcxproj 18 D workspace tensorflow tensorflow contrib cmake build gif create destination dir vcxproj 18 1 D workspace tensorflow tensorflow contrib cmake build gif vcxproj 19 InitializeBuildStatus AlwaysCreate x64 Release gif gif tlog unsuccessfulbuild FinalizeBuildStatus x64 Release gif gif tlog unsuccessfulbuild x64 Release gif gif tlog gif lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build gif vcxproj InitializeBuildStatus AlwaysCreate x64 Release gif create destination dir gif crea BBA1858C tlo g unsuccessfulbuild FinalizeBuildStatus x64 Release gif create destination dir gif crea BBA1858C tlog unsuccessfulbuild x64 Release gif create destination dir gif crea BBA1858C tlog gif create destination dir lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build gif create destination dir vcxproj InitializeBuildStatus AlwaysCreate x64 Release gif copy headers to destination gif copy B8CE1EC 7 tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build gif install include gif lib h D workspace tensorflow tensorflow contrib cmake build external gif archive giflib 5 1 4 if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release gif copy headers to destination gif copy B8CE1EC7 tlog unsuccessfulbuild x64 Release gif copy headers to destination gif copy B8CE1EC7 tlog gif copy headers to de stination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build gif copy headers to destination vcxp roj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build highwayhash copy headers to destina tion vcxproj 20 D workspace tensorflow tensorflow contrib cmake build highwayhash copy headers to destinat ion vcxproj 20 1 D workspace tensorflow tensorflow contrib cmake build highwa yhash create destination dir vcxproj 21 D workspace tensorflow tensorflow contrib cmake build highwayhash create destination dir v cxproj 21 1 D workspace tensorflow tensorflow contrib cmake build highwayhash vcxproj 22 InitializeBuildStatus AlwaysCreate x64 Release highwayhash highwayhash tlog unsuccessfulbuild CustomBuild Performing update step for 'highwayhash' FinalizeBuildStatus x64 Release highwayhash highwayhash tlog unsuccessfulbuild x64 Release highwayhash highwayhash tlog highwayhash lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build highwayhash vcxproj InitializeBuildStatus AlwaysCreate x64 Release highwayhash create destination dir highwayh B196 919F tlog unsuccessfulbuild FinalizeBuildStatus x64 Release highwayhash create destination dir highwayh B196919F tlog unsuccessfulbuild x64 Release highwayhash create destination dir highwayh B196919F tlog highwayhash create destination dir lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build highwayhash create destination dir v cxproj InitializeBuildStatus AlwaysCreate x64 Release highwayhash copy headers to destination highwayh E3D19F9A tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy directory D workspace tensorflow tensorflo w contrib cmake build highwayhash install include D workspace tensorflow tensorflow cont rib cmake build external highwayhash highwayhash if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release highwayhash copy headers to destination highwayh E3D19F9A tlog unsuccessfulbu ild x64 Release highwayhash copy headers to destination highwayh E3D19F9A tlog highwayhash co py headers to destination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build highwayhash copy headers to destinat ion vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build jpeg copy headers to destination vc xproj 23 D workspace tensorflow tensorflow contrib cmake build jpeg copy headers to destination vcx proj 23 1 D workspace tensorflow tensorflow contrib cmake build jpeg create d estination dir vcxproj 24 D workspace tensorflow tensorflow contrib cmake build jpeg create destination dir vcxproj 24 1 D workspace tensorflow tensorflow contrib cmake build jpeg vcxproj 25 InitializeBuildStatus AlwaysCreate x64 Release jpeg jpeg tlog unsuccessfulbuild FinalizeBuildStatus x64 Release jpeg jpeg tlog unsuccessfulbuild x64 Release jpeg jpeg tlog jpeg lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build jpeg vcxproj InitializeBuildStatus AlwaysCreate x64 Release jpeg create destination dir jpeg cre A5B93FBD tl og unsuccessfulbuild FinalizeBuildStatus x64 Release jpeg create destination dir jpeg cre A5B93FBD tlog unsuccessfulbuild x64 Release jpeg create destination dir jpeg cre A5B93FBD tlog jpeg create destination di r lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build jpeg create destination dir vcxproj InitializeBuildStatus AlwaysCreate x64 Release jpeg copy headers to destination jpeg cop 01FA55 1C tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg install include jconfig h D workspace tensorflow tensorflow contrib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg install include jerror h D workspace tensorflow tensorflow contrib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg install include jmorecfg h D workspace tensorflow tensorflo w contrib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg install include jpeglib h D workspace tensorflow tensorflow contrib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg cderror h D workspace tensorflow tensorflow contri b cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg cdjpeg h D workspace tensorflow tensorflow contrib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg jdct h D workspace tensorflow tensorflow contrib c make build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg jinclude h D workspace tensorflow tensorflow contr ib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg jmemsys h D workspace tensorflow tensorflow contri b cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg jpegint h D workspace tensorflow tensorflow contri b cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg jversion h D workspace tensorflow tensorflow contr ib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build jpeg src jpeg transupp h D workspace tensorflow tensorflow contr ib cmake build external jpeg archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release jpeg copy headers to destination jpeg cop 01FA551C tlog unsuccessfulbuild x64 Release jpeg copy headers to destination jpeg cop 01FA551C tlog jpeg copy headers to destination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build jpeg copy headers to destination vcx proj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build jsoncpp vcxproj 26 InitializeBuildStatus AlwaysCreate x64 Release jsoncpp jsoncpp tlog unsuccessfulbuild CustomBuild Performing update step for 'jsoncpp' FinalizeBuildStatus x64 Release jsoncpp jsoncpp tlog unsuccessfulbuild x64 Release jsoncpp jsoncpp tlog jsoncpp lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build jsoncpp vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build lmdb copy headers to destination vc xproj 27 D workspace tensorflow tensorflow contrib cmake build lmdb copy headers to destination vcx proj 27 1 D workspace tensorflow tensorflow contrib cmake build lmdb create d estination dir vcxproj 28 D workspace tensorflow tensorflow contrib cmake build lmdb create destination dir vcxproj 28 1 D workspace tensorflow tensorflow contrib cmake build lmdb vcxproj 29 InitializeBuildStatus AlwaysCreate x64 Release lmdb lmdb tlog unsuccessfulbuild FinalizeBuildStatus x64 Release lmdb lmdb tlog unsuccessfulbuild x64 Release lmdb lmdb tlog lmdb lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build lmdb vcxproj InitializeBuildStatus AlwaysCreate x64 Release lmdb create destination dir lmdb cre EF427DD5 tl og unsuccessfulbuild FinalizeBuildStatus x64 Release lmdb create destination dir lmdb cre EF427DD5 tlog unsuccessfulbuild x64 Release lmdb create destination dir lmdb cre EF427DD5 tlog lmdb create destination di r lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build lmdb create destination dir vcxproj InitializeBuildStatus AlwaysCreate x64 Release lmdb copy headers to destination lmdb cop 18AF5D C1 tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build lmdb install include lmdb h D workspace tensorflow tensorflow co ntrib cmake build external lmdb if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build lmdb install include midl h D workspace tensorflow tensorflow co ntrib cmake build external lmdb if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release lmdb copy headers to destination lmdb cop 18AF5DC1 tlog unsuccessfulbuild x64 Release lmdb copy headers to destination lmdb cop 18AF5DC1 tlog lmdb copy headers to destination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build lmdb copy headers to destination vcx proj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build png copy headers to destination vcx proj 30 D workspace tensorflow tensorflow contrib cmake build png copy headers to destination vcxp roj 30 1 D workspace tensorflow tensorflow contrib cmake build png create des tination dir vcxproj 31 D workspace tensorflow tensorflow contrib cmake build png create destination dir vcxproj 31 1 D workspace tensorflow tensorflow contrib cmake build png vcxproj 32 InitializeBuildStatus AlwaysCreate x64 Release png png tlog unsuccessfulbuild FinalizeBuildStatus x64 Release png png tlog unsuccessfulbuild x64 Release png png tlog png lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build png vcxproj InitializeBuildStatus AlwaysCreate x64 Release png create destination dir png crea DCB84CF1 tlo g unsuccessfulbuild FinalizeBuildStatus x64 Release png create destination dir png crea DCB84CF1 tlog unsuccessfulbuild x64 Release png create destination dir png crea DCB84CF1 tlog png create destination dir lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build png create destination dir vcxproj InitializeBuildStatus AlwaysCreate x64 Release png copy headers to destination png copy 153F572 B tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build png install include libpng12 png h D workspace tensorflow tensor flow contrib cmake build external png archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build png install include libpng12 pngconf h D workspace tensorflow te nsorflow contrib cmake build external png archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release png copy headers to destination png copy 153F572B tlog unsuccessfulbuild x64 Release png copy headers to destination png copy 153F572B tlog png copy headers to de stination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build png copy headers to destination vcxp roj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build re2 vcxproj 33 InitializeBuildStatus AlwaysCreate x64 Release re2 re2 tlog unsuccessfulbuild CustomBuild Performing update step for are2' FinalizeBuildStatus x64 Release re2 re2 tlog unsuccessfulbuild x64 Release re2 re2 tlog re2 lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build re2 vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build tf protos cc vcxproj 34 InitializeBuildStatus AlwaysCreate tf protos cc dir Release tf protos cc tlog unsuccessfulbuild CustomBuild ClCompile Lib tf protos cc vcxproj D workspace tensorflow tensorflow contrib cmake build Release tf protos cc lib FinalizeBuildStatus tf protos cc dir Release tf protos cc tlog unsuccessfulbuild tf protos cc dir Release tf protos cc tlog tf protos cc lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build tf protos cc vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj 9 1 D workspace tensorflow tensorflow contrib cmake build zlib copy headers to destination vc xproj 35 D workspace tensorflow tensorflow contrib cmake build zlib copy headers to destination vcx proj 35 1 D workspace tensorflow tensorflow contrib cmake build zlib create d estination dir vcxproj 36 InitializeBuildStatus AlwaysCreate x64 Release zlib create destination dir zlib cre A3320549 tl og unsuccessfulbuild FinalizeBuildStatus x64 Release zlib create destination dir zlib cre A3320549 tlog unsuccessfulbuild x64 Release zlib create destination dir zlib cre A3320549 tlog zlib create destination di r lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build zlib create destination dir vcxproj InitializeBuildStatus AlwaysCreate x64 Release zlib copy headers to destination zlib cop ED29D1 64 tlog unsuccessfulbuild PreBuildEvent setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build zlib install include zconf h D workspace tensorflow tensorflow c ontrib cmake build external zlib archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd setlocal C Program Files CMake bin cmake exe E copy if different D workspace tensorflow tensor flow contrib cmake build zlib install include zlib h D workspace tensorflow tensorflow co ntrib cmake build external zlib archive if errorlevel neq 0 goto cmEnd cmEnd endlocal call cmErrorLevel errorlevel goto cmDone cmErrorLevel exit b 1 cmDone if errorlevel neq 0 goto VCEnd VCEnd FinalizeBuildStatus x64 Release zlib copy headers to destination zlib cop ED29D164 tlog unsuccessfulbuild x64 Release zlib copy headers to destination zlib cop ED29D164 tlog zlib copy headers to destination lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build zlib copy headers to destination vcx proj InitializeBuildStatus AlwaysCreate tf core lib dir Release tf core lib tlog unsuccessfulbuild CustomBuild ClCompile Lib tf core lib vcxproj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release tf core lib lib FinalizeBuildStatus tf core lib dir Release tf core lib tlog unsuccessfulbuild tf core lib dir Release tf core lib tlog tf core lib lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build tf core lib vcxproj InitializeBuildStatus proto text dir Release proto text tlog unsuccessfulbuild touching CustomBuild ClCompile Link C Program Files x86 Microsoft Visual Studio 14 0 VC bin amd64 link exe ERRORREPORT QUE UE OUT D workspace tensorflow tensorflow contrib cmake build Release proto text exe I NCREMENTAL NO NOLOGO kernel32 lib user32 lib gdi32 lib winspool lib shell32 lib ole32 lib oleaut32 lib uuid lib comdlg32 lib advapi32 lib zlib install lib zlibstatic lib gif insta ll lib giflib lib png install lib libpng12 static lib jpeg install lib libjpeg lib lmdb in stall lib lmdb lib jsoncpp src jsoncpp src lib json Release jsoncpp lib farmhash install l ib farmhash lib fft2d src lib fft2d lib highwayhash install lib highwayhash lib protobuf src protobuf Release libprotobuf lib re2 src re2 Release re2 lib grpc src grpc Release grp c unsecure lib grpc src grpc Release grpc unsecure lib grpc src grpc Release gpr lib wso ck32 lib ws2 32 lib shlwapi lib C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 l ib x64 cudart static lib C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 lib x64 cuda lib C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 lib x64 cublas lib C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 lib x64 cublas device lib C Prog ram Files NVIDIA GPU Computing Toolkit CUDA v8 0 lib x64 cufft lib C Program Files NVID IA GPU Computing Toolkit CUDA v8 0 lib x64 curand lib C Program Files NVIDIA GPU Comput ing Toolkit CUDA v8 0 extras CUPTI libx64 cupti lib C Program Files NVIDIA GPU Computin g Toolkit CUDA v8 0 lib x64 cusolver lib C Program Files NVIDIA GPU Computing Toolkit C UDA v8 0 lib x64 cudnn lib Release tf protos cc lib MANIFEST MANIFESTUAC level 'asInvo ker' uiAccess 'false' manifest embed PDB D workspace tensorflow tensorflow contrib cm ake build Release proto text pdb SUBSYSTEM CONSOLE TLBID 1 DYNAMICBASE NXCOMPAT IMPL IB D workspace tensorflow tensorflow contrib cmake build Release proto text lib MACHIN E X64 machine x64 ignore 4049 ignore 4197 ignore 4217 ignore 4221 proto text dir Rel ease gen proto text functions obj proto text dir Release gen proto text functions lib obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release arena obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release bitmap obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release coding obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release status obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release stringpiece obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release threadpool obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release gif io obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release crc32c obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release crc32c acce lerate obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release hash obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release histogram o bj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release block obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release block build er obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release buffered in putstream obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release compression obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release format obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release inputbuffer obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release inputstream interface obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release iterator ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release path obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release random inpu tstream obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release record read er obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release record writ er obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release snappy inpu tbuffer obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release snappy outp utbuffer obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release table obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release table build er obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release two level i terator obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release zlib inputs tream obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release zlib output buffer obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release jpeg handle obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release jpeg mem ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release collection registry obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release png io obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release distributio n sampler obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release random obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release simple phil ox obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release weighted pi cker obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release base64 obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release numbers obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release ordered cod e obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release proto text util obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release scanner obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release str util ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release strcat obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release stringprint f obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release wav io obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release cpu feature guard obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release cpu info ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform cuda libdevice path cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release denormal ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform env cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform env time cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release file system obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release protobuf ut il obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release setround ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release tensor codi ng obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform tracing cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform default cuda libdevice path cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release gpu tracer obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release logging obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release protobuf ob j D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform default tracing cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release resource ha ndle obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform windows env cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform windows env time cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform windows error cc obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release net obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release port obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release windows fil e system obj D workspace tensorflow tensorflow contrib cmake build tf core lib dir Release D workspac e tensorflow tensorflow core platform posix error cc obj gpu tracer obj error LNK2019 public void cdecl tensorflow StepStatsCollector Save c lass std basic string char struct std char traits char class std allocator char const class tensorflow NodeExecStats Save StepStatsCollector tensorflow QEAAXAEBV basi c string DU char traits D std V allocator D 2 std PEAVNodeExecStats 2 Z public virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Coll ect class tensorflow StepStatsCollector Collect GPUTracerImpl gputracer tensorflow U EAA AVStatus 3 PEAVStepStatsCollector 3 Z D workspace tensorflow tenso rflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityDisable enum CUpti ActivityKind ActivityDisable CuptiWrapper profiler gputools perftools QEAA AW4CUptiResult W4CUpti ActivityKind Z pu blic class tensorflow Status cdecl tensorflow gputracer CUPTIManager DisableTrace voi d DisableTrace CUPTIManager gputracer tensorflow QEAA AVStatus 3 XZ D workspace tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityEnable enum CUpti ActivityKind ActivityEnable CuptiWrapper pr ofiler gputools perftools QEAA AW4CUptiResult W4CUpti ActivityKind Z publ ic class tensorflow Status cdecl tensorflow gputracer CUPTIManager EnableTrace class tensorflow gputracer CUPTIClient EnableTrace CUPTIManager gputracer tensorflow QEAA AVStatus 3 PEAVCUPTIClient 23 Z D workspace tensorflow tensorflow con trib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityFlushAll unsigned int ActivityFlushAll CuptiWrapper profiler gputools perftools QEAA AW4CUptiResult I Z public class tensorflow Status cdecl tensorflow gputracer CUPTIManager DisableTrace void DisableTrace CUPTIManage r gputracer tensorflow QEAA AVStatus 3 XZ D workspace tensorflow tenso rflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityGetNextRecord unsigned char unsigned int64 struct CUpti Activ ity ActivityGetNextRecord CuptiWrapper profiler gputools perftools QEAA AW4CUptiRes ult PEAE KPEAPEAUCUpti Activity Z private void cdecl tensorflow gputra cer CUPTIManager InternalBufferCompleted struct CUctx st unsigned int unsigned char un signed int64 unsigned int64 InternalBufferCompleted CUPTIManager gputracer tensorflo w AEAAXPEAUCUctx st IPEAE K2 Z D workspace tensorflow tensorflow cont rib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityGetNumDroppedRecords struct CUctx st unsigned int unsigned in t64 ActivityGetNumDroppedRecords CuptiWrapper profiler gputools perftools QEAA AW4CUp tiResult PEAUCUctx st IPEA K Z private void cdecl tensorflow gputracer CUPTIManager InternalBufferCompleted struct CUctx st unsigned int unsigned char unsign ed int64 unsigned int64 InternalBufferCompleted CUPTIManager gputracer tensorflow A EAAXPEAUCUctx st IPEAE K2 Z D workspace tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper ActivityRegisterCallbacks void cdecl unsigned char unsigned in t64 unsigned int64 void cdecl struct CUctx st unsigned int unsigned char uns igned int64 unsigned int64 ActivityRegisterCallbacks CuptiWrapper profiler gputools QEAA AW4CUptiResult P6AXPEAPEAEPEA K1 ZP6AXPEAUCUctx st IPEAE K5 Z Z public cdecl tensorflow gputracer CUPTIManager CUPTIManager void 0CUPTIMana ger gputracer tensorflow QEAA XZ D workspace tensorflow tensorflow con trib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper GetTimestamp unsigned int64 GetTimestamp CuptiWrapper profiler gp utools perftools QEAA AW4CUptiResult PEA K Z public virtual class tensorfl ow Status cdecl tensorflow gputracer GPUTracerImpl Start void Start GPUTracerImpl gputracer tensorflow UEAA AVStatus 3 XZ D workspace tensorflow tensorf low contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper EnableCallback unsigned int struct CUpti Subscriber st enum CUpti Callb ackDomain unsigned int EnableCallback CuptiWrapper profiler gputools perftools QEAA AW4 CUptiResult IPEAUCUpti Subscriber st W4CUpti CallbackDomain I Z public vi rtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Start void Start GPUTracerImpl gputracer tensorflow UEAA AVStatus 3 XZ D workspac e tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper Subscribe struct CUpti Subscriber st void cdecl void enum CUpt i CallbackDomain unsigned int void const void Subscribe CuptiWrapper profiler gputo ols perftools QEAA AW4CUptiResult PEAPEAUCUpti Subscriber st P6AXPEAXW4CUpti CallbackDoma in IPEBX Z1 Z public virtual class tensorflow Status cdecl tensorflow g putracer GPUTracerImpl Start void Start GPUTracerImpl gputracer tensorflow UEAA AVSta tus 3 XZ D workspace tensorflow tensorflow contrib cmake build proto te xt vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools profi ler CuptiWrapper Unsubscribe struct CUpti Subscriber st Unsubscribe CuptiWrapper pro filer gputools perftools QEAA AW4CUptiResult PEAUCUpti Subscriber st Z pu blic virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Stop vo id Stop GPUTracerImpl gputracer tensorflow UEAA AVStatus 3 XZ D wo rkspace tensorflow tensorflow contrib cmake build proto text vcxproj D workspace tensorflow tensorflow contrib cmake build Release proto text exe fatal error LNK1120 11 D workspace tensorflow tensorflow contrib cmake build pro to text vcxproj D workspace tensorflow tensorflow contrib cmake build proto text vcxproj D workspace tensorflow tensorflow contrib cmake build tf core framework vcxproj D workspace tensorflow tensorflow contrib cmake build tf cc framework vcxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj 1 1 D workspace tensorflow tensorflow contrib cmake build tf cc ops vcxproj 37 D workspace tensorflow tensorflow contrib cmake build tf cc ops vcxproj 37 1 D workspace tensorflow tensorflow contrib cmake build create cc ops header dir vcxproj 47 InitializeBuildStatus AlwaysCreate x64 Release create cc ops header dir create c 0DE93F51 tlog unsuccessfulbuild FinalizeBuildStatus x64 Release create cc ops header dir create c 0DE93F51 tlog unsuccessfulbuild x64 Release create cc ops header dir create c 0DE93F51 tlog create cc ops header dir last buildstate touching D workspace tensorflow tensorflow contrib cmake build create cc ops header dir vcxproj D workspace tensorflow tensorflow contrib cmake build tf cc ops vcxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj 1 1 D workspace tensorflow tensorflow contrib cmake build tf stream executor vcxproj 107 InitializeBuildStatus AlwaysCreate tf stream executor dir Release tf strea A6006ACF tlog unsucc essfulbuild CustomBuild ClCompile Lib tf stream executor vcxproj D workspace tensorflow tensorflow contrib cmake build tf st ream executor dir Release tf stream executor lib FinalizeBuildStatus tf stream executor dir Release tf strea A6006ACF tlog unsuccessfulbuild tf stream executor dir Release tf strea A6006ACF tlog tf stream executor lastbuildstate touching D workspace tensorflow tensorflow contrib cmake build tf stream executor vcxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj D workspace tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj 1 D workspace tensorflow tensorflow contrib cmake build tf cc framework vcxproj 3 D workspace tensorflow tensorflow contrib cmake build tf core framework vcxproj 4 D workspace tensorflow tensorflow contrib cmake build proto text vcxproj 5 Link gpu tracer obj error LNK2019 public void cdecl tensorflow StepStatsCollector Save class std basic string char struct std char traits char class std allocator char con st class tensorflow NodeExecStats Save StepStatsCollector tensorflow QEAAXAEBV ba sic string DU char traits D std V allocator D 2 std PEAVNodeExecStats 2 Z public virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Co llect class tensorflow StepStatsCollector Collect GPUTracerImpl gputracer tensorflow AVStatus 3 PEAVStepStatsCollector 3 Z D workspace tensorflow ten sorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityDisable enum CUpti ActivityKind ActivityDisable CuptiWrappe r profiler gputools perftools QEAA AW4CUptiResult W4CUpti ActivityKind Z public class tensorflow Status cdecl tensorflow gputracer CUPTIManager DisableTrace v oid DisableTrace CUPTIManager gputracer tensorflow QEAA AVStatus 3 XZ D workspace tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityEnable enum CUpti ActivityKind ActivityEnable CuptiWrapper profiler gputools perftools QEAA AW4CUptiResult W4CUpti ActivityKind Z pu blic class tensorflow Status cdecl tensorflow gputracer CUPTIManager EnableTrace clas s tensorflow gputracer CUPTIClient EnableTrace CUPTIManager gputracer tensorflow QE AA AVStatus 3 PEAVCUPTIClient 23 Z D workspace tensorflow tensorflow c ontrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityFlushAll unsigned int ActivityFlushAll CuptiWrapper profile r gputools perftools QEAA AW4CUptiResult I Z public class tensorflow Stat us cdecl tensorflow gputracer CUPTIManager DisableTrace void DisableTrace CUPTIMana ger gputracer tensorflow QEAA AVStatus 3 XZ D workspace tensorflow ten sorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityGetNextRecord unsigned char unsigned int64 struct CUpti Act ivity ActivityGetNextRecord CuptiWrapper profiler gputools perftools QEAA AW4CUptiR esult PEAE KPEAPEAUCUpti Activity Z private void cdecl tensorflow gput racer CUPTIManager InternalBufferCompleted struct CUctx st unsigned int unsigned char unsigned int64 unsigned int64 InternalBufferCompleted CUPTIManager gputracer tensorf low AEAAXPEAUCUctx st IPEAE K2 Z D workspace tensorflow tensorflow co ntrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityGetNumDroppedRecords struct CUctx st unsigned int unsigned int64 ActivityGetNumDroppedRecords CuptiWrapper profiler gputools perftools QEAA AW4C UptiResult PEAUCUctx st IPEA K Z private void cdecl tensorflow gputrace r CUPTIManager InternalBufferCompleted struct CUctx st unsigned int unsigned char unsi gned int64 unsigned int64 InternalBufferCompleted CUPTIManager gputracer tensorflow IPEAE K2 Z D workspace tensorflow tensorflow contri b cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper ActivityRegisterCallbacks void cdecl unsigned char unsigned int64 unsigned int64 void cdecl struct CUctx st unsigned int unsigned char u nsigned int64 unsigned int64 ActivityRegisterCallbacks CuptiWrapper profiler gputoo ls perftools QEAA AW4CUptiResult P6AXPEAPEAEPEA K1 ZP6AXPEAUCUctx st IPEAE K5 Z Z public cdecl tensorflow gputracer CUPTIManager CUPTIManager void 0CUPTIMa nager gputracer tensorflow QEAA XZ D workspace tensorflow tensorflow c ontrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper GetTimestamp unsigned int64 GetTimestamp CuptiWrapper profiler gputools perftools QEAA AW4CUptiResult PEA K Z public virtual class tensor flow Status cdecl tensorflow gputracer GPUTracerImpl Start void Start GPUTracerImp l gputracer tensorflow UEAA AVStatus 3 XZ D workspace tensorflow tenso rflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper EnableCallback unsigned int struct CUpti Subscriber st enum CUpti Cal lbackDomain unsigned int EnableCallback CuptiWrapper profiler gputools perftools QEAA A W4CUptiResult IPEAUCUpti Subscriber st W4CUpti CallbackDomain I Z public virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Start void Start GPUTracerImpl gputracer tensorflow UEAA AVStatus 3 XZ D worksp ace tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper Subscribe struct CUpti Subscriber st void cdecl void enum CU pti CallbackDomain unsigned int void const void Subscribe CuptiWrapper profiler gpu tools perftools QEAA AW4CUptiResult PEAPEAUCUpti Subscriber st P6AXPEAXW4CUpti CallbackDo main IPEBX Z1 Z public virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Start void Start GPUTracerImpl gputracer tensorflow UEAA AVS tatus 3 XZ D workspace tensorflow tensorflow contrib cmake build proto text vcxproj gpu tracer obj error LNK2019 public enum CUptiResult cdecl perftools gputools pro filer CuptiWrapper Unsubscribe struct CUpti Subscriber st Unsubscribe CuptiWrapper p rofiler gputools perftools QEAA AW4CUptiResult PEAUCUpti Subscriber st Z public virtual class tensorflow Status cdecl tensorflow gputracer GPUTracerImpl Stop void Stop GPUTracerImpl gputracer tensorflow UEAA AVStatus 3 XZ D workspace tensorflow tensorflow contrib cmake build proto text vcxproj D workspace tensorflow tensorflow contrib cmake build Release proto text exe fatal erro r LNK1120 11 D workspace tensorflow tensorflow contrib cmake build p roto text vcxproj 0 12 00 00 06 72 D workspace tensorflow tensorflow contrib cmake build,,asimshankar,2017-07-21 01:50:29,2017-07-21 02:17:19
IS,Cross compile TensorFlow for armeabi v7a failed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 Python version 2 7 12 Bazel version if compiling from source 0 5 2 CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce bazel build c opt tensorflow core android tensorflow lib crosstool top external android crosstool cpu armeabi v7a host crosstool top bazel tools tools cpp toolchain You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I was able to cross compile TensorFlow to armeabi v7a using TensorFlow 1 0 But when I used the same command using TensorFlow 1 2 1 the compilation failed Please find the detailed error message in the Source code logs section The command I used is as follows bazel build c opt tensorflow core android tensorflow lib crosstool top external android crosstool cpu armeabi v7a host crosstool top bazel tools tools cpp toolchain Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem ERROR home yitao cache bazel bazel yitao c0c4f6e5ab173d18db201c4c55c4dc60 external protobuf BUILD 133 1 C compilation of rule ' protobuf protobuf' failed false failed error executing command bin false MD MF bazel out stub armeabi v7a opt bin external protobuf objs protobuf external protobuf src google protobuf stubs substitute pic d remaining 26 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 Target tensorflow core android tensorflow lib failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 42 154s Critical Path 6 27s,,andrewharp,2017-07-18 22:12:49,2017-07-21 04:02:03
IS,Unable to optimise the graph,I have frozen the tensorflow graph and I have noticed that the using the graph in realtime for prediction is too slow so I would like to do graph optimization Within my project file I have got a folder called model which contains the model file pb file Now I tried running the following command inside the model dir But it is firing the following error bazel build tensorflow python tools strip unused ERROR no such package 'tensorflow python tools' BUILD file not found on package path,,"shreyneil,shreyneil,shreyneil,shreyneil,shreyneil,shreyneil,shreyneil,asimshankar",2017-07-19 18:04:45,2017-07-21 05:15:41
PR,fix windows gpu build,introduced some issues for windows gpu builds because tools like proto text do not link with all gpu libraries needed for gpu tracer cc,,"guschmue,mrry,caisq,mrry,caisq,guschmue,gunan,guschmue,gunan,guschmue,guschmue",2017-07-20 16:54:30,2017-07-21 06:19:38
IS,Group Convolutions Support Request,Group convolutions recently become popular will this be supported in tf nn module,,shreyneil,2017-07-21 08:14:25,2017-07-21 13:35:17
IS,missing line of code in get started tutorial on website,as mentioned by an issue closed 19 days ago there is a line missing in the tutorial code at a custom model a custom model this earlier issue was closed but on the current version of the site that i see the issue still persists the missing line is eval input fn tf contrib learn io numpy input fn x x eval y eval 4 num epochs 1000 which should appear after input fn tf contrib learn io numpy input fn x x train y train 4 num epochs 1000 please note that these same lines appear in the code above the mentioned block in the basic usage section also i hope opening a new issue is the correct action in this case if i should have done something else please let me know,,"drpngx,shreyneil,MarkDaoust",2017-07-20 03:22:55,2017-07-21 14:05:43
PR,make tf read file support non ASCII characters in filename,fixes the bug in issue 8581 tf read file does not support non ASCII characters in filename,,mrry,2017-07-21 09:50:44,2017-07-21 14:06:24
IS,Using TF slim DatasetDataProvider generate batch data but get an error,System information OS Platform and Distribution e g Linux Ubuntu 16 04 macOS TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 5 0 In the StackOverflow OutOfRangeError I find similar problems but no one answered Please give me some advice Thanks,,,2017-07-14 04:47:52,2017-07-21 15:28:02
IS,1 3 0rc0 GPU Windows Binaries are broken,UPDATE This is most likely due to the new cuDNN requirement not being specified Users stumbling across this issue should check what cuDNN version they have installed as 1 3 binaries are built with cuDNN v6 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 64 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 0rc0 GPU Python version 3 6 CUDA cuDNN version 8 5 1 GPU model and memory k40 12gb Exact command to reproduce import tensorflow as tf Describe the problem Only tried GPU versions Despite what the release config matrix says here it appears that the binaries pip and from ci for 1 3 0rc0 do not work on windows Each time will return the pywrap DLL error etc Checked with check script and everything is ok Tried with python 3 5 and 3 6 1 2 1 works on both those python versions just fine I noticed that the 3 5 build for win gpu was failing but jenkins reckons 3 6 build is ok but i'm unable to replicate a successful install Note that I have been running tf gpu on this machine for a while now so not a dll problem etc Epecially as a mrry check script is ok and b 1 2 1 works just Source code logs insert pywrap DLL error here,,"gunan,av8ramit,av8ramit,mrry,mrry",2017-07-20 15:02:12,2017-07-21 16:46:10
IS,Gradients be dropped in tf train SyncReplicaOptimizer,Problem Description tf train SyncReplicaOptimizer is very helpful for backup workers but the gradients computed by slow workers are just dropped Below is the documentation I see Once the gradients have been computed push them into gradient queue only if local step equals global step otherwise the gradients are just dropped The problem is I want to use backup workers in online training it means every sample can be just consumed by TensorFlow once and I do not want some samples to be just ignored is it possible to make backup servers behave like the one in Hadoop which is guaranteed to utilize all data partitions Or can the workers know whether its gradient is dropped or not by the aggregator I think this feature will be useful,,"asimshankar,asimshankar",2017-07-21 05:47:38,2017-07-21 18:35:56
PR,Branch 162749134,,,jhseu,2017-07-21 17:13:52,2017-07-21 19:55:18
PR,XLA Fix plugin example buffer address for tuples,Currently the returned se DeviceMemoryBase buf size uses the incremented buf which may cause deallocation error Resubmit of 11595 after CLA fix,,jhseu,2017-07-19 23:13:20,2017-07-21 20:06:29
PR,Add comment to clarify semantics of opt level parameter,Note This is my first PR against this project Let me know if I have done anything wrong I should be on IBM is corporate CLA The meaning of the opt level parameter of OptimizerOptions was ambiguous leading a user to open which requests functionality that is actually already present but undocumented This PR documents the functionality,,"frreiss,jhseu",2017-07-19 13:30:09,2017-07-21 20:06:43
PR,Add logical or and less equal to tf op files txt,Add below ops implementations to the list tensorflow core kernels cwise op logical or cc tensorflow core kernels cwise op less equal cc When I am using the Android and iOS lib above ops are not registered while in full version they are available I think these are very basic ops and should add to the list by default,,"resec,petewarden",2017-07-20 03:57:30,2017-07-21 20:07:40
PR,Add interface for long int64 datatype,Added below methods for TensorFlowInferenceInterface They are very useful in case when we are handling int64 Tensor e g output of tf argmax I do not see the unit test file for TensorFlowInferenceInterface java so I did not add any test case for the change But this change is very straight forward Please let me know if I missed any Thanks,,"resec,andrewharp",2017-07-20 05:15:44,2017-07-21 20:08:22
PR,Update normalisation py,The self for mean and vaiance has to be added as we need to retain the mean value as it is,,"gautam1858,jhseu",2017-07-21 04:22:43,2017-07-21 20:19:40
IS,Issue while using AttentionWrapper,I am getting issue related to miss match of state and output But I am unable to figure the issue It would be really appreciated if someone can guide me Thanks in advance I am using tensorfow gpu 1 2 1 with 1080 Ti graphics Error is as below ValueError Shapes 8 522 and 8 512 are incompatible Error occurs in the file attention wrapper py in the method named call at line 708 cell output next cell state self cell cell inputs cell state I was able to figure out that it is adding the attention size to the shape and so there is a mismatch But I have no idea how to fix it The code is as below hyper parameters are declared as below test purpose batch size 8 number of units per layer 512 number of layers 3 attn size 10 def build decoder cell enc output enc state source sequence length attn size batch size encoder outputs enc output encoder last state enc state encoder inputs length source sequence length attention mechanism attention wrapper LuongAttention num units attn size memory encoder outputs memory sequence length encoder inputs length scale True name 'LuongAttention' Building decoder cell decoder cell list build single cell for i in range num layers decoder initial state encoder last state def attn decoder input fn inputs attention if not self attn input feeding return inputs Essential when use residual True input layer Dense size dtype tf float32 name 'attn input feeding' return input layer array ops concat inputs attention 1 AttentionWrapper wraps RNNCell with the attention mechanism Note We implement Attention mechanism only on the top decoder layer decoder cell list 1 attention wrapper AttentionWrapper cell decoder cell list 1 attention mechanism attention mechanism attention layer size attn size cell input fn attn decoder input fn initial cell state encoder last state 1 alignment history False name 'Attention Wrapper' To be compatible with AttentionWrapper the encoder last state of the top layer should be converted into the AttentionWrapperState form We can easily do this by calling AttentionWrapper zero state Also if beamsearch decoding is used the batch size argument in zero state should be decoder beam width times to the origianl batch size batch size self batch size if not self use beamsearch decode else self batch size self beam width initial state state for state in encoder last state initial state 1 decoder cell list 1 zero state batch size batch size dtype tf float32 decoder initial state tuple initial state return tf contrib rnn MultiRNNCell decoder cell list decoder initial state Thank you once again,,asimshankar,2017-07-18 16:06:41,2017-07-21 20:29:08
PR,Fix value error generated on is scalar check,is scalar shape is not None and not shape raises a value error when shape is a scalar ValueError The truth value of an array with more than one element is ambiguous Use a any or a all,,"jhseu,martinwicke,martinwicke,martinwicke,martinwicke,drpngx,drpngx,drpngx,frankchn,jhseu",2017-06-02 08:55:44,2017-07-21 20:29:29
IS,BUG When restore model from check point,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 win 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 10 Python version 3 52 Bazel version if compiling from source CUDA cuDNN version 8 0 5 1 GPU model and memory 2Gb Exact command to reproduce Describe the problem I trained my model in a GPU version tensorflow 1 10 but when I restore the model in another computer without GPU it throw the error at the fallow command result mnist classifier predict x feature batch size 1 as iterable False I had tested the whole project on the computer which trained the model so I think the code is right Source code logs Traceback most recent call last File D xieminzhao tf test main func main func py line 71 in module print rf cooper recog img test 2 had been tested File D xieminzhao tf test main func recognition func py line 37 in cooper recog return recogni is cooper is cooper image File D xieminzhao tf test main func recogni is cooper py line 110 in is cooper result mnist classifier predict x feature batch size 1 as iterable False AssertionError,,drpngx,2017-07-21 01:06:42,2017-07-22 02:00:54
PR,grappler swap to host bug fix,I have already solved the problem mentioned in the following issue This fix actually is trivial and could please take a look at it to see whether it is ready to be merged,,benoitsteiner,2017-07-05 03:21:52,2017-07-22 04:40:34
IS,Error when running imported restored model that uses feedable iterator tf contrib data,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below Build 242 Jul 17 2017 2 25 00 AM Python version Python 3 6 2 Bazel version if compiling from source na CUDA cuDNN version 8 0 6 0 GPU model and memory 670 gtx 2gb Exact command to reproduce na Describe the problem I can not restore and run checkpoints of models that use feedable iterators but I can restore and run checkpoints of models that directly use make one shot iterator Below is code for the feedable iterator version and below that code for the make one shot iterator version,,,2017-07-22 00:34:57,2017-07-22 06:39:04
IS,Missing numpy dependency at installation,I installed PyTorch on a fresh Python 3 6 installation brew install python3 got an error and found out that numpy was not installed I installed numpy and then things work Should not it be included among dependencies of the PyTorch package with the right version requirement see 559,,asimshankar,2017-07-22 10:56:29,2017-07-22 17:49:51
PR,Add new feature description for tfdbg to r1 3 release notes,,,caisq,2017-07-22 02:44:04,2017-07-22 18:15:54
PR,Add a note about tf contrib signal to the 1 3 release notes,Feel free to close if this is too late do not know if there will be an RC1,,rryan,2017-07-22 16:57:36,2017-07-22 18:16:18
IS,Windows 64 bit GPU Build Failing,The nightly windows 64 bit GPU build has been failing for over 3 days I could reproduce the error on different machines PY 36 245 consoleText Maybe the health monitor on the main site could include this build as well Otherwise breaking errors might not be noticed for some longer time,,"drpngx,gunan,guschmue,drpngx,gunan,drpngx",2017-07-20 11:05:02,2017-07-22 20:48:32
PR,Fix stackoverflow link to avoid redirect warning,Redirect warning is always shown to go to stackoverflow img width 1081 alt screen shot 2017 07 23 at 16 50 25 src,,Lewuathe,2017-07-23 07:55:36,2017-07-23 15:56:01
PR,Model file example in Tensorboard repository,graph run run2 pbtxt example was moved to tensorboard repository,,Lewuathe,2017-07-24 12:56:41,2017-07-24 14:04:50
PR,Fix typos,This PR fixes some typos partiton and executon,,"taehoonlee,jhseu",2017-07-20 00:32:44,2017-07-24 15:57:53
IS,run silent configure,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version intel python Bazel version if compiling from source 0 5 CUDA cuDNN version none GPU model and memory none Exact command to reproduce Describe the problem I am building a docker container compiling tensorflow from source would like to use MKL and need to run script silently alternatively Does someone have a Docker script that will compile tensorflow USING the MKL,,asimshankar,2017-07-24 10:02:03,2017-07-24 16:41:38
IS,how to use the trained model build in OOP schema to predict new samples,Hi there I write a OOP schema cnn model but there is some error when predict I know that if define Variable and write the code like c style in one file it is easy to restore the value but in OOP schema it is something wrong Here is my class Do you know how to load the Variable like OOP schema is there a demo projects Thanks,,asimshankar,2017-07-24 16:09:15,2017-07-24 16:41:58
IS,gather nd InvalidArgumentError,2017 07 24 10 35 25 247357 W tensorflow core framework op kernel cc 1152 Invalid argument flat indices 12287 127 42 does not index into param shape 32 512 100 1 Node conv maxpool 3 GatherNd GatherNd Tindices DT INT32 Tparams DT FLOAT device job localhost replica 0 task 0 cpu 0 ExpandDims conv maxpool 3 stack 2017 07 24 10 35 25 247422 W tensorflow core framework op kernel cc 1152 Invalid argument flat indices 12287 127 42 does not index into param shape 32 512 100 1 Node conv maxpool 3 GatherNd GatherNd Tindices DT INT32 Tparams DT FLOAT device job localhost replica 0 task 0 cpu 0 ExpandDims conv maxpool 3 stack Traceback most recent call last File usr local lib python3 6 site packages tensorflow python client session py line 1039 in do call return fn args File usr local lib python3 6 site packages tensorflow python client session py line 1021 in run fn status run metadata File usr local Cellar python3 3 6 1 Frameworks Python framework Versions 3 6 lib python3 6 contextlib py line 89 in exit next self gen File usr local lib python3 6 site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl InvalidArgumentError flat indices 12287 127 42 does not index into param shape 32 512 100 1 Node conv maxpool 3 GatherNd GatherNd Tindices DT INT32 Tparams DT FLOAT device job localhost replica 0 task 0 cpu 0 ExpandDims conv maxpool 3 stack During handling of the above exception another exception occurred Traceback most recent call last File mix py line 66 in module autoen nn clf train epoch x train y train batch size dropout rate 0 5 File Users MilesZhao Desktop ORNL data epath data yong cnn py line 248 in clf train epoch feed dict feed dict File usr local lib python3 6 site packages tensorflow python client session py line 778 in run run metadata ptr File usr local lib python3 6 site packages tensorflow python client session py line 982 in run feed dict string options run metadata File usr local lib python3 6 site packages tensorflow python client session py line 1032 in do run target list options run metadata File usr local lib python3 6 site packages tensorflow python client session py line 1052 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError flat indices 12287 127 42 does not index into param shape 32 512 100 1 Node conv maxpool 3 GatherNd GatherNd Tindices DT INT32 Tparams DT FLOAT device job localhost replica 0 task 0 cpu 0 ExpandDims conv maxpool 3 stack Caused by op 'conv maxpool 3 GatherNd' defined at File mix py line 64 in module num classes File Users MilesZhao Desktop ORNL data epath data yong cnn py line 125 in init filter size File Users MilesZhao Desktop ORNL data epath data yong cnn py line 217 in conv layer local in doc mat tf gather nd in doc mat temp File usr local lib python3 6 site packages tensorflow python ops gen array ops py line 1321 in gather nd name name File usr local lib python3 6 site packages tensorflow python framework op def library py line 768 in apply op op def op def File usr local lib python3 6 site packages tensorflow python framework ops py line 2336 in create op original op self default original op op def op def File usr local lib python3 6 site packages tensorflow python framework ops py line 1228 in init self traceback extract stack InvalidArgumentError see above for traceback flat indices 12287 127 42 does not index into param shape 32 512 100 1 Node conv maxpool 3 GatherNd GatherNd Tindices DT INT32 Tparams DT FLOAT device job localhost replica 0 task 0 cpu 0 ExpandDims conv maxpool 3 stack,,asimshankar,2017-07-24 14:42:54,2017-07-24 16:42:23
IS,nn,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-07-24 09:38:04,2017-07-24 16:42:45
IS,tf import graph def load quantized graph error,root A01 R04 I221 14 export dir python predict py Traceback most recent call last File predict py line 70 in module load graph 'quantized graph pb' File predict py line 33 in load graph tf import graph def graph def File usr lib python2 7 site packages tensorflow python framework importer py line 365 in import graph def input name ValueError graph def is invalid at node u'while add 6 y' More inputs specified 'while Switch 1' than the op expects,,asimshankar,2017-07-24 01:55:29,2017-07-24 16:43:50
PR,Fix for invalid Darkflow command,The command flow model cfg tiny yolo voc cfg load bin tiny yolo voc weights savepb verbalise True is not a valid Darkflow command and will result in the following error Changing the command to flow model cfg tiny yolo voc cfg load bin tiny yolo voc weights savepb verbalise will fix the issue,,,2017-07-24 10:34:23,2017-07-24 17:50:21
PR,Fix missing spaces for several errors,,,"taehoonlee,caisq",2017-07-24 06:12:14,2017-07-24 17:53:26
IS,syntaxnet Global training is worse than greedy trainning when the training data size is 1 millon data,As you can see the following is my experimental configuration parameters and experiment results I would like to know on a fairly large amount of data how to adjust the super parameters can get a result that global better than greedy when the trainning data size is 20 000 We got the global trainning better than greedy trainning using default configuration parameters But when the training data increased to 1 million We can not reproduce the results This is our experimental result image This is our experimental configuration greedy trainging parameters image global trainging parameters image I guess that is the parameter setting problem Anyone who has experience can help me with this problem Thanks,,asimshankar,2017-07-24 02:26:08,2017-07-24 18:31:30
PR,add metric op,This pull request is aimed to create a metric op for TF Slim learning to be able to show the streaming metrics accuracy for the training phase The op reset the total and count local variables defined by streaming metric if it is streaming accuracy per each epoch of training so the accumulative accuracy per epoch can be represented,,"sguada,sguada,drpngx,vrv",2017-06-02 17:05:16,2017-07-24 18:46:20
PR,Branch 162842890,,,"caisq,caisq,caisq,caisq,caisq",2017-07-24 01:43:45,2017-07-24 18:56:08
IS,Different behavior tf contrib data Dataset unbatch TF ver 1 2 1 and ver 1 3 0 rc0,Code for reproduce problem,,"mrry,ebrevdo",2017-07-21 12:23:54,2017-07-24 18:56:29
PR,Refactor and implementation of the camera API 1 it fixes 8736,As detailed in 8736 the legacy devices should work with the Camera API 1 the detector demo would need even more refactor in order to work,,"andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,drpngx,drpngx,andrewharp,andrewharp,andrewharp,andrewharp,yifeif,yifeif,drpngx,andrewharp,drpngx,drpngx,andrewharp,jhseu,andrewharp",2017-06-16 17:38:13,2017-07-24 19:05:03
PR,Update DetectorActivity java,darkflow parameter fix,,"drpngx,frankchn,vrv",2017-06-23 08:33:54,2017-07-24 20:01:17
PR,11055 test to reproduce Keras load model raises ValueError when loading optimizer weights,,,"drpngx,fchollet,fchollet,vrv",2017-06-26 03:20:21,2017-07-24 20:02:24
PR,Enable building label image with jpeg gif png decoder for Android,This PR adds the Android platform building of the jpeg gif and png decoder to the C image classification demo label image It enables the evaluation of practical dataset such as ImageNet on Android platform devices for both model precision and hardware performance,,frankchn,2017-07-12 10:42:04,2017-07-24 21:46:29
IS,Does orthogonal initialization have GPU implementation fails when explicitly assigned on a gpu,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 3 4 3 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory Tesla P100 16 gb Describe the problem I get an error when trying to use orthogonal initialization which is explicitly assigned to be run on GPU Looking at the log it looks like some parts of it e g QR decomposition are available on CPU only Is this the case or is there some bug that is blocking it from being run on GPU only Source code logs The following code could be used to reproduce the issue,,reedwm,2017-07-21 22:41:05,2017-07-24 22:19:32
IS,retrain inception v3 error,,,reedwm,2017-07-23 07:48:19,2017-07-24 22:24:49
PR,Update monitors py,Renaming PrintTensor to Logging Tensor,,"alanyee,jhseu,alanyee,jhseu,terrytangyuan,jhseu",2017-07-21 18:55:56,2017-07-24 22:27:08
PR,replace supervised session to monitored session,The author should forget to modify doc for MonitoredSession is closed when refactoring supervisor to monitored session,,"horance-liu,vrv,vrv",2017-07-19 13:00:21,2017-07-24 22:27:26
PR,OpenCL DenseUpdate sync,Fixes undefined symbol for tensorflow functor DenseUpdate Eigen SyclDevice linking error,,"lukeiwanski,gunan",2017-07-20 11:53:57,2017-07-24 22:30:00
PR,Fix build doc README,README for generating documentation includes outdated information src dir must be absolute path docs src was moved to tensorflow docs src,,Lewuathe,2017-07-20 13:39:26,2017-07-24 22:30:40
IS,error in tensorflow tutorial,In tensorflow tutorial at under 'A custom model' section it is missing an assignment for eval input fn as eval input fn tf contrib learn io numpy input fn x x eval y eval 4 num epochs 1000,,alanyee,2017-07-24 07:59:38,2017-07-24 22:32:27
PR,added link to benchmarks in community page,,,jhseu,2017-07-20 17:09:35,2017-07-24 22:34:43
IS,Feature Request Update tf image sample distorted bounding box to use Scalar Tensor Inputs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 Bazel version if compiling from source CUDA cuDNN version 8 0 5 1 GPU model and memory Titan X Exact command to reproduce Can you please update the scalar inputs to tf image sample distorted bounding box to also be accepted as Tensors I am dynamically creating min object covered values random values but currently can not input them to the function,,"aselle,yongtang",2017-06-14 23:36:28,2017-07-24 22:38:59
PR,Update sample distorted bounding box to use v2 kernel,This fix is a follow up of 10840 so that sample distorted bounding box uses v2 kernel to follow the API compatibility workflow 3 weeks This fix updates related tests so that redudant tests could be removed This fix fixes 10715 Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv",2017-07-21 17:04:35,2017-07-24 22:38:59
PR,Update fft2d cmake,The cmake fft2d library was installing to ' fft2d INSTALL ' instead of the appropriate variable set by CMake I suspect this was unintentional Changing the parentheses to curly brackets fixes this,,jhseu,2017-07-21 18:08:15,2017-07-24 22:39:16
PR,Add as default to MonitoredSession MonitoredTrainingSession and SingularMonitoredSession,Equivalent to tf Session as default allows refetching the session from elsewhere in code using tf get default session Notes additive public API change If there is a better way to get the current session when using these tf Session wrappers this may be unnecessary I just could not find it,,"darrengarvey,darrengarvey,vrv",2017-07-23 15:26:16,2017-07-24 22:43:33
IS,Can anybody please let me know an error free code of basic CNN tensorflow code I am having hard time to resolve tensorflow coding working even the tensorflow tutorial code from tensorflow org,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2017-07-23 07:41:19,2017-07-24 22:53:34
PR,Add mark flag as required functions to make the APIs compatible with,Add mark flag as required functions to make the APIs compatible with python gflags 11195,,"nolanliou,vrv,vrv,vrv,yilei,nolanliou,vrv,yilei,nolanliou,nolanliou,vrv,vrv,nolanliou,nolanliou,vrv,vrv,nolanliou,vrv,nolanliou,yilei,nolanliou,nolanliou,vrv,asimshankar",2017-07-18 08:05:12,2017-07-24 22:53:51
PR,Sort out confusion around usage of selective registration,config android arm is defined in tensorflow BUILD where it resolved to crosstool top external android crosstool cpu armeabi v7a seems like this cannot be referenced here,,"Androbin,Androbin,Androbin,petewarden,drpngx,Androbin,Androbin,Androbin,vrv,Androbin,Androbin,vrv,andrewharp,Androbin",2017-06-08 22:15:59,2017-07-24 22:54:17
PR,Update wide n deep tutorial py,mkdtemp is low level and creates a temporary file somewhere out of sight that requires users to delete the file themselves For the use case of a tutorial it is best to use a method that cleanups the file when finished TemporaryFile does such as described above but not available in Python 2,,"alanyee,vrv",2017-07-24 18:09:44,2017-07-25 00:11:26
IS,tf one hot indices out of bound,Hi I have ran into some nasty indexing bugs which were not caught by TF I investigated and found the following behaviour Both overflow and underflow result in a zeroed array Should this be caught and errors be thrown If not why and when would this zeroed behaviour make sense Or is it costly to check and throw assertions,,reedwm,2017-07-25 00:09:14,2017-07-25 00:25:03
IS,slice input producer bug slows down exponentially for larger datasets,My input pipeline involves sampling a filename and label with slice input producer then data augmentation then batching with tf train shuffle batch For smaller datasets 1M this works fine For larger datasets slice input producer slows down even though all it is doing is sampling from two lists It is bad enough that it is several orders of magnitude slower than all the rest of my input pipeline and training combined I wrote a quick test to measure the time per call to slice input producer for different lengths of input lists Which gives Datalength 1000 time 0 172 ms sample Datalength 1000000 time 0 207 ms sample Datalength 10000000 time 0 537 ms sample Datalength 100000000 time 13 991 ms sample python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 2 0 0 g12f033d' '1 2 0',,"drpngx,mrry,mrry,reedwm",2017-07-18 21:54:02,2017-07-25 00:43:09
PR,Branch 163011166,,,vrv,2017-07-25 00:18:58,2017-07-25 01:22:31
IS,error in installation instructions,In instructions specified at ValidateYourInstallation it states For example the following command installs the CPU only version of TensorFlow for Python 2 7 tensorflow pip install ignore installed upgrade However it is for Python 3 4 not 2 7,,asimshankar,2017-07-24 08:02:08,2017-07-25 01:22:48
IS,Not found Key variable name not found in checkpoint even though it exists in meta graph,System information Python version 3 6 Tensorflow version 1 1 Here are the commands needed to reproduce the error,,reedwm,2017-07-19 01:53:00,2017-07-25 01:29:18
IS,solved Reducing the binary size,Hi all i am now succeed in using a cross compiled lib project call tensorflow now i got tensorflow run on ios android and linux using one same app code any one has any questions can ask me for help so my question now is turned to Reducing the binary size many posts told that to config tf op files txt but my questions are 1 need we also config other files such as tf pb text files txt proto text cc files txt for reducing 2 is there any other thinking for reducing than configuring the txt files Exhaustive Attackly,,"drpngx,andrewharp,reedwm",2017-07-19 12:48:24,2017-07-25 01:58:27
IS,when i train a GAN model AdamOptimizer get ValueError,with tf variable scope tf get variable scope reuse None d optim tf train AdamOptimizer learning rate learning rate beta1 0 5 minimize d loss var list d vars global step global step g optim tf train AdamOptimizer learning rate learning rate beta1 0 5 minimize g loss var list g vars global step global step i set reuse None but it still has ValueError Variable d bn2 beta Adam does not exist or was not created with tf get variable Did you mean to set reuse None in VarScope i even tried set it to False but it still has the error is that a bug in version r1 2,,"drpngx,reedwm",2017-07-20 09:30:25,2017-07-25 02:02:36
IS,Error Building from source with ARM processor gif io png io errors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I'm following this guide for installing tensorflow on a raspberry pi because it most closely resembles the environment that I am building on I noticed that there were a couple of things that had changed since those instructions were written so if things had changed in the code when I checked them I did not follow those instructions for changing the code I do not think the error is because of these instructions which is why I am posting here instead of there OS Platform and Distribution e g Linux Ubuntu 16 04 I am building in a Debian Jessie environment that I have built exclusively for the purposes of building tensorflow on ARM with the latest versions of gcc g that I could find TensorFlow installed from source or binary Source TensorFlow version use command below I'm assuming the most recent because I just cloned it yesterday The script errors because tf has not actually made it to the installation step cat etc issue Linux 3 14 38 yocto 00005 ge466b18 1 SMP PREEMPT Tue May 30 10 41 58 MDT 2017 armv7l GNU Linux VERSION ID 8 VERSION 8 jessie compiler c Debian 4 8 4 1 4 8 4 gcc version 4 8 4 Debian 4 8 4 1 Copyright C 2013 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux 3 14 38 yocto 00005 ge466b18 1 SMP PREEMPT Tue May 30 10 41 58 MDT 2017 armv7l GNU Linux check pips numpy 1 8 2 Python version Python 2 7 9 Bazel version if compiling from source Build label 0 4 5 non git CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build c opt tensorflow tools pip package build pip package Though I have also gotten errors with,,"drpngx,reedwm",2017-07-19 17:58:04,2017-07-25 02:05:53
PR,Bump the required protobuf version for the pip package,Forgot to do this as part of Related b 62969990,,"jhseu,vrv",2017-07-25 00:10:24,2017-07-25 03:20:08
PR,pass O options when generating dependency,In the current implementation when generating the dependency in L126 L216 the optimization option is not passed to nvcc which makes nvcc to generate a lot of warnings that looks like This PR clear these warnings by passing optimization option when generating dependency The following issues are fixed by this PR,,"zasdfgbnm,frankchn,vrv,zasdfgbnm,vrv,zasdfgbnm",2017-06-23 01:02:02,2017-07-25 04:50:19
PR,Add a function for generating random values with predefined seed,I added a seeded random function as it was requested in this PR issuecomment 315590857 Please use seeded rands to make the tests deterministic and easier to debug,,"vrv,drpngx,drpngx,vrv,drpngx,vrv,vrv",2017-07-20 07:06:04,2017-07-25 04:50:41
PR,fix issues serving 421 Symbol not found ZN6google8protobuf8internal10LogMessageC1ENS0 8LogLevelEPKci,fix issues serving 421 the problem reason is google protobuf internal LogMessage LogMessage,,"vrv,vrv,vrv,vrv,vrv",2017-07-24 07:34:14,2017-07-25 04:51:55
PR,update WORKSPACE uncommented line range to L19 L36,,,,2017-07-25 03:46:41,2017-07-25 05:17:16
PR,Update losses implementation,Various replacements of deprecated functions with equivalent tf losses Minor HTTPS calls,,"alanyee,vrv,vrv,alanyee,vrv,vrv,alanyee,vrv",2017-07-21 16:21:45,2017-07-25 05:46:39
IS,Using VSCode to import tensorflow failed,I have installed tensorflow on Windows 10 successfully But I can only run tensorflow under terminal command What I want to do is to write python script on VSCode It turns out some configuration may be done for VSCode So Is there anyone who can solve this Thanks a lot,,,2017-07-25 07:23:07,2017-07-25 07:27:33
IS,ImportError cannot import name contrib,How to downgrade tensorflow to 1 0 0,,,2017-07-25 10:02:02,2017-07-25 10:10:25
IS,Using AOT compilation on network with bidirectionnal layer fails because of missing Exit on Switch node,I have been reproducing that for a while ranging from 1 0 1 builds to current master Running tfcompile fails like this This indeed worked and I have been able to build even cross build for ARM RPi3 a RNN based network using BasicRNN cells or BasicLSTM cells So I guess that the questions is really am I just lucky that it works because one Switch MUST really have an Exit node and thus is there something wrong in the current model or is it just being picky,,carlthome,2017-07-25 10:41:18,2017-07-25 10:47:40
IS,ctc,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-07-25 11:43:59,2017-07-25 11:46:56
PR,typo in the beginning comment,There is typo r before the beginning comment,,caisq,2017-07-25 12:10:46,2017-07-25 14:02:04
PR,Fix web link to tool developers guide,Fix web link in README md by changing it from to,,resec,2017-07-25 08:15:35,2017-07-25 14:02:54
PR,Disable failing tests in Windows Bazel build,Fix,,"meteorcloudy,vrv,meteorcloudy",2017-07-24 08:39:46,2017-07-25 14:56:48
PR,add aarch64,,,,2017-07-25 15:07:56,2017-07-25 15:11:40
IS,Different GPU memory not all allocated,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version cuda8 0 cudnn5 5 GPU model and memory GTX Titan 6GB GTX 1080Ti 11GB Describe the problem Note that tensorflow will allocate tensor op to all available gpus but i only got 1080Ti occupied I wonder if it is a bug or tensorflow does not support different gpu models,,"reedwm,reedwm",2017-07-22 08:59:52,2017-07-25 16:40:10
PR,Cherry pick GradientsDebugger from master to r1 3 with fixes to GPU build issues,,,"caisq,gunan,caisq",2017-07-25 02:20:47,2017-07-25 16:51:33
PR,R0 10,I need it for test,,vrv,2017-07-25 15:44:13,2017-07-25 17:05:43
PR,Fix wrong template type name in QuantizedAddUsingEigen,input type is T1 and smaller input type is T2,,vrv,2017-07-25 01:59:08,2017-07-25 17:14:21
PR,Exposed more graph io methods,I think these should probably be exposed since some of these are being used in examples such as parsing utilities here L86,,"terrytangyuan,alextp,vrv",2017-07-23 21:40:22,2017-07-25 17:21:53
PR,Backport get started md to 1 2 0,,,"aselle,aselle",2017-07-06 18:48:18,2017-07-25 17:32:36
IS,how to assign a tensor to a sub part of another tensor,Hi dear all I am new to tensorflow Previously I use theano Now I want to assign a tensor to a sub part of another tensor e g a 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 b 1 3 4 5 I would assign to a 0 like this a 1 0 0 0 3 0 0 0 4 0 0 0 5 0 0 0 in theano we use set subtensor what should I do with tensorflow Thank you very much,,reedwm,2017-07-25 17:35:12,2017-07-25 17:47:11
PR,Minor updates in MD files,Made explicit HTTPS calls Minor edits,,"alanyee,vrv,vrv,alanyee,alanyee,vrv",2017-07-25 16:34:54,2017-07-25 17:58:33
IS,syntaxnet parser eval graph builder greedy Assign requires shapes of both tensors to match lhs shape 32 69 rhs shape 400 69,Error image I use GPU to train when greedy training I can train model and parser eval with graph builder structured successful but parser eval with graph builder greedy failed here is my configuration bazel bin syntaxnet parser trainer arg prefix brain parser batch size 400 compute lexicon decay steps 4400 graph builder greedy hidden layer sizes 1024 1024 learning rate 0 08 momentum 0 9 seed 4 output path TMP DIR task context TMP DIR context training corpus training corpus tuning corpus tuning corpus params PARAMS num epochs 25 report every 1000 checkpoint every 10000 logtostderr bazel bin syntaxnet parser eval task context TMP DIR brain parser greedy PARAMS context hidden layer sizes 1024 1024 input dev corpus output stdout arg prefix brain parser graph builder greedy model path TMP DIR brain parser greedy PARAMS model logtostderr TMP DIR greedy out bazel bin syntaxnet parser eval task context TMP DIR context hidden layer sizes 1024 1024 beam size 1 input dev corpus output stdout arg prefix brain parser graph builder structured model path TMP DIR brain parser greedy PARAMS model logtostderr TMP DIR struct beam1 out,,reedwm,2017-07-25 06:52:10,2017-07-25 18:18:42
PR,Format 1 3 0 release notes added a new feature to tfdbg section,,,caisq,2017-07-25 19:03:01,2017-07-25 20:13:38
IS,can not understand tf contrib training bucket by sequence length,what I intended was batch size 4 for those input length are smaller than 4 batch size 2 for those input length is bigger or the same as 4 because the bucket boundaries 4 There was a similar post before 5609 but I still think that there lacks a proper example for it which point do i misunderstand about,,"alanyee,aselle",2017-07-25 10:35:23,2017-07-25 20:31:13
PR,Minor corrections to tensordot documentation,edit was trying to merge against wrong branch Will open another PR Changed some math indices formating and the format of the axes argument for Example 3,,,2017-07-25 21:57:47,2017-07-25 22:14:56
PR,Cherrypicks,,,"av8ramit,av8ramit,av8ramit",2017-07-25 20:12:04,2017-07-25 22:56:30
IS,several Session Models in one file,so I am using CNN for fave detection and also I have CNN for age classification but it seems two network does not work together my code is,,asimshankar,2017-07-25 08:04:33,2017-07-26 01:27:42
PR,Branch 163121296,,,"vrv,suiyuan2009,vrv,vrv",2017-07-25 23:37:09,2017-07-26 01:41:41
IS,Issue for tensorboard logdir save,System information tensorboard logdir save this command occurred some issue OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X with AMD TensorFlow installed from source or binary pip3 6 TensorFlow version use command below The latest version Python version 3 6 Memory 16G python c import tensorflow as tf print tf GIT VERSION tf VERSION v1 2 0 5 g435cdfc 1 2 1,,reedwm,2017-07-26 01:24:22,2017-07-26 02:00:38
IS,Feature request Instance Normalization,Instance Normalization is recently widely used in style transfer and GAN since it avoid the drawback of batch normalization which brings in batch correlations Tensorflow only has quantized version instance norm right now but a full version is also easy to implement I am interested in it Also I wonder if it is better to implemented in C using eigen or simply add some lines in nn impls py with the benefit of being able to use fused batch norm Mxnet does the first way while Pytorch use the latter method,,aselle,2017-07-23 12:24:01,2017-07-26 03:24:06
PR,Minor corrections to tensordot documentation,Changed some math indices formating and the format of the axes argument for Example 3,,,2017-07-25 22:19:43,2017-07-26 03:34:56
PR,Add less equal and logical or to android core ops,Added below two ops to android core ops as similar to 11631 tensorflow core kernels cwise op logical or cc tensorflow core kernels cwise op less equal cc I think these are very basic ops and should add to the list by default,,"resec,vrv",2017-07-25 07:41:20,2017-07-26 04:26:39
PR,Implemented selu activation 10612,This pull request implements the SELU activation function The activation function works properly when training a simple MLP for digit recognition But the following test fails tensorflow python kernel tests relu op test This happens due to large error when checking the gradient of gradient The log is show below Any help in resolving this issue is appreciated,,"lakshayg,lakshayg,lakshayg,drpngx,lakshayg,lakshayg,lakshayg,AnishShah,lakshayg,AnishShah,yifeif,drpngx,drpngx,lakshayg,drpngx,lakshayg,lakshayg,josh11b,drpngx,lakshayg,drpngx,lakshayg,drpngx,josh11b,gunan,vrv,lakshayg,drpngx,lakshayg,gunan,gunan,lakshayg,thesuperzapper,lakshayg,thesuperzapper",2017-06-19 09:45:26,2017-07-26 04:48:02
PR,Fix quantization tutorial,Fix this tutorial on quantization 1 Remove outdated dependencies as pointed out in 10463 1 The change made in 10592 was incomplete The example how can you quantize your models on how to run transform graph to quantize a graph should follow this tutorial eight bit calculations about graph transforms but the argument inputs 'Mul' is missing I'm also wondering when how will the tutorial on tensorflow org get updated I'm assuming it should be the same as quantization md that I'm fixing Related to 11181 Thanks,,"drpngx,vrv",2017-07-05 03:40:05,2017-07-26 05:01:59
IS,Docker Restoring from a model outside the container returns FailedPreconditionError,System information OS Platform and Distribution Docker Tensorflow CPU Image TensorFlow version use command below 1 2 1 Python version Python 2 7 12 Source code logs,,"caisq,aselle",2017-07-25 09:02:20,2017-07-26 06:54:59
IS,BUILD Failed missing input file ' mkl LICENSE',System information OS Platform and Distribution e g Linux Ubuntu 16 04 Centos 7 TensorFlow installed from source or binary source TensorFlow version use command below latest Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel build config mkl c opt tensorflow tools pip package build pip package I was trying to build Tensorflow and hitting this error missing input file ' mkl LICENSE' i did it a week back no problem faced everything worked fine with same command line,,"gunan,gunan,agramesh1,gunan,agramesh1",2017-07-21 23:19:43,2017-07-26 11:09:19
PR,Fix GradientDescentOptimizer argument,Both the text line 370 and python code example example code L59 uses 0 5 Using 0 05 keeps success percentage around 90 instead of the mentioned 92,,,2017-07-26 11:13:55,2017-07-26 11:31:55
PR,Definitions about between the workspace bzl and grpc,grpc expects external protobuf clib and external protobuf compiler to point to the protobuf is compiler library Definitions about between the workspace bzl and grpc,,"jhseu,jart,jart,snnn",2017-07-21 06:47:12,2017-07-26 15:32:04
PR,Add Raspberry PI build,Does what it says on the box follow instructions in third party toolchains cpus arm build raspberry pi sh,,"ebrevdo,petewarden,ebrevdo,petewarden,ebrevdo,petewarden,gunan,gunan,gunan,gunan,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,petewarden,samjabrahams,ebrevdo,ebrevdo,petewarden,gunan,ebrevdo,petewarden,vrv,petewarden,samjabrahams,ebrevdo,petewarden,ebrevdo,petewarden",2017-07-21 22:09:02,2017-07-26 16:39:41
IS,Unexpected behavior in tf scatter update,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 3 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Python version 2 7 10 Bazel version if compiling from source CUDA cuDNN version CPU GPU model and memory CPU Exact command to reproduce Describe the problem I am trying to update mask at indices sampled by dist and I need past updates to persist as I add more updates to mask That is I would expect the second call to be 1 1 3 5 1 5 5 1 1 1 Since tf scatter update mutates mask I would expect the updates to persist but it seems like the the updates are made anew every time I call mask eval Furthermore perhaps I'm missing something but the output of the second call is further unexpected in the sense that I see three 3 is in mask even when I never assigned three 3 is to mask only two Is there an explanation for this If this is not a bug then could we add a feature to allow for consistent and persistent updates Source code logs Please see above,,reedwm,2017-07-26 14:52:28,2017-07-26 17:38:51
IS,run errors,Hi when I run python for tensorflow my python file show errors and can not run success errors likes 017 07 26 19 57 14 274316 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 07 26 19 57 14 372830 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 07 26 19 57 14 372864 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations home ah0818lijhong CNN kereas cnn kereas py 155 UserWarning The Merge layer is deprecated and will be removed after 08 2017 Use instead layers from keras layers merge e g add concatenate etc merged Merge model left model right model 3 mode 'concat' Epoch 1 3 Traceback most recent call last File home ah0818lijhong CNN kereas cnn kereas py line 167 in module model fit x train y train epochs 3 File home ah0818lijhong anaconda2 lib python2 7 site packages keras models py line 845 in fit initial epoch initial epoch File home ah0818lijhong anaconda2 lib python2 7 site packages keras engine training py line 1485 in fit initial epoch initial epoch File home ah0818lijhong anaconda2 lib python2 7 site packages keras engine training py line 1140 in fit loop outs f ins batch File home ah0818lijhong anaconda2 lib python2 7 site packages keras backend tensorflow backend py line 2073 in call feed dict feed dict File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python client session py line 778 in run File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python client session py line 778 in run run metadata ptr File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python client session py line 982 in run feed dict string options run metadata File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python client session py line 1032 in do run target list options run metadata File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python client session py line 1052 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError indices 0 868 115873 is not in 0 20001 Node embedding 1 Gather Gather Tindices DT INT32 Tparams DT FLOAT validate indices true device job localhost replica 0 task 0 cpu 0 embedding 1 embeddi ngs read recv embedding 1 input 0 Caused by op u'embedding 1 Gather' defined at File home ah0818lijhong CNN kereas cnn kereas py line 122 in module model left add embedding layer File home ah0818lijhong anaconda2 lib python2 7 site packages keras models py line 422 in add layer x File home ah0818lijhong anaconda2 lib python2 7 site packages keras engine topology py line 554 in call output self call inputs kwargs File home ah0818lijhong anaconda2 lib python2 7 site packages keras layers embeddings py line 119 in call out K gather self embeddings inputs File home ah0818lijhong anaconda2 lib python2 7 site packages keras backend tensorflow backend py line 966 in gather return tf gather reference indices File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python ops gen array ops py line 1207 in gather validate indices validate indices name name File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python framework op def library py line 768 in apply op op def op def File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python framework ops py line 2336 in create op original op self default original op op def op def File home ah0818lijhong anaconda2 lib python2 7 site packages tensorflow python framework ops py line 1228 in init self traceback extract stack InvalidArgumentError see above for traceback indices 0 868 115873 is not in 0 20001 Node embedding 1 Gather Gather Tindices DT INT32 Tparams DT FLOAT validate indices true device job localhost replica 0 task 0 cpu 0 embedding 1 embeddi ngs read recv embedding 1 input 0 I hope someone can fix it thank you,,reedwm,2017-07-26 12:09:36,2017-07-26 17:42:33
PR,Enable Android lib bazel build for mips and mips64,Currently the Android so lib bazel build is failing for cpu mips and cpu mips64 This PR is fixing this The changes are Add latomic linkopt for cpu mips this is to avoid failing at the end for undefined reference to ' atomic ' alike errors Remove Os optimization flag for cpu mips and cpu mips64 this is to avoid failing in compiling tensorflow core lib core threadpool o for failure memory model cannot be stronger than success memory model for ' atomic compare exchange' errors Added some hints in tensorflow workspace bzl for API level selection when compiling 64 bit lib By checking online seems there is a bug in gcc compiler at least the gcc inside NDK r12b I did try using newer NDK version however since r13b the default compiler is changed to clang and bazel is only working with clang with NDK r13b or higher as well as currently compiling Tensorflow with clang is failing for some strange errors to me so it did not work that in some cases Os flag would crash the compiling Removing Os for cpu mips and cpu mips64 is only a sub optimal solution as the generated so lib will be relatively bigger but not much,,"resec,vrv",2017-07-26 06:54:58,2017-07-26 17:51:18
IS,tf control dependencies does not work with variable initializer for read value,Consider this code TensorFlow v1 2 0 rc2 21 g12f033d 1 2 0 installed via pip on Ubuntu 16 04 Linux It only seems to happen with GPU I think on TF 1 1 and earlier this worked although maybe for some reason the probability to fail was much lower there and I did not notice it,,"alextp,alextp,alextp",2017-07-03 09:08:06,2017-07-26 18:02:18
IS,tf nn sparse softmax cross entropy with logits raise Segmentation fault,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow code from tensorflow nmt OS Platform and Distribution centos 7 TensorFlow installed from pip install TensorFlow version 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 5 Bazel version if compiling from source CUDA cuDNN version without gpu GPU model and memory None Exact command to reproduce You can collect some of this information using our environment capture script Describe the problem As the code pointed tf nn sparse softmax cross entropy with logits seems supporting less size tensor than tf nn softmax cross entropy with logits At least do shape check rather than Segmenation fault error Source code logs,,"reedwm,reedwm,reedwm",2017-07-24 19:30:39,2017-07-26 19:15:42
IS,Check failed sss idx Get key value Failed to seek to the record for tensor,hi I am so appreciated with your great job here is my question when i finetune the resnet v1 50 with pretrained model I have exclude the logists layer when comes to the code isaver restore sess checkpoint path ' it gives me the error like this image can you help me,,aselle,2017-07-26 11:39:15,2017-07-26 19:59:34
PR,Branch 163213141,repushing will not squash commits,,vrv,2017-07-26 17:34:31,2017-07-26 20:09:00
IS,404 for mac GPU,Installation section in readme for Mac GPU 404 error TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label gpu mac lastSuccessfulBuild artifact pip test whl tensorflow gpu 1 3 0rc0 py2 none any whl,,"reedwm,reedwm,av8ramit",2017-07-25 19:28:50,2017-07-26 20:44:31
IS,app crashed on android device of api level 19 when load library libtensorflow inference so,System information Os version 4 4 4 sdk level 19 logcat 07 26 15 01 59 429 6521 6521 E AndroidRuntime FATAL EXCEPTION main Process al omid tfdroid PID 6521 java lang UnsatisfiedLinkError dlopen failed cannot locate symbol rand referenced by libtensorflow inference so at java lang Runtime loadLibrary Runtime java 364 at java lang System loadLibrary System java 526 at al omid tfdroid MainActivity clinit MainActivity java 28 at java lang Class newInstanceImpl Native Method at java lang Class newInstance Class java 1208 at android app Instrumentation newActivity Instrumentation java 1061 at android app ActivityThread performLaunchActivity ActivityThread java 2114 at android app ActivityThread handleLaunchActivity ActivityThread java 2257 at android app ActivityThread access 800 ActivityThread java 143 at android app ActivityThread H handleMessage ActivityThread java 1209 at android os Handler dispatchMessage Handler java 102 at android os Looper loop Looper java 136 at android app ActivityThread main ActivityThread java 5120 at java lang reflect Method invokeNative Native Method at java lang reflect Method invoke Method java 515 at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 818 at com android internal os ZygoteInit main ZygoteInit java 634 at dalvik system NativeStart main Native Method 07 26 15 02 01 179 6521 6521 al omid tfdroid W System err at com android internal os RuntimeInit UncaughtHandler uncaughtException RuntimeInit java 94 Describe the problem Could you pleas tell me how can I solve this Is libtensorflow inference so usable for android devices of api level 20,,"andrewharp,andrewharp",2017-07-26 07:13:59,2017-07-26 22:42:05
IS,Missing definition in Getting Started With TensorFlow guide,System information macOS 10 12 5 installed from binary Tensorflow v1 2 0 1751 g43a819e13 1 2 1 Python 3 6 1 Bazel 0 5 2 homebrew Describe the problem The custom model section of the Getting Started With TensorFlow guide does not define eval input fn I ran across the error when I copied the code line by line and ran it on my machine I fixed it by adding the following definition after input fn is defined,,,2017-07-05 04:58:45,2017-07-26 22:49:05
PR,Update version to rc1,,,av8ramit,2017-07-26 23:45:52,2017-07-26 23:47:37
PR,Update README md,Remove bad practices of sudo pip and install use safer pip install commands,,"alanyee,vrv",2017-07-26 22:01:25,2017-07-27 01:11:03
PR,Removing Mac GPU links out of r1 3,,,"av8ramit,vrv,av8ramit",2017-07-26 20:44:04,2017-07-27 01:47:09
PR,Branch 163282839,,,vrv,2017-07-27 01:10:22,2017-07-27 04:15:55
IS,Bug in ctc ops py is documentation,see in L201 it says the inputs is logits but from the op test L111 we can see the input should be log probability Although seems this does not affect the decoder is output but it affects the decoder is return of path is log prob and the discribe of neg sum logits is confusing I think the document should be changed the inputs should be log of probabilities and the output should be log p maybe we can transform the output to p with tf exp p i think probability output is more comfortable and confusing people from another issue 6034,,"aselle,ebrevdo",2017-07-26 10:40:12,2017-07-27 04:38:22
PR,rename target protobuf closes 11599,,,"lakshayg,vrv",2017-07-27 05:47:03,2017-07-27 05:58:51
PR,Refine docstrings,,,Kongsea,2017-07-27 05:44:04,2017-07-27 05:59:49
PR,Refactoring device name utils,remove duplicated code for full name and legacy name for DeviceNameUtils,,"horance-liu,vrv",2017-07-27 01:24:42,2017-07-27 06:00:06
IS,cxx,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-07-27 13:39:58,2017-07-27 13:41:16
IS,tf contrib data Iterator Continue from dataset with reinitializable iterator,I would like to request the following feature In TF 1 3 0rc0 and probably before the reinitializable iterator can be used to switch between dataset sources as shown here This is great for switching between train and test data but has a nasty side effect when reinitializing the iterator the iteration starts from the beginning of the dataset Therefore switching the dataset between epoch i e do a validation run every 100 iterations or so causes the epoch to never finish Moreover training will only ever use the first 100 batches except you have a huge shuffle buffer size of the dataset The following illustrates the problem,,,2017-07-27 13:05:55,2017-07-27 15:10:14
PR,Cmake support snappy,Windows CMake builds do not include SNAPPY compression library support thus the resulting applications are not able to parse TensorFlow models that were compressed with SNAPPY This pull request adds SNAPPY as ExternalProject just as it is done with all other 3rd party libraries Unfortunately I cannot verify this on a Linux machine right now so option is disabled for Linux by default There is a relevant Stackoverflow question This is my first contribution so I apologize in advance for any guidelines I might have violated Feedback is appreciated,,,2017-07-27 15:18:55,2017-07-27 15:24:17
IS,Setting weights for different layers in a CNN,I have a number of models which I have trained in lasagne I have weights saved for all those models As of now I want to switch to tensorflow I can build the whole architecture in tf but I want to load the weights from my hard disk How can I set the pre trained weights for the network,,,2017-07-27 09:38:30,2017-07-27 16:04:20
PR,DOC Fix typo,you could could be I O bottlenecked TO you could be I O bottlenecked,,,2017-07-27 10:18:09,2017-07-27 16:24:15
PR,Ensure that the multi instruction fuse can take shared inputs,Note that the fuse action only works when the shared input constant appears after all of its consumers in the list of instructions there is not currently a test to verify that this behaviour will continue to function in the future,,"DavidNorman,eliben,DavidNorman,DavidNorman,DavidNorman,vrv,DavidNorman,vrv,vrv,vrv,DavidNorman,DavidNorman,DavidNorman,vrv",2017-07-25 13:10:51,2017-07-27 16:58:24
PR,Fix error with default python path selection,When the env var USE DEFAULT PYTHON LIB PATH is set to 1 and there is not PYTHON LIB PATH set then the configure used to select the first entry that python itself returned this was broken recently I suspect that it was a mistake rather than a deliberate choice,,"DavidNorman,vrv,DavidNorman",2017-07-27 11:09:54,2017-07-27 17:38:13
IS,contrib data Dataset doc issue with Dataset map tf py func in 1 3 0rc0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary 1 3 0rc0 Python version 3 6 CUDA cuDNN version 8 6 GPU model and memory GTX 1080 Exact command to reproduce The following sample is taken from here and works in TF 1 2 1 This should at least be mentioned in the API docs programmer guide,,"aselle,aselle,mrry",2017-07-26 14:14:49,2017-07-27 17:38:34
PR,Upgrade gRPC,Just Jenkins testing for now,,"jhseu,jhseu,jhseu,jhseu,jhseu,vrv",2017-07-26 00:45:42,2017-07-27 17:40:16
PR,Add the Constant operator class,Create a custom operator class to create constants in the Graph and introduce the Operator marker annotation to identify operator classes Please see 7149 for the master tracking issue,,"kbsriram,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,kbsriram,kbsriram,asimshankar,asimshankar,kbsriram,asimshankar",2017-07-17 21:33:21,2017-07-27 17:53:58
PR,PR again Enable building label image with jpeg gif png decoder for Android,Modify 11451 according to is comments Enable building label image with jpeg gif png decoder for Android Add dependency android tesnorflow image op to label image which is not overlapped with android tensorflow kernels Hi Pete Please review it again Looking forward to your advice if any Thank you,,"petewarden,petewarden,jhseu,jhseu,vrv,petewarden",2017-07-13 10:51:58,2017-07-27 17:54:44
PR,Fix configure on Windows,Make configure and configure py work on Windows Fix,,"meteorcloudy,meteorcloudy,meteorcloudy,gunan,meteorcloudy",2017-07-26 08:39:01,2017-07-27 18:09:25
IS,Looks like a bug tensorflow 1 2 1 with gpu error during basic gpu test,System information No custom code OS Windows 10 TensorFlow installed from TensorFlow version use command below 1 2 1 Python version 3 5 Anaconda environment Bazel version if compiling from source N A CUDA cuDNN version 8 0 GPU model and memory Exact command to reproduce python basic gpu test py The trace C Anaconda3 envs py35 lib site packages tensorflow python framework test util py 591 RuntimeWarning invalid value encountered in greater np abs a b atol rtol np abs b np isnan a np isnan b not close where array dtype int64 array dtype int64 array dtype int64 not close lhs not close rhs not close dif not close tol dtype float32 shape 1 3 5 E ERROR testTypes main MathBuiltinUnaryTest Traceback most recent call last File basic gpu test py line 136 in testTypes self testDtype dtype use gpu True File basic gpu test py line 114 in testDtype self compare data np arcsinh math ops asinh use gpu AttributeError module 'tensorflow python ops math ops' has no attribute 'asinh' Ran 13 tests in 12 158s FAILED errors 1,,"reedwm,aselle,gunan,gunan,aselle",2017-07-27 13:25:38,2017-07-27 18:11:13
IS,tf estimate quickstart,I am in the process of making jupyter notebooks from the tensorflow documentation The tensorflow org page on tf esimator quickstart had numerous problems I have straightened out the coding issues and the fixes are in my notebook I still have some more markup text to straighten out Aide from the python2 3 tensoflow 1 2 etc issues the actual test case was not predicting properly I made my own simple one and it predicted just fine so I did not spend time trying to figure out whether the original was wrong or not I'm not volunteering to fix the main tensorflow markdown because I'm against the idea of having so much code there that can not be tested and is constantly breaking because tensorflow is changing and so I do not want to try and fix that with no way to test it and to give people something bulletproof that will work There are lots of posts going unanswered in stackoverflow for 6 months of more on many of these pages and for this scikit learn one especially because people know that already and it is an obvious starting place for newbies,,"reedwm,reedwm",2017-07-26 13:45:27,2017-07-27 19:37:29
PR,XLA Add filtering of tests for 3rd party devices on the python suite,Currently the tests are marked with specific exclusions for devices For 3rd party devices where we do not want their names and configs in the public repo this change allows the devices to specify which tests they want to exclude No change for the CPU GPU builtin devices,,"DavidNorman,frankchn,DavidNorman,DavidNorman,DavidNorman,vrv,hawkinsp,DavidNorman,hawkinsp,DavidNorman,DavidNorman",2017-07-10 12:56:50,2017-07-27 21:03:47
PR,fix memory leak and remove duplicated implements,fix memory leak and remove duplicated implements,,"horance-liu,vrv,horance-liu,vrv,horance-liu",2017-07-27 09:56:31,2017-07-27 22:32:33
PR,External leveldb link changed,table format txt was renamed to table format md,,,2017-07-27 23:10:20,2017-07-27 23:13:55
PR,Add missing grpc dependency to include the proto util h header,,,"jhseu,jhseu,vrv,jhseu,jhseu",2017-07-27 22:16:09,2017-07-28 00:23:57
PR,Branch 163409348,,,"vrv,vrv",2017-07-28 00:34:41,2017-07-28 01:25:52
IS,Using a tf Tensor as a Python bool is not allowed,with the output of 1 2 3 False False False It seems to be a bug or it is designed to be so,,yaroslavvb,2017-07-28 02:50:56,2017-07-28 02:57:06
IS,Add support for XLA cross products,XLA currently supports basic trigonometric operations but does not natively support cross products Cross products are fundamental to many geometric operations and TF has a tf cross function Note relevant discussion in 8315 comment issuecomment 317947166 and preliminary work here,,"learyg,learyg,learyg",2017-07-26 14:54:41,2017-07-28 03:42:17
IS,tf contrib rnn static rnn not found,I am using tensorflow version 0 12 1 and trying to implement simple RNN using static rnn lstm layer tf contrib rnn LayerNormBasicLSTMCell n hidden forget bias 1 outputs states tf contrib rnn static rnn lstm cell x dtype tf float32 The IDE is not able to resolve static rnn In tensorflow documentation tf contrib rnn static rnn is listed here But on clicking on it it redirects to 404 page Is there a change in static rnn in tensorflow If yes then whats the new alternative implementation,,,2017-07-28 10:31:49,2017-07-28 11:56:43
IS,Unclear about how to make BeamSearchDecoder work,UPDATE In the latest tensorflow 1 2 1 this is no longer a problem Please ignore this problem and install the latest tensorflow Hello I am trying to understand the way to use BeamSearchDecoder in a seq2seq model by following the tutorial of nmt beam search However both the documentation and error message seem to be very unclear for starters I have wrote the minimal code for a common seq2seq purpose with beam search,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-07-19 02:47:53,2017-07-28 12:30:47
PR,Fixed two typos,Fixed two typos,,,2017-07-28 15:24:01,2017-07-28 16:46:30
PR,Merge rc1 into master,,,"av8ramit,rryan,av8ramit",2017-07-28 01:10:43,2017-07-28 16:53:02
IS,arg max error,my code is y tf Variable tf random normal shape 2 5 3 10 12 5 a tf arg max y 0 a shape sess tf Session sess run tf global variables initializer sess run a error is InvalidArgumentError see above for traceback ArgOp Unhandled input dimensions 6 Node ArgMax 7 ArgMax T DT FLOAT Tidx DT INT32 device job localhost replica 0 task 0 cpu 0 Variable 9 read ArgMax 7 dimension,,reedwm,2017-07-28 03:21:06,2017-07-28 17:10:47
PR,Add resampler to release notes,,,malcolmreynolds,2017-07-28 10:41:36,2017-07-28 17:19:18
IS,Momentum Adam and other optimizers do not work for variable input output sizes,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 1 3 0 rc0 Python version 2 7 12 Bazel version if compiling from source 0 5 0 CUDA cuDNN version 8 0 5 1 10 GPU model and memory GeForce GTX Titan X 12GB Exact command to reproduce N A You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem None of the optimizers other than GradientDescentOptimizer seem to work when the network is working with inputs and outputs of variable sizes in FCN input size output size defined by BATCH SIZE None None CHANNELS Below are the error I get when using various optimizers Momentum Optimizer AttributeError 'Tensor' object has no attribute 'is fully defined' RMSPropOptimizer ValueError Shape of a new variable expanding step4 deconv bias RMSProp must be fully defined but instead was unknown AdamOptimizer AttributeError 'Tensor' object has no attribute 'is fully defined' GradientDescentOptimizer Works Note that these optimizers had worked for the same code when I was using TF 1 0 1 Source code logs This is the stack trace for MomentumOptimizer usr local lib python2 7 dist packages tensorflow python training optimizer pyc in minimize self loss global step var list gate gradients aggregation method colocate gradients with ops name grad loss 323 324 return self apply gradients grads and vars global step global step 325 name name 326 327 def compute gradients self loss var list None usr local lib python2 7 dist packages tensorflow python training optimizer pyc in apply gradients self grads and vars global step name 444 str v for v in converted grads and vars 445 with ops control dependencies None 446 self create slots get variable for v for v in var list 447 update ops 448 with ops name scope name self name as name usr local lib python2 7 dist packages tensorflow python training momentum pyc in create slots self var list 64 def create slots self var list 65 for v in var list 66 self zeros slot v momentum self name 67 68 def prepare self usr local lib python2 7 dist packages tensorflow python training optimizer pyc in zeros slot self var slot name op name 764 named slots self slot dict slot name 765 if var key var not in named slots 766 named slots var key var slot creator create zeros slot var op name 767 return named slots var key var usr local lib python2 7 dist packages tensorflow python training slot creator pyc in create zeros slot primary name dtype colocate with primary 168 slot shape slot shape if slot shape is fully defined 169 else array ops shape primary initialized value 170 if slot shape is fully defined 171 initializer init ops zeros initializer dtype 172 return create slot with initializer AttributeError 'Tensor' object has no attribute 'is fully defined',,"ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx",2017-07-27 09:49:43,2017-07-28 18:16:46
IS,'No module named tensorflow' error in jupyter notebook after installing tensorflow gpu using pip in the same virtual environment I am using python 2 7 12,I am trying to use tensorflow gpu on Ubuntu16 04 I installed tensorflow via pip inside virtual environment and other required libraries When I start jupyter notebook in the same environment and try to run a code that uses tensorflow the line 'import tensorflow as tf' gives an error It says no module named tensorflow I had a similar problem with skimage I initially installed scikit image instead of python skimage and I was getting an error But it got resolved after I installed the right library However I can not make sense of why it can not find the tensorflow module,,reedwm,2017-07-28 16:03:57,2017-07-28 18:31:50
IS,Cannot build TensorFLow with GPU support when using TensorFlow as an external dependency,Currently my project uses TensorFlow as an external dependency local repository When I build my project with CPU only the build is successful However if I add config cuda the build will succeed but without the GPU part yes I have run configure The warning I get is WARNING Config values are not defined in any rc file cuda This does not happen if I build my project inside TensorFlow is source tree,,"shreyneil,shreyneil,aselle",2017-07-18 13:27:39,2017-07-28 19:22:08
IS,The current makefile is incomplete,Can someone provide a makefile that is equivalent to tensorflow libtensorflow cc so This current makefile is missing many C API is Is there a way to find all the files needed to build tensorflow libtensorflow cc so recursively,,"aselle,petewarden,petewarden",2017-06-16 02:59:05,2017-07-28 19:22:40
PR,Add more coverage of file io methods in gcs smoke tests,Add more coverage of file io methods in gcs smoke tests Also adds some missing assertions in existing test cases,,"rinugun,caisq,caisq,caisq,caisq,caisq",2017-07-27 21:30:40,2017-07-28 19:45:02
PR,Branch 163490703,,,"vrv,vrv,vrv,av8ramit,av8ramit",2017-07-28 18:14:45,2017-07-28 21:14:34
PR,Adding disabling mechanism for plugins,This adds a scheme to allow 3rd party XLA drivers to disable python tests using the disabled manifest mechanism already in existence,,"DavidNorman,DavidNorman,hawkinsp,DavidNorman",2017-07-27 21:02:55,2017-07-28 21:37:28
PR,Issue 11241 Add checkpoint convert py script to package and make RNN NAME REPLACEMENTS public,As requested in this PR adds the script to the TensorFlow pip package and removes the leading underscore from the name of RNN NAME REPLACEMENTS to indicate that this constant can be used by user code Testing done Verified that checkpoint convert py is not included in the package prior to this change Verified that checkpoint convert py is included in the package after this change Verified that checkpoint convert py does not complain about missing imports when invoked from the command line after installing the pip package Ran unit tests in contrib rnn after the change,,"frreiss,josh11b,frreiss,josh11b,frreiss,vrv,vrv,asimshankar,vrv",2017-07-23 13:27:25,2017-07-28 21:38:25
PR,Testing PRs,,,"av8ramit,av8ramit,gunan,av8ramit,av8ramit",2017-07-28 18:59:37,2017-07-28 22:16:01
PR,Ensure that TensorBoard is still available when pip installed,Context After r1 2 TensorBoard moved out of the TensorFlow repository into its own repository and its own pip package presently tensorflow tensorboard will later switch to just tensorboard The new pip package specifies the tensorboard command so I removed it from the list of console scripts forTensorFlow I also added tensorflow tensorboard as a pip dependency However it turns out that the pip order of operations is install pip dependencies thus getting tensorflow tensorboard and the new tensorboard command remove deprecated console scripts thus erroneously removing the new pointer to tensorboard To fix this I returned the tensorboard console script to tensorflow is setup py except it now references the tensorboard package rather than the tensorflow package Thus the console script declaration in tensorflow and tensorboard are identical We can be confident that the tensorboard package is available because it is specified by the pip dependency Test Plan Create a clean virtualenv pip install tensorflow 1 3 verify that the tensorboard command works properly pip install tensorflow 1 3 using a pip package generated with this change verify that the tensorboard command still works This is the fix for master I sent a separate PR to move this fix into r1 3,,"dandelionmane,wchargin,vrv",2017-07-27 23:56:08,2017-07-28 22:33:42
PR,Fix windows bazel build,,,"snnn,meteorcloudy,meteorcloudy,meteorcloudy,meteorcloudy,meteorcloudy,vrv,vrv",2017-07-28 07:50:11,2017-07-28 22:35:59
PR,Branch 163534909,,,vrv,2017-07-28 23:49:40,2017-07-29 00:01:10
PR,Android demo Explicitly import R java,Add explicit import of the R class to fix Google internal Android demo builds,,"andrewharp,vrv,andrewharp,andrewharp,vrv",2017-07-28 18:03:07,2017-07-29 00:01:28
PR,Bug in builds pip sh causes failure if NO TEST ON INSTALL 1,do virtualenv pip test uses CLEAN VENV DIR which is defined in do clean virtualenv smoke test But if NO TEST ON INSTALL is set to 1 CLEAN VENV DIR would never be defined and pip sh will fail It is very likely that we actually meant to use VENV DIR instead,,"caisq,caisq,vrv",2017-07-28 19:35:31,2017-07-29 00:02:26
PR,GPU Tracer Add peer to peer memcpy annotations,In order to trace memory copies between devices with more recent versions of CUDA the GPU tracer must capture peer to peer i e device to device memory transfers e g cuMemcpyDtoD cudaMemcpy cudaMemcpyDeviceToDevice Add handling to capture these,,"jthestness,vrv,vrv",2017-07-27 01:10:02,2017-07-29 00:02:59
IS,bazel build error no such package ' protobuf src google protobuf',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 x Python version 3 5 Bazel version if compiling from source 0 4 5 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce sudo bazel build config opt tensorflow tools pip package build pip package Describe the problem When I use bazel to build I met the follow error PS I had installed python3 protobuf using pip3 ERROR no such package ' protobuf src google protobuf' Could not find handler for bind rule external protobuf,,"snnn,snnn,reedwm",2017-07-28 08:43:11,2017-07-29 00:28:42
PR,grpc changed to only build Release flavor,cmake builds are broken for Debug RelWithDebInfo builds because grpc now only builds Release binaries Always point to the Release bits to fix it,,"guschmue,jhseu,vrv,guschmue,guschmue",2017-07-28 22:56:34,2017-07-29 01:15:55
PR,Fixed issue Conv ops python unit test fails,Fixed an issue where the Conv ops python unit test fails for MKL,,"claynerobison,vrv",2017-07-28 22:26:39,2017-07-29 01:32:58
IS,tf nn conv2d produces incorrect results,conv2d does not seem to produce results that are correct when compared with a C implementation and MATLAB is conv2 These errors are most pronounced when importing parameters from an external model The same network in tf produces an accuracy of 60 while the original network has an accuracy of 97 To verify that the problem indeed is in tf is conv2d I used the following simple example MATLAB code k2 reshape 1 9 3 3 ' k2 repmat k2 1 1 3 x2 reshape 1 16 4 4 ' x2 repmat x2 1 1 3 c conv2 x2 1 k2 1 isame' conv2 x2 2 k2 2 isame' conv2 x2 3 k2 3 isame' output 87 186 249 225 297 576 711 594 621 1116 1251 990 789 1338 1455 1095 Python TF code import tensorflow as tf import numpy as np k np reshape range 1 10 3 3 1 1 k np repeat k 3 2 astype 'float16' x np reshape range 1 17 1 4 4 1 x np repeat x 3 3 astype 'float16' dev X tf Variable x dtype tf float16 dev K tf Variable k dtype tf float16 dev C tf nn conv2d dev X dev K strides 1 1 1 1 padding 'SAME' session tf Session session run tf global variables initializer print session run dev C 0 0 output 333 534 651 435 693 1044 1179 756 1089 1584 1719 1080 591 822 885 525 What exactly is different in tf is implementation of convolution Is this a bug,,"ppwwyyxx,ppwwyyxx",2017-07-29 04:54:57,2017-07-29 06:09:05
IS,AbortionError code StatusCode NOT FOUND details FeedInputs unable to find feed output ToFloat 0,Hello I am trying to host the ssd mobilenet v1 coco model from the Tensorflow Object Detection API model zoo with Tensorflow Serving I was able to successfully export the model with the exporter script in models object detection exporter py as a SavedModel The issue arises when I tried to run the modified client I am using this commit of tensorflow to build the model server which is the default submodule of tensorflow serving,,,2017-07-29 00:12:04,2017-07-29 09:05:29
IS,Dense layer throwing error with inputs from Keras Concatenate layer,I think this is the most weird error I have ever seen I concatenated the outputs of max pool and average pool using two different methods and passed the output to another dense layer as As the incoming inputs are all float32 should not the dense layer infer that itself,,fchollet,2017-07-29 09:52:46,2017-07-29 21:23:43
PR,Fix a minor typo,Just a fix for minor typo,,,2017-07-29 19:42:00,2017-07-30 04:24:31
PR,Minor typo correction,,,,2017-07-30 02:02:06,2017-07-30 04:24:54
IS,How to shutdown a tf train Server is port,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Pip TensorFlow version use command below 1 2 1 Python version 2 7 Bazel version if compiling from source None CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem When I createt a tf train Server object It is open a port immediately But I can not find any way to close the Server I means the port tf train Server started What can I do if I want to start run stop a tf train Server in a loop I need to start tf train Server in a while loop one more thing on my macbook the code can run without error but on a linux server failed Source code logs,,yaroslavvb,2017-07-29 17:54:30,2017-07-30 05:33:33
PR,Add a custom tag for use by fusion ops,Currently when replacing an op with a fusion of many the information which is carried by that fusion op is limited to a small fixed enumeration I have previously added a 'custom' entry to that enumeration however it is not really enough to label an arbitrary and non fixed set of fuse results This adds a general integer that can be used by any back end to label fused ops arbitrarily There are other ways to achieve this replacing the FusionKind enumeration with an integer field allowing read write access to the metadata structure and replacing it with something like a map some other thing I can not think of right now I'm happy to go with a different scheme but I do think that the HloInstruction needs an annotation interface of some kind,,"DavidNorman,DavidNorman,DavidNorman,DavidNorman,DavidNorman,DavidNorman,vrv,majnemer,DavidNorman,DavidNorman",2017-07-24 15:02:57,2017-07-30 10:43:32
PR,fix minor typo,,,,2017-07-30 08:08:37,2017-07-30 15:49:03
PR,Branch 163636676,,,"frankchn,frankchn",2017-07-30 23:07:02,2017-07-30 23:57:17
IS,Bazel build failure with gpu version,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 0 I'm installing from tha master branch Python version 2 7 Bazel version if compiling from source 0 5 3 CUDA cuDNN version 5 1 GPU model and memory GTX1060 6G Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem I followed every step from the installing configuration page at tf official website ConfigureInstallation But when I came the bazel build step I ran into the problem showed in the error logs below I should mention that 1 I choosed cuda support in the configure step you can find the configure details below as well 2 I previously installed the cpu version of tensorflow on the same computer and it worked fine Now I have uninstalled it of course Source code logs My configuration,,,2017-07-30 15:15:49,2017-07-31 00:12:47
IS,Where can I find c head file tensorflow cc ops sparse ops h,I want to use the sparse tensor in C API But when I search in there is no tensorflow cc ops sparse ops h Does anyone know how to use the sparse tensor in C,,asimshankar,2017-07-31 04:03:46,2017-07-31 06:06:20
PR,Fix typos,This PR fixes some typos squeee argumnet succeeeded and pyton,,taehoonlee,2017-07-31 02:04:10,2017-07-31 13:38:40
IS,Why tf FIFOQueue did not removed when using tf reset default graph,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Pip TensorFlow version use command below 1 2 1 Python version 2 7 Bazel version if compiling from source None CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem I want to empty the entire session and grapth while every loop But the FIFOQueue seems did not removed when I using tf reset default graph So how to make everything clean in currrent process without create a subprocess or change FIFO is name Source code logs,,yaroslavvb,2017-07-30 07:00:14,2017-07-31 16:23:06
IS,Out of memory due to cuda host bfc allocator,Hi I am getting OOM errors when I try to move data from GPUs to CPU CPU has 0 5TB memory and when I allocate a large chunk of CPU memory directly there is no problem However for some reason cuda host bfc allocator sets the limit to 68719476736 which is incidentally 0 in int32 It looks like there is a bug here Any thoughts Thanks p s I disable the auto gc collector on purpose with get raw handle so I can quickly clear the GPU memory System information Have I written custom code as opposed to using a stock example script provided in TensorFlow y OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 3 16 43 2 deb8u2 2017 06 26 x86 64 GNU Linux TensorFlow installed from source or binary source TensorFlow version use command below v1 2 0 2010 g8605f7a 1 2 1 Python version 2 7 12 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 61 GPU model and memory 4 x Tesla P100 SXM2 16GB Exact command to reproduce python cuda host bfc oom bug py out log 2 out err Source code cuda host bfc oom bug py,,,2017-07-31 16:14:37,2017-07-31 16:26:35
PR,OpenCL Stats tracking,Adds buffer size tracking to SYCL allocator 114 The SYCL buffers underlying tensors already keep track of their sizes so we can easily provide this tracking information for debugging purposes Adds stat tracking to the SYCL allocator The SYCLAllocator will now find the max allocation size on construction and keep track of the allocation stats as given in AllocationStats,,"lukeiwanski,frankchn",2017-07-15 20:18:16,2017-07-31 16:27:32
PR,Branch 163695881,,,"benoitsteiner,benoitsteiner",2017-07-31 16:10:26,2017-07-31 18:17:15
IS,python ImportError No module named iscipy',In 1 from sklearn import linear model ImportError Traceback most recent call last ipython input 1 a6ebbebad697 in module 1 from sklearn import linear model C ProgramData Anaconda3 envs tensorflow gpu lib site packages sklearn init py in module 55 else 56 from import check build 57 from base import clone 58 check build avoid flakes unused variable error 59 C ProgramData Anaconda3 envs tensorflow gpu lib site packages sklearn base py in module 8 9 import numpy as np 10 from scipy import sparse 11 from externals import six 12 from utils fixes import signature ImportError No module named iscipy',,,2017-07-30 08:44:06,2017-07-31 19:05:45
PR,Disabling gmm test py on Windows builds as it is flaky on GPU nightly,builds CC Cannot add as a reviewer for some reason,,"av8ramit,av8ramit",2017-07-31 16:13:03,2017-07-31 19:38:26
IS,Error on tf contrib training stratified sample,I made a small example to illustrate which makes some synthetic data with unbalanced classes and tries to take balanced samples from it All the searching I did on this TypeError message returned legitimate bugs not user errors so I'm putting this here For completeness python c import tensorflow as tf print tf GIT VERSION tf VERSION gives 'v1 2 0 0 g12f033d' '1 2 0',,joel-shor,2017-07-07 21:03:01,2017-07-31 20:13:18
IS,patch is not installed on some of Windows slaves,On win0 slave,,"meteorcloudy,meteorcloudy,yifeif,meteorcloudy,yifeif,meteorcloudy",2017-07-31 06:45:22,2017-07-31 21:12:36
IS,RandomShuffleQueue seems not random when one class one file,I split cifar 10 dataset to ten files where each file contains one class of samples When I use the split files as the input of a classification model and use RandomShuffleQueue to handle the input data in one batch is not an approximate uniform sampling of the ten classes The hisogram of the labels in one batch indicates RandomShuffleQueue seems not do a real random dequeue operation Can anyone explain the details of RandomShuffleQueue dequeen operation Thanks screenshot from 2017 07 31 21 39 45,,yaroslavvb,2017-07-31 14:05:41,2017-07-31 21:44:59
PR,R1 2,,,,2017-08-01 02:02:22,2017-08-01 02:03:30
IS,How to understand multithreading in tf queue,Tensorflow provides us two ways to implement reading data The first way use many reader such as tf TextLineReader one reader per thread The second way use just one reader and multithreading of enqueue ops for example we can use tf train shuffle batch and set num threads greater than 1 I can not understand the second way we just have one reader to load data perhaps a thread why we need so many threads to enqueue And for the first way we should use tf train shuffle batch join there is no num threads parameter we can set so I think the first way is understandable Can anyone give me some explanation for why we need one reader but many threads to enqueue,,yaroslavvb,2017-08-01 02:19:44,2017-08-01 05:20:18
IS,tf train SyncReplicasOptimizer no synchronization among workers,System information Have I written custom code Yes OS Platform and Distribution Linux TensorFlow installed from source or binary Binary TensorFlow version use command below 1 2 1 Python version 3 5 2 Problem Description I'm trying to train an rnn model with distributed synchronized training and between graph replication I'm using tf train replica device setter Asynchronous Training works perfectly fine As written in the documentation I'm wrapping my optimizer and creating the hook However as already noticed in 9596 and several other issues 1 2 the training does not seem to synchronize among workers So is there a bug in SyncReplicasOptimizer I'm seeing several hints for this hypothesis 1 One worker is constantly ahead by several steps in my logs 2 When stopping one worker the other just continues with the training as if nothing happened In a synchronized setting training should stop or crash 3 The training steps take approximately the same time as asynchronous training Synchronous Training should be slower because of the synchronization Questions 1 Is there any test with which one can confirm that sync replicas optimizer py really does synchronize 2 Is the API Documentation regarding sync replicas optimizer py up to date 2 Is this somehow related to tf train replica device setter as mentioned by g in 9596 3 Are there any workarounds for this,,"reedwm,jmchen-g",2017-07-25 15:47:28,2017-08-01 07:53:12
IS,Exception in thread main java lang UnsupportedClassVersionError org tensorflow Graph Unsupported major minor version 52 0,When I use tf java API there is a problem Exception in thread main java lang UnsupportedClassVersionError org tensorflow Graph It seems that the jdk version 1 7 can not user the lib So I want to know whether can I use java api with jdk1 7 and how,,,2017-08-01 07:12:04,2017-08-01 08:50:56
IS,Where can I find gen checkpoint ops,When I was debuging inception v4 there has a message 22 from tensorflow contrib framework python ops import gen checkpoint ops 23 from tensorflow contrib util import loader 24 from tensorflow python framework import dtypes ImportError cannot import name gen checkpoint ops But I can not find a module or package named gen checkpoint ops I do not know how to resolve this problem Help,,yaroslavvb,2017-08-01 12:51:45,2017-08-01 15:15:37
IS,How to make full use of multicore only cpu mode on android phone,System information Platform android 6 0 arm64 v8a TensorFlow installed from source cpu mode only TensorFlow version 1 2 0 Bazel version 0 5 2 Describe the problem When I trained a model by using google object detection api I put it to my android env and use c api to run the pb file model on my phone it has a slow running speed and only 2 cpus are fully utilized when there are 8 cpus on my device What should I do to make full use of the remaining cpus on my mobile phone I use c api to run the model here is my config to session of tensorflow but it is useless Could some one help me Source code logs tensorflow SessionOptions options tensorflow ConfigProto config options config config mutable device count insert google protobuf MapPair std string google protobuf int32 cpu 8 config set intra op parallelism threads 8,,snnn,2017-08-01 06:09:45,2017-08-01 16:47:04
IS,does libtensorflow inference so contains both code for training pb file and code for analyzing pb file,Describe the problem I would like to import libtensorflow inference so to an android app to and make it possible to make some machine learning in the app But the size of libtensorflow inference so file is too large which is 9 8M Because I just want to import generated models pb file to predict and do not need to train models in android app Could you please tell me which code is used to import and analyze the pb file and witch code is used to train a pb file in tensorflow project does libtensorflow inference so contains both code for training pb file and code for analyzing pb file Is possible to remove the code for training pb file to minimize its size if it contains that,,andrewharp,2017-08-01 09:05:33,2017-08-01 18:11:17
PR,Branch 163848365,,,benoitsteiner,2017-08-01 17:49:10,2017-08-01 19:37:00
IS,All Windows GPU build links are broken,The link bolded is broken in the webpage of li Windows GPU a href PY 35 lastSuccessfulBuild artifact cmake build tf python dist tensorflow gpu 1 3 0rc1 cp35 cp35m win amd64 whl Python 3 5 64 bit a a href PY 35 build history a a href PY 36 lastSuccessfulBuild artifact cmake build tf python dist tensorflow gpu 1 3 0rc1 cp36 cp36m win amd64 whl Python 3 6 64 bit a a href PY 36 build history a li Some other links in this webpage are also broken But the file of the corresponding link in the webpage of the Build history can be downloaded,,"aselle,av8ramit,av8ramit",2017-07-30 04:36:48,2017-08-01 20:50:04
PR,Fix 11803 Force CUPTI to flush GPU activity buffers when stopping tracing,As described 11803 stopping GPU tracing GPU events are not flushed Then we cannot get GPU activities in performance statistics Calling ActivityFlushAll with flag CUPTI ACTIVITY FLAG NONE causes this problem so this commit changes the flag to CUPTI ACTIVITY FLAG FLUSH FORCED,,benoitsteiner,2017-08-01 15:59:26,2017-08-01 21:58:15
IS,gpu 0 stream does not appear on Timeline,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 2 0 2479 g88abddb' '1 3 0 rc0' Python version 2 7 12 Bazel version if compiling from source bazel release 0 4 5 CUDA cuDNN version CUDA 8 0 cuDNN 5 1 5 GPU driver version 375 66 GPU model and memory GeForce GTX 1080 8GB Exact command to reproduce python convolution py attached The Problem Making a timeline Timeline object in my environment gpu 0 stream xx rows do not appear timeline no gpu I found the event collector function BufferCompleted L149 were not called at all during measuring performance Though BufferCompleted is registered as a callback function to CUPTI for processing GPU events CUPTI does not call it in my environment This comes from failing to flush GPU events GPU events are flushed by ActivityFlushAll L206 with flag CUPTI ACTIVITY FLAG NONE group CUPTI ACTIVITY API in tensorflow But this flag does not seem to cover necessary GPU events so GPU events were not flushed and collected I modified gpu tracer cc to call ActivityFlushAll with flag CUPTI ACTIVITY FLAG FORCE INT then I got gpu 0 stream xx rows in Timeline timeline with gpu Is there any reason to use CUPTI ACTIVITY FLAG NONE Source code logs Attached source code comes from tensorflow models The following modification was added to measure performance from tensorflow python client import timeline run options tf RunOptions trace level tf RunOptions FULL TRACE run metadata tf RunMetadata l lr predictions sess run loss learning rate train prediction feed dict feed dict options run options run metadata run metadata tl timeline Timeline run metadata step stats ctf tl generate chrome trace format show memory True show dataflow True with open timeline json w as f f write ctf convolutional py zip,,,2017-07-27 06:04:45,2017-08-01 21:58:39
PR,Improve docstrings involving package structure,This PR improves docstrings involving tf learn In the case of tensorflow dataframe py I think it is better to put just DataFrame in order to keep consistency within one file Except for the case all the tf learn s are replaced by tf contrib learn s,,"taehoonlee,drpngx,taehoonlee,drpngx,taehoonlee,drpngx,martinwicke,taehoonlee,vrv,drpngx,drpngx",2017-06-30 07:57:32,2017-08-01 22:03:37
PR,Inconsistent normalization formula,Hi there In the Input Normalization video you normalize the pixels by dividing by 1 2 of the pixel depth however in the code you divide by the pixel depth This confused me at first and you may want to consider making the formula the same in both video and code Thanks All the best Jake,,vincentvanhoucke,2017-07-30 16:53:34,2017-08-01 22:06:38
IS,No OpKernel was registered to support Op 'RFFT' for CPU running on android,I'm running tensorflow on android and got this error Caused by java lang IllegalArgumentException No OpKernel was registered to support Op 'RFFT' with these attrs Registered devices CPU Registered kernels no registered kernels I'm using the master branch where the RFFT CPU verison is already supported So I'm wondering why this problem show up The TF version I used to build the graph pb file is also the latest master branch Here is to code I wrtie pb graph with tf Graph as default tf Session config tf ConfigProto allow soft placement True as session with tf variable scope model model DeployModel config config print 'Graph build finished' variable names n name for n in tf get default graph as graph def node for n in variable names print n saver tf train Saver saver restore session save path path join self config model path 'latest ckpt' print model restored from s config model path frozen graph def graph util convert variables to constants session session graph as graph def 'model inputX' 'model softmax' 'model nn outputs' tf train write graph frozen graph def os path dirname graph path os path basename graph path as text False So maybe RFFT for CPU is still not supported on android in the latest branch,,"aselle,andrewharp,aselle",2017-07-27 06:29:38,2017-08-01 22:36:43
PR,Determinant operation on the GPU,This pull request implements the computation of the matrix determinant on the GPU using LU factorization with cuSolver This is the second part of the use case presented in pull request 11878 It uses the LU factorization instead of QR factorization because this allows to compute the determinant also for non symmetric matrices This is required by the definition of the operation in Tensorflow Hence I also had to implement the LU interface to cuSolver QR would have already been implemented Two further notes First the precision of this algorithm to compute the determinant is less precise than the Eigen implementation Hence I had to relax the allowed error in the unit test This is especially important for singular or near singular matrices Second if this pull request and 11878 will both be accepted they will probably clash in cuda solvers h and or cuda solvers cc I will resolve the conflicts if it happens to be so,,rmlarsen,2017-07-30 07:46:10,2017-08-01 22:50:08
IS,No registered 'MirrorPad' OpKernel for XLA CPU JIT,tf pad mode 'REFLECT' does not work with tfcompile Will this be supported and when It is somewhat urgent on my part and it seems like it should be a simple enough addition unlike control flow as in,,"carlthome,learyg,learyg,learyg",2017-07-30 21:21:45,2017-08-01 22:51:56
PR,Make plugin data optional and not repeated,Make plugin data optional and not repeated Every summary op writes data for a single plugin to process Hence each SummaryMetadata proto should have a single PluginData optional field instead of a repeated one This removes much complexity from TensorBoard logic that loops over the plugin data It also simplifies the SQL schema it can now enforce a one to one relationship between summary op and plugin,,"chihuahua,chihuahua",2017-08-01 22:50:58,2017-08-01 23:03:46
IS,Plan for supporting tf contrib seq2seq prepare attention in r1 2,Any plans to support in r1 2,,ebrevdo,2017-07-30 17:16:09,2017-08-01 23:15:54
IS,tf contrib streaming mean squared error returns incorrect result,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 3 0 0rc0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem tf contrib streaming mean squared error returns wonky results It returns the current mean square error tensor and an update op According to the documentation their evaluated values should match They do not and the values of the latter tend to get weird A minimal example should demonstrate Source code logs Example mean squared error between two arrays whose difference is an array of ones The MSE should consistently be 1 It is not though After having a brief look at the code I do not see why the returned values do not match The docs speak of finalizing the value but it just looks like total count is returned,,alextp,2017-07-27 09:25:12,2017-08-01 23:22:28
IS,I am unable to extract the hidden layer values from Seq2Seq model in Tensorflow for NMt,Has anyone tried to extract the hidden layer values since the code explicitly does not specify the hidden layer in translate py or in seq2seq model py tensorflow version 1 0 OS CentOS Python 2 7 Is there any other program i need to look into for printing the hidden layer values,,allenlavoie,2017-08-01 09:45:07,2017-08-01 23:39:06
IS,cudnn failed with GTX960,I am trying to use conv2d for cnn with GPU and there are one GTX 960 and Quadro 600 on my computer I set up the CUDA VISIBLE DEVICES 0 to use GTX 960 but I get,,,2017-08-02 01:06:49,2017-08-02 01:27:03
IS,Unclear about how to integrate AttentionWrapper with BeamSearchDecoder,TF Version 1 2 1 I cannot find information about how to integrate AttentionWrapper with BeamSearchDecoder on website nmt tutorial in particular how to feed the beam search tiled,,,2017-07-31 09:46:55,2017-08-02 03:47:28
IS,tensorflow gpu 1 3 0rc1 cp27 none linux x86 64 whl is not a supported wheel on this platform,I am trying to install TF 1 3 0rc1 in CentOS 7 3 with Nvidia GPUs for python3 6 When I installed with python2 7 it was fine sudo pip3 6 install U I get this error with python3 6 My pip3 6 has a slight difference with sudo Without sudo when I run pip3 6 version I get pip 9 0 1 from usr local lib python3 6 site packages python 3 6 With sudo I get pip 9 0 1 from usr lib python3 6 site packages python 3 6 Any workaround for this,,,2017-08-02 14:59:07,2017-08-02 15:18:58
IS,timeout breaks FIFOQueue,System information Linux Ubuntu 14 04 TensorFlow installed from Tensorflow gpu 1 2 1 Python version 2 7 CUDA 8 0 cuDNN 5 1 10 GPU Nvidia GTX 1080 Describe the problem I use thread to add my training data to a FIFO Queue There is always an thread error occurring in the process of my training Source code logs Here is my source code relevant to the error,,yaroslavvb,2017-08-02 05:59:08,2017-08-02 16:02:36
PR,Branch 163983198,,,benoitsteiner,2017-08-02 16:06:42,2017-08-02 17:16:34
PR,Make 'import tensorflow' go faster,av8ramit I recommend this cherry pick of cl 163600869 which makes import tensorflow go much faster 2x faster on my machine I would also request that it be mentioned in the 1 3 release notes,,"jart,av8ramit,av8ramit,av8ramit,caisq",2017-07-31 20:15:52,2017-08-02 17:42:14
IS,tfcompile of tf sin and tf cos,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 12 Describe the problem I tried to use tfcompile for AOT compilation of a graph where are use tf sin and tf cos functions tfcompile raises following error,,"aselle,aselle,learyg",2017-07-27 17:08:08,2017-08-02 20:19:21
IS,tf nn weighted cross entropy with logits is bad,tf nn weighted cross entropy with logits 1 z x l log 1 exp abs x max x 0 where l 1 q 1 z but tf nn sigmoid cross entropy with logits max x 0 x z log 1 exp abs x if q 1 weighted cross entropy with logits is equvalent sigmoid cross entropy with logits 1 z x l log 1 exp abs x max x 0 l 1 max x 0 x z log 1 exp abs x x max x 0 max x 0 0 tf nn weighted cross entropy with logits must be z x l log 1 exp abs x max x 0,,,2017-08-02 19:39:10,2017-08-02 20:51:43
IS,Incorrect tfBinaryURL for installing with Anaconda on Linux,There is incorrect tfBinaryURL at tensorflow org In case of Installing with Anaconda in Linux the example shows the following command for Python 2 7 tensorflow pip install ignore installed upgrade But this is for Python 3 4 so correct command is below tensorflow pip install ignore installed upgrade,,,2017-08-02 00:44:05,2017-08-02 21:12:50
IS,Query in lower level versions of Get Put involved in EncodeFixed DecodeFixed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version 2 7 12 Bazel version if compiling from source 0 4 5 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce Run tests from core module The problem While checking coding test cc came across a sub test TEST Coding EncodingOutput which tests that encoding routines generate little endian encodings This test is passing on a big endian machine So while debugging realized that the EncodeFixed DecodeFixed functions from coding cc and raw coding h encode decode buf values on big endian incorrectly i e the character buffer writing happens in the same way as on a little endian machine After I made the required changes to correct the same although 1 test of my interest TEST TensorBundleTest Checksum now passes I could see many others failing on big endian with errors like 1 Data loss block checksum mismatch perhaps your file is in a different file format and you need to use a different restore operator 2 Data loss corrupted record at 19 3 Segmentation fault 4 Invalid argument sample rate must be in 0 2 32 got 0 So looks like this change is breaking too many things here Can anyone help in understanding why the correction is causing so many issues Will this change involve too many changes in TensorFlow code to support big endian,,"namrata-ibm,namrata-ibm",2017-07-31 13:42:19,2017-08-02 21:32:09
PR,Turn off grappler for 1 3,Tested with tf cnn benchmark suite and regression caused by the changes is resolved according to the tests This change should not be pulled back into master as a fix for the feature has been done that also needs tested,,"tfboyd,av8ramit,av8ramit",2017-08-02 19:48:25,2017-08-02 21:44:00
IS,Got ValueError Both labels and logits must be provided while both labels and logits have been provided,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 6 2 Continuum Analytics Inc default Jul 20 2017 13 51 32 GCC 4 4 7 Bazel version if compiling from source CUDA cuDNN version 5 1 GPU model and memory GTX 1050 4GB Describe the problem Got ValueError Both labels and logits must be provided while both labels and logits have been provided Source code logs,,,2017-08-01 13:18:29,2017-08-02 21:58:55
PR,Fix white spaces,This PR cleans up extra white spaces,,"taehoonlee,benoitsteiner",2017-08-01 08:21:47,2017-08-02 22:04:18
PR,Update bigquery reader ops py,Fix example code in comments by replacing tf training string input producer with tf train string input producer,,"4d55397500,4d55397500,vrv,benoitsteiner",2017-07-25 19:15:41,2017-08-02 22:06:07
PR,OpenCL Fixes SYCL profiler tests 141,The profiler relies heavily on the canonical device being listed in the TFProf nodes which is only set for those devices which return True from CountAsCPUTime so we need this to return True for SYCL device nodes too The check for whether the node will run on an Accelerator comes from IsPlacedOnAccelerator,,"lukeiwanski,benoitsteiner",2017-07-17 16:35:38,2017-08-02 22:07:23
PR,Make plugin data optional instead of repeated,Every summary op writes data for a single plugin to process Hence each SummaryMetadata proto should have a single PluginData optional field instead of a repeated one This removes much complexity from TensorBoard logic that loops over the plugin data It also simplifies the SQL schema it can now enforce a one to one relationship between summary op and plugin,,"chihuahua,av8ramit,wchargin,chihuahua,chihuahua,jart,wchargin,chihuahua,chihuahua,chihuahua,chihuahua,caisq,av8ramit,av8ramit,av8ramit,av8ramit",2017-08-01 23:03:11,2017-08-02 22:15:49
PR,Updating version to rc2,,,av8ramit,2017-08-02 23:10:01,2017-08-02 23:14:11
PR,OpenCL Provides SYCL kernels for 3D pooling 97,OpenCL Adds SYCL kernels for 3D pooling Uses simple SYCL kernels to provide implementations for all 3D pooling ops currently in use These kernels pass the tests but have not really been optimized These need benchmarking to compare with Eigen and CPU kernels OpenCL Refactors SYCL kernels to use parameter struct Moves a lot of the functor parameters into a separate data struct with the aim of simplifying the functor code OpenCL Removes extra fetching of tensor dimensions We already had the tensor dimensions passed into LaunchMaxPooling3dGradOP so do not need to fetch them from the tensor OpenCL Renames SYCL 3D pooling kernels Adds '3D' to kernel names OpenCL Adds 3D pooling SYCL kernel documentation OpenCL Adds guards around SYCLDevice typedef OpenCL Use forward input for SYCL MaxPool3DGradGrad When we had a mix of SYCL and CPU kernels the forward input would break and cause computation problems Now that we have SYCL kernels for all 3D pooling operations this is not a problem OpenCL Reformats SYCL 3D pooling code OpenCL Moves SYCL utils into separate header OpenCL Simplifies SYCL Pool param contructors Instead of each constructor initialising the data simplifies the constructors to call the first constructor,,"lukeiwanski,drpngx,benoitsteiner,benoitsteiner,benoitsteiner,lukeiwanski,drpngx,lukeiwanski,lukeiwanski,lukeiwanski,vrv,lukeiwanski,benoitsteiner",2017-06-22 10:48:39,2017-08-02 23:34:43
PR,Pin 1 3 x package to tensorflow tensorboard 0 1 x,av8ramit This is an important one line cherry pick to end all cherry picks from the TensorBoard team,,"jart,jart,av8ramit",2017-07-31 19:37:58,2017-08-02 23:45:32
PR,Ensure that TensorBoard is still available when pip installed r1 3,Context After r1 2 TensorBoard moved out of the TensorFlow repository into its own repository and its own pip package presently tensorflow tensorboard will later switch to just tensorboard The new pip package specifies the tensorboard command so I removed it from the list of console scripts forTensorFlow I also added tensorflow tensorboard as a pip dependency However it turns out that the pip order of operations is install pip dependencies thus getting tensorflow tensorboard and the new tensorboard command remove deprecated console scripts thus erroneously removing the new pointer to tensorboard To fix this I returned the tensorboard console script to tensorflow is setup py except it now references the tensorboard package rather than the tensorflow package Thus the console script declaration in tensorflow and tensorboard are identical We can be confident that the tensorboard package is available because it is specified by the pip dependency Test Plan Create a clean virtualenv pip install tensorflow 1 3 verify that the tensorboard command works properly pip install tensorflow 1 3 using a pip package generated with this change verify that the tensorboard command still works This is the fix for r1 3 I will also send this same commit in a PR against master,,"dandelionmane,wchargin,MarkDaoust,wchargin,vrv,vrv",2017-07-27 23:53:04,2017-08-03 00:10:19
IS,Occur fatal error 1002 when compiling tensorflow 1 3 with vs2015 DEBUG in windows10,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no custom code original code cloned from github OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source cmake from tensorflow contribe cmake TensorFlow version use command below r1 3 Visual studio version vs2015 CUDA cuDNN version no GPU CUDA 8 0 cuDNN5 1 GPU model and memory NVIDIA Titan X 12GB Exact command to reproduce tf cc vcxproj A C tensorflow 1 3 0 Source GPU tf cc dir Debug tf cc lib 65 a c tensorflow 1 3 0 source gpu external eigen archive eigen src core products generalblockpanelkernel h 1977 fatal error C1002 Describe the problem Hello I get error 1002 when compiling tensorflow r1 3 with vs2015 in tf core kernels use DEBUG mode without GPU which occured during compilation of GPU version too I belive I have enough memory for compilation However I compiled successfully through RELEASE mode without error Same issue in tensorflow r1 2,,"reedwm,snnn,snnn,reedwm",2017-07-26 02:24:22,2017-08-03 02:07:15
PR,Using pd Series instead of pd Dataframe,Small change to use Series for x and y values for clarity and simplicity Code executes equivalently afaict,,"drpngx,nealwu,caisq,nealwu,nealwu,nealwu,nealwu",2017-07-02 12:52:46,2017-08-03 03:12:02
IS,Python crashes with Check failed error when fitting TensorForestEstimator,Problem I am experiencing an issue trying to use TensorForestEstimator I am trying to predict 7 output labels by inputting 7 features That is my num classes 7 and num features 7 in my hyperparameters The shape of features and labels is 484876 7 Here is an example of the format of my input data,,,2017-08-03 05:23:07,2017-08-03 06:38:18
IS,Fail to restore the model after upgraded to version 1 2 1,I trained my model in tensorflow version 1 1 0 and test or restore it successfully But after I upgraded tensorflow to version 1 2 1 I fail to restore the same model with the same code Error Log Is it a bug of tensorflow or my code How to fix it,,asimshankar,2017-08-02 08:09:26,2017-08-03 07:23:20
PR,XLA Add a scheme for disabling tests based on type support by backends,This change allows CPP tests to be marked as requiring certain type support As it stands I have updated only the scalar math test with the annotations I will do the rest once this change is debated The plugin config has something like this added to the 'copts' option,,"DavidNorman,DavidNorman",2017-08-02 12:31:28,2017-08-03 07:55:31
PR,Merge pull request 1 from tensorflow master,update from tensorflow master,,,2017-08-03 09:41:09,2017-08-03 09:54:37
PR,Data type support for seq2seq attention mechanisms,Got an exception like the following when I was trying to use tf float16 in my seq2seq model with Bahdanau Attention to allocate less memory on GPU ValueError Tensor conversion requested dtype float32 for Tensor with dtype float16 'Tensor decoder 1 BahdanauAttention mul 0 shape 2048 dtype float16 ' Inserted dtype argument to attention mechanisms that is used in Dense layer of both query layer and memory layer Default is tf float32,,,2017-08-03 15:33:07,2017-08-03 15:34:29
IS,Where does unknown error message come from,Hi While doing my training of a faster rcnn model I get an unknown error message but the training seems to work fine I just want to know where in Tensorflow is source code there is a print 'unknown error' I do not seem to find that anywhere Thanks you guys,,,2017-08-03 14:27:29,2017-08-03 15:44:29
PR,Update tensor util py,np array makes a copy of the object which is not required so usage of np asarray would be more efficient,,"gautam1858,gautam1858,rryan,gautam1858",2017-08-03 10:47:10,2017-08-03 16:48:53
IS,tensorflow multi label classification,How does tensorflow CNN implement multi label classification specifically how to input multi tags and output multi label prediction results,,"gautam1858,shivaniag",2017-08-03 10:18:18,2017-08-03 17:17:51
PR,Remove tfserve page which is soon to be outdated,We are in the process of serving tfserve documentation in a different way so this file needs to be removed 1 2 is the current root branch on tensorflow org so we need to cut it from r1 2 and we were not able to cherrypick the change back from master where it is already gone,,,2017-08-03 02:08:29,2017-08-03 17:30:11
PR,Testing sanity,,,av8ramit,2017-08-03 18:21:04,2017-08-03 18:26:51
IS,Cannot build Tensorflow 'GLIBCXX 3 4 21' not found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 3 6 1 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 5 0 GPU model and memory GTX1080 8G Exact command to reproduce bazel build verbose failures config opt config cuda tensorflow tools pip package build pip package Describe the problem I cannot build Tensorflow from source I have gcc libraries installed in opt ohpc pub compiler gcc 5 4 0 lib64 But the installer was not able to pick it up It always tries to use the one in usr lib64 I have set LDFLAGS LD LIBRARY PATH etc Nothing works Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem bazel build verbose failures config opt config cuda tensorflow tools pip package build pip package WARNING ignoring http proxy in environment WARNING Output base ' home kai cache bazel bazel kai e5757f5d9b24da3fc563b551b579ddc3' is on NFS This may lead to surprising failures and undetermined behavior WARNING home kai test tensorflow 1 2 1 tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' Use SavedModel Builder instead WARNING home kai test tensorflow 1 2 1 tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle gc' Use SavedModel instead INFO Found 1 target ERROR home kai test tensorflow 1 2 1 tensorflow contrib training BUILD 339 1 null failed protoc failed error executing command cd home kai cache bazel bazel kai e5757f5d9b24da3fc563b551b579ddc3 execroot org tensorflow exec env bazel out host bin external protobuf protoc ' python out bazel out local linux py3 opt genfiles ' I Iexternal protobuf python Ibazel out local linux py3 opt genfiles external protobuf python tensorflow contrib training python training hparam proto com google devtools build lib shell BadExitStatusException Process exited with status 1 home kai cache bazel bazel kai e5757f5d9b24da3fc563b551b579ddc3 execroot org tensorflow bin process wrapper usr lib64 libstdc so 6 version GLIBCXX 3 4 21' not found required by home kai cache bazel bazel kai e5757f5d9b24da3fc563b551b579ddc3 execroot org tensorflow bin process wrapper Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 3 922s Critical Path 0 03s,,"reedwm,martinwicke",2017-07-27 06:50:08,2017-08-03 19:39:01
PR,Make layout optimizer test manual due to Grappler being off in the r1 3 branch,,,"tfboyd,yifeif,av8ramit,av8ramit",2017-08-03 17:53:08,2017-08-03 20:32:47
IS,No module named 'tensorflow contrib keras datasets',In the documentation in order to import Keras dataset you have to I think this problem would occur not just for datasets but anything else in Keras,,,2017-08-01 18:18:08,2017-08-03 21:01:52
IS,Moving average and moving variance in Batchnorm are not updated,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip TensorFlow version use command below 1 2 1 Python version 3 5 3 Bazel version if compiling from source None CUDA cuDNN version 8 5 1 GPU model and memory GeForce 1080 Exact command to reproduce Describe the problem I'm using the slim wrapper which in turn returns an instance of BatchNormalization from layers normalisation py All paramers are set to default except for scale which is set to True i e adding the gamma scaler After training when looking the at the learned parameters I notice that all the moving means in the network are still 0 while all the moving variances are 1 i e they were not updated Both variables do not show up in tf trainable variables which might explain the lack of updates However since these are not actually learned but rather calculated I'm not sure whether they would be updated by the optimiser,,"ppwwyyxx,ppwwyyxx",2017-08-02 11:22:20,2017-08-03 21:02:37
IS,tf nn max pool wrong docs,System information Not Applicable Describe the problem API states that ksize has length 4 the size of window for each dimension of the input tensor However value is a 4 D Tensor so does not this mean that ksize should be length 4 Same for strides Digging into maxpooling op cc shows that there is some check that does Line 212,,"aselle,josh11b,martinwicke,aselle,yongtang",2017-06-15 10:33:01,2017-08-03 21:05:01
PR,Update tf nn max pool docs for ksize strides 4,Update tf nn max pool docs for ksize strides 4 instead of ' 4' in the existing docs As both max pool and avg pool are wrapped in the python code this fix only changes the docstring in tensorflow python ops nn ops py This fix fixes 10729 Note I also tried using syntax as was suggested in issuecomment 309133461 However it seems that the only works with Input not with Attr Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner",2017-08-01 02:03:09,2017-08-03 21:05:01
PR,correct description of bounding box points,bbox points are upperleft and bottomright not bottomleft and upperright Also coordinates were described in idiosyncratic y x instead of x y form And no those two corrections do not cancel,,benoitsteiner,2017-07-30 20:45:28,2017-08-03 21:18:53
PR,Fix depsets cannot contain mutable items error when using Bazel 0 5 3,Allows CUDA builds with more recent versions of Bazel Fixes Perhaps we should also file a Bazel bug although it would be nice to have the workaround in the meantime,,"allenlavoie,martinwicke,yifeif,martinwicke,ahundt,av8ramit",2017-08-01 20:48:15,2017-08-03 21:26:18
PR,Fix formatting problems in Adding an Op doc,I noticed some minor code formatting issues while reading through 1 At line 181 of the Markdown file there is some non working HTML to show hide a code listing 2 At line 766 of the Markdown file there is a code listing that ends up with a bunch of extra backslashes when rendered to HTML 3 At line 1113 of the Markdown file there is a code listing a REGISTER OP macro that does not display properly in the HTML version of the document This PR fixes 1 and 2 above The third problem appears to be a bug in the script that generates the HTML and I was not able to find that script anywhere in the source tree,,"frreiss,benoitsteiner",2017-08-02 20:18:10,2017-08-03 21:47:34
IS,Missing file pywrap tensorflow internal,Please close this issue This issue was due to trying to import tensorflow from the source directory,,,2017-08-03 19:03:32,2017-08-03 22:11:11
IS,Error when using dataset map with num threads None,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes code attached below OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version 8 5 1 GPU model and memory GeForce GTX 1080 8GB Exact command to reproduce just run the script below Describe the problem When using the tf contrib data API and applying a function to a dataset via dataset map my function num threads 2 the following error occurs TypeError Input 'output buffer size' of 'ParallelMapDataset' Op has type int32 that does not match expected type of int64 Please note that num threads 2 is necessary to cause the error From what I can see in MapDataset make dataset resource file dataset ops py the if self num threads is None triggers the call to gen dataset ops parallel map dataset which then raises the error I suspect a cast from int32 to int64 got lost somewhere in that function Source code logs,,shivaniag,2017-08-02 15:01:04,2017-08-03 22:23:39
IS,ERROR Skipping ' tensorflow tools pip package build pip package' error loading package 'tensorflow tools pip package' Encountered error while reading extension file 'cuda build defs bzl' no such package ' local config cuda cuda',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 4 TensorFlow installed from source or binary source TensorFlow version use command below Python version Bazel version if compiling from source 0 5 3 CUDA cuDNN version 6 0 21 GPU model and memory Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem I know someone had reported the same issue Their solution is to roll back bazel to 0 5 2 But it does not work on my machine Does anyone know how to fix this problem without the need of rolling back bazel Thx tensorflow git sudo bazel build config opt config cuda tensorflow tools pip package build pip package WARNING ignoring http proxy in environment ERROR Skipping ' tensorflow tools pip package build pip package' error loading package 'tensorflow tools pip package' Encountered error while reading extension file 'cuda build defs bzl' no such package ' local config cuda cuda' Traceback most recent call last File home intel DevLib tensorflow git third party gpus cuda configure bzl line 1039 create local cuda repository repository ctx File home intel DevLib tensorflow git third party gpus cuda configure bzl line 976 in create local cuda repository host compiler includes repository ctx cc File home intel DevLib tensorflow git third party gpus cuda configure bzl line 145 in host compiler includes get cxx inc directories repository ctx cc File home intel DevLib tensorflow git third party gpus cuda configure bzl line 120 in get cxx inc directories set includes cpp depsets cannot contain mutable items WARNING Target pattern parsing failed ERROR error loading package 'tensorflow tools pip package' Encountered error while reading extension file 'cuda build defs bzl' no such package ' local config cuda cuda' Traceback most recent call last File home intel DevLib tensorflow git third party gpus cuda configure bzl line 1039 create local cuda repository repository ctx File home intel DevLib tensorflow git third party gpus cuda configure bzl line 976 in create local cuda repository host compiler includes repository ctx cc File home intel DevLib tensorflow git third party gpus cuda configure bzl line 145 in host compiler includes get cxx inc directories repository ctx cc File home intel DevLib tensorflow git third party gpus cuda configure bzl line 120 in get cxx inc directories set includes cpp depsets cannot contain mutable items INFO Elapsed time 4 064s FAILED Build did NOT complete successfully 0 packages loaded currently loading tensorflow tools pip package,,,2017-08-03 06:04:50,2017-08-03 22:42:18
IS,Errors,Hi I am running a simple tensor flow script and I am getting the following errors OS is macOS Tensorflow binary 1 2 1 version python version 3 5 The thing is it runs on the Jupyter notebook buy when I run python add py I get the following errors,,gautam1858,2017-08-03 09:00:45,2017-08-03 22:44:00
IS,Warning when running rnn commons select last activations TensorFlow 1 2 1,I see the following warning usr local lib python2 7 dist packages tensorflow python ops gradients impl py 93 UserWarning Converting sparse IndexedSlices to a dense Tensor of unknown shape This may consume a large amount of memory,,,2017-08-03 14:33:02,2017-08-03 23:38:56
PR,Update parameterized docker build sh,typo Dockerilfe Dockerfile,,"benoitsteiner,benoitsteiner",2017-08-03 07:52:19,2017-08-04 02:55:03
PR,Branch 164170971,,,benoitsteiner,2017-08-03 20:44:14,2017-08-04 02:57:13
IS,tf contrib distributions percentile returning AttributeError,Hello I am trying to utilize tf contrib distributiions percentile as described in OS Platform and Distribution Ubuntu 14 04 TensorFlow installed from binary TensorFlow version 1 2 0 Python version 3 4 5 My invocation is as follows pctl val tf contrib distributions percentile grad values pctl Here is the error message that I get AttributeError 'module' object has no attribute 'percentile' I understand that the percentile feature was not available in 1 1 0 and it is now available in 1 2 0 Still why do I get the error,,shivaniag,2017-08-03 23:33:24,2017-08-04 05:03:12
IS,Tensorboard fails to add summaries without any warning,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-08-04 07:34:19,2017-08-04 07:35:04
PR,Update eigen and gemmlowp dependencies,This PR updates some dependencies which are required to make Tensorflow work on the ARM platform The first dependency Eigen has been updated to version 3 4 containing this fix The second one updates Gemmlowp with this fix with the issue reported on this thread issuecomment 319718323 The PR does not work as is simply because I was not able to upload the archives to Could someone points me to the right direction on how to do it Or do it in my place if I do not have the rights to do so Thank you,,,2017-08-04 11:07:17,2017-08-04 14:53:39
IS,refresh model for spark streaming with sv tf train Supervisor under sv managed session,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I made custom distributed mnist code with spark streaming based on TensorFlowOnSpark example OS Platform and Distribution CentOS 7 TensorFlow installed from source or binary Unmodified source with HDFS enabled TensorFlow version use command below 1 2 1 Python version Python 3 5 2 Anaconda 4 2 0 64 bit Bazel version if compiling from source bazel release 0 5 2 CUDA cuDNN version 8 0 5 1 10 GPU model and memory NVIDIA Geforce 1070 8GB shared by two yarn containers each has two excuetors The code works fine but with mode inference a yarn container will restore the model from logdir at the very beginning and use the same model during the whole prediction periode based on spark logging info for restoring event My question is is there a way that I can reload some new trained model same architecture under sv managed session periodically or after new model is generated Because at the same time the other yarn container with mode train produced new model Thanks for helping,,,2017-08-04 12:24:16,2017-08-04 15:33:32
PR,Fix typos,This PR fixes some typos attempst lenght and acessed,,taehoonlee,2017-08-04 08:53:31,2017-08-04 17:24:47
IS,Parallelize bottleneck creation in retraining script,Hi It might be possible to parallelize the creation of the bottleneck files in the Inception retraining script Currently it can only do a few images per second and if you have 100s of thousands of images it takes forever I could do it myself also and create a pull request if that is fine Thanks,,yaroslavvb,2017-08-04 00:15:11,2017-08-04 17:39:49
IS,No Module Named ' pywrap tensorflow internal' still without working solution,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes it is one general import command see below OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary From source nightly build tensorflow gpu 1 2 1 cp35 cp35m win amd64 whl from 2017 07 13 TensorFlow version use command below 1 2 1 command does not work it includes the failed command Python version 3 5 2 Bazel version if compiling from source Not compiled from source CUDA cuDNN version CUDA 8 0 cudnn64 5 dll Windows file description is NVIDIA CUDA CUDNN Library Version 8 0 54 GPU model and memory GPU NVidia Geforce 1050 Exact command to reproduce import tensorflow Describe the problem Importing TensorFlow causes an error Source code logs check tensorflow py produces python check tensorflow py ERROR Failed to import the TensorFlow module Python version is 3 5 TensorFlow is installed at C Users Steph AppData Local Programs Python Python35 lib site packages tensorflow All required DLLs are present Please open an issue on the TensorFlow GitHub page The issue was already reported to Stackoverflow Stackoverflow issue 45091193,,drpngx,2017-07-18 09:59:52,2017-08-04 20:20:07
IS,print out 'nan' for simple linear regression model,,,shivaniag,2017-08-04 08:48:47,2017-08-04 20:23:58
PR,Merge Rc2 back to master,,,av8ramit,2017-08-04 18:25:10,2017-08-04 20:45:09
IS,read batch file using filename queue when fit wide and deep model,Describe the problem I read records from files using typical pipeline Googleing the error I found that ValueError Passed Tensor should have graph attribute that is equal to current graph Returning the features or labels from a closure fails because a new tf Graph is created when you call model fit so any modifications to the graph e g tf contrib calls need to be made from within the input fn and therefore after the new graph has been instantiated alcorn How to read batch data using filename queue when fit DNNLinearCombinedClassifier model Thanks,,,2017-08-04 09:23:32,2017-08-04 21:14:40
IS,docs Broken link on Tool Developer is page,Source page Bad link graph run run2 pbtxt,,"shivaniag,alanyee",2017-08-04 16:58:25,2017-08-04 21:41:00
IS,tensorflow 1 2 1 TypeError sampled loss got an unexpected keyword argument 'logits',the code is def sampled loss labels inputs labels tf reshape labels 1 1 We need to compute the sampled softmax loss using 32bit floats to avoid numerical instabilities local w t tf cast w t tf float32 local b tf cast b tf float32 local inputs tf cast inputs tf float32 return tf cast tf nn sampled softmax loss weights local w t biases local b labels labels inputs local inputs num sampled num samples num classes self target vocab size tf float32 softmax loss function sampled loss Traceback most recent call last File predict py line 177 in module tf app run File home amax tensorflow 1 2 1 local lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File predict py line 159 in main decode File predict py line 40 in decode model create model sess True File home BD bd chenyi nlp code textsum textsum py line 144 in create model forward only forward only File home BD bd chenyi nlp code textsum seq2seq model py line 167 in init softmax loss function softmax loss function File home amax tensorflow 1 2 1 local lib python2 7 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 1221 in model with buckets softmax loss function softmax loss function File home amax tensorflow 1 2 1 local lib python2 7 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 1134 in sequence loss softmax loss function softmax loss function File home amax tensorflow 1 2 1 local lib python2 7 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 1089 in sequence loss by example crossent softmax loss function labels target logits logit TypeError sampled loss got an unexpected keyword argument 'logits',,shivaniag,2017-08-03 08:51:14,2017-08-04 21:47:09
IS,tf contrib util make ndarray is slow the first time it is run,System information Output of tf env collect sh tf env txt Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc1 479 g82456f9 1 2 1 rc1 Python version Python 3 5 2 Bazel version if compiling from source n a CUDA cuDNN version cuda libs usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 lib64 libcudart static a usr local lib python3 5 dist packages torch lib libcudart so 8 0 usr local cuda 7 5 doc man man7 libcudart 7 usr local cuda 7 5 doc man man7 libcudart so 7 usr local cuda 7 5 lib libcudart so 7 5 18 usr local cuda 7 5 lib libcudart static a usr local cuda 7 5 lib64 libcudart so 7 5 18 usr local cuda 7 5 lib64 libcudart static a GPU model and memory In my project it took 105 96585726737976 for the first run and 0 0005743503570556641 the second time and closer to 0 0003 afterwards Source code logs Here is the branch I was using And the line that took 105 seconds L34,,"wchargin,wchargin,yaroslavvb,wchargin",2017-08-04 17:32:07,2017-08-04 22:25:53
IS,Could you please provide a TensorFlow dll 32 bits many thanks,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,yaroslavvb,2017-08-04 19:25:21,2017-08-04 22:32:20
IS,Feature Request Video Decoder,A video decoder would make it much easier to work with video For instance something like tf image decode jpeg but for mp4 videos or some other format perhaps,,"shivaniag,shlens",2017-08-01 15:55:07,2017-08-04 22:52:59
PR,Fix debugger logic in r1 3,In tensorflow tensorflow 11952 I had set made some logic within debug grpc testlib return too early breaking some debugger related behavior This PR fixes that,,"chihuahua,chihuahua,caisq,caisq,caisq,chihuahua",2017-08-04 22:30:32,2017-08-05 03:35:02
IS,Could not restore attention ocr checkpoint via saver,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS Sierra 10 12 5 TensorFlow installed from source or binary created environment in conda then installed tf via pip TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version 2 7 Bazel version if compiling from source Not installed CUDA cuDNN version No GPU supported GPU model and memory No Exact command to reproduce python test py You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Hi I am trying to use attention ocr in my own data a simple test is firstly implemented according to the instructions from How to use a pre trained model how to use a pre trained model but somehow failed in restoring the checkpoints without explicit error info The following condition has been checked 1 checkpoint files are complete 2 right path to the checkpoint 3 graphs have been imported from meta 4 Nothing changes after run saver train restore predictions remained the same 5 No error or hints provided The checkpoint was downloaded as suggested,,,2017-08-06 09:11:35,2017-08-06 09:40:22
IS,The name 'final result 0' refers to a Tensor which does not exist The operation 'final result' does not exist in the graph,System information Linux Ubuntu 16 04 Tensorflow 1 2 1 Having done a clean install of Tensorflow I have rebuilt the model using training data which went fine On classifying I receive Any ideas Thanks in advance,,,2017-08-06 17:56:28,2017-08-06 18:16:04
PR,Upgrade protobuf version to fix A protocol message was rejected because it was too big more than 67108864 bytes error,custom package 3 1 0 still get this A protocol message was rejected because it was too big more than 67108864 bytes error but 3 2 0 get it fixed,,"yjmade,benoitsteiner,martinwicke,jhseu,jhseu,yjmade,jhseu,yjmade",2017-08-03 05:14:13,2017-08-07 02:40:09
IS,the efficiency of StagingArea on gpu,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 2 0 2809 g7add4e6 1 2 1 rc2 Python version Python 3 5 2 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory 8 1080ti cards each 11172MB Exact command to reproduce see below Describe the problem I test the efficiency of StagingArea as described in on GPU compared to direct feed dict to session run input method The script shows these two methods have almost same speed all about 34 seconds But if I put all inputs to StagingArea first the script just need 23 seconds to run StagingArea method can not hide data copy time Source code logs,,"suiyuan2009,ppwwyyxx,suiyuan2009,suiyuan2009,ppwwyyxx,suiyuan2009,suiyuan2009,ppwwyyxx",2017-08-06 14:13:47,2017-08-07 05:55:44
PR,Make plugin data optional instead of repeated,This patches tensorflow tensorflow 11952 into master Here is that PR is description Every summary op writes data for a single plugin to process Hence each SummaryMetadata proto should have a single PluginData optional field instead of a repeated one This removes much complexity from TensorBoard logic that loops over the plugin data It also simplifies the SQL schema it can now enforce a one to one relationship between summary op and plugin,,"chihuahua,chihuahua,chihuahua,jart,chihuahua,caisq,chihuahua,chihuahua,caisq,chihuahua",2017-08-03 17:45:31,2017-08-07 08:57:40
PR,Branch 164309367,,,benoitsteiner,2017-08-04 21:33:39,2017-08-07 17:05:00
IS,Model callbacks do not work in TF r1 2 and Keras functional API Python 3 6 windows 10,Two test cases were constructed in order to show better the problem with Model callbacks which do not work in TF r1 2 and Keras functional API 1 Callbackes were used in the following way checkpoints import tensorflow contrib keras as K filedest models weights model011a best hdf5 checkpoint K callbacks ModelCheckpoint filedest monitor 'val acc' verbose 1 save best only True mode 'max' checkRLR K callbacks ReduceLROnPlateau monitor 'val acc' factor 0 1 patience 7 min lr 1 0e 10 earlyStop K callbacks EarlyStopping monitor 'val acc' patience 30 tbgraph K callbacks TensorBoard log dir ' graphs' histogram freq 1 write graph True write images False embeddings freq 1 callbacks list checkpoint earlyStop checkRLR tbgraph and then history model fit X train y train 11200 validation data X test y tst cat 7200 epochs epochs batch size 40 shuffle True callbacks callbacks list verbose 0 That resulted in successful run through the training session but with the following info INFO tensorflow Summary name embedding embeddings 0 is illegal using embedding embeddings 0 instead INFO tensorflow Summary name conv1d kernel 0 is illegal using conv1d kernel 0 instead INFO tensorflow Summary name conv1d bias 0 is illegal using conv1d bias 0 instead INFO tensorflow Summary name conv1d 1 kernel 0 is illegal using conv1d 1 kernel 0 instead INFO tensorflow Summary name conv1d 1 bias 0 is illegal using conv1d 1 bias 0 instead INFO tensorflow Summary name conv1d 2 kernel 0 is illegal using conv1d 2 kernel 0 instead INFO tensorflow Summary name conv1d 2 bias 0 is illegal using conv1d 2 bias 0 instead INFO tensorflow Summary name conv1d 3 kernel 0 is illegal using conv1d 3 kernel 0 instead INFO tensorflow Summary name conv1d 3 bias 0 is illegal using conv1d 3 bias 0 instead INFO tensorflow Summary name conv1d 4 kernel 0 is illegal using conv1d 4 kernel 0 instead INFO tensorflow Summary name conv1d 4 bias 0 is illegal using conv1d 4 bias 0 instead INFO tensorflow Summary name dense kernel 0 is illegal using dense kernel 0 instead INFO tensorflow Summary name dense bias 0 is illegal using dense bias 0 instead 2 Callbacks were used with Keras functional API in similar way described above The run resulted in similar info message PLUS the following C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras callbacks py 411 RuntimeWarning Can save best model only with val acc available skipping iskipping ' self monitor RuntimeWarning C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras callbacks py 499 RuntimeWarning Early stopping requires val acc available RuntimeWarning Traceback most recent call last File ipython input 1 70e23aa02b0a line 1 in module runfile 'C path to the files Test bugs NonTagTFmodel local v011 py' wdir 'C path to the files Test bugs' File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages spyder utils site sitecustomize py line 880 in runfile execfile filename namespace File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File C path Documents Python Scripts Recognition Run09recipes Test bugs NonTagTFmodel local v011 py line 149 in module callbacks callbacks list verbose 0 File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras engine training py line 1495 in fit initial epoch initial epoch File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras engine training py line 1158 in fit loop callbacks on epoch end epoch epoch logs File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras callbacks py line 96 in on epoch end callback on epoch end epoch logs File C path AppData Local Continuum Miniconda3 envs tensorflow lib site packages tensorflow contrib keras python keras callbacks py line 501 in on epoch end if self monitor op current self min delta self best TypeError unsupported operand type s for 'NoneType' and 'int' The same code TF r1 2 and Keras functional API runs perfectly alright if 'callbacks None' history model fit X train Y tr hot y tr cat 11200 validation data X test Y ts hot y ts cat 7200 epochs epochs batch size 40 shuffle True callbacks None verbose 1 What can be the reason for Model callbacks not working,,,2017-08-04 14:08:35,2017-08-07 18:08:40
PR,Fix typo,values is not defined,,"ppwwyyxx,rmlarsen",2017-08-07 06:18:46,2017-08-07 18:17:12
PR,Fix typo in RELEASE md,,,rmlarsen,2017-08-06 18:50:40,2017-08-07 18:31:03
IS,tf contrib xprof not supported on Windows,opts tf contrib tfprof model analyzer TRAINABLE VARS PARAMS STAT OPTIONS AttributeError module 'tensorflow contrib tfprof' has no attribute 'model analyzer' I have tensorflow version 1 2 and have made all the other transitioning changes and the above error was thrown later Has the contrib support been resolved for Windows Please help,,mrry,2017-06-25 17:58:48,2017-08-07 18:33:07
PR,Fix cmake builds,removed tpu sendrecv ops cc reflect this in cmake,,"guschmue,rmlarsen,mrry,rmlarsen",2017-08-04 19:59:20,2017-08-07 18:43:18
PR,fix a typo in tf nn separable conv2d is doc,It is obvious that the right bracket in sum di dj q r should be a right brace,,"freedomtan,rmlarsen,rmlarsen",2017-08-07 00:59:46,2017-08-07 19:09:26
PR,Update monitors test py,Move from contrib to training,,"alanyee,rmlarsen,rmlarsen",2017-08-06 16:35:04,2017-08-07 20:16:55
PR,OpenCL Fixes core rnn cell tests,SYCL uses the same implementation as the CPU one for BiasAdd,,"lukeiwanski,rmlarsen,rmlarsen,rmlarsen,rmlarsen,lukeiwanski",2017-08-07 12:49:23,2017-08-07 20:48:56
PR,MKL Removing visited node hash table fixing multinode shape mismatch issue,This PR fixes an issue that arises in multinode setup MklLayoutRewritePass maintains a hash table for visited nodes and the hash table is part of the pass and used for every graph being rewritten But it looks like in multinode setup multiple graphs may be processed simulteneously leading to incorrect modifications to the hash table So removing the hash table as we do not really need it,,"nhasabni,rmlarsen,nhasabni,rmlarsen,rmlarsen",2017-08-04 18:07:28,2017-08-07 20:49:11
PR,OpenCL Fix for tensorflow python kernel tests image ops test 111,,,"lukeiwanski,rmlarsen,rmlarsen,lukeiwanski",2017-08-04 16:26:28,2017-08-07 21:42:56
IS,TENSORFLOW CUDNN HOME NOT USED,When I build with cmake on windows10 there is always a warning CMake Warning Manually specified variables were not used by the project CUDNN HOME If I just ignore it there will be fatal errors about missing pb h files Can anyone help,,,2017-08-07 21:19:52,2017-08-07 21:49:30
PR,Fix segfault when recording raw allocation returns nullptr,See here commitcomment 23432313 for discussion,,"byronyi,rmlarsen,rmlarsen,rmlarsen,byronyi,rmlarsen,byronyi",2017-08-07 09:27:12,2017-08-07 22:16:31
IS,Issues with tensordot and axes is list of ints,,,"cancan101,yongtang",2017-08-01 21:17:03,2017-08-07 22:50:28
PR,Fix tensordot with list of ints as axes,This fix tries to fix the tensordot issue raised in 11950 where This fix fixes 11950 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,yongtang,rmlarsen",2017-08-02 03:26:55,2017-08-07 22:50:28
PR,Branch 164481383,,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen",2017-08-07 18:24:41,2017-08-07 23:55:11
PR,Revert Fix segfault when recording raw allocation returns nullptr,Reverts tensorflow tensorflow 12074 in favour of a complete fix in 9bb2c8e,,"byronyi,rmlarsen,rmlarsen,byronyi,byronyi",2017-08-07 22:21:45,2017-08-08 00:21:28
IS,bitwise ops and gen bitwise ops cannot be imported,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary Source TensorFlow version use command below 1 1 0 Python version 3 5 3 CUDA cuDNN version 8 0 60 GPU model and memory NVIDIA GeForce GT 730 Exact command to reproduce In the bitwise ops test py file located in the ops folder in python this code is there Also theres no gen bitwise ops file in the ops folder and the method is not available in the init file,,"aselle,mrry",2017-07-27 03:13:53,2017-08-08 02:47:39
IS,I got a type error without rhyme or reason when i rewrite a linear function in the rnn cell impl py,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 win64 TensorFlow installed from source or binary pip TensorFlow version use command below 1 2 Python version 3 6 CUDA cuDNN version ONLY CPU GPU model and memory ONLY CPU Exact command to reproduce No Describe the problem I want to write a lstm with batch normalization After i read the code of BasicLSTMCell i find i only need to wirte a linear function acording to this paper section 3 and the new batchlinear function is below here the only difference between batchlinear function and linear function is the arg mul it is weights separately and do it is batch normalization when i build a multi layer rnn like this logs are here Traceback most recent call last File ipython input 1 21f874a460ec line 1 in module runfile 'C Users Administrator Test char rnn py' wdir 'C Users Administrator Test' File C ProgramData Miniconda3 lib site packages spyder utils site sitecustomize py line 688 in runfile execfile filename namespace File C ProgramData Miniconda3 lib site packages spyder utils site sitecustomize py line 101 in execfile exec compile f read filename 'exec' namespace File C Users Administrator Test char rnn py line 25 in module final logits charRnn char seq batch seqlen batch charsize charsize num rnn num layers rnn numhidden rnn numhidden File C Users Administrator Test networks py line 221 in charRnn net tf nn dynamic rnn stack net seqlen batch dtype tf float32 File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn py line 574 in dynamic rnn dtype dtype File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn py line 737 in dynamic rnn loop swap memory swap memory File C ProgramData Miniconda3 lib site packages tensorflow python ops control flow ops py line 2770 in while loop result context BuildLoop cond body loop vars shape invariants File C ProgramData Miniconda3 lib site packages tensorflow python ops control flow ops py line 2599 in BuildLoop pred body original loop vars loop vars shape invariants File C ProgramData Miniconda3 lib site packages tensorflow python ops control flow ops py line 2549 in BuildLoop body result body packed vars for body File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn py line 720 in time step skip conditionals True File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn py line 206 in rnn step new output new state call cell File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn py line 708 in lambda call cell lambda cell input t state File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn cell impl py line 181 in call return super RNNCell self call inputs state File C ProgramData Miniconda3 lib site packages tensorflow python layers base py line 441 in call outputs self call inputs args kwargs File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn cell impl py line 917 in call cur inp new state cell cur inp cur state File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn cell impl py line 181 in call return super RNNCell self call inputs state File C ProgramData Miniconda3 lib site packages tensorflow python layers base py line 441 in call outputs self call inputs args kwargs File C Users Administrator Test networks py line 167 in call concat batchlinear args inputs h output size 4 self num units bias True File C Users Administrator Test networks py line 80 in batchlinear initializer kernel initializer File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 1065 in get variable use resource use resource custom getter custom getter File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 962 in get variable use resource use resource custom getter custom getter File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 360 in get variable validate shape validate shape use resource use resource File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 1405 in wrapped custom getter args kwargs File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn cell impl py line 184 in rnn get variable variable getter args kwargs File C ProgramData Miniconda3 lib site packages tensorflow python ops rnn cell impl py line 184 in rnn get variable variable getter args kwargs File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 352 in true getter use resource use resource File C ProgramData Miniconda3 lib site packages tensorflow python ops variable scope py line 653 in get single variable shape tensor shape as shape shape File C ProgramData Miniconda3 lib site packages tensorflow python framework tensor shape py line 798 in as shape return TensorShape shape File C ProgramData Miniconda3 lib site packages tensorflow python framework tensor shape py line 434 in init self dims as dimension d for d in dims iter File C ProgramData Miniconda3 lib site packages tensorflow python framework tensor shape py line 434 in listcomp self dims as dimension d for d in dims iter File C ProgramData Miniconda3 lib site packages tensorflow python framework tensor shape py line 376 in as dimension return Dimension value File C ProgramData Miniconda3 lib site packages tensorflow python framework tensor shape py line 32 in init self value int value TypeError int argument must be a string a bytes like object or a number not 'TensorShape',,,2017-08-08 03:51:08,2017-08-08 05:24:04
IS,what is the purpose of class StatsPublisherInterface,Describe the problem Tensorflow Open source version contains the class StatsPublisherInterface and a dummy implementation NoOpStatsPublisher I was wondering the design purpose of this class From the class name it seems that there is some other system that can subscribe the statistics of tensorflow step and display the information in realtime Can someone help ex Source code logs,,"yaroslavvb,suharshs",2017-08-07 04:07:31,2017-08-08 17:41:31
PR,Add framework for disabling C tests,This adds a small amount of scaffolding needed to get the disabled tests manifest into the runfiles for each test and set a string to the name of the file in the test macros rule,,"DavidNorman,hawkinsp,DavidNorman,DavidNorman,hawkinsp,hawkinsp,DavidNorman",2017-08-08 09:24:44,2017-08-08 18:34:35
IS,stream executor platform mutex h does not compile under C 14,Please go to Stack Overflow for help and support System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X with clang llvm 5 0 TensorFlow installed from source or binary source TensorFlow version use command below Python version Bazel version if compiling from source 0 4 5 Describe the problem There is an ifdef in mutex h that uses shared timed mutex when compiled as C 14 and up The file does not compile because C 14 requires using condition variable any rather than condition variable with that kind of mutex Source code logs,,"martinwicke,yongtang",2017-08-03 19:43:21,2017-08-08 18:36:40
PR,Fix build issue in c 14 for condition variable,This fix fixes the issue raised in 12017 where condition variable any has to be used in c 14 This fix defines ConditionVariableForMutex as std condition variable any in c 14 and std condition variable otherwise The fix is verified with This fix fixes 12017 Signed off by Yong Tang yong tang github outlook com,,"yongtang,hawkinsp,rmlarsen",2017-08-04 04:29:09,2017-08-08 18:36:40
PR,Disable codeowners due to noisiness,,,"jhseu,jhseu",2017-08-03 21:39:14,2017-08-08 18:37:30
IS,windows bazel build failed undeclared inclusion,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source TensorFlow version use command below 2ab9cb209babf905091dcff2f7cdce38da616cfe Python version 3 5 3 Bazel version if compiling from source 0 5 3 CUDA cuDNN version None GPU model and memory None Exact command to reproduce bazel output base C t build tensorflow tools pip package build pip package Describe the problem ERROR C os tensorflow tensorflow core BUILD 1271 1 undeclared inclusion s in rule ' tensorflow core lib internal' this rule is missing dependency declarations for the following files included by 'tensorflow core framework variant tensor data cc' 'C os tensorflow tensorflow core framework tensor h' 'C os tensorflow tensorflow core framework allocator h' 'C os tensorflow tensorflow core framework numeric types h' 'C os tensorflow tensorflow core framework type traits h' 'C os tensorflow tensorflow core framework variant h' 'C os tensorflow tensorflow core framework type index h' 'C os tensorflow tensorflow core framework tensor shape h' 'C os tensorflow tensorflow core framework tensor types h' 'C os tensorflow tensorflow core framework types h' 'C os tensorflow tensorflow core framework bfloat16 h' Source code logs,,"snnn,snnn,meteorcloudy",2017-08-03 03:24:45,2017-08-08 18:40:10
PR,Simplify tensorflow core BUILD,Fix 11985,,"snnn,meteorcloudy,rmlarsen,gunan",2017-08-03 04:05:18,2017-08-08 18:40:10
IS,tf contrib slim nets moved,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version Python 3 5 2 Bazel version if compiling from source CUDA cuDNN version 8 0 44 5 1 GPU model and memory Nvidia Tesla P100 Exact command to reproduce import tensorflow as tf vgg tf contrib slim nets vgg Describe the problem The Problem is that slim does not seem to contain the directory nets anymore even though in the repo it is still there It is also still in the slim docs Source code logs import tensorflow as tf vgg tf contrib slim nets vgg Traceback most recent call last File stdin line 2 in module AttributeError module 'tensorflow contrib slim' has no attribute 'nets',,,2017-08-08 15:35:16,2017-08-08 18:54:40
PR,Added an UpdateInput method to the Python C API,This is the only current limitation I see for allowing the implementation of gradients through the C API for while loops this relates to our discussion in 10089 and could provide a temporary solution until we have a more elegant solution Since it is in the python api h interface similar to AddControlInput I hope accepting this does not cause any issues,,"eaplatanios,eaplatanios,skye,eaplatanios,skye,eaplatanios,skye,rmlarsen,skye",2017-08-02 04:17:38,2017-08-08 19:17:24
PR,Enable passing scope to variable lookups,NB Changes the public API albeit in a backwards compatible way Especially when copying variables between scopes it is handy to be able to grab sets of variables by scope This allows the much more succinct tf trainable variables myscope which is equivalent to tf get collection tf GraphKeys TRAINABLE VARIABLES myscope Also fixup a minor unrelated documentation bug,,"darrengarvey,jhseu,josh11b,alextp,darrengarvey,alextp,darrengarvey,darrengarvey,josh11b,alextp,darrengarvey,alextp,vrv,darrengarvey,alextp",2017-07-19 20:41:37,2017-08-08 19:22:42
PR,Updating release notes known failures regarding Bazel 0 5 3,,,"av8ramit,rmlarsen,av8ramit,ahundt,ahundt",2017-08-07 23:20:06,2017-08-08 19:24:51
PR,,Descrition Fix the bug that Tensorflow on Windows running into issues when there is UTF8 encoded characters in the file path Solution Switch to use WideChar API calls for Windows like the CreateFileW FindFirstFileW FindNextFileW LoadLibraryExW Test Install Tensorflow on Windows with path have Chinese characers in it No issue Run command from tensorflow contrib rnn python ops gru ops import No issue,,"mrry,mrry,mrry,mrry,mrry,jhseu,jhseu,vrv,vrv,vrv,vrv,mrry,mrry,mrry",2017-07-17 23:03:19,2017-08-08 19:30:13
IS,I configured ops to register h and set define SHOULD REGISTER OP GRADIENT false but unexpectedly the generated libtensorflow inference so file get larger,Describe the problem I configured ops to register h as below define SHOULD REGISTER OP op true define SHOULD REGISTER OP GRADIENT false define SHOULD REGISTER OP KERNEL clz true set SHOULD REGISTER OP GRADIENT false And then I used command below to generate libtensorflow inference so file bazel build c opt copt DSELECTIVE REGISTRATION copt DSUPPORT SELECTIVE REGISTRATION tensorflow contrib android libtensorflow inference so host crosstool top bazel tools tools cpp toolchain crosstool top external android crosstool cpu armeabi v7a I expected that this configuration will reduce gradient operations and make the genereted libtensorflow inference so file smaller But unexpectedly the generated file is 16M while the so file generate by command below which will include all operators is 9 7M bazel build c opt tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a Question I can not understand why the so file get larger when I set SHOULD REGISTER OP GRADIENT false than the original so file which include all operators Could you please explain it to me Thank you very much and hope for your answer,,"andrewharp,andrewharp",2017-08-08 03:03:51,2017-08-08 19:45:31
PR,Update variables py,Added deprecated message,,"alanyee,alanyee,rmlarsen,martinwicke,rmlarsen",2017-08-07 19:10:23,2017-08-08 19:55:25
PR,show proper error message when run saved model cli without arguments instead of an error said AttributeError 'Namespace' object has no attribute 'func',before,,"yjmade,rmlarsen,rmlarsen",2017-08-08 11:02:01,2017-08-08 19:55:39
IS,A bug of tf reduce logsumexp with inf,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS 7 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Python version 2 7 13 Bazel version if compiling from source CUDA cuDNN version 8 0 5 1 3 GPU model and memory Tesla K40m 11439MiB Exact command to reproduce python c import tensorflow as tf print tf Session run tf reduce logsumexp float ' inf' Describe the problem The doc of tf reduce logsumexp says it Computes log sum exp elements across dimensions of a tensor However it does not when the tensor is inf Source code logs,,"aselle,aselle",2017-07-23 15:20:45,2017-08-08 20:01:28
PR,Fix tf reduce logsumexp to accept inf,Fix 11692,,"vrv,vrv,rmlarsen,rmlarsen",2017-07-25 18:21:44,2017-08-08 20:01:28
IS,Is tf matrix inverse supported for TF v 1 2,I notice that the Tensorlfow computation op tf matrix inverse was not supported running on GPU in the previous versions and I wonder if it is supported for Tensorflow v 1 2 now If it is still not can we make a feature request for it Thanks,,yaroslavvb,2017-08-01 23:11:42,2017-08-08 20:31:07
PR,Make Windows Bazel GPU build work again,This change mainly fixed the Windows GPU build Besides it also has some other fixes and improvments 1 print installed Bazel version in configure py 2 Remove slice op gpu cu cc from strided slice op because it is already in slice op 3 Mark some failing GPU tests as no windows gpu 4 Add DNOGDI flag for some targets to fix GPU build 5 Update TF CUDNN VERSION to 6 0 6 add test filters no gpu no pip gpu,,"meteorcloudy,gunan,gunan,gunan,meteorcloudy,meteorcloudy,meteorcloudy,gunan,meteorcloudy,gunan,gunan,meteorcloudy",2017-07-31 08:50:07,2017-08-08 20:37:02
IS,How can train my own model in tensorflow using Flickr image dataset How can i convert data into train val test modules,,,rohan100jain,2017-08-08 18:25:06,2017-08-08 22:04:27
PR,remove duplicated code,remove duplicated code and merge two implements,,"horance-liu,rmlarsen",2017-07-27 22:43:54,2017-08-08 22:07:27
PR,XLA RNG root instruction can be fused as it effectively has one user,The existing test checks for a single user when trying to fuse a random number generator instruction This is because if it is fused but has multiple users the value may be generated an incorrect number of times multiple users should receive the same random number not different ones The test checks for users length 1 This ignores the case there the instruction is the root where users length 0 but there is effectively one user,,"DavidNorman,DavidNorman,DavidNorman,DavidNorman,DavidNorman,vrv,DavidNorman,vrv,DavidNorman,DavidNorman,vrv,rmlarsen",2017-07-28 14:20:37,2017-08-08 22:12:03
PR,fix link for installing page,,,"benoitsteiner,benoitsteiner,rmlarsen",2017-07-29 14:06:18,2017-08-08 22:12:33
PR,XLA Remove overly chatty output in fusion operation,when fusing a lot of operations in a large graph this trace produces a lot of output It is not really output that is helpful when trying to trace the high level operations occuring Perhaps it is better at a lower log level,,"DavidNorman,tatatodd,DavidNorman,DavidNorman,tatatodd,tatatodd,tatatodd,rmlarsen,tatatodd,rmlarsen",2017-07-29 14:15:50,2017-08-08 22:14:50
PR,Increase docstring consistency,This PR considers the following six main items Adjusting indents of markdown code blocks Adding language identifiers on markdown code blocks Replacing Return with Returns The frequencies over all python codes 2 vs 3369 Replacing Arguments with Args Args is a consistent word over all python codes except tensorflow contrib keras and tensorflow python layers In tensorflow python framework tensor shape py removing for consistency on the file In tensorflow python ops array ops py and math ops py revising python code blocks to make them more concrete I think it is better to replace with because is not a python keyword For each operation two styles with and without tf are mixed I think it is better to make them as tf operation not operation For more concrete examples I think it is better to write down real tensors not pseudo e g 'x' is 1 4 is replaced by x tf constant 1 4,,"taehoonlee,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,taehoonlee,MarkDaoust,rmlarsen",2017-08-01 07:27:29,2017-08-08 22:15:12
PR,Fix MPI and Verbs compilation errors,This fixes the following compilation error when building TensorFlow with MPI and or Verbs support error 'gpr allocation functions' was not declared in this scope It looks like the latest gRPC changes some of the default includes and you have to manually include the alloc header,,"jbedorf,jhseu,rmlarsen",2017-08-01 08:36:18,2017-08-08 22:15:41
PR,Disable denormal test on ppc64le platform,Please find the relevant discussion L43 L73 MM GET FLUSH ZERO MODE MM GET DENORMALS ZERO MODE MM SET FLUSH ZERO MODE MM SET DENORMALS ZERO MODE Some embedded machines perform slight better in this mode but POWER servers do not So for POWER you do not need this and should simply disable it,,"sandipmgiri,gunan,sandipmgiri,sandipmgiri,gunan,rmlarsen,rmlarsen",2017-08-01 10:08:35,2017-08-08 22:17:10
PR,R1 2,miss,,,2017-08-04 13:59:25,2017-08-08 22:20:59
PR,Branch 164623298,,,"rmlarsen,rmlarsen,rmlarsen",2017-08-08 19:30:56,2017-08-08 23:22:13
IS,Tensorflow GPU import error,System information OS Platform Windows 10 Pro x64 TensorFlow installed from pip install tensorflow gpu TensorFlow version use command below 1 2 1 Python version 3 5 3 CUDA cuDNN version CUDA8 0 cuDNN v7 GPU model and memory GTX 1050 Exact command to reproduce,,,2017-08-08 04:18:54,2017-08-09 02:25:43
IS,tensorflow python kernel tests denormal test test failure on ppc64le error Arrays are not equal,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version Python 2 7 5 Bazel version if compiling from source 0 4 5 2017 07 13 037b9b9 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel test test output errors tensorflow python kernel tests denormal test Describe the problem Following code returning incorrect results L36 L44,,"sandipmgiri,sandipmgiri,sandipmgiri,drpngx,gunan,sandipmgiri",2017-07-31 09:08:29,2017-08-09 03:27:10
IS,tf shape return wrong shape,I have a png image of shape 128 128 3 tf shape r returns Tensor load images Shape 0 shape 3 dtype int32 while numpy shape r returns 128 128 3 tensorflow 1 1 0,,,2017-08-09 09:36:07,2017-08-09 14:19:19
IS,Link to Linux and Mac OS broken in TF for Java README,The link to Linux and Mac OS under section Building from Source building from source is broken,,yongtang,2017-08-09 12:40:54,2017-08-09 14:19:37
PR,Fix broken URL in tensorflow java README md,Fixes broken URL in tensorflow java README md this fix fixes 12141 Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-08-09 13:54:12,2017-08-09 14:19:37
PR,Branch 164665656,,,rmlarsen,2017-08-09 00:41:17,2017-08-09 14:26:22
IS,Using higher order operators within tf contrib data Dataset map raises a segmentation fault,System information Have I written custom code Yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 'v1 2 0 2323 geaa7a8e' '1 3 0 rc0' Python version 2 7 6 CUDA cuDNN version 8 0 GPU model and memory GTX 1080 8GB Exact command to reproduce see the code snippet below Describe the problem When using a higher order operator such as tf map fn within the tf contrib data Dataset map method the program exits with a Segmentation fault Source code logs My particular use case is to split a sentence into tokens and then map a function on each token to build tensors of characters,,"guillaumekln,reedwm,mrry",2017-07-24 10:12:08,2017-08-09 14:26:45
IS,Assert randomly fails when training with multiple threads,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 rc2 Python version 2 7 12 Bazel version if compiling from source 0 4 5 CUDA cuDNN version no GPU model and memory no Exact command to reproduce for n 0 n 100 n do python mnist softmax parallel issue py done Describe the problem The following script randomly crashes i e sometimes crashes and produces this traceback most of the times it does not The script trains the MNIST softmax model in parallel leveraging several threads Source code logs mnist softmax device issue py Traceback external eigen archive unsupported Eigen CXX11 src Tensor TensorBroadcasting h 125 Eigen TensorEvaluator const Eigen TensorBroadcastingOp Broadcast XprType Device T ensorEvaluator const XprType const Device with Broadcast const Eigen IndexList Eigen type2index 1l int ArgType const Eigen TensorMap Eigen Tensor float 2 1 long int 16 Eigen MakePointer Device Eigen ThreadPoolDevice Eigen TensorEvaluator const Eigen TensorBroadcastingOp Broadcast XprType Device XprType Eigen TensorBroadcastingOp const Eigen IndexList Eigen type2index 1l int const Eigen TensorMap Eigen Tensor float 2 1 long int 16 Eigen MakePointer Assertion input dims i ' failed,,,2017-08-07 13:11:05,2017-08-09 15:20:30
IS,My TensorBoard is not showing any data,System Ubuntu 16 04 Tensorflow built from source for python3 tensorboard inspect logdir Logdirpath correctly outputs my logs with e g sessionlog checkpoint first step 0 last step 25302 max step 25302 and scalars Validation Accuracy batch fraction of 240 full global step sec parallel read filenames fraction of 32 full parallel read fraction of 204 full tensorboard logdir Logdirpath outputs Starting TensorBoard b'55' at http 6006 Press CTRL C to quit but opening the link in firefox just shows a blank page As does the command with debug,,tatatodd,2017-08-07 13:39:46,2017-08-09 15:51:49
IS,Tensorboard Error on windows,I want to use tensorboard on windows but when I am going to start it its shows this error when is run localhost 6006 in my chrome browser screenshot 140,,"tatatodd,tatatodd",2017-08-05 12:35:41,2017-08-09 15:52:34
PR,NHWC optimizations MKL,Update MKL link to point to latest version mklml lnx 2018 0 20170720 Also undoes workarounds previously added for NHWC conversions,,"agramesh1,jart,jart,rmlarsen,rmlarsen,rmlarsen,agramesh1,rmlarsen,martinwicke,rmlarsen,agramesh1,rmlarsen,rmlarsen,agramesh1,rmlarsen,rmlarsen",2017-07-31 18:48:31,2017-08-09 15:53:12
PR,Alpha Dropout,Fixes 10612,,"AnishShah,vrv,ebrevdo,AnishShah,AnishShah,ebrevdo,vrv,AnishShah,AnishShah,thesuperzapper,AnishShah,vrv,AnishShah,vrv,AnishShah,vrv,AnishShah,rmlarsen,rmlarsen",2017-07-07 16:58:02,2017-08-09 15:57:30
IS,tf contrib data Iterator make initializer operation lacks name,I'm using tf contrib data for my input pipeline Since it feeds the model without placeholders I need to be able to reload both the model and input pipeline in order to resume training later However the make initializer method of tf contrib data Iterator does not have a name argument like most all other Tensorflow operations making it impossible or at best error prone to find these ops in the reloaded graph Unless I'm mistaken this seems like a standard use case and the missing name argument is inconsistent with the rest of Tensorflow,,"yaroslavvb,yongtang,yaroslavvb",2017-08-07 17:55:25,2017-08-09 15:57:44
PR,Add name field for tf contrib data Iterator make initializer operation,This fix adds name fields for tf contrib data Iterator make initializer operation This fix fixes 12083 Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry,yongtang,yongtang,mrry",2017-08-08 23:41:57,2017-08-09 15:57:44
PR,GPUDirect RDMA Out of Band Tensor Transport,Introduction This PR implements GDR out of band transport for TensorFlow distributed runtime complementary to current gRPC transport It uses gRPC as control plane to setup rendezvous for each tensor transmission and utilizes GPU Direct RDMA whenever possible to transmit tensors in remote GPU memory through network interface card NIC bypassing host memory and CPU entirely It gracefully falls back to ordinary RDMA or even gRPC when GDR is not available Design The GDR out of band transport is designed to avoid any unnecessary memory copies especially for large tensors 100MB That typically requires registration of tensor buffers to NIC on the fly which is rather slow as described in the design trade off of the verbs runtime The verbs runtime thus chooses to manage its own NIC registered buffers and copy the tensors from to those buffers for every single tensor transfer We show that however such design trade off is not always relevant In this patch we manage both computation and communication buffers in a unified manner By pre registration of large buffers to NIC and allocating small tensors from the buffer pool using a BFC allocator it is possible to avoid both buffer registration on the fly and memory copies all together For the actual tensor transport we rely on gRPC to transmit the remote buffer information This greatly simplifies our design and there are only 2 types of RDMA messages a single READ to retrieve the tensor data bypassing remote CPU and another invalidate using WRITE with IMM to release the tensor buffer on the remote side The remote side will only be polling the invalidate message and Unref the tensor buffers that read by its peer Environment To fully utilize GDR the target environment has to meet 3 conditions 1 There is an RDMA capable device with corresponding OFED package installed detailed information is available from your Infiniband RoCE iWarp vendor which could be verified through ibv devinfo e g The last line suggests that the GPUs with bus id 2 mapped to pci bus id prefixed 0000 8 will benefit from GDR and host memory bypass which is gpu 2 and gpu 3 in this case Caveats In current implementation only tensors that reside in host memory or in GPU memory such that the GPU is adjacent to an RDMA capable NIC will use direct RDMA as its transport When RDMA is available but not GDR a temporary tensor copy on host memory will be used as RDMA source destination and copied from to the target device When there is no RDMA device present it can even fallback to the original gRPC runtime While it is theoretically possible to mix GDR enabled TF with non GDR deployments in the same job make sure the environment is properly setup so the GDR mode is enabled whenever possible i e do not fall back to gRPC when it is not absolutely necessary,,"byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,drpngx,drpngx,byronyi,byronyi,byronyi,drpngx,gunan,byronyi,byronyi,drpngx,byronyi,drpngx,byronyi,byronyi,byronyi,drpngx,byronyi,drpngx,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,drpngx,byronyi,gunan,jart,byronyi,drpngx,byronyi,byronyi,drpngx,byronyi,vrv,byronyi,suiyuan2009,suiyuan2009,suiyuan2009,byronyi,byronyi,byronyi,byronyi,gunan,byronyi,suiyuan2009,byronyi,byronyi,suiyuan2009,byronyi,byronyi,byronyi,vrv,byronyi,byronyi,byronyi,drpngx,byronyi,byronyi,suiyuan2009,byronyi,byronyi,byronyi,byronyi,martinwicke,byronyi,martinwicke,byronyi,martinwicke,byronyi,rmlarsen,rmlarsen,byronyi,suiyuan2009,byronyi,byronyi,byronyi",2017-07-09 11:33:03,2017-08-09 15:58:13
IS,tf einsum does not have name variable,I noticed there is no ability to name a tensor generated from from tf einsum Is this on purpose,,"mrry,jart,yongtang",2017-07-14 15:46:17,2017-08-09 15:59:08
PR,Add name variable support for tf einsum,This fix adds name variable support for tf einsum This fix fixes 11501 Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,vrv,josh11b,yongtang,vrv,yongtang,vrv,josh11b,rmlarsen,rmlarsen,yongtang,rmlarsen",2017-07-15 00:21:43,2017-08-09 15:59:08
PR,SGDR Learning Rate Decay Algorithm,Implementation of SGDR Stochastic Gradient Descent with Warm Restarts by Ilya Loshchilov Frank Hutter Developed together with the author Adds cosine annealing for learning rate decay 11113 mmul,,"vrv,vrv,vrv,vrv,vrv,vrv,vrv,vrv,vrv,vrv,vrv,rmlarsen,vrv,vrv",2017-07-25 13:20:03,2017-08-09 15:59:44
IS,Tensorflow bezel command line c options does not pass down to gcc if static object is compiled,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 1 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 rc1 Python version 2 7 Bazel version if compiling from source 0 5 1 CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce bazel build copt DEIGEN USE MKL VML c opt tensorflow tools pip package build pip package s Describe the problem When I compile TensorFlow with bazel I found the c option I put in the bazel command line only passed to the object file for a dynamic library with fPIC option not the object file for a static library without fPIC For example I ran the following command bazel build copt DEIGEN USE MKL VML c opt tensorflow tools pip package build pip package s I expect DEIGEN USE MKL VML passed down to gcc but it does not for o For example the gcc command line for external nasm labels c is the following cd nfs pdx home sfu2 cache bazel bazel sfu2 fec016c4b4f3097e22950dbc1f4b848d execroot private tensorflow exec env LD LIBRARY PATH nfs pdx home sfu2 gcc install lib64 usr lib64 usr local lib PATH nfs pdx home sfu2 bin usr bin usr local bin usr lib64 qt 3 3 bin nfs pdx home sfu2 perl5 bin usr local bin usr bin usr local sbin usr sbin PWD proc self cwd usr bin gcc U FORTIFY SOURCE fstack protector Wall B usr bin B usr bin Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections g0 MD MF bazel out host bin external nasm objs nasm external nasm labels d DHAVE SNPRINTF iquote external nasm iquote bazel out host genfiles external nasm iquote external bazel tools iquote bazel out host genfiles external bazel tools isystem external bazel tools tools cpp gcc3 w ' std c99' fno canonical system headers Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c external nasm labels c o bazel out host bin external nasm objs nasm external nasm labels o You can see the c option DEIGEN USE MKL VML is not on the command line Is it a bug in TensorFlow build script,,tatatodd,2017-08-07 16:45:48,2017-08-09 16:05:18
IS,Compiling from source,I am trying to compile tensorflow from source as the pip version is compiled on older version of cuDNN System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version use command below Python version 2 7 Bazel version if compiling from source Build label 0 5 3 CUDA cuDNN version CUDA 8 cuDNN 7 0 1 GPU model and memory GTX 1080 Ti and VRAM 11GB RAM 32 GB Exact command to reproduce Trying to compile with Describe the problem Unable to compile from source I tried the binary but it uses an old version of cuDNN I am using 7 0 1 Source code logs ERROR home ntweat tensorflow tensorflow stream executor BUILD 39 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 crosstool wrapper driver is not gcc failed error executing command exec env CUDA TOOLKIT PATH usr local cuda CUDNN INSTALL PATH usr local cuda 8 0 GCC HOST COMPILER PATH usr bin gcc PWD proc self cwd PYTHON BIN PATH usr bin python2 7 PYTHON LIB PATH usr local lib python2 7 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 6 1 TF CUDA VERSION 8 0 TF CUDNN VERSION 7 0 1 TF NEED CUDA 1 TF NEED OPENCL 0,,"tatatodd,tatatodd",2017-08-07 22:48:53,2017-08-09 16:27:23
IS,Build error with Tensorflow 1 3 0 and cuDNN 7 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Arch Linux TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source 0 5 3 for Arch Linux CUDA cuDNN version CUDA 8 0 61 cuDNN 7 0 1 GPU model and memory NVIDIA GeForce GTX 960M Exact command to reproduce bazel build config opt config mkl config cuda tensorflow tools pip package build pip package Describe the problem I can not build tensorflow from source with cuDNN 7 as it throws an error pertaining to cuDNN I'm currently using a tensorflow 1 2 1 built earlier from sources using cuDNN 6 Source code logs,,tatatodd,2017-08-09 10:08:58,2017-08-09 16:28:20
IS,WARNING tensorflow The default stddev value of initializer will change from 1 sqrt vocab size to 1 sqrt dimension after 2017 02 25,I got this warning message when set Deep Model Warning message Please advice Thank you,,tatatodd,2017-08-08 01:39:29,2017-08-09 16:29:59
PR,Update README md,Fixed Stale URL in Tutorial Link,,"caisq,av8ramit",2017-08-09 12:50:33,2017-08-09 16:42:41
PR,Ensure that bazel versions of the form X Y Z mmmmm work correctly,The code in configure py does not allow for bazel versions which identify themselves as X Y Z mmmmm This is true for bazel on OS X installed through homebrew Recently some code that checks the version number has appeared and this is causing configurations built with OS X homebrew bazel to fail,,"DavidNorman,rmlarsen,DavidNorman,DavidNorman,rmlarsen,rmlarsen,DavidNorman,rmlarsen",2017-08-08 10:42:12,2017-08-09 16:56:11
PR,Update to monitors and tutorial,Removed tf learn SessionRunHook in favor of tf train SessionRunHook Remove unnecessary slash in tutorial,,"alanyee,martinwicke,rmlarsen",2017-07-31 20:17:05,2017-08-09 17:06:24
PR,OpenCL Fix allocator destruction race condition 136,OpenCL Changes SYCL Interface construction Uses C 11 static initialisation to provide singleton instance rather than a mutex and pointer OpenCL Adds const to SYCL Interface methods OpenCL Fix allocator destruction race condition A Tensor is allocator must outlive it however there is no easy way to determine whether an Allocator has any Tensors still alive and so we cannot know when it is safe to destroy an allocator The CPU allocator gets round this by being deleted so we adopt this convention here OpenCL Reformats SYCL code OpenCL Fixes SYCL comments OpenCL Tidies SYCL device description Adds check for whether the QueueInterface pointer is valid as this may not always be the case OpenCL Adds nullptr checking to SYCL allocator OpenCL Adds const specifier to SYCL Interface,,"lukeiwanski,rmlarsen,rmlarsen,lukeiwanski,lukeiwanski,rmlarsen,rmlarsen,lukeiwanski,lukeiwanski,lukeiwanski,rmlarsen",2017-08-02 14:36:39,2017-08-09 17:07:59
IS,ckpt get in win7 anaconda cannot be used in win10 The same CNN structure and params,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatatodd,2017-08-09 07:34:57,2017-08-09 17:30:40
IS,EigenAllocator for GPU ran out of memory when allocating 0,Environment info Operating System Ubuntu 16 04 Installed version of CUDA and cuDNN CUDA 8 0 CUDNN 5 1 10 Tensorflow version r1 1 Hello does anyone encountered this error After some random number of iterations i'm getting the below exception Can anyone help me where its going wrong E tensorflow core common runtime bfc allocator cc 244 tried to allocate 0 bytes W tensorflow core common runtime allocator retry cc 32 Request to allocate 0 bytes F tensorflow core common runtime gpu gpu device cc 103 EigenAllocator for GPU ran out of memory when allocating 0 See error logs for more detailed info Aborted core dumped Regards Sharath,,tatatodd,2017-08-09 14:53:53,2017-08-09 17:48:18
IS,XLA Assert when running XLA unit test,If I run the test tensorflow compiler xla tests tuple test cpu with a VLOG level of 2 then I receive the following assert I do not think that this is due to any changes that I have in my own repo,,"DavidNorman,meheffernan",2017-08-09 10:17:16,2017-08-09 18:07:12
IS,Please add predict proba to estimators class not in TF1 3 DNN,Describe the problem Feature Request The TF learn library in TF1 2 has perdict proba for getting probability estimates for predictions it is particularly helpful for setting probability levels up or down or just measuring them it is a super helpful function for analysis as well as correlations can be drawn to input variables There are many use cases where you may want to accept a prediction with less than a 50 50 think unbalanced classs and there are other cases where you want greater certainty for some medical decisions or credit scoring The DNN class in TF 1 3 with the estimator does not seem to have this function while tf learn dnn in TF1 2 does Estimators seem to be the way of the future but at least IMHO we need this to make that move,,terrytangyuan,2017-08-08 21:10:23,2017-08-09 18:18:50
IS,Unable to load saved model,I am facing similar issue but for GRU I am using tensorflow 1 1 0 and I tried dumping the model in different ways a saver tf train Saver tf global variables model exporter exporter Exporter saver Restore variables from training checkpoint TODO This restores the most recent checkpoint but if we use validation to counterract over fitting we may want to restore an earlier checkpoint checkpoint tf train get checkpoint state FLAGS checkpoint dir checkpoint path checkpoint model checkpoint path saver restore session checkpoint path log info 'Restored checkpoint at training epoch d' int checkpoint path split ' ' 1 1 Initialise the model exporter and export the model model exporter init session graph as graph def named graph signatures 'inputs' exporter generic signature 'input' input tensor 'input lengths' seq length 'outputs' exporter generic signature 'outputs' decoded if FLAGS remove export actual export dir os path join FLAGS export dir ' 08d' FLAGS export version if os path isdir actual export dir log info 'Removing old export' shutil rmtree actual FLAGS export dir try Export serving model model exporter export FLAGS export dir tf constant FLAGS export version session Export graph input graph name 'input graph pb' tf train write graph session graph FLAGS export dir input graph name as text False Freeze graph input graph path os path join FLAGS export dir input graph name input saver def path '' input binary True output node names 'output node' restore op name isave restore all' filename tensor name isave Const 0' output graph path os path join FLAGS export dir 'output graph pb' clear devices False freeze graph freeze graph input graph path input saver def path input binary checkpoint path output node names restore op name filename tensor name output graph path clear devices '' b output graph def graph util convert variables to constants session session graph as graph def 'output node' with gfile FastGFile ' data ldc93s1 output graph2 pb' 'wb' as f f write output graph def SerializeToString but for both the dump I get the following error 'rnn while multi rnn cell cell 0 gru cell gates r cond rnn while multi rnn cell cell 0 gru cell gates r strided slice assign RefEnter' Input tensor 'rnn multi rnn cell cell 0 gru cell gates r pop mean 0' Cannot convert a tensor of type float32 to an input of type float32 ref Any solution so far I followed the similar bug but that is specifically related to Batch norm 3628 And what is the reason behind this,,rohan100jain,2017-08-09 16:37:59,2017-08-09 19:24:17
IS,Tensorflow Experiment shape mismatch between train set and test set,Hi guys I am not sure if this is a bug or my mistake but it looks like when the experiment evaluates with the testing set it expects it to be of the same shape as the training set First let me show you how I feed the experiment with the train set and eval set The results are as followed Monitors are deprecated Please use tf train SessionRunHook INFO tensorflow Create CheckpointSaverHook INFO tensorflow Saving checkpoints for 1 into model ckpt INFO tensorflow step 1 loss 0 043889 It works fine for the training set but when it evaluates on the test set I get the following error ValueError Features are incompatible with given information Given features Tensor Const 0 shape 1 100 1 dtype float32 required signatures TensorSignature dtype tf float32 shape TensorShape Dimension 1 Dimension 1000 Dimension 1 is sparse False Do you know where it comes from Thanks,,"rohan100jain,selcouthlyBlue",2017-08-09 15:44:41,2017-08-09 20:06:32
PR,Update estimator py,Replace summary io SummaryWriterCache for tf summary FileWriterCache,,"alanyee,rmlarsen,rmlarsen",2017-08-09 16:18:45,2017-08-09 22:29:14
PR,Branch 164739939,,,"rmlarsen,rmlarsen,caisq,rmlarsen,rmlarsen",2017-08-09 18:16:58,2017-08-09 22:31:58
PR,Branch 164782742,,,rmlarsen,2017-08-09 22:34:35,2017-08-09 22:35:46
IS,Where is device attributes pb h,I have to use the device attributes pb h and I do not know where it is Thank you,,asimshankar,2017-08-09 03:30:27,2017-08-09 22:51:57
PR,OpenCL Extends BiasAdd to cover integral types,,,"lukeiwanski,rmlarsen,rmlarsen",2017-08-09 14:50:43,2017-08-09 23:13:14
PR,Fix sparse matmul op test on Power LE,Fix for issue 12137 Add the pbroadcast functions for ppc this passes the sparse matmul op test on ppc64le,,"rmlarsen,rmlarsen",2017-08-09 10:03:01,2017-08-09 23:13:51
IS,bug with tf unique where index output is int64,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 OSX El Capitan 10 11 6 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc1 27 g2784b1c 1 3 0 rc2 Python version 3 5 2 Bazel version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce y idx tf unique x out idx tf int64 Describe the problem The API says tf unique supports tf int64 index output However no OpKernel supports such attributes Source code logs To reproduce,,"dantkz,yongtang,tatatodd",2017-08-08 15:45:54,2017-08-09 23:14:25
PR,Add int64 support for out idx of tf unique,This fix tries to address the issue raised in 12113 where tf unique does not support int64 for out idx The support of int64 was specified by the docs though The int64 support was enabled and additional tests were added This fix fixes 12113 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen",2017-08-09 04:23:03,2017-08-09 23:14:25
PR,Add idea into gitignore for JetBrains IDE,We usually use PyCharm for reading the source code of Tensorflow so it is necessary for most developers to add idea into gitignore for JetBrains IDE to ignore those non project files,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,cancan101",2017-08-08 01:28:47,2017-08-09 23:15:40
PR,OpenCL Fixes linking issue,c13cb2e5777852c6a498410669b24ac346114eba introduced linking issue that caused logging cc text 0xa64 undefined reference to tensorflow StringPiece Hasher operator tensorflow StringPiece const',,"lukeiwanski,rmlarsen,gunan",2017-08-09 13:45:51,2017-08-10 00:49:05
PR,Fix TODO avoiding serialization in gRPC GPU path,See 10530 and 10531 for the rationale,,"byronyi,byronyi,yaroslavvb,byronyi,byronyi,rmlarsen,byronyi",2017-07-04 04:54:47,2017-08-10 00:51:10
PR,Update the graph used in quantization tutorial,Another fix to quantization tutorial after 11285 Currently following the steps in the quantization tutorial how can you quantize your models will lead to weird results as pointed out in 11181 This is because the graph file and the evaluation script are unmatched From this image recognition tutorial there are two pretrained graphs with two evaluation scripts 1 classify image graph def pb in inception 2015 12 05 tgz is to be used with the older classify image py 1 inception v3 2016 08 28 frozen pb in inception v3 2016 08 28 frozen pb tar gz is to be used with label image The weird results came from using classify image graph def pb with label image The graphs are different see also models 1314 especially in the last layer The two scripts extract information from the last layer in different ways so it works with its corresponding graph but not the other Further changes 1 In the image recognition tutorial source the usage of Python API points to option 1 above but the C API points to option 2 This might cause confusion as the two graphs scripts are not equivalent Now that there is a python implementation of the newer label image by should we update the tutorial to use this python implementation instead 1 Should this graph transform README be updated as well Currently it uses the 2015 pre trained graph hence inputs 'Mul' outputs isoftmax' If it is updated to the 2016 graph these should instead say inputs input outputs InceptionV3 Predictions Reshape 1,,rmlarsen,2017-07-31 03:42:30,2017-08-10 00:54:02
PR,Branch 164787644,,,rmlarsen,2017-08-09 23:10:54,2017-08-10 00:59:04
IS,summary FileWriter should support with statement,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 6 2 Bazel version if compiling from source CUDA cuDNN version 8 0 GPU model and memory GTX1050 4GB Exact command to reproduce Describe the problem Python users would expect a file writer to support the with statement but it does not Source code logs,,"aselle,yongtang",2017-07-25 14:29:16,2017-08-10 01:00:59
PR,Support with statement for summary FileWriter,This fix adds support of with for summary FileWriter This fix fixes 11750 Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv,josh11b,yongtang,rmlarsen,rmlarsen,vrv,rmlarsen,rmlarsen,rmlarsen",2017-07-27 04:02:44,2017-08-10 01:00:59
PR,Add loss to summary during estimator train,This would be useful for visualizing the losses during training phase,,"terrytangyuan,terrytangyuan",2017-08-04 03:33:42,2017-08-10 01:32:09
IS,XLA Should we disable REGISTER XLA BACKEND GPU if there is no GPU installed on the machine,I install TensorFlow from source with XLA and TF CPP MIN VLOG LEVEL enabled without GPU after trying XLA example I got these logs Should we disable REGISTER XLA BACKEND GPU if there is no GPU installed on the machine WDYT System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 2 1 Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce,,"ScorpioCPH,ScorpioCPH,hawkinsp,ScorpioCPH",2017-08-07 06:51:51,2017-08-10 02:52:59
PR,Fix broken link in tensorflow go README md,Fix broken link in tensorflow go README md This is related to 12145 tensorflow java README md but is in go is README md instead Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen",2017-08-09 19:52:42,2017-08-10 04:14:09
IS,tf cast Illegal instruction,why please help,,"yaroslavvb,yaroslavvb",2017-08-10 03:51:19,2017-08-10 07:24:52
PR,R1 3,Missing IndicesRowIterator operator is added,,,2017-08-10 11:03:46,2017-08-10 11:38:09
IS,Bazel Windows Build ' tensorflow tools proto text gen proto text functions' failed to link,This was first caught by Bazel CI Reported at,,"meteorcloudy,tatatodd",2017-08-08 19:39:25,2017-08-10 15:35:23
PR,Fix Windows Linking error,Fix stringpiece cc is only the src of lib internal so we have to add it as a dependency,,"meteorcloudy,tatatodd,snnn,meteorcloudy,meteorcloudy,tatatodd,gunan,snnn,meteorcloudy,meteorcloudy,learyg,rmlarsen,meteorcloudy,learyg,meteorcloudy,snnn",2017-08-09 16:55:43,2017-08-10 15:35:24
PR,dynamic stitch op gpu version,Issue 7251 Have implemented the GPU version dynamic stitch all tested passed locally use the script do a quick benchmark Env Based TF Version r1 3 cuda 8 0 cudnn 5 1 GPU Tesla M40 Result CPU Version Time 1000 40 180424 s GPU Version Time 1000 5 095576 s The thought reference code thanks for great jobs Thanks for precious suggestions,,"nolanliou,ekelsen,ekelsen,ekelsen,nolanliou,ekelsen,ekelsen,nolanliou,ekelsen,nolanliou,ekelsen,nolanliou,nolanliou,nolanliou,ekelsen,ekelsen,nolanliou,nolanliou,rmlarsen,rmlarsen,rmlarsen,nolanliou,nolanliou,rmlarsen,rmlarsen,rmlarsen,nolanliou",2017-08-01 11:01:34,2017-08-10 15:45:24
PR,Update monitors py,Replace deprecated SummaryWriter and SummaryWriterCache with FileWriter and FileWriterCache,,"alanyee,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen",2017-08-05 07:25:29,2017-08-10 16:33:12
IS,sparse matmul op test fails on ppc64le,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 RHEL SLES ppc64le TensorFlow installed from source or binary source TensorFlow version use command below master Python version 2 7 5 Bazel version if compiling from source 0 4 5 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel test test output errors tensorflow core kernels sparse matmul op test You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Test fails since the pbroadcast functions in tensorflow core kernels sparse matmul op h are not implemented for PowerPC has SSE versions resulting in incorrect values received by BroadcastPacketTest function in the test case code tensorflow core kernels sparse matmul op test cc log of failure in below section Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem INFO From Testing tensorflow core kernels sparse matmul op test Test output for tensorflow core kernels sparse matmul op test Running main from test main cc Running 4 tests from 1 test case Global test environment set up 4 tests from SparseMatmulOpTest RUN SparseMatmulOpTest BroadcastPacketTest 0 170094 0 170094 0 170094 0 170094 0 170094 0 14922 0 0823886 0 026985 differences 0 0 0208738 0 252482 0 143109 tensorflow core kernels sparse matmul op test cc 257 Failure Value of areApprox ref data2 PacketSize Actual false Expected true FAILED SparseMatmulOpTest BroadcastPacketTest 1 ms RUN SparseMatmulOpTest InterleavePacketTest OK SparseMatmulOpTest InterleavePacketTest 0 ms RUN SparseMatmulOpTest Bfloat16ExpandTest OK SparseMatmulOpTest Bfloat16ExpandTest 0 ms RUN SparseMatmulOpTest Bfloat16LoadTest OK SparseMatmulOpTest Bfloat16LoadTest 0 ms 4 tests from SparseMatmulOpTest 1 ms total Global test environment tear down 4 tests from 1 test case ran 1 ms total PASSED 3 tests FAILED 1 test listed below FAILED SparseMatmulOpTest BroadcastPacketTest 1 FAILED TEST Target tensorflow core kernels sparse matmul op test up to date bazel bin tensorflow core kernels sparse matmul op test INFO Elapsed time 14 711s Critical Path 14 07s tensorflow core kernels sparse matmul op test FAILED in 1 out of 2 in 0 0s root cache bazel bazel root 68a62076e91007a7908bc42a32e4cff9 execroot tensorflow bazel out local opt testlogs tensorflow core kernels sparse matmul op test test log Executed 1 out of 1 test 1 fails locally,,tatatodd,2017-08-09 09:59:32,2017-08-10 16:38:59
PR,Allow disabling of selected tests in vector ops,Swap over the test instantiate macro to allow selective disabling of these tests,,"DavidNorman,rmlarsen",2017-08-10 10:29:46,2017-08-10 16:58:57
PR,OpenCL Registers BytesLimit Op,,,"lukeiwanski,rmlarsen",2017-08-10 10:47:50,2017-08-10 16:59:09
PR,Update head py,Replace scalar summary for tf summary scalar,,"alanyee,rmlarsen,alanyee,alanyee,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,alanyee,ispirmustafa,alanyee",2017-08-08 07:01:46,2017-08-10 17:02:17
PR,Fix unnecessary sync memops cuda pointer attr in GDR,See the comments here discussion r132026389 I have tested on my local boxes and it seems removing CU POINTER ATTRIBUTE SYNC MEMOPS slightly improves the training throughput while introducing no data race,,"byronyi,rmlarsen,rmlarsen",2017-08-10 09:10:01,2017-08-10 17:25:06
PR,remove unused parameter,remove unused parameter pool for DirectSession GetOrCreateExecutors,,"horance-liu,rmlarsen",2017-08-10 11:23:32,2017-08-10 17:25:22
PR,Fixing an issue with merge back with rc2,,,"av8ramit,rmlarsen,rmlarsen",2017-08-09 18:16:21,2017-08-10 17:31:32
PR,enable mkl in eigen for qr op,7128,,"suiyuan2009,suiyuan2009,drpngx,drpngx,suiyuan2009,drpngx,gunan",2017-06-28 15:53:14,2017-08-10 17:43:06
PR,Corrected dimension notes in attention wrapper py,I was following along your Bahdanau implementation while doing my own and noticed a bug in the documentation While it is true you can project memory and query to attention num inputs the context is of shape B memory size To illustrate the lines around the ones I edited The alignments reduced is computed in attention wrapper py L447 L447 Additionally I do not see mention of this step in the original paper but can see how it might be needed to make calculation of context possible Maybe this is an incorrect interpretation of the original paper It does not seem to mention a projection to a common dimensionality of both memory and query D attention above denoted by num inputs in the BahdanauAttention constructor Say now we leave D attention D encoded The result would be that alignments and memory are of the same dimensionality can safely be multiplied component wise and then sum reduced along the time dimension This is an alternative interpretation of the paper an approach that does not introduce num inputs for attention and does not compute the sum along the last num inputs axis alignments reduced,,"ebrevdo,ebrevdo",2017-08-08 13:17:20,2017-08-10 17:49:35
IS,Request for Tile operation for integer types,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 Bazel version if compiling from source CUDA cuDNN version 8 0 5 GPU model and memory TitanX 12G Exact command to reproduce Describe the problem I need some matrix indices computation using tf tile function But now it is only available for float types So I have to cast int into float and after computation back into int It would be great to have tile function working with tensors with dtype of integer types Source code logs,,yongtang,2017-08-10 08:34:24,2017-08-10 17:55:29
PR,Enable int32 on GPU for tf tile,This fix enabled int32 on GPU for tf tile to fix the following error This fix fixes 12169 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,yaroslavvb,rmlarsen",2017-08-10 15:00:40,2017-08-10 17:55:29
IS,Tiny error about set CLASSPATH in Deploy Doc,In this page When introduce to set CLASSPATH shell CLASSPATH HADOOP HDFS HOME bin hadoop classpath glob There is an extra parenthesis after HADOOP HDFS HOME,,"yongtang,tatatodd",2017-08-10 07:07:23,2017-08-10 18:15:54
IS,TFRecord usage,Describe the problem Can I get meta data of record in TFRecord file using tf queue pipeline which type is an int or np ndarry without a Tensor So I can use this meta data to tf shuffle batch example and I do not want use a another Sesson to fecth from Tensors May this can be a Feature for tf,,tatatodd,2017-08-10 08:11:09,2017-08-10 18:16:38
IS,Training ops test assertion failures on Ubuntu 16 04,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version 2 7 12 Bazel version if compiling from source 0 4 5 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce bazel test c opt tensorflow python training ops test The problem The tensorflow python training ops test is failing on s390x with AssertionError in testTypesForFtrl method I have added test log below A single value differs as below in the result,,"namrata-ibm,namrata-ibm,namrata-ibm",2017-08-02 13:36:00,2017-08-10 18:33:44
PR,XLA Any unrecognised fusion type should be described as kCustom,majnemer Hi this is the knock on from cancelling having a fusion sub type if I use kCustom N as types of fusion then I need the printing routine to not fail when given a type that is not recognised The cancelled PR was,,"DavidNorman,majnemer,DavidNorman,DavidNorman,majnemer,DavidNorman,majnemer,DavidNorman,majnemer,DavidNorman,DavidNorman",2017-07-31 13:36:27,2017-08-10 18:36:42
PR,CI script for building Raspberry Pi wheels,This CL expands on is original PR adding Pi support by integrating it into the CI build scripts This is a step towards nightly builds of Pi wheels and distribution of prebuilt binaries Issue 9697 is still blocking us from switching to the latest Eigen version which is required for ARM compilation so the script makes a local change to work around this for now There is also one header added to oauth client cc because it is required by boringssl on this platform,,"petewarden,petewarden",2017-08-10 19:11:51,2017-08-10 19:40:01
PR,OpenCL Fixes double memcpy bug 151,As the debg CopyOp is called on a Tensor without type we need to use the DataType enum to get type information and use this to pass the type on to Eigen This is a workaround Eigen is need to have a type when calling memcpy If the Eigen memcpy can be provided without a type requirement then the memcpy in sycl util is unnecessary,,"lukeiwanski,rmlarsen,rmlarsen,lukeiwanski,lukeiwanski,lukeiwanski,lukeiwanski,rmlarsen",2017-08-10 10:57:43,2017-08-10 23:17:41
PR,Remove casting of int64 for reverse sequence,This fix remove unneeded cast of int64 for reverse sequence as int32 has already been enabled for reverse sequence Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-08-10 23:19:37,2017-08-11 00:19:12
PR,OpenCL Extends matmul benchmark py to cover SYCL,,,"lukeiwanski,lukeiwanski,vrv,lukeiwanski,vrv,yzhwang,lukeiwanski,vrv,lukeiwanski,rmlarsen,rmlarsen,lukeiwanski,rmlarsen,rmlarsen,lukeiwanski,vrv,vrv,lukeiwanski,rmlarsen,lukeiwanski,rmlarsen,rmlarsen,yzhwang,rmlarsen",2017-07-23 19:30:56,2017-08-11 00:35:22
PR,Fix typos,This PR fixes some typos explictly initialised paritally unecessary substitue and Paramterized,,"taehoonlee,rmlarsen",2017-08-11 00:27:47,2017-08-11 00:42:14
PR,Branch 164929133,,,rmlarsen,2017-08-11 01:10:18,2017-08-11 01:13:20
PR,Create CI build script for Raspberry Pi,This integrates the work by to create a build script for the Raspberry Pi with the CI system This script creates a Python wheel for TensorFlow on the Pi and is a step towards creating automatic redistributable binaries for the platform I had to update oauth client cc for a missing header on this platform and work around the eigen updating issue tracked in 9697,,"petewarden,gunan,petewarden",2017-08-10 19:38:57,2017-08-11 01:16:27
PR,Branch 164929133,,,rmlarsen,2017-08-11 01:36:26,2017-08-11 01:47:55
PR,Branch 164929133,,,"rmlarsen,rmlarsen",2017-08-11 01:59:24,2017-08-11 03:21:04
IS,Android example broken with nativeBuildSystem none,This commit breaks the android example when nativeBuildSystem none since it directly uses the native image conversion functions rather than calling the java ones The native conversions are not implemented when nativeBuildSystem none To reproduce 1 Set nativeBuildSystem none 2 Build example 3 Run on a phone 4 Observe crash on startup and errors about unimplemented methods,,,2017-08-08 14:09:15,2017-08-11 03:21:20
PR,Implement CRF decode Viterbi decode for tensor,Currently Tensorflow does not support CRF decoding Viterbi decoding for tensor Although tf contrib crf viterbi decode function can do CRF decoding it can only be used at test time since it accepts Numpy arrays as inputs Implementing CRF decoding for tensor benefits us a lot as this makes our model more portable e g we can freeze model save it to a pb file and then load it in Golang at test time This PR implements CRF decoding for tensor and adds test code for it This PR is change is compatible with current API,,"betterenvi,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,betterenvi,rmlarsen,drpngx,betterenvi,drpngx,rmlarsen",2017-08-05 18:56:43,2017-08-11 03:31:51
PR,Adding support for Big Endian in graph constructor test and wav io,PR to add support for Big Endian for resolving below failures 1 tensorflow core graph graph constructor test 2 tensorflow core kernels decode wav op test 3 tensorflow core lib wav wav io test 4 tensorflow core kernels encode wav op test The tensor content in graph constructor test needs to be corrected for big endian Also the ReadValue in wav io cc needs to be shifted other way for big endian,,"namrata-ibm,rmlarsen",2017-08-10 13:52:42,2017-08-11 03:41:10
PR,Add bool type supports for GPU kernels,This PR adds bool type supports for GPU kernels reshape concat and stack The problem is originally described in 11676 Following is a minimum code snippet which runs on CPU but not on GPU As far as I know there is no reason not to have boolean supports for these operations Thus I propose the boolean supports,,"taehoonlee,ekelsen,ekelsen,taehoonlee,taehoonlee,taehoonlee,rmlarsen,rmlarsen,taehoonlee,rmlarsen,rmlarsen,rmlarsen,taehoonlee,rmlarsen",2017-08-01 02:20:18,2017-08-11 04:00:13
PR,Adding support for s390x in calculation of cpu frequency,PR for changing the GetCycleCounterFrequency for s390x to fix test tensorflow core platform profile utils cpu utils test Facing issue similar to power reported here issuecomment 307097621 On s390x too cpu frequency 1 and hence below test fails Extending the fix added for PPC raised via PR issuecomment 311064869,,"namrata-ibm,gunan,gunan,gunan,namrata-ibm,gunan,namrata-ibm",2017-08-10 14:15:27,2017-08-11 05:00:38
PR,fix build issue for config sycl,,,rmlarsen,2017-08-11 03:55:08,2017-08-11 05:26:11
IS,No registered 'MirrorPad' OpKernel for XLA CPU JIT devices,It seems that mirror padding is not supported with XLA The message is triggered when running tfcompile Any ideas on when this or other ops like 11905 might be available,,,2017-08-11 08:15:22,2017-08-11 08:18:38
IS,Compiling Tensorflow Crashes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 rc2 Exact command to reproduce cpu armeabi v7a bazel build c opt tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu cpu verbose failures I have a VM setup with Ubuntu 16 64bit I tried compiling the tensorflow library with Bazel to generate the so and jar files I have modified the register types h file according to diff 76e272a58ca1535b3e0ec93499779a14 But I do not think this issue is because of that change The Error is ERROR home anand TensorflowAndroidPort tensorflow tensorflow tensorflow core kernels BUILD 4539 1 Linking of rule ' tensorflow core kernels android tensorflow kernels' failed Exit 1 arm linux androideabi ar failed error executing command Target tensorflow contrib android libtensorflow inference so failed to build INFO Elapsed time 2134 608s Critical Path 54 46s FAILED Build did NOT complete successfully With Verbose Failure Option ERROR home anand TensorflowAndroidPort tensorflow tensorflow tensorflow core kernels BUILD 4539 1 Linking of rule ' tensorflow core kernels android tensorflow kernels' failed Exit 1 arm linux androideabi ar failed error executing command exec env PWD proc self cwd external androidndk ndk toolchains arm linux androideabi 4 9 prebuilt linux x86 64 bin arm linux androideabi ar rcsD bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels libandroid tensorflow kernels lo bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels aggregate ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels bias op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl bfloat o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl bool o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl complex128 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl complex64 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl double o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl float o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl half o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl int16 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl int32 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl int64 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl int8 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl uint16 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cast op impl uint8 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels concat lib cpu o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels concat op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels constant op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise ops common o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels dense update functor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels dense update ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels example parsing ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels fill functor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels function ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels gather op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels identity n op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels identity op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels immutable constant op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels matmul op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels no op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels non max suppression op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels one hot op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels pack op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reshape op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reverse sequence op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels sendrecv ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels sequence ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels shape ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 3 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 4 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 5 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 6 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels slice op cpu impl 7 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels softmax op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels split lib cpu o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels split op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels split v op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 0 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 3 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 4 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 5 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 6 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels strided slice op inst 7 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels unpack op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels variable ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels argmax op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels avgpooling op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels batch matmul op real o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels batch norm op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels bcast ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels check numerics op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels control flow ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv grad filter ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv grad input ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv grad ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv ops fused o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels conv ops using gemm o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels crop and resize op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op abs o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op add 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op add 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op bitwise and o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op bitwise or o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op bitwise xor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op div o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op equal to 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op equal to 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op exp o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op floor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op floor div o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op greater o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op greater equal o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op invert o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op isfinite o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op less o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op less equal o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op log o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op logical and o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op logical not o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op logical or o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op maximum o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op minimum o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op mul 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op mul 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op neg o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op pow o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op reciprocal o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op rsqrt o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op select o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op sigmoid o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op sign o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op sqrt o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op square o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op squared difference o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op sub o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels cwise op tanh o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels deep conv2d o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels depthwise conv op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels dynamic partition op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels fake quant ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels fifo queue o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels fused batch norm op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels population count op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels batchtospace op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels ctc decoder ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels decode bmp op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels depthtospace op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels dynamic stitch op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels in topk op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels logging ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels lrn op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels maxpooling op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op cpu impl 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op cpu impl 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op cpu impl 3 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op cpu impl 4 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels mirror pad op cpu impl 5 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels pad op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels padding fifo queue o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels padding fifo queue op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels queue base o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels queue ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels random op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops all o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops any o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops common o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops max o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops mean o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops min o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops prod o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reduction ops sum o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels relu op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels resize bilinear op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels resize nearest neighbor op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels restore op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels reverse op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels save op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels save restore tensor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels save restore v2 ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels session ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels softplus op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels softsign op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels spacetobatch functor o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels spacetobatch op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels spacetodepth op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels sparse to dense op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels stack ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels string join op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels summary op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tensor array o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tensor array ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile functor cpu o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 1 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 2 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 3 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 4 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 5 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 6 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels tile ops cpu impl 7 o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels topk op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels training op helpers o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels training ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels transpose functor cpu o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels transpose op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels warn about ints o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels where op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels xent op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels dequantize op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels meta support o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantization utils o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantize down and shrink range o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantize op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized activation ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized add op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized batch norm op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized bias add op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized concat op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized conv ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized instance norm o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized matmul op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized mul op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized pooling ops o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized reshape op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels quantized resize bilinear op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels requantization range op o bazel out arm linux androideabi 4 9 v7a gnu libstdcpp opt bin tensorflow core kernels objs android tensorflow kernels tensorflow core kernels requantize o Target tensorflow contrib android libtensorflow inference so failed to build INFO Elapsed time 2134 608s Critical Path 54 46s FAILED Build did NOT complete successfully Bazel Version info Build label 0 5 3 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Jul 28 08 34 59 2017 1501230899 Build timestamp 1501230899 Build timestamp as int 1501230899 I'm using NDK version 12b with API version 23 and SDK 23 with Build Tools version 25 0 2 SDK was installed through android studio,,"tatatodd,andrewharp",2017-08-08 13:45:24,2017-08-11 09:47:22
IS,Encounter Fatal signal 11 SIGSEGV problem doing training on mobile device,I am stuck on the SIGSEGV problem while trying to do training on a mobile device Nexus 7 can you help me out System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I added a couple of lines to the TensorFlowInferenceInterface java OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 Python version 2 7 12 Bazel version if compiling from source 0 52 CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I am trying to find out the performance of doing training on mobile devices I got the Fatal signal 11 SIGSEGV when I am trying to work with a graph including a couple of convolutional layers FC layers and cross entropy operation Here is what I did I modified the TensorFlowInferenceInterface java by adding a function for initialization all nodes then I was able to reproduce the example in the following link in Android API I try to do the training with a more complicated graph including a couple of convolutional layers FC layers and cross entropy operation I can do the training with this graph using the C API I first solved the No OpKernel problem The error message is as follows No OpKernel was registered to support Op 'SparseSoftmaxCrossEntropyWithLogits' with these attrs I add the sparse xent op h and the sparse xent op cc files to the BUILD file locates at tensorflow tensorflow core kernels I modify the list op files txt locally adding the sparse xent op operator and rebuild the Tensorflow source The No OpKernel error disappears but the program stops at runner runAndFetchMetadata and throws me an error A libc Fatal signal 11 SIGSEGV code 1 fault addr 0x0 in tid 15173 inference Source code logs TensorFlowInferenceInterface java public void runTarget String outputNames Log d TAG start of the runTarget for String t outputNames runner addTarget t Log d TAG finished adding target runner runAndFetchMetadata Log d TAG runAndFetchMetadata runner sess runner Log d TAG sess runner Corresponding Logcat messages 08 06 16 25 01 900 15099 15173 org tensorflow demo D TensorFlowInferenceInterface start of the runTarget 08 06 16 25 01 900 15099 15173 org tensorflow demo D TensorFlowInferenceInterface finished adding target 08 06 16 25 04 576 15099 15173 org tensorflow demo A libc Fatal signal 11 SIGSEGV code 1 fault addr 0x0 in tid 15173 inference Crash dump result Crash dump Build fingerprint 'google razor flo 6 0 MRA58K 2256973 user release keys' pid 5414 tid 5478 name inference org tensorflow demo signal 11 SIGSEGV code 1 SEGV MAPERR fault addr 0x0 Stack frame 00 pc 00017664 system lib libc so memcpy base 91 Stack frame 01 pc 0072a203 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 02 pc 006eea49 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 03 pc 006d59d3 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 04 pc 006ed9c3 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 05 pc 006df991 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 06 pc 006dffb5 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 07 pc 0009eff9 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 08 pc 0009f403 data app org tensorflow demo 2 lib arm libtensorflow inference so Stack frame 09 pc 00099085 data app org tensorflow demo 2 lib arm libtensorflow inference so Java org tensorflow Session run 920 Stack frame 10 pc 000eaa29 system lib libart so art quick generic jni trampoline 40 Stack frame 11 pc 000e6331 system lib libart so art quick invoke stub internal 64 Stack frame 12 pc 00402663 system lib libart so art quick invoke static stub 170 Stack frame 13 pc 001009f4 stack 5478,,andrewharp,2017-08-07 00:07:16,2017-08-11 12:20:02
IS,fail to run android example,System information bazel version Build label 0 5 2 homebrew java version 1 8 0 131 workspace config android sdk repository name androidsdk api level 23 build tools version 25 0 1 path Users scucheri Library Android sdk android ndk repository name androidndk path Users scucheri Library Android sdk ndk bundle api level 14 Describe the problem error when I run 'bazel build tensorflow examples android tensorflow demo' in terminal could you tell me how to solve this Source code logs bazel build tensorflow examples android tensorflow demo WARNING The major revision of the Android NDK referenced by android ndk repository rule 'androidndk' is 15 The major revisions supported by Bazel are 10 11 12 13 14 Defaulting to revision 14 ERROR private var tmp bazel scucheri f55efc3e55d5b53a9cbb2375bb9bdf55 external androidsdk BUILD bazel 64 1 Traceback most recent call last File private var tmp bazel scucheri f55efc3e55d5b53a9cbb2375bb9bdf55 external androidsdk BUILD bazel line 64 create system images filegroups system image dirs system ima 53 more arguments File private var tmp bazel scucheri f55efc3e55d5b53a9cbb2375bb9bdf55 external bazel tools tools android android sdk repository template bzl line 246 in create system images filegroups int apidir split 1 invalid literal for int with base 10 MNC ERROR private var tmp bazel scucheri f55efc3e55d5b53a9cbb2375bb9bdf55 external androidsdk BUILD bazel 8 1 Target ' androidsdk build tools 25 0 1 lib dx jar' contains an error and its package is in error and referenced by ' androidsdk dx jar' ERROR private var tmp bazel scucheri f55efc3e55d5b53a9cbb2375bb9bdf55 external androidsdk BUILD bazel 8 1 Target ' androidsdk dx jar' contains an error and its package is in error and referenced by ' androidsdk dx jar import' ERROR Users scucheri AllMyProjects AndroidStudioProjects TmallAndroidProjects tensorflow WORKSPACE 20 1 Target ' androidsdk dx jar import' contains an error and its package is in error and referenced by ' external android dx jar import' ERROR Analysis of target ' tensorflow examples android tensorflow demo' failed build aborted INFO Elapsed time 3 653s,,"andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp",2017-07-13 10:43:40,2017-08-11 12:30:34
PR,Fix typos,This PR fixes some typos,,taehoonlee,2017-08-11 08:27:46,2017-08-11 13:28:56
IS,Document changes in notMNIST data sets,Describe the problem The notMNIST data set used in Assignment 1 and maybe elsewhere in this repo repeatedly changed size over the last 12 months Last year in issue 4693 a size of about 50 MB is reported for notMNIST large tar gz Now this file is 236 MB People doing the assignment are comparing their classifier accuracy to results published by previous assignment takers and some are talking about publishing research using this data set If the data set is modified unknowingly to the users observed accuracy figures are not comparable and can mislead people to wrong conclusions The files is also bigger now on your personal website However the time stamps of the atr gz and all files inside are still from 2011 Source code logs The changes in size can also be tracked in changes to the calls of maybe download in Suggestions The tar gz files should contain a readme and changelog with version information The filename should include the version number References to the data set in the assignments should be changed from the notMNIST dataset to version 1 23 of the notMNIST dataset Result tables produced by code should quote the version of the data set,,vincentvanhoucke,2017-08-11 09:45:20,2017-08-11 13:36:13
PR,Adding support for s390x for changing GetCycleCounterFrequency,Closing 12180 and re creating the PR based on review comments,,"namrata-ibm,rmlarsen",2017-08-11 04:59:13,2017-08-11 15:28:50
PR,Remove useless RecvTensorResponse allocation in GDR,See here L347 for your reference,,byronyi,2017-08-11 11:02:20,2017-08-11 15:30:56
PR,Dynamic ksize and strides with MaxPool,This fix is the renewed effort to fix 4746 with Jenkins failures fixed the previous PR was 9514 This fix tries to fix the issue raised in 4746 where ksize and strides is static attr with max pool and avg pool This fix changes ksize and strides to input tensor with MaxPoolV2 so that it is dynamic now This fix add MaxPoolV2 but has not points nn ops max pool to gen nn ops max pool v2 yet It tries to following the same api workflow as PR 10840 3 weeks before API changes This fix fixes 4746,,"yongtang,rmlarsen,yongtang,rmlarsen,yongtang,rmlarsen,rmlarsen,yongtang,rmlarsen,rmlarsen,martinwicke,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,yongtang,rmlarsen,rmlarsen,rmlarsen,yongtang",2017-07-30 02:36:04,2017-08-11 15:36:22
PR,Add option for build more python tests in Cmake,Add option tensorflow BUILD MORE PYTHON TESTS for testing some major packages under contrib directory Tested fixed and enabled some UTs on Windows Linux,,"mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,rmlarsen,rmlarsen,rmlarsen,mrry,rmlarsen,rmlarsen,rmlarsen",2017-07-28 17:18:56,2017-08-11 15:37:21
IS,Please develop a 32 bit version thank you very much,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,mrry,2017-08-11 10:54:16,2017-08-11 16:18:09
PR,Update metrics op py,Replaced contrib with direct equivalents outside of contrib,,alanyee,2017-08-11 16:31:12,2017-08-11 18:03:27
PR,Reverting a commit that is causing compilation errors,MKL optimized Tensorflow does not support EIGEN USE MKL ALL currently,,agramesh1,2017-08-11 16:59:31,2017-08-11 18:04:18
PR,Branch 164943597,,,rmlarsen,2017-08-11 16:12:05,2017-08-11 18:14:59
IS,A single value placeholder cause an GPU memory warning,I train my model on GTX 980 with 4 GB memory The tensorflow version is 1 1 0 Python is 3 6 0 The example code is on this GitHub link Since the code is kind of long I do not want to copy them IF someone can run it I will appreciate it The problem is when I increase the epoch It cause a memory error on my GPU But when delete the variable placeholder self dropout keep prob there would be no error message I do not know why my code running on CPU is totally fine Below is the warning message 2017 08 03 15 38 52 537616 W tensorflow core common runtime bfc allocator cc 217 Allocator GPU 0 bfc ran out of memory trying to allocate 3 84GiB The caller indicates that this is not a failure but may mean that there could be performance gains if more memory is available,,,2017-08-03 19:30:15,2017-08-11 19:42:49
IS,tensorflow in python,Hi I am trying to use tensorflow in ipython Linux and I got the following error h h source activate tensorflow tensorflow hx hx python Python 2 7 13 Continuum Analytics Inc default Dec 20 2016 23 09 15 GCC 4 4 7 20120313 Red Hat 4 4 7 1 on linux2 Type help copyright credits or license for more information Anaconda is brought to you by Continuum Analytics Please check out and import tensorflow as tf Traceback most recent call last File stdin line 1 in module File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python init py line 63 in module from tensorflow python framework framework lib import File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework framework lib py line 100 in module from tensorflow python framework subscribe import subscribe File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework subscribe py line 26 in module from tensorflow python ops import variables File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops variables py line 26 in module from tensorflow python ops import control flow ops File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops control flow ops py line 70 in module from tensorflow python ops import tensor array ops File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops tensor array ops py line 33 in module from tensorflow python util import tf should use File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python util tf should use py line 28 in module from backports import weakref pylint disable g bad import order ImportError cannot import name weakref import tensorflow as tf Traceback most recent call last File stdin line 1 in module File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home hx anaconda2 envs tensorflow lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow ImportError cannot import name pywrap tensorflow and not in tensorflow like this h h python Python 2 7 13 Anaconda custom 64 bit default Dec 20 2016 23 09 15 GCC 4 4 7 20120313 Red Hat 4 4 7 1 on linux2 Type help copyright credits or license for more information Anaconda is brought to you by Continuum Analytics Please check out and import tensorflow as tf Traceback most recent call last File stdin line 1 in module ImportError No module named tensorflow Thanks,,,2017-08-11 12:06:36,2017-08-12 01:07:44
PR,Add handle ties arg to in top k Op to deal with ties 10767,10767 Add handle ties argument to in top k Op to make the Op more clear,,"nolanliou,rmlarsen,rmlarsen,nolanliou,rmlarsen,nolanliou",2017-08-09 04:40:29,2017-08-12 03:00:51
PR,Add regression tests and fix some minor bugs,This pull request adds some additional unit tests for the add n and accumulate n operators I'm adding these tests as preparation for working on Specifically I added tests of the argument validation code in accumulate n and a test of gradient computation for add n This pull request also fixes two minor bugs that I encountered in the process of adding the unit tests accumulate n ignores its tensor dtype argument when the operator has only one input I have added additional error handling logic to accumulate n that rejects values of tensor dtype that are different from the input type The test UnaryOpTest testComplex64Basic was failing on my Mac because the acosh and asinh functions for single precision complex floating point are only accurate to 6 decimal places Under the assumption that 6 significant figures is good enough I increased the threshold that the test cases use when comparing gradients Note that if 6 significant figures is not good enough for acosh and asinh a more involved fix will be necessary for the second problem,,"frreiss,rmlarsen,rmlarsen",2017-08-11 00:41:13,2017-08-12 06:29:08
PR,Fix issues due to old numpy versions in dist test and gcs test,Previously numpy was installed with apt get leading to a version too old to be compatible with the recently added autograd dependency of tensorflow This change set fixes that,,"caisq,caisq,gunan",2017-08-12 01:56:23,2017-08-12 23:43:09
IS,Feature Request Return final loss from tf estimator Estimator train along with self,Describe the problem Things like hyper opt need to know the loss so that it can effectively pick the best hyper parameters for the model Right now self is just returned it is a one line change to the code since the loss is set the exact line before I would be happy to initiate the PR myself assuming its wanted Source code logs From,,"terrytangyuan,tatatodd,terrytangyuan,terrytangyuan,ispirmustafa",2017-08-08 00:41:40,2017-08-13 00:42:48
PR,R0 12 cmake 2017,,,,2017-08-13 03:49:35,2017-08-13 03:58:10
PR,Revert Update metrics op py 12218,This reverts commit b3e0738a4420d0dce8ebba554ff5c68ee8c228e7 Reason broke metrics op test e g see TF BUILD IS PIP NO PIP TF BUILD PYTHON VERSION PYTHON2 label cpu slave 586 console,,"caisq,caisq,alanyee,alanyee,caisq,alanyee",2017-08-12 19:51:49,2017-08-13 04:47:33
PR,Update tensor util py and fix metric ops py,Added deprecated note,,alanyee,2017-08-12 18:00:55,2017-08-13 04:47:38
IS,Error importing tensorflow gpu,capture I installed Cuda Toolkit cuDNN 5 1 on windows 8 1 I also installed tensorflow gpu using pip3 When I tried importing tensorflow in python I got the above error Can you please help me out,,,2017-08-13 05:59:56,2017-08-13 06:29:45
IS,variable scope name is not displayed correctly,snip20170814 1 As shown scope2 is name should be new scope 1,,ppwwyyxx,2017-08-14 05:40:20,2017-08-14 06:48:29
IS,How do I build a whole compute graph and Variables Weights arguments then training it in C,,,,2017-08-14 09:51:44,2017-08-14 10:50:38
IS,Where is gen logging ops source code,Hi I have a question about this import from tensorflow tensorflow python summary summary py line 53 from tensorflow python ops import gen logging ops as gen logging ops When I go to the directory tensorflow python ops there is no such file called gen logging ops I am wondering how this worked out BTW I am tracking the r1 3 version Any suggestion is highly appreciated Best wishes Binhang,,rohan100jain,2017-08-14 09:35:52,2017-08-14 14:32:36
IS,Principle of setting 'hash bucket size' parameter,Question 1 In wide n deep tutorial py there is a hyper parameter named hash bucket size for both tf feature column categorical column with hash bucket and tf feature column crossed column methods and the value is hash bucket size 1000 But why 1000 How to set this parameter Question 2 The second question about crossed columns that is crossed columns tf feature column crossed column education occupation hash bucket size 1000 tf feature column crossed column age buckets education occupation hash bucket size 1000 tf feature column crossed column native country occupation hash bucket size 1000 in wide n deep tutorial py Why choose education occupation age buckets education occupation and native country occupation as crossed columns are there any rule of thumb,,rohan100jain,2017-08-14 01:33:59,2017-08-14 14:34:39
IS,Recurrent Reinforcement Learning Issue,Hi guys I am working on a structure with recurrent neural network as the deep part of deep reinforcement learning I have been searching all along but I have not found a way to build this structure by using tensorflow The recurrent feature makes the objective function iterative I am wondering if TF can calculate the gradient by itself It would be great if I can get to know if this structure can be done or not,,rohan100jain,2017-08-07 08:30:44,2017-08-14 14:36:16
IS,Where is NumTraits h,,,rohan100jain,2017-08-09 03:27:14,2017-08-14 14:40:29
IS,request Make tensorflow checkpoints portable,System information Not applicable this is a general feature request Describe the problem Feature request make checkpoint files portable Checkpoint files are not portable because they use absolute paths If I move the directory containing a trained graph and then try to restore from a checkpoint I get unable to match files errors because tensorflow does not know to look in the checkpoint directory for checkpoint files,,ppwwyyxx,2017-08-12 00:57:19,2017-08-14 15:13:59
IS,Invalid argument NodeDef mentions attr 'Tshape' not in Op name Reshape signature tensor T shape int32 output T attr T type,I got this kind of error message once my Android app launced Error message 08 12 10 28 32 307 25515 25533 E native executor cc 334 Executor failed to create kernel Invalid argument NodeDef mentions attr 'Tshape' not in Op name Reshape signature tensor T shape int32 output T attr T type NodeDef pool 3 reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 pool 3 pool 3 reshape shape Node pool 3 reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 pool 3 pool 3 reshape shape 08 12 10 28 32 352 25515 25533 I native tensorflow jni cc 299 End computing Ran in 786ms 786ms avg over 1 runs 08 12 10 28 32 357 25515 25533 A native tensorflow jni cc 304 Error during inference Invalid argument NodeDef mentions attr 'Tshape' not in Op name Reshape signature tensor T shape int32 output T attr T type NodeDef pool 3 reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 pool 3 pool 3 reshape shape Node pool 3 reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 pool 3 pool 3 reshape shape 08 12 10 28 32 357 25515 25533 A libc Fatal signal 6 SIGABRT code 6 in tid 25533 InferenceThread These two line of codes that possibility produced the error message 1 2 Please advice Thank you,,skye,2017-08-12 02:43:43,2017-08-14 15:14:25
IS,Tensorflow inception speed issue,hello this is Rohan Naik i developed an app which interact with tensorflow running on server and shows parking spaces available for your car i am using inception model which was retrained and modified to process live video and tell the users where parking slots are available The issue is it takes a 10 seconds to process 8 thread which run the image recognition function Is there any way i can make it run faster Is tensorflow slim model can process the images faster code txt,,skye,2017-08-12 04:30:09,2017-08-14 15:15:02
IS,add new op for tensorflow in windows os,Hello how can create new op in window os a example or manual the same link in linux build the op library Thanks,,skye,2017-08-12 06:11:18,2017-08-14 15:15:15
IS,tensorflow compile error,When I run bazel build c opt copt mavx copt mavx2 copt mfma copt mfpmath both copt msse4 2 config opt config cuda tensorflow ERROR home wangmeng tools tensorflow tensorflow compiler xla tools BUILD 109 1 Linking of rule ' tensorflow compiler xla tools replay computation hlo evaluator' failed Exit 1 bazel out local linux opt bin tensorflow compiler plugin executor libplugin lib lo device o In function tensorflow lambda tensorflow OpKernelConstruction 1 FUN tensorflow OpKernelConstruction ' device cc text ZN10tensorflowUlPNS 20OpKernelConstructionEE 4 FUNES1 0x1e undefined reference to tensorflow XlaDeviceLaunchOp XlaDeviceLaunchOp tensorflow OpKernelConstruction ' collect2 error ld returned 1 exit status INFO Elapsed time 61 551s Critical Path 36 75s FAILED Build did NOT complete successfully tensorflow r1 3 bazel 0 5 3,,skye,2017-08-14 05:56:49,2017-08-14 15:26:47
IS,Using Bazel to bulid a tensorflow C source in Windows but stuck at this problem,OS Platform and Distribution Windows 10 Bazel version 0 5 3 I download the source on and I want to build the example from it But when I use command bazel build it prompt error tensorflow D FsCode tensorflow bazel build tensorflow examples label image ERROR D fscode tensorflow tensorflow core BUILD 1528 1 no such target ' tensorflow tools git gen spec json' target 'gen spec json' not declared in package 'tensorflow tools git' defined by D fscode tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR D fscode tensorflow tensorflow core BUILD 1528 1 no such target ' tensorflow tools git gen head' target 'gen head' not declared in package 'tensorflow tools git' defined by D fscode tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR D fscode tensorflow tensorflow core BUILD 1528 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by D fscode tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow examples label image label image' failed build aborted INFO Elapsed time 1 569s I search the problem on issues Somebody suggest to run configure But in Windows system this can not be run,,skye,2017-08-14 07:10:40,2017-08-14 15:28:17
IS,tensorboard 0 1 1 No such file or directory ' usr local lib python3 4 dist packages tensorflow tensorboard TAG',Just upgrade to TF 1 3 and tensorboard 0 1 1 from Pypi Ubuntu 14 04 64 bit and python 3 4 Running tensorboard gives me the following error EDIT I realize this is more like a issue of Tensorboard than Tensorflow Please feel free to move it to correct place if that helps solve it,,,2017-08-14 15:41:01,2017-08-14 16:31:19
PR,Branch 165019969,Needed a CP for 1 3,,"av8ramit,rmlarsen,av8ramit,rmlarsen,av8ramit,rmlarsen,rmlarsen,rmlarsen,av8ramit,av8ramit,av8ramit,gunan,av8ramit",2017-08-11 21:08:06,2017-08-14 16:46:06
IS,Tensorboard AttributeError 'SummaryMetadata' object has no attribute wouldisplay name',System information No custom code OS MaxOS Sierra 10 12 6 TensorFlow installed from source or binary TensorFlow version use command below 1 2 1 Python version 3 6 Bazel version if compiling from source Build label 0 5 3 homebrew CUDA cuDNN version GPU model and memory Exact command to reproduce tensorboard logdir Users Pertis Syncog TF SUD logs p1 summaries Describe the problem Tensorflow and Tensorboard built from source Tensorboard finds event files but returns AttributeError 'SummaryMetadata' object has no attribute wouldisplay name' Tensorboard installed from prebuilt binaries runs without error Source code logs See stack trace below TensorBoard 0 1 3 at 6006 Press CTRL C to quit C tensorflow Rocs iMac tensorboard Pertis tensorboard logdir Users Pertis Syncog TF SUD logs p1 summaries Exception in thread Reloader Traceback most recent call last File Users Pertis anaconda envs tensorflow lib python3 6 threading py line 916 in bootstrap inner self run File Users Pertis anaconda envs tensorflow lib python3 6 threading py line 864 in run self target self args self kwargs File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard backend application py line 325 in reload forever reload multiplexer multiplexer path to run File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard backend application py line 299 in reload multiplexer multiplexer Reload File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard backend event processing event multiplexer py line 195 in Reload accumulator Reload File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard backend event processing event accumulator py line 209 in Reload self ProcessEvent event File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard backend event processing event accumulator py line 355 in ProcessEvent value data compat migrate value value File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard data compat py line 53 in migrate value return handler value if handler else value File private var tmp bazel Pertis 77b889388121c5daae674df9c3cd82a3 execroot org tensorflow tensorboard bazel out darwin x86 64 py3 fastbuild bin tensorboard tensorboard runfiles org tensorflow tensorboard tensorboard data compat py line 80 in migrate image value display name value metadata display name or value tag AttributeError 'SummaryMetadata' object has no attribute wouldisplay name',,"reedwm,chihuahua",2017-08-10 15:34:57,2017-08-14 18:07:49
PR,Updating the hashes for NVlabs cub package,PR to fix master cmake builds,,"av8ramit,gunan",2017-08-14 17:10:19,2017-08-14 18:23:31
IS,Cannot use mean absolute error,I made a very simple neural network on tf and I wanted to use mean absolute error loss function however I got this error right after I created the optimizer No gradients provided for any variable check your graph for ops that do not support gradients between variables and loss Tensor This is what I did Why the function does not work JM,,reedwm,2017-08-13 20:07:41,2017-08-14 18:51:31
IS,Lack of documentation in tf decode raw,Hi i need to load arrays stored in tfrecords files so i need to convert the raw string byte data to number but i do not understand the output i get using tf decode raw Unfortunately function documentation does not help me Here an example of the strange for me behavior of this function The strangest thing for me is that numpy fromstring applied both to the raw tensor and the decoded tensor evaluated gives the same output Thank you,,reedwm,2017-08-12 11:48:49,2017-08-14 19:14:21
PR,Updating CUB urls for r1 3 branch,,,av8ramit,2017-08-14 18:26:06,2017-08-14 19:48:12
PR,R1 2,,,av8ramit,2017-08-14 20:14:32,2017-08-14 20:56:55
PR,r1 3 fix Bazel 0 5 3 build error,This is the patch necessary for TensorFlow r1 3 to compile with Bazel 0 5 3 which is set to be merged before the 1 3 release Mentioned in issuecomment 321956462 from which this change is cherry picked is this on the 1 3 branch If not can you cherry pick it It is build only so no need for another RC because of this I can confirm it is not on the 1 3 branch I'm building on Bazel 0 5 3 and I can also confirm that the r1 3 build works locally on my Ubuntu 16 04 once this patch is added but does not work without it change description Fix depsets cannot contain mutable items error with CUDA builds in Bazel 0 5 3 cherry picked from commit c5d311eaf8cc6471643b5c43810a1feb19662d6c,,"ahundt,av8ramit,av8ramit",2017-08-13 07:30:59,2017-08-14 22:02:06
PR,Implements tf arg for complex numbers Closes 483,The following code runs as expected so I believe that the gradients are working fine,,"lakshayg,aselle,aselle,aselle,lakshayg,lakshayg,aselle,lakshayg,lakshayg,rmlarsen,rmlarsen,rmlarsen,rmlarsen,lakshayg,lakshayg,rmlarsen,rmlarsen,lakshayg,rmlarsen,caisq,lakshayg,lakshayg,drpngx,lakshayg,drpngx,lakshayg,drpngx,lakshayg,drpngx,drpngx,drpngx,lakshayg,drpngx,lakshayg,drpngx,lakshayg,gunan,drpngx,lakshayg,drpngx,lakshayg,drpngx,lakshayg,lakshayg,vrv,lakshayg,gunan,vrv,lakshayg,vrv,asimshankar,rmlarsen,rmlarsen,rmlarsen,lakshayg,asimshankar,rmlarsen",2017-06-12 03:54:43,2017-08-14 23:27:13
PR,Branch 165220185,Need a push for 1 3 cherrypicks,,av8ramit,2017-08-14 21:58:39,2017-08-14 23:52:07
IS,Is full matrices False working for tf svd,I am working with tensorflow svd decomposition and I notice that the svd results do not have any differences for singular matrix no matter I set full matrices False or to be True For example The results are always same no matter full matrices False or True However the online doc says If true compute full sized u and v If false the default compute only the leading P singular vectors So I wonder if there is a bug for this argument Thanks,,"yaroslavvb,reedwm",2017-08-09 20:58:57,2017-08-15 00:07:41
IS,learner run Could not find trained model,I have built my custom experiment like this When I run it I have files created in model with names like 'model ckpt 6 meta' plus the monitor shows the following results Monitors are deprecated Please use tf train SessionRunHook INFO tensorflow step 1 loss 0 0437659 INFO tensorflow Saving checkpoints for 1 into model model ckpt INFO tensorflow Saving checkpoints for 6 into model model ckpt INFO tensorflow Saving checkpoints for 11 into model model ckpt INFO tensorflow Saving checkpoints for 16 into model model ckpt INFO tensorflow Saving checkpoints for 20 into model model ckpt INFO tensorflow Loss for final step 0 0438498 NotFittedError Traceback most recent call last ipython input 3 4a9282b8a5f5 in module 177 learning rate 0 01 178 decay rate 0 96 179 decay steps 10 180 181 C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn learn runner py in run experiment fn output dir schedule run config hparams 208 schedule schedule or get default schedule run config 209 210 return execute schedule experiment schedule 211 212 C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn learn runner py in execute schedule experiment schedule 45 logging error 'Allowed values for this experiment are s' valid tasks 46 raise TypeError 'Schedule references non callable member s' schedule 47 return task 48 49 C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn experiment py in train and evaluate self 499 metrics self eval metrics 500 name eval dir suffix 501 hooks self eval hooks 502 export results self maybe export eval result 503 return eval result export results C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn experiment py in call evaluate self sentinel input fn steps metrics name checkpoint path hooks 686 name name 687 checkpoint path checkpoint path 688 hooks hooks 689 690 C Program Files Anaconda3 lib site packages tensorflow python util deprecation py in new func args kwargs 287 'in a future version' if date is None else 'after s' date 288 instructions 289 return func args kwargs 290 return tf decorator make decorator func new func wouldeprecated' 291 add deprecated arg notice to docstring C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn estimators estimator py in evaluate self x y input fn feed fn batch size steps metrics name checkpoint path hooks log progress 541 checkpoint path checkpoint path 542 hooks hooks 543 log progress log progress 544 545 if eval results is not None C Program Files Anaconda3 lib site packages tensorflow contrib learn python learn estimators estimator py in evaluate model self input fn steps feed fn metrics name checkpoint path hooks log progress 814 if not latest path 815 raise NotFittedError Could not find trained model at s 816 self model dir 817 checkpoint path latest path 818 NotFittedError Could not find trained model at model Why it cannot find the model Thanks for assistance,,reedwm,2017-08-10 19:02:09,2017-08-15 00:13:33
IS,Integrating both Tensorflow an Caffe in C,System information I wrote custom code Ubuntu 14 04 TensorFlow installed from source TF 1 2 1 C API No Bazel CUDA 7 5 Describe the problem Hello I am trying to write a code in C using the Eclipse IDE without Bazel To get my project to do this I had to perform some hacks to generate the Tensorflow C APIs Tensorflow C seems to be working fine I can load a model and perform predictions I have another code that uses a Caffe library to do something else These both seem to work fine separately I want to integrate BOTH Tensorflow and Caffe in my code When I include both libraries I get issues that seem to imply that both TF C and Caffe which uses glog redefine certain things This leads to my code not working Is there a way to make TF use glog Am I doing something wrong It seems that this is a bug Thank you for any help Source code logs In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 87 0 warning LOG redefined enabled by default define LOG severity TF LOG severity In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 483 0 note this is the location of the previous definition define LOG severity COMPACT GOOGLE LOG severity stream In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 117 0 warning VLOG IS ON redefined enabled by default define VLOG IS ON lvl VLOG IS ON lvl FILE In file included from usr include glog logging h 490 0 from bin caffe master distribute include caffe common hpp 6 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog vlog is on h 82 0 note this is the location of the previous definition define VLOG IS ON verboselevel In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 119 0 warning VLOG redefined enabled by default define VLOG lvl In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 1068 0 note this is the location of the previous definition define VLOG verboselevel LOG IF INFO VLOG IS ON verboselevel In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 127 0 warning CHECK redefined enabled by default define CHECK condition In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 561 0 note this is the location of the previous definition define CHECK condition In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 268 0 warning CHECK OP LOG redefined enabled by default define CHECK OP LOG name op val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 719 0 note this is the location of the previous definition define CHECK OP LOG name op val1 val2 log In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 276 0 warning CHECK OP redefined enabled by default define CHECK OP name op val1 val2 CHECK OP LOG name op val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 740 0 note this is the location of the previous definition define CHECK OP name op val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 279 0 warning CHECK EQ redefined enabled by default define CHECK EQ val1 val2 CHECK OP Check EQ val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 765 0 note this is the location of the previous definition define CHECK EQ val1 val2 CHECK OP EQ val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 280 0 warning CHECK NE redefined enabled by default define CHECK NE val1 val2 CHECK OP Check NE val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 766 0 note this is the location of the previous definition define CHECK NE val1 val2 CHECK OP NE val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 281 0 warning CHECK LE redefined enabled by default define CHECK LE val1 val2 CHECK OP Check LE val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 767 0 note this is the location of the previous definition define CHECK LE val1 val2 CHECK OP LE val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 282 0 warning CHECK LT redefined enabled by default define CHECK LT val1 val2 CHECK OP Check LT val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 768 0 note this is the location of the previous definition define CHECK LT val1 val2 CHECK OP LT val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 283 0 warning CHECK GE redefined enabled by default define CHECK GE val1 val2 CHECK OP Check GE val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 769 0 note this is the location of the previous definition define CHECK GE val1 val2 CHECK OP GE val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 284 0 warning CHECK GT redefined enabled by default define CHECK GT val1 val2 CHECK OP Check GT val1 val2 In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 770 0 note this is the location of the previous definition define CHECK GT val1 val2 CHECK OP GT val1 val2 In file included from usr local include tf tensorflow core platform logging h 25 0 from usr local include tf tensorflow core lib core status h 25 from usr local include tf tensorflow core framework variant h 28 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core platform default logging h 285 0 warning CHECK NOTNULL redefined enabled by default define CHECK NOTNULL val In file included from bin caffe master distribute include caffe common hpp 6 0 from bin caffe master distribute include caffe blob hpp 8 from bin caffe master distribute include caffe caffe hpp 7 from home yevgeniy Desktop tovarish ExtraLibraries GOTURN master src network regressor h 4 from ME T42 cpp 24 usr include glog logging h 775 0 note this is the location of the previous definition define CHECK NOTNULL val In file included from ME T42 cpp 62 0 usr local include tf tensorflow core lib core status h 37 7 error expected identifier before int class Status In file included from usr local include tf tensorflow core framework variant h 28 0 from usr local include tf tensorflow core framework allocator h 26 from usr local include tf tensorflow core framework tensor h 22 from usr local include tf tensorflow cc framework ops h 21 from usr local include tf tensorflow cc ops const op h 19 from ME T42 cpp 297 usr local include tf tensorflow core lib core status h 37 14 error expected unqualified id before token class Status ME T42 cpp 2862 1 error expected at end of input ME T42 cpp 197 12 warning c defined but not used Wunused variable static int c 0 make ME T42 o Error 1,,reedwm,2017-08-14 19:50:48,2017-08-15 00:57:06
IS,Output quantized graphs,Feature It would be nice if it was easy to output as a u8 instead of a f32 between 0 1 I think a simple modification to should do it quantized output would be symmetrical,,reedwm,2017-08-14 21:29:02,2017-08-15 01:00:16
IS,numpy 1 11 0 is not sufficient repro script included,Our pip package includes a dependency on numpy 1 11 0 1 However when numpy version 1 11 0 is already installed and then the user installs TensorFlow TensorFlow fails to load with the following error 1 L35,,"wchargin,skye,yifeif,wchargin",2017-08-10 17:53:28,2017-08-15 01:42:08
PR,Update requirement for numpy,Autograd requires numpy 1 12 1 If numpy 1 11 0 is already installed on the system pip will not upgrade numpy when installing tensorflow Fix 12185,,yifeif,2017-08-14 17:49:41,2017-08-15 01:42:08
IS,CUDA ERROR OUT OF MEMORY,,,reedwm,2017-08-12 15:28:22,2017-08-15 03:35:53
IS,No module named 'tensorflow',I downloaded the Anaconda 4 1 1 For Windows with Python 3 5 2 version Create a conda environment named tensorflow by invoking the following command C conda create n tensorflow Activate the conda environment by issuing the following command C activate tensorflow tensorflow C I install the CPU only version of TensorFlow I installed it successfully but then c python python version 3 5 2 anaconda import tensorflow as tf it appears this Error Traceback File line 1 in ModuleNotFoundError No module named 'tensorflow',,,2017-08-14 03:55:23,2017-08-15 04:12:33
IS,ValueError At least one of the merge inputs is None,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes it is my code that does not work as expected OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 1 LTS TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version 2 7 12 Bazel version if compiling from source Build label 0 4 5 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Thu Mar 16 12 19 38 2017 1489666778 Build timestamp 1489666778 Build timestamp as int 1489666778 CUDA cuDNN version 5 GPU model and memory GTX 1080 8GB Exact command to reproduce See below Describe the problem The code below crashes with the error shown below although I see no reason why it should not work fine Source code logs,,"nolanliou,nolanliou",2017-08-10 13:17:36,2017-08-15 14:36:58
IS,Fail to tune the number of CPU for training,System information uname a Linux aws prophet tf01 4 4 53 1 el7 centos x86 64 1 SMP Sun Mar 12 12 38 41 EDT 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 3 0 tensorflow 1 2 1 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem We are using TensorFlow to benchmark and train an simple neural network model We found that the usage of CPU was around 200 while we have more idle CPUs And we have manually set the configuration of session like this which will not work,,"yaroslavvb,yaroslavvb",2017-08-14 01:53:35,2017-08-15 15:28:41
IS,tf string split did not behave the same as that split in python,In python if we split the following string 'a ' split ' ' we will get a list of two elements 'a' '' While in tensorflow if we use tf string split we will get an sparsetensor with only one elements For reproduction you can run the following piece of code As a result when we use tf string split we do not know whether the 2 is before or after the I think such behavior is undesirable since we usually have missing values when decoding csv files,,"yongtang,rohan100jain,yongtang",2017-08-08 13:38:45,2017-08-15 16:24:38
PR,Add skip empty option to tf string split,This fix add skip empty to tf string split so that it is possible to have tf string split behaving similiarly with python This fix fixes 12108 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,asimshankar,rmlarsen,rmlarsen,yongtang,rmlarsen",2017-08-09 01:40:57,2017-08-15 16:24:38
IS,android detection,I use the android demo but in my mobile I can not get the bounding box I do not know what result it,,andrewharp,2017-08-15 07:01:13,2017-08-15 17:16:28
IS,Loss stays a constant 0 6931 while training,i just add the out maps to a big value step 0 loss 0 6773 accuracy 0 61 step 1 loss 2 4587 accuracy 0 66 step 2 loss 5 3353 accuracy 0 32 step 3 loss 1 0234 accuracy 0 52 step 4 loss 10 6901 accuracy 0 67 step 5 loss 1 9899 accuracy 0 62 step 6 loss 3 5713 accuracy 0 63 step 7 loss 0 6869 accuracy 0 64 step 8 loss 0 6931 accuracy 0 65 step 9 loss 0 6931 accuracy 0 60 step 9 loss 0 6931 accuracy 0 66 step 10 loss 0 6931 accuracy 0 70 step 11 loss 0 6931 accuracy 0 58 step 12 loss 0 6931 accuracy 0 72 step 13 loss 0 6931 accuracy 0 81 step 14 loss 0 6931 accuracy 0 67 step 15 loss 0 6931 accuracy 0 68 step 16 loss 0 6931 accuracy 0 72 step 17 loss 0 6931 accuracy 0 72 step 18 loss 0 6931 accuracy 0 71 step 19 loss 0 6931 accuracy 0 72 step 19 loss 0 6931 accuracy 0 66 step 20 loss 0 6931 accuracy 0 60 step 21 loss 0 6931 accuracy 0 66 step 22 loss 0 6931 accuracy 0 70 step 23 loss 0 6931 accuracy 0 73 step 24 loss 0 6931 accuracy 0 69 step 25 loss 0 6931 accuracy 0 59 step 26 loss 0 6931 accuracy 0 69 step 27 loss 0 6931 accuracy 0 76 step 28 loss 0 6931 accuracy 0 72 step 29 loss 0 6931 accuracy 0 67 step 29 loss 0 6931 accuracy 0 67 step 30 loss 0 6931 accuracy 0 66 step 31 loss 0 6931 accuracy 0 74 step 32 loss 0 6931 accuracy 0 75 step 33 loss 0 6931 accuracy 0 80 step 34 loss 0 6931 accuracy 0 57,,yaroslavvb,2017-08-15 07:06:27,2017-08-15 17:25:53
PR,Cherrypicks,wolffg had to patch yours in in the last commit please verify everything is right,,av8ramit,2017-08-15 00:22:01,2017-08-15 17:33:48
PR,Updating the version to 1 3 0,Updating version for final release,,av8ramit,2017-08-15 17:36:10,2017-08-15 17:40:47
IS,Tutorial code on linear regression is missing a line,Hello The tutorial code on the main website is missing a line that makes it crash when testing Here is the page of the tutorial Here is the said code after the input fn tf contrib learn io numpy input fn x x train y train 4 num epochs 1000 line Hope it will help someone,,shivaniag,2017-08-15 13:02:15,2017-08-15 18:03:02
IS,MonitoredSession has no close,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Minimum custom code OS Platform and Distribution e g Linux Ubuntu 16 04 mac os 10 12 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 2 7 13 Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Describe the problem Bug MonitoredSession has no close but it should have according to close I think in some cases self sess is not initialized Source code logs minimum code to reproduce with tf train MonitoredTrainingSession as sess sess close compared to working code using simple session with tf Session as sess sess close,,yongtang,2017-08-11 23:36:00,2017-08-15 18:18:42
PR,Fix error caused in MonitoredSession close,This fix tries to address the error raised in 12224 The error was caused by double call on internal close This fix fixes the issue by skipping the error at the end of the close This fix fixes 12224 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,ispirmustafa,caisq,yongtang,caisq,yongtang,yongtang",2017-08-12 03:16:19,2017-08-15 18:18:42
IS,problem in imprting the tensorflow in phython,Hi I installed tensorflow cpu version but I got the following error actually I am using python 3 5 2 so please anyone can help to solve this problem PMicrosoft Windows Version 6 1 7601 Copyright c 2009 Microsoft Corporation All rights reserved C Windows system32 python Python 3 5 2 v3 5 2 4def2a2901a5 Jun 25 2016 22 18 55 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Install AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Install AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Install AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Install AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Install AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"mrry,mrry",2017-08-11 18:16:00,2017-08-15 20:33:26
PR,Add a tf contrib image translate function,Progress on this issue,,"ringw,drpngx,vrv,ringw",2017-06-16 00:22:42,2017-08-15 21:14:07
PR,DO NOT MERGE YET Update gRPC to a version that does not require build patches,Testing for now,,"jhseu,rmlarsen,snnn,jhseu",2017-07-31 20:18:24,2017-08-15 21:33:04
PR,Branch 165340781,,,"rmlarsen,terrytangyuan,rmlarsen,martinwicke,terrytangyuan,martinwicke",2017-08-15 20:05:50,2017-08-15 21:47:45
IS,Android demo SDD Mobilenet model download failed,System information OS Platform and Distribution Windows 10 TensorFlow installed from Source TensorFlow version master branch Python version 2 7 12 Bazel version NA CUDA cuDNN version NA GPU model and memory NA Describe the problem Hi I'm trying to compile the android demo example project just released the August 11 2017 I'm building it with Android Studio and gradlle The build fails downloading the SSD Mobilenet model with this error I can download the other models but not this one How can I fix it Thanks,,"skye,andrewharp,martinwicke,petewarden,andrewharp",2017-08-14 12:44:52,2017-08-15 21:48:04
IS,LNK 2019 errors while building tf label image example on latest github version for tensorflow on windows,Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 Bit TensorFlow installed from source or binary Source TensorFlow version use command below Output copied below Python version 3 5 3 Anaconda Bazel version if compiling from source CUDA cuDNN version 8 0 GPU model and memory Exact command to reproduce Building tf label image example project in Release mode cat etc issue MINGW64 NT 10 0 DESKTOP SL66NSK 2 8 0 0 309 5 3 2017 05 19 13 17 x86 64 Msys are we in docker No compiler bash c command not found uname a MINGW64 NT 10 0 DESKTOP SL66NSK 2 8 0 0 309 5 3 2017 05 19 13 17 x86 64 Msys check pips numpy 1 12 1 numpydoc 0 6 0 check for virtualenv False tensorflow import Traceback most recent call last File line 1 in ModuleNotFoundError No module named 'tensorflow' env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi bash nvidia smi command not found cuda libs Describe the problem I downloaded the latest source code from github and used the windows instructions I used Anaconda installation instructions and followed this with installation from source I am running into LNK 2019 errors while building tf label image example Source code logs 105 Creating library E AIMLDL TensorFlow tensorflow 8 14 tensorflow tensorflow contrib cmake build Release tf label image example lib and object E AIMLDL TensorFlow tensorflow 8 14 tensorflow tensorflow contrib cmake build Release tf label image example exp 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees DecisionTreeConfig cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeConfig trees boosted trees tensorflow arena protobuf google sapeavdecisiontreeconfig trees boosted trees tensorflow peav012 z 105 prediction ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow qeaa XZ 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow qeaa XZ 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees trees DecisionTreeConfig Swap class tensorflow boosted trees trees DecisionTreeConfig Swap DecisionTreeConfig trees boosted trees tensorflow qeaaxpeav1234 z referenced in function public virtual void cdecl tensorflow AddTreesToEnsembleOp Compute class tensorflow OpKernelContext const Compute AddTreesToEnsembleOp tensorflow ueaaxqeavopkernelcontext 2 z 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig class google protobuf Arena 0DecisionTreeConfig trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees DecisionTreeConfig cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeConfig trees boosted trees tensorflow arena protobuf google sapeavdecisiontreeconfig trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig class google protobuf Arena 0DecisionTreeConfig trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata void 0DecisionTreeMetadata trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees DecisionTreeMetadata cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeMetadata trees boosted trees tensorflow arena protobuf google sapeavdecisiontreemetadata trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata void 0DecisionTreeMetadata trees boosted trees tensorflow qeaa XZ 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata class google protobuf Arena 0DecisionTreeMetadata trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees DecisionTreeMetadata cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeMetadata trees boosted trees tensorflow arena protobuf google sapeavdecisiontreemetadata trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata class google protobuf Arena 0DecisionTreeMetadata trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig void 0DecisionTreeEnsembleConfig trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees DecisionTreeEnsembleConfig cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeEnsembleConfig trees boosted trees tensorflow arena protobuf google sapeavdecisiontreeensembleconfig trees boosted trees tensorflow peav012 z 105 model ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig void 0DecisionTreeEnsembleConfig trees boosted trees tensorflow qeaa XZ 105 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig class google protobuf Arena 0DecisionTreeEnsembleConfig trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees DecisionTreeEnsembleConfig cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDecisionTreeEnsembleConfig trees boosted trees tensorflow arena protobuf google sapeavdecisiontreeensembleconfig trees boosted trees tensorflow peav012 z 105 model ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig class google protobuf Arena 0DecisionTreeEnsembleConfig trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 prediction ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner AveragingConfig default instance AveragingConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VAveragingConfig learner boosted trees tensorflow Internal protobuf google A referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow qeaa QEAVOpKernelConstruction 2 z 105 prediction ops cc obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner LearnerConfig default instance LearnerConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VLearnerConfig learner boosted trees tensorflow Internal protobuf google A 105 training ops cc obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner LearnerConfig default instance LearnerConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VLearnerConfig learner boosted trees tensorflow Internal protobuf google A 105 prediction ops cc obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner LearningRateConfig default instance LearningRateConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VLearningRateConfig learner boosted trees tensorflow Internal protobuf google A 105 training ops cc obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner LearningRateConfig default instance LearningRateConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VLearningRateConfig learner boosted trees tensorflow Internal protobuf google A 105 prediction ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees trees DecisionTreeEnsembleConfig default instance DecisionTreeEnsembleConfig default instance trees boosted trees tensorflow 3v ExplicitlyConstructed VDecisionTreeEnsembleConfig trees boosted trees tensorflow Internal protobuf google A referenced in function private void cdecl tensorflow boosted trees GradientTreesPredictionOp DoCompute class tensorflow OpKernelContext class tensorflow boosted trees models DecisionTreeEnsembleResource DoCompute GradientTreesPredictionOp boosted trees tensorflow aeaaxpeavopkernelcontext 3 PEAVDecisionTreeEnsembleResource models 23 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 1DecisionTreeConfig trees boosted trees tensorflow UEAA XZ referenced in function private void cdecl tensorflow boosted trees GradientTreesPartitionExamplesOp DoCompute class tensorflow OpKernelContext class tensorflow boosted trees models DecisionTreeEnsembleResource DoCompute GradientTreesPartitionExamplesOp boosted trees tensorflow aeaaxpeavopkernelcontext 3 PEAVDecisionTreeEnsembleResource models 23 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig void 1DecisionTreeEnsembleConfig trees boosted trees tensorflow UEAA XZ referenced in function private void cdecl tensorflow boosted trees GradientTreesPredictionOp DoCompute class tensorflow OpKernelContext class tensorflow boosted trees models DecisionTreeEnsembleResource DoCompute GradientTreesPredictionOp boosted trees tensorflow aeaaxpeavopkernelcontext 3 PEAVDecisionTreeEnsembleResource models 23 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig DecisionTreeEnsembleConfig class tensorflow boosted trees trees DecisionTreeEnsembleConfig const 0DecisionTreeEnsembleConfig trees boosted trees tensorflow qeaa AEBV0123 z referenced in function private void cdecl tensorflow boosted trees GradientTreesPredictionOp DoCompute class tensorflow OpKernelContext class tensorflow boosted trees models DecisionTreeEnsembleResource DoCompute GradientTreesPredictionOp boosted trees tensorflow aeaaxpeavopkernelcontext 3 PEAVDecisionTreeEnsembleResource models 23 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees learner AveragingConfig AveragingConfig void 0AveragingConfig learner boosted trees tensorflow qeaa XZ referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow qeaa QEAVOpKernelConstruction 2 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees learner AveragingConfig AveragingConfig void 1AveragingConfig learner boosted trees tensorflow UEAA XZ referenced in function public virtual void cdecl tensorflow boosted trees GradientTreesPredictionOp scalar deleting destructor' unsigned int GGradientTreesPredictionOp boosted trees tensorflow UEAAPEAXI Z 105 prediction ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees learner AveragingConfig CopyFrom class tensorflow boosted trees learner AveragingConfig const CopyFrom AveragingConfig learner boosted trees tensorflow QEAAXAEBV1234 Z referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow QEAA QEAVOpKernelConstruction 2 Z 105 prediction ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig LearningRateDropoutDrivenConfig void 0LearningRateDropoutDrivenConfig learner boosted trees tensorflow QEAA XZ referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow QEAA QEAVOpKernelConstruction 2 Z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig LearningRateDropoutDrivenConfig void 0LearningRateDropoutDrivenConfig learner boosted trees tensorflow QEAA XZ 105 prediction ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig LearningRateDropoutDrivenConfig void 1LearningRateDropoutDrivenConfig learner boosted trees tensorflow UEAA XZ referenced in function public virtual void cdecl tensorflow boosted trees GradientTreesPredictionOp scalar deleting destructor' unsigned int GGradientTreesPredictionOp boosted trees tensorflow ueaapeaxi Z 105 training ops cc obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig LearningRateDropoutDrivenConfig void 1LearningRateDropoutDrivenConfig learner boosted trees tensorflow UEAA XZ 105 prediction ops cc obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees learner LearningRateDropoutDrivenConfig const cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig default instance void default instance LearningRateDropoutDrivenConfig learner boosted trees tensorflow saaebv1234 XZ 105 training ops cc obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees learner LearningRateDropoutDrivenConfig const cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig default instance void default instance LearningRateDropoutDrivenConfig learner boosted trees tensorflow saaebv1234 XZ 105 prediction ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig CopyFrom class tensorflow boosted trees learner LearningRateDropoutDrivenConfig const CopyFrom LearningRateDropoutDrivenConfig learner boosted trees tensorflow qeaaxaebv1234 z referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow qeaa QEAVOpKernelConstruction 2 z 105 training ops cc obj error LNK2001 unresolved external symbol public void cdecl tensorflow boosted trees learner LearningRateDropoutDrivenConfig CopyFrom class tensorflow boosted trees learner LearningRateDropoutDrivenConfig const CopyFrom LearningRateDropoutDrivenConfig learner boosted trees tensorflow qeaaxaebv1234 z 105 prediction ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 0LearnerConfig learner boosted trees tensorflow qeaa XZ referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow qeaa QEAVOpKernelConstruction 2 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 0LearnerConfig learner boosted trees tensorflow qeaa XZ 105 prediction ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 0LearnerConfig learner boosted trees tensorflow qeaa XZ 105 prediction ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 1LearnerConfig learner boosted trees tensorflow UEAA XZ referenced in function public cdecl tensorflow boosted trees GradientTreesPredictionOp GradientTreesPredictionOp class tensorflow OpKernelConstruction const 0GradientTreesPredictionOp boosted trees tensorflow qeaa QEAVOpKernelConstruction 2 z 105 training ops cc obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 1LearnerConfig learner boosted trees tensorflow UEAA XZ 105 prediction ops cc obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees learner LearnerConfig LearnerConfig void 1LearnerConfig learner boosted trees tensorflow UEAA XZ 105 quantile ops cc obj error LNK2019 unresolved external symbol public cdecl boosted trees QuantileConfig QuantileConfig void 0QuantileConfig boosted trees qeaa XZ referenced in function void cdecl tensorflow anonymous namespace' ParseConfig class tensorflow OpKernelConstruction const class std basic string char struct std char traits char class std allocator char const class std vector class boosted trees QuantileConfig class std allocator class boosted trees QuantileConfig ParseConfig A0xff956ef5 tensorflow YAXQEAVOpKernelConstruction 2 AEBV basic string DU char traits D std V allocator D 2 std PEAV vector VQuantileConfig boosted trees V allocator VQuantileConfig boosted trees std 5 Z 105 quantile ops cc obj error LNK2019 unresolved external symbol public virtual cdecl boosted trees QuantileConfig QuantileConfig void 1QuantileConfig boosted trees UEAA XZ referenced in function void cdecl tensorflow anonymous namespace' ParseConfig class tensorflow OpKernelConstruction const class std basic string char struct std char traits class std allocator const class std vector class boosted trees QuantileConfig class std allocator ParseConfig A0xff956ef5 tensorflow yaxqeavopkernelconstruction 2 AEBV basic string DU char traits D std v allocator D 2 std peav vector VQuantileConfig boosted trees v allocator VQuantileConfig boosted trees std 5 z 105 quantile ops cc obj error LNK2019 unresolved external symbol public cdecl boosted trees QuantileConfig QuantileConfig class boosted trees QuantileConfig const 0QuantileConfig boosted trees qeaa AEBV01 z referenced in function class boosted trees QuantileConfig cdecl std Uninitialized move al unchecked1 class boosted trees QuantileConfig class boosted trees QuantileConfig class std allocator class boosted trees QuantileConfig class boosted trees QuantileConfig class boosted trees QuantileConfig struct std Wrap alloc class std allocator struct std General ptr iterator tag struct std Any tag Uninitialized move al unchecked1 PEAVQuantileConfig boosted trees peav12 V allocator VQuantileConfig boosted trees std std yapeavquantileconfig boosted trees peav12 00AEAU Wrap alloc V allocator VQuantileConfig boosted trees std 0 U General ptr iterator tag 0 U Any tag 0 z 105 quantile ops cc obj error LNK2019 unresolved external symbol public cdecl boosted trees QuantileEntry QuantileEntry void 0QuantileEntry boosted trees qeaa XZ referenced in function public static class boosted trees QuantileEntry cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VQuantileEntry boosted trees arena protobuf google sapeavquantileentry boosted trees peav012 z 105 quantile ops cc obj error LNK2019 unresolved external symbol protected cdecl boosted trees QuantileEntry QuantileEntry class google protobuf Arena 0QuantileEntry boosted trees iEAA PEAVArena protobuf google z referenced in function public static class boosted trees QuantileEntry cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VQuantileEntry boosted trees arena protobuf google sapeavquantileentry boosted trees peav012 z 105 quantile ops cc obj error LNK2019 unresolved external symbol public cdecl boosted trees QuantileSummaryState QuantileSummaryState void 0QuantileSummaryState boosted trees qeaa XZ referenced in function public static class boosted trees QuantileSummaryState cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VQuantileSummaryState boosted trees arena protobuf google sapeavquantilesummarystate boosted trees peav012 z 105 quantile ops cc obj error LNK2019 unresolved external symbol protected cdecl boosted trees QuantileSummaryState QuantileSummaryState class google protobuf Arena 0QuantileSummaryState boosted trees iEAA PEAVArena protobuf google z referenced in function public virtual void cdecl tensorflow QuantileAccumulatorFlushSummaryOp Compute class tensorflow OpKernelContext Compute QuantileAccumulatorFlushSummaryOp tensorflow ueaaxpeavopkernelcontext 2 z 105 quantile ops cc obj error LNK2019 unresolved external symbol public cdecl boosted trees QuantileStreamState QuantileStreamState void 0QuantileStreamState boosted trees qeaa XZ referenced in function public virtual void cdecl tensorflow QuantileAccumulatorDeserializeOp Compute class tensorflow OpKernelContext Compute QuantileAccumulatorDeserializeOp tensorflow ueaaxpeavopkernelcontext 2 z 105 quantile ops cc obj error LNK2019 unresolved external symbol public virtual cdecl boosted trees QuantileStreamState QuantileStreamState void 1QuantileStreamState boosted trees UEAA XZ referenced in function public virtual void cdecl tensorflow QuantileAccumulatorDeserializeOp Compute class tensorflow OpKernelContext Compute QuantileAccumulatorDeserializeOp tensorflow ueaaxpeavopkernelcontext 2 z 105 quantile ops cc obj error LNK2019 unresolved external symbol protected cdecl boosted trees QuantileStreamState QuantileStreamState class google protobuf Arena 0QuantileStreamState boosted trees iEAA PEAVArena protobuf google z referenced in function public virtual void cdecl tensorflow QuantileAccumulatorSerializeOp Compute class tensorflow OpKernelContext Compute QuantileAccumulatorSerializeOp tensorflow ueaaxpeavopkernelcontext 2 z 105 split handler ops cc obj error LNK2019 unresolved external symbol bool cdecl tensorflow boosted trees learner LearnerConfig MultiClassStrategy IsValid int LearnerConfig MultiClassStrategy IsValid learner boosted trees tensorflow YA NH Z referenced in function public cdecl tensorflow BaseBuildSplitOp BaseBuildSplitOp class tensorflow OpKernelConstruction const 0BaseBuildSplitOp tensorflow qeaa QEAVOpKernelConstruction 1 z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 decision tree obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 training ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 bias feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 categorical feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode clear node void clear node TreeNode trees boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees Leaf clear leaf void clear leaf Leaf trees boosted trees tensorflow aeaaxxz referenced in function public void cdecl tensorflow BaseBuildSplitOp FillLeaf int struct tensorflow boosted trees learner stochastic NodeStats const class tensorflow boosted trees trees Leaf const FillLeaf BaseBuildSplitOp tensorflow qebaxhaebunodestats stochastic learner boosted trees 2 PEAVLeaf trees 62 z 105 training ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees Leaf clear leaf void clear leaf Leaf trees boosted trees tensorflow aeaaxxz 105 bias feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees Leaf clear leaf void clear leaf Leaf trees boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees Vector Vector void 0Vector trees boosted trees tensorflow qeaa XZ referenced in function public void cdecl tensorflow BaseBuildSplitOp FillLeaf int struct tensorflow boosted trees learner stochastic NodeStats const class tensorflow boosted trees trees Leaf const FillLeaf BaseBuildSplitOp tensorflow qebaxhaebunodestats stochastic learner boosted trees 2 PEAVLeaf trees 62 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees Vector Vector void 0Vector trees boosted trees tensorflow qeaa XZ 105 bias feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees Vector Vector void 0Vector trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees Vector Vector class google protobuf Arena 0Vector trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public void cdecl tensorflow BaseBuildSplitOp FillLeaf int struct tensorflow boosted trees learner stochastic NodeStats const class tensorflow boosted trees trees Leaf const FillLeaf BaseBuildSplitOp tensorflow qebaxhaebunodestats stochastic learner boosted trees 2 PEAVLeaf trees 62 z 105 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees Vector Vector class google protobuf Arena 0Vector trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 bias feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees Vector Vector class google protobuf Arena 0Vector trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees SparseVector SparseVector void 0SparseVector trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees SparseVector cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseVector trees boosted trees tensorflow arena protobuf google sapeavsparsevector trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseVector SparseVector void 0SparseVector trees boosted trees tensorflow qeaa XZ 105 bias feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseVector SparseVector void 0SparseVector trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseVector SparseVector class google protobuf Arena 0SparseVector trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees SparseVector cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseVector trees boosted trees tensorflow arena protobuf google sapeavsparsevector trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseVector SparseVector class google protobuf Arena 0SparseVector trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 bias feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseVector SparseVector class google protobuf Arena 0SparseVector trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit void 0DenseFloatBinarySplit trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees DenseFloatBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDenseFloatBinarySplit trees boosted trees tensorflow arena protobuf google sapeavdensefloatbinarysplit trees boosted trees tensorflow peav012 z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit void 0DenseFloatBinarySplit trees boosted trees tensorflow qeaa XZ 105 decision tree obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit void 0DenseFloatBinarySplit trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit class google protobuf Arena 0DenseFloatBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees DenseFloatBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VDenseFloatBinarySplit trees boosted trees tensorflow arena protobuf google sapeavdensefloatbinarysplit trees boosted trees tensorflow peav012 z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit class google protobuf Arena 0DenseFloatBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 decision tree obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DenseFloatBinarySplit DenseFloatBinarySplit class google protobuf Arena 0DenseFloatBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft void 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow arena protobuf google sapeavsparsefloatbinarysplitdefaultleft trees boosted trees tensorflow peav012 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft void 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow qeaa XZ 105 decision tree obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft void 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft class google protobuf Arena 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow arena protobuf google sapeavsparsefloatbinarysplitdefaultleft trees boosted trees tensorflow peav012 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft class google protobuf Arena 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 decision tree obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft SparseFloatBinarySplitDefaultLeft class google protobuf Arena 0SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft slow mutable split void slow mutable split SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow aeaaxxz referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft slow mutable split void slow mutable split SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow aeaaxxz 105 decision tree obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft slow mutable split void slow mutable split SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight void 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseFloatBinarySplitDefaultRight trees boosted trees tensorflow arena protobuf google sapeavsparsefloatbinarysplitdefaultright trees boosted trees tensorflow peav012 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight void 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow qeaa XZ 105 decision tree obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight void 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight class google protobuf Arena 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VSparseFloatBinarySplitDefaultRight trees boosted trees tensorflow arena protobuf google sapeavsparsefloatbinarysplitdefaultright trees boosted trees tensorflow peav012 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight class google protobuf Arena 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 decision tree obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight SparseFloatBinarySplitDefaultRight class google protobuf Arena 0SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight slow mutable split void slow mutable split SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow aeaaxxz referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight slow mutable split void slow mutable split SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow aeaaxxz 105 decision tree obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight slow mutable split void slow mutable split SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit void 0CategoricalIdBinarySplit trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees CategoricalIdBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VCategoricalIdBinarySplit trees boosted trees tensorflow arena protobuf google sapeavcategoricalidbinarysplit trees boosted trees tensorflow peav012 z 105 categorical feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit void 0CategoricalIdBinarySplit trees boosted trees tensorflow qeaa XZ 105 decision tree obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit void 0CategoricalIdBinarySplit trees boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit class google protobuf Arena 0CategoricalIdBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees CategoricalIdBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VCategoricalIdBinarySplit trees boosted trees tensorflow arena protobuf google sapeavcategoricalidbinarysplit trees boosted trees tensorflow peav012 z 105 categorical feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit class google protobuf Arena 0CategoricalIdBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 decision tree obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees CategoricalIdBinarySplit CategoricalIdBinarySplit class google protobuf Arena 0CategoricalIdBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 split handler ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees learner SplitInfo SplitInfo void 0SplitInfo learner boosted trees tensorflow qeaa XZ referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees learner SplitInfo SplitInfo void 0SplitInfo learner boosted trees tensorflow qeaa XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees learner SplitInfo SplitInfo void 1SplitInfo learner boosted trees tensorflow UEAA XZ referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 training ops cc obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees learner SplitInfo SplitInfo void 1SplitInfo learner boosted trees tensorflow UEAA XZ 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable split node void slow mutable split node SplitInfo learner boosted trees tensorflow aeaaxxz referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 training ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable split node void slow mutable split node SplitInfo learner boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable left child void slow mutable left child SplitInfo learner boosted trees tensorflow aeaaxxz referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 training ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable left child void slow mutable left child SplitInfo learner boosted trees tensorflow aeaaxxz 105 split handler ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable right child void slow mutable right child SplitInfo learner boosted trees tensorflow aeaaxxz referenced in function public virtual void cdecl tensorflow BuildSparseInequalitySplitsOp Compute class tensorflow OpKernelContext const Compute BuildSparseInequalitySplitsOp tensorflow ueaaxqeavopkernelcontext 2 z 105 training ops cc obj error LNK2001 unresolved external symbol private void cdecl tensorflow boosted trees learner SplitInfo slow mutable right child void slow mutable right child SplitInfo learner boosted trees tensorflow aeaaxxz 105 training ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees trees GrowingMetadata default instance GrowingMetadata default instance trees boosted trees tensorflow 3v ExplicitlyConstructed VGrowingMetadata trees boosted trees tensorflow Internal protobuf google A referenced in function public virtual void cdecl tensorflow boosted trees GrowTreeEnsembleOp Compute class tensorflow OpKernelContext const Compute GrowTreeEnsembleOp boosted trees tensorflow ueaaxqeavopkernelcontext 3 z 105 training ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees trees TreeNodeMetadata default instance TreeNodeMetadata default instance trees boosted trees tensorflow 3v ExplicitlyConstructed VTreeNodeMetadata trees boosted trees tensorflow Internal protobuf google A referenced in function private void cdecl tensorflow boosted trees GrowTreeEnsembleOp PruneTree class tensorflow boosted trees trees DecisionTreeConfig PruneTree GrowTreeEnsembleOp boosted trees tensorflow aeaaxpeavdecisiontreeconfig trees 23 z 105 training ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeConstraintsConfig default instance TreeConstraintsConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeConstraintsConfig learner boosted trees tensorflow Internal protobuf google A referenced in function private struct std pair class tensorflow boosted trees trees DecisionTreeConfig class tensorflow boosted trees trees DecisionTreeMetadata cdecl tensorflow boosted trees GrowTreeEnsembleOp UpdateAndRetrieveGrowableTree class tensorflow boosted trees models DecisionTreeEnsembleResource float unsigned int64 UpdateAndRetrieveGrowableTree GrowTreeEnsembleOp boosted trees tensorflow Aeaa AU pair PEAVDecisionTreeConfig trees boosted trees tensorflow peavdecisiontreemetadata 234 std peavdecisiontreeensembleresource models 23 M K Z 105 categorical feature column handler obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeConstraintsConfig default instance TreeConstraintsConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeConstraintsConfig learner boosted trees tensorflow Internal protobuf google A 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeConstraintsConfig default instance TreeConstraintsConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeConstraintsConfig learner boosted trees tensorflow Internal protobuf google A 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeConstraintsConfig default instance TreeConstraintsConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeConstraintsConfig learner boosted trees tensorflow Internal protobuf google A 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode void 0TreeNode trees boosted trees tensorflow qeaa XZ 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode void 0TreeNode trees boosted trees tensorflow qeaa XZ 105 bias feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode void 0TreeNode trees boosted trees tensorflow qeaa XZ 105 categorical feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode void 0TreeNode trees boosted trees tensorflow qeaa XZ 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode void 0TreeNode trees boosted trees tensorflow qeaa XZ 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode class tensorflow boosted trees trees TreeNode const 0TreeNode trees boosted trees tensorflow qeaa AEBV0123 z 105 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode class tensorflow boosted trees trees TreeNode const 0TreeNode trees boosted trees tensorflow qeaa AEBV0123 z 105 bias feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode class tensorflow boosted trees trees TreeNode const 0TreeNode trees boosted trees tensorflow qeaa AEBV0123 z 105 categorical feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode class tensorflow boosted trees trees TreeNode const 0TreeNode trees boosted trees tensorflow qeaa AEBV0123 z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees TreeNode TreeNode class tensorflow boosted trees trees TreeNode const 0TreeNode trees boosted trees tensorflow qeaa AEBV0123 z 105 training ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees trees TreeNode CopyFrom class tensorflow boosted trees trees TreeNode const CopyFrom TreeNode trees boosted trees tensorflow qeaaxaebv1234 z referenced in function private void cdecl tensorflow boosted trees GrowTreeEnsembleOp PruneTree class tensorflow boosted trees trees DecisionTreeConfig PruneTree GrowTreeEnsembleOp boosted trees tensorflow aeaaxpeavdecisiontreeconfig trees 23 z 105 categorical feature column handler obj error LNK2001 unresolved external symbol public void cdecl tensorflow boosted trees trees TreeNode CopyFrom class tensorflow boosted trees trees TreeNode const CopyFrom TreeNode trees boosted trees tensorflow qeaaxaebv1234 z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol public void cdecl tensorflow boosted trees trees TreeNode CopyFrom class tensorflow boosted trees trees TreeNode const CopyFrom TreeNode trees boosted trees tensorflow qeaaxaebv1234 z 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public void cdecl tensorflow boosted trees trees TreeNode CopyFrom class tensorflow boosted trees trees TreeNode const CopyFrom TreeNode trees boosted trees tensorflow qeaaxaebv1234 z 105 training ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees TreeNode TreeNode class google protobuf Arena 0TreeNode trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees TreeNode cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VTreeNode trees boosted trees tensorflow arena protobuf google sapeavtreenode trees boosted trees tensorflow peav012 z 105 training ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNode slow mutable node metadata void slow mutable node metadata TreeNode trees boosted trees tensorflow aeaaxxz referenced in function void cdecl tensorflow boosted trees anonymous namespace' RecursivePruneTree unsigned int64 class std vector class tensorflow boosted trees trees TreeNode class std allocator class tensorflow boosted trees trees TreeNode RecursivePruneTree A0xaf924787 boosted trees tensorflow YAX KPEAV vector VTreeNode trees boosted trees tensorflow V allocator VTreeNode trees boosted trees tensorflow std std Z 105 training ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees TreeNodeMetadata slow mutable original leaf void slow mutable original leaf TreeNodeMetadata trees boosted trees tensorflow AEAAXXZ referenced in function void cdecl tensorflow boosted trees anonymous namespace' RecursivePruneTree unsigned int64 class std vector class tensorflow boosted trees trees TreeNode class std allocator RecursivePruneTree A0xaf924787 boosted trees tensorflow YAX KPEAV vector VTreeNode trees boosted trees tensorflow v allocator VTreeNode trees boosted trees tensorflow std std z 105 training ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees Leaf Leaf void 0Leaf trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees Leaf cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VLeaf trees boosted trees tensorflow arena protobuf google sapeavleaf trees boosted trees tensorflow peav012 z 105 bias feature column handler obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees Leaf Leaf void 0Leaf trees boosted trees tensorflow qeaa XZ 105 training ops cc obj error LNK2019 unresolved external symbol public static class tensorflow boosted trees trees Leaf const cdecl tensorflow boosted trees trees Leaf default instance void default instance Leaf trees boosted trees tensorflow saaebv1234 XZ referenced in function private void cdecl tensorflow boosted trees GrowTreeEnsembleOp SplitTreeNode int struct tensorflow boosted trees anonymous namespace' SplitCandidate class tensorflow boosted trees trees DecisionTreeConfig SplitTreeNode GrowTreeEnsembleOp boosted trees tensorflow AEAAXHPEAUSplitCandidate A0xaf924787 23 PEAVDecisionTreeConfig trees 23 Z 105 multiple additive trees obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees Leaf const cdecl tensorflow boosted trees trees Leaf default instance void default instance Leaf trees boosted trees tensorflow SAAEBV1234 XZ 105 training ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees trees Leaf CopyFrom class tensorflow boosted trees trees Leaf const CopyFrom Leaf trees boosted trees tensorflow QEAAXAEBV1234 Z referenced in function void cdecl tensorflow boosted trees anonymous namespace' RecursivePruneTree unsigned int64 class std vector class tensorflow boosted trees trees TreeNode class std allocator RecursivePruneTree A0xaf924787 boosted trees tensorflow YAX KPEAV vector VTreeNode trees boosted trees tensorflow v allocator VTreeNode trees boosted trees tensorflow std std z 105 training ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees Leaf Leaf class google protobuf Arena 0Leaf trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees Leaf cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VLeaf trees boosted trees tensorflow arena protobuf google sapeavleaf trees boosted trees tensorflow peav012 z 105 bias feature column handler obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees Leaf Leaf class google protobuf Arena 0Leaf trees boosted trees tensorflow iEAA PEAVArena protobuf google z 105 training ops cc obj error LNK2019 unresolved external symbol public static class tensorflow boosted trees trees Vector const cdecl tensorflow boosted trees trees Vector default instance void default instance Vector trees boosted trees tensorflow saaebv1234 XZ referenced in function public virtual void cdecl tensorflow boosted trees CenterTreeEnsembleBiasOp Compute class tensorflow OpKernelContext const Compute CenterTreeEnsembleBiasOp boosted trees tensorflow ueaaxqeavopkernelcontext 3 z 105 multiple additive trees obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees Vector const cdecl tensorflow boosted trees trees Vector default instance void default instance Vector trees boosted trees tensorflow saaebv1234 XZ 105 training ops cc obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees SparseVector const cdecl tensorflow boosted trees trees SparseVector default instance void default instance SparseVector trees boosted trees tensorflow saaebv1234 XZ 105 multiple additive trees obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees SparseVector const cdecl tensorflow boosted trees trees SparseVector default instance void default instance SparseVector trees boosted trees tensorflow saaebv1234 XZ 105 training ops cc obj error LNK2019 unresolved external symbol private void cdecl tensorflow boosted trees trees DecisionTreeEnsembleConfig slow mutable growing metadata void slow mutable growing metadata DecisionTreeEnsembleConfig trees boosted trees tensorflow aeaaxxz referenced in function private class tensorflow boosted trees trees Leaf cdecl tensorflow boosted trees CenterTreeEnsembleBiasOp RetrieveBias class tensorflow boosted trees models DecisionTreeEnsembleResource RetrieveBias CenterTreeEnsembleBiasOp boosted trees tensorflow aeaapeavleaf trees 23 PEAVDecisionTreeEnsembleResource models 23 z 105 training ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees learner SplitInfo SplitInfo class tensorflow boosted trees learner SplitInfo const 0SplitInfo learner boosted trees tensorflow qeaa AEBV0123 z referenced in function public struct std Tree node struct std pair int const struct tensorflow boosted trees anonymous namespace' SplitCandidate void cdecl std Tree comp alloc class std Tmap traits int struct tensorflow boosted trees anonymous namespace' SplitCandidate struct std less class std allocator struct std pair int const struct tensorflow boosted trees anonymous namespace' SplitCandidate 0 Buynode struct std pair int struct tensorflow boosted trees anonymous namespace' SplitCandidate struct std pair int struct tensorflow boosted trees anonymous namespace' SplitCandidate Buynode U pair HUSplitCandidate A0xaf924787 boosted trees tensorflow std Tree comp alloc V Tmap traits HUSplitCandidate A0xaf924787 boosted trees tensorflow U less H std V allocator U pair CBHUSplitCandidate A0xaf924787 boosted trees tensorflow std 6 0A std std QEAAPEAU Tree node U pair CBHUSplitCandidate A0xaf924787 boosted trees tensorflow std PEAX 1 QEAU pair HUSplitCandidate A0xaf924787 boosted trees tensorflow 1 Z 105 training ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees learner SplitInfo CopyFrom class tensorflow boosted trees learner SplitInfo const CopyFrom SplitInfo learner boosted trees tensorflow QEAAXAEBV1234 Z referenced in function void cdecl tensorflow boosted trees anonymous namespace' UpdateBestSplit class tensorflow boosted trees learner LearnerConfig const int struct tensorflow boosted trees A0xaf924787 SplitCandidate class std map int struct tensorflow boosted trees anonymous namespace' SplitCandidate struct std less int class std allocator struct std pair int const struct tensorflow boosted trees anonymous namespace' SplitCandidate UpdateBestSplit A0xaf924787 boosted trees tensorflow yaxaebvlearnerconfig learner 23 HPEAUSplitCandidate 123 PEAV map HUSplitCandidate A0xaf924787 boosted trees tensorflow U less H std v allocator U pair CBHUSplitCandidate A0xaf924787 boosted trees tensorflow std 6 std z 105 training ops cc obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees trees TreeNode default instance TreeNode default instance trees boosted trees tensorflow 3v ExplicitlyConstructed VTreeNode trees boosted trees tensorflow Internal protobuf google A referenced in function private void cdecl tensorflow boosted trees GrowTreeEnsembleOp SplitTreeNode int struct tensorflow boosted trees anonymous namespace' SplitCandidate class tensorflow boosted trees trees DecisionTreeConfig SplitTreeNode GrowTreeEnsembleOp boosted trees tensorflow aeaaxhpeausplitcandidate A0xaf924787 23 PEAVDecisionTreeConfig trees 23 z 105 bias feature column handler obj error LNK2019 unresolved external symbol public virtual cdecl tensorflow boosted trees trees TreeNode TreeNode void 1TreeNode trees boosted trees tensorflow UEAA XZ referenced in function void cdecl std Destroy range class std allocator struct tensorflow boosted trees learner stochastic FeatureSplitCandidate struct tensorflow boosted trees learner stochastic FeatureSplitCandidate struct tensorflow boosted trees learner stochastic FeatureSplitCandidate struct std Wrap alloc class std allocator Destroy range V allocator UFeatureSplitCandidate stochastic learner boosted trees tensorflow std peaufeaturesplitcandidate stochastic learner boosted trees tensorflow std yaxpeaufeaturesplitcandidate stochastic learner boosted trees tensorflow 0aeau Wrap alloc V allocator UFeatureSplitCandidate stochastic learner boosted trees tensorflow std 0 z 105 categorical feature column handler obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees trees TreeNode TreeNode void 1TreeNode trees boosted trees tensorflow UEAA XZ 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees trees TreeNode TreeNode void 1TreeNode trees boosted trees tensorflow UEAA XZ 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol public virtual cdecl tensorflow boosted trees trees TreeNode TreeNode void 1TreeNode trees boosted trees tensorflow UEAA XZ 105 bias feature column handler obj error LNK2019 unresolved external symbol public virtual void cdecl tensorflow boosted trees trees TreeNode Clear void Clear TreeNode trees boosted trees tensorflow ueaaxxz referenced in function public virtual void cdecl tensorflow boosted trees learner stochastic BiasFeatureColumnHandler GenerateFeatureSplitCandidates class tensorflow boosted trees learner LearnerConfig const class std vector int class std allocator const class std vector struct tensorflow boosted trees learner stochastic NodeStats class std allocator const class tensorflow boosted trees learner FeatureStatsAccumulator struct tensorflow boosted trees learner stochastic GradientStats struct tensorflow boosted trees learner stochastic GradientStatsAccumulator const class std vector struct tensorflow boosted trees learner stochastic FeatureSplitCandidate class std allocator const GenerateFeatureSplitCandidates BiasFeatureColumnHandler stochastic learner boosted trees tensorflow uebaxaebvlearnerconfig 345 AEBV vector HV allocator H std std aebv vector UNodeStats stochastic learner boosted trees tensorflow v allocator UNodeStats stochastic learner boosted trees tensorflow std 8 AEBV FeatureStatsAccumulator UGradientStats stochastic learner boosted trees tensorflow ugradientstatsaccumulator 2345 345 PEAV vector UFeatureSplitCandidate stochastic learner boosted trees tensorflow v allocator UFeatureSplitCandidate stochastic learner boosted trees tensorflow std 8 z 105 categorical feature column handler obj error LNK2019 unresolved external symbol public static class tensorflow boosted trees trees CategoricalIdBinarySplit const cdecl tensorflow boosted trees trees CategoricalIdBinarySplit default instance void default instance CategoricalIdBinarySplit trees boosted trees tensorflow saaebv1234 XZ referenced in function public virtual void cdecl tensorflow boosted trees learner stochastic CategoricalFeatureColumnHandler GenerateFeatureSplitCandidates class tensorflow boosted trees learner LearnerConfig const class std vector int class std allocator const class std vector struct tensorflow boosted trees learner stochastic NodeStats class std allocator const class tensorflow boosted trees learner FeatureStatsAccumulator struct tensorflow boosted trees learner stochastic GradientStats struct tensorflow boosted trees learner stochastic GradientStatsAccumulator const class std vector struct tensorflow boosted trees learner stochastic FeatureSplitCandidate class std allocator const GenerateFeatureSplitCandidates CategoricalFeatureColumnHandler stochastic learner boosted trees tensorflow uebaxaebvlearnerconfig 345 AEBV vector HV allocator H std std aebv vector UNodeStats stochastic learner boosted trees tensorflow v allocator UNodeStats stochastic learner boosted trees tensorflow std 8 AEBV FeatureStatsAccumulator UGradientStats stochastic learner boosted trees tensorflow ugradientstatsaccumulator 2345 345 PEAV vector UFeatureSplitCandidate stochastic learner boosted trees tensorflow v allocator UFeatureSplitCandidate stochastic learner boosted trees tensorflow std 8 z 105 decision tree obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees CategoricalIdBinarySplit const cdecl tensorflow boosted trees trees CategoricalIdBinarySplit default instance void default instance CategoricalIdBinarySplit trees boosted trees tensorflow saaebv1234 XZ 105 categorical feature column handler obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeRegularizationConfig default instance TreeRegularizationConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeRegularizationConfig learner boosted trees tensorflow Internal protobuf google A referenced in function public cdecl tensorflow boosted trees learner stochastic SplitStats SplitStats class tensorflow boosted trees learner LearnerConfig const struct tensorflow boosted trees learner stochastic NodeStats const struct tensorflow boosted trees learner stochastic NodeStats const struct tensorflow boosted trees learner stochastic NodeStats const 0SplitStats stochastic learner boosted trees tensorflow qeaa AEBVLearnerConfig 234 AEBUNodeStats 1234 11 Z 105 dense quantized feature column handler obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeRegularizationConfig default instance TreeRegularizationConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeRegularizationConfig learner boosted trees tensorflow Internal protobuf google A 105 sparse quantized feature column handler obj error LNK2001 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees learner TreeRegularizationConfig default instance TreeRegularizationConfig default instance learner boosted trees tensorflow 3v ExplicitlyConstructed VTreeRegularizationConfig learner boosted trees tensorflow Internal protobuf google A 105 decision tree obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees DenseFloatBinarySplit const cdecl tensorflow boosted trees trees DenseFloatBinarySplit default instance void default instance DenseFloatBinarySplit trees boosted trees tensorflow saaebv1234 XZ 105 decision tree obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft const cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultLeft default instance void default instance SparseFloatBinarySplitDefaultLeft trees boosted trees tensorflow saaebv1234 XZ 105 decision tree obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight const cdecl tensorflow boosted trees trees SparseFloatBinarySplitDefaultRight default instance void default instance SparseFloatBinarySplitDefaultRight trees boosted trees tensorflow saaebv1234 XZ 105 decision tree obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit CategoricalIdSetMembershipBinarySplit void 0CategoricalIdSetMembershipBinarySplit trees boosted trees tensorflow qeaa XZ referenced in function public static class tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VCategoricalIdSetMembershipBinarySplit trees boosted trees tensorflow arena protobuf google sapeavcategoricalidsetmembershipbinarysplit trees boosted trees tensorflow peav012 z 105 decision tree obj error LNK2001 unresolved external symbol public static class tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit const cdecl tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit default instance void default instance CategoricalIdSetMembershipBinarySplit trees boosted trees tensorflow saaebv1234 XZ 105 decision tree obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit CategoricalIdSetMembershipBinarySplit class google protobuf Arena 0CategoricalIdSetMembershipBinarySplit trees boosted trees tensorflow iEAA PEAVArena protobuf google z referenced in function public static class tensorflow boosted trees trees CategoricalIdSetMembershipBinarySplit cdecl google protobuf Arena CreateMessage class google protobuf Arena CreateMessage VCategoricalIdSetMembershipBinarySplit trees boosted trees tensorflow arena protobuf google sapeavcategoricalidsetmembershipbinarysplit trees boosted trees tensorflow peav012 z 105 decision tree obj error LNK2019 unresolved external symbol class google protobuf internal ExplicitlyConstructed tensorflow boosted trees trees DenseFloatBinarySplit default instance DenseFloatBinarySplit default instance trees boosted trees tensorflow 3v ExplicitlyConstructed VDenseFloatBinarySplit trees boosted trees tensorflow Internal protobuf google A referenced in function public static class std vector int class std allocator cdecl tensorflow boosted trees trees DecisionTree GetChildren class tensorflow boosted trees trees TreeNode const GetChildren DecisionTree trees boosted trees tensorflow sa AV vector HV allocator H std std aebvtreenode 234 z 105 E AIMLDL TensorFlow tensorflow 8 14 tensorflow tensorflow contrib cmake build Release tf label image example exe fatal error LNK1120 85 unresolved externals Rebuild All 104 succeeded 1 failed 0 skipped,,"reedwm,reedwm",2017-08-15 23:24:33,2017-08-16 00:12:23
IS,compile using bazel test failed on mac,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 11 6 TensorFlow installed from source or binary source TensorFlow version use command below master Python version 3 5 Bazel version if compiling from source 0 5 3 homebrew CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Describe the problem It seems that tensorflow cannot work with clang of Mac And even though I install gcc 4 8 with brew and set export CC gcc 4 8 install dir compile still failed,,"facaiy,reedwm,gunan,facaiy,gunan,facaiy,facaiy",2017-08-14 12:52:33,2017-08-16 12:44:04
IS,Exception when shutting down TensorFlow after running some ops,Error The following error appears when exiting the Python session after a TensorFlow op has been run in a session Most ops seem to trigger this I tried tf square tf add and tf summary scalar and tf summary text and they all do However tf constant does not Introduction Bug introduced between 20170814 and 20170815 nightlies In particular build 588 does not have the bug while build 589 does The changelog for these two builds is b93fd37e143bcdd6339f8e6081c948384a262e0b 1d33a59a9d554be863cfb06e9aa0ce1fa33ce9e6 which does include changes to eager build 588 TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label cpu slave 588 build 589 TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label cpu slave 589,,"wchargin,carlthome,wchargin,wchargin",2017-08-15 23:00:09,2017-08-16 16:55:28
IS,Tensorflow installation fails on python 3 3 6,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 See below TensorFlow installed from source or binary Tried with pip3 TensorFlow version use command below Python version 3 3 6 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script cat etc issue Linux 11bb6e68305e 4 9 36 moby 1 SMP Wed Jul 12 15 29 07 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 14 04 5 LTS Trusty Tahr VERSION ID 14 04 are we in docker Yes compiler c Ubuntu 4 8 4 2ubuntu1 14 04 3 4 8 4 Copyright C 2013 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux 11bb6e68305e 4 9 36 moby 1 SMP Wed Jul 12 15 29 07 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips check for virtualenv True tensorflow import Traceback most recent call last File string line 1 in module ImportError No module named 'tensorflow' env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem When i try to install tensorflow on Ubunutu 14 04 python 3 3 6 pip 9 0 1 it fails because of numpy version 1 11 0 which requires Python version 2 7 or 3 4 I followed the installations steps mentioned in Installation works fine on python 3 4 3 6 I think it would be good to specify if 3 3 is not supported here make Python 3 4 prerequisite python and pip Source code logs env33 root 11bb6e68305e home python version Python 3 3 6 env33 root 11bb6e68305e home pip3 install upgrade You must give at least one requirement to install see pip help install env33 root 11bb6e68305e home pip3 install upgrade pip Downloading unpacking pip from md5 297dbd16ef53bcef0447d245815f5144 Downloading pip 9 0 1 py2 py3 none any whl 1 3MB 1 3MB downloaded Installing collected packages pip Found existing installation pip 1 5 4 Uninstalling pip Successfully uninstalled pip Successfully installed pip Cleaning up env33 root 11bb6e68305e home pip3 install upgrade tensorflow Collecting tensorflow Downloading tensorflow 1 2 1 cp33 cp33m manylinux1 x86 64 whl 35 0MB 100 35 0MB 58kB s Collecting numpy 1 11 0 from tensorflow Downloading numpy 1 12 1 zip 4 8MB 100 4 8MB 429kB s Complete output from command python setup py egg info Traceback most recent call last File string line 1 in module File tmp pip build bbyh55 numpy setup py line 34 in module raise RuntimeError Python version 2 7 or 3 4 required RuntimeError Python version 2 7 or 3 4 required Command python setup py egg info failed with error code 1 in tmp pip build bbyh55 numpy env33 root 11bb6e68305e home pip version pip 9 0 1 from home env33 lib python3 3 site packages python 3 3,,carlthome,2017-08-16 00:08:03,2017-08-16 17:51:40
PR,something wrong with the path,,,"gunan,gunan",2017-08-16 13:41:24,2017-08-16 17:59:30
IS,Indexing problem in tensorflow with tf where,I want to clip the variable 'a' values which are less than or equal to max val ValueError Shape must be rank 1 but is rank 3 for istrided slice 1' op 'StridedSlice' with input shapes 13 20 1 2 1 2 1 tf clip by value a tf where tf less equal a max val 0 0,,reedwm,2017-08-16 08:59:29,2017-08-16 18:01:17
PR,Updating the Release notes with cudnn 7,,,av8ramit,2017-08-16 18:06:34,2017-08-16 18:22:49
IS,cannot bazel build freeze graph on windows,using bazel 0 53 python 3 6 2 on windows 10 64 with tf gpu 1 3 0rc2 bazel build tensorflow python tools freeze graph ERROR C users eyaler downloads tensorflow master tensorflow master tensorflow python tools BUILD 32 1 error loading package 'tensorflow core' Encountered error while reading extension file 'protobuf bzl' no such package ' protobuf archive ' Traceback most recent call last File C users eyaler downloads tensorflow master tensorflow master tensorflow workspace bzl line 119 apply patch repo ctx repo ctx attr patch file File C users eyaler downloads tensorflow master tensorflow master tensorflow workspace bzl line 110 in apply patch execute and check ret code repo ctx cmd File C users eyaler downloads tensorflow master tensorflow master tensorflow workspace bzl line 94 in execute and check ret code fail Non zero return code 1 when Non zero return code 127 when executing 'c tools msys64 usr bin bash exe c patch p1 d C users eyaler appdata local temp bazel eyaler trcps2te external protobuf archive i C users eyaler downloads tensorflow master tensorflow master third party protobuf add noinlines patch' Stdout Stderr 1 main patch 14524 C Program Files Git usr bin patch exe fatal error cygheap base mismatch detected 0x1802F3408 0x1802FD408 This problem is probably due to using incompatible versions of the cygwin DLL Search for cygwin1 dll using the Windows Start Find Search facility and delete all but the most recent version The most recent version should reside in x cygwin bin where 'x' is the drive on which you have installed the cygwin distribution Rebooting is also suggested if you are unable to find another cygwin DLL and referenced by ' tensorflow python tools freeze graph' ERROR Analysis of target ' tensorflow python tools freeze graph' failed build aborted INFO Elapsed time 85 042s,,reedwm,2017-08-16 10:25:34,2017-08-16 18:41:50
PR,Add SquaredDifference gradient,I added gradient function for the SquaredDifference and test case,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,frankchn,drpngx,vrv,rmlarsen,rmlarsen,vrv,rmlarsen,rmlarsen,rmlarsen,skye,suharshs",2017-07-16 07:18:55,2017-08-16 19:30:30
IS,TensorFlow Serving error in documentation,It seems that TensorFlow serving installation guide has incorrect python package name for API So tensorflow serving api should be changed to tensorflow serving client,,kirilg,2017-08-09 22:06:41,2017-08-16 20:43:10
IS,No builds for Linux Py3 6 gpu TF1 3 RC2,Using Python 3 6 in Anaconda on Ubuntu 16 04 I checked the build stream and do not see a Linux PY3 6 GPU being built Seems to me that since I have TF 1 2 installed it had the PY3 6GPU support that new RC is should also include builds for Py3 6 GPU or a lot of people just wo not build a separt downgraded test environment for the RC Or is the intention to drop support I hope not,,"ppwwyyxx,skye",2017-08-10 18:50:49,2017-08-16 20:43:23
PR,Padding queue support for tf estimator generator input pipeline,So as I desrcibe here there is no padding possibilities in current estimator is input pipelines For now I added simple possibility to you data have dynamic shape over last axis If such solution looks good then I am looking forward for next contributing steps,,"martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,drpngx,drpngx,vrv,rmlarsen,rmlarsen,rmlarsen,rmlarsen,martinwicke,martinwicke,martinwicke,rmlarsen",2017-06-15 12:47:49,2017-08-16 21:22:55
PR,Add noclang tag to platform setround test,,,yifeif,2017-08-16 18:20:24,2017-08-16 22:07:16
PR,read up for slim parallel reader 11164,,,"vrv,rmlarsen,rmlarsen",2017-07-18 19:49:21,2017-08-16 22:25:19
PR,Merge pull request 1 from tensorflow master,pull all without selection,,,2017-08-15 00:03:17,2017-08-16 22:37:19
IS,Tensorflow crashes when i try to quantize my output,BUG Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory,,"reedwm,reedwm",2017-08-16 21:04:52,2017-08-16 22:45:05
PR,Add TensorBoard to 1 3 release notes,,,jart,2017-08-17 01:19:52,2017-08-17 01:20:32
IS,Feature suggestion Keep dim for slicing and list based slicing with getitem in Tensors and Variables,Sometimes it would be helpful to maintain the dimension when accessing a particular slice of a tensor or a variable In NumPy this is possible by slicing with a list index like so ndarr np ones 5 4 3 ndarr 1 Shape 5 3 ndarr 1 Shape 5 1 3 It would be great to have similar list based indexing which is essentially similar to what tf gather nd,,,2017-08-16 21:41:48,2017-08-17 01:29:31
IS,Cuda build fail with 1 3 0,Please go to Stack Overflow for help and support issue with the same outcomes is here System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 8 4 TensorFlow installed from source or binary Trying to compile it from source TensorFlow version use command below latest git head Python version 2 7 10 Bazel version if compiling from source 5 2 CUDA cuDNN version various tried CUDA 8 0 7 5 7 0 and cuDNN 4 0 5 0 5 1 Exact command to reproduce git clone tensorflow 1 3 0 configure WARNING Running Bazel server needs to be killed because the startup options are different You have bazel 0 5 2 non git installed Please specify the location of python Default is software python 2 7 10 intel bin python Found possible Python library paths software python 2 7 10 intel lib python2 7 site packages software python27 modules software python 2 7 10 intel lib python2 7 site packages Please input the desired Python library path to use Default is software python 2 7 10 intel lib python2 7 site packages software python27 modules software python 2 7 10 intel lib python2 7 site packages Do you wish to build TensorFlow with jemalloc as malloc support Y n jemalloc as malloc support will be enabled for TensorFlow Do you wish to build TensorFlow with Google Cloud Platform support y N No Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support y N No Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with XLA JIT support y N No XLA JIT support will be enabled for TensorFlow Do you wish to build TensorFlow with GDR support y N No GDR support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N No VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL support y N No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N y CUDA support will be enabled for TensorFlow Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 8 0 Please specify the location where CUDA 8 0 toolkit is installed Refer to README md for more details Default is usr local cuda software cuda 8 0 Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 5 Please specify the location where cuDNN 5 library is installed Refer to README md for more details Default is software cuda 8 0 software cudnn 5 1 Please specify a list of comma separated Cuda compute capabilities you want to build with You can find the compute capability of your device at Please note that each additional compute capability significantly increases your build time and binary size Default is 3 5 5 2 2 0 3 5 Do you want to use clang as CUDA compiler y N nvcc will be used as CUDA compiler Please specify which gcc should be used by nvcc as the host compiler Default is usr bin gcc Do you wish to build TensorFlow with MPI support y N No MPI support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Add config mkl to your bazel command to build with MKL support Please note that MKL on MacOS or windows is still not supported If you would like to use a local MKL instead of downloading please set the environment variable TF MKL ROOT every time before build Configuration finished bazel build config cuda tensorflow tools pip package build pip package Describe the problem After some time of compiling this error is raised tensorflow core util cuda kernel helper h 620 error identifier shfl is undefined tensorflow core util cuda kernel helper h 640 error identifier shfl up is undefined tensorflow core util cuda kernel helper h 660 error identifier shfl down is undefined tensorflow core util cuda kernel helper h 680 error identifier shfl xor is undefined 4 errors detected in the compilation of tmp tmpxft 000042b4 00000000 10 resampler ops gpu cu compute 20 cpp1 ii ERROR scratch hanousek tensorflow 1 3 0 rc2 tensorflow contrib resampler BUILD 45 1 output 'tensorflow contrib resampler objs python ops resampler ops gpu tensorflow contrib resampler kernels resampler ops gpu cu pic o' was not created ERROR scratch hanousek tensorflow 1 3 0 rc2 tensorflow contrib resampler BUILD 45 1 not all outputs were created or valid More detailed error message is here url expire after a month,,"gunan,gunan,yifeif",2017-08-10 14:29:08,2017-08-17 02:38:12
IS,C lib for windows with GPU support,I know that there is a windows c library built for cpu However I could not find one with gpu support I have tried but obvious it does not exist Is it possible to have one Thank you,,snnn,2017-06-26 09:40:03,2017-08-17 07:34:02
IS,Most of embedding lookup embedding lookup sparse computations are on CPU Most of the GPU time is transferring data,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Centos 7 TenorFlow installed from source or binary source TensorFlow version use command below r 12 Python version 2 7 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 GPU model and memory P40 Describe the problem I have done some profiling about embedding lookup sparse i have use tf device ' gpu 0' to specify where the ops run But the results show Most of the operations are performed on the CPU GPU was transferring data at most of time After I looked into the codes there are some Ops without GPU version including dynamic partition segment sum strided slice So I'm a little confused Is this intended behavior Or are these Ops not implemented yet Thanks for the explanations Here is some profiling result tfprof,,"nolanliou,reedwm,nolanliou,reedwm,nolanliou,alextp,nolanliou,nolanliou,alextp,nolanliou",2017-07-24 08:19:52,2017-08-17 10:44:13
IS,Default Python lib paths are not matched with the Python exe user inputted when 'configure',Here is the output of 'configure' In above user typed Python3 for the location but the library paths found are with Python2 1 Env 1 1 OS Ubuntu 16 04 LTS 64 bit with CUDA 8 1 2 Bazel Build label 0 5 3 1 3 Python Python 2 7 and Python 3 5 are installed Default python cmd in this OS is python2 7 1 4 Tensorflow git rev parse HEAD 863d7e7f0202cf5b513f2e3e691e7686562c8d74 2 Desc Using python3 configure py to start configuration instead of configure would save the trouble directly but may not preferable to others,,yongtang,2017-08-12 06:09:05,2017-08-17 16:51:42
PR,Use python bin path to check for site packages,This fix tries to fix the issue raised in 12232 where the python invoked the configure py was used to check the site packages However the site packages should be checked by the provided python bin path This fix fixes the issue Below is the output after fix This fix fixes 12232 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yifeif,yifeif,yifeif,yongtang,yongtang,gunan,yongtang,gunan,yifeif,yifeif,yifeif",2017-08-12 15:44:24,2017-08-17 16:51:42
IS,string input producer num epochs not working as expected,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Reading a csv file with string input producer start queue runners works up to a certain limit Using tf train shuffle batch only the first N lines of the file are read Also num epochs seems limited to a certain number 30 without batching lower with batch Source code logs Simple script for reading a csv file training a linear model The code WORKS But it does NOT respond to changes in num epochs the number of steps printed at the end is not what we expect to see csv file model W 1 b 1 y Wx b 2 1 3 0 4 1 5 2 repeated import tensorflow as tf W tf Variable 3 dtype tf float32 b tf Variable 3 dtype tf float32 x tf placeholder tf float32 name x y tf placeholder tf float32 linear model tf add W x b name model squared deltas tf square linear model y loss tf reduce sum squared deltas train tf train AdamOptimizer 1e 3 minimize loss reading input filename queue tf train string input producer tmp input csv num epochs 100 reader tf TextLineReader skip header lines 0 csv row reader read filename queue record defaults 0 0 col x col label tf decode csv csv row record defaults record defaults features tf stack col x with tf Session as sess sess run tf local variables initializer sess run tf global variables initializer coord tf train Coordinator threads tf train start queue runners coord coord n 0 while True try n 1 inp lab sess run features col label sess run train feed dict x inp y lab except tf errors OutOfRangeError break finally coord request stop coord join threads print n with batch adding those lines in reading input batch size 20 min after dequeue 10000 col x col label tf decode csv csv row record defaults record defaults capacity 3 min after dequeue batch size x batch label batch tf train shuffle batch col x col label batch size batch size capacity capacity min after dequeue min after dequeue,,,2017-08-17 04:27:53,2017-08-17 16:58:55
IS,Feature Request Seq2Seq Inference Helper w o Embeddings,tf contrib seq2seq has two Helper classes to use during inference SampleEmbeddingHelper and GreedyEmbeddingHelper However both make use of embeddings which is unhelpful when building sequence to sequence models that operate on non embedded target sequences my target sequence already consists of meaningful vectors I would like a new Helper class that pipes the output of the decoder RNN at one time step into the decoder RNN at the following time step It should permit the start tokens to be vectors tensors and the end token to be a vector tensor as well Right now I'm attempting to use ScheduledOutputTrainingHelper with sampling probability set equal to 1 0 but I'm struggling to get it to work Something like a simple OutputInferenceHelper would be very nice If there already exists an easy way to do what I'm suggesting please let me know,,"tatatodd,lukaszkaiser,ebrevdo,adarob,adarob,adarob,adarob,ebrevdo,adarob,adarob,ebrevdo",2017-08-06 22:18:57,2017-08-17 17:05:59
PR,Fixed channel mismatch if num outputs None,Addresses feature request from issue 10432 Continuation of feature implementation initial changes did not address the case where num outputs None in which case strides and the input channels must be reformulated according to data format The previous commit is b7e2f03008e2eec28c26d3abf881ddc91b07fcda,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,vrv,rmlarsen",2017-08-08 21:52:21,2017-08-17 17:35:06
IS,Tensorflow android can not check results for optimized model,I used this tutorial to run model on android 4 But after pruning DecodeJpeg by command python m tensorflow python tools optimize for inference input tf files retrained graph pb output tf files optimized graph pb input names Cast output names final result I can not check the result with this command python m scripts label image tf files flower photos daisy 21652746 cc379e0eea m jpg tf files optimized graph pb it shows error TypeError Cannot interpret feed dict key as Tensor The name 'DecodeJpeg contents 0' refers to a Tensor which does not exist The operation 'DecodeJpeg contents' does not exist in the graph So how can i check result for optimized android model on computer,,skye,2017-08-17 08:25:36,2017-08-17 19:07:33
IS,how to do 3 D image classification with timedistributed conv2d,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,skye,2017-08-17 10:13:51,2017-08-17 19:07:49
IS,Windows 7 python mnist with summaries py having the error,When running python tensorflow tensorflow examples tutorials mnist mnist with summaries py it has occurred the following error image Why Any idea on how to resolve this problem Thank you,,reedwm,2017-08-17 07:41:10,2017-08-17 19:07:50
IS,convert ckpt to pb,I trained my own model using ssd mobilenets in object detection and it works well on my computer I see the update of android demo I want to use the ssd mobilenets model on my android phone But I only have ckpt files and do not know how to trans ckpt to pb because the graph is too comlex to see which is the final tensor name Does only one know how to genetate pb of ssd mobilenets,,reedwm,2017-08-17 06:00:02,2017-08-17 19:08:17
IS,error,bazel build tensorflow libtensorflow so ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen spec json' target 'gen spec json' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen head' target 'gen head' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow libtensorflow so' failed build aborted,,skye,2017-08-17 12:04:38,2017-08-17 19:11:19
IS,Freeze tensor forest graph for Android problem,Hi I built a aimple Random Forest model in tensorflow and want to freeze optimize it for android I used the following function for building the tesnor forest estimator def build estimator model dir num classes num features num trees max nodes params tensor forest ForestHParams num classes num classes num features num features num trees num trees max nodes max nodes min split samples 3 graph builder class tensor forest RandomForestGraphs return random forest TensorForestEstimator params graph builder class graph builder class model dir model dir This function stores the textual model to graph pbtxt file in the specified model directory Then I train it using est build estimator output model dir 3 np size features eval 1 5 6 train X features eval astype dtype np float32 train Y labels y astype dtype np float32 est fit x train X y train Y batch size np size features eval 0 in this simple example number of trees 5 max nodes 6 Now I want to freeze the model so I call this function def save model android model path checkpoint state name model ckpt 1 input graph name graph pbtxt output graph name freezed model pb checkpoint path os path join model path checkpoint state name input graph path os path join model path input graph name input saver def path None input binary False output node names output restore op name save restore all filename tensor name save Const 0 output graph path os path join model path output graph name clear devices True freeze graph input graph path input saver def path input binary checkpoint path output node names restore op name filename tensor name output graph path clear devices and in the freezed model pb file generated I get only 1 op which is the output node in the console I get the following message when the freeze graph function is called Converted 0 variables to const ops 1 ops in the final graph Does anyone knows why only one node get exported when calling to freeze graph I'm using Tensorflow version 1 2 1 with cuda support installed from sources on linux,,skye,2017-08-17 13:41:54,2017-08-17 19:14:52
IS,Including scatter nd in android ops crashes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes as described below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 64 bit TensorFlow installed from source or binary Source TensorFlow version 1 2 1 Perhaps using a newer version may fix the issue Bazel version if compiling from source Build label 0 5 3 Exact command to reproduce bazel build c opt tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a verbose failures I'm trying to port a encoder decoder net model to android and I was able to add all the required operations to the core ops extended ops and compile it The last method that needs to be included in the scatter nd Operation for unpooling I'm using a custom implementation which uses scatter nd from here I included the scatter nd op h in filegroup mobile srcs Do I need to add any more dependencies to the BUILD file Or are there any alternatives to scatter nd which can be used in Android Thanks,,skye,2017-08-11 11:16:48,2017-08-17 19:16:28
IS,Failed to load the native TensorFlow runtime error when installing tensorflow 10026 did not work 10794 was abandoned,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 2 1 Python version have tried on both 2 7 and 3 6 CUDA Version 8 0 61 Cudnn Verison 5 1 GeForce GTX 950M import tensorflow as tf Describe the problem I am trying to install GPU supported version of tensorflow Regardless of installation method or python version I use I always get the message down below Note that CPU version installs and runs without problem I have tried uninstalling packages anaconda pip and then installing them through ATP but nothing seems to help Thanks beforehand Source code logs import tensorflow as tf Traceback most recent call last File stdin line 1 in module File home kpk227133 tensorflow local lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home kpk227133 tensorflow local lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home kpk227133 tensorflow local lib python2 7 site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File home kpk227133 tensorflow local lib python2 7 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File home kpk227133 tensorflow local lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home kpk227133 tensorflow local lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError home kpk227133 tensorflow local lib python2 7 site packages tensorflow python pywrap tensorflow internal so undefined symbol cuDevicePrimaryCtxRetain Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"carlthome,skye",2017-08-15 20:10:53,2017-08-17 19:22:43
IS,Single Image Inference in Tensorflow Python,I have already converted a pre trained ckpt file to pb file freezing the model and saving the weighs as well What I am trying to do now is to make a simple inference using that pb file and extract and save output image The model is a Fully Convolutional Network for Semantic Segmentation downloaded from here So far I have managed to load the image set the default tf graph and import the graph defined by the model on that read the input and the output tensors and run the session error here Why inference of a single image in tensorflow is so complicated,,reedwm,2017-08-16 09:43:03,2017-08-17 19:39:42
PR,Merging 1 3 back into master,Accidentally made the branch on tf tf I will delete after,,"av8ramit,caisq",2017-08-17 18:26:25,2017-08-17 19:45:50
IS,fit instance method of skflow TensorFlowDNNClassifier raises unexpected error,System information Custom code no elementary example for classifying the Iris dataset Operating System MacOS 10 12 6 TensorFlow installed from source or binary binary using pip3 install tensorflow and later pip3 install skflow TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version Python 3 6 2 GPU model and memory Intel Iris integrated graphics Exact command to reproduce the fit instance method of skflow TensorFlowDNNClassifier Describe the problem Calling fit on instances of skflow TensorFlowDNNClassifier produces an AttributeError about tensorflow not having an attribute called histogram summary Source code logs,,"skye,terrytangyuan",2017-08-16 03:56:13,2017-08-17 19:48:54
PR,Check cuda compute capability 3 0 in configure,Fix 12181,,yifeif,2017-08-17 17:12:05,2017-08-17 19:51:03
IS,Resource Exhausted Error,This is my first experience with git hub so please mention if i did not provide the right details Here is the Screen shot of the error I am running my program on Tesla K20c GPU which has the following properties name Tesla K20c major 3 minor 5 memoryClockRate GHz 0 7055 pciBusID 0000 41 00 0 Total memory 4 63GiB Free memory 4 57GiB res System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 0 10 0 Python version 3 5 2 Describe the problem I am trying to train the model from scratch and have about 500 train and test images and i am using the batch size as 128 the size of the each image is 512 512 I tried changing batch size to even 1 but still it is not working Why is it showing that error Thanks,,"carlthome,reedwm",2017-08-17 09:59:44,2017-08-17 20:10:39
IS,Bug Session Hang during training with 'mnist replica py' and learning rate as a placeholder,System information OS Mac OS TF 1 2 0 pip install Python 2 7 9 also tested on RHEL with TF 1 1 and Python 2 7 13 the problem still exists I do not think it is system specific Describe the problem I am training the 'mnist replica py' provided on github link is here and set up two workers and one parameter server on my laptop I made only one modification to the code use learning rate as a placeholder rather than a fixed value and feed 0 01 to it each step When I train it asynchronously it is ok to go but the session hangs in run after one or two steps when I train it in synchronous Can anyone figure out the reason of this Source code logs the source code is here just provide it for ease It is almost the same as the original one,,,2017-08-02 01:32:13,2017-08-17 22:25:17
PR,Patching the missing nightly GPU build links,,,"av8ramit,gunan,av8ramit,av8ramit",2017-08-17 20:10:32,2017-08-17 23:17:12
IS,tf contrib data Dataset behaves strangely when re defined,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 on GCP TensorFlow installed from source or binary pip implies binary install I think TensorFlow version use command below GIT Version v1 2 0 5 g435cdfc Version 1 2 1 Python version 2 7 and 3 5 I checked with both Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Run the attached script tf repro txt Describe the problem It seems like once we start initializing and using datasets redefining them even in minor ways leads to errors I think This is rather unlike any other error in python Normally I would not expect redefinitions of python variables to cause problems I have noticed the following Using separate variables for the datasets does not help regardless of whether the old dataset is kept around or not Creating the datasets first and using them after does work again regardless of whether separate variables If this is intended behavior it might be worth documenting it It is easy enough to work around I suppose I do not know enough about TensorFlow internals to know what might be causing it Source code logs Here is the output I get when I run the attached script PG,,mrry,2017-08-17 22:02:22,2017-08-17 23:23:11
IS,tensorflow contrib session bundle example export half plus two py fails with ValueError invalid option,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version Python 2 7 9 Bazel version if compiling from source 0 4 5 CUDA cuDNN version Not used Exact command to reproduce python tensorflow contrib session bundle example export half plus two py Describe the problem The given script is used to generate testdata for savedmodel python tensorflow contrib session bundle example export half plus two py Fails with below error Source code logs tensorflow contrib session bundle example export half plus two py,,"Nayana-ibm,Nayana-ibm,reedwm,vrv,vrv,vrv",2017-08-11 10:13:17,2017-08-18 00:26:01
PR,Add missing 'type' keyword to ArgumentParser add argument,Fixes 12210,,vrv,2017-08-14 18:48:52,2017-08-18 00:26:01
IS,Cannot include ' pb h' files in tf tutorials cmake,System information Windows10 VisualStudio 2015 TensorFlow 1 3 0 Python 3 5 3 CMake 3 9 0 I am generating C tensorflow 'GPU' version of tf tutorials example trainer example as defined in using Cmake and MSbuild Describe the problem Build failing due to missing header files contrib boosted trees proto ph h The proto files are present and I can use protoc exe to manually generate the ph h files This removes the 'cannot include' errors BUT now there are linker errors when building the tf tutorials example trainer exe as it can not find the routines structures defined in the pb h files NOTE proto files in other directories are also not expanded to pb h equivalents Source code logs c Users Martin Rosevear tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj default target 1 C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj default target 104 ClCompile target C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib trees decision tree h 19 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner common partitioners example partitioner cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic handlers categorical feature column handler cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic handlers bias feature column handler cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic handlers dense quantized feature column handler cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib utils dropout utils h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib utils dropout utils cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib learner stochastic handlers sparse quantized feature column handler cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib trees decision tree h 19 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib trees decision tree cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib models multiple additive trees h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C Users Martin Rosevear tensorflow tensorflow contrib boosted trees lib models multiple additive trees cc C Users Martin Rosevear tensorflow tensorflow contrib cmake build tf core kernels vcxproj,,reedwm,2017-08-10 04:37:27,2017-08-18 00:41:54
IS,Hash mismatch for cub project while building tf label image example project in Release mode on Windows 64 bit build,Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 Bit TensorFlow installed from source or binary Source TensorFlow version use command below Output copied below Python version 3 5 3 Anaconda Bazel version if compiling from source CUDA cuDNN version 8 0 GPU model and memory Exact command to reproduce Building tf label image example project in Release mode cat etc issue MINGW64 NT 10 0 DESKTOP SL66NSK 2 8 0 0 309 5 3 2017 05 19 13 17 x86 64 Msys are we in docker No compiler bash c command not found uname a MINGW64 NT 10 0 DESKTOP SL66NSK 2 8 0 0 309 5 3 2017 05 19 13 17 x86 64 Msys check pips numpy 1 12 1 numpydoc 0 6 0 check for virtualenv False tensorflow import Traceback most recent call last File string line 1 in module ModuleNotFoundError No module named 'tensorflow' env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi bash nvidia smi command not found cuda libs Describe the problem I downloaded the latest source code from github and used the windows instructions I used Anaconda installation instructions and followed this with installation from source 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retry after 60 seconds attempt 5 8 Using src '' MSB6006 cmd exe exited with code 1 Source code logs 1 Build started Project zlib Configuration Release x64 2 Build started Project gif Configuration Release x64 3 Build started Project farmhash Configuration Release x64 4 Build started Project highwayhash Configuration Release x64 5 Build started Project jpeg Configuration Release x64 6 Build started Project lmdb Configuration Release x64 7 Build started Project fft2d Configuration Release x64 8 Build started Project cub Configuration Release x64 4 Performing update step for 'highwayhash' 8 Building Custom Rule C CPA Tensorflow tensorflow tensorflow contrib cmake CMakeLists txt 1 Performing update step for 'zlib' 9 Build started Project lmdb create destination dir Configuration Release x64 10 Build started Project farmhash create destination dir Configuration Release x64 11 Build started Project gif create destination dir Configuration Release x64 12 Build started Project jpeg create destination dir Configuration Release x64 13 Build started Project re2 Configuration Release x64 14 Build started Project highwayhash create destination dir Configuration Release x64 15 Build started Project png Configuration Release x64 8 CMake does not need to re run because C CPA Tensorflow tensorflow tensorflow contrib cmake build CMakeFiles generate stamp is up to date 8 Creating directories for 'cub' 8 Performing download step download verify and extract for 'cub' 8 Downloading 8 dst 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 timeout 'none' 8 Using src '' 16 Build started Project protobuf Configuration Release x64 17 Build started Project zlib create destination dir Configuration Release x64 13 Performing update step for are2' 18 Build started Project png create destination dir Configuration Release x64 19 Build started Project farmhash copy headers to destination Configuration Release x64 20 Build started Project highwayhash copy headers to destination Configuration Release x64 21 Build started Project gif copy headers to destination Configuration Release x64 22 Build started Project jpeg copy headers to destination Configuration Release x64 16 Performing update step for 'protobuf' 23 Build started Project zlib copy headers to destination Configuration Release x64 24 Build started Project grpc Configuration Release x64 25 Build started Project jsoncpp Configuration Release x64 8 download 0 complete 8 download 1 complete 26 Build started Project eigen Configuration Release x64 27 Build started Project gemmlowp Configuration Release x64 8 download 2 complete 28 Build started Project png copy headers to destination Configuration Release x64 29 Build started Project lmdb copy headers to destination Configuration Release x64 8 download 3 complete 24 Performing update step for 'grpc' 25 Performing update step for 'jsoncpp' 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 8 complete 8 download 9 complete 8 download 10 complete 8 download 12 complete 8 download 13 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 20 complete 8 download 21 complete 8 download 22 complete 8 download 23 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 28 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 30 Build started Project create cc ops header dir Configuration Release x64 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 48 complete 8 download 50 complete 8 download 51 complete 8 download 52 complete 8 download 54 complete 8 download 56 complete 8 download 57 complete 8 download 58 complete 8 download 59 complete 8 download 60 complete 8 download 61 complete 8 download 62 complete 8 download 63 complete 8 download 65 complete 8 download 66 complete 8 download 67 complete 8 download 68 complete 8 download 69 complete 8 download 70 complete 8 download 71 complete 8 download 72 complete 8 download 73 complete 8 download 75 complete 8 download 78 complete 8 download 80 complete 8 download 83 complete 8 download 86 complete 8 download 88 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retrying 8 Using src '' 8 download 0 complete 8 download 1 complete 8 download 2 complete 8 download 3 complete 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 8 complete 8 download 9 complete 8 download 10 complete 8 download 11 complete 8 download 12 complete 8 download 13 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 21 complete 8 download 23 complete 8 download 24 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 8 download 38 complete 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 49 complete 8 download 50 complete 8 download 51 complete 8 download 52 complete 8 download 53 complete 8 download 54 complete 8 download 55 complete 8 download 56 complete 8 download 57 complete 8 download 58 complete 8 download 59 complete 8 download 60 complete 8 download 61 complete 8 download 62 complete 8 download 64 complete 8 download 65 complete 8 download 66 complete 8 download 67 complete 8 download 68 complete 8 download 70 complete 8 download 71 complete 8 download 72 complete 8 download 73 complete 8 download 74 complete 8 download 75 complete 8 download 76 complete 8 download 79 complete 8 download 81 complete 8 download 84 complete 8 download 87 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retry after 5 seconds attempt 2 8 Using src '' 8 download 0 complete 8 download 1 complete 8 download 2 complete 8 download 3 complete 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 9 complete 8 download 10 complete 8 download 11 complete 8 download 12 complete 8 download 13 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 20 complete 8 download 21 complete 8 download 22 complete 8 download 23 complete 8 download 24 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 28 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 8 download 38 complete 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 48 complete 8 download 49 complete 8 download 50 complete 8 download 51 complete 8 download 52 complete 8 download 53 complete 8 download 54 complete 8 download 55 complete 8 download 56 complete 8 download 57 complete 8 download 58 complete 8 download 59 complete 8 download 60 complete 8 download 61 complete 8 download 62 complete 8 download 63 complete 8 download 64 complete 8 download 65 complete 8 download 66 complete 8 download 67 complete 8 download 69 complete 8 download 70 complete 8 download 71 complete 8 download 72 complete 8 download 74 complete 8 download 75 complete 8 download 77 complete 8 download 80 complete 8 download 83 complete 8 download 85 complete 8 download 88 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retry after 5 seconds attempt 3 8 Using src '' 8 download 0 complete 8 download 1 complete 8 download 2 complete 8 download 3 complete 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 8 complete 8 download 9 complete 8 download 10 complete 8 download 11 complete 8 download 12 complete 8 download 13 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 20 complete 8 download 21 complete 8 download 22 complete 8 download 23 complete 8 download 24 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 28 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 8 download 38 complete 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 48 complete 8 download 49 complete 8 download 50 complete 8 download 53 complete 8 download 55 complete 8 download 58 complete 8 download 60 complete 8 download 63 complete 8 download 66 complete 8 download 68 complete 8 download 71 complete 8 download 74 complete 8 download 75 complete 8 download 76 complete 8 download 77 complete 8 download 78 complete 8 download 79 complete 8 download 80 complete 8 download 81 complete 8 download 82 complete 8 download 83 complete 8 download 84 complete 8 download 85 complete 8 download 86 complete 8 download 87 complete 8 download 88 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retry after 15 seconds attempt 4 8 Using src '' 8 download 0 complete 8 download 1 complete 8 download 2 complete 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 8 complete 8 download 9 complete 8 download 10 complete 8 download 11 complete 8 download 12 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 21 complete 8 download 22 complete 8 download 23 complete 8 download 24 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 28 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 8 download 38 complete 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 48 complete 8 download 49 complete 8 download 50 complete 8 download 51 complete 8 download 52 complete 8 download 53 complete 8 download 54 complete 8 download 55 complete 8 download 56 complete 8 download 57 complete 8 download 58 complete 8 download 59 complete 8 download 60 complete 8 download 61 complete 8 download 63 complete 8 download 64 complete 8 download 65 complete 8 download 66 complete 8 download 67 complete 8 download 68 complete 8 download 69 complete 8 download 70 complete 8 download 71 complete 8 download 72 complete 8 download 73 complete 8 download 74 complete 8 download 75 complete 8 download 76 complete 8 download 77 complete 8 download 78 complete 8 download 79 complete 8 download 80 complete 8 download 81 complete 8 download 82 complete 8 download 83 complete 8 download 84 complete 8 download 85 complete 8 download 86 complete 8 download 87 complete 8 download 88 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 Retry after 60 seconds attempt 5 8 Using src '' 8 download 0 complete 8 download 1 complete 8 download 2 complete 8 download 3 complete 8 download 4 complete 8 download 5 complete 8 download 6 complete 8 download 7 complete 8 download 9 complete 8 download 10 complete 8 download 11 complete 8 download 12 complete 8 download 13 complete 8 download 14 complete 8 download 15 complete 8 download 16 complete 8 download 17 complete 8 download 18 complete 8 download 19 complete 8 download 20 complete 8 download 21 complete 8 download 22 complete 8 download 23 complete 8 download 24 complete 8 download 25 complete 8 download 26 complete 8 download 27 complete 8 download 28 complete 8 download 29 complete 8 download 30 complete 8 download 31 complete 8 download 32 complete 8 download 33 complete 8 download 34 complete 8 download 35 complete 8 download 36 complete 8 download 37 complete 8 download 38 complete 8 download 39 complete 8 download 40 complete 8 download 41 complete 8 download 42 complete 8 download 43 complete 8 download 44 complete 8 download 45 complete 8 download 46 complete 8 download 47 complete 8 download 48 complete 8 download 49 complete 8 download 50 complete 8 download 51 complete 8 download 52 complete 8 download 53 complete 8 download 55 complete 8 download 56 complete 8 download 57 complete 8 download 59 complete 8 download 60 complete 8 download 63 complete 8 download 66 complete 8 download 68 complete 8 download 71 complete 8 download 74 complete 8 download 75 complete 8 download 76 complete 8 download 77 complete 8 download 78 complete 8 download 79 complete 8 download 80 complete 8 download 81 complete 8 download 82 complete 8 download 83 complete 8 download 84 complete 8 download 85 complete 8 download 86 complete 8 download 87 complete 8 download 88 complete 8 download 89 complete 8 download 90 complete 8 download 91 complete 8 download 92 complete 8 download 93 complete 8 download 94 complete 8 download 95 complete 8 download 96 complete 8 download 97 complete 8 download 98 complete 8 download 99 complete 8 download 100 complete 8 verifying file 8 file 'C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip' 8 SHA256 hash of 8 C CPA Tensorflow tensorflow tensorflow contrib cmake build downloads 1 6 4 zip 8 does not match expected value 8 expected '966d0c4f41e2bdc81aebf9ccfbf0baffaac5a74f00b826b06f4dee79b2bb8cee' 8 actual '4198e9c447a1e2a963b9e0e4d861df48baa47fb02e5e4fc507d1834afc99185a' 8 Hash mismatch removing 8 CMake Error at cub stamp download cub cmake 157 message 8 Each download failed 8 8 8 8 8 8 C Program Files x86 MSBuild Microsoft Cpp v4 0 V140 Microsoft CppCommon targets 171 5 error MSB6006 cmd exe exited with code 1,,"mrry,mrry",2017-08-14 19:37:56,2017-08-18 00:41:54
IS,Missing tf python protos cc library dependency in tf tutorials cmake,System information Windows10 VisualStudio 2017 TensorFlow 1 3 0 Python 3 5 3 CMake 3 8 1 Describe the problem I can not build tf tutorials example trainer due missing library dependency to tf python protos cc lib A lot of linking errors occurred If the bold line is added into tf tutorials cmake then the compilation works target link libraries tf tutorials example trainer PUBLIC tf protos cc tf python protos cc tf core gpu kernels lib tensorflow EXTERNAL LIBRARIES CMake is used build the project files for VisualStudio image Source code logs 1 Build started Project tf tutorials example trainer Configuration Release x64 1 Creating library C Development dev test projects deeplearning tensorflow build64 Release tf tutorials example trainer lib and object C Development dev test projects deeplearning tensorflow build64 Release tf tutorials example trainer exp 1 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow QEAA XZ referenced in function public static class tensorflow boosted trees trees DecisionTreeConfig cdecl google protobuf Arena CreateMessage class tensorflow boosted trees trees DecisionTreeConfig class google protobuf Arena CreateMessage VDecisionTreeConfig trees boosted trees tensorflow Arena protobuf google SAPEAVDecisionTreeConfig trees boosted trees tensorflow PEAV012 Z 1 prediction ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow QEAA XZ 1 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig void 0DecisionTreeConfig trees boosted trees tensorflow QEAA XZ 1 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public void cdecl tensorflow boosted trees trees DecisionTreeConfig Swap class tensorflow boosted trees trees DecisionTreeConfig Swap DecisionTreeConfig trees boosted trees tensorflow QEAAXPEAV1234 Z referenced in function public virtual void cdecl tensorflow AddTreesToEnsembleOp Compute class tensorflow OpKernelContext const Compute AddTreesToEnsembleOp tensorflow UEAAXQEAVOpKernelContext 2 Z 1 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig class google protobuf Arena 0DecisionTreeConfig trees boosted trees tensorflow IEAA PEAVArena protobuf google Z referenced in function public static class tensorflow boosted trees trees DecisionTreeConfig cdecl google protobuf Arena CreateMessage class tensorflow boosted trees trees DecisionTreeConfig class google protobuf Arena CreateMessage VDecisionTreeConfig trees boosted trees tensorflow Arena protobuf google SAPEAVDecisionTreeConfig trees boosted trees tensorflow PEAV012 Z 1 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeConfig DecisionTreeConfig class google protobuf Arena 0DecisionTreeConfig trees boosted trees tensorflow IEAA PEAVArena protobuf google Z 1 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata void 0DecisionTreeMetadata trees boosted trees tensorflow QEAA XZ referenced in function public static class tensorflow boosted trees trees DecisionTreeMetadata cdecl google protobuf Arena CreateMessage class tensorflow boosted trees trees DecisionTreeMetadata class google protobuf Arena CreateMessage VDecisionTreeMetadata trees boosted trees tensorflow Arena protobuf google SAPEAVDecisionTreeMetadata trees boosted trees tensorflow PEAV012 Z 1 training ops cc obj error LNK2001 unresolved external symbol public cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata void 0DecisionTreeMetadata trees boosted trees tensorflow QEAA XZ 1 ensemble optimizer ops cc obj error LNK2019 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata class google protobuf Arena 0DecisionTreeMetadata trees boosted trees tensorflow IEAA PEAVArena protobuf google Z referenced in function public static class tensorflow boosted trees trees DecisionTreeMetadata cdecl google protobuf Arena CreateMessage class tensorflow boosted trees trees DecisionTreeMetadata class google protobuf Arena CreateMessage VDecisionTreeMetadata trees boosted trees tensorflow Arena protobuf google SAPEAVDecisionTreeMetadata trees boosted trees tensorflow PEAV012 Z 1 training ops cc obj error LNK2001 unresolved external symbol protected cdecl tensorflow boosted trees trees DecisionTreeMetadata DecisionTreeMetadata class google protobuf Arena 0DecisionTreeMetadata trees boosted trees tensorflow IEAA PEAVArena protobuf google Z 1 C Development dev test projects deeplearning tensorflow build64 Release tf tutorials example trainer exe fatal error LNK1120 85 unresolved externals 1 Done building project tf tutorials example trainer vcxproj FAILED Build 0 succeeded 1 failed 0 up to date 0 skipped,,"mrry,mrry",2017-08-04 13:35:03,2017-08-18 00:41:54
IS,Build error for finding some generated header files,I just build the master branch on windows based on the CMake method as shown in link I first build the PIP package as described in the above link But there is build error says that C v clhian tensorflow tensorflow contrib boosted trees lib utils dropout utils h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib utils dropout utils cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj sparse column iterable cc tensor utils cc example partitioner cc C v clhian tensorflow tensorflow contrib boosted trees lib trees decision tree h 19 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib learner common partitioners example partitioner cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj bias feature column handler cc categorical feature column handler cc dense quantized feature column handler cc sparse quantized feature column handler cc multiple additive trees cc decision tree cc masked matmul ops cc wals solver ops cc C v clhian tensorflow tensorflow contrib boosted trees lib trees decision tree h 19 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib trees decision tree cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic handlers sparse quantized feature column handler cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj factorization ops cc C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic handlers categorical feature column handler cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj generate vocab remapping op cc load and remap matrix op cc zero initializer op cc C v clhian tensorflow tensorflow contrib boosted trees lib models multiple additive trees h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto tree config pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib models multiple additive trees cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic handlers bias feature column handler cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic stats node stats h 21 fatal error C1083 Cannot open include file 'tensorflow contrib boosted trees proto learner pb h' No such file or directory compiling source file C v clhian tensorflow tensorflow contrib boosted trees lib learner stochastic handlers dense quantized feature column handler cc C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj checkpoint ops cc sparse feature cross kernel cc sparse feature cross op cc resampler ops cc tensor forest ops cc reinterpret string to float op cc scatter add ndim op cc tree utils cc hard routing function op cc k feature gradient op cc k feature routing function op cc routing function op cc routing gradient op cc stochastic hard routing function op cc stochastic hard routing gradient op cc unpack path op cc utils cc skip gram kernels cc skip gram ops cc cross replica ops cc infeed ops cc outfeed ops cc replication ops cc tpu configuration ops cc Done Building Project C v clhian tensorflow tensorflow contrib cmake build tf core kernels vcxproj default targets FAILED It cannot find the generated header files learner pb h and tree config pb h But I find them on my disk under folder C xxx tensorflow tensorflow contrib cmake build tensorflow contrib boosted trees proto illustrating that it already generate the files So is there any configuration for this,,"reedwm,guschmue,mrry,guschmue,mrry",2017-08-15 08:16:58,2017-08-18 00:41:55
IS,Building Error on Windows of master branch,After fixing the error mention in 12288 there are new error as shown below May be some other Cmakelist error could you help fix this,,mrry,2017-08-16 17:12:34,2017-08-18 00:41:55
PR,CMake Add missing dependencies on boosted trees protos and other fixes,This PR fixes some of the CMake targets that are not built as part of CI 1 It adds the contrib boosted trees protos to the tf protos cc srcs variable which ensures that they are built before the corresponding kernels This enables non Python targets such as tf label image example to be built again 2 It excludes the core kernels fuzzing code from being built which enables the CMake build to work on non Windows platforms An ifndef PLATFORM WINDOWS was in place to preserve the functioning Windows builds 3 It includes the missing CUDA code for the ZeroInitializerOp when building for GPU Fixes 12037 Fixes 12164 Fixes 12277 Fixes 12288 Fixes 12332,,"mrry,mrry,mrry,mrry,gunan,mrry",2017-08-16 06:15:44,2017-08-18 00:41:55
IS,404 for linux GPU python2 download,HTTP ERROR 404 Click the url in readme following occurs Problem accessing view Nightly job nightly matrix linux gpu TF BUILD IS OPT OPT TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label gpu linux lastSuccessfulBuild artifact pip test whl tensorflow gpu 1 3 0rc2 cp27 none linux x86 64 whl Reason Not Found,,"skye,gunan,av8ramit,av8ramit,av8ramit",2017-08-17 10:39:31,2017-08-18 01:52:23
IS,using two different models for prediction,Im using the following code to import graph def since i want to use two model files individually but how do I use them after importing individually I tried adding name 'age' and name 'gender' to differentiate but it is not working out as well,,reedwm,2017-08-18 03:04:17,2017-08-18 03:14:46
IS,Who can explain the usage of this c api,Who can explain the usage of this api Status Run const FeedType inputs const std vector Output fetch outputs const std vector Operation run outputs std vector Tensor outputs const I read the doc but i still can not understand it I don t know the role of each parameter,,reedwm,2017-08-18 02:10:58,2017-08-18 03:17:44
IS,ssd mobilenets model faild using in android demo,I am glad to see android demo is updated to be available for ssd mobilenets models I tried the demo on my phone and it works well But when I tried my own model the app can not work normally 1 I used export inference graph py in object detection to convert ckpt to pb files 2 I replaced the original model by my pb file 3 Also I changed the label list txt After doing this I generate the app but the app crushed Is there anything wrong with my handle,,reedwm,2017-08-18 01:43:19,2017-08-18 03:23:52
IS,Issues related to integrating syntaxnet parsey mcparseface in Java tf reduce sum,Summary tldr It would be nice with more String support in the Java API and a tf reduce sum which supports string concatenation Body I have successfully hacked in the custom ops of syntaxnet into the Tensorflow master as I wish to run syntaxnet from my Java NLP pipeline I do this by saving a SavedModelBundle and load it again from Java My project is based on a saved model of parsey mcparseface from this branch By user And a tensorflow build based on the custom ops from Hacked into master of tensorflow Hacking in the ops as build in ops was necessary as the Java api through the JNI does not support user loaded ops yet AFAIK The code with the syntaxnet ops hacked in can be found here I have everything running except that the strings in the output tensor from my saved model includes junk non printable chars which I think is due to the offset table described in tensor jni cc file I can run the same model from Python without any issues The Java API does currently not seem to support anything but scalar string tensors It looks like using a scalar string tensor will solve my problem as that part of the codes seems to handle the offset table I would therefore like to reduce the string tensor produced by my parsey mcparseface model I then found that the tf reduce sum does not yet support string concatenation There should already be an op for it User commented that he was looking for a use case for this here,,mrry,2017-08-16 13:39:05,2017-08-18 12:33:38
IS,Limit GPU memory usage not working in distributed training of inception,I'm using the example provided for distributed trainig of inception I have three hosts with one for parameter server and two for workers All hosts have TensorFlow 1 2 installed with CUDA 8 0 cuDNN 5 1 and Titan X Pascal GPU running Ubuntu 14 04 I followed the instruction for distributed training as provided in the readme and it runs successfully But when I try to limit the GPU usage by making the following changes Change sess config tf ConfigProto allow soft placement True log device placement FLAGS log device placement to sess config tf ConfigProto allow soft placement True log device placement FLAGS log device placement gpu options tf GPUOptions per process gpu memory fraction 0 6 in inception distributed train py L255 I recompiled the example using 'bazel build inception imagenet distributed train' and run the example But the process still occupies all GPU memory available observed using nvidia smi,,"mrry,mrry",2017-08-18 03:01:00,2017-08-18 15:03:23
PR,Remove tensorboard if we are building tf nightly,Once there are consistent nightly tensorboard builds I will have the update version script just update the tensorboard dependency tag,,"av8ramit,av8ramit",2017-08-17 23:53:58,2017-08-18 16:04:58
IS,Does StreamExecutor support OpenCL,I only see TENSORFLOW STREAM EXECUTOR MACHINE MANAGER PREFER OPENCL option in machine manager cc However I do not see where SE links to OpenCL headers and libs So I wonder of SE supports OpenCL Thanks RLE,,reedwm,2017-08-18 15:21:13,2017-08-18 16:55:45
IS,Running ops with restored model gives FailedPreconditionError,I'm trying running some ops with a pre trained model and the model was restored successfully When running some ops that depend on one node in the graph TF returns me It was the line print tf argmax GoogleNet test image 1 eval feed dict keep prob 1 0 that messed this up A side question here the model was trained well but it gives me a poor test accuracy of 0 0004 which basically shows that the predictions with the test samples are all wrong Is this a bug,,reedwm,2017-08-18 11:24:25,2017-08-18 17:06:27
PR,Update install windows md to mention cuDNN 6,This PR updates the r1 3 docs which are currently the default on the website Fixes 12366,,"mrry,mrry,av8ramit",2017-08-18 03:05:39,2017-08-18 18:48:14
PR,Branch 165646100,Pushing internal commits,,"andrewharp,andrewharp",2017-08-18 00:06:15,2017-08-18 19:13:40
IS,CrashLoopBackOff,I am trying to follow the tensorflow deployment on kubernetes following the tutorial here part 2 deploy in kubernetes Instead of running on gclound I am trying to run on local machine But I ran into the following problem pangolins serving kubectl get pods NAME READY STATUS RESTARTS AGE inception deployment 2217120516 jmkbm 0 1 CrashLoopBackOff 9 31m inception deployment 2217120516 rr04x 0 1 CrashLoopBackOff 9 31m inception deployment 2217120516 xvc58 0 1 CrashLoopBackOff 9 31m monolith 1 1 Running 0 1d nginx 1803751077 5cst4 1 1 Running 0 2d pangolins serving bazel bin tensorflow serving example inception client server 10 0 0 45 32683 image tensorflow tensorflow contrib pi examples label image data grace hopper jpg Traceback most recent call last File home pangolins software serving bazel bin tensorflow serving example inception client runfiles tf serving tensorflow serving example inception client py line 56 in module tf app run File home pangolins software serving bazel bin tensorflow serving example inception client runfiles org tensorflow tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File home pangolins software serving bazel bin tensorflow serving example inception client runfiles tf serving tensorflow serving example inception client py line 51 in main result stub Predict request 10 0 10 secs timeout File home pangolins anaconda2 lib python2 7 site packages grpc beta client adaptations py line 324 in call self request serializer self response deserializer File home pangolins anaconda2 lib python2 7 site packages grpc beta client adaptations py line 210 in blocking unary unary raise abortion error rpc error call grpc framework interfaces face face AbortionError AbortionError code StatusCode UNAVAILABLE details Connect Failed,,reedwm,2017-08-17 19:23:35,2017-08-18 21:07:15
IS,compilation error,On Ubuntu 16 04 with gcc5 configure You have bazel 0 5 3 installed Please specify the location of python Default is usr bin python Found possible Python library paths usr local lib python2 7 dist packages usr lib python2 7 dist packages Please input the desired Python library path to use Default is usr local lib python2 7 dist packages Using python library path usr local lib python2 7 dist packages Do you wish to build TensorFlow with MKL support y N No MKL support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Do you wish to use jemalloc as the malloc implementation Y n jemalloc enabled Do you wish to build TensorFlow with Google Cloud Platform support y N No Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support y N No Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with the XLA just in time compiler experimental y N No XLA support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N No VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL support y N No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N y CUDA support will be enabled for TensorFlow Do you want to use clang as CUDA compiler y N nvcc will be used as CUDA compiler Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 8 Please specify the location where CUDA 8 toolkit is installed Refer to README md for more details Default is usr local cuda Invalid path to CUDA 8 toolkit usr local cuda lib64 libcudart so 8 cannot be found Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 8 Please specify the location where CUDA 8 toolkit is installed Refer to README md for more details Default is usr local cuda Invalid path to CUDA 8 toolkit usr local cuda lib64 libcudart so 8 cannot be found Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 8 0 Please specify the location where CUDA 8 0 toolkit is installed Refer to README md for more details Default is usr local cuda Please specify which gcc should be used by nvcc as the host compiler Default is usr bin gcc Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 7 0 1 Please specify the location where cuDNN 7 0 1 library is installed Refer to README md for more details Default is usr local cuda usr lib x86 64 linux gnu Please specify a list of comma separated Cuda compute capabilities you want to build with You can find the compute capability of your device at Please note that each additional compute capability significantly increases your build time and binary size Default is 6 1 Do you wish to build TensorFlow with MPI support y N MPI support will not be enabled for TensorFlow Configuration finished BUILD 39 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 tensorflow stream executor cuda cuda dnn cc In instantiation of 'cudnnStatus t perftools gputools cuda wrap WrapperShim cudnnSetRNNDescriptor operator perftools gputools cuda CUDAExecutor Args with Args cudnnRNNStruct int int cudnnDropoutStruct cudnnRNNInputMode t cudnnDirectionMode t cudnnRNNMode t cudnnDataType t ' tensorflow stream executor cuda cuda dnn cc 1021 50 required from here tensorflow stream executor cuda cuda dnn cc 140 38 error cannot convert 'cudnnRNNStruct ' to 'cudnnHandle t aka cudnnContext ' for argument '1' to 'cudnnStatus t cudnnSetRNNDescriptor cudnnHandle t cudnnRNNDescriptor t int int cudnnDropoutDescriptor t cudnnRNNInputMode t cudnnDirectionMode t cudnnRNNMode t cudnnRNNAlgo t cudnnDataType t ' cudnnStatus t retval name args tensorflow stream executor cuda cuda dnn cc 234 3 note in expansion of macro 'PERFTOOLS GPUTOOLS CUDNN WRAP' macro cudnnSetRNNDescriptor,,"reedwm,tfboyd",2017-08-18 21:31:40,2017-08-18 22:01:32
IS,Error when retraining with retrain py,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow original one OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 10 TensorFlow installed from source or binary sudo pip3 install tensorflow TensorFlow version use command below latest sudo pip3 install tensorflow before retraining v1 0 0 65 g4763edf dirty 1 0 1 Python version Python 3 5 3 Anaconda custom 64 bit default Mar 6 2017 11 58 13 GCC 4 4 7 20120313 Red Hat 4 4 7 1 on linux Bazel version if compiling from source not used CUDA cuDNN version not used GPU model and memory not used Exact command to reproduce I know it is Ubuntu 16 10 but mb the problem in something different that you may already know Describe the problem Error when retraining mobilenet Source code logs,,,2017-08-20 10:44:14,2017-08-20 12:36:38
PR,ADB is the tool USB debugging is the connection,ADB is Android Debug Bridge and allows the USB debugging connection or over WiFi which is a more complex topic later on Basically you need a debugging connection to the phone either as USB or WiFi,,,2017-08-20 12:35:31,2017-08-20 12:36:58
PR,android demo Fix applicationId to 'org tensorflow demo',For nativeBuildSystem 'cmake' change applicationId 'com tensorflow demo' to applicationId 'org tensorflow demo' Otherwise Android system treat bult app com tensorflow demo as separate one and install it alonside to org tensorflow demo,,ArtsiomCh,2017-08-20 18:52:27,2017-08-20 19:38:28
IS,can i used it by C,can i used it by C What time can provide C version Why is not the official c demo thanks,,"asimshankar,asimshankar",2017-08-20 07:05:40,2017-08-21 05:37:32
IS,external eigen archive unsupported Eigen CXX11 Tensor 84 26 fatal error cuda runtime h No such file or directory,System information After run the tf env collect sh in my terminal i get this infomation cat etc issue Linux saners 4 10 0 32 generic 36 16 04 1 Ubuntu SMP Wed Aug 9 09 19 02 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux saners 4 10 0 32 generic 36 16 04 1 Ubuntu SMP Wed Aug 9 09 19 02 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 4 tensorflow import Traceback most recent call last File string line 1 in module File usr local lib python2 7 dist packages tensorflow init py line 24 in module from tensorflow python import File usr local lib python2 7 dist packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError libcusolver so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi Mon Aug 21 17 31 46 2017 NVIDIA SMI 375 82 Driver Version 375 82 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Quadro K620 Off 0000 01 00 0 On N A 34 41C P8 1W 30W 307MiB 1999MiB 1 Default Processes GPU Memory GPU PID Type Process name Usage 0 1014 G usr lib xorg Xorg 134MiB 0 1723 G compiz 82MiB 0 2368 G proc self exe 88MiB cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 Tensorflow version 'v1 3 0 rc1 1204 g084d29e' '1 3 0' Describe the problem 1 1 when i use sudo bazel build tensorflow examples android tensorflow demo to get apk I meet the error ERROR home saners tensorflow tensorflow core kernels BUILD 4581 1 C compilation of rule ' tensorflow core kernels android tensorflow kernels' failed arm linux androideabi gcc failed error executing command external androidndk ndk toolchains arm linux androideabi 4 9 prebuilt linux x86 64 bin arm linux androideabi gcc fstack protector strong fpic ffunction sections funwind tables remaining 77 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 In file included from third party eigen3 unsupported Eigen CXX11 Tensor 1 0 from tensorflow core kernels bias op gpu h 21 from tensorflow core kernels bias op cc 30 external eigen archive unsupported Eigen CXX11 Tensor 84 26 fatal error cuda runtime h No such file or directory include cuda runtime h compilation terminated Target tensorflow examples android tensorflow demo failed to build 1 2 when i use bazel build tensorflow examples android tensorflow demo in the terminal the error is changed tensorflow core kernels lrn op cc 34 31 fatal error cuda include cuda h No such file or directory 1 3 import tensorflow and import tensorflow as tf in python is ok but why it has some problems after run the tf env collect sh for example ''ImportError libcusolver so 8 0 cannot open shared object file No such file or directory and how to fix the error LD LIBRARY PATH is unset and DYLD LIBRARY PATH is unset my tensorflow has installed but i do not know how to solve this problem Anyone can help me I'am very tired to deal with the error but no method works THANK YOU VERY MUCH,,"andrewharp,andrewharp",2017-08-20 13:08:43,2017-08-21 09:15:31
IS,The sample code on PROGRAMMER'S GUIDE has a problem,Hello There is a problem on the PROGRAMMER'S GUIDE sharing variables In the second code snippet of the chapter Sharing variables And the code after this also have the problem,,yongtang,2017-08-21 07:53:54,2017-08-21 19:05:00
PR,Fix issue in variable docs,A couple of doc error in programmers guide variables md This fix fixes 12444 Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-08-21 15:47:58,2017-08-21 19:05:01
PR,R1 3,,,jhseu,2017-08-21 07:39:49,2017-08-21 19:09:51
PR,Update Readme md,Fixed run on sentence s I'm just trying to help please do not hurt me,,jhseu,2017-08-21 04:09:59,2017-08-21 19:11:05
PR,typo in docs one once,in tensorflow docs src programmers guide datasets md,,,2017-08-21 02:15:37,2017-08-21 19:11:37
PR,Update link to doc for global variables initializer,Update link to doc for global variables initializer,,,2017-08-18 13:28:27,2017-08-21 19:54:41
PR,update from origin,merge from origin access,,jhseu,2017-08-17 06:54:36,2017-08-21 19:57:38
PR,Correct minimum Python 3 version in install instruction,,,"carlthome,caisq,carlthome,gunan",2017-08-16 18:49:13,2017-08-21 20:00:54
PR,Update control flow ops py,Updated documentation of while loop function,,AndreiCostinescu,2017-08-16 05:23:32,2017-08-21 20:02:21
PR,Update documentations,Add links Replace OS X with macOS Minor url cleanups,,"alanyee,alanyee",2017-08-13 07:25:13,2017-08-21 20:09:02
PR,Branch 165958212,,,"andrewharp,caisq,andrewharp",2017-08-21 20:03:07,2017-08-21 20:09:42
PR,Allow mixed ints and Dimensions for reshape shape param,CF issue 11974 I think this should fix issue with PR 12127 by mapping the dimensions to a new list avoiding any attempt to assign to the shape param if it is a tuple,,"facaiy,jhseu",2017-08-12 02:52:35,2017-08-21 20:12:00
PR,Branch 165951046,,,caisq,2017-08-21 18:47:19,2017-08-21 20:15:59
IS,tf Dataset with tf py func does not work as the tutorial says,System information Ubuntu 16 04 TF 1 3 released version CUDA 8 0 CUDNN 6 0 Python 3 5 Describe the problem Dataset with tf py func does not work as the dataset tutorial says in Source code logs minimum code to reproduce the problem,,"mrry,mrry",2017-08-18 15:42:02,2017-08-21 20:16:26
IS,tf contrib data Dataset does not correctly handle nested dictionaries,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee Python version 2 7 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem tf contrib data Dataset objects do not correctly deal with nested dictionary structures When using a dataset with a nested dictionary the inner dictionaries are replaced with the first tensor in that inner dictionary and following tensors are restored for incorrect keys This is not an issue with tf contrib framework nest only with datasets which appear to instead use tensorflow contrib data python util nest The particular difference causing the bug appears to be L279 vs L184 Source code logs,,mrry,2017-08-17 21:08:36,2017-08-21 20:16:26
IS,Train Multibox object detector included in the TF Detect Android demo,Can anyone guide me how to train our own multibox model pb included in the tensorflow android example,,andrewharp,2017-08-21 05:33:14,2017-08-21 20:57:28
PR,reuse RefCountIsOne function member,reuse RefCountIsOne function member and replace the same implement,,"horance-liu,jhseu",2017-08-21 10:42:15,2017-08-21 21:09:03
PR,Disable denormal test on s390x platform,As per the discussion happened on 11902 the mentioned modes are not applicable for s390x architecture as well So disabling denormal test for s390x platform,,jhseu,2017-08-19 10:13:13,2017-08-21 21:09:21
PR,Update array ops py,Space import statements according to PEP8 Remove unnecessary import statements,,alanyee,2017-08-19 08:09:23,2017-08-21 21:09:38
PR,Eager API inclusion to the dynamic library build target,,,"eaplatanios,caisq,eaplatanios,caisq,alextp,caisq,eaplatanios,caisq,caisq",2017-08-18 17:09:57,2017-08-21 21:10:49
PR,modify doc about deploy of hadoop deprecate KERB TICKET CACHE PATH,I have create to declare this problem,,"jhseu,jhseu",2017-08-16 03:51:49,2017-08-21 21:11:53
PR,android demo Complete path to nsync library destination,CMake Error at CMakeLists txt 30 set target properties set target properties called with incorrect number of arguments,,"ArtsiomCh,jhseu",2017-08-21 20:38:54,2017-08-21 23:06:32
PR,Refactor word2vec basic,This MR changes two functions on word2vec basic py create dataset Update how the function search the dictionary for an index value generate batch Update how the context words are obtained The function originally does that using the following code In this approach an array of valid context words are created without randomly selecting each valid word This valid context words are shuffled and added to a deque to make word removal less costly I believe that this modifications make both create dataset and generate batch a little simpler to understand and although this is not the intention of this MR but a little faster as well,,"jhseu,jhseu,jhseu,jhseu,jhseu",2017-08-20 02:33:18,2017-08-21 23:51:40
IS,Gradient for self adjoint eigvals fails self adjoint eig works fine,As also noted in 1915 already but that ticket had been closed there is a bug in the implementation of self adjoint eigvals whereas self adjoint eig works fine but it is rather inefficient to compute eigenvectors and their gradients if I only require the eigenvalues System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no stock usage of tf self adjoint eigvals minimal failing example below OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version v1 2 1 2 gc996c7b Python version 3 5 2 Bazel version if compiling from source 0 5 2 binary install CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1070 with 8 GB memory Exact command to reproduce see below Minimal failing example Thanks,,"reedwm,rmlarsen,rmlarsen,rmlarsen",2017-07-27 15:38:11,2017-08-21 23:52:26
IS,BUG TypeError in DNNClassifier eval when using same name for feature in feature engineering fn,Describe the problem If we use the same key to replace a feature tensorflow might throw TypeError when evaluating eg When features is dict it is a mutable object Hence the bug is caused by evaluate method which runs feature engineering fn again see code L1165 I will open a PR later,,facaiy,2017-08-11 08:21:10,2017-08-21 23:56:32
PR,BUG Estimator eval runs feature engineering fn more than once,The PR is aimed to fix 12205 What changes were proposed in this pull request eliminate the second call of feature engineering fn in evaluate method How was this patch tested x add an unit test,,"facaiy,ispirmustafa,facaiy,facaiy,ispirmustafa,facaiy,facaiy,facaiy,facaiy,jhseu,facaiy",2017-08-11 08:27:02,2017-08-21 23:56:33
PR,Feature add provide Java Graph class getter for all operations,c api code and tests Java code and tests and JNI code to support exposing and using the cardinality of operations contained in a graph and an aggregate of them This is to support As is the stuff of Git sleepover folklore i stand in the bathroom mirror and softly say three times,,"asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,martinwicke,martinwicke,martinwicke,jhseu,jhseu",2017-08-13 02:56:07,2017-08-22 00:06:56
PR,Clean up ishell True' in using subprocess module,Currently configure py always use the running python interpreter to find the site packages path When user has specified a different python in the previous step the specified one should be used,,"yifeif,yifeif,yifeif,yifeif,yifeif,yifeif",2017-08-17 05:18:21,2017-08-22 00:44:19
PR,Testing out the build,,,"jhseu,jhseu",2017-08-21 23:19:00,2017-08-22 00:49:05
PR,Update boringssl,to include Work around language and compiler bug in memcpy etc Details in That change was needed on my system to avoid the following compilation error external boringssl src crypto asn1 a bitstr c 118 5 error 'memcpy' specified size between 18446744071562067968 and 18446744073709551615 exceeds maximum object size 9223372036854775807 Werror stringop overflow,,"caisq,jhseu,jhseu",2017-08-18 21:01:36,2017-08-22 00:49:48
PR,Update estimator py,Replace contrib with training and core framework APIs,,"alanyee,jhseu,jhseu",2017-08-18 18:48:48,2017-08-22 00:49:59
PR,fix bugs in stack bidirectional rnn,The condition of the original codes is not related to the constraint I think initial states bw is written as cells bw by mistake,,jhseu,2017-08-15 14:24:39,2017-08-22 00:50:12
IS,Feature InputStream variant for ReadBinaryProto and ReadTextProto,System information N A Describe the problem Currently in master branch both ReadBinaryProto and ReadTextProto accepts only file path to load model proto while in some cases we may want to load from a network stream or any other input stream of model proto file that input stream is our best option So I think adding two variants accepts stream input instead of file path should be good As both these ReadBinaryProto and ReadTextProto are in C public API may I know is it feasible to add Or any other security or implementation difficulty that is blocking it Or design conflict If it is just lacking of people sure I can help Source code logs N A,,"resec,reedwm,tatatodd,resec,tatatodd",2017-08-18 01:49:12,2017-08-22 01:54:00
IS,Train our own dataset,Can you guide me to train our own data set for TFdetect example I read lots of guidelines regarding this but those are confusing me So can anyone give me well ordered set of instructions to complete this,,andrewharp,2017-08-20 11:11:44,2017-08-22 03:26:03
IS,Error in estimator py,Hi I am running the tutorial code A Guide to TF Layers Building a Convolutional Neural Network on API r 1 3 My code is here The error shows,,,2017-08-22 01:40:46,2017-08-22 04:18:11
IS,Failure to build on OS X,I have the following error when building on OS X,,"DavidNorman,DavidNorman,powderluv",2017-08-22 08:35:03,2017-08-22 09:26:23
IS,FIFOQueue ' 1 input producer' is closed,I'm using an input pipeline in a tf managed session and encountered the following error message Thank you in advance for your help,,,2017-08-19 13:31:55,2017-08-22 13:23:10
IS,Installation failure on Windows 10,Hi i'm having trouble installing tensorflow It already worked and evereything was fine when i changed cuDNN to 6 0 for something else But now even after installing everything from the drivers of the gpu to CUDA and cudnn5 1 new tensorflow installation is failing I am always getting this error but every solution i found in other issues with similar errors is not working All the pathes are set correct Anyone has an idea import tensorflow as tf Traceback most recent call last File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow internal py line 18 in swig import helper return importlib import module mname File C Users rkoch AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed Das angegebene Modul wurde nicht gefunden During handling of the above exception another exception occurred Traceback most recent call last File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users rkoch AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tenso rflow internal py line 18 in swig import helper return importlib import module mname File C Users rkoch AppData Local Programs Python Python35 lib importlib init py line 126 in import File C Users rkoch AppData Local Programs Python Python35 lib site pac kages tensorflow init py line 24 in module from tensorflow python import File C Users rkoch AppData Local Programs Python Python35 lib site pac kages tensorflow python init py line 49 in module ed from tensorflow python import pywrap tensorflow File C Users rkoch AppData Local Programs Python Python35 lib site pac kages tensorflow python pywrap tensorflow py line 52 in module e raise ImportError msg oved ImportError Traceback most recent call last File C Users rkoch AppData Local Programs Python Python35 lib site pac kages tensorflow python pywrap tensorflow internal py line 18 in swig i mport helper return importlib import module mname File C Users rkoch AppData Local Programs Python Python35 lib importlikages tensorflow python pywrap tenso b init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import kages tensorflow python pywrap tenso File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlock ed kages tensorflow python pywrap tenso File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed Das angegebene Modul wurde nicht gefunden During handling of the above exception another exception occurred Traceback most recent call last File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users rkoch AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users rkoch AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,,2017-08-21 07:22:49,2017-08-22 14:25:36
IS,Use Tensorflow in conjunction with PyTorch Theano,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 0 12 1 Python version 2 7 10 Bazel version if compiling from source None CUDA cuDNN version 5 1 GPU model and memory 1080 Ti Exact command to reproduce None Describe the problem I'm trying to use Tensorflow in conjunction with PyTorch I built the model in Tensorflow to generate vector representations and PyTorch trains on top of those However the problem is that PyTorch runs out of memory because TF will replicate the model in ALL available CUDA devices In this case CUDA VISIBLE DEVICES is not helpful and I tried GPU device tf device gpu 0 but Tensorflow still fills up all GPUs' memory Is there some way to actually limit Tensorflow is GPU usage to one and free up the other for other DL libraries like PyTorch or Theano,,mrry,2017-08-22 07:56:07,2017-08-22 14:38:49
PR,Fix serveral typos in docs,Signed off by Ti Zhou tizhou1986 gmail com Fix serveral typos in docs Including tensorflow docs src programmers guide threading and queues md tensorflow docs src api guides python reading data md,,,2017-08-22 09:26:40,2017-08-22 14:41:37
PR,Fix images not showing in profiler README,,,bryant1410,2017-08-22 13:52:57,2017-08-22 17:38:17
PR,Fix code highlight language in profiler README,,,"bryant1410,caisq,bryant1410,caisq,bryant1410",2017-08-22 13:48:21,2017-08-22 18:34:51
IS,Feature Java Inspect tensors in a Graph,Dear Tensorflow maintainers First of all i really like it that tensorflow allows easy interop from keras to tensorflow and then allows for interference to Java I have noticed that when you load an invalid graph for example an empty byte array then it will just accept it without giving an error An exception will be thrown when we try to run the graph Thus i would propose two improvements for the tensorflow java API throw an exception when loading an invalide graph add api functionality to inspect the tensors contained in the graph I also noticed in the example for java that you wrapped the graph builder in a convenience java class and it seems that this could be implemented in a really clean way in scala I would gladly offer you my assistance to implement a scala wrapper Kind regards Boris,,"tatatodd,asimshankar",2017-08-09 08:56:44,2017-08-22 19:36:10
IS,AttributeError 'int' object attribute ' doc ' is read only,In the file tensorflow compiler tests adagrad test poplar runfiles org tensorflow tensorflow python ops variable scope py line 191 I have an error when trying to run unit tests Python is unhappy with trying to assign to doc This is on OS X with a virtualenv containing all of the modules required for the head of master on 22nd August 2017 I have had to add autograd and enum and as a consequence of the OS X built in numpy I have switched to building tensorflow in a virtualenv,,"DavidNorman,yongtang",2017-08-22 13:06:57,2017-08-22 20:14:22
IS,README link to Linux GPU Python 3 5 nightly build is broken,I figured you would not need the form information The link TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON3 5 label gpu linux lastSuccessfulBuild artifact pip test whl tensorflow gpu 1 3 0 cp35 cp35m linux x86 64 whl My response,,,2017-08-21 22:07:41,2017-08-22 20:30:40
IS,The tensorflow was not compiled to use AVX2 on Windows,I instaled the python 3 and the tensorflow from pip But when I run the program I receive the warnings image How to hidden or fix the warnings on Windows Thank you so much,,,2017-08-21 12:10:15,2017-08-22 20:35:28
IS,Installation problem while building tensorflow GPU,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-08-21 06:39:36,2017-08-22 20:50:02
IS,Tensorflow GPU import causes exeptions Resolved,There is a problem occures when I import tensorflow C Program Files Python35 python exe D NetDisks DropBox Dropbox Develop Python TensorFlow GPUTest py Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File D NetDisks DropBox Dropbox Develop Python TensorFlow GPUTest py line 1 in module import tensorflow as tf File C Program Files Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Program Files Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help Process finished with exit code 1 Windows 7 x64 SP1 CPU Intel Core I7 990x Motherboard Asus P6T SE GPU GTX 1080 TI tensorflow have been installed with native PIP command pip install tensorflow gpu Python 3 5 2 CUDA 8 0 Toolkit CUDNN 5 1 The code is import tensorflow as tf Path C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 bin C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 libnvvp C Program Files Python35 Scripts C Program Files Python35 C Program Files Microsoft MPI Bin C Windows C Windows System32 C Program Files dotnet C Program Files Anaconda3 C Program Files Anaconda3 Scripts C Program Files Anaconda3 Library bin C Program Files Anaconda2 C Program Files Anaconda2 Scripts C Program Files Anaconda2 Library bin C Program Files x86 Anaconda3 C Program Files x86 Anaconda3 Scripts C Program Files x86 Anaconda3 Library bin C Program Files x86 Anaconda2 C Program Files x86 Anaconda2 Scripts C Program Files x86 Anaconda2 Library bin C Program Files NVIDIA Corporation cuda bin C Program Files x86 NVIDIA Corporation PhysX Common C Program Files NVIDIA Corporation cuda bin C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 bin C Program Files NVIDIA GPU Computing Toolkit CUDA C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 lib x64 C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 extras CUPTI libx64 CUDA HOME C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 CUDA PATH C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 CUDA PATH V8 0 C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 MSVC 2015 x64 is installed cudnn64 5 dll is located at C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 bin Also if i install a regular tensorflow it works OK How do I deal with fix this,,,2017-08-21 03:36:10,2017-08-22 20:50:28
IS,Feature TF on mix environnment CPU GPU,When using TF GPU either switches to GPU depending on GPU availability When we have a mixed environnment CPU GPU it would be better to distribute across CPU and GPU available specify the core available to TF for full usage keeping one for centralized processing,,,2017-08-20 09:09:44,2017-08-22 20:52:29
IS,about fps,In android device if I want to know the fps in the detection activity what should I do in the DetectorActivity java,,,2017-08-19 07:54:29,2017-08-22 20:57:10
IS,building from source for iOS crashes because of nsync compilation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 5 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce sh build all ios sh Describe the problem I am building tensorflow from source for iOS it crashes when executing TARGET NSYNC LIB tensorflow contrib makefile compile nsync sh t ios First it looks for a specific version of the iPhoneSimulator rather than the latest When I change my symlink to point to the correct version it crashes saying that string h cannot be found Note the previous call to HOST NSYNC LIB tensorflow contrib makefile compile nsync sh executes correctly Source code logs,,,2017-08-23 07:30:27,2017-08-23 08:08:09
IS,Running session using c api is significantly slower than using python,System information OS Platform and Distribution Linux 13 1 Bottle TensorFlow installed from source TensorFlow version 1 1 0 git version v1 1 0 1 g10ec24a compiler version v1 1 0 1 g10ec24a Compiler c SUSE Linux 4 8 1 20130909 gcc 4 8 branch revision 202388 Bazel version 0 4 5 Packages numpy 1 11 3 numpydoc 0 6 0 protobuf 3 1 0 No docker no virtual environment All tests were done using CPU only All optimization flags are set no warnings are shown tcmalloc is also used Batching also helps to increase the performance both for c and python but the gap stays the same Describe the problem I have written a simple benchmark based on official Deep MNIST example I create a simple convolutional net train it on MNIST number of training steps is small as we are interested in speed not accuracy freeze the graph and load it to c Then I do tests using python and using c and measure average time that it takes to run a tensorflow session My tests show that running session in python takes 2ms while doing the same using c api is slower 3ms The code of the benchmark can be found here It should also be mentioned that the same tests were done for the multilayer perceptron In that case c api was significantly 7 10x times faster than python just as was expected,,"aselle,aselle,alextp,alextp,alextp,alextp,alextp,alextp,yaroslavvb,yaroslavvb,petewarden,alextp,alextp,yaroslavvb,yaroslavvb",2017-06-13 08:32:48,2017-08-23 11:35:10
IS,This is regarding the installation of tensorflow in windows For version 1 3 you have said cuDNN 5 1 for CUDA 8 0 is required I wasted 2 days trying to overcome the errors but later I found that cuDNN 6 is required for TensorFlow v1 3,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-08-23 11:46:03,2017-08-23 11:46:19
IS,bug CUDA messes up after improperly closing Tensorflow session,Whenever I run Keras sessions on PyCharm and I forget to properly close the session example I log off the computer or close session It seems like the CUDA driver stops working I can still run nvcc V and nvidia smi successfully but running the deviceQuery sanity check from the CUDA samples fails which means the system has stopped detecting the graphics card Has anyone else had this problem I definitely recall that this is not the first time this has happened to me using tensorflow vs say using torch pytorch that also use the graphics card and forgetting to close my session Perhaps I am just being spoiled Note that this has happened both using tensorflow directly and using keras with tensorflow as backend where I do not have direct control over closing sessions directly as far as I know,,"reedwm,reedwm",2017-08-18 15:02:06,2017-08-23 14:55:07
IS,Eager tensor execution not inferring dtype attributes,Hi I have noticed that when I use the StridedSlice op for example with the new eager tensor execution API the type arguments T and Index in this case are not automatically inferred and the library complains that they are not provided Also when I do provide them I get an error saying NodeDef mentions attr ' which I cannot figure out maybe you have some idea of what is happening Thanks Anthony,,"eaplatanios,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,eaplatanios,eaplatanios,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,alextp,eaplatanios,alextp",2017-08-17 23:47:01,2017-08-23 15:55:02
PR,DO NOT MERGE Remove RTLD GLOBAL when importing pywrap tensorflow,Just making a pull request to run tests,,"allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,jhseu,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,jhseu",2017-07-18 00:10:56,2017-08-23 16:15:36
PR,Update doc and imports for crf decode,A new method crf decode was added recently does the equivalent of viterbi decode but with tf Tensors as input However it is still not in the docs and it is not importable in tf contrib crf hence the proposed changes,,guillaumekln,2017-08-22 23:36:04,2017-08-23 17:04:27
IS,Building Error Solved,,,,2017-08-22 23:31:28,2017-08-23 18:17:41
IS,Backprop through conv2d with large tensors fails,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 1 0 Python version 3 5 2 Bazel version if compiling from source 0 4 5 CUDA cuDNN version CUDA Version 8 0 61 GPU model and memory GeForce GTX 1080 8GB Exact command to reproduce Please find the full log attached,,"yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang",2017-07-06 15:12:58,2017-08-23 18:50:00
PR,replace explicit type decl with auto deduction for device manager,,,"horance-liu,jhseu",2017-08-22 06:39:20,2017-08-23 19:47:16
PR,replace prune subgraph algorithm with auto deduction for ranged for,,,"horance-liu,jhseu",2017-08-22 02:43:05,2017-08-23 19:47:35
PR,replace auto deduction for master session close member function,,,"horance-liu,jhseu",2017-08-22 02:07:03,2017-08-23 19:47:51
PR,replace auto deduction for master reset member function,,,"horance-liu,jhseu",2017-08-22 01:53:20,2017-08-23 19:48:02
PR,Branch 166229572,,,"jhseu,jhseu",2017-08-23 19:24:55,2017-08-23 23:13:41
IS,BUG DropoutWrapper incorrectly updates memory state,Describe the problem GRU units wikipedia image tf contrib rnn DropoutWrapper documentation state keep prob unit Tensor or float between 0 and 1 output keep probability if it is constant and 1 no output dropout will be added State dropout is performed on the output states of the cell In GRU units the output state is the memory state When variational recurrent True the same temporal dropout mask is applied to the output state in each time step with the remaining outputs divided by the dropout probability This leads to exponential growth of the memory state and exploding outputs given long enough time series image The correct way is probably to divide U z U r and U h and not the output state Source code logs System information cat etc issue Linux mvdslab 4 4 0 83 generic 106 Ubuntu SMP Mon Jun 26 17 54 43 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 2 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux mvdslab 4 4 0 83 generic 106 Ubuntu SMP Mon Jun 26 17 54 43 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 12 1 numpydoc 0 6 0 protobuf 3 3 0 tensorflow 1 2 0 tensorflow gpu 1 2 0 check for virtualenv False tensorflow import tf VERSION 1 2 0 tf GIT VERSION v1 2 0 1131 gbc691dd tf COMPILER VERSION v1 2 0 1131 gbc691dd Sanity check array 1 dtype int32 env LD LIBRARY PATH home anton torch install lib usr local cuda 8 0 lib64 DYLD LIBRARY PATH home anton torch install lib home anton torch install lib nvidia smi Thu Jul 20 10 36 06 2017 NVIDIA SMI 375 66 Driver Version 375 66 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Quadro K1200 Off 0000 01 00 0 On N A 39 38C P0 1W 35W 459MiB 4034MiB 3 Default Processes GPU Memory GPU PID Type Process name Usage 0 1183 G usr lib xorg Xorg 110MiB 0 6218 G el token 544D2517E333A364F4E0C0630D2C9DD1 347MiB cuda libs usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7,,"asimshankar,ebrevdo,ebrevdo,ebrevdo",2017-07-20 18:17:53,2017-08-23 23:14:20
IS,Eager execution API strided slice problem,alextp there seems to be a problem with eagerly executing strided slice ops The problem seems to be in the shape inference component and is non deterministic If you add the following code in the eager c api test cc file and run the test multiple times you will notice that sometimes it succeeds and sometimes it fails randomly More specifically I get errors related to the strides input tensor but I think this may have to do with how the memory is managed for eager tensors,,"eaplatanios,alextp,eaplatanios,alextp,alextp,eaplatanios,alextp,eaplatanios,alextp,eaplatanios",2017-08-23 19:56:06,2017-08-23 23:40:27
IS,tensorflow cmake compile problem on vs2015,System information windows10 install tensorflow from source by vs2015 TensorFlow version r1 2 Python Anaconda 4 2 0 python3 5 SWIG swigwin3 0 10 CMake 3 8 2 Command line to compile D Developer Microsoft Visual Studio 14 0 VC bin amd64 vcvars64 bat cd tensorflow tensorflow contrib cmake mkdir build cd build cmake A x64 DCMAKE BUILD TYPE Release More DSWIG EXECUTABLE C tools swigwin 3 0 10 swig exe More DPYTHON EXECUTABLE D Developer Anaconda3 python exe More DPYTHON LIBRARIES D Developer Anaconda3 libs python35 lib More Dtensorflow WIN CPU SIMD OPTIONS arch AVX Describe the problem after generate the configure files run the command as bellow MSBuild M 10 p Configuration Release tf tutorials example trainer vcxproj I have used this command to compile the tensorflow c example project and some c libs successfully about a month ago But now I tried many times never success Error log But this time it did not work and return the compile error C Users Administrator Desktop tensorflow tensorflow contrib cmake build tf tutorials example trainer vcxproj default target 1 C Users Administrator Desktop tensorflow tensorflow contrib cmake build tf core framework vcxproj default ta rget 6 CustomBuild target C Program Files x86 MSBuild Microsoft Cpp v4 0 V140 Microsoft CppCommon targets 171 5 error MSB6006 cmd exe exited with code 1 C Users Administrator Desktop tensorflow tensorflow contrib cmake build tf core fram ework vcxproj 277 Warning s 1 Error s,,"mrry,mrry",2017-08-21 09:44:22,2017-08-24 01:23:40
PR,Branch 166267240,Repushing to fix the Go build,,jhseu,2017-08-23 23:50:20,2017-08-24 01:51:58
PR,add lvalue ref for auto deduction and avoid to copy object,,,"horance-liu,mrry",2017-08-22 08:06:01,2017-08-24 01:54:32
PR,Use XLA TEST F to allow disabling of individual tests,converting test to allow individual test cases to be disabled using the CC test disable manifest,,"DavidNorman,hawkinsp",2017-08-20 19:45:41,2017-08-24 01:56:09
PR,XLA Break the Slice test into different tests for each data type,This allows our backend and others to disable types which they do not support Previously all types were tested by the same test function,,"DavidNorman,hawkinsp,hawkinsp,hawkinsp",2017-08-17 10:16:48,2017-08-24 01:57:49
PR,XLA Bring XLA Transpose021Tiled up to date with reference CUDA implementation,The Transpose021Tiled is no longer up to date with the reference Cuda implementation and this PR updates the XLA to generate codes that resemble the latest reference Cuda implementation The main improvement is that a two dimensional logical thread block is launched instead of a one dimensional one Having more threads in a block increases throughput of transpose,,"tjingrant,jhseu,jhseu,jhseu,jhseu",2017-08-16 20:42:26,2017-08-24 01:58:52
PR,remove duplicated code for find master session by handle,remove all duplicated code for finding master session by session handle,,"horance-liu,mrry,mrry,mrry,horance-liu,jhseu,jhseu",2017-08-16 06:42:32,2017-08-24 01:59:19
PR,typo missing ' ',it is missing the at end of android ndk repository,,"jhseu,jhseu",2017-08-23 00:13:58,2017-08-24 02:36:35
IS,Data Augmentation of uint16 images such as PNG,How we can do data augmentation rotation flip of uint16 images Here is a piece of my code import os import tensorflow as tf filQ 'ex4497 fbp 13 png' 'ex4497 fbp 12 png' filQQ tf train string input producer filQ reader tf WholeFileReader key value reader read filQQ myimg tf image decode png value dtype tf uint16 myimg1 tf image rot90 myimg k 1 name None I get an error that TypeError Value passed to parameter 'tensor' has DataType uint16 not in list of allowed values uint8 int8 int32 int64 bool float16 float32 float64 complex64 complex128 string So basically unit16 does not exist unit8 is not a good choice because the pixel values in my image are NOT in the range 0 255 and we can only use data type uint8 uint16 for PNG in tensorflow So again the question becomes How we can do data augmentation rotation flip of uint16 images,,"yongtang,yongtang,yongtang",2017-08-23 15:18:52,2017-08-24 03:18:08
PR,Enable int16 and uint16 for reverse op,This fix tries to address the issue in 12528 where it was not possible to run uint16 on rot90 reverse op The int16 and uint16 has been implemented in CPU though they were not enabled yet This fix enables int16 and uint16 This fix fixes 12528 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu",2017-08-23 16:34:51,2017-08-24 03:18:08
PR,Docs typo fix,key value pair key value pair,,jhseu,2017-08-23 15:25:55,2017-08-24 03:18:20
PR,Expose new CRF classes and function,12056 introduced a new tensor based CRF decoding This PR exposes the new names at the module level,,"guillaumekln,jhseu",2017-08-22 12:55:22,2017-08-24 03:19:52
PR,replace loop with ranged for from worker is get status,,,"horance-liu,jhseu",2017-08-22 06:48:47,2017-08-24 03:20:04
PR,XLA Replace TEST F with XLA TEST F to allow for disabling,This will allow any of the tests in the CopyTest suite to be disabled by using a disable manifest,,"DavidNorman,jhseu",2017-08-23 08:33:32,2017-08-24 04:20:35
PR,Update head py,Use tf metrics instead of contrib version Use core lookup instead of contrib version Nvm another PR Remove TODO in tensorflow contrib lookup init py since already done,,"alanyee,jhseu",2017-08-23 07:14:46,2017-08-24 04:20:52
PR,remove redundant line in fused batch norm,,,jhseu,2017-08-23 02:41:33,2017-08-24 04:21:05
PR,Update get started md,Add python 2 compatibility for tutorial code Corrected console outputs Included or rearrange some import statements,,"alanyee,alanyee,jhseu",2017-08-22 16:25:35,2017-08-24 04:22:08
PR,Modification and Uniformisation of setup py files,Hello everyone As you may find on PyPI tensorflow is not reported as a package which is compatible with python 3 Which does not prevent to be able to install it with pip properly it just mess up any API call to the PyPI API which is not good for all our friends using CI tools The reason is actually quite simple some classifiers were missing So the main objective of this PR is basically to fix the aforesaid issues in the two setup py i was able to find I also took the opportunity to uniformise the two setup py files They now declare the same audiences and topics I hope it will be fine Else I can still revert the changes and just keep the changes related to Python 3 compatibility Please have a great day Best Regards Jonathan DEKHTIAR,,"gunan,gunan,gunan,gunan,jhseu",2017-08-22 09:28:48,2017-08-24 04:23:20
PR,Implement BiasAddGradHelper,Registers the BiasAddGrad op as the gradient for BiasAdd by implementing BiasAddGradHelper Unlike the other tested ops in nn grad tests cc BiasAdd takes two arguments The test I added does test both arguments but not simultaneously Not sure if that is acceptable Guidance appreciated This is only my second PR to TensorFlow When giving feedback please assume that I barely know what I'm doing,,"bpiel,suharshs,suharshs,suharshs,asimshankar,bpiel,jhseu",2017-08-21 11:57:56,2017-08-24 04:24:41
PR,XLA Add F16 as type for the literal conversion functions,The F16 synonym for eigen half type was not included in the literal conversion functions float double is supported as a type conversion by the eigen half so adding identical lines as the native types,,"DavidNorman,hawkinsp,DavidNorman,DavidNorman,DavidNorman,hawkinsp",2017-08-14 13:09:56,2017-08-24 04:34:33
PR,Verbs hang fix,Replaces the sync wrappers for device to device operations in verbs util with a call to the async function with a callback function Resolves Issue 11725 As mentioned in the issue I think the problem rises because the Sync deviceToDevice operation blocks the thread preventing the earlier Async Device to Device operation from finishing which for some reason blocks the later operation I have tested this fix in origin r1 3 since origin master is currently broken 2nd commit only removes the unused functions from verbs utils It is not required for validity can you please go over this,,"yanivbl6,yanivbl6,byronyi,yanivbl6,yanivbl6,jhseu,jhseu",2017-08-17 12:19:05,2017-08-24 04:57:08
PR,Constructor with InputStream only for TensorFlowInferenceInterface,Added a InputStream Constructor for TensorFlowInferenceInterface which support loading model from network or many other situations that we can only have a InputStream of the model One thing worth mentioning is that the private modelName member is not set this new constructor but the field is private and only use in the original constructor which I prefer this member should be deleted I think it should be fine,,"resec,jhseu,jhseu,jhseu,jhseu,resec,jhseu",2017-08-17 01:17:38,2017-08-24 04:58:18
PR,Update learning py,Using core variables and training framework instead of deprecated variables,,"alanyee,jhseu",2017-08-16 20:39:28,2017-08-24 04:58:35
PR,rm duplicated implements for GrpcRemoteMaster,Refactoring GrpcRemoteMaster and rm duplicated implements for it,,"horance-liu,mrry,jhseu",2017-08-16 05:52:51,2017-08-24 04:58:47
PR,XLA Register XLA GPU iff cuda enable,Fix PTAL Thanks,,"ScorpioCPH,hawkinsp,ScorpioCPH,ScorpioCPH,rmlarsen,ScorpioCPH,hawkinsp,jhseu,jhseu,hawkinsp,caisq,ScorpioCPH,jhseu,ScorpioCPH",2017-08-10 14:35:38,2017-08-24 05:00:41
PR,Clean up in sparse fill empty rows op cc,Both int64 prev row 1 and const int64 row indices i 0 was not used It generates quite a few warnings in the output Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu,jhseu,jhseu,jhseu",2017-08-14 15:38:39,2017-08-24 05:04:45
PR,Support boolean type to variables' ops and assign like ops 12046,Fix 12046,,"nolanliou,jhseu,jhseu,jhseu,nolanliou,jhseu",2017-08-15 10:02:42,2017-08-24 05:19:10
IS,tf cnn benchmarks py stuck when running with multiple GPUs and ImageNet data with protocol grpc verbs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No running tf cnn benchmarks py from benchmarks repo OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary Unmodified source with RDMA Verbs enabled TensorFlow version use command below 1 3 0 rc0 Python version 2 7 12 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 6 GPU model and memory NVIDIA Tesla P100 PCIe 16GB 8 per node Exact command to reproduce PS CUDA VISIBLE DEVICES '' python tf cnn benchmarks py ps hosts 12 12 12 43 20000 worker hosts 12 12 12 44 20000 12 12 12 41 20000 batch size 64 model inception3 variable update parameter server local parameter device cpu job name ps task index 0 server protocol grpc verbs Worker0 CUDA VISIBLE DEVICES '0 1 2 3 4 5 6 7' python tf cnn benchmarks py ps hosts 12 12 12 43 20000 worker hosts 12 12 12 44 20000 12 12 12 41 20000 batch size 64 model inception3 variable update parameter server local parameter device cpu job name worker task index 0 num gpus 8 data dir data imagenet data train dir data imagenet train server protocol grpc verbs Worker1 CUDA VISIBLE DEVICES '0 1 2 3 4 5 6 7' python tf cnn benchmarks py ps hosts 12 12 12 43 20000 worker hosts 12 12 12 44 20000 12 12 12 41 20000 batch size 64 model inception3 variable update parameter server local parameter device cpu job name worker task index 1 num gpus 8 data dir data imagenet data train dir data imagenet train server protocol grpc verbs RDMA driver version MLNX OFED LINUX 4 1 1 0 2 0 Describe the problem When running the above commands Inception V3 synchronized data parallelism training with 2 workers and 1 external ps the tf cnn benchmarks application hangs forever after some iterations usually in warm up It happens only when real data is involved ImageNet and with 4 GPUs More GPUs less iterations before it hangs Does not happen with grpc protocol or when running with synthetic data The master service in the workers is stuck here L608 which I guess means some operations in the computation have not been completed The RDMA protocol looks valid and clean all messages corresponds to the protocol see below logs There some tensors requested by the workers which they do not receive but they are passed by the RDMA Verbs transport to the BaseRendezvoudMgr with RecvLocalAsync in a valid way and for some reason the higher level worker service does not trigger the Send kernel on those tensors Any help is much appreciated If there are some debug mechanisms I can use to understand which tensors operations have not been completed it can greatly help I was mostly debugging this from the RDMA Verbs layer till now without much success and I feel I do not have enough information there to understand what is missing Also I feel we do not have enough knowledge on how the step id acts diving into this in the code now but there is some higher level documentation it can greatly help My initial guess was an occurrence of a racy condition when loading the data since it creates a gap in execution time worker0 starts the first training step 30 60 seconds after worker1 since it does the preprocessing of the data twice for a reason I could not understand yet but after the first iteration which usually passes successfully the time is synchronized between workers Source code logs Those are the logs of the runtime after moving the logging in rdma cc to VLOG 0 also adding Tensor name and step id for all cases in some cases the step id does not mean anything like BUFFER REQUEST RESPONSE for example and also some VLOG in master session cc worker0 worker1 ps Unfortunately they are fairly large but it is better then to cut the log files IMO Example for analysis I did in the verbs layer comparing the Sent Tensor requests to the actual received tensors writes in both workers worker 0 job ps replica 0 task 0 cpu 0 f3c10d28b54074c0 job worker replica 0 task 0 gpu 0 edge 116943 group deps 2 NoOp 1 0 0 80661058974090965 job worker replica 0 task 1 cpu 0 1a50d5c51cd9c5d1 job worker replica 0 task 0 gpu 0 edge 116947 group deps 3 NoOp 1 0 0 80661058974090965 job worker replica 0 task 1 gpu 2 7f00fadabfe781f5 job worker replica 0 task 0 gpu 0 edge 111078 group deps 1 NoOp 2 0 0 80661058974090965 job worker replica 0 task 1 gpu 4 b07185dd19f62088 job worker replica 0 task 0 gpu 0 edge 111080 group deps 1 NoOp 4 0 0 80661058974090965 worker 1 job ps replica 0 task 0 cpu 0 f3c10d28b54074c0 job worker replica 0 task 1 cpu 0 edge 155113 AssignAdd 0 0 80661058974090965 job worker replica 0 task 0 gpu 0 f3df8abf03739fe8 job worker replica 0 task 1 cpu 0 edge 116948 group deps 3 0 0 80661058974090965 The tensors requests received well by the other side and passed to RecvLocalAsync but are not called later Thanks a lot,,"reedwm,suiyuan2009,reedwm,suiyuan2009,byronyi,byronyi,suiyuan2009,suiyuan2009,byronyi,byronyi,byronyi,byronyi,yanivbl6,yanivbl6,yanivbl6",2017-07-24 20:01:58,2017-08-24 05:21:42
PR,Remove type constraint on shape invariants,This PR fixes the unnecessarily strict type checking addressed in issue 11115 Turning type checking off for the shape invariants parameter in tf while loop will allow the parameter to be more easily used when for example trying to provide an invariant for an LSTMStateTuple variable,,"caisq,vrv,rmlarsen,jhseu",2017-06-30 15:33:24,2017-08-24 05:35:32
IS,Feature add safe mode for tf cast,tf cast allows to cast float value to int without any warnning It seems quite unsafe and data will be truncated Perhaps it will be better like astype in numpy to add a casting to support both safe and unsafe casting mode I can work on it if possible,,"facaiy,facaiy,facaiy",2017-08-12 11:54:40,2017-08-24 05:36:46
PR,small update to partial run setup,leaving out the feeds argument for partial run setup produced an error due to the default being None Passing an empty list as feeds fixed the problem so make this the default,,"caisq,caisq,caisq,vrv,rmlarsen,jhseu",2017-07-07 15:40:48,2017-08-24 05:37:32
PR,Update CODE OF CONDUCT md with additional protected characteristic,Government Military Veteran affiliation government catch all protected characteristic added to opening paragraph,,"vrv,vrv,rmlarsen,jhseu",2017-07-20 16:34:44,2017-08-24 05:44:01
PR,Update layers py,I have added a check on beta with reference to the following issue raised Please verify and get back Thank you,,"shreyneil,caisq,shreyneil,vrv,rmlarsen,jhseu",2017-07-23 08:35:51,2017-08-24 05:48:09
PR,fixed tf pow edge case,The tf pow function has an edge case which causes it to hang with no error message If you try to evaluate tf pow x y when x is an integer and thus the output tensor is also an integer while y is a negative value tensorflow hangs trying to cast the fraction as an integer,,"aselle,vrv,vrv,rmlarsen,jhseu",2017-07-28 16:37:50,2017-08-24 05:50:24
PR,Refactor create worker sessions,Refactoring to OO style for worker group for create worker sessions and it is more clear for implements,,"horance-liu,mrry,horance-liu,horance-liu,jhseu",2017-08-19 14:40:12,2017-08-24 06:02:12
IS,Outdated Documentation ImportError libcudnn so 6,Problem Description The binary version for GPU provided here python 36 on installation page of Ubuntu expects cuDNN v6 However the documentation mentions the version of cuDNN required as 5 1 Kindly rectify the error in documentation System information Linux Ubuntu 16 04 TensorFlow installed from binary GPU Version Tensorflow version v1 3 0 rc2 20 g0787eee 1 3 0,,"yongtang,yongtang,yongtang",2017-08-19 15:24:00,2017-08-24 06:04:25
PR,Change required cuDNN from v5 1 to v6 0 for Linux in the docs,This fix changes the required cuDNN from v5 1 to v6 0 for Linux in tensorflow docs src install install linux md as the build is linked against libcudnn so 6 now not libcudnn so 5 This fix fixed 12416 Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry",2017-08-21 22:37:55,2017-08-24 06:04:25
PR,12537 issue solution,print prefix message by flag value,,,2017-08-24 08:30:30,2017-08-24 09:02:09
IS,CMake fatal error 'nsync time init h' file not found on mac,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Darwin T X local 16 5 0 Darwin Kernel Version 16 5 0 Fri Mar 3 16 52 33 PST 2017 root xnu 3789 51 2 3 RELEASE X86 64 x86 64 TensorFlow installed from source or binary Source TensorFlow version use command below Not applicable Happens during build Python version Not applicable Happens during build Bazel version if compiling from source Not applicable Compiling directory tensorflow contrib cmake using CMake 3 7 2 and clang Apple LLVM version 8 1 0 clang 802 0 42 CUDA cuDNN version Not applicable GPU model and memory Not applicable Exact command to reproduce cmake build Users kasper Development tensorflow pr tensorflow contrib cmake target all j 8 Describe the problem This is a bug related to the CMake build of TensorFlow which fails on my system due to an error with the nsync build The nsync build seems to not include some headers see below I have tested with TensorFlow v1 0 0 v1 1 0 v1 2 0 and the current master branch I have not been able to investigate the nsync error because a standalone nsync build i e clone cmake make fails at an earlier step Users kasper Development nsync platform macos platform h 35 13 error typedef redefinition with different types 'int' vs 'enum clockid t' typedef int clockid t Unfortunately I have not been able to submit an issue to and resolve this problem because issues are disabled for this repository Source code logs 46 Building CXX object CMakeFiles nsync dir platform c 11 src time rep timespec cc o no Users kasper Development TensorFlowImageFilter SuperBuild cmake build debug TensorFlow build nsync src nsync platform c 11 src time rep timespec cc 19 10 fatal error 'nsync time init h' file not found include nsync time init h,,,2017-08-23 19:35:35,2017-08-24 11:37:20
IS,freeze graph giving decode error,i am using tensorflow gpu 1 3 0rc2 cp36 cp36m win amd64 whl running freeze graph in python 3 6 2 on windows 10 64 Traceback most recent call last File C Anaconda3 lib runpy py line 193 in run module as main main mod spec File C Anaconda3 lib runpy py line 85 in run code exec code run globals File C Anaconda3 lib site packages tensorflow python tools freeze graph py line 260 in module app run main main argv sys argv 0 unparsed File C Anaconda3 lib site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File C Anaconda3 lib site packages tensorflow python tools freeze graph py line 192 in main FLAGS variable names blacklist File C Anaconda3 lib site packages tensorflow python tools freeze graph py line 170 in freeze graph input graph def parse input graph proto input graph input binary File C Anaconda3 lib site packages tensorflow python tools freeze graph py line 137 in parse input graph proto input graph def ParseFromString f read File C Anaconda3 lib site packages google protobuf message py line 185 in ParseFromString self MergeFromString serialized File C Anaconda3 lib site packages google protobuf internal python message py line 1063 in MergeFromString if self InternalParse serialized 0 length length File C Anaconda3 lib site packages google protobuf internal python message py line 1099 in InternalParse pos field decoder buffer new pos end self field dict File C Anaconda3 lib site packages google protobuf internal decoder py line 633 in DecodeField if value InternalParse buffer pos new pos new pos File C Anaconda3 lib site packages google protobuf internal python message py line 1099 in InternalParse pos field decoder buffer new pos end self field dict File C Anaconda3 lib site packages google protobuf internal decoder py line 612 in DecodeRepeatedField if value add InternalParse buffer pos new pos new pos File C Anaconda3 lib site packages google protobuf internal python message py line 1099 in InternalParse pos field decoder buffer new pos end self field dict File C Anaconda3 lib site packages google protobuf internal decoder py line 743 in DecodeMap if submsg InternalParse buffer pos new pos new pos File C Anaconda3 lib site packages google protobuf internal python message py line 1089 in InternalParse new pos local SkipField buffer new pos end tag bytes File C Anaconda3 lib site packages google protobuf internal decoder py line 850 in SkipField return WIRETYPE TO SKIPPER wire type buffer pos end File C Anaconda3 lib site packages google protobuf internal decoder py line 799 in SkipGroup new pos SkipField buffer pos end tag bytes File C Anaconda3 lib site packages google protobuf internal decoder py line 850 in SkipField return WIRETYPE TO SKIPPER wire type buffer pos end File C Anaconda3 lib site packages google protobuf internal decoder py line 814 in SkipFixed32 raise DecodeError 'Truncated message ' google protobuf message DecodeError Truncated message,,reedwm,2017-08-16 07:44:12,2017-08-24 15:59:34
PR,Updating the Windows install documents in master,,,"av8ramit,av8ramit",2017-08-24 17:32:56,2017-08-24 18:01:39
PR,Cherrypicks,Docs updates Mark requested,,"av8ramit,MarkDaoust,av8ramit",2017-08-22 17:38:33,2017-08-24 18:06:09
PR,Windows docs,,,av8ramit,2017-08-24 18:10:56,2017-08-24 18:11:04
IS,The precision difference between tensorflow and numpy when using tf reduce mean and np mean,,,"reedwm,ekelsen,ekelsen,ekelsen",2017-08-18 08:34:47,2017-08-24 19:00:30
PR,Fix the XLA build,I merged in a pull request prematurely Tested locally,,jhseu,2017-08-24 18:45:31,2017-08-24 19:45:09
PR,Optimize non max suppression by iterating backwards,In typical scenarios high overlapping boxes are likely to have similar scores Therefore if there are any high overlapping boxes it is faster to find them starting from boxes that have similar scores This simple heuristic improves performance of the op on several actual workload by 10 20 The workloads are like 10k boxes produced by a region proposal network,,"ppwwyyxx,rmlarsen,jhseu,rmlarsen",2017-08-23 15:15:27,2017-08-24 21:21:09
IS,Non fused batch norm with NCHW is mush slower than with NHWC,Describe the problem I noticed that in my environment non fused batch norm with NCHW format run significantly slower Environment info And my tested results data format fused non fused batch norm images sec NHWC fused 1085 5 NHWC non fused 969 1 NCHW fused 1315 6 NCHW non fused 301 1 I test benchmarks with model resnet50 on P40 and get similar results data format fused non fused batch norm images sec NHWC fused 65 7 NHWC non fused 51 0 NCHW fused 84 4 NCHW non fused 7 5 What related GitHub issues or StackOverflow threads have you found by searching the web for your problem I found issue similar with my problem but with opposite result,,"zheng-xq,zhangyaobit",2017-08-19 21:06:27,2017-08-24 22:04:57
PR,Update documentation for contrib,Add small details to documentation Correct styling for documentation,,"alanyee,jhseu,jhseu,jhseu,jhseu",2017-08-20 07:11:07,2017-08-24 23:36:16
IS,Error in installation guide for windows should use cuDNN v6 0 with tensorflow v1 3 0,In the installation guide for windows where it says 'Requirements to run TensorFlow with GPU support' and 'cuDNN v5 1' Actually using cnDNN v5 1 will not work Instead cnDNN v6 0 works This error would cause great waste of time for newbees Please update the doc Thanks,,,2017-08-24 03:55:47,2017-08-24 23:47:57
PR,Adding tf nightly info to the readme,,,"av8ramit,gunan",2017-08-23 22:40:41,2017-08-24 23:49:29
PR,Reopened PR Add handle ties arg to in top k Op to deal with ties 10767,Reopened PR for 10767 Add handle ties argument to in top k Op to make the Op more clear,,"nolanliou,nolanliou,martinwicke,nolanliou,nolanliou,martinwicke",2017-08-12 03:39:17,2017-08-25 01:45:29
IS,rnn MultiRNNCell problems and solution,ValueError Attempt to reuse RNNCell tensorflow contrib rnn python ops core rnn cell impl GRUCell object at 0x11d32cbd0 with a different variable scope than its first use First use of cell was with scope 'rnn multi rnn cell cell 0 gru cell' this attempt is with scope 'rnn multi rnn cell cell 1 gru cell' Please create a new instance of the cell if you would like it to use a different set of weights If before you were using MultiRNNCell GRUCell num layers change to MultiRNNCell GRUCell for in range num layers If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN simply create two instances one for forward one for reverse In May 2017 we will start transitioning this cell is behavior to use existing stored weights if any when it is called with scope None which can lead to silent model degradation so this error will remain until then the origin code from tensorflow contrib import rnn inputs tf placeholder dtype tf int32 shape None None name inputs keep prob tf placeholder dtype tf float32 name keep prob cell rnn GRUCell 10 cell rnn DropoutWrapper cell cell input keep prob keep prob cell rnn MultiRNNCell cell for in range 5 state is tuple True outs states tf nn dynamic rnn cell cell inputs look up dtype tf float32 solution inputs tf placeholder dtype tf int32 shape None None name inputs keep prob tf placeholder dtype tf float32 name keep prob cell rnn MultiRNNCell rnn DropoutWrapper rnn GRUCell 10 input keep prob keep prob for in range 5 state is tuple True,,,2017-08-25 03:58:51,2017-08-25 04:08:13
IS,tfdbg does not work when using start queue runners,Today i tried to use tfdbg to debug my tensorflow model but i found that the run end CLI did not show up when using start queue runners here is my code,,caisq,2017-08-24 04:23:14,2017-08-25 05:00:31
PR,Optimizers in the C API Issue 9837,This pull request adds the Optimizer base class and the GradientDescentOptimizer class to the C API More details here,,"theflofly,caisq,caisq,caisq,caisq,caisq,caisq,caisq,theflofly,suharshs,caisq,caisq,theflofly,caisq,theflofly,theflofly,suharshs,theflofly,asimshankar,theflofly,theflofly,rmlarsen,asimshankar,theflofly,theflofly,rmlarsen,skye,asimshankar,theflofly,theflofly,theflofly,theflofly,theflofly,theflofly,theflofly,theflofly,theflofly,asimshankar,theflofly,asimshankar,theflofly",2017-07-08 14:43:44,2017-08-25 05:12:05
IS,Feature Request Add gradient for BiasAdd op in C API,Add BiasAdd gradient implementation for C API so it can be added to graph through AddSymbolicGradients function,,"bpiel,bpiel,bpiel,bpiel,bpiel,bpiel",2017-08-19 17:39:10,2017-08-25 08:18:14
IS,Tensorflow Bug load avg rises very high cannot kill process system freeze,The following script run sh will increase load avg to several 100 it takes usually 100 iterations run sh The error started to appear in Ubuntu 14 04 where it freezes the workstation Updating to Ubuntu 16 04 makes the workstation more responsible but a reboot is still necessary observations I can not kill the PID of the python process when the load avg rises changing to python3 did not resolve the issue compiling tf 1 3 0 from source did not resolve the issue cat etc issue Linux bipower6 4 4 0 89 generic 112 Ubuntu SMP Mon Jul 31 19 38 41 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux bipower6 4 4 0 89 generic 112 Ubuntu SMP Mon Jul 31 19 38 41 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 3 0 tensorflow gpu 1 2 1 check for virtualenv True tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH home a torch install lib home a torch install lib usr local cuda 8 0 lib64 usr local cuda 8 0 usr local lib usr local cuda 8 0 lib64 usr local cuda 8 0 usr local lib DYLD LIBRARY PATH home a torch install lib home a torch install lib nvidia smi Tue Aug 15 11 25 32 2017 NVIDIA SMI 375 66 Driver Version 375 66 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 1080 Off 0000 02 00 0 Off N A 29 44C P0 41W 180W 0MiB 8114MiB 0 Default 1 TITAN X Pascal Off 0000 04 00 0 Off N A 0 52C P0 56W 250W 0MiB 12189MiB 2 Default 2 Tesla P40 Off 0000 83 00 0 Off 0 N A 69C P0 128W 250W 21897MiB 22912MiB 93 Default Processes GPU Memory GPU PID Type Process name Usage 2 89766 C home a dl bin python 21895MiB cuda libs usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 7 5 doc man man7 libcudart so 7 usr local cuda 7 5 doc man man7 libcudart 7 usr local cuda 7 5 lib libcudart static a usr local cuda 7 5 lib libcudart so 7 5 18 usr local cuda 7 5 lib64 libcudart static a usr local cuda 7 5 lib64 libcudart so 7 5 18 END,,skye,2017-08-15 09:44:32,2017-08-25 09:53:51
IS,tensorflow with cocos2d x failed to build the project,tensorflow with cocos2d x failed to build the project when building project the terminal throws error jni tensorflow third party eigen3 unsupported Eigen CXX11 Tensor 1 42 fatal error unsupported Eigen CXX11 Tensor No such file or directory include unsupported Eigen CXX11 Tensor,,"reedwm,reedwm,gunan,andrewharp",2017-08-17 13:38:35,2017-08-25 14:08:39
IS,Tensorflow estimator with shared network,I am building a tensorflow model with new estimator high level api My model looks like this In fact the model is more complex than that due to the model is used to simulate game operation Classification is responsible for decide whether it is good time for action Then the regression will give the details about the action It contains a combination of CNN and RNN However due to the complexity and memory consumption it is impossible to train and run classification and regression as two network simultaneously Also when I create my estimator like I can only provide one model function for the estimator Is is possibile to train and run two estimator together,,,2017-08-25 05:22:51,2017-08-25 15:42:39
PR,Add estimators md,Copied from master git checkout master tensorflow docs src programmers guide estimators md It is already referenced in tensorflow docs src programmers guide leftnav files,,"MarkDaoust,av8ramit",2017-08-25 15:56:33,2017-08-25 16:52:39
IS,tf variables initializer seems broken,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary The nightly wheel TensorFlow version use command below The nightly build that went out at 2AM on 7 28 2017 TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label gpu linux Python version 2 7 13 Bazel version if compiling from source 0 5 3 CUDA cuDNN version 8 0 GPU model and memory GTX 1080 Exact command to reproduce To reproduce run this snippet in the python interpreter It seems like tf variables initializer is broken it does not initialize the variables passed to it This has caused a TensorBoard test summary test to fail today TensorBoard runs tests on nightly TensorFlow The test had been passing yesterday on nightly built on 7 27,,"chihuahua,chihuahua,chihuahua,yaroslavvb,alextp,chihuahua,alextp,chihuahua,chihuahua,yaroslavvb,alextp,yaroslavvb,alextp,alextp,yaroslavvb,chihuahua",2017-07-28 18:48:30,2017-08-25 17:08:13
IS,accept,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-08-25 15:42:16,2017-08-25 17:25:41
IS,TF Slim can not exclude variables when import data from checkpoint files,I exclude variables that do not exist in the checkpoint file by using the he func variables to restore slim get variables to restore exclude exclude set these variables come from slim train MomentumOptimizer which include ' momentum 0' in name But the program seems to still try to find them in the checkpoint This really confusing me Anyone can help me The link of stackoverflow is,,,2017-08-25 13:06:22,2017-08-25 18:07:59
IS,Slim No cross validation in inception,I run the code for fine tune inception in slim but I find that only train split is used when training so is there no cross validation in inception how should I stop training just at the max steps what is validation split for evaluate the trained model,,,2017-08-25 13:00:02,2017-08-25 18:11:15
PR,Updating install linux md for cuDNN 6,gunan does line 59 need to be updated as well,,"av8ramit,gunan",2017-08-25 16:33:58,2017-08-25 18:14:16
IS,Feature Request Dynamic Dispatch of optimized functions for deployment builds,P System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NA OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 16 TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Hello Thanks for TF Recently OpenCV has integrated dynamic dispatch allowing OpenCV library to leverage optimal code paths for supported hardware acceleration sse fma avx avx2 etc from a single compiled binary This is super useful for deployment builds when you are unsure what CPU family features will potentially run your binary I understand TF is execution model and potentially XLA may add complications not even to say GPU support but for CPU ops or CPU only deployments I imagine something equivalent would be well received While we are speaking of deployment builds are folks just shipping non optimized for client hardware binaries or compiling different builds for different hardware features for end products Thank you,,yaroslavvb,2017-08-23 23:44:40,2017-08-25 18:14:45
PR,Partially fixes 10838,The following warnings seem to print for compiling many ops using gcc 4 9 For example in cuda solvers gpu cu cc I believe this fix will address many but not all of the warnings during the build,,"byronyi,jhseu",2017-08-24 18:39:07,2017-08-25 18:17:03
IS,bug in DataFeeder constructor,System information centos 7 0 python 3 4 tensorflow 1 2 1 Describe the problem When I call tensorflow contrib learn DNNRegressor fit x train dict y train steps 1000 x train dict is dict and y train is array the program throws the following exception and then it works,,yongtang,2017-08-23 10:57:45,2017-08-25 18:17:17
PR,Fix bug in DataFeeder constructor,This fix fixes 12525 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu",2017-08-24 18:08:11,2017-08-25 18:17:17
IS,Compiling TensorFlow gives 3k lines of warnings,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 4 8 kernel TensorFlow installed from source or binary Compiling TF from Source TensorFlow version use command below 1 2 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version CUDA 8 0 CuDNN 5 1 GPU model and memory 1050Ti 4GB Notebook version Intel i5 7300hq CPU Exact command to reproduce Compiling from source following documentation Describe the problem I compiled tensorflow from source The process finished successfully and the binary managed to install and run successfully What seems strange is that during the process I got 3k lines of warnings I am linking to them at the end of the issue I am wondering if that is expected behavior or indication of a small or not so small problem One thing that may affect this is bazel installation I followed Bazel Installation Instructions and used the recommended apt method This led to me running into this issue Installing openjdk 8 jdk on top of the ibm java80 jdk as suggested in a comment issuecomment 304957009 solves the problem although I am not sure how much technical debt this solution caries which may have manifested in some of the warnings produced during compilation Source code logs Configuration Script options Console output of compilation command Because the output is too big to be placed within the issue I have put it in it is own repository,,"rohan100jain,yongtang",2017-06-19 23:48:39,2017-08-25 18:17:30
IS,indicator column raises a TypeError when weighted categorical column is used as its input,Describe the problem indicator column raises a TypeError when weighted categorical column is used as its input I have fixed the bug and the PR is coming later Source code logs,,facaiy,2017-08-24 11:05:44,2017-08-25 18:17:53
PR,convert Dimension to Int for sparse merge in IndicatorColumn,The PR is aimed to fix 12557 sparse merge cannot handle Dimension hence casting Dimension to int when invoked How to test x add an unit test pass all tests,,"facaiy,facaiy,alextp",2017-08-24 11:12:12,2017-08-25 18:17:53
PR,Update RELEASE md,Removed extra for,,jhseu,2017-08-24 06:30:29,2017-08-25 18:18:44
PR,fix gdr compiling error,,,"byronyi,jhseu,byronyi,byronyi,jhseu,jhseu,jhseu,byronyi,byronyi",2017-08-21 22:27:32,2017-08-25 18:19:21
PR,Updating the README to include tf nightly information,,,av8ramit,2017-08-24 23:49:16,2017-08-25 18:39:41
IS,Usage of bit casted tensor function with C api implementation on IOS,Any tutorial on this bit casted tensor function I am building an app on IOS based on ios tensorflow model The model generated a tensor with type float However for my model a unit8 format is required So I want to transfer the tensor is format I found this bit casted tensor maybe useful for directly transformation But I when tried to use it in the code like the following tensorflow TTypes tensorflow uint8 Tensor a new tensor bit casted tensor image tensor the issue use of undeclared identifier 'bit casted tensor' always showed up According to reference bit casted tensor function should use like this TTypes T NDIMS ConstTensor bit casted tensor const Return the tensor data to an Eigen Tensor with the same size but a bitwise cast to the specified dtype T Using a bitcast is useful for move and copy operations NOTE this is the same as tensor except a bitcast is allowed TF Reference Link classtensorflow 1 1 tensor 1afced940422a1e726d9487cb3cb039630 I am not sure if I use it correctly Or it is due to the limited support of tensorflow function on IOS platform Keen for any kind of help,,,2017-08-25 00:57:06,2017-08-25 19:46:11
IS,Impossible to change variable inside checkpoint,I have a checkpoint file and I want to change increase shapes of some Variables from this checkpoint It seems to be impossible using tf assign Tried to use tf assign for var in tf global variables if var name 22 convolutional biases 0 assign tf assign var a validate shape False sess run assign And then when I am trying to execute sess run tf global variables initializer I have an error Assign requires shapes of both tensors to match lhs shape 1 1 1024 60 rhs shape 1 1 1024 55 Node 22 convolutional kernel Adam 1 Assign Assign T DT FLOAT class loc 22 convolutional kernel use locking true validate shape true device job localhost replica 0 task 0 cpu 0 22 convolutional kernel Adam 1 zeros 51 So is it really impossible in TF Could it be a feature request,,,2017-08-25 19:35:16,2017-08-25 19:52:33
IS,ValueError No attr named ' XlaCompile' and AttributeError 'NoneType' object has no attribute 'back prop' with tf while loop and templates,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow version use command below 1 2 1 3 Python version 3 4 CUDA cuDNN version 5 6 GPU model and memory GTX 1080 Ti Describe the problem When I run tf train Optimizer minimize loss I receive the error message below The code is a bit unwieldy so I just provide the overall structure of my code,,"carlthome,carlthome",2017-08-20 01:25:47,2017-08-25 21:47:53
IS,MonitoredTrainingSession can not add summary and checkpoint hook,I trying to add summary and checkpoint to my distributed tensorflow training with custom data pre summary hook tf train SummarySaverHook save secs 600 output dir FLAGS log dir summary op summary op checkpoint hook tf train CheckpointSaverHook save steps test timing checkpoint dir FLAGS log dir saver saver with tf train MonitoredTrainingSession server target is chief is chief hooks sync replicas hook summary hook checkpoint hook config sess config as sess pre with above I can not run the sess with error of below pre 2017 08 24 19 38 31 250556 W tensorflow core framework op kernel cc 1148 Invalid argument Shape 1 13 has negative dimensions 2017 08 24 19 38 31 250633 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Invalid argument Shape 1 13 has negative dimensions Node mfcc input Placeholder dtype DT FLOAT shape 13 device job worker replica 0 task 0 gpu 0 2017 08 24 19 38 31 251688 W tensorflow core framework op kernel cc 1148 Invalid argument Shape 1 13 has negative dimensions 2017 08 24 19 38 31 251734 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Invalid argument Shape 1 13 has negative dimensions Node mfcc input Placeholder dtype DT FLOAT shape 13 device job worker replica 0 task 0 gpu 0 2017 08 24 19 38 31 253478 W tensorflow core framework op kernel cc 1148 Invalid argument Shape 1 3 has negative dimensions 2017 08 24 19 38 31 253522 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Invalid argument Shape 1 3 has negative dimensions Node labels Placeholder dtype DT INT32 shape 3 device job worker replica 0 task 0 gpu 0 pre how ever if I run without the summary and checkpoint hook it just work fine I want to specify which timing and which directory to view my summary and save the checkpoint Does anyone have an idea how to solve this problem,,,2017-08-24 10:42:49,2017-08-25 23:01:57
PR,Branch 166528119,,,jhseu,2017-08-26 00:55:29,2017-08-26 02:52:37
IS,tensorflow installation error,I have installed tensorflow and keras I have used virtualenviroment given in tensorflow website It is showing the below error when I try to import keras with tensorflow as backend CPU COUNT psutil cpu count AttributeError 'module' object has no attribute 'cpu count' tensorflow version Version 1 3 0 keras Version 2 0 7 dask Version 0 15 0 pandas Version 0 20 3 For detailed error attaching the image untitled,,,2017-08-26 05:14:09,2017-08-26 07:15:29
PR,Eager API String Tensors and others that need to be copied Fix,This PR partially fixes the issue related to string tensors described in 12612 Note that there are still some issues remaining related to string tensors 1 There is a small inconsistency when dealing with TFE tensors now in that for the string data type a copy of the provided TF Tensor is created whereas for others types that is not the case This can be problematic when users of the API attempt to use the underlying tensor buffer directly e g to read values of specific elements The problem could potentially be alleviated if the same memory layout is used for string TF Tensor s and tensorflow Tensor s I'm not sure why that is not the case and I'm also not sure what the memory layout for string tensors is internally could someone provide some insight into that please 2 The above mentioned problem could be partially alleviated by providing a TFE function for obtaining a byte array representation of the i th element in the flattened row major tensor That is currently the only use I have found for directly accessing the underlying buffer 3 This fix resolves the issues specific to string tensors and the eager execution API but one issue related to 12612 still remains When I try to use some ops such as the Unpack op I get the following error no matter what the data type of the tensor is C libtensorflow so 0x20f0 TFE TensorHandleDeviceName 0x0 I plan to look more into this but please let me know if you can see a reason why this might be happening could you please give me some information on what the memory layout is for string tensors internally and on why we cannot use the same representation for the C API TF Tensor s That would resolve points 1 and 2 above I think that a function for obtaining the i th element would still be very useful though in either case,,"eaplatanios,eaplatanios,eaplatanios",2017-08-27 02:29:50,2017-08-27 03:55:25
IS,Error tensorflow python framework errors impl InternalError Unable to get element from the feed as bytes,I have met this error Traceback most recent call last File demo pb py line 25 in module result dict news demo newsAggreg image path File home rszj liutao news aggreg news demo pb py line 32 in newsAggreg predict news predict run images path File home rszj liutao news aggreg news predict pb py line 201 in run predict sess run pred feed dict x imgs is train False File home rszj anaconda2 lib python2 7 site packages tensorflow python client session py line 767 in run run metadata ptr File home rszj anaconda2 lib python2 7 site packages tensorflow python client session py line 965 in run feed dict string options run metadata File home rszj anaconda2 lib python2 7 site packages tensorflow python client session py line 1015 in do run target list options run metadata File home rszj anaconda2 lib python2 7 site packages tensorflow python client session py line 1035 in do call raise type e node def op message tensorflow python framework errors impl InternalError Unable to get element from the feed as bytes Background Firstly I have a simple cnn program and I build a model ckpt files Secondly I make be ckpt converting to pb Thridly I used ckpt model doing predict and pb model doing predict In simple cnn program ckpt and pb all do normal predict by using predict sess run pred feed dict x imgs is train False However when I using upper method to cnn rnn program I could have a normal predict result using ckpt model file but it had a tensorflow python framework errors impl InternalError Unable to get element from the feed as bytes problem using pb I can not solve this problem I need help Please Thanks,,,2017-08-25 10:03:43,2017-08-27 13:17:18
PR,Add Wno write strings to remove the warning in external protobuf compilation,This fix is an effort based on the discussion issuecomment 311420644 Currently a big chunk 200 of the warnings when compiling tensorflow are caused by Wwrite strings in external protobuf package As protobuf is external it makes sense to add the flag of Wno write strings to reduce the number of warnings in the output This fix reduces 200 warnings Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu",2017-08-25 20:27:46,2017-08-27 20:09:22
PR,extract common function for start abort rendezvous,,,"horance-liu,mrry,jhseu,jhseu,horance-liu,mrry",2017-08-22 12:19:33,2017-08-27 20:17:22
PR,Updated iOS build to handle threading correctly requires iOS 9 or later,There was a long standing issue with Apple is version of clang not supporting thread local attributes which are used inside Eigen in some places As a 'temporary' hack I defined these attributes out of existence but this lingered for a lot longer than it should have and I believe is the cause of issues like 12298 From comments there testing this fix it looks like it does help iOS 9 and later support thread local so as an improvement this change moves to that It will block building on older versions but now that v11 is almost out I think supporting two versions back should be ok for most developers though feedback is welcome if I'm wrong,,"petewarden,jhseu",2017-08-24 23:53:30,2017-08-27 20:19:32
PR,Better documentation for tf contrib layers optimize loss,tf contrib layers optimize loss references OPTIMIZER SUMMARIES in its docstring so we should expose that in the API Correct the documentation for what summaries optimize loss uses by default,,"alanhdu,alanhdu,jhseu,jhseu,jhseu,jhseu,alanhdu,jhseu",2017-08-18 16:18:47,2017-08-27 20:23:08
PR,Removing slightly confusing from output,I found the a bit confusing in the output of import pb to tensorboard py,,"daj,daj,daj",2017-08-27 19:36:40,2017-08-27 21:50:59
IS,tf gfile FastGFile can not read french path,tf gfile FastGFile r'F train Rubus pedatifolius Gen v 4000 jpg' 'rb' read failed but tf gfile FastGFile r'C Users d Desktop 4000 jpg' 'rb' read successed so is it a bug or tf gfile FastGFile can not read french path,,"yongtang,mrry,yongtang,mrry",2017-08-26 02:39:44,2017-08-28 02:02:54
IS,How to Retrain Final Layer for New Categories,Could there be another or newer classification algorithm for image classification like ResNet etc There are a lot of new neural nets with less classification error than Inception ImageNet results INCR,,,2017-08-02 19:14:55,2017-08-28 03:23:08
IS,Save seq2seq model error tensowflow 1 0 0,1 I had trained a seq2seq model with tensorflow 1 0 0 cpu version install pip install ignore installed upgrade 2 Save the model save path saver save session 'model model ckpt' 3 load the model new saver tf train import meta graph 'model model ckpt meta' when I load the model there is a error as follows File D python3 5 2 lib site packages tensorflow python training saver py line 1577 in import meta graph kwargs File D python3 5 2 lib site packages tensorflow python framework meta graph py line 498 in import scoped meta graphproducer op list producer op list File D python3 5 2 lib site packages tensorflow python framework importer py line 259 in import graph def raise ValueError 'No op named s in defined operations ' node op ValueError No op named attn mul fun f32f32 in defined operations what is the reason for the error I found the function attn mul fun from the file D python3 5 2 Lib site packages tensorflow contrib seq2seq python ops attention decoder fn py I do not know what is the connection between attn mul fun f32f32 and attn mul fun how to fix the error when loading the model,,gautam1858,2017-08-03 03:16:02,2017-08-28 03:24:43
IS,DNNClassifier estimator cannot be exported,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information tensorflow tensorflow latest container ubuntu linux installed from pip TensorFlow version 'v1 2 0 5 g435cdfc' '1 2 1' Python 2 7 Bazel version if compiling from source Exact command to reproduce The problem happens because DNNClassifier constructor creates a head with name None L365,,"facaiy,facaiy,facaiy,facaiy,facaiy",2017-08-23 01:02:07,2017-08-28 03:32:15
IS,Cannot learn initial states with batch sequences with states,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 3 0 0rc0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Using tf contrib training batch sequences with states it seems impossible to learn the initial states passed to it I have tried using Variables with trainable True with several initializers and while my optimizer picks them up through tf trainable variables their values do not get learned I assume this has something to do with TensorFlow continuing to work with the Tensors not the Variables Additionally the initializer is called each run and in TensorBoard it shows that it does not feed into the optimizer whereas network weights for example would Are my presumptions correct and if not how do I fix this If this is a TensorFlow limitation how could I work around it Source code logs,,rohan100jain,2017-08-07 18:32:48,2017-08-28 03:39:21
IS,iOS thread pools appear to spin forever even after session close,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No Built for iOS using provided scripts Defined ops to be included in build as documented using ops to register h OS Platform and Distribution e g Linux Ubuntu 16 04 Built on macOS 10 12 6 for distribution on iOS TensorFlow installed from source or binary source TensorFlow version use command below Unsure sorry my python environment is all messed up right now My HEAD is at 0d2f6918322c7bf29d1de3075b0d4ed3b1b72919 Python version 2 7 12 but I believe that is irrelevant for this issue Bazel version if compiling from source 0 5 1 homebrew but I'm using build all ios sh instead of Bazel to build CUDA cuDNN version Unknown GPU model and memory iPhone 7 Plus but AFAIK GPU is unavailable on iOS Exact command to reproduce No particular command Please see description of issue Also asked about this on Stack Overflow where it was suggested I file an issue Describe the problem I believe this is a bug in Tensorflow I am running Tensorflow on iOS using the C API I'm doing some image classification I have a long lived session and I call Run many times on it to evaluate different images from a backlog Once I'm done the RunQueue s via NonBlockingThreadPool s continue to pin the CPU at near max usage They appear to be stuck in the Steal loop presumably with no work to do Source code logs I tried Close ing and then delete ing the session and having read some of the C source this should have shut down the thread pools that belong to the session but this did not change the situation One thing to note while my understanding is that this is not necessary I did also try using a mutex to ensure that Close and delete would not be called concurrently with any call to Run but again no luck The only thing that has reduced CPU load to a reasonable level is to set inter op parallelism threads to 1 This does not resolve the underlying problem that the threads are never cleaned up but it does mean that the Steal loop is avoided so the thread just blocks forever,,"yaroslavvb,petewarden",2017-08-15 15:53:34,2017-08-28 03:48:22
IS,Feature Request Add an extra argument is duplicated to scatter sub Ops and make the kernel to multi thread for speedup,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TenorFlow installed from source or binary source TensorFlow version use command below v1 3 0 rc2 Python version 2 7 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 5 1 10 GPU model and memory nvidia M40 CPU 32 cores Describe the problem I profile the embedding lookup sparse on single machine with tfprof in which i put the params on cpu So the gather and scatter sub Op are also put on cpu Profiling result shows gather and scatter sub Op takes so much time the former takes about 33 the latter takes about 43 Making the gather op kernel to multi thread gain about 10x speedup relate to PR and 11709 Follow the same thought I want to make the scatter sub to be multi thread If there is no duplicate index we can realize lock free code which could gain about 10x speedup too If there are duplicate indices use lock which can gain little speedup So I think an extra argument is duplicated is a good choice to divide the two situation Here is some profiling result tfprof Code embedding lookup sparse,,"nolanliou,reedwm,alextp,nolanliou,nolanliou",2017-08-17 11:20:09,2017-08-28 03:50:54
IS,tf train batch does not preserve the order of data and miss some data,I use tf train batch to produce data in tensorflow but get unexpected data order as following the label produced by tf train batch 6 03125 5 2734375 4 03125 5 84375 5 15625 A total of 33 labels the label of original data 6 03125 5 2734375 4 546875 4 03125 6 1875 5 8438 A total of 68 labels It seems that the generated data differs from the original data in the order and is less Why,,mrry,2017-08-18 03:35:05,2017-08-28 03:53:42
IS,Error with tf losses sparse softmax cross entropy weights,I use the function tf losses sparse softmax cross entropy for my unbalanced dataset but i get error when using it My question is if my labels in one batch have shape 8 4096 my prediction or logits have shape 8 4096 14 and I have 14 classes What should the shape of my weights Another question should i have one specific weight for each class or a specific weight for each sample Thanks,,,2017-08-25 07:31:59,2017-08-28 03:55:18
IS,Cannot build TF 1 3 1 2 for iOS,I have built TF 1 1 before without problems as follows git clone branch r1 1 makefile dir build all ios sh If I change the branch to r1 3 it stops with a segmentation fault Also seems to happen with r1 2 System MacOS Sierra 10 12 6 16G29 It also seems to fail with other error messages in different compile runs on different files of course like clang error unable to execute command Illegal instruction 4 or malloc free errors,,,2017-08-25 09:49:24,2017-08-28 03:55:49
IS,Simple release note typo,Simple typo on 1 3 0 release note 2017 08 24 14 57 12,,,2017-08-24 06:00:48,2017-08-28 03:59:09
IS,Is there any method to dump the IR and machine code of XLA compiler,Is there any method to dump the IR of tensorflow xla from the compilers front end to the backend as detailed as better Such as the HLO IR to LLO IR and the machine code generated by xla backend I wonder the details of TensorFlow XLA compiler the official website is not detailed,,learyg,2017-08-23 16:07:40,2017-08-28 04:00:42
IS,Cannot open in Safari,As subject says always error msg saying Safari cannot open the page because it cannot open make the secure connection with the server Has anybody encountered the problem and can you share your experience how to fix Opening the website from Firefox is OK System Mac 10 12 6,,,2017-08-22 16:33:34,2017-08-28 04:06:42
IS,Feature request manual parallel,when I run my code in that way for i in range num with tf control dependencies None output i tf identity deepnn x TF will run the deepnn x one by one Would it be possible to parallel it manually like this pragma omp for,,,2017-08-22 13:15:03,2017-08-28 04:11:13
IS,Why my tensorflow gpu runs only on cpu Ubuntu,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from pip3 install tensorflow gpu TensorFlow version 'v1 1 0 rc0 61 g1ec6ed5' '1 1 0' Python version Python 3 5 2 CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 61 My tensorflow gpu runs only on cpu how to fix it I have already tried to set CUDA DEVICE VISIBLE all my gpus But it did not work Then I tried to use this code sess tf Session config tf ConfigProto log device placement True The output is following Device mapping no known devices 2017 08 18 16 44 44 654177 I tensorflow core common runtime direct session cc 300 Device mapping Then nothing It does not output the map I have also tried to install it with virtualenv and run the program in virtualenv or reinstall still not working Why is this happening How can I fix it,,,2017-08-18 09:03:07,2017-08-28 04:15:34
IS,OpenMP OpenACC support for tensorflow,Is there any effort in porting the Tensorflow using OpenMP or OpenACC,,yaroslavvb,2017-08-20 20:04:07,2017-08-28 04:18:57
IS,How to Retrain Inception v3 without a reshape layer,Hi all I was trying the pretrained Inception v3 model available in tensorflow When i was looking into the tensorgraph of the retrained model i found that while retrianing it uses a reshape layer followed by a full connected layer Is there any method to retrain the model without using the reshape layer Please suggest me any possible solution if possible Thank and Regards,,,2017-08-21 05:38:46,2017-08-28 04:20:42
IS,TF 1 3 Install error,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow version use command below 1 3 0 Python version 3 6 Describe the problem Error when installing with pip pip3 install tensorflow gpu This error appears,,"carlthome,carlthome",2017-08-21 19:14:35,2017-08-28 04:24:44
IS,Undefined symbol 'fixed address empty string' new tensorflow op with protobuf,I would like to create a new operation that can communicate to an external python process At the momemnt I created a new operation that sends to a python process hello world with protobuf In this tiny example I'm sending a string In the future I would like to send more complex data like Eigen matrices that is why I chose protobuf and for possible 'easy integration into tensorflow msg proto,,,2017-08-23 18:12:33,2017-08-28 04:27:17
IS,Tensorflow internally creates operators,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I made custom distributed inception code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Unmodified source with RDMA Verbs enabled TensorFlow version use command below 1 3 0 rc1 Python version 2 7 12 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 5 1 5 GPU model and memory NVIDIA TITAN Xp PCIe 12GB 4 per node I tried to run distributed inception and I removed some nodes by breaking control dependencies in the graph However tensorflow creates operators such as inception v3 mixed 17x17x1280a branch7x7x3 Conv 2 BatchNorm AssignMovingAvg 1 S21149 internally and called it Why this kind of operators are created and is there any way to prevent it,,,2017-08-25 10:03:46,2017-08-28 04:27:45
IS,NaNs during training with tf contrib rnn LayerNormBasicLSTMCell,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 Python version 3 5 CUDA cuDNN version CUDA 8 0 and CuDNN 6 although I can replicate without a GPU GPU model and memory Nvidia K80 from Amazon P2 instance Exact command to reproduce Describe the problem When training a model using tf contrib rnn LayerNormBasicLSTMCell sometimes my weights go to nan even though the training data looks perfectly innocent I have not seen this with Tensorflow 1 2 1 which leads me to suspect that there is been a regression somewhere but I could have just been luckier with TF 1 2 nevermind I have reproduced this with TF 1 2 1 Source code logs I have created two examples of this in clone the repo enter a folder and run test py or build and run the Dockerfile The key line s there are The first print statement prints all True s which is good but after the training step suddenly some of the weights have nan s in them and hence there is one False in the second print statement,,"alanhdu,alanhdu,alanhdu",2017-08-23 04:48:54,2017-08-28 04:41:19
IS,core dump when running tensorflow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 5 2 Bazel version if compiling from source CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 1070 8GB gpu memory Exact command to reproduce Describe the problem python lstm ocr py when I run it core dumps I use gdb and got this message gdb file python Reading symbols from python no debugging symbols found done gdb run lstm ocr py Starting program home lili tf1 2 1 py3 bin python lstm ocr py Thread debugging using libthread db enabled Using host libthread db library lib x86 64 linux gnu libthread db so 1 New Thread 0x7ffff3a36700 LWP 350 New Thread 0x7ffff3235700 LWP 351 New Thread 0x7ffff0a34700 LWP 352 New Thread 0x7fffee233700 LWP 353 New Thread 0x7fffe9a32700 LWP 354 New Thread 0x7fffe9231700 LWP 355 New Thread 0x7fffe6a30700 LWP 356 Thread 0x7ffff3235700 LWP 351 exited Thread 0x7fffe6a30700 LWP 356 exited Thread 0x7fffe9231700 LWP 355 exited Thread 0x7fffe9a32700 LWP 354 exited Thread 0x7fffee233700 LWP 353 exited Thread 0x7ffff0a34700 LWP 352 exited Thread 0x7ffff3a36700 LWP 350 exited New Thread 0x7fffe6a30700 LWP 364 New Thread 0x7fffe9231700 LWP 365 New Thread 0x7fffe9a32700 LWP 366 New Thread 0x7fffee233700 LWP 367 New Thread 0x7fffa1d72700 LWP 368 New Thread 0x7fffa1571700 LWP 369 New Thread 0x7fffa0d70700 LWP 371 New Thread 0x7fff9bfff700 LWP 372 loading train data please wait get image 128000 loading validation data please wait get image 500 2017 08 23 15 42 02 794111 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 08 23 15 42 02 794131 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 08 23 15 42 02 794135 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 08 23 15 42 02 794161 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 08 23 15 42 02 794166 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations New Thread 0x7fffaa462700 LWP 374 New Thread 0x7fffa9c61700 LWP 375 New Thread 0x7fffa9460700 LWP 376 New Thread 0x7fff9a13e700 LWP 377 New Thread 0x7fff9993d700 LWP 378 New Thread 0x7fff9913c700 LWP 379 New Thread 0x7fff9893b700 LWP 380 New Thread 0x7fff7ffff700 LWP 381 Thread 1 python received signal SIGSEGV Segmentation fault GI pthread mutex lock mutex 0x3028 at nptl pthread mutex lock c 67 67 nptl pthread mutex lock c no such file or directory Source code logs,,,2017-08-23 07:42:54,2017-08-28 04:42:47
IS,tf image resize images differs from PIL scipy misc imresize,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 Linux localhost localdomain 3 10 0 514 el7 x86 64 1 SMP Tue Nov 22 16 42 41 UTC 2016 x86 64 x86 64 x86 64 GNU Linux VERSION 7 Core VERSION ID 7 CENTOS MANTISBT PROJECT VERSION 7 REDHAT SUPPORT PRODUCT VERSION 7 TensorFlow installed from source or binary Source TensorFlow version use command below tf VERSION 1 2 1 tf GIT VERSION v1 2 1 0 gb4957ff tf COMPILER VERSION v1 2 1 0 gb4957ff Sanity check array 1 dtype int32 Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version CUDA8 0 CUDNN6 0 GPU model and memory GeForce GTX 1080 8113MiB Exact command to reproduce See Source code Describe the problem As the title states tf image resize images returns different values compared to imresize in scipy or PIL This is important because we expect the same behaviour for migrating code originally written using scipy misc imresize or PIL Source code logs,,ppwwyyxx,2017-08-27 18:24:58,2017-08-28 04:47:13
IS,Node pool 3 AvgPoolT DT FLOAT data format NHWC ksize 1 8 8 1 padding VALID strides 1 1 1 1 device job localhost replica 0 task 0 cpu 0,iOS App I have changes All the file name and Size but still getting below error Source Code URL Changes Code const int wanted input width 229 const int wanted input height 229 const int wanted input channels 3 const float input mean 128 0f const float input std 128 0f const std string input layer name Mul const std string output layer name final result computed output size would be negative Node pool 3 AvgPoolT DT FLOAT data format NHWC ksize 1 8 8 1 padding VALID strides 1 1 1 1 device job localhost replica 0 task 0 cpu 0 Please suggest what we are doing wrong In build pb and txt are working fine imagenet comp graph label strings txt tensorflow inception graph pb but created new pb and txt is not working rounded graph pb and retrained labels txt Note I also rename the pb and txt file,,,2017-08-24 10:28:16,2017-08-28 07:04:55
IS,tf layers conv2d does not accept higher dimension tensor,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 x64 TensorFlow installed from source or binary pip install TensorFlow version use command below r1 3 Python version 3 5 amd 64 Bazel version if compiling from source Used binary CUDA cuDNN version CUDA 8 0 CuDNN 6 0 GPU model and memory GeForce GTX 1070 8 00GiB I am trying to feed a I think it is OK to feed layer with high dimension as long as last three dimension is image If it is impossible to add this feature may I try to merge first two dimensions together and feed it to conv2d layer Then separate it to origin form but maintain the order How to do it,,,2017-08-27 04:21:56,2017-08-28 17:18:27
IS,Is there any class similar to tf contrib learn monitors ValidationMonitor in TF Slim for evalution in logging,I want to evaluate my model using validation data when training and show the evalution result in logging which is similar to tf contrib learn monitors ValidationMonitor and i can customize my metrics to evaluate Is there any one in TF Slim,,,2017-08-28 04:05:04,2017-08-28 17:18:48
IS,Android Demo SpeechActivity Fatal Exception,Samsung Galaxy J1 Android ver 5 1 1 08 26 11 56 55 226 I TensorFlowInferenceInterface 14094 Model load took 41ms TensorFlow version 1 3 0 08 26 11 56 55 226 I TensorFlowInferenceInterface 14094 Successfully loaded model from 'file' 08 26 11 56 55 231 D AndroidRuntime 14094 Shutting down VM 08 26 11 56 55 231 E AndroidRuntime 14094 FATAL EXCEPTION main 08 26 11 56 55 231 E AndroidRuntime 14094 Process org tensorflow demo PID 14094 08 26 11 56 55 231 E AndroidRuntime 14094 java lang NoSuchMethodError No virtual method requestPermissions Ljava lang String I V in class Lorg tensorflow demo SpeechActivity or its super classes declaration of 'org tensorflow demo SpeechActivity' appears in data app org tensorflow demo 1 base apk 08 26 11 56 55 231 E AndroidRuntime 14094 at org tensorflow demo SpeechActivity requestMicrophonePermission SpeechActivity java 158 08 26 11 56 55 231 E AndroidRuntime 14094 at org tensorflow demo SpeechActivity onCreate SpeechActivity java 153 08 26 11 56 55 231 E AndroidRuntime 14094 at android app Activity performCreate Activity java 6609 08 26 11 56 55 231 E AndroidRuntime 14094 at android app Instrumentation callActivityOnCreate Instrumentation java 1134 08 26 11 56 55 231 E AndroidRuntime 14094 at android app ActivityThread performLaunchActivity ActivityThread java 3086 08 26 11 56 55 231 E AndroidRuntime 14094 at android app ActivityThread handleLaunchActivity ActivityThread java 3243 08 26 11 56 55 231 E AndroidRuntime 14094 at android app ActivityThread access 1000 ActivityThread java 218 08 26 11 56 55 231 E AndroidRuntime 14094 at android app ActivityThread H handleMessage ActivityThread java 1718 08 26 11 56 55 231 E AndroidRuntime 14094 at android os Handler dispatchMessage Handler java 102 08 26 11 56 55 231 E AndroidRuntime 14094 at android os Looper loop Looper java 145 08 26 11 56 55 231 E AndroidRuntime 14094 at android app ActivityThread main ActivityThread java 6917 08 26 11 56 55 231 E AndroidRuntime 14094 at java lang reflect Method invoke Native Method 08 26 11 56 55 231 E AndroidRuntime 14094 at java lang reflect Method invoke Method java 372 08 26 11 56 55 231 E AndroidRuntime 14094 at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 1404 08 26 11 56 55 231 E AndroidRuntime 14094 at com android internal os ZygoteInit main ZygoteInit java 1199,,petewarden,2017-08-26 11:11:12,2017-08-28 17:24:12
IS,Check failed stream parent GetConvolveAlgorithms algorithms,INFO tensorflow Creating bottleneck at tmp bottleneck dandelion 10043234166 e6dd915111 n jpg inception v3 txt 2017 08 22 12 36 45 710892 W c tf jenkins home workspace release win m windows gpu py 35 tensorflow core framework op def util cc 332 Op BatchNormWithGlobalNormalization is deprecated It will cease to work in GraphDef version 9 Use tf nn batch normalization 2017 08 22 12 36 46 351813 E c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda dnn cc 359 could not create cudnn handle CUDNN STATUS NOT INITIALIZED 2017 08 22 12 36 46 351943 E c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda dnn cc 366 error retrieving driver version Unimplemented kernel reported driver version not implemented on Windows 2017 08 22 12 36 46 354865 E c tf jenkins home workspace release win m windows gpu py 35 tensorflow stream executor cuda cuda dnn cc 326 could not destroy cudnn handle CUDNN STATUS BAD PARAM 2017 08 22 12 36 46 356828 F c tf jenkins home workspace release win m windows gpu py 35 tensorflow core kernels conv ops cc 671 Check failed stream parent GetConvolveAlgorithms algorithms,,,2017-08-22 07:08:52,2017-08-28 17:28:07
PR,Implement L2Loss gradient,This branch implements L2LossGrad the gradient for L2Loss It is a port of the python implementation L752 This is my first PR to TensorFlow When giving feedback please assume that I barely know what I'm doing Side question I plan to do a few more gradients Is it ok if I batch a few simple ones like this one into a single PR,,"bpiel,bpiel,jhseu,jhseu,jhseu,jhseu,yifeif,jhseu,jhseu,bpiel,yifeif,bpiel,gunan,bpiel,bpiel,jhseu,bpiel,gunan,bpiel,gunan,bpiel",2017-08-18 12:19:49,2017-08-28 17:44:32
IS,Variable in Dataset map function is not stably initialized,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 macos TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source 0 5 3 homebrew CUDA cuDNN version NO GPU model and memory Exact command to reproduce Describe the problem unable to init variable in map flatmap fillter function of Dataset API Source code logs,,mrry,2017-08-28 10:14:12,2017-08-28 17:44:53
PR,Simplify task name condition checks at android example build gradle,PS Looks like task name 'assembleDebug' task name 'assembleRelease' is always true and can be omitted Leave it just in case I do not fully understand logic behind that check,,ArtsiomCh,2017-08-15 18:59:05,2017-08-28 20:35:46
PR,Adding a decode to support Python 3 5 on Windows,Fix this error python 3 5 TypeError a bytes like object is required not istr',,"av8ramit,gunan",2017-08-28 22:39:02,2017-08-28 23:06:07
PR,Add a timeout for tests in cmake,,,"gunan,gunan,mrry",2017-08-28 18:11:40,2017-08-29 00:40:34
IS,docs Windows Instructions need updating,Any way to contribute to the installation instructions for Windows I deal with a lot of people having installation instructions on Stack Overflow etc and there are a couple of things on the Install pages that could do with being corrected clarified or changed Happy to do these myself if you would like I will list them below TensorFlow only supports version 3 5 x of Python on Windows is no longer true since 1 2 as 3 6 is supported The r1 3 version of the install page introduces this new line TensorFlow will not load if it cannot find cuDNN64 5 dll To use a different version of cuDNN you must build from source however I thought that 1 3 was built with cuDNN 6 Users may find this conflict confusing because as I found with 11645 1 3 0 will NOT load with cuDNN64 5 dll Should not this change to cuDNN64 6 dll Anaconda Installation slightly misleading I use anaconda to run our tensorflow environments without a problem I download via pip install tensorflow gpu instead of the unsupported conda version and from a user is point of view there is no reason for it be unsupported is there a reason that a pypi installation put in an anaconda environment would act differently enough to virtual env root install to be unsupported I also do not see why the installation page can not recommend downloading straight from pypi instead of using the long storage googleapis url Especially as 3 6 is now supported Happy to implement these changes if I knew where Are the markdown files in docs src linked to the website If so i will pop a PR into there Cheers,,"aselle,gunan,mrry,gunan,gunan,gunan,tfboyd,gunan,av8ramit,snnn",2017-07-26 13:46:11,2017-08-29 08:31:24
IS,Java load python trained mode by SavedModelBundle predict wrong result,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 1 2 1 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I trained a simple model using python and save it with SavedModelBuilder Then I loaded it using java it is loaded successfully but predict wrong result Source code logs My python code is in and java code,,asimshankar,2017-08-29 05:28:14,2017-08-29 09:18:52
IS,Bundling tensorflow app to desktop,I have got a tensorflow based app which recognizes the objects state I use opencv and tensorflow to get this done The final application has to be a desktop app How do I bundle all dependencies and export it for desktop,,asimshankar,2017-08-29 05:06:48,2017-08-29 09:24:29
PR,c gradients for mean and sum,Gradients for the math ops Mean and Sum Ported from python L95 I grouped these together because they share helper functions cc,,"bpiel,suharshs,bpiel",2017-08-29 00:16:00,2017-08-29 16:35:56
IS,top k does not order lower index first if two elements are equals,Bug If two elements are equal,,"ebrevdo,rmlarsen",2017-08-03 14:18:13,2017-08-29 16:57:46
PR,Updating docs to show support for Python 3 6 in Windows,,,av8ramit,2017-08-29 16:51:08,2017-08-29 17:01:08
PR,Fix TensorFlow Windows build,1 fix configure py on Windows 2 Update nsync to make it work on Windows 3 disabled some failing tests,,"meteorcloudy,meteorcloudy,yifeif,meteorcloudy,meteorcloudy,snnn",2017-08-25 18:03:08,2017-08-29 17:05:06
PR,Fixed code formatting,,,,2017-08-29 09:25:57,2017-08-29 17:30:31
PR,Make Graph long Constructor Public,It would be very useful when user wants to do custom model loading in C C via JNI then return the handle to Java and use this constructor to wrap maintain the graph object Changed Graph long from Graph long To public Graph long,,"resec,asimshankar,resec,asimshankar,resec",2017-08-29 02:55:47,2017-08-29 17:46:27
IS,Error in tf contrib layers batch norm when explicitly assigned on gpu,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 3 4 3 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory Tesla P100 16 gb Describe the problem Batch norm layer fails with an error when explicitly assigned to be run on gpu and zero debias moving mean is False Interesting that I'm getting this error only when is training is a placeholder passing just True does not reproduce the error If commented line is used instead zero debias moving mean True the code also works without any error Source code logs The following code could be used to reproduce the issue,,"aselle,zhangyaobit,vrv,taehoonlee,zhangyaobit",2017-07-21 22:31:12,2017-08-29 17:47:24
PR,Update rules closure to 0 4 2,This change is required for compatibility with Bazel 0 6,,gunan,2017-08-29 14:03:40,2017-08-29 18:24:11
IS,Install instructions should ask for libcudnn 6 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 04 TensorFlow installed from source or binary binary pip3 TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 3 Bazel version if compiling from source CUDA cuDNN version 6 0 GPU model and memory GTX 1080 8GB Exact command to reproduce NA Describe the problem The install instructions at tell users to install libcudnn 5 1 I followed these and ended up with the error on import tensorflow ImportError libcudnn so 6 cannot open shared object file No such file or directory So I installed libcudnn 6 0 instead and tensorflow is now working My request is for the install instructions to be updated to reflect the move to cudnn 6 0 Source code logs NA,,yongtang,2017-08-23 09:28:54,2017-08-29 18:24:15
IS,building tensorflow from source general issue,Dear Tensorflow team I was facing a problem described here In short words In the documentation there is no any single word about bazel version need for specific version of Tensorflow In particular I could not build a Python package with the newest version of Bazel Experimentally I found out that that the master version r1 3 can be built successfully with Bazel not newer than 0 5 1 with very old versions it also does not work So I am kindly asking to mention a Bazel version as well as other dependencies such as gcc etc to have successful build for the next releases I spent a lot of time to find a solution Probably it will be useful experience for others Cheers Sergey,,"martinwicke,gunan,yifeif,martinwicke,yifeif,martinwicke",2017-08-28 08:51:02,2017-08-29 19:16:40
IS,keras resnet50 example yields different predictions than in stand alone keras,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No using example from Keras documentation here classify imagenet classes with resnet50 OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 6 TensorFlow installed from source or binary Binary CPU Version TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 OS X system version Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Also note that you need the 'elephant jpg' file in the working directory to reproduce You can find that file here,,"aselle,fchollet,taehoonlee,taehoonlee,fchollet",2017-07-29 11:54:27,2017-08-29 20:26:17
IS,Speech Commands Example URL broken,Found here speech commands example is broken,,yongtang,2017-08-29 23:06:16,2017-08-30 02:01:34
IS,Issue loading label file on Android example,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Android 8 0 TensorFlow installed from source or binary Android Binary TensorFlow version use command below Python version NA Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA Whenever I try to build and launch the TF Classify demo app provided the app crashes with the following error 08 29 21 03 01 791 9614 9614 org tensorflow demo E AndroidRuntime FATAL EXCEPTION main Process org tensorflow demo PID 9614 java lang RuntimeException Problem reading label file at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 100 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 107 at org tensorflow demo CameraActivity 2 onPreviewSizeChosen CameraActivity java 324 at org tensorflow demo CameraConnectionFragment setUpCameraOutputs CameraConnectionFragment java 407 at org tensorflow demo CameraConnectionFragment openCamera CameraConnectionFragment java 414 at org tensorflow demo CameraConnectionFragment access 000 CameraConnectionFragment java 64 at org tensorflow demo CameraConnectionFragment 1 onSurfaceTextureAvailable CameraConnectionFragment java 95 at android view TextureView getHardwareLayer TextureView java 390 at android view TextureView draw TextureView java 339 at android view View updateDisplayListIfDirty View java 18069 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View draw View java 19122 at android view View updateDisplayListIfDirty View java 18069 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View draw View java 19122 at com android internal policy DecorView draw DecorView java 785 at android view View updateDisplayListIfDirty View java 18069 at android view ThreadedRenderer updateViewTreeDisplayList ThreadedRenderer java 643 at android view ThreadedRenderer updateRootDisplayList ThreadedRenderer java 649 at android view ThreadedRenderer draw ThreadedRenderer java 757 at android view ViewRootImpl draw ViewRootImpl java 2980 at android view ViewRootImpl performDraw ViewRootImpl java 2794 at android view ViewRootImpl performTraversals ViewRootImpl java 2347 at android view ViewRootImpl doTraversal ViewRootImpl java 1386 at android view ViewRootImpl TraversalRunnable run ViewRootImpl java 6733 at android view Choreographer CallbackRecord run Choreographer java 911 at android view Choreographer doCallbacks Choreographer java 723 at android view Choreographer doFrame Choreographer java 658 at android view Choreographer FrameDisplayEventReceiver run Choreographer java 897 at android os Handler handleCallback Handler java 789 at android os Handler dispatchMessage Handler java 98 at android os Looper loop Looper java 164 at android app ActivityThread main ActivityThread java 6541 at java lang reflect Method invoke Native Method at com android internal os Zygote MethodAndArgsCaller run Zygote java 240 at com android internal os ZygoteInit main ZygoteInit java 767 Caused by java io FileNotFoundException imagenet comp graph label strings txt at android content res AssetManager openAsset Native Method at android content res AssetManager open AssetManager java 374 at android content res AssetManager open AssetManager java 348 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 93 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 107 at org tensorflow demo CameraActivity 2 onPreviewSizeChosen CameraActivity java 324 at org tensorflow demo CameraConnectionFragment setUpCameraOutputs CameraConnectionFragment java 407 at org tensorflow demo CameraConnectionFragment openCamera CameraConnectionFragment java 414 at org tensorflow demo CameraConnectionFragment access 000 CameraConnectionFragment java 64 at org tensorflow demo CameraConnectionFragment 1 onSurfaceTextureAvailable CameraConnectionFragment java 95 at android view TextureView getHardwareLayer TextureView java 390 at android view TextureView draw TextureView java 339 at android view View updateDisplayListIfDirty View java 18069 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View draw View java 19122 at android view View updateDisplayListIfDirty View java 18069 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View updateDisplayListIfDirty View java 18060 at android view View draw View java 18847 at android view ViewGroup drawChild ViewGroup java 4214 at android view ViewGroup dispatchDraw ViewGroup java 4000 at android view View draw View java 19122 at com android internal policy DecorView draw DecorView java 785 at android view View updateDisplayListIfDirty View java 18069 at android view ThreadedRenderer updateViewTreeDisplayList ThreadedRenderer java 643 at android view ThreadedRenderer updateRootDisplayList ThreadedRenderer java 649 at android view ThreadedRenderer draw ThreadedRenderer java 757 at android view ViewRootImpl draw ViewRootImpl java 2980 at android view ViewRootImpl performDraw ViewRootImpl java 2794 at android view ViewRootImpl performTraversals ViewRootImpl java 2347 at android view ViewRootImpl doTraversal ViewRootImpl java 1386 at android view ViewRootImpl TraversalRunnable run ViewRootImpl java 6733 at android view Choreographer CallbackRecord run Choreographer java 911 at android view Choreographer doCallbacks Choreographer java 723 at android view Choreographer doFrame Choreographer java 658 at android view Choreographer FrameDisplayEventReceiver run Choreographer java 897 at android os Handler handleCallback Handler java 789 at android os Handler dispatchMessage Handler java 98 at android os Looper loop Looper java 164 at android app ActivityThread main ActivityThread java 6541 at java lang reflect Method invoke Native Method at com android internal os Zygote MethodAndArgsCaller run Zygote java 240 at com android internal os ZygoteInit main ZygoteInit java 767 The app has storage permissions enabled and was built on windows from the makefile not Bazel,,,2017-08-30 02:07:49,2017-08-30 02:37:48
PR,Merge pull request r1 3 from tensorflow master,Update from origin to r1 3,,,2017-08-30 09:19:44,2017-08-30 09:31:21
IS,multi GPU training too slow when L2 regularizer enabled,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 home edition TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 5 3 Bazel version if compiling from source CUDA cuDNN version Cuda 8 0 cudnn 6 0 GPU model and memory Nvidia 1080 GTX 8GB x 2 Exact command to reproduce Describe the problem I try to train a face recognition classifier using inception resnet v1 model with 2 GPUs On single GPU the training proceeds just fine with a processing capacity around 220 images sec but when I train with 2 GPUs I only observe marginal benefit capacity increases to around 280 images sec After some profiling I found out that the poor performance was somehow due to the introduced L2 regularizer When the regularizer is enabled the computation of the gradient becomes unexpectedly slow resulting in the slowdown of the entire training cycle As a comparison if the regularizer is disabled I could obtain a processing capacity around 350 images sec which although not perfect is more or less satisfactory The boost in the performance in the latter scenario cannot be attributed to the reduced computation complexity from the removal of the regularizer This is evidenced by a reference experiment with exactly the same parameter except for on a single GPU see below I cannot figure out an explanation for this It took me several days to narrow down the problem to seemingly the introduction of L2 regularizer and the computation of gradient In my program I used standard tf slim layers together with a downloaded inception resnet v1 model script The main part of the code is the following,,,2017-08-29 18:11:41,2017-08-30 13:11:03
IS,DNN Classifier producing Blue Screen of Death every time,Hi When running inputs 9 10 and 11 from the below notebook I get a blue screen of death every time I'm using Python ver 3 5 3 Tensorflow 1 2 1 Running on a windows 7 pro machine Any tips on how to resolve this,,"mrry,mrry",2017-08-28 19:39:32,2017-08-30 14:42:51
IS,Input function tutorial does not deliver reported performance,Running the example explained here results in a reported loss 100 times bigger than what is reported in the tutotrial It also does not converge and it seems to be going up and down The expected performance is Environment cat etc issue Linux adrin leni ancud de 4 12 7 1 ARCH 1 SMP PREEMPT Sun Aug 13 08 17 09 CEST 2017 x86 64 GNU Linux are we in docker No compiler c GCC 7 2 0 Copyright C 2017 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux adrin leni ancud de 4 12 7 1 ARCH 1 SMP PREEMPT Sun Aug 13 08 17 09 CEST 2017 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv True tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs,,jart,2017-08-30 14:41:28,2017-08-30 19:53:40
IS,ERROR tensorflow Only one valid folder of images found at tf files2 images multiple classes are needed for classification,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,jart,2017-08-30 12:23:10,2017-08-30 19:59:32
IS,During handling of the above exception Another exception occured,qq 20170829141338 qq 20170829141241 Does anyone know what is the cause of this My system environment Ubuntu 16 04 X86 64 nvidia dirver version v384 66 nvcc version v8 0 cuDNN 6 0 I dont know why Thank you before,,jart,2017-08-30 01:52:55,2017-08-30 20:02:26
IS,Bundling tensorflow app to desktop,I have got a tensorflow based app which recognizes the objects state I use opencv and tensorflow to get this done The final application has to be a desktop app How do I bundle all dependencies and export it for desktop PS I have asked the same question in stackoverflow with no response for my question hence Im asking this here hoping for a positive reply,,"snnn,snnn,jart",2017-08-30 01:51:28,2017-08-30 20:04:20
IS,object detection eval,When evaluating the model tensorboard values is NaN why,,jart,2017-08-29 09:28:46,2017-08-30 20:42:44
PR,Update CUB version in the cmake build,,,"gunan,gunan",2017-08-30 20:43:35,2017-08-30 21:09:06
PR,Update README md,Edit the tutorial URL,,jhseu,2017-08-27 19:30:11,2017-08-30 21:11:06
PR,R1 3,,,,2017-08-28 05:56:41,2017-08-30 21:11:12
IS,tensorflow1 3 bazel bin tensorflow examples label image label image failed to run,step 1 python tensorflow examples image retraining retrain py architecture inception v3 output graph inception v3 pb step2 bazel build tensorflow examples label image step3 bazel bin tensorflow examples label image label image then get the following error tensorflow examples label image main cc 349 Running model failed Not found FeedInputs unable to find feed output input Any step wrong Could you give me some hint,,jart,2017-08-28 09:39:59,2017-08-30 21:15:51
IS,batch normalization,These days i have meet some problem about BN layers code is here i want run my net on mnist dataset it worked when i am training how when i verify on valiation data or test date when i change the state 'is training' what is wrong when i am verifing and how can i save mean and val in training state import tensorflow as tf from tensorflow examples tutorials mnist import input data mnist input data read data sets MNIST data one hot True define some weights def weight variable shape initial tf truncated normal shape stddev 0 01 return tf Variable initial def bias variable shape initial tf constant 0 01 shape shape return tf Variable initial def conv2d input in features out features kernel size with bias False W weight variable kernel size kernel size in features out features conv tf nn conv2d input W 1 1 1 1 padding 'SAME' if with bias return conv bias variable out features return conv def batch activ conv current in features out features kernel size is training keep prob current tf contrib layers batch norm current scale True is training is training updates collections None current tf nn relu current current conv2d current in features out features kernel size current tf nn dropout current keep prob return current def block input layers in features growth is training keep prob current input features in features for idx in xrange layers tmp batch activ conv current features growth 3 is training keep prob current tf concat current tmp 3 features growth return current features def avg pool input s return tf nn avg pool input 1 s s 1 1 s s 1 'VALID' define graph layers 12 print 'create graph ' x tf placeholder tf float32 None 784 y label tf placeholder tf float32 None 10 lr tf placeholder tf float32 keep prob tf placeholder tf float32 is training tf placeholder tf bool shape current tf reshape x 1 28 28 1 current conv2d current 1 16 3 current features block current layers 16 12 is training keep prob current batch activ conv current features features 1 is training keep prob current avg pool current 2 14x14 current features block current layers features 12 is training keep prob current batch activ conv current features features 1 is training keep prob current avg pool current 2 7x7 current features block current layers features 12 is training keep prob current tf contrib layers batch norm current scale True is training is training updates collections None current tf nn relu current current avg pool current 7 final dim features current tf reshape current 1 final dim Wfc weight variable final dim 10 set classifiers bfc bias variable 10 y predict tf nn softmax tf matmul current Wfc bfc cross entropy tf reduce mean tf nn softmax cross entropy with logits labels y label logits y predict l2 tf add n tf nn l2 loss var for var in tf trainable variables weight decay 1e 4 update moving mean and moving variance update ops tf get collection tf GraphKeys UPDATE OPS with tf control dependencies update ops train step tf train GradientDescentOptimizer lr minimize cross entropy l2 weight decay correct prediction tf equal tf argmax y predict 1 tf argmax y label 1 accuracy tf reduce mean tf cast correct prediction tf float32 caculate the right numbers def mytrain print 'train ' saver tf train Saver with tf Session as sess sess run tf global variables initializer for epoch in xrange 1 10 train if epoch 150 l 0 5 elif epoch 200 l 0 1 else l 0 01 print 'epoch ' epoch batch x batch y mnist train next batch 500 acc loss sess run train step accuracy cross entropy feed dict x batch x y label batch y lr l is training True keep prob 0 8 print 'train acc ' acc loss loss val batch x val mnist validation images batch y val mnist validation labels acc loss sess run accuracy cross entropy feed dict x batch x val y label batch y val is training False keep prob 0 8 print 'val acc ' acc ' loss ' loss saver save sess 'temp densenet ckpt' def mytest print 'test ' saver tf train Saver with tf Session as sess saver restore sess ' temp densenet ckpt' x val mnist validation images y val mnist validation labels val results sess run accuracy feed dict x x val y label y val is training True keep prob 1 print 'val acc ' val results right 0 for i in range 100 x test y test mnist validation next batch 500 test results sess run accuracy feed dict x x test y label y test is training False keep prob 1 right right test results print 'test acc ' test results if name ' main ' mytrain mytest,,jart,2017-08-26 11:38:36,2017-08-30 21:46:39
PR,Branch 167045325,,,"gunan,gunan,martinwicke",2017-08-30 21:09:48,2017-08-31 02:56:04
IS,Slim learning train support tf debug,tfdbg is a great tool for debugging TensorFlow programs But if I use slim for training like in TensorFlow object detection API it seems not support to use tf dbg and brings inconvenience,,"caisq,sguada",2017-08-18 05:00:36,2017-08-31 02:56:39
IS,sharing variables but matrices are transposed even though src dst tensors appear to have same shape,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary pip install tensorflow gpu 1 2 1 TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version Python 2 7 13 Anaconda custom 64 bit default Dec 20 2016 23 09 15 Type copyright credits or license for more information IPython 5 3 0 An enhanced Interactive Python Bazel version if compiling from source CUDA cuDNN version Cuda V8 0 61 CuDNN 5 1 GPU model and memory GeForce GTX 1080 8GB Describe the problem At first I thought I was doing something wrong initially posted on stackoverflow but now I think this is a bug Full text from SO pasted below I want to share variables between an autoencoder and a decoder But the weights matrix from z to the first fully connected flat layer is transposed even though at every step of the graph construction I dump the previous tensor scopename and shape to the console and in both cases 'autoencoder' and wouldecoder' the scopenames and shapes are identical To be specific the error is Trying to share variable dense kernel but specified shape 128 65536 and found shape 65536 128 But in both cases I'm creating a dense layer from 128 to units 65536 with the same code print wouldense from to ' format t post z flat dim t tf layers dense inputs t units post z flat dim which gives the output autoencoder dense from Tensor z Merge 0 shape 128 dtype float32 to 65536 decoder dense from Tensor z 1 0 shape 128 dtype float32 to 65536 The only difference is for the decoder t is a placeholder whereas for autoencoder it is the result of a sequence of operations but still of shape None 128 Relevant code is below followed by the output Output when I use the above Note the scopenames and shapes in decoder1 which is created without variable sharing and it is identical to autoencoder But decoder2 which tries to share variables with autoencoder fails autoencoder Model usage Usage autoencoder reuse None main Model init 256 256 3 64 128 128 256 3 x 256 256 3 x 0 conv 128 128 64 encoder0 conv Relu 0 conv 64 64 128 encoder1 conv Relu 0 conv 32 32 128 encoder2 conv Relu 0 conv 16 16 256 encoder3 conv Relu 0 pre z flat 65536 Flatten Reshape 0 z 128 z Merge 0 dense from Tensor z Merge 0 shape 128 dtype float32 to 65536 post z flat 65536 dense Relu 0 post z img 16 16 256 Reshape 0 deconv 32 32 256 decoder0 up sampling2d 1 ResizeNearestNeighbor 0 deconv 64 64 128 decoder1 up sampling2d 2 ResizeNearestNeighbor 0 deconv 128 128 128 decoder2 up sampling2d 3 ResizeNearestNeighbor 0 deconv 256 256 64 decoder3 up sampling2d 4 ResizeNearestNeighbor 0 y 256 256 3 final conv Sigmoid 0 decoder1 Model usage Usage decoder reuse None main Model init 256 256 3 64 128 128 256 3 z 128 z 0 dense from Tensor z 0 shape 128 dtype float32 to 65536 post z flat 65536 dense Relu 0 post z img 16 16 256 Reshape 0 deconv 32 32 256 decoder0 up sampling2d 1 ResizeNearestNeighbor 0 deconv 64 64 128 decoder1 up sampling2d 2 ResizeNearestNeighbor 0 deconv 128 128 128 decoder2 up sampling2d 3 ResizeNearestNeighbor 0 deconv 256 256 64 decoder3 up sampling2d 4 ResizeNearestNeighbor 0 y 256 256 3 final conv Sigmoid 0 decoder2 Model usage Usage decoder reuse autoencoder main Model init 256 256 3 64 128 128 256 3 z 128 z 1 0 dense from Tensor z 1 0 shape 128 dtype float32 to 65536 Traceback most recent call last File ipython input 4 6f2915008bb4 line 1 in module decoder2 Model usage Usage decoder reuse autoencoder File home memo Dropbox research py apps webcam pix2pix tensorflow models cnnvae py line 152 in init t tf layers dense inputs t units post z flat dim activation activation fc File home memo anaconda2 lib python2 7 site packages tensorflow python layers core py line 218 in dense return layer apply inputs File home memo anaconda2 lib python2 7 site packages tensorflow python layers base py line 320 in apply return self call inputs kwargs File home memo anaconda2 lib python2 7 site packages tensorflow python layers base py line 286 in call self build input shapes 0 File home memo anaconda2 lib python2 7 site packages tensorflow python layers core py line 123 in build trainable True File home memo anaconda2 lib python2 7 site packages tensorflow python ops variable scope py line 1049 in get variable use resource use resource custom getter custom getter File home memo anaconda2 lib python2 7 site packages tensorflow python ops variable scope py line 948 in get variable use resource use resource custom getter custom getter File home memo anaconda2 lib python2 7 site packages tensorflow python ops variable scope py line 349 in get variable validate shape validate shape use resource use resource File home memo anaconda2 lib python2 7 site packages tensorflow python layers base py line 275 in variable getter variable getter functools partial getter kwargs File home memo anaconda2 lib python2 7 site packages tensorflow python layers base py line 228 in add variable trainable trainable and self trainable File home memo anaconda2 lib python2 7 site packages tensorflow python ops variable scope py line 341 in true getter use resource use resource File home memo anaconda2 lib python2 7 site packages tensorflow python ops variable scope py line 658 in get single variable found var get shape ValueError Trying to share variable dense kernel but specified shape 128 65536 and found shape 65536 128,,,2017-08-30 20:50:55,2017-08-31 08:46:51
IS,AttributeError,Im getting the following error while training mobile net model as,,rohan100jain,2017-08-07 17:55:18,2017-08-31 18:40:07
PR,Add eager pip to simple console for windows zip,To fix unitest errors in tf master win bzl build,,"snnn,caisq,asimshankar,meteorcloudy,snnn,meteorcloudy,caisq,snnn,meteorcloudy,asimshankar,caisq,caisq,caisq",2017-08-29 10:18:36,2017-08-31 19:14:41
IS,NO documentation for Linux SUSE SLES 12,Hello Team I struggled to get the clear documentation for Linux SUSE SLES12 Now a days one single rpm usually contains the entire install able binaries Could you please add this as new feature Regards Naveen,,jart,2017-08-31 12:14:04,2017-08-31 19:26:28
PR,Added a library to convert TensorFlow GraphDef to XLA SessionModule,I have only added the minimal code without lot of comments I wanted to make sure this approach is acceptable I have made the xlagen library public so a python library can be built externally by using TensorFlow as a submodule Please let me know if this is acceptable and I will spruce up the PR with more documentation comments and tests,,"keveman,keveman,jmchen-g,tatatodd,keveman,keveman",2017-08-18 23:40:36,2017-08-31 20:51:14
PR,Fix markdown syntax mistakes,Add a space after and,,,2017-08-28 23:51:12,2017-09-01 01:03:48
PR,Merge pull request 1 from tensorflow master,merge,,,2017-09-01 01:56:32,2017-09-01 02:35:26
IS,Bug bazel test kernel tests scatter ops test on master branch got ImportError No module named autograd,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below master Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version 8 0 5 1 10 GPU model and memory M40 Exact command to reproduce bazel test c opt verbose failures tensorflow python kernel tests scatter ops test Describe the problem I have clone the source and run kernel test with the above command got following error Then I check out branch v1 3 it is ok,,"nolanliou,reedwm,nolanliou",2017-08-20 03:45:27,2017-09-01 09:36:15
IS,AssertionError Cannot find runfiles directory for bazel bin tensorflow python tools freeze graph,After I install the tensorflow from source i'm trying to use freeze graph tool and it appear this error My OS is MacOS 10 12 5,,,2017-08-31 09:48:42,2017-09-01 12:53:57
PR,Fix step numbering in Linux install docs,On this page the numbering for the steps seems to be off InstallingVirtualenv,,,2017-09-01 02:21:28,2017-09-01 13:09:25
IS,Training model on Android,I want to training my model on the Android mobile phones by using Tensorflow How to train the model and save the model on Android mobile phone I can not find corresponding functions on Java API of TensorFlow Is it possible to find a way to implement such functions on android mobile phone maybe tensorflow on Android with Python bindings Or other Deep learning framework,,,2017-08-30 01:52:19,2017-09-01 18:06:27
IS,how to find distance from camera to object,hello i am a beginner how to find distance Meter from camera to object with tensorflow Thanks,,,2017-08-31 02:05:43,2017-09-01 18:06:51
IS,Flatten all gradients in an MLP to a tensor of rank 1 i e 1D array,Suppose the following Keras model Obviously we can calculate the gradients by grads K gradients loss params which just calls tf gradients loss variables colocate gradients with ops True This returns a list of tensors containing 1 a tensor with 512x784 elements input to hidden connections 2 a tensor with the biases of the 512 units in the hidden layer 3 a tensor with 10x512 elements hidden to output connections 4 a tensor with the biases of the 10 output units I would like to ask if there is a simple way to flatten grads to a single tensor of rank 1 i e 1D array with 512x784 512 10x512 10 elements without looping over the layers and corresponding biases Thanks,,,2017-08-31 09:20:27,2017-09-01 18:11:40
IS,Has anyone tried to visualize this program with tensorboard,I was trying to visualize the vectors with thensorboard but it did not work it was loading for over 30 minutes what is wrong,,,2017-08-31 16:30:07,2017-09-01 18:23:44
IS,Issue with tf py func tf Tensor set shape and tf Queues,This works fine,,,2017-09-01 18:53:18,2017-09-01 22:11:53
IS,a,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-01 06:14:33,2017-09-01 23:24:11
PR,Remove initialize all tables,Finishing TODO yleon Remove this function,,"alanyee,martinwicke",2017-08-30 17:13:50,2017-09-02 06:27:22
PR,Merge pull request 2 from tensorflow master,Update from origin,,martinwicke,2017-08-30 09:23:41,2017-09-02 06:28:44
PR,R1 3 Delete monitors md,The monitors in this doc are not compatible with the core Estimators in the other get started docs This will likely only cause confusion Since AFAIK monitors are deprecated I see no advantage to preserving this doc in api guides If we delete it here I can regenerate the root version of the website without this file I will mirror these changes into master,,"MarkDaoust,martinwicke,martinwicke",2017-08-28 15:19:44,2017-09-02 07:00:15
PR,fix typo,fix the meaning of num units in BasicRnncell,,,2017-09-02 08:34:52,2017-09-02 18:25:08
PR,Avoid gcc7 memcpy build error by updating BoringSSL,Tensorflow produces this build error with gcc7 due to ambiguous memcpy inlining in all versions of BoringSSL prior to on Dec 12 2016 Updating BoringSSL snapshot from 7 11 16 to 7 7 17 fixes this July 7 snapshot was picked because this is the stable build that Apollo uses Reliance on older snapshots of BoringSSL with this same memcpy bug is also breaking GRPC and Tensorflow Serving on modern gcc toolchains in the same way Note This build error is ubiquitous since bazel is primary workspace bzl downloads and builds BoringSSL regardless of whether it is required i e even when Google Cloud Storage support is disabled and when SSL support is not enabled,,"gunan,gunan,facaiy,facaiy,martinwicke,gunan",2017-09-01 11:20:35,2017-09-02 19:21:08
IS,GPU support on Mac OS X compile by oneself,I'm to select ubuntu or Hackintosh as my PC Note As of version 1 2 TensorFlow no longer provides GPU support on Mac OS X Could anyone tell the reason Could I compile tensorflow with gpu cuda support by myself Why or Why not,,"gunan,gunan",2017-09-02 18:44:12,2017-09-02 19:24:47
IS,ImportError DLL load failed VS2012 PTVS 2 1 1 Windows 7,System information OS Platform Windows 7 TensorFlow version tensorflow gpu 1 3 0 CUDA cuDNN version 8 0 6 0 GPU model and memory GeForce GTX 750 IDE Visual Studio 2012 PTVS 2 1 1 virtualenv 15 1 0 Problem I installed tensorflow gpu in virtualenv Under the following environment it works well prompt activate virtualenv start python import tensorflow However it does not work well under the following environment Python Environments virtualenv I try to run main py which has only 1 line import tensorflow Then the error mentioned below occurs How can I use tensorflow gpu Log Traceback most recent call last File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 914 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File debug input line 1 in module File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow init py line 24 in module from tensorflow python import File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 914 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File D WORK online3 pyToolbox Packages virtualenv venv35 64 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,mrry,2017-09-01 09:01:07,2017-09-02 19:29:10
IS,the side deep model is not good compare with deep model and wide model,these days I'm learning the wide deep model and run the wide n deep tutorial py so the anwser looks like this XXT apptruexxnet python wide n deep tutorial py model type deep Training data is downloaded to tmp tmpFB4dsd Test data is downloaded to tmp tmpomj5Pi 2017 09 02 20 03 15 713609 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 03 15 713884 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 03 15 714050 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on yo ur machine and could speed up CPU computations WARNING tensorflow Casting dtype 'float32' labels to bool WARNING tensorflow Casting dtype 'float32' labels to bool model directory tmp tmpWei9wK accuracy 0 850071 accuracy baseline 0 763774 auc 0 894038 auc precision recall 0 743199 average loss 0 393638 global step 2000 label mean 0 236226 loss 39 3179 prediction mean 0 242167 XXT apptruexxnet python wide n deep tutorial py model type wide Training data is downloaded to tmp tmpFJdWft Test data is downloaded to tmp tmpjB5nm7 2017 09 02 20 01 09 197612 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 01 09 197906 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 01 09 198072 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on yo ur machine and could speed up CPU computations WARNING tensorflow Casting dtype 'float32' labels to bool WARNING tensorflow Casting dtype 'float32' labels to bool model directory tmp tmpuPHsDx accuracy 0 835391 accuracy baseline 0 763774 auc 0 882763 auc precision recall 0 694257 average loss 0 352975 global step 2000 label mean 0 236226 loss 35 2563 prediction mean 0 240918 XXT apptruexxnet python wide n deep tutorial py Training data is downloaded to tmp tmpDdWc T Test data is downloaded to tmp tmpFF0PZJ 2017 09 02 20 00 08 334742 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 00 08 335105 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 09 02 20 00 08 335273 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on yo ur machine and could speed up CPU computations WARNING tensorflow Casting dtype 'float32' labels to bool WARNING tensorflow Casting dtype 'float32' labels to bool model directory tmp tmpq2M7SE accuracy 0 820834 accuracy baseline 0 763774 auc 0 850518 auc precision recall 0 676198 average loss 0 424271 global step 2000 label mean 0 236226 loss 42 3776 prediction mean 0 256489 I do not know why looks likes this so someone can help me thank you,,carlthome,2017-09-02 12:12:36,2017-09-02 19:31:07
PR,Formatting typo,,,,2017-09-02 22:39:59,2017-09-03 00:52:45
PR,Fix indices is out of bounds in IndicatorColumn,The same bug of 12583 exists in tf feature column as well CF pr 12584 What changes were proposed in this pull request slice weighted column to get rid of 1 index How was this patch tested x add unit tests x pass all tests,,"facaiy,ispirmustafa,facaiy,facaiy,facaiy,martinwicke",2017-08-28 02:16:52,2017-09-03 02:21:59
PR,Make Dataset map not unpack namedtuple,The map method of tf contrib data Dataset unpacks iterables before passing them to the mapped function This is quite convenient However currently this also happens for namedtuples which IMHO is not what one would expect Consider for example the following code This does not work because the namedtuple instance is unpacked and its fields are passed as separate arguments to preprocess example So currently one has to reassemble the namedtuple manually This is not a big deal but it would be more convenient if namedtuples were not unpacked as is also the case for dictionaries This can be easily achieved by making should unpack args return False for namedtuples as is done in this pull request,,"adaitche,mrry,adaitche,adaitche,mrry,adaitche,mrry",2017-08-27 13:29:29,2017-09-03 02:23:20
IS,tf reshape does not accept Dimension objects for the shape parameter,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 x64 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 6 1 Anaconda 4 4 0 64 bit Bazel version if compiling from source CUDA cuDNN version GPU model and memory GTX 780 Exact command to reproduce tf reshape You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request tf reshape does not accept a list with mixed Integer and Dimension as elements for the shape parameter It should accept shapes that have Dimension as elements since tensor shapes consist of dimensions Specifically tf tensor shape returns a list of Dimensions therefore using a similar object to specify a shape in tf reshape should not cause an error Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Example code This is rectified by casting X shape 1 to int before passing to tf reshape A similar unrelated issue is that X shape returns 784 while it should return 1 784 This requires reshaping to turn the placeholder back into a 2D tensor I have not determined if this is a bug but it occurs when the tensor is explicitly specified as a 2D tensor so it is probably worth changing,,"yaroslavvb,shivaniag,yaroslavvb,facaiy,yaroslavvb,facaiy,facaiy,yaroslavvb,facaiy,yaroslavvb,facaiy",2017-08-02 17:21:49,2017-09-03 02:41:24
PR,make Dimension be compatible with integer,The PR is another solution to fix 11974 I believe that it is better than 12127 What changes were proposed in this pull request Make Dimension to be compatible with integer so 1 Dimension 2 will be casted to 1 2 automatically How was this patch tested x add a doctest x add an unit test x pass all unit tests,,"facaiy,alextp,alextp,facaiy,facaiy,alextp,facaiy,facaiy,alextp,facaiy,alextp,alextp,alextp,facaiy,facaiy,alextp,facaiy",2017-08-23 05:25:54,2017-09-03 02:41:25
PR,tf reshape accepts Dimension objects for the shape parameter,The PR aims to fix 11974 Because it is my first contribution so the PR is opened early to get feedback from community What changes were proposed in this pull request Cast tf Dimension to int for shape argument How was this patch tested x add a doctest,,"facaiy,facaiy,yaroslavvb,facaiy,rmlarsen,rmlarsen,facaiy,facaiy,facaiy,facaiy,yaroslavvb,facaiy",2017-08-09 03:30:03,2017-09-03 02:46:03
IS,bazel build tensorflow python tools optimize for inference failed,bazel build tensorflow python tools optimize for inference ERROR Users andylin Desktop gitwork tensorflow tensorflow core BUILD 1416 1 no such target ' tensorflow tools git gen spec json' target 'gen spec json' not declared in package 'tensorflow tools git' defined by Users andylin Desktop gitwork tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users andylin Desktop gitwork tensorflow tensorflow core BUILD 1416 1 no such target ' tensorflow tools git gen head' target 'gen head' not declared in package 'tensorflow tools git' defined by Users andylin Desktop gitwork tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users andylin Desktop gitwork tensorflow tensorflow core BUILD 1416 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by Users andylin Desktop gitwork tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow python tools optimize for inference' failed build aborted INFO Elapsed time 0 875s,,gunan,2017-09-01 10:22:37,2017-09-03 06:16:55
IS,BUILD 1227 1,bazel build tensorflow libtensorflow so ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen spec json' target 'gen spec json' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen head' target 'gen head' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Users dile tensorflow tensorflow core BUILD 1227 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by Users dile tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow libtensorflow so' failed build aborted,,"reedwm,gunan",2017-08-17 12:08:59,2017-09-03 06:46:49
IS,not installing,Collecting tensorflow Could not find a version that satisfies the requirement tensorflow from versions No matching distribution found for tensorflow,,gunan,2017-08-14 00:33:13,2017-09-03 06:50:24
IS,Cannot compile on Mac OS X due to BoringSSL,System information,,"tatatodd,RenatoUtsch,facaiy,RenatoUtsch,RenatoUtsch,snnn,RenatoUtsch,RenatoUtsch,gunan",2017-08-08 23:51:22,2017-09-03 06:52:49
IS,built 1 3 0 from source got version 1 2 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 2 0 2651 g82456f9 1 2 1 rc1 Python version Python 3 5 2 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory titanx 12GB Exact command to reproduce no Describe the problem git log shows latest commit is 82456f9fee7c4b5e9beb100e59ba8dc5eb688b28 my python install package file is named tensorflow 1 3 0rc1 cp35 cp35m linux x86 64 whl but python3 c import tensorflow as tf print tf GIT VERSION tf VERSION output v1 2 0 2651 g82456f9 1 2 1 rc1 I use python help to see some api doc and find they are same as 1 3 0 rc1 says,,"suiyuan2009,av8ramit,yaroslavvb,yaroslavvb,suiyuan2009,suiyuan2009,yaroslavvb,suiyuan2009,gunan",2017-08-01 07:57:33,2017-09-03 06:55:25
IS,How to install tensorflow c,Hi I am trying to build email spam filtering I have already done when email has text only but the problem when deal with images Any help how to install tensorflow and deal with images Thanks,,gunan,2017-07-18 10:50:48,2017-09-03 06:58:21
IS,Enable MKL Support in TensorFlow for Java,Description I'm trying to use TensorFlow for Java in a Dataflow pipeline Currently everything appears to be working but since Dataflow only supports CPU instances inference time seems to be quite slow In my previous experiments I have seen that building TensorFlow from source with MKL support usually provides a very significant speed gain Since I'm currently using TensorFlow for Java directly from Maven repository I wo not be able to get MKL support Would it be possible to enable MKL support for TensorFlow in Java,,"drpngx,asimshankar,tfboyd,gunan,tfboyd",2017-07-03 04:41:25,2017-09-03 07:01:28
IS,Cannot build TensorFlow on macOS 10 12,When I trying to build TensorFlow with avx avx2 fma sse4 1 sse4 2 it shown that clang does not support sse4 1 and sse4 2 And I can not change the bazel compiler to gcc anyway,,"gunan,gunan",2017-06-30 15:37:41,2017-09-03 07:05:08
IS,windows 10 Anaconda python 3 6 1 Tensroflow import error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary TensorFlow version use command below Bazel version if compiling from source CUDA cuDNN version v8 0 cudnn 8 0 windows10 x64 v6 0 GPU model and memory NVIDIA Geforce GTX 1060 6GB Exact command to reproduce D Anaconda3 C Users user python import tensorflow as tf Traceback most recent call last File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File D Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File D Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File D Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File D Anaconda3 lib site packages tensorflow init py line 24 in module from tensorflow python import File D Anaconda3 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File D Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File D Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed During handling of the above exception another exception occurred Traceback most recent call last File D Anaconda3 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File D Anaconda3 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File D Anaconda3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help Here is the errors came up I just started python and kinda novice to programming Can you guys get me any help,,"mrry,gunan",2017-06-26 07:58:25,2017-09-03 07:05:41
IS,Unable to install TensorFlow properly on windows for python Please help,I am trying to install TensorFlow on Windows 10 for Python 3 5 64 bit It says successfully installed but when I test it using import tensorflow as tf command in the command prompt it shows a long error saying DLL load failed and failed to load native tensorflow runtime I had tried installing it earlier but it did not work When I uninstalled from cmd pip uninstall tensorflow it said successfully uninstalled But when I try reinstalling it says requirement already satisfied and gives the same long error DLL load failed etc when i type import tensorflow as tf This does not make sense Please help Please see images image image,,"mrry,gunan",2017-06-26 17:38:51,2017-09-03 07:06:00
IS,install with MKL and OpenCL without locate command,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Description SUSE Linux Enterprise Server 11 x86 64 TensorFlow installed from source or binary source TensorFlow version use command below master branch Bazel version if compiling from source 0 5 1 CUDA cuDNN version 7 5 GPU model and memory Tesla K20Xm Exact command to reproduce configure Describe the problem I am trying to install tensorflow on Tokyo Institute of Technology Supercomputer TSUBAME I want to install with MKL support but locate command is required The university says that because TSUBAME is a public service and locate can be used to see files from other users the command is not going to be installed So it means MKL can not be used even it is installed in the supercomputer I suggest a feature to install tensorflow with the supports without locate command I guess tensorflow is used in a lot of supercomputers the same problem may occur elsewhere Source code logs Do you wish to build TensorFlow with MKL support y N y MKL support will be enabled for TensorFlow Do you wish to download MKL LIB from the web Y n n Please specify the location where MKL is installed Default is opt intel mklml usr apps sp3 isv intel xe2013 1 046 composer xe 2013 sp1 2 144 mkl configure line 279 locate command not found,,gunan,2017-06-24 07:49:36,2017-09-03 07:07:18
IS,DLL Problem with fresh tensorflow gpu installation,Hi I installed tensorflow gpu in an anaconda environment on my new notebook It is a complete fresh installation I can not get it to work On my other machine it works fine but not on this new notebook Machine Windows 10 Pro i7 7700HQ NVIDIA GTX 1060 6GB newest device driver 382 53 16 GB RAM Anaconda 3 CUDA Toolkit 8 0 installed CUDnn 5 1 for Cuda Toolkit 8 0 installed My anaconda3 python environment uses Python35 3 5 3 I installed tensorflow gpu via pip I also tried pip install ignore installed upgrade I checked the DDL is They are all there I got the following list of DDLs from here issuecomment 263708081 in C windows system32 i can find KERNEL32 dll WSOCK32 dll WS2 32 dll SHLWAPI dll python35 dll MSVCP140 dll VCRUNTIME140 dll in the anaconda folder i can find api ms win crt runtime l1 1 0 dll api ms win crt heap l1 1 0 dll api ms win crt utility l1 1 0 dll api ms win crt stdio l1 1 0 dll api ms win crt string l1 1 0 dll api ms win crt math l1 1 0 dll api ms win crt convert l1 1 0 dll api ms win crt environment l1 1 0 dll api ms win crt filesystem l1 1 0 dll api ms win crt time l1 1 0 dll when i want to run a mnist example or when i just execute 'import tensorflow' I get this error message,,"mrry,gunan,gunan",2017-06-22 19:09:57,2017-09-03 07:08:13
IS,Tensor flow importing error please help very important,error1 error2,,"caisq,gunan",2017-06-13 09:52:06,2017-09-03 07:09:12
IS,tensorflow 1 2 0 import tensorflow Segmentation fault,hi I installed tensorflow 1 2 0 in my machine and met a segment fault as below linux swfm workarea test python Python 2 7 13 default Jun 20 2017 20 03 45 GCC 4 9 2 on linux2 Type help copyright credits or license for more information import tensorflow as tf Segmentation fault my system is USE Linux Enterprise Server 11 SP3 cuda sdk version is 8 0 and cudnn is 6 0 my command to build tensorflow is below bazel build config opt config cuda tensorflow tools pip package build pip package,,"byronyi,byronyi,rohan100jain,jart,gunan",2017-06-21 02:48:54,2017-09-03 07:10:04
PR,Fix undefined reference to libtensorflow core a,Adjust parameter order to fix undefined reference error,,,2017-09-03 07:29:25,2017-09-03 07:53:57
PR,Fix undefined reference to libtensorflow core a,Adjust gcc parameter order to fix linker error Tested on gcc version 5 4 0 20160609 Ubuntu Linaro 5 4 0 6ubuntu1 16 04 4,,,2017-09-03 08:07:32,2017-09-03 08:44:07
PR,Removing contrib tensorboard and its references,The only reference to contrib tensorboard was in contrib init py and contrib keras python keras callbacks py Both of those references did not include and tensorboard plugins that the Tensorboard repo does not have So I have added multiple if exists statements inside keras callbacks py and removed contrib tensorboard completely The reason for this some guy at Arch Linux repos have added a rm rf to his PKGBUILD and now me and anybody who has the latest version of Tensorflow on Arch Linux is unable to use it I thought maybe we can clear up the confusion since Kenser will be included with Tensorflow by default Link to my ticket Arch Linux Tensorflow Ticket,,martinwicke,2017-09-02 17:37:07,2017-09-03 19:31:22
IS,nest flatten does not work with list,System information cat etc issue Linux mews3153 3 16 0 4 amd64 1 SMP Debian 3 16 36 1 deb8u2 2016 10 19 x86 64 GNU Linux VERSION ID 8 VERSION 8 jessie are we in docker No compiler c Debian 4 9 2 10 4 9 2 Copyright C 2014 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux mews3153 3 16 0 4 amd64 1 SMP Debian 3 16 36 1 deb8u2 2016 10 19 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv True tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH usr lib libipp intel opt boost lib usr lib64 mobileye shared boost python2 7 lib DYLD LIBRARY PATH is unset nvidia smi tmp tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem The function tensorflow contrib data python util nest flatten fails to flatten a list Given a flat list it returns a nested list This causes a problem in dataset ops py when the datasource is created by zipping several datasources and then attempting to create an iterator Source code logs Example 1 from tensorflow contrib data python util import nest nest flatten 1 2 3 4 1 2 3 4 nest flatten 1 2 3 4 works with a tuple 1 2 3 4 Example 2 import tensorflow as tf dataset1 tf contrib data Dataset from tensor slices tf random uniform 4 10 dataset2 tf contrib data Dataset from tensor slices tf random uniform 4 dataset3 tf contrib data Dataset zip dataset1 dataset2 iterator dataset3 make initializable iterator sess tf InteractiveSession sess run iterator initializer next1 next2 iterator get next running the above code Traceback most recent call last File tmp tds py line 7 in module iterator dataset3 make initializable iterator File homes elyassaf venv local lib python2 7 site packages tensorflow contrib data python ops dataset ops py line 464 in make initializable iterator return Iterator from dataset self shared name File homes elyassaf venv local lib python2 7 site packages tensorflow contrib data python ops dataset ops py line 97 in from dataset output types nest flatten dataset output types File homes elyassaf venv local lib python2 7 site packages tensorflow contrib data python ops dataset ops py line 1199 in output types ds output types for ds in nest flatten self datasets AttributeError 'list' object has no attribute 'output types',,yongtang,2017-09-03 08:06:58,2017-09-03 19:38:28
PR,Added shape information to the while loop input placeholders for the C API,As discussed with,,"eaplatanios,skye,skye,skye,skye,skye,skye,skye,skye,skye,skye,skye,eaplatanios,skye,eaplatanios,skye,eaplatanios,eaplatanios,eaplatanios",2017-08-23 19:44:33,2017-09-03 20:52:26
PR,Branch 167401527,,,martinwicke,2017-09-03 18:21:13,2017-09-03 22:02:51
IS,C gradients reduce min reduce max,Anyone already working on adding these two operators to the C gradients Otherwise I will sign up for it cc,,"kbsriram,bpiel",2017-08-30 22:45:06,2017-09-03 22:03:19
IS,Three questions about ChiefSessionCreator,There are two parameters of ChiefSessionCreator 1 checkpoint dir and checkpoint filename with path what difference between them And ChiefSessionCreator has a parameter scaffold 2 which has a parameter saver does it mean ChiefSessionCreator uses scaffold saver to save and restore variables And scaffold also has a parameter init fn and it can be used like init fn assign from checkpoint fn 3 assign from checkpoint fn will new a saver with the parameter var list of assign from checkpoint fn So here comes another question ChiefSessionCreator will use scaffold saver to restore variables or init fn To answer the three questions above you may need read the source code but I am not capable to do it so I need your help Thanks 1 2 3,,jart,2017-09-02 14:01:21,2017-09-03 23:07:17
IS,C tensorflow interface is taking too long to terminate and return the calculated graph output,Hi All I am loading a trained graph from python in c as explained in the below links 1 hamedmp exporting trained tensorflow models to c the right way cf24b609d183 2 I am using this tf feature in larger c application the working is as follows main function creates a process that will load the graph calculate and return the output This process will be called every 0 1 seconds The interface works fine however it takes rather long 1 second to terminate and return the value to main I have also timed duration from loading the graph until return within the tf api it takes 0 015 seconds I am unable to figure out the reason for this delay I am not sure if it is due to c createprocess or tf sesion handling can someone help me to address this issue I have also posted the same question in stackoverflow which got down voted a lot as I am unable to solve this problem I am posting it here too sorry if it is not the correct platform I am using python 3 5 Anaconda 4 2 0 on a Windows 7 system tensorflow CPU version 1 2 0 bazel 0 5 3 VS 2015 Describe the problem C tensorflow interface is taking too long to terminate return the calcualted graph output Source code logs,,jart,2017-09-03 17:36:22,2017-09-03 23:52:35
IS,Behavior of SVM in tensorflow contrib learn python learn estimators inconsistent between dense and sparse inputs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary Binary community arch linux repo TensorFlow version use command below 1 3 0 1 Python version 3 6 2 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I'm trying to use the SVM in tensorflow contrib learn with sparse input The minimal test with real dense valued column works However when I try to reproduce the exact same classification problem but wrapped in sparse feature columns with sparse columns with integerized features and weighted sparse columns it fails It might be a misuse of the sparse columns from me but I have spent a good amount of time reading the doc and the source code without understanding why Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,jart,2017-09-03 19:38:01,2017-09-04 00:01:18
IS,Halted partial dataset download for speech commands example renders example broken,If a user attempts to run tensorflow examples speech commands train py for the first time against a new data dir location and then halts the execution of Python before the download can finish subsequent attempts to run the script using the same data dir specification or lack of specification will result in Python exiting in error with the gzip libraries complaining about incorrect CRC value This is because AudioProcessor maybe download and extract dataset in tensorflow examples speech commands input data py only downloads if the file does not already exist sensibly and assumes that tarfile open extractall will complete error free less sensibly which it wo not on the partially downloaded gzipped tar asset This probably merits a documentation inclusion as opposed to a code re write since it is example code but that decision is above my pay grade,,"facaiy,jart",2017-09-02 22:00:55,2017-09-04 00:12:29
IS,Training does not start when using batch normalization,I am following the article When I use the below code the training does not start update ops tf get collection tf GraphKeys UPDATE OPS with tf control dependencies update ops train op optimizer minimize loss Any help will be greatly appreciated,,jart,2017-08-27 21:12:07,2017-09-04 00:14:34
IS,Feature request Hyper Parameters optimizer,Hi Do you plan to add a code in order to optimize automatically the hyper parameters of deep learning algorithm number of hidden layers value of the learning rate type of down sampling etc Best,,"yaroslavvb,jart",2017-09-01 20:57:09,2017-09-04 00:22:55
IS,Android Tensorflow model loading issue,I have saved model using tf train Saver save and then freeze the graph bu using below method def freezeModel modelName input graph path modelName ' pb' checkpoint path ' ' modelName ' ckpt' input saver def path input binary True output node names x indices x values x dense shape unary scores transition params train op restore op name save restore all filename tensor name save Const 0 output frozen graph name 'frozen ' modelName ' pb' clear devices True freeze graph freeze graph input graph path input saver def path input binary checkpoint path output node names restore op name filename tensor name output frozen graph name clear devices freeze graph freeze graph input saved model dir 'Model ' saved model tags iserve' return Then loading the modelName pb file in Android using inference api as below TensorFlowInferenceInterface inferenceInterface new TensorFlowInferenceInterface context getAssets MODEL FILE I am getting below error Caused by java io IOException Not a valid TensorFlow Graph serialization Value for attr 'T' of int64 is not in the list of allowed values float int32 NodeDef Less 1 Less T DT INT64 ToInt64 2 ToInt64 3 Op name Less signature x T y T z bool attr T type allowed DT FLOAT DT INT32 at org tensorflow contrib android TensorFlowInferenceInterface loadGraph TensorFlowInferenceInterface java 439 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 98 Here is the code using to create the graph x indices t tf placeholder tf int64 shape None 3 name x indices x values t tf placeholder tf float32 shape None name x values x dense shape t tf placeholder tf int64 shape 3 name x dense shape len X train max word count feature count shape unary score t tf placeholder dtype tf int64 shape None None None name shape unary score num examples t max word count num tags shape t tf shape shape unary score t x t tf SparseTensor indices x indices values x values dense shape x dense shape To resolve above error i changed the dtype of indices and shapes to int32 then tf SparseTensor is givving below error File CRF POS Trainer Tensor Training py line 323 in module x t tf SparseTensor indices x indices t values x values t dense shape x dense shape t File home anaconda3 envs tensorflow lib python3 6 site packages tensorflow python framework sparse tensor py line 119 in init indices name indices dtype dtypes int64 File home anaconda3 envs tensorflow lib python3 6 site packages tensorflow python framework ops py line 676 in convert to tensor as ref False File home anaconda3 envs tensorflow lib python3 6 site packages tensorflow python framework ops py line 741 in internal convert to tensor ret conversion func value dtype dtype name name as ref as ref File home anaconda3 envs tensorflow lib python3 6 site packages tensorflow python framework ops py line 614 in TensorTensorConversionFunction dtype name t dtype name str t ValueError Tensor conversion requested dtype int64 for Tensor with dtype int32 'Tensor x indices 0 shape 3 dtype int32 ' So how to i resolve issue to create SparseTensor with int32 data Tensorflow Version 1 3 0,,jart,2017-09-01 09:35:17,2017-09-04 01:16:09
IS,Incompatible Shapes during Validation for TensorFlow is seq2seq module,I'm using TensorFlow is seq2seq module During validation my decoder will occasionally produce output sequences with different lengths than the target sequences this causes the following error when calculating the loss using tf nn sigmoid cross entropy with logits batch major not time major InvalidArgumentError see above for traceback Incompatible shapes 128 22 4 vs 128 26 4 What is the best practice for dealing with this problem I checked how the NMT tutorial solved the problem As far as I can tell they use a TrainingHelper during validation which forces the decoder to unroll the same number of steps as the target sequence but this seems like cheating they are estimating how the model will perform during inference but the decoder is receiving additional information the target sequence length that it wo not have at inference time I opened an issue to clarify but I have not heard back I also posted on StackOverflow but from earlier experience I doubt I will receive a response My problem is not specific to platform or TensorFlow version but here is that information regardless OS macOS Sierra version 10 12 6 TensorFlow installed from source TensorFlow version 'v1 3 0 rc2 20 g0787eee' '1 3 0',,"jart,adarob",2017-08-31 17:48:33,2017-09-04 01:39:24
IS,Reproducing results in tensorflow,Hi All I set the graph level seed and op level seed to be 0 and run the same script for 10 times However for a different run 5 out of 10 times the results are exactly the same weights in the model and the training loss For the other 5 times the results are completely different for each run apart from the initialization steps Anyone has any idea of what is going on here Thanks,,jart,2017-08-31 14:33:07,2017-09-04 02:16:09
IS,Is tf one hot w GPU not working under windows10,I'm trying to run tensorflow in Windows10 environment When I use tf one hot function with GPU then it occur error Below is test code and it is working find in Ubuntu Test code System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version 8 0 5 1 GPU model and memory Titan XP 12GB Exact command to reproduce,,jart,2017-08-31 11:05:17,2017-09-04 03:04:58
IS,There are sudden change in validation line,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Os platform version Win10 install From conda tensorflow version tensorflow 1 1 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version 8 0 5 0 GPU model and memory GTX1080ti Describe the problem I resume weights model from local I find there are sudden change in validation line but my train line do not this problem I think maybe there are something wrong with tensorflow source code below is train history graph Source code logs if RESUME print 'Restoring previously trained model at s' MODEL SAVE PATH saver restore sess MODEL SAVE PATH Restore previous loss history with open 'loss history p' 'rb' as f loss history pickle load f else print 'Training model from scratch' Variable initialization sess run tf global variables initializer For book keeping keep track of training and validation loss over epochs like such train acc epoch1 valid acc epoch1 train acc epoch2 valid acc epoch2 loss history,,jart,2017-08-28 02:22:25,2017-09-04 03:17:27
IS,Calculating marginals in CRF,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-08-26 19:38:01,2017-09-04 03:18:08
IS,dataset with tf pyfunc error,The new IO API is awesome but I found this error in my project image I tried to get some index from dataset then make a batch index given the batch index I got the features from memory which used tf py func API but I found this error Invalid argument Shapes of all inputs must match values 0 shape 4096 values 3 shape 4096 41,,gunan,2017-08-31 05:42:17,2017-09-04 05:14:24
PR,Eager API String Tensors and others that need to be copied Fix,This PR partially fixes the issue related to string tensors described in 12612 Note that there are still some issues remaining related to string tensors 1 There is a small inconsistency when dealing with TFE tensors now in that for the string data type a copy of the provided TF Tensor is created whereas for others types that is not the case This can be problematic when users of the API attempt to use the underlying tensor buffer directly e g to read values of specific elements The problem could potentially be alleviated if the same memory layout is used for string TF Tensor s and tensorflow Tensor s I'm not sure why that is not the case and I'm also not sure what the memory layout for string tensors is internally could someone provide some insight into that please 2 The above mentioned problem could be partially alleviated by providing a TFE function for obtaining a byte array representation of the i th element in the flattened row major tensor That is currently the only use I have found for directly accessing the underlying buffer 3 This fix resolves the issues specific to string tensors and the eager execution API but one issue related to 12612 still remains When I try to use some ops such as the Unpack op I get the following error no matter what the data type of the tensor is C libtensorflow so 0x20f0 TFE TensorHandleDeviceName 0x0 I plan to look more into this but please let me know if you can see a reason why this might be happening could you please give me some information on what the memory layout is for string tensors internally and on why we cannot use the same representation for the C API TF Tensor s That would resolve points 1 and 2 above I think that a function for obtaining the i th element would still be very useful though in either case,,"eaplatanios,asimshankar,asimshankar,asimshankar,eaplatanios,eaplatanios,asimshankar,eaplatanios,eaplatanios,asimshankar,eaplatanios,eaplatanios,asimshankar,eaplatanios,eaplatanios,alextp,eaplatanios,asimshankar,eaplatanios",2017-08-27 04:12:27,2017-09-04 05:32:13
PR,Added SNAPPY support in CMake scripts,Windows CMake builds do not include SNAPPY compression library support thus the resulting applications are not able to parse TensorFlow models that were compressed with SNAPPY This pull request adds SNAPPY as ExternalProject just as it is done with all other 3rd party libraries Unfortunately I cannot verify this on a Linux machine right now so option is disabled for Linux by default There is a relevant Stackoverflow question Example command line to build snappy as a part of TF This is my first contribution so I apologize in advance for any guidelines I might have violated Feedback is appreciated,,"mrry,mrry,mrry,mrry,rmlarsen,mrry,jhseu,jhseu,mrry,mrry,mrry",2017-07-27 15:36:45,2017-09-04 06:55:49
PR,Java Build rules and skeleton for operation wrappers generator,In this PR Bazel rules to generate operation wrappers in Java at build time and a very minimal implementation of the generator in C are added For now the generator only create empty packages one package per op library and combine them into a source archive srcjar that is added as a source dependency of the tensorflow Java library target The goal of this PR is to make sure that everything is setup properly and agreed on before starting to generate for real the operation wrappers,,"karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,karllessard,asimshankar,kbsriram,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,asimshankar,karllessard,asimshankar,kbsriram,asimshankar,karllessard,asimshankar,karllessard,asimshankar,asimshankar,asimshankar",2017-08-02 16:08:51,2017-09-04 07:01:32
IS,Run Retrained inception model,I have trained tensorflow inception v3 model with new data sets on ubuntu I got output graph pb and output labels txt files in tmp folder When I tried to run as below python label image py image home ubuntu 140924 HDR3DSC 0092 ISO00050 SS1250 JPG graph tmp output graph pb labels tmp output labels txt I got below errors File label image py line 121 in module input operation graph get operation by name input name File home ubuntu tensorflow local lib python2 7 site packages tensorflow python framework ops py line 2836 in get operation by name return self as graph element name allow tensor False allow operation True File home ubuntu tensorflow local lib python2 7 site packages tensorflow python framework ops py line 2708 in as graph element return self as graph element locked obj allow tensor allow operation File home ubuntu tensorflow local lib python2 7 site packages tensorflow python framework ops py line 2768 in as graph element locked graph repr name KeyError The name 'import input' refers to an Operation not in the graph Please suggest me what to do to resolve this Please suggest me if anything wrong from my end,,,2017-08-31 11:25:22,2017-09-04 10:24:31
IS,queue skips first few elements under multiple enqueue threads,Possible problems I want to use tf slice input producer to produce a list of filenames and then use multiple threads to load data and feed it to a tf FIFOQueue It seems first few elements have been skipped unexpectedly It only happens when there exist multiple enqueue threads I have searched the web and only find one similar question on stackoverflow com with zero answer Sorry for creating this issue Maybe I missed something However I really feel deeply puzzled about this and tried a lot to solve this Minimum reproducible example,,ebrevdo,2017-08-30 00:42:35,2017-09-04 15:43:09
IS,tensorflow create myOwn op dll on windows,Hi tf developers I have one request regarding tensorflow is windows version I have tensorflow gpu successfully built on windows 10 with visual studio 2015 from the source code as a result I get tensorflow dll and tensorflow lib I have CUDA8 0 and cudnn 5 0 with a gtx 1080 gpu equipped however my question is not about building and compiling tensorflow it is about creating tensorflow plugins I followed the tutorial to construct my own plug in and then I tried to compile a windows dll so windows would not export symbols automatically for me then I compile a static lib first and used your tools tensorflow contrib cmake tools create def file py to create a def file for me and eventually used that to compile the dll however in my python code when I tried to correlation tf load op library correlation dll and I called correlation correlation with Correlation registered using REGISTER OP Correlation it still tells me AttributeError module '7b088d8b906b36d3e50721b0adbaaa6a' has no attribute 'correlation' I think this is just a windows or cl compiler issue maybe what REGISTER OP Correlation did is just not picked up by the compiler so is there any thing I can do to make this happen on windows,,jart,2017-09-04 21:26:01,2017-09-04 23:13:19
IS,tensorflow is moving too fast could you release it a long term support version,Hi Tensorflow is moving too fast to use my future project could you release it a long term support stable and full version,,yaroslavvb,2017-09-04 07:38:56,2017-09-05 01:25:27
PR,Revert Add vmodule support to TF OSS logging,This reverts commit 072b0c9c552837a97c967963628b3c30951388f9 This is to fix again because got rollbacked Sorry I have to roll back this to fix the Windows build,,"meteorcloudy,learyg,meteorcloudy,gunan,learyg,reedwm",2017-09-04 15:57:04,2017-09-05 03:41:24
IS,computed output size would be negative Node pool 3 AvgPool T DT FLOAT data format NHWC ksize 1 8 8 1 padding VALID strides 1 1 1 1 device job localhost replica 0 task 0 cpu 0 mixed 10 join,python train model and run bazel bin tensorflow python tools optimize for inference input Users andylin Desktop tess retrained graph pb output Users andylin Desktop tess retrained graph optimized pb input names Mul output names final result error computed output size would be negative Node pool 3 AvgPool T DT FLOAT data format NHWC ksize 1 8 8 1 padding VALID strides 1 1 1 1 device job localhost replica 0 task 0 cpu 0 mixed 10 join,,,2017-09-04 12:50:49,2017-09-05 04:26:43
PR,Fix a typo,Fix a typo in comments,,caisq,2017-09-05 07:16:08,2017-09-05 13:29:09
IS,Speech Recognitin issue,Hi While running python tensorflow examples speech commands train py I am getting following issue ImportError cannot import name audio ops Please help,,drpngx,2017-09-05 05:25:00,2017-09-05 15:04:35
PR,MklReshapeOp fix for TensorShape int64 support,MklReshapeOp fix for TensorShape int64 data type,,"mdfaijul,martinwicke",2017-08-30 19:49:19,2017-09-05 15:33:18
PR,add function gradients return none exception,Signed off by um4825 gmail com,,"alextp,alextp,alextp",2017-08-24 08:26:45,2017-09-05 15:41:55
PR,Updating docs to show support for Python 3 6 in Windows 12687,Cherrypicking into r1 3 for docs gen,,"av8ramit,caisq,caisq,av8ramit,av8ramit,martinwicke,gunan",2017-08-29 17:15:19,2017-09-05 15:43:56
PR,Add TensorFlow User Group Utsunomiya into TensorFlow Communities Around the World,We operate TensorFlow User Group Utsunomiya sponsored by GCP Community Support Please add to TensorFlow Communities list,,,2017-08-29 13:31:10,2017-09-05 15:44:25
PR,Mkl filter optimization,This pull request optimizes the MKL convolution backpropagation by avoiding extra filter data conversion,,"mahmoud-abuzaina,nhasabni,martinwicke,nhasabni,tfboyd,vivek-rane,martinwicke",2017-08-28 16:43:26,2017-09-05 15:47:18
PR,delete get started monitors md,This is a copy of cherrypicked onto master The monitors in this doc are not compatible with the core Estimators in the other get started docs This will likely only cause confusion Since AFAIK monitors are deprecated I see no advantage to preserving this doc in api guides If we delete it here I can regenerate the root version of the website without this file I will mirror these changes into master,,"MarkDaoust,martinwicke",2017-08-28 15:29:38,2017-09-05 15:48:05
PR,Removing slightly confusing from output,I found the a bit confusing in the output of import pb to tensorboard py,,daj,2017-08-27 21:50:03,2017-09-05 15:49:39
PR,fix profiler bazel build usage,,,jhseu,2017-08-25 11:24:27,2017-09-05 15:51:23
PR,Double check after regex search for cudnn path in configure py,If chose wrong cuDNN version on linux configure py will throw an exception as shown below This PR add double check after regex search Related PR PTAL,,"ScorpioCPH,yifeif,ScorpioCPH,yifeif,ScorpioCPH,ScorpioCPH,ScorpioCPH,yifeif,ScorpioCPH,yifeif,yifeif",2017-08-25 04:59:17,2017-09-05 16:08:33
PR,remove unused cpu allocator factory,Because MakeCpuAllocator was replaced with cpu allocator so I remove unused MakeCpuAllocator factory method,,"horance-liu,byronyi,yaroslavvb,jhseu,martinwicke",2017-08-25 01:35:24,2017-09-05 16:12:59
IS,tf subtract does not work for uint8 and uint16 images such as PNG,It seems that tf subtract does not support uint8 and unit16 image Could someone please add a PR to enable the uint16 and int16 support for subtraction Thanks,,yongtang,2017-08-24 22:46:04,2017-09-05 16:14:03
PR,Add support of int8 uint8 int16 uint16 for tf subtract,This fix adds support of int8 uint8 int16 uint16 for tf subtract on CPU only This fix fixes 12571 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,yongtang,martinwicke",2017-08-24 23:59:21,2017-09-05 16:14:03
PR,Fix typo Clarify comment,Fix typo in comment Profiler Profile uint64 can be misunderstood as np uint64 So I propose to change it to int This edit is to avoid misusage of tf Profile by a developer using it for the first time See the scenario below 0 He or she follow this instruction L120 from comment 1 He or she may want to pass evaluated global step which type is np int32 to profiler add step 4 BUT TypeError in method 'AddStep' argument 1 of type 'int64' raise again 5 correct answer is to try to convert step as int step,,,2017-09-05 11:12:46,2017-09-05 16:15:04
PR,Fix deprecation warnings of global step functions,In tensorflow contrib layers python layers optimizers py use global step functions from tf train instead of tf contrib framework,,"guillaumekln,jhseu,jhseu",2017-08-24 10:03:08,2017-09-05 16:15:48
PR,Update head py,Update contrib lookup to core lookup,,"alanyee,jhseu,jhseu",2017-08-24 07:03:06,2017-09-05 16:17:38
PR,Fix bug on the gradients graph computation caused by an Assign node C API,The gradient computation in the C API works as follow Let is say that we have the following graph Here our Output is Tanh and our Input is Var The gradient method does a BFS from Var to Tanh to count for each node how many backprop we should expect If a node has two outgoing edges it will be ready only when both would have been backpropagated and the gradient summed In our case Var has 2 Assign 0 MatMul 1 These values are saved into a pending array Then the gradient method does a BFS from Tanh to Var this is the actual backpropagation the error is backpropagated until we reach Var When a Node is reached pending is decreased by one and if pending 0 the Node is ready and is added to the queue of Nodes to be processed If it is not ready it will be reached again in the future and will be ready at some point In our case doing a BFS from Var to Tanh give us 2 expected gradients one from Assign and one from MatMul whereas doing a BFS from Tanh to Var we will reach Var only once because we can not reach Assign from Tanh In that case the pending count will never reach Zero Var will never be ready and the BFS will end At the end a check is done and if pending nodes are still there an error is raised This PR updates the gradient method to ignore nodes that have 0 outgoing edges and are not in the list of Output Tanh is the only one in the list of outputs in our case The unit tests have been updated to use Variable with Assign nodes and not Const because differentiating w r t Const make less sense and the error would have been catched before,,"theflofly,skye,theflofly,skye,skye,skye,skye,skye,skye,skye,skye,skye,skye,skye,skye,theflofly,theflofly,skye,skye,skye,theflofly,skye,theflofly,theflofly,theflofly,theflofly,theflofly,jhseu,theflofly,bpiel,theflofly,skye,martinwicke,bpiel,theflofly,bpiel,theflofly,bpiel,theflofly,martinwicke,bpiel,theflofly",2017-08-18 15:51:27,2017-09-05 16:22:24
PR,Add SerializeTensor operator,The opposite of ParseTensor this operator takes a tensor as input and outputs a serialized TensorProto,,"asimshankar,vrv,vrv,vrv,vrv,vrv,vrv,rmlarsen,jhseu,jhseu,jhseu,martinwicke,martinwicke,vrv,martinwicke",2017-08-03 07:49:27,2017-09-05 16:28:43
PR,Add name of C source file to generated Python files for ops,While tracing back through the Python logging APIs to find their implementation I ran into a dead end at the generated file gen logging ops py This generated file contains no information about where it came from It took a fair amount of time poking through Bazel build files to track down the rule that generates this file from the output of a program that is linked against an object file that is produced by compiling logging ops cc Other developers do not seem to have gotten that far for example the reporter who gave up without finding logging ops cc This PR adds the name of the original C source file to the generated Python files for built in operators I have modified python op gen main cc to check whether it is running from one of the special executables that the Bazel build creates for these internal operators If the program is running from inside such a rule it generates a header comment with the name of the original C source file Note the last line Original C source file This should be enough information for someone new to the project to track down the implementation of a built in operator I would have preferred to modify the REGISTER OP macro to incorporate information about the original source file in the OpDef itself but doing so would have required modifying op def proto Hence this approach of checking the executable name in python op gen main cc,,"frreiss,josh11b,frreiss,josh11b,frreiss,josh11b,frreiss,asimshankar,josh11b,rmlarsen,jhseu,frreiss,martinwicke,martinwicke",2017-07-21 08:25:26,2017-09-05 16:34:24
PR,Add GPU implementation for tf segment sum,As per 11228 a GPU version of segment sum has been created Performance On a Tesla K40c GPU the following performance tests have been performed The test case sizes are represented using 3 tuples of integers The first two integers correspond to the outer and inner dimension of the input data and the last integer corresponds to the outer dimension of the output data which is also the total number of segments The first three rows of data are obtained by running reductions on float32 input type whereas the last three rows of data are obtained by running reductions on float64 input type We use the GPU version of unsorted segment reduction as the baseline During experiments they share the same input data and outputs are compared for consistency 1024 1024 128 2048 2048 256 4096 4096 512 t unsorted 84 942us 332 12us 1 3170ms t sorted 71 047us 264 16us 1 0391ms speedup 1 20 1 26 1 27 t unsorted 160 69us 594 93us 2 2895ms t sorted 106 94us 395 19us 1 5662ms speedup 1 50 1 51 1 46 Known Limitations We do not check segment id to make sure that they are within 0 num outputs 1 We do not verify that segment id is increasing,,"tjingrant,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,tjingrant,tjingrant,tjingrant,tjingrant,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,tjingrant,zheng-xq,zheng-xq,tjingrant,tjingrant,rmlarsen,rmlarsen,tjingrant,rmlarsen,rmlarsen,zheng-xq,tjingrant,tjingrant,nolanliou,tjingrant,tjingrant,zheng-xq,tjingrant,zheng-xq,tjingrant,martinwicke,tjingrant",2017-07-20 03:39:37,2017-09-05 16:36:08
IS,Bug on the gradients graph computation C API,The gradient computation in the C API works as follow Let is say that we have the following graph Here our Output is Tanh and our Input is Var The gradient method does a BFS from Var to Tanh to count for each node how many backprop we should expect If a node has two outgoing edges it will be ready only when both would have been backpropagated and the gradient summed In our case Var has 2 Assign 0 MatMul 1 These values are saved into a pending array Then the gradient method does a BFS from Tanh to Var this is the actual backpropagation the error is backpropagated until we reach Var When a Node is reached pending is decreased by one and if pending 0 the Node is ready and is added to the queue of Nodes to be processed If it is not ready it will be reached again in the future and will be ready at some point In our case doing a BFS from Var to Tanh give us 2 expected gradients one from Assign and one from MatMul whereas doing a BFS from Tanh to Var we will reach Var only once because we can not reach Assign from Tanh In that case the pending count will never reach Zero Var will never be ready and the BFS will end At the end a check is done and if pending nodes are still there an error is raised The PR updates the gradient method to ignore nodes that have 0 outgoing edges and are not in the list of Output Tanh is the only one in the list of outputs in our case As pointed it out as a comment in the PR there is other cases where there is still a problem I am working on it,,"theflofly,theflofly,theflofly,theflofly",2017-08-23 07:57:21,2017-09-05 16:38:13
PR,Removing extra space,,,"martinwicke,yifeif",2017-09-02 03:34:01,2017-09-05 17:43:08
PR,Update head py,Replace contrib framework with core framework Replace contrib model fn with core model fn,,alanyee,2017-08-26 07:00:52,2017-09-05 19:17:47
IS,Same code runs fine in one machine ValueError in another,I am running a modified version of the LFADS code available at I run the exact same code in two machines in one it works fine in another it throws a ValueError Here are the two tf env txt MY MACHINE CODE WORKS cat etc issue Darwin Daniels MacBook Pro 2 local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 8 1 0 clang 802 0 42 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin Daniels MacBook Pro 2 local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow gpu 1 1 0 tensorflow tensorboard 0 1 2 check for virtualenv False tensorflow import tf VERSION 1 1 0 tf GIT VERSION unknown tf COMPILER VERSION unknown Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi collect sh line 105 nvidia smi command not found cuda libs THE CLUSTER MACHINE THROWS THE VALUE ERROR cat etc issue Linux holmes 3 10 0 327 el7 x86 64 1 SMP Thu Oct 29 17 29 29 EDT 2015 x86 64 x86 64 x86 64 GNU Linux VERSION 7 3 Maipo VERSION ID 7 3 REDHAT BUGZILLA PRODUCT VERSION 7 3 REDHAT SUPPORT PRODUCT VERSION 7 3 are we in docker No compiler c GCC 6 1 0 Copyright C 2016 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux holmes 3 10 0 327 el7 x86 64 1 SMP Thu Oct 29 17 29 29 EDT 2015 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 numpydoc 0 6 0 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH cm shared apps slurm 16 05 8 lib64 slurm cm shared apps slurm 16 05 8 lib64 cm local apps gcc 6 1 0 lib cm local apps gcc 6 1 0 lib64 DYLD LIBRARY PATH is unset nvidia smi collect sh line 105 nvidia smi command not found SOURCE CODE LOGS Here is the log for the error Traceback most recent call last File lfads py line 1014 in optimization grads tf gradients self cost tvars File home anaconda2 lib python2 7 site packages tensorflow python ops gradients impl py line 562 in gradients in grad set shape t in get shape File home anaconda2 lib python2 7 site packages tensorflow python framework ops py line 378 in set shape self shape self shape merge with shape File home anaconda2 lib python2 7 site packages tensorflow python framework tensor shape py line 566 in merge with raise ValueError Shapes s and s are not compatible self other ValueError Shapes 50 and 1 are not compatible I have diffed the files involved to double check that they are the same Can someone point me to what can possibly be happening,,,2017-08-29 06:31:28,2017-09-05 20:05:57
PR,Branch 167604306,,,yifeif,2017-09-05 18:22:48,2017-09-05 20:13:58
PR,adding missing dep on jdk for gen ops bzl,sandboxed builds for this target are broken with the following error external local jdk bin jar cMf bazel out linux gnu x86 opt genfiles tensorflow java ops java op gen sources srcjar C bazel out linux gnu x86 opt genfiles tensorflow java ops external local jdk bin jar error while loading shared libraries libjli so cannot open shared object file No such file or directory I found a similar issue in bazelbuild seems to be the case that this error is produced when a e g the genrule in line 476 is missing the JDK as an input to the action,,"martinwicke,yifeif",2017-09-05 20:11:30,2017-09-05 21:52:49
PR,Branch 167632896,,,gunan,2017-09-05 22:25:26,2017-09-05 23:40:11
PR,Update relaxed onehot categorical py,Fixed default dtype in class documentation,,yifeif,2017-09-05 18:13:00,2017-09-05 23:53:17
IS,android demo UnsatisfiedLinkError exception on app start if build with nativeBuildSystem 'none',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 app build at Android Studio 2 3 3 on Linux Ubuntu 16 04 app tested on Meizu M2 Note Android 5 1 API 22 TensorFlow installed from source or binary Source TensorFlow version use command below Master branch from GitHub Python version 2 7 not used in that case Bazel version if compiling from source 0 5 3 not used in that case CUDA cuDNN version none GPU model and memory none Exact command to reproduce Android Studio Run build gradle Describe the problem With nativeBuildSystem 'none' app exit with UnsatisfiedLinkError exception see log below Quick investigation shows call of env ImageUtils convertYUV420SPToARGB8888 Native Method native method from CameraActivity onPreviewFrame CameraActivity java 113 convertYUV420SPToARGB8888 suppose to be implemented in libtensorflow demo so wich is not created in case of nativeBuildSystem 'none' With nativeBuildSystem 'cmake' libtensorflow demo so created and convertYUV420SPToARGB8888 works fine Quick fix may be obtained by including libtensorflow demo so into JCenter and download it like the TensorFlow Inference Interface package Another solution would be Java implementation of convertYUV420SPToARGB8888 the same as it been done for convertYUV420ToARGB8888 in commit 003deb8 at PR 10771 Refactor and implementation of the camera API 1 it fixes 8736 10771 I start working with that Java implementation of convertYUV420SPToARGB8888 but I do not think I have enough skills to make it At the moment I create Java wrapper for native convertYUV420SPToARGB8888 and make all native methods private to isolate the rest of the Java code from occasional use them url url Would be great if creator of Java implementation of convertYUV420ToARGB8888 can help in porting Java implementation of convertYUV420ToARGB8888 for convertYUV420SPToARGB8888 Source code logs 08 20 13 28 38 212 19058 19058 I TensorFlowInferenceInterface Model load took 1303ms TensorFlow version 1 2 0 08 20 13 28 38 217 19058 19058 I TensorFlowInferenceInterface Successfully loaded model from 'file' 08 20 13 28 38 219 19058 19058 I TensorFlowImageClassifier Read 1001 labels output layer size is 1008 08 20 13 28 38 219 19058 19058 I tensorflow ClassifierActivity Sensor orientation 90 Screen orientation 0 08 20 13 28 38 219 19058 19058 I tensorflow ClassifierActivity Initializing at size 640x480 08 20 13 28 38 223 19058 19058 W tensorflow ImageUtils Native library not found native RGB YUV conversion may be unavailable 08 20 13 28 38 225 19058 19058 E art No implementation found for void org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 byte int int int boolean tried Java org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 and Java org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 3B 3IIIZ 08 20 13 28 38 226 19058 19058 E AndroidRuntime FATAL EXCEPTION main Process org tensorflow demo PID 19058 java lang UnsatisfiedLinkError No implementation found for void org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 byte int int int boolean tried Java org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 and Java org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 3B 3IIIZ at org tensorflow demo env ImageUtils convertYUV420SPToARGB8888 Native Method at org tensorflow demo CameraActivity onPreviewFrame CameraActivity java 113 at android hardware Camera EventHandler handleMessage Camera java 1288 at android os Handler dispatchMessage Handler java 111 at android os Looper loop Looper java 194 at android app ActivityThread main ActivityThread java 5877 at java lang reflect Method invoke Native Method at java lang reflect Method invoke Method java 372 at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 1020 at com android internal os ZygoteInit main ZygoteInit java 815 08 20 13 28 38 265 19058 19058 I Process Sending signal PID 19058 SIG 9,,"ArtsiomCh,andrewharp,ArtsiomCh,ArtsiomCh,andrewharp,andrewharp,ArtsiomCh,ArtsiomCh,andrewharp,ArtsiomCh",2017-08-20 18:12:39,2017-09-06 00:00:58
PR,mnist,,,,2017-09-06 00:55:51,2017-09-06 00:56:03
PR,R1 3,,,,2017-09-06 09:57:59,2017-09-06 09:58:58
IS,problem with optimize for inference,hi I'm using tensorflow 1 3 0 installed via pip with python 2 7 12 Ubuntu 16 04 cuda 8 nvidia 1060 when i try to optimize a custom model trained with tensorflow 1 3 0 with python m tensorflow python tools optimize for inference input saved model pb output opt model pb input names in output names out i get the following error when trying to load the model with tensorflow on android first i thought this would be because of some unsupported ops so i went the optimize for inference way but i guess it looks like a protobuf issue i would appreciate any hint to solve this issue with best regards,,,2017-09-04 16:02:39,2017-09-06 11:48:17
IS,Compilation issue with AVX option,System information OS Platform and Distribution Debian Buster TensorFlow installed from source TensorFlow version commit Python version 3 5 4 Bazel version 0 5 4 CUDA cuDNN version CUDA 8 CuDNN 6 GPU model and memory 2xTesla K80 with 12GB each CPU model Intel Xeon E5 2683 v4 Exact command to reproduce Am I using a wrong command line or is it a bug in the compilation process Thanks in advance for any help,,,2017-09-06 11:09:37,2017-09-06 12:15:33
IS,from tensorflow python ops gen audio ops import,I am trying to follow the steps as per the readme file I get an import error After i inspected the repo i found that gen audio ops is missing under tensorflow python ops package Following is an image which shows the import image Can you please help to get me the said package,,,2017-08-31 06:26:54,2017-09-06 13:35:22
PR,Exported eager API TFE symbols in the dynamic library,Dicussed in 12784,,"eaplatanios,asimshankar,eaplatanios,martinwicke,eaplatanios,martinwicke,martinwicke,eaplatanios,caisq,eaplatanios,caisq,eaplatanios,caisq,eaplatanios,martinwicke",2017-09-03 20:57:17,2017-09-06 13:49:14
IS,The efficiency of sess run,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"yaroslavvb,yaroslavvb",2017-09-05 08:43:40,2017-09-06 17:50:42
IS,Sqeezenet pretrained model,Where can I find the pretrained squeezenet model using CIFAR or image net data sets if possible on tensorflow I would like to use that to re train for some new classes for classification,,drpngx,2017-09-04 07:05:47,2017-09-06 20:46:42
IS,Zero accuracy if shuffle is False in TF Keras ImageDataGenerator,If I use the TF Keras reimplementation tensorflow contrib keras and set the ImageDataGenerator is shuffle param to False I get zero accuracy every time Also this I have just used for the first time the ModelCheckpoint from function to save the best model best model True and wanted to test its performance When the model was saved it said that the val acc was at 83 3 before saving I loaded the model and used the evaluate generator on validation generator but the result for val acc was 0 639 I got confused and used it again and got 0 654 and then 0 647 0 744 and so on Questions are 1 Am I loading the model correctly and if not what did I miss Why is the result so much different 2 Why are the results between different evaluate generator executions different no retraining is happening just shear execution of predict generator multiple times in a row important part of the code ResNet50 fine tuning,,drpngx,2017-09-04 07:26:01,2017-09-06 20:49:21
IS,TensorBoard executed stuck,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Pro 1703 TensorFlow installed from source or binary install binary with GPU version by pip based on Python 3 5 2 TensorFlow version use command below '1 3 0' Python version 3 5 2 Bazel version if compiling from source none CUDA cuDNN version cuda v8 0 cuDNN v6 0 GPU model and memory GeForce GTX 1080 Ti 11GB Describe the problem I am trying to open TensorBoard after running mnist with summaries py source code from the TensorBoard tutorials However After I run tensorboard logdir tmp tensorflow mnist in cmd it stuck and did not showing anything else I try to use tensorboard logdir tmp tensorflow mnist debug and have the same result capture,,"jart,jart",2017-08-29 23:17:26,2017-09-06 20:56:21
PR,modify lambda capture list and prohibit copying objects,1 capture work name done by reference to avoid copying object 2 capture pointer by value and remove reference,,"horance-liu,mrry,martinwicke,mrry",2017-08-29 12:13:48,2017-09-06 23:40:12
IS,Feature Request Read the last batch in Dataset,The programmer guide provides an example of work flow like this filenames var data file1 tfrecord var data file2 tfrecord dataset tf contrib data TFRecordDataset filenames dataset dataset map dataset dataset batch 32 iterator dataset make initializable iterator next element iterator get next Compute for 100 epochs for in range 100 sess run iterator initializer while True try sess run next element except tf errors OutOfRangeError break if we have 33 examples in dataset then we will miss the last example Is there an API to adjust the batch size automatically e g in this case 1 in order to feed all the examples into model,,mrry,2017-09-06 22:01:06,2017-09-07 00:05:32
IS,Wrong error message during compiling,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Amazon Linux 2017 03 TensorFlow installed from source or binary source TensorFlow version use command below release v1 3 0 Python version 3 6 2 Bazel version if compiling from source 0 5 4 CUDA cuDNN version CUDA 7 5 cuDNN 5 1 10 GPU model and memory Tesla K80 Exact command to reproduce remove patch command and try to compile Describe the problem There is a wrong error message when you try to compile TensorFlow without patch command installed It is not a big deal but could take a couple of hours to figure it out Source code logs ERROR home ec2 user workplace tensorflow tensorflow tools pip package BUILD 100 1 no such package ' boringssl ' Traceback most recent call last File home ec2 user workplace tensorflow tensorflow workspace bzl line 116 apply patch repo ctx repo ctx attr patch file File home ec2 user workplace tensorflow tensorflow workspace bzl line 107 in apply patch execute and check ret code repo ctx cmd File home ec2 user workplace tensorflow tensorflow workspace bzl line 91 in execute and check ret code fail Non zero return code 1 when Non zero return code 256 when executing 'patch p1 d home ec2 user cache bazel bazel ec2 user 4ee13f1db5bfc278f4537815cf99cd27 external boringssl i home ec2 user workplace tensorflow third party boringssl add boringssl s390x patch' Stdout Stderr java io IOException Cannot run program patch in directory home ec2 user cache bazel bazel ec2 user 4ee13f1db5bfc278f4537815cf99cd27 external boringssl error 2 No such file or directory and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted,,"drpngx,facaiy,facaiy,drpngx",2017-09-05 14:14:40,2017-09-07 01:29:06
PR,BLD precheck patch command before invoked,The PR is opened to fix 12821 How to test I have no idea how to test,,"facaiy,facaiy,yifeif,yifeif",2017-09-06 05:46:13,2017-09-07 01:29:06
PR,R1 3,,,yifeif,2017-09-07 01:05:28,2017-09-07 01:37:09
PR,memory mapped file,This uses a FileChannel to map the model file for slightly faster IO Because of the difficulty with assets in android the files must be copied outside of the apk first and then read in I did not include that part deciding it would be the onus of the parent application ctx getFileStreamPath model is called in a static factory alongside what is already there for backward compatibility This means files must have been copied to the internal storage per ctx getFilesDir Also it passed in the Application for context taking care to recreate it as needed for reclaimed memory This is a preliminary example of what could be changed I am disappointed that the mmap implementation in Java is very limited The byte of array is not written to work with MappedByteBuffer oddly and asking for loaded state with load can kick off additional IO calls It is working in my library but I will also continue to improve on it I also plan to add a native jni version as well which makes use of the mmap util to see which runs faster I backed out my static changes and will see if that works in another PR,,yifeif,2017-09-06 02:34:26,2017-09-07 03:01:17
PR,Branch 167800256,,,yifeif,2017-09-07 01:33:20,2017-09-07 05:10:42
PR,R1 3,update,,yifeif,2017-09-07 03:32:14,2017-09-07 05:11:10
PR,Branch 167812735,,,"yifeif,yifeif",2017-09-07 04:36:08,2017-09-07 06:52:57
IS,FailedPreconditionError when restoring initializable iterator with Scaffold in a MonitoredTrainingSession for the second time,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 macOS TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 1 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Context Using initializable iterator with MonitoredTrainingSession because there are stateful lookup ops index table from tensor lookup tables that do not work with one shot iterator initializable iterator is initialized with a tf train Scaffold This does not look like an intended use Statement This does not seem as an intended behaviour What is a better way to use initializable iterator with MonitoredTrainingSession or lookup ops index table from tensor with one shot iterator,,"mrry,mrry,ispirmustafa,ispirmustafa,mrry,ispirmustafa,ispirmustafa,ispirmustafa,ispirmustafa,mrry",2017-09-06 23:37:27,2017-09-07 12:25:52
IS,feature request could tfdbg dump out debug data by specified step range,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 4 BuildVersion 16E195 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 3 0 rc1 1702 g512d3d086' '1 3 0' Python version Python 2 7 13 default Apr 4 2017 08 47 57 Bazel version if compiling from source 0 5 4 homebrew Build time Fri Aug 25 16 55 29 2017 1503680129 CUDA cuDNN version null GPU model and memory null Exact command to reproduce sess dumping wrapper DumpingDebugWrapperSession sess session root dump path log usage False feature request description I find that DumpingDebugWrapperSession in dumping wrapper py L31 dumps debug data for each step which makes the training very slow with hundreds thousands of small files being generated In fact sometimes it is not necessary for us to need the information of all steps to debug So could tfdbg dump out debug data by specified step range Thanks,,caisq,2017-09-04 10:17:33,2017-09-07 13:49:56
IS,tf map fn handles elems differently if it is a list or tuple,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes see below OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below b'unknown' 1 3 0 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version 6 GPU model and memory GTX 1080 8GB Exact command to reproduce Just run the script Describe the problem It seems from some simple experiments that tf map fn behaves differently from what documented according to the specific type of its elems parameter If the parameter is a tuple of tensors the code works If it is a list of tensors however the function is applied to the list itself instead than its elements thus raising an error in the example code I put below Code,,,2017-09-07 14:25:10,2017-09-07 14:47:26
IS,Command 'graph transforms transform graph' not found,i ran the following script since i want to optimise the graph for using in android Im getting the following error Command 'graph transforms transform graph' not found Try 'bazel help',,,2017-07-30 16:27:27,2017-09-07 15:50:24
IS,image classifier error,Source tensorflow for poets 4,,"drpngx,drpngx",2017-09-05 07:19:30,2017-09-07 18:58:31
PR,Make saver test pass on Windows Bazel Build,This is a workaround for,,"meteorcloudy,meteorcloudy,gunan",2017-09-06 11:02:49,2017-09-07 20:04:29
PR,Element wise optimizations,Added MKL element wise ops that utilize eigen ops as their back end Also added an input conversion op that ensures that shapes of both input tensors are compatible same or broadcastable,,"vivek-rane,vivek-rane,tfboyd,vivek-rane,martinwicke,martinwicke,vivek-rane,vivek-rane,tfboyd,tfboyd,vivek-rane,yifeif",2017-08-28 22:34:35,2017-09-07 20:05:58
PR,Install name fix for libtensorflow so,There exists a problem with the built shared library for Mac If ones creates a shared library that depends on libtensorflow so and distributes it in a folder along with libtensorflow so then the Mac linker will failed to load the library unless libtensorflow so is in DYLD LIBRARY PATH This is problematic when libraries are distributed together as a package e g in the context of JNI From what I read online this can be fixed using rpath This is what this patch is about and it seems to work in my experiments,,"eaplatanios,asimshankar,asimshankar,asimshankar,asimshankar,eaplatanios",2017-09-05 13:45:48,2017-09-07 20:07:04
PR,Fix compile nsync sh,compile nsync sh is not workable with android x86 arch here is the fix by replacing arm specific arch option,,"resec,yifeif,yifeif",2017-09-05 06:21:00,2017-09-07 20:07:19
PR,Export C API symbols of pywrap tensorflow internal so on OS X,This follows up 10469 by exporting C API symbols on OS X How This PR widens the lds matching pattern to include the C API symbols as they are mangled on OS X Before this PR the C API symbols are exported in Linux but are hidden in OS X notice the change from t to T i e static to global Why This is important for libraries that use multiple client APIs as described in 7541 My use case is an R package that uses the Python API through rstudio tensorflow and also uses the C API library I build tf graphs using the Python API and run those graphs from R wrapped C code using the C API This already works in Linux and should also work in OS X after this PR Tested Successfully loaded a shared library in R that uses symbols from pywrap tensorflow internal so x Linux x OS X,,"fritzo,martinwicke,fritzo,allenlavoie,fritzo,allenlavoie,yifeif,yifeif,fritzo",2017-09-01 04:40:02,2017-09-07 20:08:21
PR,Add SONAME for Makefile built libtensorflow inference so,Currently if we build our own shared library that depends on Makefile built Tensorflow shared library our built library is linking the Tensorflow library with absolute path So added a SONAME to Makefile built Tensorflow shared library to resolve this problem,,"resec,yifeif",2017-09-06 03:53:56,2017-09-07 20:08:47
PR,Fix typos in contrib estimator extenders py,,,terrytangyuan,2017-09-07 17:40:44,2017-09-07 20:12:14
PR,Fix minor typo in Programmer is Guide docs,Change my row vetor to my row vector in the Tensors guide,,,2017-09-07 07:04:48,2017-09-07 20:16:29
PR,Fix a path in README md,,,yifeif,2017-09-06 23:37:14,2017-09-07 20:18:41
PR,adding missing dep on jdk for gen ops bzl again,Redoing changes in undid by merge,,yifeif,2017-09-07 14:30:35,2017-09-07 20:19:55
PR,Update documentation,Made explicit HTTPS calls,,"alanyee,yifeif,yifeif",2017-09-07 07:06:24,2017-09-07 20:52:11
PR,Fixed 12797 uint8 now has a length,This small change allows tensors of uint8 to be constructed from the Java API I am leaving the new test case of it over in the phase2 PR 11535 because that test case relies on other changes to Tensor create,,"andrewcmyers,asimshankar",2017-09-07 19:06:38,2017-09-07 21:15:06
IS,UINT8 is used but only partly supported in the Java API,The datatype uint8 exists in the Java API see DataType UINT8 and is used by the LabelImage program However it does not seem to be fully supported In particular elemByteSize in tensor jni cc does not have a case for TF UINT8 which prevents uint8 tensors from being created or extracted from TensorFlow,,"andrewcmyers,drpngx,asimshankar,andrewcmyers",2017-09-04 14:35:59,2017-09-07 21:21:49
PR,Update feature column ops py,Using get variables over model variable,,"alanyee,alanyee,yifeif",2017-08-27 07:21:31,2017-09-07 21:30:43
IS,InvalidArgument error with tf scan,System information No custom code Error encountered on Windows 10 and CentOS 6 7 binary TF 1 1 0 and 1 2 1 respectively 3 6 CUDA 8 0 CUDNN 5 1 GeForce 940MX 2GB ran out of memory in execution Titan X 12 GB Describe the problem I encountered this error when using tf scan on an MultiRNNCell InvalidArgumentError see above for traceback Max scatter index must be array size 141 vs 141 Source code logs If you look here L1072 url It seems that the condition is not consistent with the error message,,yongtang,2017-08-18 19:36:46,2017-09-07 21:44:00
PR,Fix incorrect error message in TensorArray scatter,This fix tries to fix the issue raised in 12403 where the error message in TensorArray scatter is incorrect Specifically in The array size in error message should be array size as the maximum value of index 0 based should always be smaller than array size This fix fixes 12403 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,yifeif",2017-09-04 16:46:40,2017-09-07 21:44:00
PR,MKL build broken Proposed fix here,The CPU version of TensorFlow was not building because the MKL was broken it was broken because a merge conflict somehow made it all the way through to here See diff,,,2017-09-07 22:23:12,2017-09-07 22:49:05
PR,Fix dtype for streaming confusion matrix,Currently dependents of streaming confusion matrix do not actually work correctly with floating point weights,,"taion,taion,alextp,alextp,taion,taion,taion,martinwicke,taion,taion,martinwicke,taion,martinwicke,taion,martinwicke,taion,alextp,alextp,taion,taion,alextp,alextp,martinwicke,martinwicke",2017-08-30 22:20:39,2017-09-07 23:00:22
PR,Fix broken link in Estimators,Move Estimators to beginning of Prog Guide Change title of Datasets unit PiperOrigin RevId 167314186,,"av8ramit,av8ramit",2017-09-07 21:50:46,2017-09-07 23:46:47
PR,Verbs fix Removed Dependency on Duplicate Recv Flag,This PR is a response for 11825 I have added a new Queue and Table for the RdmaTensorBuffer where the relevant information from the send recv waiter table is stored in case the actual rdma write does not occur If the allocated buffer is too small or busy When we get a RDMA MESSAGE BUFFER RESPONSE or RDMA MESSAGE BUFFER IDLE we check the new queue table instead of checking the waiter table This happens in the new ReSendNextItem function Also added a new function that generates the callback lambda function to avoid code redundancy The result is that the code is less clean I am open to suggestions on making it more tidy,,"yanivbl6,yanivbl6,yanivbl6,martinwicke,yifeif",2017-08-30 10:30:33,2017-09-07 23:48:11
PR,Conv2DGrad MaxPoolGradHelper,Gradients for the nn ops Conv2D and MaxPool Ported from python L457 These are simple enough that I grouped them into a single PR I can split into two if necessary cc,,"bpiel,suharshs,bpiel,bpiel,martinwicke,martinwicke,martinwicke,martinwicke",2017-08-28 23:54:36,2017-09-07 23:52:06
IS,Error in tf contrib layers batch norm when center False data format 'NCHW' and zero debias moving mean True,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 3 4 3 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory Tesla P100 16 gb Describe the problem Batch norm layer fails with an error when both center False data format 'NCHW' and zero debias moving mean True arguments are used It looks like the solution would be just adding additional if to check if beta is None in the same way it is done for gamma but maybe there are some more dependencies Source code logs The following code could be used to reproduce the issue,,reedwm,2017-07-21 19:55:12,2017-09-07 23:53:50
PR,Fix issue in batch norm,Fix issue in batch norm where center False data format 'NCHW' and zero debias moving mean True and add a test case for it This fix closes 11673,,"yongtang,yifeif",2017-09-07 02:27:53,2017-09-07 23:53:50
PR,Removed unused imports in layers modules,,,"yardstick17,yifeif,yardstick17,yifeif,yifeif,yifeif,yifeif",2017-09-06 12:27:41,2017-09-07 23:54:52
PR,remove temp variable,1 I remove temp variable and return it directly 2 using auto deduction,,"horance-liu,jhseu,horance-liu,martinwicke",2017-08-24 03:57:20,2017-09-07 23:55:37
IS,BUG indices 0 0 1 is out of bounds for OneHotColumn,Describe the problem For sparse column with keys out of vocabulary feature values is 1 by default However 1 is invalid index when sparse tensor is converted to tensor in one hot column Source code logs code,,"facaiy,facaiy",2017-08-25 05:14:18,2017-09-07 23:56:15
PR,Fix indices is out of bounds in OneHotColumn,The PR is opened to fix 12583 CF pr 12638 What changes were proposed in this pull request slice weighted column to get rid of 1 index How was this patch tested x add unit tests pass all tests,,"facaiy,facaiy,facaiy,martinwicke,martinwicke,martinwicke,facaiy",2017-08-25 05:16:38,2017-09-07 23:56:15
PR,XLA Add a check to the HLO verifier for badly formatted Broadcasts,This adds a check to the HloVerifier which ensures that the Hlo Broadcast instructions are formatted correctly Since they are different from the UserComputation broadcast instructions and therefore the XLA docs examples of invalid instructions were appearing in the repo Also fix up the two cases where the code was creating invalid broadcasts,,"DavidNorman,jpienaar,DavidNorman,martinwicke,martinwicke,DavidNorman,jpienaar,DavidNorman,DavidNorman,jpienaar,jpienaar,martinwicke,gunan",2017-08-26 12:51:31,2017-09-08 00:04:36
PR,Add maxout op to tf contrib layers,Hey I just wanted to activate this PR 5528 Ported maxout layer from 5528 Improved documentation Created test units Could someone please review this one Thanks,,"alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,martinwicke,alextp,martinwicke,alextp",2017-07-27 18:31:24,2017-09-08 00:23:20
PR,Addn mklml kernel,This branch contains the implementations for Intel MKL AddN kernel While the number of inputs are two tf add n will call the MKL AddN kernel if compiled with MKL,,"jinghuangintel,martinwicke,martinwicke,jinghuangintel,yifeif",2017-08-29 20:47:46,2017-09-08 00:30:21
IS,ant 1234,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-08 00:44:20,2017-09-08 00:45:00
PR,PREP migrate lgamma gradient to c side,It is my first attempt to contribute to C side Hence the PR is opened early to get feedback What changes were proposed in this pull request Migrate the implementation of Lagmma from python side to c side see 12686 How was this patch tested x add unit tests pass all tests,,"facaiy,facaiy,kbsriram,kbsriram,facaiy,facaiy,facaiy,facaiy,suharshs,facaiy,facaiy,kbsriram,yifeif,facaiy,suharshs,facaiy",2017-08-31 04:03:16,2017-09-08 00:50:25
IS,Tensorflow gpu build error,I am getting the following error when building Cuda enabled Tensorflow ERROR home ubuntu tensorflow tensorflow stream executor BUILD 39 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 tensorflow stream executor cuda cuda dnn cc In instantiation of 'cudnnStatus t perftools gputools cuda w rap WrapperShim cudnnSetRNNDescriptor operator perftools gputools cuda CUDAExecutor Args wit h Args cudnnRNNStruct int int cudnnDropoutStruct cudnnRNNInputMode t cudnnDirectionMode t cudnnRN NMode t cudnnDataType t ' tensorflow stream executor cuda cuda dnn cc 1017 50 required from here tensorflow stream executor cuda cuda dnn cc 139 46 error cannot convert 'cudnnRNNStruct ' to 'cudnnHandle t aka cudnnContext ' for argument '1' to 'cudnnStatus t cudnnSetRNNDescriptor cudnnHandle t cudnnRNNDescr iptor t int int cudnnDropoutDescriptor t cudnnRNNInputMode t cudnnDirectionMode t cudnnRNNMode t cudn nRNNAlgo t cudnnDataType t ' cudnnStatus t retval name args I installed Cuda 8 0 61 latest with cudNN 7 0 latest stable It is my first time building tensorflow for the GPU so any explanation of the error would be great Edit Found the answer 12052,,,2017-09-08 00:49:49,2017-09-08 01:11:09
PR,android demo fix issue 12431 Java implementation of YUV420SP to ARGB8888 converting,This PR fix issue 12431 Java implementation of ImageUtils convertYUV420SPToARGB8888 made and refactoring for Java implementation of ImageUtils convertYUV420ToARGB8888 made as well Despite the fact that code looks a bit 'nuddle style' that was made for efficiency reasons Breaking down it into few more readable functions like it was made before at ImageUtils convertYUV420ToARGB8888 lead into 3 time function execution increase Previous implementation of ImageUtils convertYUV420ToARGB8888 cause invocation inside double nested circles 307200 times 640x480 of YUV2RGB function and three times more convertByteToInt with Math min and Math max functions Total costs of classification at TF Classify was around 3000 ms on my test device Meizu N2 API 22 Proposed implementation drops it down to 1000 1100 ms which is comparable with native C implementation from libtensorflow demo so 700 ms,,"ArtsiomCh,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,ArtsiomCh,andrewharp",2017-08-26 23:04:39,2017-09-08 01:36:09
PR,remove unused code it does not happen,I remove some implements for GetDeviceLocalityAsync because it does not happen,,"horance-liu,mrry,byronyi,byronyi,byronyi,martinwicke,gunan",2017-08-23 01:07:31,2017-09-08 03:25:27
PR,SVD operation on the GPU,This merge request implements the SVD on the GPU using cuSolver We are building a sparse Gaussian Mixture Model using Tensorflow and for that we need the SVD and determinant computation see another merge request Since these operations were not implemented on the GPU yet and the communication resulted in a large overhead I implemented them on the GPU The SVD is implemented using cuSolver cuSolver however has the downside of only supporting matrices with m n The CPU Version of SVD supports also matrices with m n So this kernel throws an error when matrices with m n are passed and notifies the user to explicitly switch to the CPU kernel,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,martinwicke,rmlarsen,rmlarsen,rmlarsen,rmlarsen",2017-07-30 07:28:27,2017-09-08 03:28:42
PR,Branch 167933991,,,"yifeif,terrytangyuan,yifeif",2017-09-08 00:48:05,2017-09-08 04:08:50
IS,Unable to install tensorflow 1 0 0,I have been trying to install tensorflow 1 0 0 using pip in Anaconda environment I found the below error while installation I have seen previous posts in github and stackover flow but I could not find the solution C Users naresh kumar AppData Local Continuum Anaconda3 C Users naresh kumar pip install ignore installed upgrade pip 9 0 1 python 3 6 1 Anaconda 4 3 21 Please help me out how to solve this issue,,gunan,2017-09-06 11:06:49,2017-09-08 05:26:00
IS,bazel error,ERROR Users dile tensorflow third party py numpy BUILD 11 1 no such package ' local config python ' Traceback most recent call last File Users dile tensorflow third party py python configure bzl line 310 create local python repository repository ctx File Users dile tensorflow third party py python configure bzl line 268 in create local python repository get python bin repository ctx File Users dile tensorflow third party py python configure bzl line 166 in get python bin get env var repository ctx PYTHON BIN PATH No File Users dile tensorflow third party py python configure bzl line 49 in get env var python configure fail ' s' environment variable is n File Users dile tensorflow third party py python configure bzl line 37 in python configure fail fail sPython Configuration Error Python Configuration Error 'PYTHON BIN PATH' environment variable is not set and referenced by ' third party py numpy headers' ERROR Analysis of target ' tensorflow examples image retraining retrain' failed build aborted,,"drpngx,gunan",2017-09-05 15:28:54,2017-09-08 05:28:40
IS,uploads tensorflow as follow error,uploads tensorflow as follow error ImportError numpy core multiarray failed to import Failed to load the native TensorFlow runtime See common installation problems Thank you for your help,,gunan,2017-08-31 07:42:47,2017-09-08 05:30:23
IS,The installation instructions not updated for latest Mac OS X,Please update instructions ML engineers dont have time to waste spending on configurations,,"gunan,gunan",2017-08-31 00:36:38,2017-09-08 05:31:32
IS,The predict results using java and python is different,My graph contains the following statements tf contrib layers batch norm incoming is training is training scale True decay 0 99 tf contrib layers dropout incoming keep prob keep prob is training is training When the variable is training is set to True the saved model give the same result using Java and Python The result is right But when the variable is training is set to False the saved model give different result using Java and Python Python give a right result Java give a wrong result Why does this happen Tensorflow 1 2 0 OS centos7 Java Sun jdk 1 8 0 144 Python 3 4 5,,"drpngx,asimshankar",2017-09-05 06:34:41,2017-09-08 07:51:25
IS,mlocate should be denpendency,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 docker centos 7 TensorFlow installed from source or binary source TensorFlow version use command below r1 2 Python version 2 7 5 Bazel version if compiling from source 0 5 3 CUDA cuDNN version none GPU model and memory none Exact command to reproduce configure Describe the problem mlocate command should be claimed as a dependency in your installation instruction,,"gunan,vivek-rane,gunan",2017-08-10 08:30:13,2017-09-08 09:30:28
PR,add args of TimeReversedFusedRNN,I want to use TimeReversedFusedRNN together with LSTMBlockFusedCell but the batch axis of LSTMBlockFusedCell is input is 1 but not 0 But the reverse function of TimeReversedFusedRNN can not decide which is batch axis just do array ops reverse sequence t lengths 0 1 So I think it is useful that users can tell it which is batch axis and seq axis,,"rmlarsen,ebrevdo,ebrevdo",2017-08-07 11:03:59,2017-09-08 10:12:07
IS,Unable to compile TF 1 3 from source using full MKL,Steps to reproduce git clone test cd test git checkout r1 3 yes TF NEED CUDA 0 TF NEED MKL 1 TF DOWNLOAD MKL 0 MKL INSTALL PATH path l mkl 2017 3 196 inst mkl configure bazel build config mkl c opt verbose failures tensorflow tools pip package build pip package OS version Ubuntu Linux 14 04 Bazel version 0 5 3 Error message ERROR missing input file ' third party mkl libmklml intel so' ERROR path tensorflow test third party mkl BUILD 16 1 third party mkl intel binary blob missing input file ' third party mkl libmklml intel so' Target tensorflow tools pip package build pip package failed to build ERROR path tensorflow test third party mkl BUILD 16 1 1 input file s do not exist The configure script is creating symlinks in third party mkl for libmkl rt so see here L260 which is fine but not for libmklml intel so see here L264 which does not exist in the full MKL distribution However third party mkl BUILD references libmklml intel so L20 Is this a bug or is use of the full MKL library not supported in TensorFlow 1 3,,"drpngx,gunan,gunan",2017-09-06 12:07:55,2017-09-08 11:34:00
IS,Generators in graphs,I am wondering is there any way to place a generator in a graph that would push values to lower parts of graph or asynchronous operations of this kind should be always placed outside of tensorflow graphs,,rohan100jain,2017-09-08 11:27:19,2017-09-08 16:23:47
PR,Branch 167998450,,,"caisq,yifeif,chihuahua",2017-09-08 15:33:26,2017-09-08 16:42:14
IS,C gradients data flow ops,This set has just two ops to port DynamicStitch and DynamicPartition Anyone already working on it Otherwise I will sign up for this cc,,kbsriram,2017-09-06 23:15:17,2017-09-08 16:43:24
PR,Do not check patch command on Windows,Fix Windows build,,"meteorcloudy,yifeif",2017-09-08 08:07:24,2017-09-08 16:45:29
PR,docs Fix link to tf estimator DNNLinearCombinedRegressor,,,yifeif,2017-09-08 13:02:05,2017-09-08 16:50:55
PR,Fixed typo in tf metrics docs,,,yifeif,2017-09-08 15:49:16,2017-09-08 16:52:11
PR,Update metrics op py,Using core method over private,,"alanyee,yifeif",2017-08-25 07:03:06,2017-09-08 17:31:16
PR,Safely read content from InputStream,Changed to use ByteArrayOutputStream on converting InputStream into byte instead of relying on InputStream available available The old way may cause problem in cases like reading from buffered input stream or a network stream,,"resec,asimshankar,asimshankar,resec,asimshankar,asimshankar,resec,yifeif,resec,yifeif,resec,resec,yifeif,resec",2017-08-28 06:06:42,2017-09-08 18:04:40
PR,Load op library fix,This fixes the issue with external bindings to TensorFlow loading custom op libraries It does so by exporting all the relevant symbols in libtensorflow so Note that these symbols were there but they were hidden and we could not link to them previously Currently with this fix developers of custom op libraries can link at compile time using libtensorflow so thus avoiding the need for undefined dynamic lookup on Macs which also currently does not work as a solution on its own and the need for loading with RTLD GLOBAL which also does not work on its own given that pywrap tensorflow so needs to be loaded with that flag given it is the own exporting the necessary symbols I have tested this on my mac and it resolves the issue I know this is not really a good solution given that you probably do not want to export everything in libtensorflow so but I think it offers a good temporary workaround to the issue until the fix is working on is published P S This issue has been discussed a bit in 12895,,"eaplatanios,asimshankar,eaplatanios,asimshankar,eaplatanios,asimshankar,allenlavoie,eaplatanios",2017-09-08 17:25:58,2017-09-08 18:19:01
PR,Corrected description of what padding SAME does,The description read that the padding SAME adds zeros to the output tensor It should say that it pads the input tensor,,,2017-09-08 18:10:22,2017-09-08 18:52:08
PR,Add batch layer normalization support in DNNClassifiers,,,"yifeif,ispirmustafa",2017-09-08 07:17:03,2017-09-08 19:26:22
IS,bazel error related to python,bazel build tensorflow examples image retraining retrain ERROR home dile tensorflow third party py numpy BUILD 11 1 no such package ' local config python ' Traceback most recent call last File home dile tensorflow third party py python configure bzl line 310 create local python repository repository ctx File home dile tensorflow third party py python configure bzl line 268 in create local python repository get python bin repository ctx File home dile tensorflow third party py python configure bzl line 166 in get python bin get env var repository ctx PYTHON BIN PATH No File home dile tensorflow third party py python configure bzl line 49 in get env var python configure fail ' s' environment variable is n File home dile tensorflow third party py python configure bzl line 37 in python configure fail fail sPython Configuration Error Python Configuration Error 'PYTHON BIN PATH' environment variable is not set and referenced by ' third party py numpy headers' ERROR Analysis of target ' tensorflow examples image retraining retrain' failed build aborted INFO Elapsed time 4 555s FAILED Build did NOT complete successfully 0 packages loaded currently loading tensorflow core 3 packages Operating system is ubuntu and i dont know how to run configure what and all i have to select in that,,,2017-09-08 10:06:26,2017-09-08 20:12:55
IS,Eager API symbols not exported in the CI libtensorflow so,The eager API symbols i e TFE do not seem to be exported in the libtensorflow so built by the CI system I tried the nightly builds and they are missing from them I checked using nm D libtensorflow so as well as readelf Ws libtensorflow so and objdump TC libtensorflow so I'm not sure where to look to fix this though as the Mac nightly build seems fine,,"eaplatanios,asimshankar,eaplatanios,eaplatanios,eaplatanios",2017-09-03 20:41:15,2017-09-08 21:00:12
IS,Eager execution with string tensors,alextp String tensors seem to cause lots of errors for me when using the eager execution API that do not occur when using normal ops and executing them using a session The way I'm creating string tensors is by allocating a TF Tensor with the right data type shape and size where I use TF StringEncodedSize to get the byte sizes of each element Then I encode the strings using TF StringEncode and write them in the tensor buffer along with the offset table as described here L211 Afterwards I call TFE NewTensorHandle to get an eager tensor handle and I delete the TF Tensor object This works fine for normal op construction and execution using sessions but it fails for eager execution Often I get a check failed IsAligned error from tensor cc but other times the whole application crashes such as in the example that follows,,"eaplatanios,eaplatanios,alextp,eaplatanios,eaplatanios,asimshankar,eaplatanios,eaplatanios",2017-08-26 04:58:35,2017-09-08 21:12:48
PR,First base version of snapcraft yaml Work in progress DO NOT MERGE,I'm following the instructions from I'm using this as a tutorial,,"av8ramit,saeta,gunan,gunan,av8ramit,av8ramit",2017-08-26 00:12:44,2017-09-08 21:41:23
IS,BUG unexpect results when run init with assign,,,ppwwyyxx,2017-09-07 01:43:13,2017-09-08 23:42:31
PR,mmap file,I added a memory mapped file option for the model file Since the model files have to be copied out of the apk due to assets directory readonly status and inability to create the FileChannel directly it is assumed that you have done so to internal storage with the same context that is passed into the overloaded constructor Internal storage eliminates problems of SD card not being present or M runtime permissions requests but is also in danger of being full etc Expansion files are the only other option but this requires a download from the play store which is an extra step I therefore did the most simple thing,,"andrewharp,andrewharp,andrewharp,yifeif,andrewharp",2017-09-07 18:58:41,2017-09-08 23:57:29
IS,python wrapper around libtensorflow,I wish to use tensorflow as a standalone library I have libtensorflow so How do I bridge it to python so I can use it for standalone purpose or is there any github repo for the same,,,2017-09-07 11:04:09,2017-09-08 23:58:27
IS,Are there any predefined image format image size etc for training using your tutorial I found some error for several times such as No image found in category validation division by zero problem,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-09-07 12:14:24,2017-09-08 23:59:07
IS,Is it a bug of tf map fn,Look at the code Is it a bug If you want to know more llo at the discussion on stackoverflow,,"yongtang,ppwwyyxx",2017-09-07 14:21:24,2017-09-09 00:00:17
IS,autoconf error when running build all ios sh,When running the build all ios sh script on iOS I am getting the following error autoreconf f i Wall no obsolete configure ac 30 error possibly undefined macro AC PROG LIBTOOL If this token and others are legitimate please use m4 pattern allow See the Autoconf documentation autoreconf usr local Cellar autoconf 2 69 bin autoconf failed with exit status 1 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Not getting to the point of running code OS Platform and Distribution e g Linux Ubuntu 16 04 OSX High Sierra TensorFlow installed from source or binary Source TensorFlow version use command below Python version Python 2 7 10 Bazel version if compiling from source release 0 5 4 homebrew CUDA cuDNN version GPU model and memory NVIDIA GeForce GT 750M 2GB Exact command to reproduce tensorflow contrib makefile build all ios sh,,drpngx,2017-09-08 23:24:28,2017-09-09 00:04:15
PR,Changed number to float in documentation example Get Started in order to be consistent,Stumbled upon this while going through the Get Started added a dot to the 7 to make clear it is a float like every other number,,yifeif,2017-09-08 22:06:27,2017-09-09 00:12:14
IS,Input streaming data to tensorflow,Can you please reccommend a way to input streaming data which comes in json format to tensorflow,,mrry,2017-09-08 09:31:05,2017-09-09 00:12:16
IS,typo in config py line 688,Currently is note the extra space in the current version,,"yifeif,yifeif",2017-09-02 00:39:06,2017-09-09 01:54:42
PR,Elastic Average optimizer,I have implemented a new distributed optimizer ElasticAverageOptimizer It is mentioned in the following issue 12472 issuecomment 327976993 EASGD is an async optimizer During the training Each worker will update the local variables and maintains its own local step which starts from 0 and is incremented by 1 after each update of local variables Whenever the communication period divides the local step the worker requests the current global center variables and then computed the elastic difference between global center variables and local variables The elastic difference then be used to update both local variables and global variables Reference,,,2017-09-09 03:23:51,2017-09-09 04:21:40
IS,RFE tensorboard provide a File Open like UI for saved model pb files,This was originally solicited as by but got derailed with a very nice tools contribution from The original request would still imo make for a nice addition to tensorboard specifically were the UI of a running instance of TB to have something akin to a File Open function to load a saved model pb file users who were tasked with the use case of person gives them a saved model to inspect would appreciate it,,gunan,2017-09-09 03:23:18,2017-09-09 04:37:50
IS,error when giving this command bazel bin tensorflow examples image retraining retrain image dir home dile dataset dosa,Traceback most recent call last File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow examples image retraining retrain py line 108 in module import tensorflow as tf File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow init py line 24 in module from tensorflow python import File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow python init py line 63 in module from tensorflow python framework framework lib import File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow python framework framework lib py line 76 in module from tensorflow python framework ops import Graph File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow python framework ops py line 28 in module from autograd import core as ag core ImportError No module named autograd,,,2017-09-09 04:43:16,2017-09-09 05:53:32
PR,Reverse change eb75ded6 so that internal tests will pass,As support for int64 global steps is not ready in TPUs I am reversing this change so that our internal performance and regression tests will pass,,"frankchn,frankchn",2017-09-09 07:14:11,2017-09-09 17:03:19
PR,Corrected hyperlink for audio training tutorial,,,yifeif,2017-09-09 00:16:48,2017-09-09 17:06:25
IS,Reading float value from tfrecord return a not same value,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 6 2 Continuum Analytics Inc Describe the problem When i read feature label with float type from tfrecord it return not same value Example 3 3 3 29999995 3 7 3 70000005 4 9 4 9000001 Here code make Example Some one can help me Plzz told me some ways to fix it,,"martinwicke,martinwicke,martinwicke",2017-09-07 11:06:05,2017-09-09 18:29:58
IS,Error building freeze graph,I am trying to build freeze graph with bazel like this bazel build tensorflow python tools freeze graph and I am getting this error I installed bazel from scratch but did not give a solution Any suggestions on that bazel version Build label 0 5 4 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Aug 25 10 00 00 2017 1503655200 Build timestamp 1503655200 Build timestamp as int 1503655200 As it turns out I cannot build any script with bazel,,,2017-09-11 10:49:59,2017-09-11 11:59:20
IS,does new dataset api support pre read data,I found that currently dataset api does not support pre read data as old reading data api If we have so much train data the feature the speed of reading data is critical,,"mrry,mrry",2017-09-11 09:15:22,2017-09-11 14:45:51
IS,AttributeError 'NoneType' object has no attribute 'get tensor by name',I trained mnist model and then create one pb file by freeze that model then i want to load this freeze model so my code is for load the freeze graph import tensorflow as tf import argparse from tensorflow python platform import gfile def load graph model filename with tf Session as sess model filename 'output graph pb' with gfile FastGFile model filename 'rb' as f graph def tf GraphDef graph def ParseFromString f read g in tf import graph def graph def if name ' main ' parser argparse ArgumentParser parser add argument model filename default results output graph pb type str help model filename to import args parser parse args print 'Loading the model' graph load graph args model filename x graph get tensor by name x 0 y graph get tensor by name op1 0 with tf Session graph graph as sess data np vectorize lambda x 255 x np ndarray flatten scipy ndimage imread C Users HP Desktop digi jpg flatten True result sess run tf argmax y 1 feed dict x data print ' ' join map str result Half of the code is run successfully but in last get the error of no attribute 'get tensor by name'' Loading the model Traceback most recent call last File C Users HP Desktop programs TensorFlow save export fie py line 29 in module x graph get tensor by name x 0 AttributeError 'NoneType' object has no attribute 'get tensor by name' what is issue with my code,,mrry,2017-09-11 05:24:06,2017-09-11 14:52:37
PR,R1 3,,,,2017-09-11 07:19:22,2017-09-11 17:00:56
PR,Added support for JVM callback ops,This PR is a proposed workaround for a limitation related to my Scala API and discussed in 12895 and 12915 Given that we currently cannot load external op libraries through languages other than Python this PR adds a JVM callback op to the main TensorFlow library I understand this is not ideal and may not be acceptable but it is just offered as a possible workaround On the plus side this op is not specific to Scala It allows any JVM language to create ops that call functions in that language The arguments and outputs of such functions are arrays of pointers to eager tensors The only limitation is that the op invocation has access to the original JVM instance that was used when constructing it This is similar to the current py func op limitation though and so should be fine for now Do you think that this is acceptable for now P S The replication of a few lines from the C API code is ugly but I'm not sure what is best to do here and I did not want to introduce more changes until you take a look,,"eaplatanios,asimshankar,eaplatanios",2017-09-09 14:19:47,2017-09-11 17:09:30
IS,Efficient way to load a model over 2GiB with C interface,Hi all When applying TF model with its C interface freeze graph operations for the graph file and the cpk file are required This operation will then generate a dumped binary protobuffer file However protobuffer does not support to dump a file that is larger than 2GiB In this case what is the right way to load a big model in TF with its C interface Any clues will be appriciated Thank you,,"drpngx,reedwm",2017-09-07 10:48:32,2017-09-11 17:16:35
PR,Branch 168186374,,,"yifeif,drpngx",2017-09-11 05:35:51,2017-09-11 17:46:32
IS,ValueError in CTCLoss,TF version 1 1 0 Ubunu 16 04 Cuda 8 0 Cudnn 6 loss tf nn ctc loss targets logits maxT time major False File home ilab anaconda2 lib python2 7 site packages tensorflow python ops ctc ops py line 145 in ctc loss ctc merge repeated ctc merge repeated File home ilab anaconda2 lib python2 7 site packages tensorflow python ops gen ctc ops py line 165 in ctc loss name name File home ilab anaconda2 lib python2 7 site packages tensorflow python framework op def library py line 768 in apply op op def op def File home ilab anaconda2 lib python2 7 site packages tensorflow python framework ops py line 2339 in create op set shapes for outputs ret File home ilab anaconda2 lib python2 7 site packages tensorflow python framework ops py line 1719 in set shapes for outputs shapes shape func op File home ilab anaconda2 lib python2 7 site packages tensorflow python framework ops py line 1669 in call with requiring return call cpp shape fn op require shape fn True File home ilab anaconda2 lib python2 7 site packages tensorflow python framework common shapes py line 610 in call cpp shape fn debug python shape fn require shape fn File home ilab anaconda2 lib python2 7 site packages tensorflow python framework common shapes py line 676 in call cpp shape fn impl raise ValueError err message ValueError Shape must be rank 1 but is rank 0 for 'CTCLoss' op 'CTCLoss' with input shapes 64 23,,reedwm,2017-09-11 06:25:59,2017-09-11 18:15:21
IS,Different confidence with same model pb from android and python,I trained a model pb with python and put it in android well I find the confidence score that in android is always lower than python application on my PC AFAIK for android model pb I did not use DecodeJpeg because it not support on Android Is there anything wrong or different with DecodeJpeg in android example when processing image Trace beginSection preprocessBitmap Preprocess the image data from 0 255 int to normalized float based on the provided parameters bitmap getPixels intValues 0 bitmap getWidth 0 0 bitmap getWidth bitmap getHeight for int i 0 i intValues length i final int val intValues i floatValues i 3 0 val 16 0xFF imageMean imageStd floatValues i 3 1 val 8 0xFF imageMean imageStd floatValues i 3 2 val 0xFF imageMean imageStd Trace endSection,,reedwm,2017-09-11 09:22:22,2017-09-11 18:17:00
PR,Fix minor typo in Programmers guide,Fix However you may also specify a grpc URL to specify the address of a TensorFlow server which gives the session access to all devices on machines that that server controls to However you may also specify a grpc URL to specify the address of a TensorFlow server which gives the session access to all devices on machines that server controls in Graphs and Session,,caisq,2017-09-11 14:45:44,2017-09-11 18:22:23
IS,imagePickerController for iOS not recognize,Hello I have created pb and txt file for some specific images and want to test with same image taking that image from Gallery in iPhone Device and trying to recognise but its not working properly Can you please suggest How we can use tensor flow in Gallery Images what size are required to use it,,,2017-09-04 07:17:03,2017-09-11 18:57:51
PR,Minor wording change in timeseries module is README,,,"terrytangyuan,allenlavoie,terrytangyuan",2017-09-09 18:40:35,2017-09-11 19:46:38
IS,Default keras initializers parameters have changed,At least in Tensorflow 1 3 some of the Keras initializers have changed they default parameters since Tensorflow 1 1 In Tensorflow 1 1 from tensorflow contrib keras python keras initializers import TruncatedNormal TruncatedNormal stddev returns 0 05 In Tensorflow 1 3 from tensorflow contrib keras python keras initializers import TruncatedNormal TruncatedNormal stddev returns 1 I assume this was not intentional since this is a breaking change and I did not see it documented in the release notes,,"reedwm,fchollet",2017-09-11 17:34:23,2017-09-11 19:57:27
IS,Anaconda installation example does not match the description on web site,On this page installing with anaconda Step 4 says where tfBinaryURL is the URL of the TensorFlow Python package For example the following command installs the CPU only version of TensorFlow for Python 2 7 However the example command below it actually installs TensorFlow for Python 3 4 not 2 7 pip install ignore installed upgrade,,"asimshankar,av8ramit,av8ramit",2017-08-18 13:57:50,2017-09-11 20:49:35
IS,config mkl leads to libmklml intel so error undefined reference to wouldladdr',Cloning master 702d595822e9e5f5232b8140c6296683612c33a9 running configure with No throughout and trying to build a pip package Bazel 0 5 4 Ubuntu 16 10 with the new config mkl flag crashes,,"carlthome,reedwm,tfboyd,carlthome,carlthome,tfboyd,carlthome",2017-09-10 23:50:54,2017-09-11 21:01:43
PR,Windows script docs,,,av8ramit,2017-09-11 21:25:04,2017-09-11 21:39:15
IS,I am facing this issue after installing it on Windows 7 32 Bit AMD processor python 3 5 2 TensorFlow 1 0 0,Microsoft Windows Version 6 1 7601 Copyright c 2009 Microsoft Corporation All rights reserved C Users SEM python Python 3 5 2 v3 5 2 4def2a2901a5 Jun 25 2016 22 18 55 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import help er return importlib import module mname File C Users SEM AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed 1 is not a valid Win32 application During handling of the above exception another exception occurred Traceback most recent call last File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python init py line 66 in module from tensorflow python import pywrap tensorflow File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 21 in module pywrap tensorflow swig import helper File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import help er return importlib import module ' pywrap tensorflow' File C Users SEM AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python init py line 72 in module raise ImportError msg ImportError Traceback most recent call last File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import help er return importlib import module mname File C Users SEM AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed 1 is not a valid Win32 application During handling of the above exception another exception occurred Traceback most recent call last File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python init py line 66 in module from tensorflow python import pywrap tensorflow File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 21 in module pywrap tensorflow swig import helper File C Users SEM AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import help er return importlib import module ' pywrap tensorflow' File C Users SEM AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow' Failed to load the native TensorFlow runtime See import error for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"caisq,gunan",2017-09-10 05:48:58,2017-09-11 22:17:43
PR,Update docs symposium,,,"av8ramit,av8ramit",2017-09-11 21:43:52,2017-09-11 23:01:34
IS,About Cyclic Graph,Here is the code that confuses me It outputs different results 1 3 6 and 7 7 is the most at different runs I think it is caused by the cyclic graph I do not know if tf has the constriction that the above graph is not allowed But I have another more common example a convnet with bn img a b convnet with bn img b when the convnet is share the bn' moving average operations is like the above code Can anybody tells me how I can deal with the above problem,,yaroslavvb,2017-09-04 14:27:24,2017-09-12 00:00:57
IS,tensorflow performance issue for map fn and gather,I am trying to understand more about certain surprising results i see in implementing a tf graph The graph i am working with is just a forest bunch of trees This is just a plain forward inference graph and nothing related to training I am sharing the snippets for 2 implementation code snippet 1 with tf name scope main def get tree output offset loop vars offset leaf indice tf while loop cond body loop vars back prop False parallel iterations 1 name while loop tree score tf gather score tensor leaf indice name tree scores output tf add tree score output leaf indices tf map fn get tree output tree offsets tensor dtype INT TYPE parallel iterations n trees back prop False name tree scores tree scores tf gather score tensor leaf indices name tree scores output tf reduce sum tree scores name sum output output tf sigmoid output name sigmoid output code snippet 2 with tf name scope main tree offsets tensor tf constant tree offsets dtype INT TYPE name tree offsets tensor loop vars tree offsets tensor leaf indices tf while loop cond body loop vars back prop False parallel iterations n trees name while loop tree scores tf gather score tensor leaf indices name tree scores output tf reduce sum tree scores name sum output output tf sigmoid output name sigmoid output The rest of the code is exactly the same the constant tensors variables condition and body for the while loop thread and parallelism was also the same in both case code snippet2 takes about 500 micro sec to do inference code snippet 1 take about 12 milli sec to do inference The difference is that in snippet 1 I use map fn to operate on tree offset tensor where as in snippet 2 I get rid of that map fn and just directly use that tensor so as I understand in snippet1 get tree output method gets called with one element from tree offset tensor we are having multiple while loop for each individual offset value whereas in snippet 2 we just have one while loop that just takes multiple offset values basically the offset tensor I also tried another variation for snippet instead of using the map fn I write a hand written for loop code snippet 1 variation for loop output 0 with tf name scope main for offset in tree offsets loop vars offset offset here is a scalar leaf indice tf while loop cond body loop vars back prop False parallel iterations 1 name while loop tree score tf gather score tensor leaf indice name tree scores output tf add tree score output leaf indices tf map fn get tree output tree offsets tensor dtype INT TYPE parallel iterations n trees back prop False name tree scores tree scores tf gather score tensor leaf indices name tree scores output tf reduce sum tree scores name sum output output tf sigmoid output name sigmoid output This gives minor improvement 9 millisec The while condition does a bunch of gather operation so if i use map fn or the for loop the gather operates on a bunch of scalars instead of tensor of offset Why is the code 20 40x slower is the usage wrong or are there any caveats here Any help in understanding or optimizing this is appreciated,,,2017-09-05 06:03:21,2017-09-12 00:04:44
PR,support passing in a source url to the mnist read data sets function,It would be great to be able to pass in an alternate source url to the mnist read data sets function to make it easier to use 'fashion mnist' etc Does this seem like a reasonable way to do it,,,2017-09-11 22:49:41,2017-09-12 01:01:47
PR,Support for CUDA 9 0,For review by xq Add explicit syncwarp to bias op Makes warp synchronous code safe on Volta Add sync mask to shfl intrinsics Add libdevice bytecode paths for CUDA 9 In CUDA 9 all supported architectures are merged into a single file Update code gating for CUDA 9 Add sm 70 to the lookup table used by XLA Change the default sm arch from 20 to 30 Fix for NVPTX not yet supporting sm 70 Remove unnecessary cuda decorators from defaulted constructors Use updated NCCL for CUDA 9 fp16 support,,"nluehr,jlebar,jlebar,jlebar,jlebar,jlebar,zheng-xq,sjperkins,sjperkins,nluehr,jlebar,nluehr,jlebar,nluehr,nluehr,nluehr,nluehr,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,nluehr,Artem-B,jhseu,tfboyd,jthestness,nluehr,zheng-xq,jlebar,jlebar,byronyi,tfboyd",2017-08-22 22:12:59,2017-09-12 01:22:33
IS,tensorflow tensorflow examples ios benchmark Calculate in Images,In this example How we can calculate the of Prediction We are getting 1 0 978 water bottle 1 0 988 bottle 1 0 078 mug type of result How we can convert in value,,,2017-09-05 06:40:31,2017-09-12 04:01:36
IS,Magic name directories prevent to embed the mkl library,For some reasons the build pip package script sues the magic directory solib k8 That directory does not exists if you compile mkl on a vm machine where the libraries are added under solib local,,"Mistobaan,gunan,Mistobaan,gunan,Mistobaan,damienmg,gunan",2017-09-01 00:54:48,2017-09-12 07:47:56
PR,Also accept non k8 CPU types in build pip package,Fixes 12735,,"gunan,drpngx,gunan,drpngx,gunan,drpngx",2017-09-11 17:43:20,2017-09-12 07:47:56
IS,Different corrupted record Issue with TFRecordReader,Hi I am trying to convert some 11 mn features and labels into TFRecords I convert my examples into scipy csr coo and the features are simple 1Dim features I am trying to make a batch of features of 1000 in a csr and I am able to write it into TFRecordWriter The files are generated The problem is when I try to read it using parse example I am trying to create a tensor equivalent to compressed sparse matrix of scipy and I am running into issues I am ONLY trying to test my tensor values using sess run tensor and I am getting this corrupted error I tried to change different reading formats FixedFeature VarLenFeature but no breakthrough corrupted record at 0 Node ReaderReadV2 ReaderReadV2 device job localhost replica 0 task 0 cpu 0 TFRecordReaderV2 input producer Here is how I am trying to parse the TFRecord features 'feature data' tf FixedLenFeature tf string 'feature row' tf FixedLenFeature tf string 'feature col' tf FixedLenFeature tf string 'feature shape' tf FixedLenFeature tf string 'feature dim2' tf FixedLenFeature 1 tf int64 print 'Reader initialized' tfrecord features tf parse single example serialized example features fea data tf decode raw tfrecord features 'feature data' tf int32 fea row tf decode raw tfrecord features 'feature row' tf int32 fea col tf decode raw tfrecord features 'feature col' tf int32 fea shape tf decode raw tfrecord features 'feature shape' tf int32 print 'Parsed example' print type fea data print type fea row ade features tf sparse to dense sparse indices fea row fea col sparse values fea data output shape fea shape sess run ade features Here is how I am trying to write the feature writer tf python io TFRecordWriter filename for index in range features vectors shape 0 for iteration start end in enumerate batches print 'Writing label index ' str index feature batch features vectors start end again a csr feature batch feature batch tocoo label vec labels start end csr label vec label vec tocoo example tf train Example features tf train Features feature 'feature data' self bytes feature feature batch data tobytes 'feature row' self bytes feature feature batch row tobytes 'feature col' self bytes feature feature batch col tobytes 'feature shape' self bytes feature np array feature batch shape np int32 tobytes writer write example SerializeToString writer close I am using tensorflow 1 2 1,,,2017-09-12 07:26:57,2017-09-12 10:20:18
IS,Possible bug in nightly build for Linux gpu,OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS Linux release 7 2 1511 Core TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 rc1 2023 g4af9be9 Python version 3 6 1 Bazel version if compiling from source 0 5 4 CUDA cuDNN version cuda 8 0 cudnn 5 1 5 GPU model and memory Titan X Maxwell Titan X Pascal The compilation fails with the following error On the TensorFlow GitHub page it shows that the nightly build is passing I am confused by this,,,2017-09-12 02:17:02,2017-09-12 15:02:06
IS,data format NCHW did not work for tf nn max pool,In 78 x2 tf random uniform 64 3 32 32 In 79 x2 pool tf nn max pool x2 1 3 3 1 1 2 2 1 padding VALID data format NHWC In 80 x2 pool shape Out 80 TensorShape Dimension 64 Dimension 1 Dimension 15 Dimension 32 In 81 x2 pool tf nn max pool x2 1 3 3 1 1 2 2 1 padding VALID data format NCHW In 82 x2 pool shape Out 82 TensorShape Dimension 64 Dimension 1 Dimension 15 Dimension 32,,,2017-09-12 16:08:40,2017-09-12 16:51:57
PR,error while validating the installation of tensorflow,When I try to validate installation following error occur How can I solve this error Traceback most recent call last File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users omkar AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users omkar AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File pyshell 0 line 1 in module import tensorflow as tf File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users omkar AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users omkar AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users omkar AppData Local Programs Python Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"drpngx,drpngx",2017-09-12 16:12:28,2017-09-12 17:17:07
PR,Correct minor typo in substr docs example,This fixes a very minor typo Python strings should be started and ended with same character Shows up at error in doc webpage This was raised at by,,,2017-09-12 06:31:13,2017-09-12 17:20:15
PR,fix ExponentialMovingAverage documentation regarding control dependencies,This PR fixes the documentation for ExponentialMovingAverage so that ema apply var0 var1 is evaluated within tf control dependencies opt op The documentation for ExponentialMovingAverage contains the following code,,,2017-09-12 03:06:44,2017-09-12 17:24:19
PR,Add a missing template explicit instantiation of SetZeroFunctor,To fix a build error on Windows,,"snnn,rmlarsen,rmlarsen,rmlarsen,rmlarsen,drpngx,snnn,gunan,rmlarsen,gunan",2017-09-04 09:19:43,2017-09-12 17:36:25
IS,android tensorflow libtensorflow so build fails due to missing build target,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below master Python version 3 6 2 Bazel version if compiling from source 0 5 4 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Full build,,"andrewharp,andrewharp,andrewharp",2017-09-12 04:29:43,2017-09-12 17:38:43
IS,Could not find backports weakref while installing TensorFlow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 6 TensorFlow installed from source or binary Trying to install through package manager pip2 TensorFlow version use command below 1 2 0 Python version 2 7 13 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce pip2 install tensorflow 1 2 0 Describe the problem While I try to install TF 1 2 0 on Python2 7 through the package manager Pip pip2 install tensorflow 1 2 0 I get the following error So it does not find the backports weakref package in PyPl even if I can see it here Is this a known issue What can I do to install this dependency manually,,"reedwm,gunan,yifeif",2017-09-11 15:06:59,2017-09-12 17:40:24
IS,cudnn rnn ops py cannot find cudnn rnn ops so,L37,,reedwm,2017-09-09 20:53:10,2017-09-12 19:13:49
PR,Branch 168392949,,,"drpngx,drpngx,drpngx",2017-09-12 17:43:47,2017-09-12 21:01:35
IS,inconsistent behavior in variable sharing,hello I have been struggling for few days with an issue that I'm facing in TensorFlow I hesitated before opening this GitHub as an issue because I'm not sure if what I'm facing is a bug or a mere confusion on my side anyways it seems that I'm experiencing an inconsistent behavior in tensorFlow with variable name reusing where I have a function that creates some cells and attentions objects below is the function the print commands parings the returned objects first print outputs 'intial train state' AttentionWrapperState cell state LSTMStateTuple c tf Tensor iscope InnerScope tile batch 1 Reshape 0' shape 512 dtype float32 h tf Tensor iscope InnerScope tile batch 1 Reshape 1 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope InnerScope tile batch 1 Reshape 2 0' shape 512 dtype float32 h tf Tensor iscope InnerScope tile batch 1 Reshape 3 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope InnerScope tile batch 1 Reshape 4 0' shape 512 dtype float32 h tf Tensor iscope InnerScope tile batch 1 Reshape 5 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope InnerScope tile batch 1 Reshape 6 0' shape 512 dtype float32 h tf Tensor iscope InnerScope tile batch 1 Reshape 7 0' shape 512 dtype float32 attention tf Tensor iscope InnerScope AttentionWrapperZeroState zeros 1 0' shape 100 512 dtype float32 time tf Tensor iscope InnerScope AttentionWrapperZeroState zeros 0' shape dtype int32 alignments tf Tensor iscope InnerScope AttentionWrapperZeroState zeros 2 0' shape 100 dtype float32 alignment history and the second print outputs 'intial infer state' AttentionWrapperState cell state LSTMStateTuple c tf Tensor iscope 1 InnerScope tile batch 1 Reshape 0' shape 512 dtype float32 h tf Tensor iscope 1 InnerScope tile batch 1 Reshape 1 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope 1 InnerScope tile batch 1 Reshape 2 0' shape 512 dtype float32 h tf Tensor iscope 1 InnerScope tile batch 1 Reshape 3 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope 1 InnerScope tile batch 1 Reshape 4 0' shape 512 dtype float32 h tf Tensor iscope 1 InnerScope tile batch 1 Reshape 5 0' shape 512 dtype float32 LSTMStateTuple c tf Tensor iscope 1 InnerScope tile batch 1 Reshape 6 0' shape 512 dtype float32 h tf Tensor iscope 1 InnerScope tile batch 1 Reshape 7 0' shape 512 dtype float32 attention tf Tensor iscope 1 InnerScope AttentionWrapperZeroState zeros 1 0' shape 300 512 dtype float32 time tf Tensor iscope 1 InnerScope AttentionWrapperZeroState zeros 0' shape dtype int32 alignments tf Tensor iscope 1 InnerScope AttentionWrapperZeroState zeros 2 0' shape 300 dtype float32 alignment history I was expecting that both output would be the same since I'm reusing the variables but as you can see that for example in the first variable the output has something like this scope InnerScope tile batch 1 Reshape 1 0 and in the second variable scope 1 InnerScope tile batch 1 Reshape 1 0 I do not know why 1 is added to scope in the second call and I'm a bit confused if the variable is being shared or not further more when I set the reuse option to False I get the below error in the second function call ValueError Variable scope memory layer kernel already exists disallowed Did you mean to set reuse True or reuse tf AUTO REUSE in VarScope Originally defined at which leads me to think that the function was reusing the variables when the reuse flag was True but I still do not understand why is tensorFlow adding 1 to the variable name scope 1 and does that mean it not being reused and how do I fix this I'm using Tensorflow 1 3 ON MacOs 10 12 4 I have also opened a stackoverflow question thank you,,lukaszkaiser,2017-09-08 17:29:15,2017-09-12 21:35:13
IS,Tensorflow import breaks numpy calls,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow See source code below OS Platform and Distribution e g Linux Ubuntu 16 04 Thanks in advance,,yaroslavvb,2017-09-12 22:05:13,2017-09-12 22:54:34
PR,Branch 168439341,,,drpngx,2017-09-12 21:13:26,2017-09-12 22:57:36
PR,boringssl sha256 checksum mismatched,issue 12986 How to test confirmed by 12752,,"facaiy,drpngx,gunan,facaiy,gunan",2017-09-12 08:53:58,2017-09-13 12:47:40
IS,GPU Error with tf losses sparse softmax cross entropy,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow See below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary PIP TensorFlow version use command below v1 1 0 rc0 61 g1ec6ed5 1 1 0 Bazel version if compiling from source n a CUDA cuDNN version 8 0 5 1 5 GPU model and memory NVIDIA Titan X 12GB Exact command to reproduce Describe the problem Am I doing something wrong or does this function not have a GPU implementation yet I guess I can do this on the CPU but I thought I would check It does work on the CPU I did check that Source code logs The error message is attached error message txt,,aselle,2017-06-14 20:16:47,2017-09-13 13:02:22
PR,Add uint16 support for tf decode raw,This fix tries to address the request raised in 10124 where uint16 support for tf decode raw is needed tf decode raw already support half float32 float64 int8 int16 int32 int64 uint8 And uint16 was not supported yet This fix adds uint16 support for tf decode raw This fix fixes 10124 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,martinwicke,yongtang,yifeif,yifeif,rmlarsen,yongtang,rmlarsen,rmlarsen",2017-08-31 03:59:19,2017-09-13 17:03:01
PR,Merge pull request 1 from tensorflow master,pull master 6 19,,drpngx,2017-09-13 07:52:37,2017-09-13 17:31:08
PR,Updating default version for building from master source,Making the default build from source version 1 4 0dev The whl files that are built will be 1 3 0devDDMMYYYY,,"av8ramit,drpngx,drpngx,av8ramit",2017-09-11 16:52:54,2017-09-13 17:46:38
IS,allocate output tensor for every operation before the first inference,Describe the problem I was wondering if it is possible to allocate memory in advance for internal output tensors of every operation in my inference workload I notice TF will automatically allocate and de allocate memory for every internal result in a graph If my inference workload repeats many times all these allocations deallocations will also repeat Why do not we allocate these internal output tensors just once before the first inference run and delete them after the last For example I have the following workload which will run thousands of times Is it possible to allocate M before the first run and use the memory for all inference To avoid allocation of M in every single inference,,"yaroslavvb,yaroslavvb,reedwm,yaroslavvb,yaroslavvb,reedwm",2017-09-08 06:34:42,2017-09-13 17:53:39
IS,ImportError cannot import name 'c einsum',I updated tensorflow from 1 1 0 to 1 3 0 using the wheel file tensorflow 1 3 0 cp35 cp35m win amd64 whl and in the line import tensorflow as tf I got the following error Any help,,drpngx,2017-09-08 06:10:35,2017-09-13 18:43:23
PR,random crop option to return the crop offset,I have a segmentation application where I need to know the selected random crop offset to correctly crop the label image in the same manner This PR adds the random crop get offset True option to return that additional information to the user,,"ahundt,drpngx,asimshankar,ahundt,drpngx,ahundt",2017-09-10 19:41:07,2017-09-13 18:57:27
IS,build fail looser throw specifier in EnvWrapper,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Fedora 17 TensorFlow installed from source or binary Trying to build from source TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source 0 5 4 CUDA cuDNN version Disabled GPU model and memory Disabled Exact command to reproduce bazel build Describe the problem I'm trying to compile tensorflow from source do not modify anything simply following the instructions on the webpage built bazel 0 5 4 from source git clone git checkout origin 1 3 configure all answers are the defaults bazel build verbose failures config opt tensorflow tools pip package build pip package The above fails with with a looser throw specifier error in core platform env h The versions of the various tools involved openjdk 1 8 0 bazel 0 5 4 python 2 7 gcc 4 7 2 libstdc 4 7 2 The problem is reproducible on my box Source code logs The precise failure from the bazel build is this ERROR home fetch tensorflow tensorflow core BUILD 1244 1 C compilation of rule ' tensorflow core lib internal' failed Exit 1 gcc failed error executing command cd home fetch cache bazel bazel fetch 7ef242de6c5f89b75c729448096cd3bb execroot org tensorflow exec env LD LIBRARY PATH usr lib64 usr lib64 openmpi lib PATH opt obuildfactory jdk 1 8 0 openjdk x86 64 bin usr lib jvm java 1 7 0 openjdk 1 7 0 25 x86 64 bin usr lib64 openmpi bin home fetch opt bin home fetch bin usr lib64 openmpi bin home fetch opt bin home fetch bin usr lib64 qt 3 3 bin usr local bin bin usr bin usr local sbin usr sbin PWD proc self cwd PYTHON BIN PATH bin python PYTHON LIB PATH usr lib python2 7 site packages TF NEED CUDA 0 TF NEED OPENCL 0 bin gcc U FORTIFY SOURCE fstack protector Wall B bin B usr bin Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections ' march native' ' std c 0x' ' march native' MD MF bazel out local opt bin tensorflow core objs lib internal tensorflow core platform default tracing pic d ' frandom seed bazel out local opt bin tensorflow core objs lib internal tensorflow core platform default tracing pic o' fPIC DEIGEN MPL2 ONLY DSNAPPY iquote iquote bazel out local opt genfiles iquote external bazel tools iquote bazel out local opt genfiles external bazel tools iquote external protobuf iquote bazel out local opt genfiles external protobuf iquote external eigen archive iquote bazel out local opt genfiles external eigen archive iquote external local config sycl iquote bazel out local opt genfiles external local config sycl iquote external gif archive iquote bazel out local opt genfiles external gif archive iquote external jpeg iquote bazel out local opt genfiles external jpeg iquote external com googlesource code re2 iquote bazel out local opt genfiles external com googlesource code re2 iquote external farmhash archive iquote bazel out local opt genfiles external farmhash archive iquote external fft2d iquote bazel out local opt genfiles external fft2d iquote external highwayhash iquote bazel out local opt genfiles external highwayhash iquote external png archive iquote bazel out local opt genfiles external png archive iquote external zlib archive iquote bazel out local opt genfiles external zlib archive iquote external snappy iquote bazel out local opt genfiles external snappy isystem external bazel tools tools cpp gcc3 isystem external protobuf src isystem bazel out local opt genfiles external protobuf src isystem external eigen archive isystem bazel out local opt genfiles external eigen archive isystem external gif archive lib isystem bazel out local opt genfiles external gif archive lib isystem external farmhash archive src isystem bazel out local opt genfiles external farmhash archive src isystem external png archive isystem bazel out local opt genfiles external png archive isystem external zlib archive isystem bazel out local opt genfiles external zlib archive DEIGEN AVOID STL ARRAY Iexternal gemmlowp Wno sign compare fno exceptions msse3 pthread Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c tensorflow core platform default tracing cc o bazel out local opt bin tensorflow core objs lib internal tensorflow core platform default tracing pic o In file included from tensorflow core lib core threadpool h 21 0 from tensorflow core platform default tracing impl h 25 from tensorflow core platform tracing h 266 from tensorflow core platform default tracing cc 16 tensorflow core platform env h 295 11 error looser throw specifier for 'virtual tensorflow EnvWrapper EnvWrapper ' tensorflow core platform env h 50 11 error overriding 'virtual tensorflow Env Env noexcept true ' tensorflow core platform default tracing cc 32 19 warning 'tensorflow port dummy' defined but not used Wunused variable Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 418 721s Critical Path 19 37s,,"drpngx,reedwm,gunan",2017-09-07 23:31:06,2017-09-13 19:57:59
IS,Add Dataset from variable length to accept numpy arrays with varying length,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS x TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 2 Continuum Analytics Inc Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Dataset has a nice padded batch feature which allows padding batches to ensure all tensors have the same size which is very nice for the common use case of having sequences of different lengths However it seems impossible to create such a dataset from a list of numpy array with different lengths See command above It would be very nice to have a Dataset from variable length tensor slices or such that could take such inputs I know I'm supposed to use a TextLineDataset or something similar and then use a series of map functions but I think tensorflow should support doing all of the pre processing outside of tensorflow instead of forcing it into a delayed execution graph paradigm which is harder to reason about and debug Also my data is stored in JSON files and requires complex pre processing so the TextLineDataset map approach does not cut it,,"mrry,mrry",2017-09-13 14:36:39,2017-09-13 20:27:31
PR,EHN csv supports missing value,What changes were proposed in this pull request tf decode csv support NA values see 13007 How was this patch tested x add unit tests pass all tests,,"facaiy,gunan,drpngx,facaiy,drpngx,facaiy,drpngx,facaiy,drpngx",2017-09-13 02:28:19,2017-09-13 22:17:59
PR,Improvements to Java API handling of datatypes and arrays,This is a set of connected changes broken out from 11535 Generic Java API and improved a bit further still synergistic with that PR and should allow whittling that PR down toward a digestible size Changed how datatypes are computed from arrays to not crawl over the array but instead just inspect the array is class object This seems somewhat simpler more efficient and easier to maintain going forward Added the notion that a given array component type can correspond to more than one tensor datatype I think that we already would like this to be able to support both uint8 and string using byte arrays and the need will become more acute as more TensorFlow types are added Resurrected the test case for creating and extracting uint8 tensors requires previous change,,"andrewcmyers,andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,drpngx",2017-09-09 03:48:56,2017-09-13 22:18:23
PR,Update monitors py,Refactor contrib,,"alanyee,martinwicke,martinwicke,alanyee,yifeif,alanyee",2017-09-02 15:29:40,2017-09-13 22:19:56
IS,Invalid argument shape must be a vector of int32 int64 got shape,I try to use the interface of RandomUniform as follows But it prints the error for me What is it means I am not good at c And where are the demo i can find,,reedwm,2017-09-13 22:00:13,2017-09-14 00:26:28
IS,tf qint8 Quantized 8 bit signed integer Definition code piece examples,What does quantized mean in this scenario Could you please explain with an example and a descriptive definition along with the code used for this tf qint8 Quantized 8 bit signed integer What does quantized mean in this scenario tf quint8 Quantized 8 bit unsigned integer What does quantized mean in this scenario tf qint16 Quantized 16 bit signed integer What does quantized mean in this scenario tf quint16 Quantized 16 bit unsigned integer What does quantized mean in this scenario tf qint32 Quantized 32 bit signed integer What does quantized mean in this scenario tf resource Handle to a mutable resource What does mutable resource mean,,,2017-09-06 20:01:57,2017-09-14 00:29:34
IS,init weights from pre train model resnet v2 101 something wrong Assign requires shapes of both tensors to match lhs shape 19 rhs shape 256,SSD generate feature map by VGG16 I replaced VGG16 with ResNet V2 101 the code as follows with slim arg scope resnet utils resnet arg scope net end points resnet v2 resnet v2 101 inputs reuse reuse global pool False is training True scope aresnet v2 101' when i restore the pretrain weights from the checkpoint path something wrong as follows InvalidArgumentError see above for traceback Assign requires shapes of both tensors to match lhs shape 19 rhs shape 256 Node save 1 Assign 294 Assign T DT FLOAT class loc resnet v2 101 block3 unit 18 bottleneck v2 conv2 BatchNorm gamma use locking true validate shape true device job localhost replica 0 task 0 cpu 0 resnet v2 101 block3 unit 18 bottleneck v2 conv2 BatchNorm gamma save 1 RestoreV2 294 I do not konw why Hope for your help,,,2017-09-07 07:28:55,2017-09-14 00:44:15
IS,error in Building tensor flow sun security validator ValidatorException,cat etc issue Linux ravi 4 4 0 93 generic 116 Ubuntu SMP Fri Aug 11 21 17 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux ravi 4 4 0 93 generic 116 Ubuntu SMP Fri Aug 11 21 17 51 UTC 2017 x86 64 x86 64 x86 64 GNU Linux Hello Below is compilation error i am getting bin bazel build c opt config opt tensorflow tools pip package build pip package Extracting Bazel installation ERROR home ravi spatil LinuxShare caffe opecv resources mobilenet tensorflow ori tensorflow tools pip package BUILD 101 1 no such package ' nsync ' Error downloading to home ravi spatil cache bazel bazel ravi spatil 39b7c1709071717822a0ecd1200753ba external nsync ad722c76c6e6653f66be2e1f69521b7f7517da55 tar gz sun security validator ValidatorException PKIX path building failed sun security provider certpath SunCertPathBuilderException unable to find valid certification path to requested target and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted INFO Elapsed time 28 497s FAILED Build did NOT complete successfully 106 packages loaded Below is system information check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv False tensorflow import Traceback most recent call last File string line 1 in module ImportError No module named tensorflow env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tools tf env collect sh line 105 nvidia smi command not found,,,2017-09-07 10:50:41,2017-09-14 00:44:45
IS,Tutorial code in Logging and Monitoring Basics with tf contrib learn with multiple errors,I have tried to run the setup code in the tutorial but I met some confusing running errors I'm new to tensorflow so I have no idea how to deal with it Could anybody help me fix this problem Thanks a lot Here is what I saw WARNING tensorflow From logging monitoring py 33 calling BaseEstimator fit from tensorflow contrib learn python learn estimators estimator with x is deprecated and will be removed after 2016 12 01 Instructions for updating Estimator is decoupled from Scikit Learn interface by moving into separate class SKCompat Arguments x y and batch size are only available in the SKCompat class Estimator will only accept input fn Example conversion est Estimator est SKCompat Estimator WARNING tensorflow From logging monitoring py 33 calling BaseEstimator fit from tensorflow contrib learn python learn estimators estimator with y is deprecated and will be removed after 2016 12 01 Instructions for updating Estimator is decoupled from Scikit Learn interface by moving into separate class SKCompat Arguments x y and batch size are only available in the SKCompat class Estimator will only accept input fn Example conversion est Estimator est SKCompat Estimator WARNING tensorflow From C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators head py 642 scalar summary from tensorflow python ops logging ops is deprecated and will be removed after 2016 11 30 Instructions for updating Please switch to tf summary scalar Note that tf summary scalar uses the node name instead of the tag This means that TensorFlow will automatically de duplicate summary names based on the scope they are created in Also passing a tensor or list of tags to a scalar summary op is no longer supported 2017 09 07 20 00 50 306221 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 09 07 20 00 50 306424 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 09 07 20 00 50 447012 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 0 biases not found in checkpoint 2017 09 07 20 00 50 447738 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 0 weights not found in checkpoint 2017 09 07 20 00 50 448265 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 0 biases denlayer 0 biases part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 451033 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn multi class head dnn learning rate not found in checkpoint 2017 09 07 20 00 50 451078 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 1 biases not found in checkpoint 2017 09 07 20 00 50 451715 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 0 weights enlayer 0 weights part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 452925 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 1 biases denlayer 1 biases part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 454670 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn logits weights nn logits weights part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 455734 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 1 weights enlayer 1 weights part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 455777 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 1 weights not found in checkpoint 2017 09 07 20 00 50 460821 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 2 biases not found in checkpoint 2017 09 07 20 00 50 463001 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn logits weights not found in checkpoint 2017 09 07 20 00 50 464352 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 2 biases denlayer 2 biases part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 464794 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 2 weights not found in checkpoint 2017 09 07 20 00 50 467010 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn hiddenlayer 2 weights enlayer 2 weights part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 467803 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn logits biases dnn logits biases part 0 Adagrad not found in checkpoint 2017 09 07 20 00 50 472935 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core framework op kernel cc 1192 Not found Key dnn logits biases not found in checkpoint Traceback most recent call last File C Program Files Python36 lib site packages tensorflow python client session py line 1327 in do call return fn args File C Program Files Python36 lib site packages tensorflow python client session py line 1306 in run fn status run metadata File C Program Files Python36 lib contextlib py line 88 in exit next self gen File C Program Files Python36 lib site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl NotFoundError Key dnn hiddenlayer 0 biases not found in checkpoint Node save RestoreV2 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 tensor names save RestoreV2 shape and slices During handling of the above exception another exception occurred Traceback most recent call last File logging monitoring py line 47 in module tf app run File C Program Files Python36 lib site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File logging monitoring py line 33 in main steps 2000 File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func return func args kwargs File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 442 in fit SKCompat self fit x y batch size steps max steps monitors File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1353 in fit monitors all monitors File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func return func args kwargs File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 458 in fit loss self train model input fn input fn hooks hooks File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1006 in train model config self session config File C Program Files Python36 lib site packages tensorflow python training monitored session py line 365 in MonitoredTrainingSession stop grace period secs stop grace period secs File C Program Files Python36 lib site packages tensorflow python training monitored session py line 668 in init stop grace period secs stop grace period secs File C Program Files Python36 lib site packages tensorflow python training monitored session py line 490 in init self sess RecoverableSession self coordinated creator File C Program Files Python36 lib site packages tensorflow python training monitored session py line 842 in init WrappedSession init self self create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 847 in create session return self sess creator create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 551 in create session self tf sess self session creator create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 425 in create session init fn self scaffold init fn File C Program Files Python36 lib site packages tensorflow python training session manager py line 273 in prepare session config config File C Program Files Python36 lib site packages tensorflow python training session manager py line 205 in restore checkpoint saver restore sess ckpt model checkpoint path File C Program Files Python36 lib site packages tensorflow python training saver py line 1560 in restore self saver def filename tensor name save path File C Program Files Python36 lib site packages tensorflow python client session py line 895 in run run metadata ptr File C Program Files Python36 lib site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File C Program Files Python36 lib site packages tensorflow python client session py line 1321 in do run options run metadata File C Program Files Python36 lib site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl NotFoundError Key dnn hiddenlayer 0 biases not found in checkpoint Node save RestoreV2 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 tensor names save RestoreV2 shape and slices Caused by op isave RestoreV2' defined at File logging monitoring py line 47 in module tf app run File C Program Files Python36 lib site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File logging monitoring py line 33 in main steps 2000 File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func return func args kwargs File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 442 in fit SKCompat self fit x y batch size steps max steps monitors File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1353 in fit monitors all monitors File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func return func args kwargs File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 458 in fit loss self train model input fn input fn hooks hooks File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1006 in train model config self session config File C Program Files Python36 lib site packages tensorflow python training monitored session py line 365 in MonitoredTrainingSession stop grace period secs stop grace period secs File C Program Files Python36 lib site packages tensorflow python training monitored session py line 668 in init stop grace period secs stop grace period secs File C Program Files Python36 lib site packages tensorflow python training monitored session py line 490 in init self sess RecoverableSession self coordinated creator File C Program Files Python36 lib site packages tensorflow python training monitored session py line 842 in init WrappedSession init self self create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 847 in create session return self sess creator create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 551 in create session self tf sess self session creator create session File C Program Files Python36 lib site packages tensorflow python training monitored session py line 416 in create session self scaffold finalize File C Program Files Python36 lib site packages tensorflow python training monitored session py line 209 in finalize self saver build File C Program Files Python36 lib site packages tensorflow python training saver py line 1172 in build filename self filename File C Program Files Python36 lib site packages tensorflow python training saver py line 684 in build restore sequentially reshape File C Program Files Python36 lib site packages tensorflow python training saver py line 450 in AddShardedRestoreOps name restore shard File C Program Files Python36 lib site packages tensorflow python training saver py line 407 in AddRestoreOps tensors self restore op filename tensor saveable preferred shard File C Program Files Python36 lib site packages tensorflow python training saver py line 247 in restore op spec tensor dtype 0 File C Program Files Python36 lib site packages tensorflow python ops gen io ops py line 663 in restore v2 dtypes dtypes name name File C Program Files Python36 lib site packages tensorflow python framework op def library py line 767 in apply op op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access NotFoundError see above for traceback Key dnn hiddenlayer 0 biases not found in checkpoint Node save RestoreV2 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 arg save Const 0 0 save RestoreV2 tensor names save RestoreV2 shape and slices ERROR tensorflow Object was never used type class 'tensorflow python framework ops Tensor' tf Tensor areport uninitialized variables 1 boolean mask Gather 0' shape dtype string If you want to mark it as used call its mark used method It was originally created here 'File logging monitoring py line 47 in module n tf app run ' 'File C Program Files Python36 lib site packages tensorflow python platform app py line 48 in run n sys exit main sys argv 1 flags passthrough ' 'File logging monitoring py line 33 in main n steps 2000 ' 'File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func n return func args kwargs ' 'File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 442 in fit n SKCompat self fit x y batch size steps max steps monitors ' 'File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1353 in fit n monitors all monitors ' 'File C Program Files Python36 lib site packages tensorflow python util deprecation py line 296 in new func n return func args kwargs ' 'File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 458 in fit n loss self train model input fn input fn hooks hooks ' 'File C Program Files Python36 lib site packages tensorflow contrib learn python learn estimators estimator py line 1006 in train model n config self session config' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 365 in MonitoredTrainingSession n stop grace period secs stop grace period secs ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 668 in init n stop grace period secs stop grace period secs ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 490 in init n self sess RecoverableSession self coordinated creator ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 842 in init n WrappedSession init self self create session ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 847 in create session n return self sess creator create session ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 551 in create session n self tf sess self session creator create session ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 416 in create session n self scaffold finalize ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 196 in finalize n default ready for local init op ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 258 in get or default n op default constructor ' 'File C Program Files Python36 lib site packages tensorflow python training monitored session py line 193 in default ready for local init op n variables global variables ' 'File C Program Files Python36 lib site packages tensorflow python util tf should use py line 175 in wrapped n return add should use warning fn args kwargs ' 'File C Program Files Python36 lib site packages tensorflow python util tf should use py line 144 in add should use warning n wrapped TFShouldUseWarningWrapper x ' 'File C Program Files Python36 lib site packages tensorflow python util tf should use py line 101 in init n stack s strip for s in traceback format stack ',,rohan100jain,2017-09-07 12:16:29,2017-09-14 00:45:35
IS,tensorflow master version compile build all ios sh error armv7 compilation failed,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-08 03:30:16,2017-09-14 00:47:38
IS,T SNE Suddenly Not Working in Projector,Hello I'm sorry this is not a technical question but just this week I have noticed that T SNE in the tensorboard projector is no longer clustering data properly I am running the same vectors I did a few weeks ago with the same perplexity While before I saw distinct clusters now the points are all forming an indistinct ball Has anyone else noticed this,,dandelionmane,2017-09-08 15:25:41,2017-09-14 02:35:01
PR,Get sysroot path in a robust way for nsync ios build,The sysroot path in nsync ios build is hardcoded this PR changed it to use xcrun just like how other build scripts did,,resec,2017-09-14 02:04:19,2017-09-14 02:38:26
PR,Update README md,,,drpngx,2017-09-14 03:15:15,2017-09-14 03:20:39
IS,Tensorflow broken on importing tensorflow contrib tensorboard module,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Archlinux TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 3 6 2 Bazel version if compiling from source 0 5 4 CUDA cuDNN version 8 0 61 GPU model and memory GTX 1070 7 92GiB Exact command to reproduce And I have installed the tensorboard package But the problem remains Could anyone help me Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-09-06 08:54:25,2017-09-14 07:35:08
IS,tf image resize bicubic produces artifacts in output image,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes See below OS Platform and Distribution e g Linux Ubuntu 16 04 All platforms TensorFlow installed from source or binary source TensorFlow version use command below 1 0 Bazel version if compiling from source 0 4 5 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem tf image resize bicubic produces weird artifacts in output image To reproduce please save this image as bbf png and run the program below This is what tf image resize bicubic produces output Source code logs,,"aselle,aselle",2017-06-15 07:01:34,2017-09-14 12:46:22
IS,Type error occurring in the input pipeline should give more descriptive error messages than RandomShuffleQueue is closed and has insufficient elements,I do not have a particular code example but I had the case that a tf py func node returned the wrong data type and thus caused the queue to stall It was impossible to tell what the error was from the error messages that TensorFlow produced What is the reason that there are no error messages about type mismatches,,aselle,2017-06-15 18:49:04,2017-09-14 12:46:26
PR,Branch 168619288,,,"caisq,caisq,caisq",2017-09-14 01:48:41,2017-09-14 13:32:40
IS,All tf sets ops fail to reproduce their own official examples,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 3 5 Bazel version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce n a Context tf sets ops documentation declares that ' All but the last dimension of a and b must match ' Also the example is provided From this error it is deducible that a dense tensor is needed This statement contradicts the description of methods Also logically we would not want to have a dense tensor or any kind of padding in sets this leads to excessive padding elements in sets which defies the purpose Statement Either the functionality or the description of tf sets must be fixed,,"reedwm,martinwicke,MarkDaoust",2017-09-11 16:39:25,2017-09-14 13:33:08
IS,Feature request Dataset from py func,I have an input pipeline that is especially complex It is coded entirely in plain Python While it may be possible to reimplement it in TensorFlow operations that would be a huge amount of work and take far too much time to be worth it right now It would be great if I could hook my existing pipeline into the new Dataset approach via something like Dataset from py func One would pass a reference to a Python function that has no inputs and when executed acts as a generator that yields examples one at a time as numpy arrays For example def generate for example in complex input pipeline yield example dataset Dataset from py func generate Do normal things with dataset I have been unable to figure out a way to do something like this using existing functionality so it would be great if it could be added,,mrry,2017-09-14 13:22:29,2017-09-14 13:39:50
PR,delete dummy 'r',I just delete this dummy r character in the front of multi line annotation,,drpngx,2017-09-14 09:24:14,2017-09-14 16:17:38
PR,delete dummy 'r' in front of annotation,I just delete this dummy r character in the front of multi line annotation with the newest version,,drpngx,2017-09-14 09:52:52,2017-09-14 16:18:09
IS,Does tensorflow is used for content based recommendations,Hi I wanted to perform content based recommendation context based but I did not find any example of tensor flow doing it can we use tensor flow for doing content based recommendations,,,2017-09-12 05:00:16,2017-09-14 16:38:49
IS,Mixture model with gaussians fails to create,Hello I have written some code to model GMM and further prob some data points I already have weights and other params for initialization Here is the code When debugging I found out that this exact function is hit when Shape check is performed And self logits get shape does return Shape 32 but taking 1 from it leads to an error Is this an intended behaviour,,,2017-09-12 06:40:44,2017-09-14 16:39:57
IS,restore part of model using Estimator API,Hi I am trying to restore part of model using tensorflow high level API Estimator but I can not find I way I can only specify checkpoint path for Estimator Here is an example I what to extract COCO images feature using tf slim pretrained model resnet v2 but this pretrained model does not provide resnet v2 152 block1 unit 1 bottleneck v2 conv2 biases So I need to initialize it to zero But using Estimator It will find that this biases not in checkpoint and raise a Not found error The error is obvious 2017 09 12 20 36 31 231422 W tensorflow core framework op kernel cc 1192 Not found Tensor name resnet v2 152 block1 unit 1 bottleneck v2 conv2 biases not found in checkpoint files root data checkpoints resnet v2 152 2017 04 14 resnet v2 152 ckpt,,,2017-09-12 12:40:41,2017-09-14 16:42:02
PR,docs Fix Anaconda environment creation step,There is a bug in the install instructions for Anaconda users 1 Before you can use pip to install tensorflow you must first install python which includes pip to the new environment Otherwise the user will accidentally use the system is pip and tensorflow will be installed to the system python instead of the intended environment 1 InstallingAnaconda,,,2017-09-14 14:08:18,2017-09-14 16:48:10
IS,Can I install and run TensorFlow on my machine with this much of information,C Users SEM python Python 3 5 2 v3 5 2 4def2a2901a5 Jun 25 2016 22 18 55 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information,,reedwm,2017-09-14 16:58:30,2017-09-14 17:02:05
IS,Load model in C API and get from device CUDA ERROR OUT OF MEMORY error,My model is about 2 4GB In my inference step I want to load model by multi processing method in each GPU That means I try to make two process in one GPU and each load a model After I make configuration of each session done each session get about 5GB memory But I still meet the from device CUDA ERROR OUT OF MEMORY I am wondering Asking for help GPU information search qrwt01 home s apps qtfserverd bin nvidia smi Thu Sep 14 21 42 48 2017 NVIDIA SMI 375 26 Driver Version 375 26 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Tesla K80 Off 0000 08 00 0 Off 0 N A 48C P0 61W 149W 11366MiB 11439MiB 0 Default 1 Tesla K80 Off 0000 09 00 0 Off 0 N A 32C P0 72W 149W 11359MiB 11439MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 33056 C ome s apps qtfserverd etc qtfserverd conf 5823MiB 0 33057 C ome s apps qtfserverd etc qtfserverd conf 5515MiB 1 33058 C ome s apps qtfserverd etc qtfserverd conf 5823MiB 1 33059 C ome s apps qtfserverd etc qtfserverd conf 5516MiB Session configuration 46 void create session void graph std string checkpoint path 47 int intra op threads int inter op threads std string device list 48 Session session NULL 49 SessionOptions sess opts 50 int NUM THREADS 8 51 if intra op threads 0 52 sess opts config set intra op parallelism threads intra op threads 53 54 if inter op threads 0 55 sess opts config set inter op parallelism threads inter op threads 56 57 58 sess opts config set allow soft placement true 59 sess opts config mutable gpu options set visible device list device list 60 sess opts config mutable gpu options set allocator type BFC 61 sess opts config mutable gpu options set per process gpu memory fraction 0 5 62 sess opts config mutable gpu options set allow growth true 63 Status status NewSession sess opts session 64 if status ok 65 fprintf stderr Create Session Failed s n status ToString c str 66 return NULL 67 Error information load home search tensorflow deploy combine model meta graph to gpu 1 success 2017 09 14 21 42 31 188212 I tensorflow core common runtime gpu gpu device cc 965 Found device 0 with properties name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 0000 09 00 0 totalMemory 11 17GiB freeMemory 11 05GiB 2017 09 14 21 42 31 188260 I tensorflow core common runtime gpu gpu device cc 1055 Creating TensorFlow device device GPU 0 device 1 name Tesla K80 pci bus id 0000 09 00 0 compute capability 3 7 qss switch 1 lstm switch 1 qss switch 1 lstm switch 1 2017 09 14 21 42 33 826598 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 1 58G 1701773312 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 838694 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 1 43G 1531596032 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 893832 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 903917 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 913843 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 924008 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 935385 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 946556 E tensorflow stream executor cuda cuda driver cc 936 failed to allocate 439 82M 461180672 bytes from device CUDA ERROR OUT OF MEMORY 2017 09 14 21 42 33 956340 E tensorflow stream executor cuda cuda driver,,reedwm,2017-09-14 14:02:56,2017-09-14 17:04:06
IS,How to check tensorflow inception version number from an inception pb file,Hi I am trying to figure out which Tensorflow version an inception pb file is This file is used in a OpenCV plugin to Unity3D game engine OpenCV for Unity Enox software wraps OpenCV 3 3 0 I replaced these files with a model I re trained with TF 1 3 0 yesterday and it made the whole Unity3D editor crash So I assume I have the wrong tensorflow inception version as the default zip version worked and my re trained model worked inside docker test but I do not know what is the right version to use due to lack of documentation knowledle being tf noobie Does anybody here know how to check the version from the pb file,,reedwm,2017-09-14 10:50:18,2017-09-14 17:07:06
IS,W tensorflow core framework op kernel cc 993 Failed precondition,I want to run the tensorflow deeplab resnet and I prepared my own training data for it But When I try to run train py to train data it always did not work And the error are as follows Uploading error jpg I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcublas so 8 0 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcudnn so 5 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcufft so 8 0 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcuda so 1 locally I tensorflow stream executor dso loader cc 135 successfully opened CUDA library libcurand so 8 0 locally Tensor create inputs batch 0 shape 2 4000 4000 3 dtype float32 sssssssssssss Tensor create inputs batch 1 shape 2 4000 4000 1 dtype uint8 sssssssssss W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE3 instructions but these are available on your machine and could speed up CPU computations W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations I tensorflow core common runtime gpu gpu device cc 885 Found device 0 with properties name Quadro M4000 major 5 minor 2 memoryClockRate GHz 0 7725 pciBusID 0000 03 00 0 Total memory 7 92GiB Free memory 7 51GiB I tensorflow core common runtime gpu gpu device cc 906 DMA 0 I tensorflow core common runtime gpu gpu device cc 916 0 Y I tensorflow core common runtime gpu gpu device cc 975 Creating TensorFlow device gpu 0 device 0 name Quadro M4000 pci bus id 0000 03 00 0 Restored model parameters from home precision code tensorflow deeplab resnet master deeplab resnet ckpt W tensorflow core framework op kernel cc 993 Failed precondition home precision code tensorflow deeplab resnet master dataset VOCdevkit W tensorflow core framework op kernel cc 993 Failed precondition home precision code tensorflow deeplab resnet master dataset VOCdevkit W tensorflow core framework op kernel cc 993 Out of range FIFOQueue ' 1 create inputs batch fifo queue' is closed and has insufficient elements requested 2 current size 0 Node create inputs batch QueueDequeueManyV2 component types DT FLOAT DT UINT8 timeout ms 1 device job localhost replica 0 task 0 cpu 0 create inputs batch fifo queue create inputs batch n Traceback most recent call last File train py line 258 in module main File train py line 247 in main loss value images labels preds summary sess run reduced loss image batch label batch pred total summary train op feed dict feed dict File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python client session py line 767 in run run metadata ptr File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python client session py line 965 in run feed dict string options run metadata File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python client session py line 1015 in do run target list options run metadata File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python client session py line 1035 in do call raise type e node def op message tensorflow python framework errors impl OutOfRangeError FIFOQueue ' 1 create inputs batch fifo queue' is closed and has insufficient elements requested 2 current size 0 Node create inputs batch QueueDequeueManyV2 component types DT FLOAT DT UINT8 timeout ms 1 device job localhost replica 0 task 0 cpu 0 create inputs batch fifo queue create inputs batch n Caused by op u'create inputs batch' defined at File train py line 258 in module main File train py line 142 in main image batch label batch reader dequeue args batch size File home precision code tensorflow deeplab resnet master deeplab resnet image reader py line 180 in dequeue num elements File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python training input py line 872 in batch name name File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python training input py line 667 in batch dequeued queue dequeue many batch size name name File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops data flow ops py line 458 in dequeue many self queue ref n n component types self dtypes name name File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops gen data flow ops py line 1310 in queue dequeue many v2 timeout ms timeout ms name name File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework op def library py line 763 in apply op op def op def File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework ops py line 2327 in create op original op self default original op op def op def File home precision anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework ops py line 1226 in init self traceback extract stack OutOfRangeError see above for traceback FIFOQueue ' 1 create inputs batch fifo queue' is closed and has insufficient elements requested 2 current size 0 Node create inputs batch QueueDequeueManyV2 component types DT FLOAT DT UINT8 timeout ms 1 device job localhost replica 0 task 0 cpu 0 create inputs batch fifo queue create inputs batch n W tensorflow core framework op kernel cc 993 Failed precondition I have written the path address for the training set explicitly but the training program does not work properly Can you help me with this problem Thanks a lot,,reedwm,2017-09-14 09:47:26,2017-09-14 17:12:23
IS,GMM clustering example not working,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 12 6 TensorFlow installed from source or binary binary TensorFlow version use command below v1 0 0 rc2 15 g47bba63 dirty 1 0 0 Python version Python 3 6 0 Anaconda 4 3 1 x86 64 default Dec 23 2016 13 19 00 Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce python gmm test py Describe the problem I'm trying to use the gaussian mixed model clustering algorithm from contrib However the gmm class is really buggy and I'm unable to get the test cases in the gmm test py file to work Source code logs Using the iris dataset from sklearn I have tried to update the gmm fit step to use it as opposed to an input fn,,reedwm,2017-09-14 04:18:41,2017-09-14 17:22:55
IS,Very Slow Run time on A Pre Trained Network Inception V1,System information example script Very Similar label Image py but simpler Windows 10 X64 TensorFlow installed from source TensorFlow version 1 3 Python version 3 5 3 Cmake 3 8 1 CUDA cuDNN version CUDA 8 0 cuDNN 6 1 GPU model and memory Nvidia GTX 1050 4GB Exact command to reproduce Describe the problem I encountered a disturbing issue regarding the run time for processing an arbitrary image through an inception V1 GoogleNet pre trained model the runtime took approximately 9 2 ms When using the same image and exactly the same model with Caffe It was running X4 faster than Tensorflow 2 3 ms The models I used both for Caffe and Tensorflow Labels file is attached How is it even possible Am I doing something incorrectly By the way I carefully checked with GPU Z and it seems Tensorflow properly uses the GPU resources Source code logs Attahced along with the used label file In order to use the python script simply put it in the same folder as the model and label file and rename it to TF Running Inception py TF Running Inception txt imagenet slim labels txt,,reedwm,2017-09-10 19:40:09,2017-09-14 17:44:21
IS,Ca not compile tensorflow on Ubuntu with Skylake CPU i7 7820X,Ca not compile tensorflow on Ubuntu with Skylake CPU i7 7820X I get the following error Compilation command bazel build config opt config cuda cxxopt fabi version 0 tensorflow tools pip package build pip package verbose failures Is it possible to disable AVX512 but leave all other native optimization parameters,,"yongtang,yongtang,yongtang,yongtang,gunan,gunan",2017-09-13 12:33:17,2017-09-14 20:22:27
PR,Revert EHN csv supports missing value 13008,This reverts commit 36c5f218d00c4bdee296974b7a7e4d95da8a88a7 Original change needs to go through API review,,gunan,2017-09-14 22:13:17,2017-09-14 23:13:11
PR,Branch 168776302,,,"drpngx,drpngx",2017-09-15 01:42:59,2017-09-15 02:28:01
IS,Cmake nightly builds for Windows are broken for more than a month,Cmake nightly builds for Windows are broken for more than a month Will tensorflow ever support Windows again,,"reedwm,yaroslavvb,mrry,ekelsen,ekelsen",2017-09-11 19:42:50,2017-09-15 02:28:28
IS,cub BlockReduce error while building tensorflow in windows using cmake,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit TensorFlow installed from source or binary Using CMake and instructions present at tensorflow tensorflow contrib cmake TensorFlow version use command below Using Master Branch Python version 3 6 1 Bazel version if compiling from source CUDA cuDNN version CUDA 8 0 61 cuDNN 5 1 GPU model and memory NVIDIA GeForce GTX TITAN X 382 05 Exact command to reproduce MSBuild p Configuration Release tf label image example vcxproj Describe the problem I encounter the following error while building the tensorflow project for image recognition tf label image example vcxproj The error occurs when this image recognition project builds tf core gpu kernels vcxproj error argument list for template cub BlockReduce T BLOCK DIM X ALGORITHM BLOCK DIM Y BLOCK DIM Z PTX ARCH Reduce with T std iterator tra its T value type BLOCK DIM X num threads ALGORITHM cub BLOCK REDUCE WARP REDUCTIONS BLOCK DIM Y 1 BLOCK DIM Z 1 PTX ARCH 0 is missing,,"mrry,yaroslavvb,ekelsen",2017-09-14 12:15:11,2017-09-15 02:28:28
IS,Crash when load Fine tune model on Android,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 12 Bazel version if compiling from source 0 5 4 CUDA cuDNN version 8 0 61 GPU model and memory NVIDIA Corporation Device 1b06 Exact command to reproduce How I do Fine tune I am not sure which part result in this if any further information is needed please tell me thank you,,,2017-09-14 08:53:49,2017-09-15 13:55:36
PR,Updating readme to show Windows binary support,,,av8ramit,2017-09-15 00:55:57,2017-09-15 16:35:34
IS,'load csv with header' no longer works Please suggest a solution,I have been trying to run the tutorial program on IRIS data set and everytime when I try to run the program am seeing this error 'module' object has no attribute 'load csv with header' Please suggest me how to solve this,,"facaiy,reedwm,reedwm,reedwm",2017-09-13 05:35:32,2017-09-15 17:05:36
IS,No gradient defined for operation ' ' op type QueueDequeueUpToV2,When I tried to compute the gradient of the loss with 'grads opt compute gradients total loss update gradient vars ' there was an error said 'No gradient defined for operation ' ' op type QueueDequeueUpToV2 ',,,2017-09-07 01:46:01,2017-09-15 17:43:38
IS,How to fetch the last batch in a multigpu model,The new dataset API is awesome but I do not know to fetch the last batch in my model image image,,ppwwyyxx,2017-09-09 01:42:53,2017-09-15 17:58:12
PR,R1 3,,,drpngx,2017-09-15 02:26:51,2017-09-15 18:32:04
IS,1 notmnist assignment1 zero mean equation in code,Okay in tutorial its say to make zero mean do r 128 128 but in code its r 128 255 Below is the code provided in ipython notebook image size 28 Pixel width and height pixel depth 255 0 Number of levels per pixel def load letter folder min num images Load the data for a single letter label image files os listdir folder dataset np ndarray shape len image files image size image size dtype np float32 print folder num images 0 for image in image files image file os path join folder image try image data ndimage imread image file astype float pixel depth 2 pixel depth if image data shape image size image size raise Exception 'Unexpected image shape s' str image data shape dataset num images image data num images num images 1 except IOError as e print 'Could not read ' image file ' ' e ' it is ok skipping ',,,2017-09-12 19:19:44,2017-09-15 18:44:05
IS,tf reduce max inconsistent with numpy max when handling NaN values,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 2 Bazel version if compiling from source N A CUDA cuDNN version 8 0 6 0 GPU model and memory P100 16GB Exact command to reproduce see below Describe the problem The documentation for tf reduce max states that it is Equivalent to np max This is not true when the provided input tensor includes NaN values TensorFlow ignores NaN values and returns inf if present or the largest finite value Numpy will propagate NaN values in np max np amax and has a special function np nanmax for ignoring NaN values See the Notes section here Expected behavior is that tf reduce max returns NaN when its input includes NaN values Source code logs,,yongtang,2017-09-14 17:23:57,2017-09-15 20:13:53
IS,Word2vec on GPU slower than CPU,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 12 Bazel version if compiling from source 0 5 0 CUDA cuDNN version 8 0 6 0 GPU model and memory NVIDIA GTX 1060 3GB Docker used yes I picked up the code from the word2vec example on your official repo and made a few changes The core code to train word2vec remains the same Describe the problem I have been working on benchmarking commonly used frameworks libraries for unsupervised learning of word embeddings word2vec I am currently comparing tensorflow cpu gpu gensim deeplearning4j and the original c code on standard metrics like training time peak memory usage and quality of learned vectors Link to my github repo still working on it I ran the benchmark on text8 corpus plan to run it on a much larger corpus later for the true picture which gave me strange results Tensorflow on GPU is much slower than CPU Tensorflow is much slower than other frameworks Is this behavior expected Would appreciate any inputs Source code logs Link to tensorflow code Link to results of sample benchmark on text8 corpus,,,2017-09-14 20:27:56,2017-09-15 20:28:05
IS,Clarifying relations of high level APIs,There are right now several high level APIs in TensorFlow tf keras tf estimators tf layers tf contrib learn that seem to be sometimes complementary and sometimes redundant It is somewhat hard for me and other parts of the internet I have searched to understand which API to use for which purpose and how they relate to each other For me it would greatly help if it could be specified What is the intended high level API for the future Even so if none of them will be discontinued it would be nice one could just get pointed to one preferred All I could find the documentation right now is The higher level APIs are built on top of TensorFlow Core These higher level APIs are typically easier to learn and use than TensorFlow Core In addition the higher level APIs make repetitive tasks easier and more consistent between different users A high level API like tf estimator helps you manage data sets estimators training and inference How different modules from contrib relate to those in core tensorflow E g it seems that tf estimators is a portion of tf contrib learn that made it into core Why there are duplicate implementations like tf layers contrib conv2d and tf layers conv2d If modules have complementary or duplicate functionality E g tf layers can be used with tf estimators to define the model but probably one does not want to mix tf layers and tf keras It would be great if that could be specified in the Overview section of the respective documentations instead of just saying it is a high level API,,"yaroslavvb,martinwicke,facaiy,yaroslavvb,martinwicke,facaiy,martinwicke",2017-09-15 09:20:40,2017-09-15 20:55:24
PR,expose sparse column with vocabulary file method,The bug is explained in 12568 I am not familiar with build tool however I observe that the method is missing in init py,,"facaiy,yifeif,facaiy,drpngx,facaiy,drpngx,drpngx,drpngx,facaiy,drpngx,facaiy,drpngx,drpngx,drpngx",2017-08-26 07:31:59,2017-09-15 21:46:59
PR,Revert Updating default version for building from master source,Reverts tensorflow tensorflow 12970 This is breaking all our nightly links and our gcs links After further inspection we need to create a dynamically linked update version process For now I will add the update version logic combined with head links for all nightly packages,,"av8ramit,gunan,av8ramit",2017-09-15 21:10:26,2017-09-15 22:52:23
PR,Fix tf image central crop return zero dimension,This fix tries to address the issue raised in 10315 where tf image central crop will return 0 0 3 when input is 240 320 3 The issue is that the calculation was done by dividing which causes deviation when accuracy is not enough This fix did the calculation in double and use multiply until the last step A test case has been added This fix fixes 10315 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu,jhseu,jhseu,martinwicke,yifeif,drpngx,yongtang,drpngx,drpngx,yongtang,drpngx,yongtang,drpngx",2017-08-12 17:27:51,2017-09-16 01:35:55
PR,Branch 168917534,,,drpngx,2017-09-16 01:44:08,2017-09-16 02:38:26
IS,distributed Tensorflow assign device issue,I recently found an interesting issue on device assignment when I ran the following simple code test py As the code uses tf train replica device setter with worker device gpu 0 I imagine all tensorflow Variable ops go to the parameter server while all other type of ops stay in the worker However if we run the above code python test py job name ps task index 0 python test py job name worker task index 0 python test py job name worker task index 1 I notice that all tensorflow ops go to parameter server for example in the worker log report uninitialized variables boolean mask strided slice stack 2 Const job ps replica 0 task 0 gpu 0 But if I change worker device gpu 0 in the code to worker device job worker task 0 gpu 0 then the result is correct all non Variable ops go to worker So does it mean there is a bug for tf train replica device setter to automatically assign devices P S The above code runs on single GPU TITAN X Pascal PCIe SSE2 with Ubuntu 16 04 Python 3 5 and Tensorflow v1 2,,"yaroslavvb,mrry,yaroslavvb,yaroslavvb",2017-09-15 23:59:49,2017-09-16 17:13:37
PR,Revert accidentally changed android test proto lib dep to protos cc,android test proto lib is a Google internal target,,"andrewharp,asimshankar,andrewharp,andrewharp",2017-09-15 23:15:19,2017-09-16 17:37:16
PR,Branch 168957558,,,"caisq,caisq",2017-09-16 18:36:11,2017-09-16 20:20:49
IS,Failed to Load the native TensorFlow Runtime,I installed tensorflow through Anaconda with Python 3 6 2 It got installed successfully But I am not able to import tensorflow and I am using a 64 bit machine with Windows 10 OS I got following error import tensorflow as tf Traceback most recent call last File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users HP AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users HP AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users HP AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users HP AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users HP AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"reedwm,mrry",2017-09-13 17:35:46,2017-09-16 20:27:14
PR,Merge pull request 1 from tensorflow master,updating from original,,,2017-09-16 22:24:47,2017-09-16 22:25:26
PR,Docs tf constant docstring Whitespace fix,This should allow the python section to properly render on the API page which at the time of writing displays the fences in plain text,,"drpngx,gunan,drpngx",2017-09-15 16:42:24,2017-09-16 22:32:56
PR,Fix typo in math ops py,Subscripts in documentation of tensdordot function were not enclosed in curly braces which led to only one of the three subscripts being lowered,,drpngx,2017-09-15 07:58:32,2017-09-16 22:33:40
PR,Java Android Fix bug introduce in 12643,The contents of the graphDef file were not actually being read into the byte array,,"asimshankar,asimshankar,drpngx,drpngx,drpngx",2017-09-15 23:11:34,2017-09-16 22:36:58
PR,Fix incorrect error message in conv2d transpose,This fix fixes the incorrect error message in conv2d transpose where value get shape 3 should be changed to value get shape axis for input depth in NCHW format The incorrect error message could be seen from the following where 4 4 is quite confusing Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,yongtang,drpngx,drpngx",2017-09-16 23:53:55,2017-09-17 02:39:13
IS,tf contrib keras modules can not Open HDFS file,OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 TensorFlow installed from source or binary source TensorFlow version use command below 1 1 0 Bazel version if compiling from source CUDA cuDNN version 5 1 10 I use keras preprocessing image ImageDataGenerator class I invoke flow from directory function when train data dir is a HDFS directory the script throw exception I refer the source code I found the ImageDataGenerator class not use GFile class to open path So it is possible to use GFile to open file in tf contrib keras modules,,"skye,fchollet",2017-06-29 04:19:32,2017-09-17 17:43:48
IS,About the issue Ran out of GPU memory,HI every one I wrote my first tensorflow code it is a classic CNN And when I run it on Ubuntu16 it report error 2017 09 17 05 16 34 243946 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 09 17 05 16 34 243983 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 09 17 05 16 34 244007 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 09 17 05 16 34 244017 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 09 17 05 16 34 244023 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 09 17 05 16 35 679378 I tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name Tesla P100 SXM2 16GB major 6 minor 0 memoryClockRate GHz 1 4805 pciBusID 0000 89 00 0 Total memory 15 89GiB Free memory 15 61GiB 2017 09 17 05 16 36 490317 W tensorflow stream executor cuda cuda driver cc 523 A non primary context 0xab5bff0 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2017 09 17 05 16 36 492491 I tensorflow core common runtime gpu gpu device cc 955 Found device 1 with properties name Tesla P100 SXM2 16GB major 6 minor 0 memoryClockRate GHz 1 4805 pciBusID 0000 8a 00 0 Total memory 15 89GiB Free memory 15 61GiB 2017 09 17 05 16 36 496233 I tensorflow core common runtime gpu gpu device cc 976 DMA 0 1 2017 09 17 05 16 36 496258 I tensorflow core common runtime gpu gpu device cc 986 0 Y Y 2017 09 17 05 16 36 496267 I tensorflow core common runtime gpu gpu device cc 986 1 Y Y 2017 09 17 05 16 36 496282 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name Tesla P100 SXM2 16GB pci bus id 0000 89 00 0 2017 09 17 05 16 36 496353 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 1 device 1 name Tesla P100 SXM2 16GB pci bus id 0000 8a 00 0 step 0 train accuracy 0 step 100 train accuracy 0 845555 step 200 train accuracy 0 80391 step 300 train accuracy 0 913599 step 400 train accuracy 0 893777 step 500 train accuracy 0 918844 step 600 train accuracy 0 937555 2017 09 17 05 16 41 502931 E tensorflow core common runtime bfc allocator cc 244 tried to allocate 0 bytes 2017 09 17 05 16 41 503008 W tensorflow core common runtime allocator retry cc 32 Request to allocate 0 bytes 2017 09 17 05 16 41 503035 E tensorflow core common runtime bfc allocator cc 244 tried to allocate 0 bytes 2017 09 17 05 16 41 503060 W tensorflow core common runtime allocator retry cc 32 Request to allocate 0 bytes 2017 09 17 05 16 41 503223 E tensorflow core common runtime bfc allocator cc 378 tried to deallocate nullptr 2017 09 17 05 16 41 503268 E tensorflow core common runtime bfc allocator cc 378 tried to deallocate nullptr Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python client session py line 1327 in do call return fn args File usr local lib python3 5 dist packages tensorflow python client session py line 1306 in run fn status run metadata File usr lib python3 5 contextlib py line 66 in exit next self gen File usr local lib python3 5 dist packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl ResourceExhaustedError Ran out of GPU memory when allocating 0 bytes for Node SoftmaxCrossEntropyWithLogits SoftmaxCrossEntropyWithLogits T DT FLOAT device job localhost replica 0 task 0 gpu 0 Reshape 2 Reshape 3 During handling of the above exception another exception occurred Traceback most recent call last File check cnn py line 228 in module TrainNetwork File check cnn py line 147 in TrainNetwork sess run train step feed dict x xs y ys keep prob 0 5 File usr local lib python3 5 dist packages tensorflow python client session py line 895 in run run metadata ptr File usr local lib python3 5 dist packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File usr local lib python3 5 dist packages tensorflow python client session py line 1321 in do run options run metadata File usr local lib python3 5 dist packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl ResourceExhaustedError Ran out of GPU memory when allocating 0 bytes for Node SoftmaxCrossEntropyWithLogits SoftmaxCrossEntropyWithLogits T DT FLOAT device job localhost replica 0 task 0 gpu 0 Reshape 2 Reshape 3 Caused by op 'SoftmaxCrossEntropyWithLogits' defined at File check cnn py line 228 in module TrainNetwork File check cnn py line 128 in TrainNetwork cross entropy tf nn softmax cross entropy with logits logits Ylogits labels y File usr local lib python3 5 dist packages tensorflow python ops nn ops py line 1597 in softmax cross entropy with logits precise logits labels name name File usr local lib python3 5 dist packages tensorflow python ops gen nn ops py line 2385 in softmax cross entropy with logits features features labels labels name name File usr local lib python3 5 dist packages tensorflow python framework op def library py line 767 in apply op op def op def File usr local lib python3 5 dist packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File usr local lib python3 5 dist packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback Ran out of GPU memory when allocating 0 bytes for Node SoftmaxCrossEntropyWithLogits SoftmaxCrossEntropyWithLogits T DT FLOAT device job localhost replica 0 task 0 gpu 0 Reshape 2 Reshape 3 The system is ubuntu16 tensorflow 1 2 CUDA 8 cudnn 6 the machine is Sun Sep 17 06 30 45 2017 NVIDIA SMI 375 26 Driver Version 375 26 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Tesla P100 SXM2 On 0000 89 00 0 Off 0 N A 39C P0 34W 300W 0MiB 16276MiB 0 Default 1 Tesla P100 SXM2 On 0000 8A 00 0 Off 0 N A 38C P0 32W 300W 0MiB 16276MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage No running processes found So please help me for this thanks,,yaroslavvb,2017-09-17 06:50:45,2017-09-17 17:49:15
IS,zeros like does not fully respect the optimize argument,The definition of zeros like L1463 is We can see that if the shape of tensor is already known the optimize parameter is ignored which is inconsistent with the documented behavior,,yongtang,2017-08-21 03:15:45,2017-09-17 18:11:34
PR,Respect optimize parameter in zeros like,This fix address the issue in 12436 where optimize flag was not respected when shape is fully defined for zeros like This fix fixes 12436 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,benoitsteiner,drpngx,drpngx,drpngx",2017-08-21 21:49:50,2017-09-17 18:11:34
PR,12537 issue solution,printing prefix message by parameter value,,"byronyi,drpngx",2017-08-24 16:08:19,2017-09-17 18:20:14
PR,Update tf nn in top k to use v2 kernel,This fix is a follow up to PR 11197 so that tf nn in top k uses V2 kernel now This fix follows the API compatibility workflow 3 weeks This fix also updates related tests so that gen nn ops could be removed This fix fixes 9717 NOTE In the original PR 11197 the in top kv2 was incorrectly called even the comments specified to wait for 3 weeks That was fixed by commit Thanks for the fix Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,drpngx",2017-09-16 18:53:06,2017-09-17 18:30:01
PR,Update readme of CRF,PR 12056 implemented CRF decoding in tensor way but the README has not been updated This PR got this done,,"jinze1994,jinze1994,drpngx,drpngx,drpngx,drpngx",2017-09-14 15:53:16,2017-09-17 18:39:29
PR,Use corret SDK paths from xcrun,Closes 12650,,"martinwicke,drpngx",2017-08-29 09:02:53,2017-09-17 18:41:36
PR,Fixes 11829 Faster to import tensorflow contrib on Python 3,As described in 11829 a lot of time is spent doing inspect stack when importing import tensorflow contrib with Python 3 There does not seem to be any issue with Python 2 By replacing inspect stack with only getting the current and previous frame and then getting the frame info for just the previous frame this unnecessary overhead is removed The time to import tensorflow contrib as reported by time python2 3 c import tensorflow contrib before and after my commit When Python 2 7 13 Python 3 6 2 before 3 2 7 5 after 3 1 3 3 There are unit tests that would catch if the decorator name would be incorrect after my change specifically these tests testSetsDecoratorNameToFunctionThatCallsMakeDecoratorIfAbsent testUnwrapReturnsDecoratorListFromOutermostToInnermost testUnwrapBoundMethods All Python unit tests passed in Docker I did not find any issues when linting the changed file,,"charlesnicholson,benoitsteiner,rmlarsen,drpngx,charlesnicholson,drpngx",2017-07-27 22:38:12,2017-09-17 20:38:11
IS,Slow to import tensorflow contrib with Python 3 because inspect stack is slow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 5 TensorFlow installed from source or binary source TensorFlow version use command below v1 2 0 2420 g2b4a0f9a4 1 3 0 rc0 Python version 3 6 2 Bazel version if compiling from source 0 5 2 homebrew CUDA cuDNN version CPU only build GPU model and memory CPU only build Exact command to reproduce time python3 c import tensorflow contrib The problem Doing import tensorflow contrib take 7 5 seconds on my machine when doing it with Python 3 6 2 With Python 2 7 13 it takes 3 2 seconds Investigating this revealed that a lot of time is spent in inspect stack in the function make decorator in python util tf decorator py The stack is inspected to find the name of the caller of the function With Python2 inspect stack is fast but with Python 3 each call to inspect stack take approximately 0 2 seconds and there are 23 calls made which account for the difference in time between Python 2 and 3 References Keras by default imports tensorflow contrib when the Tensorflow backend is used Therefore Keras is slow to import when using Python 3 There is a stackoverflow question referencing this issue,,"drpngx,drpngx,drpngx",2017-07-27 22:21:25,2017-09-17 20:38:41
PR,remove unused member vairable and clear compiler warning,I remove highest eax and clear this compiler warning because it is unused,,"horance-liu,drpngx,drpngx",2017-08-25 01:43:19,2017-09-17 20:38:45
PR,Rename all BackProp to Backprop for consistency,Resolving issue 12515 First attempt to start contributing to tensorflow,,"benoitsteiner,drpngx",2017-08-26 23:32:08,2017-09-17 20:39:00
PR,TensorFlowInferenceInterface Constructor with Graph,Added a new Constructor with Graph object only it would be very useful for custom graph loading Combining with 12668 user can even perform custom graph loading in C C via Android NDK as well New Constructor Signature public TensorFlowInferenceInterface Graph g,,"resec,drpngx",2017-08-29 03:36:07,2017-09-17 20:39:43
IS,Inconsistent use of naming Backprop,Describe the problem Tensorflow code has two types of naming Backprop and BackProp How about to rename all BackProp to Backprop for consistency Source code logs Backprop in code control flow ops py L909 op level cost estimator cc L672,,,2017-08-23 06:03:02,2017-09-17 23:51:51
IS,tf py func errors in freeze graph,I use tf py func in my networks and it works fine in training and test mode Then I run bazel bin tensorflow python tools freeze graph to freeze the graph and generate xxx pb file I try to restore the xxx pb and run the model again error happens Erorr logs I found the tf py func is not in the graph How can I define and use the tf py func in freezed graph,,yaroslavvb,2017-08-07 09:01:18,2017-09-18 02:36:49
IS,nsync is broken on Windows in Bazel build,nsync is introduced in b48cfaea2aea3707a33e60c10385a87e37101b95 Fortunately nsync already builds on Windows with CMake I have sent a PR to add Bazel support cc Could you please merge the PR or is there any other way you prefer me to contribute to this repo,,"meteorcloudy,meteorcloudy,meteorcloudy",2017-08-23 10:46:26,2017-09-18 07:47:48
IS,tensorflow python debug cli offline analyzer failed to read debug data from HDFS filesys,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 from master branch Python version Python 2 7 12 default Nov 19 2016 06 48 10 Bazel version if compiling from source 0 4 5 CUDA cuDNN version null GPU model and memory null Exact command to reproduce python m tensorflow python debug cli offline analyzer dump dir hdfs debug data dir Issue description I saved debug data by DumpingDebugHook into hdfs filesys and then it failed to read the data by python m tensorflow python debug cli offline analyzer dump dir hdfs debug data path but it works well with the local filesys by the same way Error info,,,2017-09-18 08:38:12,2017-09-18 09:43:26
IS,'DNNClassifier' object has no attribute ' train model',I got an error saying 'DNNClassifier' object has no attribute ' train model' when I run this,,,2017-09-18 09:18:12,2017-09-18 10:10:28
IS,An error in llvm Object SymbolicFile h expected ' ' before 'PRIxPTR',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS Linux release 7 2 1511 Core TensorFlow installed from source or binary source TensorFlow version use command below git hash 1e96d54d9f928c4ea4bf0564ef9900f6bd03acd5 Python version 3 6 1 Bazel version if compiling from source 0 5 3 CUDA cuDNN version CUDA 8 0 cudnn 5 1 5 GPU model and memory Titan X Maxwell Titan X Pascal GTX 1080 Pascal Exact command to reproduce bazel build config opt verbose failures config cuda tensorflow tools pip package build pip package Compiler used gcc It seems to be a problem with a header file and hence I would be grateful for answering this bug,,"mrry,yongtang,sanjoy",2017-09-12 15:10:15,2017-09-18 11:25:14
PR,Fix issue in tf image extract glimpse,This fix tries to fix the issue raised in 2134 where tf image extract glimpse does not work as expected when centered False and normalized False This fix fixes 2134 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx",2017-09-05 21:42:02,2017-09-18 13:18:54
PR,Fix test breakage on Mac Python3 due to assert called,Replace assert called with self assertTrue and called,,"caisq,caisq,caisq,drpngx,xiejw",2017-09-18 00:13:48,2017-09-18 13:27:41
PR,Fix typos,This PR fixes some typos Tenor tenor and varibles,,"taehoonlee,caisq",2017-09-18 02:08:47,2017-09-18 15:37:24
PR,Cover the numpy ndarray bug on s390x,NumPy is low level method for instantiating an array ndarray constructor is behaving differently for s390x architecture Providing the data type of the array is elements explicitly is solving the issue Please refer to issue 11431 for the detailed discussion Though this a bug with NumPy implementation adding data type for array elements should be safe,,"mrry,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-09-11 13:49:54,2017-09-18 15:38:02
IS,Session creation silently failing on iOS when loading a SavedModel,Issue I am trying to integrate a TensorFlow solution into my iOS apps but inference does not seem to work when I try to run simple graphs created in Python In fact the tensorflow inception graph from the examples is the only graph that seems to work with iOS inference Every other inference attempt is met with the following error Invalid argument Session was not created with a graph before Run So what I'm finding is that on mobile if we try to run a canned neural network like the tensorflow inception graph inference works perfectly but if we try to run any kind of custom model like 1 1 2 the graph wo not run To demonstrate this I used Python to write and export to a SavedModel the simplest graph I can think of it just adds 1 1,,"mrry,mrry",2017-09-17 00:01:57,2017-09-18 15:47:05
PR,Unreachable input gradients,This PR checks if all the inputs are reachable from the outputs during AddSymbolicGradients would be the best person to review this task as she asked me to add a TODO during a previous PR,,"theflofly,skye,skye,skye,skye,skye,drpngx,drpngx,drpngx,drpngx,drpngx,skye,theflofly,theflofly,theflofly,drpngx,caisq",2017-09-15 20:19:11,2017-09-18 17:35:47
PR,Introduce MPI allreduce and allgather in a new contrib project,This commit adds the tensorflow contrib mpi collectives namespace and contrib project which has a variety of ops that work with MPI The MPI system works by starting a background thread which communicates between the different processes at a regular interval and schedules asynchronous reductions At every tick every rank will notify rank zero of the tensors it is ready to reduce signifying completion with an empty DONE message Rank zero will count how many ranks are ready to reduce every tensor and whenever a tensor is ready to reduce that is every rank is ready to reduce it rank zero will issue a message to all other ranks directing them to reduce that tensor This repeats for all the tensors that are ready to reduce after which rank zero sends all other ranks a DONE message indicating that the tick is complete Authors Andrew Gibiansky andrew gibiansky gmail com Joel Hestness jthestness gmail com,,"jthestness,jthestness,jthestness,jthestness,jthestness,jthestness,alsrgv,byronyi,martinwicke,martinwicke,jthestness,martinwicke,martinwicke,martinwicke,gunan,jthestness,gunan,drpngx,jthestness,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,jhseu,jthestness",2017-08-15 16:24:43,2017-09-18 18:14:20
PR,Reopened XLA Bring XLA Transpose021Tiled up to date with reference CUDA implementation,Reopening this PR The commits have been cherry picked to master branch Ping because you were the previous assignee and assigner,,"tjingrant,jlebar,jlebar,tjingrant,jlebar,jpienaar,jpienaar,tjingrant,jpienaar,tjingrant,tjingrant,drpngx,drpngx,drpngx,drpngx",2017-08-28 21:09:39,2017-09-18 18:14:32
PR,cmake external projects pass libdir to configure,If libdir is not set configure will install into a subdirectory lib64 on some platforms while the build system has lib hard coded to find the static libraries later,,"yifeif,yifeif,mrry,drpngx,drpngx,drpngx",2017-08-31 20:00:15,2017-09-18 18:16:19
PR,Fix undefined reference to libtensorflow core a,Adjust gcc parameter order to fix linker error Tested on gcc version 5 4 0 20160609 Ubuntu Linaro 5 4 0 6ubuntu1 16 04 4,,"yifeif,drpngx,drpngx,caisq",2017-09-03 08:54:24,2017-09-18 19:28:35
PR,R1 3,good,,drpngx,2017-09-18 11:16:17,2017-09-18 19:30:20
PR,Fix anchor tag in adding an op md,Default anchor tag id is generated by the target text of the title And it uses an underscore instead of hyphen,,"Lewuathe,drpngx,MarkDaoust,drpngx,drpngx,drpngx,drpngx",2017-08-27 01:34:35,2017-09-18 20:05:16
PR,Added the EMNIST dataset,This PR adds EMNIST to the datasets EMNIST is an extension of the MNIST dataset but it also adds Characters and more numbers It can be found in the paper here,,"drpngx,av8ramit,nealwu,vincentvanhoucke,nealwu",2017-08-11 14:54:38,2017-09-18 21:45:32
PR,Reverting the version back to 1 3 Sync rotation reverted the revert,,,av8ramit,2017-09-18 20:42:36,2017-09-18 22:46:24
PR,Skip environment check if config is from core,Since core RunConfig does not have environment,,"terrytangyuan,xiejw,xiejw,terrytangyuan,terrytangyuan,terrytangyuan,terrytangyuan,martinwicke,martinwicke,terrytangyuan,drpngx,terrytangyuan,drpngx",2017-07-08 19:51:21,2017-09-18 23:03:35
PR,Add py3 support for speech commands example,Add imports for xrange and cast iterable to list,,"caisq,caisq,drpngx,caisq,drpngx",2017-09-18 03:28:15,2017-09-18 23:35:30
PR,Increasing the minor version of the nightly version by 1,Expedited patch via github,,av8ramit,2017-09-18 23:08:33,2017-09-18 23:36:21
PR,fixed a typo in the documentation,fixed a typo in the documentation,,,2017-09-18 23:50:01,2017-09-18 23:55:13
PR,Added missing error check,,,"anight,anight,asimshankar",2017-09-18 20:02:25,2017-09-19 00:05:30
PR,Add int64 t typemap for swig,,,"jhseu,drpngx,drpngx,drpngx,drpngx",2017-08-04 07:47:53,2017-09-19 00:43:59
PR,Branch 169166848,,,caisq,2017-09-18 23:46:26,2017-09-19 01:08:24
PR,Update mnist beginners softmax variables,The usage of variable 'x' when describing the softmax function can be confusing to newcomers since 'x' is used immediately prior to represent the unweighted input Continuing the usage of 'evidence' helps with continuity,,drpngx,2017-09-15 04:55:02,2017-09-19 02:02:20
IS,Ca not freeze pbtxt to pb file Multiple OpKernel registrations match NodeDef after compiled android arm so,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 12 Bazel version if compiling from source 0 5 4 CUDA cuDNN version 8 0 61 GPU model and memory NVIDIA Corporation Device 1b06 Exact command to reproduce I know the op FIFOQueueV2 is not supported on Android so I followed 8404 recompiled my so file before this occurred But does it result in this Does it only be used when model loaded on Android Or all bazel compilation,,,2017-09-18 10:21:56,2017-09-19 06:53:33
IS,tf nn in top k strange behavior,Based on the documentation here tf nn in top k treats ties as positive which is almost never what you would want This is a major flaw which leads to misleading metrics An all zero predictions would give you 0 error with any targets I think the default behavior should be to not count ties,,"reedwm,facaiy,ppwwyyxx,ppwwyyxx,ppwwyyxx,martinwicke",2017-09-13 02:00:29,2017-09-19 07:15:44
PR,Fixed XLA for integration as submodule,This PR incorporates some of the known workarounds like str Label to enable the integration as a git submodule when using XLA This was only tested on a macOS environment with a project using tf library Maybe someone with his her own xla project could cross check this,,"hawkinsp,yifeif,drpngx,drpngx,drpngx,drpngx,drpngx,frankchn,frankchn,drpngx,vrv,rmlarsen,drpngx",2017-06-19 11:11:17,2017-09-19 14:55:25
IS,Error for slim dataset using fixed length reader,I want to use tensorflow slim data provider All examples I can find only are only reading tfrecord files However I want to read binary files directly by my own reader I use fixed length reader to extract Cifar10 binary data However dataBytes tf decode raw data tf unit8 always produce error that AttributeError module 'tensorflow' has no attribute 'unit8' when using in slim DatasetDataProvider But no such error occurs when I use the reader directly without using DatasetDataProvider Did I not use it correctly or does DatasetDataProvider only support tfrecord readers Thank you My codes are as below CIFAR LABEL BYTE 1 CIFAR HEIGHT 32 CIFAR WIDTH 32 CIFAR DEPTH 3 CIFAR RECORD BYTE CIFAR HEIGHT CIFAR WIDTH CIFAR DEPTH CIFAR LABEL BYTE CIFAR CLASS NUM 10 CIFAR TRAINING NUM 50000 CIFAR TEST NUM 10000 ITEMS TO DESCRIPTIONS 'image' 'A 32 x 32 x 3 color image ' 'label' 'A single integer between 0 and 9' class CifarBinaryDecoder DataDecoder def decode self data items outputs print data shape dataBytes tf decode raw data tf uint8 for item in items if item 'label' currLabel tf cast tf strided slice dataBytes 0 CIFAR LABEL BYTE tf int32 outputs append currLabel if item 'image' imageData tf reshpae tf strided slice dataBytes CIFAR LABEL BYTE CIFAR RECORD BYTE CIFAR DEPTH CIFAR HEIGHT CIFAR WIDTH imageData tf transpose imageData 1 2 0 outputs append imageData return outputs def list items self return 'label' 'image' def get cifar10 training filenames binary data dir file pattern 'test batch bin' return file pattern def get cifar training dataset binary data dir file pattern get cifar10 training filenames binary data dir decoder CifarBinaryDecoder return slim dataset Dataset data sources file pattern reader tf FixedLengthRecordReader decoder decoder num samples CIFAR TRAINING NUM items to descriptions ITEMS TO DESCRIPTIONS num classes CIFAR CLASS NUM def main dataset get cifar training dataset FLAGS cifar data dir provider slim dataset data provider DatasetDataProvider dataset num readers 1 common queue capacity 1000 common queue min 500 reader kwargs arecord bytes' CIFAR RECORD BYTE with tf Session as sess init op tf group tf global variables initializer tf local variables initializer sess run init op tf train start queue runners for i in range 2 img lab provider get 'image' 'label' image label sess run img lab,,"mrry,mrry",2017-09-19 15:54:14,2017-09-19 17:17:21
IS,how can i convert a frozen pb file to ckpt file,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,shivaniag,2017-09-19 03:53:52,2017-09-19 17:19:32
IS,Where can I get the pre trained models in slim,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,shivaniag,2017-09-19 00:52:27,2017-09-19 17:20:50
IS,label image run slower and slower,Hello Everyone Is there anybody who had ever run the code label image py in tensorflow tensorflow examples label image label image py I have modify it to run on a dataset and read and calssify image one by one and as the number of images goes the speed is slower and slower at first that is about ten images per second and when the number of image goes to 1000 the time is about 7s Incredibly and I find the problem is in the function read tensor from image file in label image py and this part is read and preprocess images so what is the matter and I want to know how to speed up and how to modify the code so as to making it run for batches,,shivaniag,2017-09-19 02:30:43,2017-09-19 17:42:13
IS,Session run with fetches list apparently works incorrectly,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow The problem manifests in a standard tutorial and I wrote custom code to better understand it OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 12 default Nov 19 2016 06 48 10 GCC 5 4 0 20160609 on linux2 Bazel version if compiling from source CUDA cuDNN version no GPU GPU model and memory none Describe the problem The TensorFlow Mechanics 101 tutorial code outputs value of the same Op loss in two ways summary and console output The two values do not match The code is located here To make the problem clear I changed the console output format on line 305 to 8 decimals cat sprintf 'Step d loss 8f 3f sec n' I compared the console output for loss with the results of the summary Op the op is defined on lines 120 and 262 and run on line 308 I obtained the results of the summary op from the csv file downloaded from tensorboard The console output is close to the csv file but different often in the third decimal they should be identical since the op is the same on the same step I do not copy the output here since it is unstable changes from one run to another I have not been able to stabilize it with use session with seed or with tf set random seed I changed lines 297 298 from values sess run list train op loss feed dict feed dict loss value values 2 to a supposedly equivalent code sess run train op feed dict feed dict loss value sess run loss feed dict feed dict After that the console output agreed fully with summary data obtained from csv I take it that sess run list works incorrectly I do not know whether the problem is in TensorFlow or in the R interface to it,,"ppwwyyxx,yaroslavvb,PuchatekwSzortach,yaroslavvb,PuchatekwSzortach,PuchatekwSzortach",2017-09-18 22:07:44,2017-09-19 18:32:57
IS,Help completely removing Tensorflow pip and virtualenv,Hey there I am new to all the tf and Python programming and have installed tensorflow through pip and virtualenv but now I read that in order to use Spyder for Python it is best to use Anaconda I know that tf can be installed through conda as well but how do I go about it now Do I have to completely remove the existing installations first and if yes can someone explain in detail which and how I can do it Thanks in advance,,yaroslavvb,2017-09-16 19:10:00,2017-09-19 18:35:24
IS,Trouble installing as well as uninstalling Tensorflow,So as you can see here we have python and anaconda If it is pre installed as it says ideally the program 1 should work but it does not Can you help please,,shreyneil,2017-09-17 17:28:15,2017-09-19 18:38:04
IS,tf contrib data Dataset outputs have only partial shape,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source N A CUDA cuDNN version 8 0 6 GPU model and memory Titan X 12GB Exact command to reproduce see below Describe the problem Dataset outputs should have the first shape dimension specified when dataset batch is specified Instead is given Source code logs,,"mrry,mrry,mrry,mrry",2017-09-19 18:06:13,2017-09-19 18:39:01
PR,Refactoring Pull out repeated shape related code into shared function,While looking for some example code to initialize an op is output shape from a shape provided in an attribute I found a six line snippet that is repeated in seven different places It looks like some copying and pasting has happened in the past This pull request pulls that shared code into a single function in common shape fns cc,,"frreiss,caisq",2017-09-19 17:04:56,2017-09-19 19:35:29
IS,Missing tensorflow core debug debug service grpc pb h header file,Hi debug io utils h includes a header file tensorflow core debug debug service grpc pb h which is missing from the repo This causes build on Linux failed TODO cais Support grpc debug URLs in open source once Python grpc genrule becomes available See b 23796275 ifndef PLATFORM WINDOWS include tensorflow core debug debug service grpc pb h Anyone see this issue Thanks RLE,,"caisq,caisq,yongtang,yongtang",2017-08-03 20:03:55,2017-09-19 22:33:10
PR,Fix cmake build issue on Linux,This fix tries to address the issue raised in 12018 and 13061 where the cmake build on Linux caused error This fix addressed several issues 1 Add grpc cpp plugin to the cmake build process This is needed to address the following error 2 Fix a missing CMakefile issue for sqlite on Linux 3 Fix a build error caused by libjpeg turbo vs jpeg The build error is temporarily addressed with LIBJPEG TURBO VERSION used to detect the underlying library This fix fixes 12018 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,caisq,caisq",2017-09-19 04:49:30,2017-09-19 22:33:10
PR,Replace WIN32 PLATFORM WINDOWS,I was trying to make cmake build on Linux 12018 13061 but noticed that WIN32 was used in tensorflow core lib jpeg jpeg mem cc I do not know enough history with TensorFlow is code base though I assume WIN32 should only be inside tensorflow core platform Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang",2017-09-18 16:16:08,2017-09-19 22:41:03
PR,Fixing protobuf bazel workspace issue,Removing the github mirror which has the wrong sha hash,,"av8ramit,gunan",2017-09-19 22:47:55,2017-09-19 23:56:33
IS,IGNORE,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,shivaniag,2017-09-19 22:49:54,2017-09-19 23:57:03
PR,GDR Eliminate several unnecessary sync barriers,Following the plan I mentioned in issuecomment 323101744 I have refactored out the sync wrapper around copy between CPU and GPU Now the user need to supply a StatusCallback when calling RemoteMemoryManager TransportOptionsFromTensor and RemoteMemoryManager TensorFromTransportOptions in order to prepare for the potential CPU GPU tensor transfer,,"byronyi,drpngx,drpngx",2017-09-19 01:10:24,2017-09-20 01:34:09
PR,Non scalar Multinomial draws,This PR tries to fix the issue in 12804 where supports total count to be a non scalar tensor I have already test this feature in local but I have not found any file to add test code please let me know if I need to add any test code,,jinze1994,2017-09-20 11:08:49,2017-09-20 11:17:04
IS,Quantize training test fails with matmul operation on Ubuntu 16 04,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version 2 7 12 Bazel version if compiling from source 0 4 5 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce bazel test c opt tensorflow python quantize training test The problem The testQuantizedSaveRestore from tensorflow python quantize training test is failing on s390x while importing graph here L72 The error message shown is ValueError Shapes must be equal rank but are 0 and 2 for 'a Min AssignValue' op 'Assign' with input shapes 1 1 The check for this failure is at Merge function L374 This Merge is called by Assign Op kernel I tried changing the math ops matmul operation from the above test to math ops subtract minimum multiply With these operations the test passes after removing asserts for 'a Min Variable 0' or 'b read Max Variable 0' etc I suppose other operations do not create these tensors Could anyone please provide some inputs on this failure I am not aware about the computations that are happening when graph is imported with the matmul operation Source code logs,,"namrata-ibm,namrata-ibm,namrata-ibm",2017-08-09 09:53:31,2017-09-20 12:09:17
PR,Remove multiple includes of gpu tracer cc in Makefile build,Currently the tensorflow core platform default gpu tracer cc is included by both L468 and L515 in the Makefile Leading to multiple definition build failure when the built tensorflow static lib is linked by other project ndk root toolchains x86 64 4 9 prebuilt darwin x86 64 lib gcc x86 64 linux android 4 9 x x86 64 linux android bin ld error tensorflow root lib x86 64 libtensorflow core a gpu tracer o multiple definition of 'tensorflow CreateGPUTracer ' ndk root toolchains x86 64 4 9 prebuilt darwin x86 64 lib gcc x86 64 linux android 4 9 x x86 64 linux android bin ld tensorflow root lib x86 64 libtensorflow core a gpu tracer o previous definition here clang error linker command failed with exit code 1 use v to see invocation Problem should be introduced from 083f5433f65b92a406f41806e7bc8c5d0ae679ac So removed the later include to resolve the problem,,"resec,drpngx,drpngx,gunan,drpngx,drpngx",2017-09-18 02:01:27,2017-09-20 13:54:08
IS,No OpKernel was registered to support Op 'Transpose' with these attrs,System information Windows 10 TensorFlow installed from source TensorFlow version r1 3 Python version 3 5 3 Bazel version n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce n a Describe the problem The 'Transpose Op is not supported sufficiently in C environment I have got this below Does transpose operation ever works in a pure C project Source code logs No OpKernel was registered to support Op 'Transpose' with these attrs Registered devices CPU Registered kernels device 'CPU' T in DT INT64 Tperm in DT INT32 device 'CPU' T in DT INT32 Tperm in DT INT32 device 'CPU' T in DT UINT16 Tperm in DT INT32 device 'CPU' T in DT INT16 Tperm in DT INT32 device 'CPU' T in DT UINT8 Tperm in DT INT32 device 'CPU' T in DT INT8 Tperm in DT INT32 device 'CPU' T in DT HALF Tperm in DT INT32 device 'CPU' T in DT FLOAT Tperm in DT INT32 device 'CPU' T in DT DOUBLE Tperm in DT INT32 device 'CPU' T in DT COMPLEX64 Tperm in DT INT32 device 'CPU' T in DT COMPLEX128 Tperm in DT INT32 device 'CPU' T in DT BOOL Tperm in DT INT32 device 'CPU' T in DT STRING Tperm in DT INT32 device 'CPU' T in DT RESOURCE Tperm in DT INT32 device 'CPU' T in DT BFLOAT16 Tperm in DT INT32,,,2017-09-20 13:27:18,2017-09-20 14:25:51
PR,upgrade tensorflow to latest package,1 upgrade package to 1 3 0rc2 the latest package 2 imporve ipykernel install steps under python 2 x,,"caisq,caisq,caisq,caisq,drpngx",2017-09-19 10:20:28,2017-09-20 14:33:00
PR,Branch 169299199,I needed a file from master asap so I thought I would push,,"av8ramit,av8ramit,caisq,caisq,caisq",2017-09-19 22:50:09,2017-09-20 14:37:30
PR,A fix for,The problem was with usage of runtime SetFinalizer in golang bindings When a variable become unreferenced GC can harvest it any moment after According to this SetFinalizer For example if p points to a struct that contains a file descriptor d and p has a finalizer that closes that file descriptor and if the last use of p in a function is a call to syscall Write p d buf size then p may be unreachable as soon as the program enters syscall Write The finalizer may run at that moment closing p d causing syscall Write to fail because it is writing to a closed file descriptor or worse to an entirely different file descriptor opened by a different goroutine To avoid this problem call runtime KeepAlive p after the call to syscall Write In our case unreferenced variable was feeds i e input tensors After investigations I found out that func t Tensor finalize was called a way before SessionRun was finished and that was the cause of crash,,"anight,anight",2017-09-20 14:46:13,2017-09-20 14:47:17
IS,random crashes while serving multiple frozen models in parallel using go api,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I have written custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Linux x86 64 SLES12 TensorFlow installed from source or binary Source latest master at the moment TensorFlow version use command below 'v1 3 0 rc1 2265 g6e7539b' '1 4 0 dev' I also tried r1 3 with similar result Python version Python 2 7 9 Bazel version if compiling from source Build label 0 5 4 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Aug 25 10 00 00 2017 1503655200 Build timestamp 1503655200 Build timestamp as int 1503655200 CUDA cuDNN version Not used GPU model and memory Not used Exact command to reproduce tfcrash n models 16 n images 100 An output of this program can be different The bug has random nature In some cases the process just segfaults Typical output is tfcrash n models 16 n images 100 2017 09 18 16 45 43 setting 8 cpu 2017 09 18 16 45 43 launching 16 models 2017 09 18 16 45 43 feeding 100 images 2017 09 18 16 45 43 waiting 2017 09 18 16 45 51 session Run failed Expects arg 0 to be uint8 but INVALID is provided Or tfcrash 2017 09 18 16 57 54 setting 8 cpu 2017 09 18 16 57 54 launching 16 models 2017 09 18 16 57 54 feeding 100 images 2017 09 18 16 57 54 waiting Segmentation fault core dumped Describe the problem I'm trying to serve predictions from multiple frozen models that I have trained and generated previously using python script My programming language for serving predictions is golang I have found that sometimes my process crashes randomly Exact conditions needed to reproduce this behaviour are unknown It is also unknown if this bug related to golang bindings or tensorflow itself I also tried different builds of tensorflow all of them are affected so far including one built with cuda support I also noticed that setting lower numbers for n images and n models parameters decreases probability of bug reproduction In my experience setting n models to 16 and up gives 100 probability of crash I tried both go 1 8 3 and go 1 9 with similar result Source code logs I wrote a short program less than 100 lines in go which is able to reproduce crash with 90 probability The model file type frozen pb size 34Mb,,"anight,anight",2017-09-18 16:20:49,2017-09-20 15:20:29
IS,send recv operators bug in constructing the graph,Running the following snippet several times shows some weird operator in the graph There is a weird operator in it name send Const 0 just send tensor from cpu0 to cpu0 This device already has the right result of Add operator And I notice the send device incarnation is a random number which generates by New64 L43 The whole log of this snippet available in Thanks,,"yaroslavvb,mrry",2017-09-20 01:09:58,2017-09-20 16:10:51
PR,Cleanup work,Updated summary op util py head py estimator py lookup ops py,,"alanyee,drpngx,alanyee,drpngx,drpngx,drpngx,alanyee",2017-09-04 20:24:04,2017-09-20 16:45:09
PR,fixed doc typo,,,,2017-09-20 16:40:27,2017-09-20 17:32:21
IS,Memory Leak from Training Step,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes although my code is somewhat based on the MNIST deep learning tutorial OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 VERSION 14 04 5 LTS Trusty Tahr TensorFlow installed from source or binary Installed via the VirtualEnv method TensorFlow version use command below 1 1 and 1 2 Bazel version if compiling from source CUDA cuDNN version CUDA Version 8 0 44 GPU model and memory GeForce GTX 780M 4GB Exact command to reproduce self sess run self train step feed dict self x trainingdata self y true traininglabels self keepratio self training keep rate Describe the problem This is very similar to the bug report I submitted here but is a bit of a slower leak and is present in both TF 1 1 and 1 2 I have finalized my graph Using the architecture described by Zeiler et al 2013 ZF Net batch sizes of 64 and 224x224 grayscale 1 channel input it leaks approximately 4GB after approximately 3000 batches This makes it unworkable for say 80 epochs of ImageNet training I have confirmed that the leak either does not occur or is much less severe hard to tell which if I comment out the training line i e still do all of my preprocessing and loading As directed in that last linked issue I tried to call sess run with options tf RunOptions trace level tf RunOptions FULL TRACE run metadata run metadata and start the program with env TF CPP MIN VLOG LEVEL 1 python deep learning main py but the amount of spew was enormous and it wo not respond to keyboard interrupts I have to kill the job If that info would be helpful how do I go about recording saving this information properly to upload and help you all debug 1 08 zip,,"reedwm,yaroslavvb,reedwm,yaroslavvb,aselle,aselle",2017-07-24 16:34:32,2017-09-20 17:57:53
PR,Add cudnn7 support,Attention xq Account for cudnnSetRNNDescriptor API change Add support for CUDNN TENSOR OP MATH in cudnn v7 Applies to forward and backward convolutions that have fp16 input output Computations will fall back to pseudo fp16 if tensor op math is disabled or not supported Enabled by default but can be disabled using the environment variable TF ENABLE TENSOR OP MATH 0 The choice of whether to use tensor op math is included in the autotuning of convolutions,,"nluehr,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,zheng-xq,zheng-xq,nluehr,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,jlebar,zheng-xq,zheng-xq,jlebar,nluehr,nluehr,nluehr,nluehr,nluehr,jhseu,tfboyd,nluehr,zheng-xq,drpngx,nluehr,jlebar,drpngx,drpngx,drpngx",2017-08-22 23:05:44,2017-09-20 18:02:04
PR,test for partial run setup with no feeds passed,,,"frankchn,frankchn,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,jhseu,drpngx,drpngx",2017-07-08 15:41:28,2017-09-20 18:03:03
PR,Branch 169431251,,,"caisq,caisq",2017-09-20 19:35:36,2017-09-20 20:22:41
PR,Fix random crashes in SessionRun,This patch fixes The problem was with usage of runtime SetFinalizer in golang bindings When a variable become unreferenced GC can harvest it any moment after According to this SetFinalizer For example if p points to a struct that contains a file descriptor d and p has a finalizer that closes that file descriptor and if the last use of p in a function is a call to syscall Write p d buf size then p may be unreachable as soon as the program enters syscall Write The finalizer may run at that moment closing p d causing syscall Write to fail because it is writing to a closed file descriptor or worse to an entirely different file descriptor opened by a different goroutine To avoid this problem call runtime KeepAlive p after the call to syscall Write In our case unreferenced variable was feeds i e input tensors After investigations I have found out that func t Tensor finalize C TF DeleteTensor t c was called a way before SessionRun was finished and that was the cause of crash in my case,,"anight,asimshankar,anight,asimshankar,asimshankar,anight,asimshankar,anight,asimshankar,asimshankar,caisq",2017-09-20 14:54:50,2017-09-20 20:38:21
PR,Support S3 Filesystem for Tensorflow,This is for S3 Filesystem support in Tensorflow It utilizes Tensorflow is FileSystem C interface similar to currently available HDFS or GCS support The code depends on AWS is C SDK Apache License The code is placed under the directory of tensorflow contrib s3 TODO List X Add the implementation of S3 file system X Work out the BUILD configuration currently build a so not sure the best way in bazel X Add tests similar to gcs file system test cc This fix is related to 10616,,"yongtang,drpngx,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,jhseu,yongtang,drpngx,yongtang,jhseu,vrv,vrv,vrv,drpngx,yongtang,yongtang,yongtang,drpngx,yongtang,drpngx,yongtang,drpngx,rmlarsen,jhseu,jhseu,yongtang,jhseu,martinwicke,yongtang,martinwicke,martinwicke,drpngx,drpngx,yongtang,drpngx,yongtang,drpngx,yongtang,drpngx,drpngx,drpngx,drpngx,drpngx,gunan,yongtang,DjangoPeng,martinwicke,DjangoPeng,yongtang,caisq,gunan,martinwicke,case540,drpngx,yongtang,yongtang,yongtang,yongtang",2017-06-27 20:03:59,2017-09-20 21:34:51
PR,Fixes in MKL add n to address several regressions,Fixed failures due to scalar and empty tensors,,"agramesh1,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,jinghuangintel,rmlarsen,drpngx,caisq,rmlarsen,rmlarsen,rmlarsen",2017-09-13 18:19:13,2017-09-20 21:53:11
IS,variable assign incorrect,When the two assignment operations are the same var tf Variable 1 assign 1 var assign tf multiply var 2 assign 2 var assign tf multiply var 2 with tf Session as sess sess run var initializer sess run assign 1 assign 2 print sess run var 2 When the two assignment operations are not the same var tf Variable 1 assign 1 var assign tf multiply var 2 assign 2 var assign tf multiply var 3 with tf Session as sess sess run var initializer sess run assign 1 assign 2 print sess run var 6,,"yaroslavvb,facaiy",2017-09-20 05:03:26,2017-09-20 22:03:46
IS,How can I change value by threshold in tensor,When I do some 2 class classify practices I use sigmoid as output layer and it return a value in 0 1 but I want 1 if the value greater than 0 5 else set the value 0 I can not find a function to finish it Thank you for help Just like a tf constant 0 1 0 2 0 6 0 7 turn to a tf constant 0 0 1 1,,"ppwwyyxx,shreyneil,aselle",2017-09-16 14:56:57,2017-09-20 22:05:14
IS,Errror in creatinig training and inference logits,I am using ubuntu 16 04 version of tensorflow is 1 3 0 installed and validated using anaconda While trying to create training and inference logits of input 32 of the following python notebook I was getting errors while executing the following command train logits inference logits seq2seq model tf reverse input data 1 targets keep prob batch size sequence length len answers vocab to int len questions vocab to int encoding embedding size decoding embedding size rnn size num layers questions vocab to int Stack trace Traceback most recent call last File stdin line 4 in module File stdin line 6 in seq2seq model File stdin line 10 in encoding layer File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 405 in bidirectional dynamic rnn time major time major scope fw scope File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 598 in dynamic rnn dtype dtype File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 761 in dynamic rnn loop swap memory swap memory File home shreyash local lib python2 7 site packages tensorflow python ops control flow ops py line 2775 in while loop result context BuildLoop cond body loop vars shape invariants File home shreyash local lib python2 7 site packages tensorflow python ops control flow ops py line 2604 in BuildLoop pred body original loop vars loop vars shape invariants File home shreyash local lib python2 7 site packages tensorflow python ops control flow ops py line 2554 in BuildLoop body result body packed vars for body File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 744 in time step skip conditionals True File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 236 in rnn step new output new state call cell File home shreyash local lib python2 7 site packages tensorflow python ops rnn py line 732 in lambda call cell lambda cell input t state File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 180 in call return super RNNCell self call inputs state File home shreyash local lib python2 7 site packages tensorflow python layers base py line 450 in call outputs self call inputs args kwargs File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 938 in call cur inp new state cell cur inp cur state File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 774 in call output new state self cell inputs state scope File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 180 in call return super RNNCell self call inputs state File home shreyash local lib python2 7 site packages tensorflow python layers base py line 450 in call outputs self call inputs args kwargs File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 401 in call concat linear inputs h 4 self num units True File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 1039 in linear initializer kernel initializer File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 1065 in get variable use resource use resource custom getter custom getter File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 962 in get variable use resource use resource custom getter custom getter File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 360 in get variable validate shape validate shape use resource use resource File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 1405 in wrapped custom getter args kwargs File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 183 in rnn get variable variable getter args kwargs File home shreyash local lib python2 7 site packages tensorflow python ops rnn cell impl py line 183 in rnn get variable variable getter args kwargs File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 352 in true getter use resource use resource File home shreyash local lib python2 7 site packages tensorflow python ops variable scope py line 664 in get single variable name join traceback format list tb ValueError Variable bidirectional rnn fw multi rnn cell cell 0 basic lstm cell kernel already exists disallowed Did you mean to set reuse True in VarScope Originally defined at File stdin line 10 in encoding layer File stdin line 6 in seq2seq model File stdin line 2 in module,,"shreyneil,aselle",2017-09-17 05:06:55,2017-09-20 22:06:25
IS,Controlling Dreams in TensorFlow,Hi guys I am trying to re implement controlling dreams using TensorFlow which was implemented in the original google deepdreams algorithm using Caffe see the last part of But I think I got problems This controlling dreams part does not exist in this tutorial I am looking for someone who knows Caffe and deepdream to help I have never used Caffe before but I tried to understand what they were doing in the script To control the dream they firstly input a small guide image roughly 240 x 240 into the neural network and extract the features in each channel in certain layer specified These features are called guide features Then they input the large image which they want to modify into the model The large image was octaved For each octave image they input the octave image into the neural network extract the features in each channel in the same layer specified to the guide image Then they have to find the best matching guide features of certain channel to each of the features in the layer of octave image Here the best matching means the dot product of the two feature vectors is the largest Here comes the question They extract the guide features beforehand Therefore the matrix shape of guide features is constant But the shape of the feature matrix in octave can vary This means that I may not be able to calculate the dot product of these two matrices I believe I did not understand correctly their algorithm I would like to have someone to explain to me or provide me a reference Thank you Best Lei,,shivaniag,2017-09-20 13:50:33,2017-09-20 22:24:51
IS,quantized conv3d and quantized pool3d features,Now I am trying to implement 3D CNN on FPGA Do you have plan to support quantized conv3d and quantized pool3d features these two months if yes when will it be released Cheers,,aselle,2017-09-16 06:09:57,2017-09-20 22:32:38
IS,Optimizer loss function without desired paramater,Hi all For Tensorflow Is it possible to train a neural network to optimize a loss function e g minimize cost function without a desired parameter And what is optimizer in Tensorflow for the objective thank you,,shivaniag,2017-09-20 02:25:10,2017-09-20 22:38:57
IS,Feature Request API for weights values conversion,It would be very nice if the TensorFlow developers can provide a simple API for converting the weight values ported from other frameworks like Theano Torch Caffe and Chainer A lot of researchers still use these frameworks Most of the times when an individual convert weights values obtained from some framework other than TF the results are not reproducible which is not desirable Providing such an API can help the TF community to port the models from other frameworks to TF proving that the same thing could have been done more easily in TF The API can have a method that takes the following signature,,aselle,2017-09-18 05:50:12,2017-09-20 22:43:20
IS,inline assembly requires more registers than available while cross compiling tensroflow for arm cortex a15 using clang 3 8,I am trying to cross compile tensorflow for armv7a cortex a15 using clang 3 8 and I am using bazel 0 5 4 to build tensorflow My Environment details are Ubuntu 16 04 Clang 3 8 bazel 0 5 4 tensorflow source code version 1 3 target cpu cortex a15 compiler flag O2 The command i am using is bazel build copt Wno c 11 narrowing crosstool top tools arm compiler toolchain cpu armeabi v7a verbose failures sandbox debug tensorflow tools pip package build pip package The error is external gemmlowp meta transform kernels arm 32 h 5506 7 error inline assembly requires more registers than available ldr r0 input range min n The compiler flags are configured as bellow in CROSSTOOL toolchain abi version clang 3 8 abi libc version glibc 2 19 builtin sysroot compiler clang host system name armeabi v7a needsPic true supports gold linker false supports incremental linker false supports fission false supports interface shared objects false supports normalizing ar true supports start end lib false supports thin archives true target libc glibc 2 19 target cpu armeabi v7a target system name arm a15 toolchain identifier clang linux armhf tool path name ar path linaro linux gcc arm linux gnueabihf ar tool path name compat ld path linaro linux gcc arm linux gnueabihf ld tool path name cpp path linaro linux gcc clang bin clang tool path name dwp path linaro linux gcc arm linux gnueabihf dwp tool path name gcc path linaro linux gcc clang bin clang tool path name gcov path arm frc linux gnueabi arm frc linux gnueabi gcov 4 9 C compiles invoke the compiler as that is the one knowing where to find libraries but we provide LD so other rules can invoke the linker tool path name ld path linaro linux gcc arm linux gnueabihf ld tool path name nm path linaro linux gcc arm linux gnueabihf nm tool path name objcopy path linaro linux gcc arm linux gnueabihf objcopy objcopy embed flag I objcopy embed flag binary tool path name objdump path linaro linux gcc arm linux gnueabihf objdump tool path name strip path linaro linux gcc arm linux gnueabihf strip compiler flag target compiler flag armv7a arm linux gnueabihf compiler flag sysroot external linaro linux gcc repo arm linux gnueabihf libc compiler flag mfloat abi hard compiler flag mcpu cortex a15 compiler flag mfpu neon vfpv4 compiler flag nostdinc compiler flag isystem compiler flag usr lib clang 3 8 include compiler flag isystem compiler flag external linaro linux gcc repo lib gcc arm linux gnueabihf 4 9 3 include compiler flag isystem compiler flag external linaro linux gcc repo arm linux gnueabihf libc usr include compiler flag isystem compiler flag external linaro linux gcc repo lib gcc arm linux gnueabihf 4 9 3 include fixed compiler flag isystem compiler flag external linaro linux gcc repo arm linux gnueabihf libc usr include cxx flag isystem cxx flag external linaro linux gcc repo arm linux gnueabihf include c 4 9 3 arm linux gnueabihf cxx flag isystem cxx flag external linaro linux gcc repo arm linux gnueabihf include c 4 9 3 cxx flag isystem cxx flag external linaro linux gcc repo include c 4 9 3 arm linux gnueabihf cxx flag isystem cxx flag external linaro linux gcc repo include c 4 9 3 cxx builtin include directory package linaro linux gcc repo include cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf libc usr include cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf libc usr lib include cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf libc lib gcc arm linux gnueabihf 4 9 3 include fixed cxx builtin include directory package linaro linux gcc repo include c 4 9 3 cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf libc lib gcc arm linux gnueabihf 4 9 3 include cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf libc lib gcc arm linux gnueabihf 4 9 3 include fixed cxx builtin include directory package linaro linux gcc repo lib gcc arm linux gnueabihf 4 9 3 include cxx builtin include directory package linaro linux gcc repo lib gcc arm linux gnueabihf 4 9 3 include fixed cxx builtin include directory package linaro linux gcc repo arm linux gnueabihf include c 4 9 3 cxx builtin include directory usr lib clang 3 8 include cxx builtin include directory usr lib llvm 3 8 lib clang 3 8 0 include cxx builtin include directory home gopinathr Documents work tf1 2 tensorflow bazel out clang linux armhf opt genfiles external local config python python include arm linux gnueabihf python2 7 cxx flag std c 0x cxx flag std c 11 linker flag target linker flag armv7a arm linux gnueabihf linker flag sysroot external linaro linux gcc repo arm linux gnueabihf libc linker flag lstdc linker flag Ltools arm compiler linaro linux gcc clang more libs linker flag Lexternal linaro linux gcc repo arm linux gnueabihf lib linker flag Lexternal linaro linux gcc repo arm linux gnueabihf libc lib linker flag Lexternal linaro linux gcc repo arm linux gnueabihf libc usr lib linker flag Bexternal linaro linux gcc repo arm linux gnueabihf bin linker flag Wl dynamic linker lib ld linux armhf so 3 Anticipated future default This makes GCC and Clang do what we want when called through symlinks unfiltered cxx flag no canonical prefixes linker flag no canonical prefixes Make C compilation deterministic Use linkstamping instead of these compiler symbols unfiltered cxx flag Wno builtin macro redefined unfiltered cxx flag D DATE redacted unfiltered cxx flag D TIMESTAMP redacted unfiltered cxx flag D TIME redacted Security hardening on by default Conservative choice D FORTIFY SOURCE 2 may be unsafe in some cases We need to undef it before redefining it as some distributions now have it enabled by default compiler flag U FORTIFY SOURCE compiler flag fstack protector compiler flag fPIE linker flag pie linker flag Wl z relro z now Enable coloring even if there is no attached terminal Bazel removes the escape sequences if nocolor is specified compiler flag fdiagnostics color always All warnings are enabled Maybe enable Werror as well compiler flag Wall Enable a few more warnings that are not part of Wall compiler flag Wunused but set parameter But disable some that are problematic compiler flag Wno free nonheap object has false positives Keep stack frames for debugging even in opt mode compiler flag fno omit frame pointer Stamp the binary with a unique identifier linker flag Wl build id md5 linker flag Wl hash style gnu compilation mode flags mode DBG Enable debug symbols compiler flag g compilation mode flags mode OPT No debug symbols Maybe we should enable for opt or even generally However that can not happen here as it requires special handling in Bazel compiler flag g0 Conservative choice for O O3 can increase binary size and even slow down the resulting binaries Profile first and or use FDO if you need better performance than this compiler flag O2 Disable assertions compiler flag DNDEBUG Removal of unused code and data at link time can this increase binary size in some cases compiler flag ffunction sections compiler flag fdata sections added by sachin compiler flag v linker flag Wl gc sections The file contents are external gemmlowp meta transform kernels arm 32 h template inline void Transform1DKernel uint8 t int32 t BiasAdd uint8 t 16 0 Transform const uint8 t input const BiasAdd uint8 t params int32 t output ifdef DEBUG ifdef DEBUG METAGEMM VERBOSE std cout FILE LINE BiasAdd uint8 t uint8 t int32 t BiasAdd uint8 t 16 0 Transform std endl std flush endif endif int params rows copy params rows asm volatile ldr r0 input range min n vdup 32 q8 r0 n ldr r0 input range scale n vdup 32 q9 r0 n ldr r0 bias range min n vdup 32 q10 r0 n ldr r0 bias range scale n vdup 32 q11 r0 n ldr r0 output range min n vdup 32 q12 r0 n ldr r0 one over output range scale n vdup 32 q13 r0 n ldr r0 output range offset n vdup 32 q14 r0 n 1 mov r0 count n mov r1 bias n 2 subs r0 r0 16 n BiasAdd Transform vld1 32 d0 d1 input n vld1 32 d8 d9 r1 n pld input 32 n vmovl u8 q1 d1 n vmovl u8 q0 d0 n vmovl u8 q5 d9 n vmovl u8 q4 d8 n vmovl s16 q3 d3 n vmovl s16 q2 d2 n vmovl s16 q7 d11 n vmovl s16 q6 d10 n vmovl s16 q1 d1 n vmovl s16 q0 d0 n vmovl s16 q5 d9 n vmovl s16 q4 d8 n vcvt f32 s32 q0 q0 n vcvt f32 s32 q1 q1 n vcvt f32 s32 q2 q2 n vcvt f32 s32 q3 q3 n vcvt f32 s32 q4 q4 n vcvt f32 s32 q5 q5 n vcvt f32 s32 q6 q6 n vcvt f32 s32 q7 q7 n vmul f32 q0 q0 q9 n vmul f32 q1 q1 q9 n vmul f32 q2 q2 q9 n vmul f32 q3 q3 q9 n vmul f32 q4 q4 q11 n vmul f32 q5 q5 q11 n vmul f32 q6 q6 q11 n vmul f32 q7 q7 q11 n vadd f32 q0 q0 q8 n vadd f32 q1 q1 q8 n vadd f32 q2 q2 q8 n vadd f32 q3 q3 q8 n vadd f32 q4 q4 q10 n vadd f32 q5 q5 q10 n vadd f32 q6 q6 q10 n vadd f32 q7 q7 q10 n vadd f32 q0 q0 q4 n vadd f32 q1 q1 q5 n vadd f32 q2 q2 q6 n vadd f32 q3 q3 q7 n vsub f32 q0 q0 q12 n vsub f32 q1 q1 q12 n vsub f32 q2 q2 q12 n vsub f32 q3 q3 q12 n vmul f32 q0 q0 q13 n vmul f32 q1 q1 q13 n vmul f32 q2 q2 q13 n vmul f32 q3 q3 q13 n vadd f32 q0 q0 q14 n vadd f32 q1 q1 q14 n vadd f32 q2 q2 q14 n vadd f32 q3 q3 q14 n vcvt s32 f32 q0 q0 n vcvt s32 f32 q1 q1 n vcvt s32 f32 q2 q2 n vcvt s32 f32 q3 q3 n vst1 32 d0 d1 d2 d3 output n vst1 32 d4 d5 d6 d7 output n pld output n bne 2b n subs rows rows 1 n bne 1b n input r input output r output count r params count rows r params rows copy output range offset m params output range offset input range scale m params input range scale one over output range scale m params one over output range scale bias range min m params bias range min output range min m params output range min bias range scale m params bias range scale bias r params bias input range min m params input range min r0 r1 d0 d1 d2 d3 d4 d5 d6 d7 d8 d9 d10 d11 d12 d13 d14 d15 d16 d17 d18 d19 d20 d21 d22 d23 d24 d25 d26 d27 d28 d29 cc memory Does anyone can help me out with what is wrong,,aselle,2017-09-15 10:53:14,2017-09-20 22:49:05
PR,Branch 169436243,,,caisq,2017-09-20 20:25:11,2017-09-20 22:54:34
PR,Updating the README with the correct nightly links to tf nightly,,,av8ramit,2017-09-21 00:18:30,2017-09-21 01:11:39
PR,R1 3,,,av8ramit,2017-09-21 01:03:40,2017-09-21 01:15:51
IS,EditDistance crashes under C environment,System information Windows 10 TensorFlow installed from source TensorFlow version 1 3 rc2 Python version 3 5 VisualStudio 2017 Describe the problem I have created a C example with EditDistance and linked a debug version of tensorflow dll which is created from tensorflow source The compiled EditDistance example crashed at session Run outputs output tensor I have tried in this example also in the tensorflow environment it crashes also It seems the EditDistance operator does not work under C I have searched another EditDistance examples but it seems nobody has tested it outside the python environment Source code logs std vector Tensor output tensor ClientSession session root Tensor hypho2 ix DT INT64 TensorShape static cast int64 t 4 3 Tensor hypho2 vals DT STRING TensorShape static cast int64 t 4 makeIndex bear hypho2 ix makeChar bear hypho2 vals Tensor truth2 ix DT INT64 TensorShape static cast int64 t 5 3 Tensor truth2 vals DT STRING TensorShape static cast int64 t 5 makeIndex beers truth2 ix makeChar beers truth2 vals Declaration of edit distance auto address dist EditDistance root hypho2 ix hypho2 vals 3 1 1 static cast int64 t 1 3 test address shape truth2 ix truth2 vals 3 1 1 ref address shape EditDistance Normalize false const std vector Output outputs address dist session Run outputs output tensor void makeIndex const std vector string rsoStringVector tensorflow Tensor roIndexTensor auto ix t roIndexTensor matrix int64 t std size t stCounter 0 for std size t stX 0 stX rsoStringVector size stX const std string rsString rsoStringVector stX for std size t stY 0 stY rsString size stY ix t stCounter 0 stX ix t stCounter 1 0 ix t stCounter 2 stY stCounter void makeChar const std vector std string rsoStringVector tensorflow Tensor roCharTensor auto vals t roCharTensor vec std string int64 t i64Index 0 for std size t stX 0 stX rsoStringVector size stX const std string rsString rsoStringVector stX for std size t stY 0 stY rsString size stY vals t i64Index rsString stY,,,2017-08-22 21:09:26,2017-09-21 08:09:33
PR,old build all android sh X be deleted,,,,2017-09-21 11:01:47,2017-09-21 12:04:36
IS,Resolved No GPU kernel for tf tile with int32 or int64 tensors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary pip TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 2 Bazel version if compiling from source n a CUDA cuDNN version CUDA 8 0 cuDNN 5 1 GPU model and memory NVidia GeForce GTX TITAN with 5 93GiB Exact command to reproduce,,"dantkz,yongtang,dantkz",2017-09-19 21:24:05,2017-09-21 13:37:23
IS,how to avoid the flag whole archive when using the static library in windows,Hi everyone I have built the static library of tensorflow for C in windows And I am trying to use this library in qtCreator however I have the issue no session factory registered for the given options But it looks adding these flags in qtCreator doesn t work so I still have the issue Does someone know how to build the library in Tensorflow so I can use the library without the flag whole archive,,"yaroslavvb,yaroslavvb,yaroslavvb,yaroslavvb",2017-09-20 12:56:18,2017-09-21 15:12:42
IS,GRPC causes training to pause in individual worker distributed tensorflow synchronised,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 8 9 jessie TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 6 2 CUDA cuDNN version cuda 8 0 cudnn 5 1 5 GPU model and memory GeForce GTX Titan X 12 GB Exact command to reproduce Describe the problem The distributed synchronized between graph replication 4 workers 3 ps training works fine until one of the ps tasks reports following error After that one of the worker processes just stops and the rest of the workers may also stop later with same error For more detail see the stackoverflow post,,,2017-09-19 12:10:35,2017-09-21 15:26:07
IS,how to compute out product with tf,how to compute out product with tf,,yaroslavvb,2017-09-21 15:53:55,2017-09-21 16:10:41
IS,tf reduce mean sum runs very slow on GPU,I notice that tf reduce mean sum runs very slow on GPU in some cases which can happen in the following simple examle x tf Variable tf ones 80 80 80 80 4 D tensor y tf reduce sum x 0 2 3 Sum over all dims except the 2nd The execution time on GPU is very large and is approximate same as or more than the time on CPU which probably means the GPU is not used at all The same result can be obtained by choosing the other axes except for the first and the last axes in which case the execution on GPU is significantly faster than CPU Here is the code that reproduces the problem You can run with keep dim k k 0 1 2 3 to select different axes I am using the following PC system Kubuntu 16 04 TensorFlow 1 2 1 'v1 2 0 5 g435cdfc' '1 2 1' Python 2 7 GeForce GTX 1080 Ti CUDA 8 0 The execution time on GPU CPU and NumPy is given as follows exec time s 1 2 3 0 2 3 0 1 3 0 1 2 GPU 0 00918 0 40572 0 55388 0 01905 CPU 0 05921 0 22461 0 56524 0 16172 NumPy 0 24799 0 24847 0 24886 0 26601 Similar result was observed also on my laptop I met this problem when I tried to implement Batch Normalization initially when I ran tf nn moment then realized the key was tf reduce I wanted to collect means of different channels Using NHWC data format the problem does not matter as C is the last dimension However slow execution occurs if I want to implement for NCHW format as C is the second dimension this makes the execution time on Batch Normalization overwhelms all other ops such as convolutions This is surely a nightmare for training and evaluation I hope it will be fixed if it is a bug Or if the reason is that the oprations are just not implemented for GPU by now I wonder if there is a way to walk around,,"yaroslavvb,yaroslavvb,yaroslavvb",2017-09-20 00:29:02,2017-09-21 16:12:17
IS,No proper documentation to use transfer learning using pretrained model in ckpt format,Hi all Tensorflow had provided a retrain sample code for inception v3 pretrained model to apply transfer learning usinng pb file of the model But there is no documentation on how to use a ckpt file for pretrained models on Imagenet such as Resnet inception resnet etc Not much information of how to get a pb file for these pretrained model in ckpt format Has anyone tried transfer learning on these models If yes did they use ckpt or pb version oof the model How to get a pb and how to perform transfer learning usinng ckpt version Please help me on the same thank and regards,,"aselle,aselle",2017-09-10 14:30:38,2017-09-21 16:15:40
IS,Tensorflow 1 3 0 not buildable because bazel fails to download protobuf,Downloading via codeload github com 2 859 576 bytes Downloading via codeload github com 3 046 594 bytes Downloading via codeload github com 3 235 206 bytes Downloading via codeload github com 3 422 448 bytes Downloading via codeload github com 3 609 690 bytes Downloading via codeload github com 3 796 932 bytes Downloading via codeload github com 3 985 320 bytes Downloading via codeload github com 4 172 562 bytes Downloading via codeload github com 4 359 804 bytes ERROR build python tensorflow cuda 1 3 0 tensorflow tools pip package BUILD 100 1 no such package ' protobuf ' java io IOException Error downloading to build python tensorflow cuda 1 3 0 cache bazel bazel pbuilder f9c4bbbece8e6d872cda536e5e92a13c external protobuf 0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66 tar gz Checksum was e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d but wanted 6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93 and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted Elapsed time 12 129s It is not a local issue reproduced several time with different Internet connection Thanks,,aselle,2017-09-21 15:52:26,2017-09-21 16:21:59
IS,Renaming checkpoint directory,If you want to rename a checkpoint directory you currently need to also do a find replace in the 'checkpoint' file It might be nice to have that handled automatically,,aselle,2017-09-20 15:03:49,2017-09-21 16:27:47
IS,no such package ' llvm ',Trying to build latest git tree git describe tags calls it v1 3 0 rc1 2262 g74cfc64734 ERROR build tensorflow git src tensorflow tensorflow tools pip package BUILD 101 1 no such package ' llvm ' java io IOException Error downloading to build cache bazel bazel builduser a152fcd393afbe6f0b02d283bc9e6174 external llvm 9aafb854cc7cb8df8338c50cb411a54ce1e09796 tar gz Checksum was e8f07137a3a0b95e143c0665cd19160dd5040114b34a48653fa7f5f91cf4c136 but wanted 2a6d4c23f6660d9130d8d5f16267db53a87f8d0104f9618b558c033570f110af and referenced by ' tensorflow tools pip package licenses' Surely the correct fix is not to just to change the expected checksum to match the observed one,,aselle,2017-09-17 22:43:56,2017-09-21 16:35:46
IS,Documentation for windows install is wrong misleading,states Requirements to run TensorFlow with GPU support cuDNN v5 This is now incorrect TensorFlow 1 3 or later requires cuDNN 6 'cudnn64 6 dll' I also suggest you add a comment and link to this gist He just saved me hours Regards Aidan,,"reedwm,gunan,av8ramit,av8ramit",2017-08-17 18:34:49,2017-09-21 17:07:01
IS,nightly link broken on github README md,On github page nightly for Linux GPU Python 3 5 is broken points to TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON3 5 label gpu linux lastSuccessfulBuild artifact pip test whl tensorflow gpu 1 4 0dev cp35 cp35m linux x86 64 whl screenshot 2017 09 13 17 28 11 screenshot 2017 09 13 17 28 56,,"yaroslavvb,yaroslavvb,gunan,av8ramit",2017-09-14 00:29:51,2017-09-21 17:11:11
IS,bazel build failed due to boringssl checksum mismatches,No custom code System snapshot GCC 5 3 1 Centos 7 Bazel 0 5 4 Building from commit id 79517578deb4ea2a8dea641f1a8fa4363c13f76b from master user master tensorflow bazel build config mkl copt march knl copt O3 s c opt tensorflow tools pip package build pip package WARNING ignoring http proxy in environment ERROR home user tensorflow tensorflow tools pip package BUILD 101 1 no such package ' boringssl ' java io IOException Error downloading to home user cache bazel bazel user 59b9d4cecf85aafc18f6c320e7734241 external boringssl e3860009a091cd1bd2bc189cdbc3c6d095abde84 tar gz Checksum was a9a3673b1f7bd80ef563e9de1d9ccdb5126dc0cce6377977009092148993c4fe but wanted 02f5950f93c4fd3691771c07c9d04cf2999ab01383ff99da345249e93b0fcfb2 and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted INFO Elapsed time 6 963s user master tensorflow,,"aselle,aselle,gunan",2017-09-11 22:49:48,2017-09-21 17:40:59
IS,Incorrect protobuf SHA in workspace bzl for v1 3 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 the tagged version specifically 9e76bf32 Python version 3 5 3 Bazel version if compiling from source 0 5 4 Exact command to reproduce configure with all the default answers and the specified python version above then bazel build config opt tensorflow tools pip package build pip package Describe the problem When attempting to build the pip package in the repository on the latest tagged release v1 3 0 I get the following fatal build error ERROR home ubuntu tensorflow tools pip package BUILD 100 1 no such package ' protobuf ' java io IOException Error downloading to home ubuntu cache bazel bazel whitlock 8ea56cff279f39ec6c0003641e649819 external protobuf 0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66 tar gz Checksum was e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d but wanted 6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93 and referenced by ' tensorflow tools pip package licenses' It looks to me like the SHA changed for that version was not specified correctly However this seems strange to me because I had built against this version within the last couple of weeks without issue master does not have this problem Replacing the SHA in tensorflow workspace bzl with the one in the error message e5fdeee solves this issue,,"yongtang,aselle,gunan,gunan",2017-09-16 12:15:10,2017-09-21 17:42:07
IS,boringssl sha256 checksum mismatched,L583 when download from the sha256 checksum is Is there something wrong thanks,,"gunan,gunan",2017-09-12 02:52:55,2017-09-21 17:42:58
IS,How can I cmpile the Tensorflow library to use CPU Instructions,My CPU is AMD Ryzen 5 1400 Here is my Instructions sets given by CPU Z MMX SSE SSE2 SSE3 SSSE3 SSE4 1 SSE4 2 SSE4A x86 64 AMD V AES AVX AVX2 FMA3 SHA,,"lakshayg,aselle,aselle,lakshayg,suiyuan2009,gunan",2017-07-01 02:19:41,2017-09-21 17:45:57
IS,Jenkins' PR builds have been failing regularly since Aug 10,I do not know if the commonality is the state of master when the branches for these changes were taken or if there is something endemic to the current builders or but the failures appear to have nothing to do with actual code changes being submitted in at least some cases,,"skye,gunan,gunan",2017-08-16 16:26:59,2017-09-21 17:48:01
IS,i want to run a batch of images using the label images example but this example is only a image not a batch of image what should i do i can not find other examples to refer,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,shivaniag,2017-09-17 05:30:41,2017-09-21 18:17:16
IS,cmake No session factory registered for the given session options,Hi everyone I have built the static library for tensorflow with cmake in Windows and I have the error No session factory registered for the given session options This issue is fixed with the flag Wholearchive however it seems there is not equivalent flag for Qt creator So my question is if someone knows if the static library built with bazel has the same issue add the flag wholearchive in windows I have read that someone people didin t have this issue with bazel in Linux but it would be great if someone can confirm it for Windows Thanks for your help,,"yaroslavvb,shivaniag",2017-09-20 09:15:25,2017-09-21 18:54:28
IS,Tensorflow installation,I am installing tensorflow on window machine with the help of Python version python 3 5 4 amd64 Command use to install tensorflow pip3 install upgrade tensorflow Bellow error getting in Import tensorflow command Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File D eclipse WorkspavePython study test py line 1 in module import tensorflow as tf File C Program Files Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Program Files Python35 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Python35 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"shreyneil,shivaniag",2017-09-18 10:27:11,2017-09-21 19:04:45
IS,i m getting this error while installing tensorflow gpu have tried everything help me plezz,Traceback most recent call last File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C python36 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File H tst py line 1 in module import tensorflow File C python36 lib site packages tensorflow init py line 24 in module from tensorflow python import File C python36 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C python36 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C python36 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems,,shivaniag,2017-09-16 13:19:27,2017-09-21 19:05:05
IS,Brand new windows 10 install TF does not run ModuleNotFoundError No module named ' pywrap tensorflow internal',I'm submitting this as a bug instead of a support question on SO because I'm getting this error after a very clean install of the operating system The error occurs when I attempt to do the most basic validation but just importing tensorflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No custom code the error is occurring when I do import tensorflow as tf at the repl OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Home version 1703 fresh install the only other thing installed on the computer is Chrome and Anaconda distribution of Python 3 6 TensorFlow installed from source or binary Binary Followed the instruction to the letter except type in 'pip' instead of 'pip3' as in pip3 install upgrade tensorflow gpu this is after installing cuda and cudablas TensorFlow version use command below 1 3 whatever is in the repo as of about 30 minutes ago Python version Python 3 6 1 Anaconda custom 64 bit Bazel version if compiling from source CUDA cuDNN version nvcc version nvcc NVIDIA R Cuda compiler driver Copyright c 2005 2016 NVIDIA Corporation Built on Mon Jan 9 17 32 33 CST 2017 Cuda compilation tools release 8 0 V8 0 60 GPU model and memory NVIDIA GeForce GTX 960M Approx Total Memory 18313 MB Exact command to reproduce import tensorflow as tf Describe the problem I re imaged my windows 10 laptop installed Chrome installed the latest anaconda python 3 6 and attempted to install tensorflow following the official instructions on the web page all of this within the last hour or two of filing this ticket Installed Cuda and Cudablas from nvidia is website as required by TF instructions Installed tensorflow gpu Saw an exception related to some setuptools file not being found sorry did not keep a record of that Upgraded setuptools Did a reinstall of tensorflow but added force reinstall flag which claimed to have installed tensorflow without errors Successfully installed bleach 1 5 0 html5lib 0 9999999 markdown 2 6 9 numpy 1 13 1 protobuf 3 4 0 setuptools 36 5 0 six 1 11 0 tensorflow gpu 1 3 0 tensorflow tensorboard 0 1 6 werkzeug 0 12 2 wheel 0 30 0 Ran the import command and saw these exception trace Source code logs,,shivaniag,2017-09-21 03:46:40,2017-09-21 19:07:34
PR,update protobuf archive checksum,Fix 12979,,,2017-09-21 19:02:14,2017-09-21 19:39:13
IS,Android Demo Bug Exception in TF Detect activity,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow At build gradle Module android def nativeBuildSystem 'none' At CameraActivity java useCamera2API true Suggested by at 12431 OS Platform and Distribution e g Linux Ubuntu 16 04 Windows version 10 Pro Android version 6 0 1 Demo version commit 18e4590 TensorFlow installed from source or binary x TensorFlow version use command below x Python version x Bazel version if compiling from source x CUDA cuDNN version x GPU model and memory x Exact command to reproduce x Describe the problem Running the activity TF Detect after installing the project with Android Studio results in an IllegalArgumentException being thrown The problem has been noticed before with other configurations at issue 12431 and pull request 10771 and tested recently by using CMake and Ubuntu Source code logs,,"andrewharp,ArtsiomCh,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp",2017-08-25 10:04:11,2017-09-21 22:03:59
IS,unit test tools print all failure logs if failed,When a PR is tested failed Jenkins just reports failure and tells where to check log However at least for me I do not know whether I have the permission and where to find the logs So I have to reproduce the failed test on my own machine but maintaining all kinds of environment is an unnecessary burden for each developer cpu gpu py2 py3 window,,"facaiy,aselle,gunan,gunan,facaiy",2017-09-16 00:29:27,2017-09-21 22:11:16
PR,Add kernels for FusedBatchNormGrad when is training False,10857,,"ppwwyyxx,zhangyaobit,zhangyaobit,zhangyaobit,ppwwyyxx,ppwwyyxx,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,ppwwyyxx,ppwwyyxx,zhangyaobit,zhangyaobit,ppwwyyxx,zhangyaobit,ppwwyyxx,zhangyaobit,zhangyaobit,ppwwyyxx,zhangyaobit,ppwwyyxx,ppwwyyxx,zhangyaobit,ppwwyyxx,zhangyaobit,drpngx,drpngx,zhangyaobit,drpngx,zhangyaobit",2017-08-25 03:25:21,2017-09-22 00:00:01
IS,No way to freeze fused BN stats,When fine tuning networks trained with BN sometimes we want to freeze and use the accumulated moving averages while allowing the gradients to be backpropagated through the BN layer but currently there is no way of doing so with fused BN since when is training False the layer gives erroneous gradients Of course we could use the batch statistics from the new task to accumulate the stats but it is not possible in the case of batch size 1 I understand that due to the nature of the CuDNN kernel it might be hard to implement such feature but a fused Batch Renorm layer could be a decent compromise as it uses the moving averages when training as well as during inference,,"tatatodd,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,ppwwyyxx,ppwwyyxx,zhangyaobit,ppwwyyxx",2017-06-20 17:11:03,2017-09-22 00:00:29
IS,build all ios sh fail with Error redefinition of 'NoBarrier CompareAndSwap',,,"skye,petewarden,aselle",2017-08-15 06:50:20,2017-09-22 03:07:33
PR,Branch 169629054,,,"caisq,drpngx,drpngx",2017-09-22 01:52:14,2017-09-22 03:30:41
IS,Android Detect demo is not working not detecting drawing anything,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Pro Android 6 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 0 Python version N A Bazel version if compiling from source N A using cmake CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Phone Moto G4 Play need to use Camera not Camera2 Describe the problem I start the TF Detect demo using my smartphone and nothing happens It just seems that is not operating neither trying to detect anything No matter how long I stay or how many things I try to detect nothing happens and the log as copied below does not change too Source code logs,,reedwm,2017-09-13 12:20:37,2017-09-22 03:31:38
IS,Is there any tool to see the tensorflow net is topology,As you known we could use to catch sight of the caffe network is topology structure Is there any one for tensorflow,,mrry,2017-09-22 03:26:37,2017-09-22 03:41:12
PR,Windows enable some contrib modules for bazel build,Still cannot build the custom OPs Hope someone can integrate 8217 into bazel rules,,"snnn,drpngx,drpngx,snnn",2017-08-15 14:10:40,2017-09-22 06:38:17
PR,Update workspace bzl to use latest farmhash commit to support s390x,We had raised an issue in google farmhash master earlier for big endian However due to restructuring in the code via latest commits the support for s390x needs to be explicitly added This support is added through this commit Now tensorflow workspace bzl can be updated with this commit id for farmhash,,"Nayana-ibm,Nayana-ibm,Nayana-ibm,Nayana-ibm,gunan,gunan,gunan",2017-09-14 09:31:52,2017-09-22 06:42:20
PR,Fixes for Raspberry Pi cross compilation issues,The nightly builds have been failing recently and it is due to a BoringSSL change that brings in system headers on our cross compilation Docker image I have worked around this my moving the system headers for OpenSSL and made a couple of other changes to improve reliability by ensuring the workspace is clean before starting,,petewarden,2017-09-22 00:22:48,2017-09-22 06:44:35
IS,where is tensorflow slim pretrained models,It seems that the url of the pretrained model below has been deleted Pretrained Pretrained So where are the tensorflow slim pretrained models now,,,2017-09-22 08:44:41,2017-09-22 08:50:06
PR,More robust sed regex syntax in compile nsync sh,The syntax t for a tab character in sed is not standard That escape is a GNU sed extension But OS X sed like other BSD sed does not support t for tab and instead treats t as meaning backslash followed by t So currently nsync Android build in MacOS fails with ar cr nsync a common o counter o cv o debug o dll o mu o mu wait o note o once o sem wait o time internal o wait o nsync semaphore mutex o per thread waiter o yield o ime rep timespec o nsync panic o ar nsync semaphore mutex o per thread waiter o yield o ime rep timespec o nsync panic o No such file or directory make nsync a Error 1 So added a to the seq syntax to enable ANSI C Quoting ANSI 002dC Quoting and problem resolved Reference Simple sed replacement of tabs mysteriously failing,,"resec,caisq,gunan",2017-09-18 05:53:18,2017-09-22 13:17:02
PR,Update NCCL and Eigen sources for CUDA9,Also fix presumably outdated manifest proto py pb2 and pandas dependencies,,"nluehr,drpngx,lukeiwanski,nluehr,zheng-xq,benoitsteiner",2017-09-05 23:50:42,2017-09-22 14:02:43
PR,Branch 169689743,,,caisq,2017-09-22 15:54:18,2017-09-22 16:06:45
PR,protobuf download Checksum was changed,The following error caused by protobuf Checksum has changed ERROR tensorflow tensorflow tools pip package BUILD 100 1 no such package ' protobuf ' java io IOException Error downloading Checksum was e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d but wanted 6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93 and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted,,av8ramit,2017-09-22 06:43:54,2017-09-22 16:31:10
IS,bazel compiliation is broken build failure due to github checksums changing,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary Source TensorFlow version use command below master Python version Python 3 6 2 Bazel version if compiling from source 0 5 4 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build verbose failures tensorflow contrib android libtensorflow inference so crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a Describe the problem GitHub tarball checksums have changed making it impossible to build tensorflow since the checksums do not match any more Source code logs,,"andrewharp,aselle,gunan,gunan,gunan",2017-09-11 20:47:44,2017-09-22 16:32:13
PR,Remove github mirror links for all TF workspace dependencies,Only use bazel mirror for github mirrors Fixes 12979,,"gunan,gunan,gunan,andrewharp,drpngx,gunan,gunan",2017-09-21 19:50:00,2017-09-22 16:32:13
PR,Fix documentation for tf case,,,,2017-09-22 16:18:29,2017-09-22 16:35:44
IS,Links to Object detection model no longer work,Examples of broken links include Thanks,,shivaniag,2017-09-22 19:40:43,2017-09-22 20:35:22
PR,Branch 169712715,,,caisq,2017-09-22 18:47:53,2017-09-22 20:49:15
PR,Refactoring of canned estimators,Class specific model fn used by each canned estimator are replaced by common model fn function and moved to utils py together with common classifier head and regression head functions Canned estimators are then refactored to use these common functions which significantly simplified their code and increased readability,,,2017-09-22 20:45:14,2017-09-22 21:50:07
IS,the version of tensorflow on TensorFlow experiment in iOS,i get tensorflow from cocoapods and the func TF Version in c api h can not run i want to get the version of tensorflow in tensorflow experiment how can i know,,aselle,2017-09-22 13:15:40,2017-09-22 22:05:33
IS,pb tensorflow gpu with cuda 7 5 and cudnn 4 is faster then tensorflow gpu cuda8 and cudnn 6,I tested tensorflow 0 8 with cuda 7 5 and cudnn 4 Maxwell Quadro K620 execution time 0 075s when i test the same code with cuda 8 and cudnn 5 execution time 0 75 s I tested the some code with tensorflow 1 3 cuda 8 cudnn 6 jetpack 3 1 jetson tx2 execution time 0 6s when i try to get the timeline with chromium tracing i added tensorflow python client import timeline that use libcputi execution time become 0 3s the code run on gpu because when i run it in cpu execution time become 0 9 s the code uses face detection with cnn i do not understand why the code is faster when i use tensorflow with cuda 7 5 and cudnn4 then cuda 8 and cudnn 5 or 6 any help please,,aselle,2017-09-22 09:56:53,2017-09-22 22:07:37
IS,tar Unrecognized archive format tar Error exit delayed from previous errors,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2017-09-19 15:52:50,2017-09-22 22:22:25
IS,ValueError No gradients provided for any variable check your graph for ops that do not support gradients,Hello everyone I have error when programming tensorflow ValueError No gradients provided for any variable check your graph for ops that do not support gradients between variables tf Variable 'Variable 0' shape 4 2 dtype float32 ref tf Variable 'Variable 1 0' shape 4 2 dtype float32 ref tf Variable 'Variable 2 0' shape 1 3 dtype float32 ref tf Variable 'Variable 3 0' shape 1 2 dtype float32 ref tf Variable 'Variable 4 0' shape 1 3 dtype float32 ref tf Variable 'Variable 5 0' shape 1 3 dtype float32 ref and loss Tensor Sum 0 dtype float32 My code is here import tensorflow as tf def weight variable shape initial tf truncated normal shape stddev 0 1 return tf Variable initial def bias variable shape initial tf constant 0 1 shape shape return tf Variable initial Model parameters W tf Variable 3 dtype tf float32 b tf Variable 3 dtype tf float32 W weight variable 1 b bias variable 1 indice tf constant 0 1 segment id tf constant 0 0 1 1 W weight variable 4 2 b bias variable 4 2 b tf Variable tf zeros 1 3 t0 tf Variable tf zeros 1 2 t1 tf Variable tf zeros 1 3 g tf Variable tf zeros 1 3 Model input and output x tf placeholder tf float32 linear model W x b forward transform linear function tf add tf matmul W x b linear function col 1 tf transpose tf nn embedding lookup tf transpose linear function indice 0 linear function col 2 tf transpose tf nn embedding lookup tf transpose linear function indice 1 min 1 tf reduce min tf segment max linear function col 1 segment id min 2 tf reduce min tf segment max linear function col 1 segment id b tf assign b min 1 min 2 0 b tf assign b min 1 min 2 0 0 t0 tf assign t0 min 2 min 1 g tf nn softmax tf scalar mul 1000 b dim 1 g tf nn softmax b inverse transform linear function inv tf divide tf transpose tf transpose t0 tf transpose b W linear function inv col 1 tf transpose tf nn embedding lookup tf transpose linear function inv indice 0 linear function inv col 2 tf transpose tf nn embedding lookup tf transpose linear function inv indice 1 max 1 tf reduce max tf segment min linear function inv col 1 segment id max 2 tf reduce max tf segment min linear function inv col 2 segment id t1 tf assign t1 max 1 max 2 0 0 y tf placeholder tf float32 loss loss tf reduce sum tf square linear model y sum of the squares loss tf reduce sum tf square g sum of the squares loss tf reduce sum tf square y tf matmul g tf transpose t1 loss tf reduce sum y tf matmul g tf transpose t1 optimizer optimizer tf train GradientDescentOptimizer 0 01 train optimizer minimize loss training data x train 1 2 3 4 x train array tf constant 0 58975124 0 22815752 x train tf diag x train array y train 0 1 2 3 y train tf constant 0 530 training loop init tf global variables initializer sess tf Session sess run init reset values to wrong for i in range 1000 sess run train x x train y y train evaluate training accuracy curr W curr b curr loss sess run W b loss x x train y y train print W s b s loss s curr W curr b curr loss Hope to get your help Thank you,,aselle,2017-09-19 02:57:30,2017-09-22 22:23:01
PR,Update RELEASE,,,,2017-09-22 23:15:08,2017-09-22 23:17:41
IS,Support for tf nn max pool with argmax on CPU,Hello Recently I trained a model using tf nn max pool with argmax on GPU and its working fine on GPU I wanted to use the model on CPU but it seems that its not supported on CPU How can I use this on CPU Will there be any support for it in near future Or any suggestions on how to use this on CPU would be great Thanks,,tatatodd,2017-06-22 10:27:32,2017-09-23 01:00:23
PR,Fix Windows build after 5c7f9e316d8c7735308a217310350d416d7498cc,Fix Dynamic linking on Windows is not well supported yet we can only still use the monolithic for now,,"meteorcloudy,gunan,drpngx",2017-09-22 18:39:50,2017-09-23 01:43:25
PR,Fix broken link for object detection model,In tensorflow models repo the models have been moved under the directory research This fix fixes a couple of broken links associated with object direction object detection research object detection Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq",2017-09-22 20:52:20,2017-09-23 01:43:45
PR,Fix for RTLD GLOBAL breakage of Pi builds and removed Eigen version change that is no longer needed,,,petewarden,2017-09-22 23:23:38,2017-09-23 02:47:29
IS,TensorFlow Debugger Colors Are Unreadable on Windows,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary binary TensorFlow version 1 3 0 TensorFlow version use command below Python 3 5 2 Bazel version if compiling from source not applicable CUDA cuDNN version not applicable GPU model and memory not applicable Exact command to reproduce Describe the problem When I run the TensorFlow Debugger tfdbg on a Windows command prompt the colors on the tfdbg screen are practically unreadable on my monitor Screen capture in the comment below The text color is indigo and the background color is black I have tried changing the colors on my command prompt but the curses package on tfdbg is changing both the foreground and the background colors on the blue text so that text remains unreadable Please change tfdbg so that default palette is readable on all monitors and so that colors can be modified Source code logs Screen capture below,,"yaroslavvb,caisq,caisq,caisq",2017-09-22 17:31:45,2017-09-23 03:04:35
IS,RNN cells parameter naming inconsistency,In most RNN cells the size is spified by the num units parameter This is true for LSTMCell LSTMBlockCell and GRUCell For GRUBlockCell the same parameter is called cell size This discrepancy could be problematic in some cases like this code I'm using to create a RNN cell depending on a string parameter passed by the user As this will return an error in case of GRUBlockCell The solution is just renaming that parameter and possibly add kwargs to all cell constructors as right now only RNNCell has kwargs,,yongtang,2017-09-18 23:49:57,2017-09-23 03:30:08
PR,Fix GRUBlockCell parameter naming inconsistency,This fix tries to fix the issue in 13137 where parameter cell size is used instead of num units This is inconsistent with other RNN cells This fix adds support of num units while at the same time maintains backward compatiblility for cell size This fix fixes 13137 Signed off by Yong Tang yong tang github outlook com,,"yongtang,ebrevdo,ebrevdo,yongtang,yongtang,drpngx,yongtang,drpngx,drpngx",2017-09-19 13:41:44,2017-09-23 03:30:08
PR,Use Tensors instead of TensorArrays for storing AttentionWrapper is alignment history,I would like to propose this fix for 13154 This is a breaking change as it replaces TensorArray s of the alignment history field with batch major Tensor s Additionally the helper function used to gather beams in BeamSearchDecoder had to be updated to allow keeping the original values dimensions,,"guillaumekln,ebrevdo",2017-09-21 10:17:47,2017-09-23 04:45:33
IS,add image gradient op,A paper 1 I am reimplementing recently uses image gradient loss 2 Numpy offers np gradient 3 to achieve this task i e np gradient image axis 0 np gradient image axis 1 however tensorflow lacks this feature or at least documentation about how to use tf gradients to get this done Therefore I propose to either send a PR where I add a gradient image op which uses fixed 2d convolution i e or have someone update documentation of tf gradients For the first I could provide a PR if this is considered interesting for tensorflow and not too implementation specific 1 2 3,,"aselle,shlens,aselle",2017-09-22 07:55:05,2017-09-23 07:09:22
PR,Spatial pyramid pooling layer implementation,PR Inspired from the work of and References 1 He Kaiming et al 2015 Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition 2 Implement SpatialPyramidPooling,,"yardstick17,yardstick17",2017-09-06 16:58:29,2017-09-23 10:33:33
PR,Branch 169770126,,,"caisq,drpngx",2017-09-23 21:17:01,2017-09-24 02:01:49
IS,Ubuntu 16 04 CUDA8 0 CUDNN5 1 C compilation fails,Operating System Ubuntu 16 04 LTS Installed version of CUDA and cuDNN 8 0 61 5 1 10,,allenlavoie,2017-09-24 01:12:06,2017-09-24 02:14:50
IS,AttributeError 'RunConfig' object has no attribute 'environment',Problem with the learn runner run method System Info Windows 10 TF 1 3 0 Python 3 5 Code Exception File F Git Tensorflow Tutorials iris linear classifier py line 107 in module learn runner run experiment fn experiment fn output dir 'build2 ' File F Anaconda3 lib site packages tensorflow contrib learn python learn learn runner py line 209 in run return execute schedule experiment schedule File F Anaconda3 lib site packages tensorflow contrib learn python learn learn runner py line 46 in execute schedule return task File F Anaconda3 lib site packages tensorflow contrib learn python learn experiment py line 502 in train and evaluate self train delay secs 0 File F Anaconda3 lib site packages tensorflow contrib learn python learn experiment py line 253 in train if config environment run config Environment LOCAL and AttributeError 'RunConfig' object has no attribute 'environment',,,2017-09-14 09:35:58,2017-09-24 05:05:06
IS,tf graph util extract sub graph should raise a better error message,Hi I used tf graph util extract sub graph to get a subgraph reaching a particular dest node My dest node is say conv2d transpose 7 I by mistake gave it as a string in the second parameter Python parses String too as a list and it raised an error AssertionError c is not in graph The extract sub graph should first check if the second parameter isinstace of a List so that it would be convenient to debug this kind of error in the future A screenshot is attached Thanks img width 613 alt screenshot at sep 14 23 53 32 src,,"facaiy,reedwm",2017-09-14 18:25:51,2017-09-24 18:01:10
PR,check invalid string type for dest nodes in extract sub graph,Fix 13047 How to test x add an unit test pass all tests,,"facaiy,reedwm,reedwm,reedwm,facaiy,reedwm,reedwm,drpngx,drpngx,facaiy,reedwm,facaiy,reedwm,drpngx",2017-09-15 05:26:54,2017-09-24 18:01:10
PR,Fix polynomial decay with cycle for global step 0,For polynomial decay with cycle True the learning rate at step 0 becomes NaN because in the process of calculating it we devide by 0 This change should fix it by setting the multiplier for the decay steps to one for global step 0,,"caisq,caisq",2017-09-24 12:32:24,2017-09-24 19:22:42
PR,Changed output directory for Pi CI build to fix permissions problem with nightlies,,,"petewarden,petewarden,gunan",2017-09-23 04:20:13,2017-09-24 21:17:06
PR,Run as the host user in docker when running docker in CI scripts,,,"gunan,gunan",2017-09-24 21:35:53,2017-09-24 22:55:39
IS,tensor flow optimizer,desto,,caisq,2017-09-24 17:53:15,2017-09-25 00:38:00
IS,GRPC causes training to pause in individual worker distributed tensorflow synchronised,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 8 9 jessie TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 6 2 CUDA cuDNN version cuda 8 0 cudnn 5 1 5 GPU model and memory GeForce GTX Titan X 12 GB Exact command to reproduce Describe the problem The distributed synchronized between graph replication 4 workers 3 ps training works fine until one of the ps tasks reports following error After that one of the worker processes just stops and the rest of the workers may also stop later with same error For more detail see the stackoverflow post,,"shivaniag,mrry,mrry",2017-09-21 15:27:50,2017-09-25 12:21:26
IS,Why will tf PaddingFIFOQueue print some information,I have asked this question on stackoverflow but never receives a response I think it is not error but log information,,mrry,2017-09-24 13:45:08,2017-09-25 18:44:29
IS,Tensorflow froze 2 variables converted to const ops,Hi there I'm new to Python Tensorflow Im using raspbian9 stretch Python 2 7 13 When i run retrain py from the examples provided using these code python retrain py bottleneck dir tf files bottlenecks how many training steps 50 model dir tf files inception output graph retrained graph pb output labels retrained labels txt image dir img input binary true There are no outputs for output labels retrained labels txt output graph retrained graph pb The codes below are the console outputs for the few last lines console output from the command above INFO tensorflow 2017 09 18 12 50 07 148873 Step 49 Train accuracy 95 0 INFO tensorflow 2017 09 18 12 50 07 149888 Step 49 Cross entropy 0 241774 INFO tensorflow 2017 09 18 12 50 08 259520 Step 49 Validation accuracy 97 0 N 100 INFO tensorflow Final test accuracy 89 3 N 28 INFO tensorflow Froze 2 variables Converted 2 variables to const ops Any solutions Thanks,,,2017-09-18 13:08:00,2017-09-25 19:06:55
IS,Doc nicety use to indicate when arguments must be keywords,shows the signature softmax cross entropy with logits sentinel None labels None logits None dim 1 name None In Python 3 the syntax for sentinel None is just and the signature would be softmax cross entropy with logits labels logits dim 1 name None where I have additionally removed the false defaults from labels and logits This can not be done to the code which has to be 2 7 compatible but it could be done to the documentation,,"girving,girving",2017-09-19 21:35:06,2017-09-25 19:37:20
PR,Updating protobuf and llvm hashes,,,"av8ramit,gunan,av8ramit,gunan,gunan,av8ramit,gunan",2017-09-19 23:58:49,2017-09-25 20:33:56
IS,E tensorflow core platform cloud http request cc 514,I run the train py in the object detection api use the code in the terminal python3 train py logtostderr train dir training pipeline conf ig path training ssd mobilenet v1 pets config encounter with the problems like that Please use tf global variables instead 2017 09 20 21 10 31 065044 E tensorflow core platform cloud http request cc 514 The transmission has been stuck at 0 bytes for 61 seconds and will be aborted 2017 09 20 21 10 31 065307 I tensorflow core platform cloud retrying utils cc 77 The operation failed and will be automatically retried in 0 980452 seconds attempt 1 out of 10 caused by Unavailable Error executing an HTTP request HTTP response code 0 error code 42 error message 'Callback aborted' 2017 09 20 21 11 33 330807 E tensorflow core platform cloud http request cc 514 The transmission has been stuck at 0 bytes for 61 seconds and will be aborted 2017 09 20 21 11 33 331297 I tensorflow core platform cloud retrying utils cc 77 The operation failed and will be automatically retried in 1 92775 seconds attempt 2 out of 10 caused by Unavailable Error executing an HTTP request HTTP response code 0 error code 42 error message 'Callback aborted' System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Ubuntu 16 04 TensorFlow install from pip TensorFlow 1 3 0 Python 3 5 Only CPU i also install python2 and anaconda 2 7 in my linux Source code logs python3 train py logtostderr train dir training pipeline config path training ssd mobilenet v1 pets config,,,2017-09-20 13:17:46,2017-09-25 21:42:35
IS,after the training process of DNNRegressor model i ran the log to check for the loss during training but the loss is not decreasing gradually and infact in my case its starting from 12654 4 and at final step 5131 29,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-20 16:36:29,2017-09-25 22:14:29
IS,In Graph Replication Multi GPU training in local single machine not working,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Wrote a minimal version custom code using TensorFlow API is see attachment OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Installed through pip TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version Cuda Version 8 0 cuDNN version 1 6 GPU model and memory GeForce GTX Titan X GPU 12 GB memory Exact command to reproduce sh run dist tf exp sh attached as zip file distributed tf issue zip Describe the problem We are trying to get single machine multi gpu training with Distributed Tensor Flow for increasing model throughput Our set up is as follows We have a single compute machine running Ubuntu 16 04 with 8 GPU is and we would like to enable Data Parallelism by training model on multiple 4 GPU is device present in the local machine to increase throughput I will explain three scenarios below which uses minimal code that just runs a LinearClassifier see attached code Scenario 1 tf config set to run single worker and single parameter server config below,,,2017-09-20 22:03:58,2017-09-25 22:34:04
IS,Makefile build symbol s not found for architecture x86 64,I'm trying to build tensorflow on a Mac OSx Sierra to be able to use it in a C project but when i compile it it gives me this error,,,2017-09-22 10:03:47,2017-09-25 23:24:45
PR,Fix several issues with go fmt and go lint,This fix fixes several issues related to gofmt and golint based on There are several changes gofmt s tensorflow go tensor go gofmt s tensorflow go example inception inference test go golint tensorflow go genop internal lib go At the moment there are still quite a few golint and ineffassign warnings in the current go code base However all of them are from tensorflow go op wrappers go which is machine generated code This fix does not cover tensorflow go op wrappers go Signed off by Yong Tang yong tang github outlook com,,"yongtang,sb2nov",2017-09-24 15:38:36,2017-09-25 23:25:58
PR,GetConvolve Algorithms return tensor op algos,Attention and xq This is the follow up on the cudnn7 patch When enumerating convolution algorithms it moves the tensor ops toggle into the GetConvolve Algorithms functions Also tensor ops are no longer included in the returned algo list if they are not supported by the cuDNN version or GPU compute capability,,"nluehr,sb2nov",2017-09-22 23:43:08,2017-09-25 23:34:17
PR,TF Docs fix for 1 3,fix broken links add links check to sanity 11394 fix broken links add links check to sanity fix broken link in export md,,av8ramit,2017-09-25 18:00:43,2017-09-25 23:56:18
IS,array elementwise ops test cpu parallel test failure on ppc64le,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Rhel 7 3 SLES 12 ppc64le TensorFlow installed from source or binary source TensorFlow version use command below master Python version 2 7 4 Bazel version if compiling from source 0 4 6 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel test test output errors tensorflow compiler xla tests array elementwise ops test cpu parallel You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Test gives failure log as below Root causing the issue error lines are these ComputationBuilder builder client TestName auto result builder IsFinite builder ConstantR0 float NAN ComputeAndCompareR0 bool builder false IsFinite on ppc64le incorrectly returning True instead of False when passed a NaN Tracing the implemnetaion of IsFinite leads to code under XLA from here seems like XLA does not support ppc64le as a backend Need some insight to help with further debugging is this analysis correct that this test failure is due to XLA not supporting ppc64le Any other pointers for this will help Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Test output for tensorflow compiler xla tests array elementwise ops test cpu parallel Note This is test shard 5 of 25 Running 5 tests from 1 test case Global test environment set up 5 tests from ArrayElementwiseOpTest RUN ArrayElementwiseOpTest IsFiniteScalarF32 2017 07 28 10 35 17 159242 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices 2017 07 28 10 35 17 160204 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices 2017 07 28 10 35 17 161041 I tensorflow compiler xla service service cc 198 XLA service 0x1002d5b4cb0 executing computations on platform Host Devices 2017 07 28 10 35 17 161051 I tensorflow compiler xla service service cc 206 StreamExecutor device 0 undefined undefined tensorflow compiler xla tests literal test util cc 151 Failure Value of Equal expected actual Actual false expected false actual true Expected true expected false vs actual true tensorflow compiler xla tests literal test util cc 151 Failure Value of Equal expected actual Actual false expected false actual true Expected true expected false vs actual true FAILED ArrayElementwiseOpTest IsFiniteScalarF32 41 ms RUN ArrayElementwiseOpTest CompareEqZeroElementF32s 2017 07 28 10 35 17 199474 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest CompareEqZeroElementF32s 6 ms RUN ArrayElementwiseOpTest MinZeroElementF32s 2017 07 28 10 35 17 205103 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest MinZeroElementF32s 5 ms RUN ArrayElementwiseOpTest ClampF32ScalarVector 2017 07 28 10 35 17 210559 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest ClampF32ScalarVector 15 ms RUN ArrayElementwiseOpTest 3DBinaryOpF32s 2017 07 28 10 35 17 225124 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest 3DBinaryOpF32s 12 ms 5 tests from ArrayElementwiseOpTest 79 ms total Global test environment tear down 5 tests from 1 test case ran 79 ms total PASSED 4 tests FAILED 1 test listed below FAILED ArrayElementwiseOpTest IsFiniteScalarF32 1 FAILED TEST Test output for tensorflow compiler xla tests array elementwise ops test cpu parallel Note This is test shard 6 of 25 Running 5 tests from 1 test case Global test environment set up 5 tests from ArrayElementwiseOpTest RUN ArrayElementwiseOpTest IsFiniteR1F32s 2017 07 28 10 35 17 180614 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices 2017 07 28 10 35 17 181740 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices 2017 07 28 10 35 17 182605 I tensorflow compiler xla service service cc 198 XLA service 0x100337e4cb0 executing computations on platform Host Devices 2017 07 28 10 35 17 182614 I tensorflow compiler xla service service cc 206 StreamExecutor device 0 undefined undefined tensorflow compiler xla tests literal test util cc 151 Failure Value of Equal expected actual Actual false expected 010100 actual 111100 Expected true expected 010100 vs actual 111100 FAILED ArrayElementwiseOpTest IsFiniteR1F32s 15 ms RUN ArrayElementwiseOpTest CompareGeF32s 2017 07 28 10 35 17 195704 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest CompareGeF32s 10 ms RUN ArrayElementwiseOpTest MinF64s 2017 07 28 10 35 17 205905 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest MinF64s 10 ms RUN ArrayElementwiseOpTest AddTwoParametersF32s 2017 07 28 10 35 17 215280 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest AddTwoParametersF32s 8 ms RUN ArrayElementwiseOpTest Add1DTo3DTwoWaysOver2 2017 07 28 10 35 17 223646 I tensorflow compiler xla service platform util cc 58 platform Host present with 8 visible devices OK ArrayElementwiseOpTest Add1DTo3DTwoWaysOver2 20 ms 5 tests from ArrayElementwiseOpTest 63 ms total Global test environment tear down 5 tests from 1 test case ran 63 ms total PASSED 4 tests FAILED 1 test listed below FAILED ArrayElementwiseOpTest IsFiniteR1F32s 1 FAILED TEST tensorflow compiler xla tests array elementwise ops test cpu parallel 23 25 cached FAILED in 2,,hawkinsp,2017-09-18 11:06:19,2017-09-26 00:57:26
IS,Error compiling in Linux Mint,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Installed from Source TensorFlow version use command below Error generated when running below command Bazel version if compiling from source Bazel 0 5 1 CUDA cuDNN version Unknown GPU model and memory No GPU Exact command to reproduce sudo bazel build config opt tensorflow tools pip package build pip package verbose failures Describe the problem Error when trying to build from source with Bazel Following error code generated WARNING home dan tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' Use SavedModel Builder instead WARNING home dan tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle gc' Use SavedModel instead INFO Found 1 target ERROR home dan cache bazel bazel root 113acdcc7c9d2b1e2c757002415fbd3e external io bazel rules closure java io bazel rules closure webfiles server BUILD 48 1 error executing shell command 'JAR 'external local jdk bin jar' OUTPUT 'bazel out host bin external io bazel rules closure java io bazel rules closure webfiles server libbuild info java proto srcjar srcjar' PROTO COMPILER 'exter ' failed bash failed error executing command cd home dan cache bazel bazel root 113acdcc7c9d2b1e2c757002415fbd3e execroot tensorflow exec env PATH usr local sbin usr local bin usr sbin usr bin sbin bin snap bin bin bash c 'JAR '''external local jdk bin jar''' OUTPUT '''bazel out host bin external io bazel rules closure java io bazel rules closure webfiles server libbuild info java proto srcjar srcjar''' PROTO COMPILER '''external com google protobuf protoc bin protoc''' SOURCE '''external io bazel rules closure java io bazel rules closure webfiles server build info proto''' INCLUDES ''' I Iexternal io bazel rules closure''' bazel out host bin external io bazel rules closure closure private gensrcjar' com google devtools build lib shell BadExitStatusException Process exited with status 1 external com google protobuf protoc bin protoc 1 external com google protobuf protoc bin protoc cannot create Directory nonexistent external com google protobuf protoc bin protoc 1 external com google protobuf protoc bin protoc ELF not found external com google protobuf protoc bin protoc 2 external com google protobuf protoc bin protoc Syntax error unexpected gensrcjar proto compiler failed Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 339 557s Critical Path 54 04s Source code logs Log Error above Let me know if you need more information,,"tjingrant,rohan100jain,aselle",2017-06-19 19:06:58,2017-09-26 01:36:15
IS,TensorFlow creates different node name for execution,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below TF v1 3 Bazel version if compiling from source 0 4 5 CUDA cuDNN version cuda 8 0 cudnn 5 1 5 GPU model and memory Tesla P40 Exact command to reproduce Describe the problem This is the tracing result when I executed ptb lstm application I wonder the meaning of sequence loss by example add 1077 I wanted to create enqueue and dequeue ops for sequence loss by example add but dequeue op is never called and different node name appears in the tracing file Can you let me know what is happened inside session run img width 439 alt 2017 09 17 18 42 36 src,,"yaroslavvb,aselle,aselle",2017-09-17 09:47:59,2017-09-26 03:49:46
IS,Failed to compile tensorflow offline with ' fetch false' after all external dependencies fetched by bazel,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 from master branch Python version Python 2 7 12 Bazel version if compiling from source 0 5 4 CUDA cuDNN version null GPU model and memory null Exact command to reproduce 1 Fetch all external dependencies by docker image with internet access So please help for that and let me know if something wrong with my operation thanks,,"martinwicke,damienmg",2017-09-21 09:40:50,2017-09-26 03:55:40
PR,Branch 169998131,,,"caisq,caisq",2017-09-26 03:23:56,2017-09-26 07:05:08
PR,Rdma params configuration,,,,2017-09-26 11:43:10,2017-09-26 11:45:16
IS,No gradients provided for any variable check your graph for ops that do not support gradients between variables,I download a code about vgg from web and use it on my own datasets But it shows No gradients provided for any variable check your graph for ops that do not support gradients between variables error code as below coding UTF 8 import tensorflow as tf import read data import numpy as np def conv op input op name kh kw n out dh dw p ''' Args input op tensor name kh kernel height kw kernel weight n out dh dw p ''' n in input op get shape 1 value input op with tf name scope name as scope scope Variable kernel tf get variable scope w kernel tf get variable shape kh kw n in n out dtype tf float32 initializer tf contrib layers xavier initializer conv2d tf nn conv2d input op kernel dh dw padding SAME conv tf nn conv2d input op kernel 1 dh dw 1 padding 'SAME' bias init val tf constant 0 0 shape n out dtype tf float32 biases tf constant 0 biases tf Variable bias init val trainable True name 'b' bias init val z tf nn bias add conv biases conv bias activation tf nn relu z name scope z activation p kernel biases kernel bias return activation activation def fc op input op name n out p n in input op get shape 1 value tensor with tf name scope name as scope kernel tf get variable scope w tf get variable shape n in n out dtype tf float32 initializer tf contrib layers xavier initializer biases 0 1 dead neuron biases tf Variable tf constant 0 1 shape n out dtype tf float32 name 'b' input op kernel biases activation activation tf nn relu layer input op kernel biases name scope p kernel biases return activation def mpool op input op name kh kw dh dw return tf nn max pool input op ksize 1 kh kw 1 kh kw strides 1 dh dw 1 dh dw padding 'SAME' name name VGGNet 16 def inference op input op keep prob ''' VGGNet 16 6 Args input op Tensor keep prob Dropout placeholder ''' p p assume input op shape is 224x224x3 input op outputs 112x112x64 3 3 64 1 1 conv1 1 conv op input op name conv1 1 kh 3 kw 3 n out 64 dh 1 dw 1 p p outputs 224x224x64 conv1 2 conv op conv1 1 name conv1 2 kh 3 kw 3 n out 64 dh 1 dw 1 p p outputs 224x224x64 pool1 mpool op conv1 2 name pool1 kh 2 kw 2 dw 2 dh 2 2 2 outputs 112x112x64 outputs 56x56x128 conv2 1 conv op pool1 name conv2 1 kh 3 kw 3 n out 128 dh 1 dw 1 p p conv2 2 conv op conv2 1 name conv2 2 kh 3 kw 3 n out 128 dh 1 dw 1 p p pool2 mpool op conv2 2 name pool2 kh 2 kw 2 dh 2 dw 2 outputs 28x28x256 conv3 1 conv op pool2 name conv3 1 kh 3 kw 3 n out 256 dh 1 dw 1 p p conv3 2 conv op conv3 1 name conv3 2 kh 3 kw 3 n out 256 dh 1 dw 1 p p conv3 3 conv op conv3 2 name conv3 3 kh 3 kw 3 n out 256 dh 1 dw 1 p p pool3 mpool op conv3 3 name pool3 kh 2 kw 2 dh 2 dw 2 outputs 14x14x512 conv4 1 conv op pool3 name conv4 1 kh 3 kw 3 n out 512 dh 1 dw 1 p p conv4 2 conv op conv4 1 name conv4 2 kh 3 kw 3 n out 512 dh 1 dw 1 p p conv4 3 conv op conv4 2 name conv4 3 kh 3 kw 3 n out 512 dh 1 dw 1 p p pool4 mpool op conv4 3 name pool4 kh 2 kw 2 dh 2 dw 2 outputs 7x7x512 conv5 1 conv op pool4 name conv5 1 kh 3 kw 3 n out 512 dh 1 dw 1 p p conv5 2 conv op conv5 1 name conv5 2 kh 3 kw 3 n out 512 dh 1 dw 1 p p conv5 3 conv op conv5 2 name conv5 3 kh 3 kw 3 n out 512 dh 1 dw 1 p p pool5 mpool op conv5 3 name pool5 kh 2 kw 2 dw 2 dh 2 VGGNet 16 flatten shp pool2 get shape flattened shape shp 1 value shp 2 value shp 3 value tf reshape 7 7 512 25088 resh1 tf reshape pool2 1 flattened shape name resh1 fully connected 4096 fc6 fc op resh1 name fc6 n out 4096 p p fc6 drop tf nn dropout fc6 keep prob name fc6 drop fc7 fc op fc6 drop name fc7 n out 4096 p p fc7 drop tf nn dropout fc7 keep prob name fc7 drop fc8 fc op fc7 drop name fc8 n out 10 p p softmax tf nn softmax fc8 predictions tf argmax softmax 1 tf argmax print predictions get shape return predictions softmax fc8 p def main file name batch size iter times x tf placeholder 'float' shape batch size 32 32 3 y tf placeholder 'float' shape batch size 1 predictions inference op x keep prob 0 5 predictions tf cast predictions tf float32 tf equal bool tensor tf reduce mean bool print predictions get shape loss tf nn softmax cross entropy with logits labels tf transpose y perm 1 0 logits predictions loss tf reduce mean loss train tf train GradientDescentOptimizer 0 01 minimize loss sess tf Session init tf global variables initializer for i in xrange iter times train x train y read data fetch data file name batch size sess run init train x train y sess run train x train y train eval feedict x train x y train y print sess run predictions if i 100 0 print d step accuarcy is f i sess run loss main 'train tfrecords' 30 2000,,,2017-09-26 13:17:53,2017-09-26 13:34:40
PR,typo fix,found while trying to compile on ARM based Raspberry Pi 2 in branch r 1 3,,,2017-09-26 13:22:16,2017-09-26 13:36:16
PR,Fixes 12401 Use traceback instead of inspect for frame information,12401 import tensorflow contrib layers takes a very long time I learned while rebasing this diff that the issue of slow imports of tensorflow contrib layers was fixed earlier this week Since the diff is ready I want to put up the diff for the sake of history but I understand if at this point the further speedup is minor enough to ignore The speedup is a factor of 2 while the original fix is a factor of 100 My performance tests compared three versions original implementation with inspect stack traceback limit current frame inspect I also found that the original implementation was sensitive to the depth of the current stack and a file importing another file generally increased that call depth by 5 Which is to say in practice my code importing tensorflow config at an import depth of 7 had much worse performance than the baseline test of just importing tensorflow config Test Timing python2 inspect stack 7 8 sec python2 inspect getframeinfo 0 12 sec python2 traceback extract stack 0 04 sec python3 inspect stack 22 8 sec python3 inspect getframeinfo 0 14 sec python3 traceback extract stack 0 07 sec tests are the total of 1000 runs with a stack of 200 to give easy to compare numbers This functionality of adding a decorator name from the call stack is covered by the existing unit test testSetsDecoratorNameToFunctionThatCallsMakeDecoratorIfAbsent And pylint did not report any issues on these changes,,"charlesnicholson,drpngx,charlesnicholson,charlesnicholson,charlesnicholson,drpngx,drpngx,drpngx,gunan,gunan,yaroslavvb,gunan,gunan,drpngx,charlesnicholson,charlesnicholson,sb2nov,drpngx,sb2nov,drpngx,caisq",2017-09-21 18:41:51,2017-09-26 14:16:55
IS,import tensorflow contrib layers takes very long time,I have used Cprofile to test my code and I find that import tensorflow contrib layers takes very long time Here is the quick screenshot of the result As seen above it took more than 6 secs to just do import tensorflow contrib layers and I wonder if this is expected Also I am pretty interested in why it takes so long time to do importing there P S The profiling test runs on MacOS Sierra 10 12 5 with Tensorflow v1 2 and Python 3 5,,reedwm,2017-08-18 19:16:27,2017-09-26 14:17:44
PR,Branch 170043510,,,"caisq,caisq",2017-09-26 13:44:05,2017-09-26 14:36:58
PR,Clarified difference between FIFOQueue and StagingArea,Clarified that StagingArea does not guarantee ordered delivery contrasting tf FIFOQueue,,"yifeif,yifeif,sjperkins,sjperkins,drpngx,sb2nov",2017-09-05 23:24:30,2017-09-26 14:39:33
IS,Concatenate in alternate fashion two tensors,Good Afternoon I would like to concatenate two tensors of shape None 16 in alternate fashion For example with simple arrays if the inputs are a 1 2 3 1 2 3 b 4 5 6 4 5 6 I want this output c 1 4 2 5 3 6 1 4 2 5 3 6 How can I do it I can not loop on tensors because of unknown shape 0 zip function is not supported for tensors tensor object is not iterable Thank u all in advance,,aselle,2017-09-26 14:24:13,2017-09-26 15:53:11
PR,GitHub only 1 3 1 release,,,av8ramit,2017-09-26 00:18:52,2017-09-26 17:54:58
PR,Fix argument name mismatch in FinalBeamSearchDecoderOutput docstring,,,"guillaumekln,sb2nov,sb2nov",2017-09-18 11:32:39,2017-09-26 18:51:43
PR,Add cmake generated files dirs in Linux to gitignore,This fix adds cmake generated files in Linux to gitignore Before this fix after This fix addresses the above issue Signed off by Yong Tang yong tang github outlook com,,"yongtang,gunan,sb2nov",2017-09-23 00:17:00,2017-09-26 18:52:07
IS,Change TanhGrad operation definition with respect to documentation,Hello TanhGrad documentation says Specifically grad dy 1 y y where y tanh x and dy is the corresponding input gradient L323 which is correct and looks good But operation has following declaration of inputs Input x T Input y T L200 what does not correlate with the documentated formula grad dy 1 y y Could you please rename inputs with respect to documentation like this Input y T Input dy T Thanks,,"yaroslavvb,yaroslavvb",2017-09-08 09:15:10,2017-09-26 18:54:32
PR,Changed TanhGrad operation definition with respect to documentation,This should resolve 12902,,"caisq,sb2nov",2017-09-21 14:22:54,2017-09-26 18:54:33
IS,BUG tf reduce max does not support int64 tensor on GPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary pip TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Also tested with v1 3 0 rc1 2523 g1e1b3d9 1 4 0 dev20170925 Python version Python 3 5 2 Bazel version if compiling from source n a CUDA cuDNN version CUDA 8 0 cuDNN 5 1 GPU model and memory NVidia GeForce GTX TITAN with 5 93GiB Exact command to reproduce,,"dantkz,yongtang",2017-09-25 16:14:24,2017-09-26 20:03:28
PR,Add int64 support for tf reduce max on GPU,This fix tries to address the issue raised in 13293 where tf reduce max on GPU does not have int64 support Test cases have been added to cover the changes This fix fixes 13293 Signed off by Yong Tang yong tang github outlook com,,"yongtang,sb2nov",2017-09-26 01:21:53,2017-09-26 20:03:28
PR,Fix docs for tf tanh tf sigmoid and tf tan,The API docs incorrectly state that tf tanh accepts int32 or int64 inputs This was referenced in issue 10376 however the fix to 10376 only removed the reference to qint32 A look at the implementation in cwise op tanh cc shows that int32 and int64 are indeed not supported This fix removes them from the API docs Similarly we remove int32 int64 and qint32 from tf sigmoid API docs Finally tf tan is defined only for float and double so I changed in math ops cc to use UNARY REAL,,"codrut3,caisq,codrut3,rmlarsen,sb2nov",2017-09-24 11:00:26,2017-09-26 22:57:16
PR,Update init py,Add Python formatting for TF website Refactor comment Import statements are shorter than 80 chars so pylint should not need to be suppressed here Add python formatting to correct website formatting away newlines,,"alanyee,martinwicke,martinwicke,martinwicke,martinwicke,alanyee,drpngx,alanyee,martinwicke,drpngx",2017-08-29 07:02:25,2017-09-26 22:57:59
PR,Disable broken MaxPool qint8 and MaxPoolV2 qint8 kernels on Windows,This is intended to unbreak the Windows GPU build 13065,,"mrry,av8ramit,mrry,av8ramit,mrry",2017-09-26 20:02:56,2017-09-26 23:21:33
PR,eager Correctly convert a list of Dimensions to a TFE TensorHandle,,,"asimshankar,asimshankar",2017-09-26 20:00:01,2017-09-26 23:40:51
PR,Workaround for NVCC 9 0 internal error,Fixes 'Internal Compiler Error codegen ' encountered when building with nvcc 9 0,,"nluehr,ekelsen,ekelsen,nluehr,nluehr,ekelsen,nluehr,ekelsen,ekelsen,nluehr,ekelsen,nluehr,sb2nov",2017-09-08 22:34:48,2017-09-26 23:43:42
PR,Give accumulate n op a gradient,This pull request addresses issue 10607 by adding a gradient to the existing accumulate n operator I followed the approach suggested by rewrite accumulate n as an atomic op which has a gradient defined for it and which gets rewritten by the runtime into the current implementation Previously this op had been implemented in Python as a constellation of lower level ops some of which are not differentiable Implementation Details I have added a new C op AccumulateN which serves as a placeholder for type inference and gradient computation A new rewrite implemented in accumulate n optimizer cc replaces this placeholder with a group of AssignAdd ops and some additional ops that create initialize and destroy temporary variables The original Python code for accumulate n has been replaced by a function that validates its arguments and creates an instance of the AccumulateN placeholder op Testing I added a more complete set of tests for accumulate n in a previous pull request to ensure that the op would still be correct after the changes in the current pull request I also added one additional test to verify that accumulate n now has a gradient All the tests under tensorflow python currently pass on my MacOS and Linux test machines Things to Note The semantics of the new implementation are broadly the same as the original with the exception of one corner case The original implementation allowed all the inputs to accumulate n to have an undefined shape My new code requires that at least one input have a defined shape or that the user provides a shape using the shape argument to the accumulate n function While implementing the AccumulateN op I noticed that the code to do the kind of shape initialization I needed was repeated verbatim at several places in the TensorFlow code base I refactored this code into a new function shape inference ExplicitShape and replaced all the existing copies,,"frreiss,alextp,alextp,frreiss,alextp,frreiss,frreiss,frreiss",2017-09-13 21:32:46,2017-09-26 23:51:11
IS,build default serving input fn uses a name that is not a valid variable scope,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 LTS TensorFlow installed from source or binary SOURCE pip install tensorflow TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 6 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem See this short example python c import tensorflow as tf f 'feature' tf placeholder name 'feature' shape 32 dtype tf float32 serving input tf contrib learn utils input fn utils build default serving input fn f serving input Traceback most recent call last File string line 4 in module File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow contrib learn python learn utils input fn utils py line 112 in input fn name t name File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow python ops array ops py line 1548 in placeholder return gen array ops placeholder dtype dtype shape shape name name File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow python ops gen array ops py line 2094 in placeholder name name File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow python framework op def library py line 374 in apply op with g as default ops name scope name as scope File usr lib python2 7 contextlib py line 17 in enter return self gen next File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow python framework ops py line 4522 in name scope with g as default g name scope n as scope File usr lib python2 7 contextlib py line 17 in enter return self gen next File usr local google home slacy src tf clean env local lib python2 7 site packages tensorflow python framework ops py line 3172 in name scope raise ValueError ' s' is not a valid scope name name ValueError 'feature 0' is not a valid scope name The issue is that in input fn utils py here L112 The attribute t name is passed to array ops placeholder and t name will always have a N suffix and is not a valid variable scope name so this function fals Source code logs See above,,"yongtang,jart,yongtang",2017-09-01 20:39:59,2017-09-27 00:00:15
PR,Fix issue of name used in build default serving input fn,This fix tries to address the issue raised in 12755 where the name used in build default serving input fn is not a valid variable scope This fix fixes this issue by using the name of the tensor is op not tensor t op name instead to avoid the 0 value index at the end This fix fixes 12755 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,yongtang,yongtang,yifeif,yifeif,drpngx,sb2nov",2017-09-01 23:29:25,2017-09-27 00:00:15
IS,CheckpointSaverHook does not check Graph of Saver,The following code will run just fine but will not save any Variables to checkpoints This is because the CheckpointSaverHook does not find an existing Saver so it creates a new one in its constructor which is executed with a different default Graph,,,2017-09-24 00:02:25,2017-09-27 00:22:39
IS,Tensorflow 1 2 0 can not load graph using tf train import meta graph,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow self written code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 on Azure VM TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 and 6 0 21 respectively GPU model and memory NVIDIA Tesla K80 Exact command to reproduce tf train import meta graph graph name 2017 06 24 07 01 44 245235 I tensorflow core common runtime gpu gpu device cc 940 Found device 0 with properties name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 92f4 00 00 0 Total memory 11 17GiB Free memory 11 11GiB 2017 06 24 07 01 44 245278 I tensorflow core common runtime gpu gpu device cc 961 DMA 0 2017 06 24 07 01 44 245291 I tensorflow core common runtime gpu gpu device cc 971 0 Y 2017 06 24 07 01 44 245304 I tensorflow core common runtime gpu gpu device cc 1030 Creating TensorFlow device gpu 0 device 0 name Tesla K80 pci bus id 92f4 00 00 0 Problem Whenever the code spawns the loading of meta graph it does not exit If the process is cancelled there is no segmentation fault and the code exits cleanly Source code logs Python 2 7 12 default Nov 19 2016 06 48 10 GCC 5 4 0 20160609 on linux2 Type help copyright credits or license for more information import tensorflow as rd KeyboardInterrupt import tensorflow as tf tf version '1 2 0' tf layers conv2d transpose function conv2d transpose at 0x7fe9ccd5e668 saver tf train import meta graph ' results nepal Need wc2 nepal 2 model ckpt meta' CTraceback most recent call last File stdin line 1 in module File usr local lib python2 7 dist packages tensorflow python training saver py line 1686 in import meta graph kwargs File usr local lib python2 7 dist packages tensorflow python framework meta graph py line 504 in import scoped meta graph producer op list producer op list File usr local lib python2 7 dist packages tensorflow python framework importer py line 387 in import graph def op add input source tensor dtype input type File usr local lib python2 7 dist packages tensorflow python framework ops py line 1473 in add input self recompute node def File usr local lib python2 7 dist packages tensorflow python framework ops py line 1542 in recompute node def self node def input extend t as node def input for t in self inputs File usr local lib python2 7 dist packages tensorflow python framework ops py line 483 in as node def input if not self op name File usr local lib python2 7 dist packages tensorflow python framework ops py line 1420 in name return self node def name KeyboardInterrupt,,skye,2017-06-24 07:04:03,2017-09-27 01:06:09
IS,'Cannot interpret feed dict key as Tensor Can not convert a int into a Tensor' when using probabilities eval,I want to use tensor flow to print all the probabilities for my own image The following code works well for any mnist image that i get from online but does not work with my own images Here is the whole code from PIL import Image import random from tensorflow examples tutorials mnist import input data import tensorflow as tf import numpy as np import scipy ndimage from PIL import Image np set printoptions threshold 'nan' mnist input data read data sets MNIST data one hot True x tf placeholder tf float32 None 784 W tf Variable tf zeros 784 10 b tf Variable tf zeros 10 y tf nn softmax tf matmul x W b y tf placeholder tf float32 None 10 cross entropy tf reduce mean tf reduce sum y tf log y reduction indices 1 train step tf train GradientDescentOptimizer 0 5 minimize cross entropy init tf initialize all variables sess tf Session sess run init for i in range 1000 batch xs batch ys mnist train next batch 1000 sess run train step feed dict x batch xs y batch ys print done with training print n n n Weights W eval print Weights Bias b eval print Bias probabilities y digit 80 batch xs np reshape mnist test images digit 1 784 print isinstance mnist test images digit tuple print batch xs img Image open 'mnist 7 367 jpg' convert 'L' convert image to 8 bit grayscale data list img getdata convert image data to a list of integers newList float x 255 0 for x in data newList1 np asarray newList batch xs np reshape newList1 1 784 batch xs batch xs 0 1 0 print isinstance newList1 list print batch xs counter 0 for x in probabilities eval feed dict x batch xs session sess print ' ' for y in x print counter ' f ' format float y counter 1 print ' ' hello np reshape batch xs 28 28 Matrix np array for x in hello for y in x Matrix np append Matrix int 255 y imageReal np reshape Matrix 28 28 img Image fromarray imageReal img show sess close The problem I am having is that for x in probabilities eval feed dict x batch xs session sess is producing the following error Cannot interpret feed dict key as Tensor Can not convert a int into a Tensor,,mrry,2017-09-25 00:26:07,2017-09-27 03:39:26
PR,R1 3,,,,2017-09-27 05:26:56,2017-09-27 05:27:52
IS,Feature request for graph visualizer turn off node collapsing,There is a simple feed forward pbtxt here It can be visualized without any edges crossing However latest TensorBoard collapses Relu Relu 6 nodes together so that complicates the diagram and introduces edge crossings It would be nice to have a way to visualize without node collapsing screenshot 2017 09 25 11 35 53 cc,,"yaroslavvb,yaroslavvb,yaroslavvb",2017-09-25 18:37:21,2017-09-27 14:59:46
IS,params is Not Used for Canned Estimators Implementations,The canned estimators implementations do not seem to pass the params to their parent class Estimator For example DNNClassifier puts all the parameters e g hidden units optimizer etc inside the model fn and then pass the model fn to the parent class here L314 This makes it difficult for reporting or parameter tuning purposes I saw params is an exposed property for Estimator L188 however it is mostly empty for canned estimators since it is not used Is this on purpose Thanks,,"terrytangyuan,ispirmustafa,terrytangyuan",2017-09-23 20:04:33,2017-09-27 15:59:06
IS,TF Record Reader Writer C API,asimshankar Would you be open to adding support for reading writing TF records using the C API Similar to the lib io stuff in the Python API,,"eaplatanios,yaroslavvb,eaplatanios,eaplatanios,yaroslavvb,eaplatanios",2017-09-21 05:39:19,2017-09-27 16:09:20
IS,gru ops py trying to load a so file on windows,gru ops py is attempting to load an so library on windows when using CPU version vs GPU is this the correct behavior It fails in my case LINE 33,,,2017-09-26 12:25:18,2017-09-27 17:52:55
PR,R1 3,sadas,,"sb2nov,av8ramit",2017-09-27 15:52:55,2017-09-27 17:57:48
PR,Added a bias term in Bahdanau attention alignments,The original paper by Bahdanau lists a bias term Eq 18 and Tensorflow is normalized Bahdanau implementation uses one so I do not see why we should not use one in the original implementation Edit Err I was wrong staring at papers too much all day and quoted an equation from the paper that introduces Bahdanau energy normalization Still the original may have used it too as they state they omit bias terms to make the equations less cluttered My bad the reviewer decides what to do with this I guess,,"jhseu,drpngx,sb2nov,ebrevdo",2017-08-08 14:56:12,2017-09-27 18:41:14
PR,Windows Export nsync symbols from the Python extension DLL,Some extension modules e g gru ops dll expect to be able to link against nsync symbols in the Python extension DLL Any use of tensorflow mutex in an extension module will rely on these symbols being exported However these are not currently exported as part of the Windows build This change modifies the Windows build to export symbols containing nsync explicitly,,"mrry,av8ramit,mrry,mrry,av8ramit,av8ramit",2017-09-26 23:29:57,2017-09-27 19:13:24
PR,XLA Register the input arguments with the XlaAllocator,If an op returns one if its inputs as an output then the XlaAllocator needs to be able to notice the buffer and find the original tensor This adds a method to the XlaAllocator to allow this action and calls it with all of the inputs and variables but not the runtime context,,"DavidNorman,DavidNorman,sb2nov,DavidNorman,sb2nov,sb2nov,DavidNorman,drpngx",2017-09-26 08:34:14,2017-09-27 21:03:39
IS,Python checkpoint to use with C,I have tried everything from freeze graph py to bazel to try and use a python trained saved checkpoint of a model in c Why is it so complicated in TF Caffe was so much easier These are the steps that I follow 1 While training I added the following line just before saving each checkpoint tf train write graph sess graph def 'modelsprototxt ' 'trainingmodel pb' as text True 2 I used freeze graphy py to send in a trained checkpoint file the written graph fle and the output graph file and I get the following error Traceback most recent call last File home anarayanan TenserflowPlayground TF DEEPLAB UNTOUCHED tensorflow deeplab resnet master freeze graph py line 175 in module tf app run File usr local lib python2 7 dist packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File home anarayanan TenserflowPlayground TF DEEPLAB UNTOUCHED tensorflow deeplab resnet master freeze graph py line 172 in main FLAGS output graph FLAGS clear devices File home anarayanan TenserflowPlayground TF DEEPLAB UNTOUCHED tensorflow deeplab resnet master freeze graph py line 115 in freeze graph text format Merge f read input graph def File usr local lib python2 7 dist packages google protobuf text format py line 476 in Merge descriptor pool descriptor pool File usr local lib python2 7 dist packages google protobuf text format py line 526 in MergeLines return parser MergeLines lines message File usr local lib python2 7 dist packages google protobuf text format py line 559 in MergeLines self ParseOrMerge lines message File usr local lib python2 7 dist packages google protobuf text format py line 574 in ParseOrMerge self MergeField tokenizer message File usr local lib python2 7 dist packages google protobuf text format py line 619 in MergeField name tokenizer ConsumeIdentifierOrNumber File usr local lib python2 7 dist packages google protobuf text format py line 1066 in ConsumeIdentifierOrNumber raise self ParseError 'Expected identifier or number ' google protobuf text format ParseError 2 1 Expected identifier or number Can someone please help me understand where the error is coming from,,asimshankar,2017-06-27 23:37:02,2017-09-28 01:42:04
IS,TensorFlow buillt with march option gives illegal instruction when imported,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 1 Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce Build and Install TensorFlow wheel and import TensorFlow Describe the problem I am trying to build TensorFlow by explicitly providing march option on z13 In the past I could build and install same version v1 2 1 with default options march native The issue is when I use below commands for configure and build respectively Configure Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native march z13 Build bazel build c opt config opt tensorflow tools pip package build pip package the build succeeds however the TensorFlow wheel when installed gives issue of python crash I have verified the system arch to be z13 However when I use command gcc Q help target I could see march zEC12 I am now trying to debug why passing z13 causes above issue with wheel Also is there a way to find out what arch is exactly detected when native is passed,,"namrata-ibm,namrata-ibm",2017-09-27 05:51:56,2017-09-28 04:44:51
PR,Adding links to the Windows GPU nightly binaries and build histories,,,"av8ramit,av8ramit",2017-09-27 23:49:25,2017-09-28 05:14:53
IS,MonitoredTrainingSession CreateSession still waiting,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 rc1 2195 gd86ee219e 1 4 0 dev Python version Python 3 6 1 Anaconda 4 4 0 x86 64 Bazel version if compiling from source 0 5 2 homebrew CUDA cuDNN version no GPU model and memory no Exact command to reproduce run sh Describe the problem I have already raised this problem on stackoverflow but have not got any feedback I run the python script four times with the bash script There are three worker tasks and one master task Sometimes all the workers successfully exit But often one or two of them hang and begin emitting CreateSession still waiting for some other task messages Such waiting worker can wait for the chief worker task 0 or some other task which is already completed So the problem is that workers and even the chief do not wait for some lagging worker Is it a bug Chief is responsible for initialisation of variables But if I put a variable on each worker nothing changes The chief still do not wait I have succeeded in synchronisation of these workers by adding FIFOQueue barriers to the beginning of each session Source code logs TF script train py,,,2017-09-27 09:03:41,2017-09-28 05:19:51
IS,Build problem Configurable attribute copts does not match this configuration,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux pine64 3 10 104 2 pine64 longsleep aarch64 aarch64 aarch64 GNU Linux TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 rc0 Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version no Exact command to reproduce bazel build c opt copt funsafe math optimizations copt ftree vectorize copt fomit frame pointer verbose failures tensorflow tools pip package build pip package Describe the problem As tensorflow supports ARM 64 bit CPU platform so I build it on PINE64 But after I install bazel exactly and try to install tensorflow there is something wrong in building process Source code logs I try to annotation the number 401 code the errer above seems disapperence but other errer happens I appreciate ever help thank you all very much,,,2017-09-18 08:17:37,2017-09-28 10:49:56
IS,Sess list devices get swig python detected a memory leak error,Look at the code Is it a bug or something wrong,,allenlavoie,2017-09-28 10:17:40,2017-09-28 14:17:45
IS,Exposing the TF Server interface through the C API,asimshankar Would you be willing to expose the server interface through the C API It consists of mainly 4 methods New Start Stop and Join and it is the only functionality missing from the C API to allow easy setup for distributed training,,"eaplatanios,eaplatanios",2017-09-27 16:07:59,2017-09-28 15:12:57
IS,'tensorflow python ops nn' has no attribute iselu',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip TensorFlow version use command below 1 3 0 Python version 3 5 2 Bazel version if compiling from source CUDA cuDNN version CUDA 8 0 GPU model and memory GTX 1080 Exact command to reproduce,,,2017-09-28 11:09:25,2017-09-28 18:16:15
PR,Revert Revert EHN csv supports missing value 13008 13051,issue 13007 CF PR 13008 This reverts commit b6f253429c475d1a6f80702feadfff8ff9409156,,"facaiy,facaiy,martinwicke,facaiy,martinwicke,facaiy,martinwicke,facaiy,martinwicke",2017-09-21 05:50:03,2017-09-28 18:56:01
IS,v1 3 0 protobuf and sha256sum does not match,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am compiling tensorflow cc so using bazel and the head was at v1 3 0 it encountered an ERROR tensorflow BUILD 446 1 error loading package 'tensorflow c' Encountered error while reading extension file 'protobuf bzl' no such package ' protobuf ' java io IOException Error downloading to cache bazel bazel xiaochunlin 8e84b434cfbb634410b719fa2fe8ff20 external protobuf 0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66 tar gz Checksum was e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d but wanted 6d43b9d223ce09e5d4ce8b0060cb8a7513577a35a64c7e3dad10f0703bf3ad93 and referenced by ' tensorflow libtensorflow cc so' I manually downloaded the protobuf with the given link in tensorflow workspace bzl and the sha256sum indeed is e5fdeee6b28cf6c38d61243adff06628baa434a22b5ebb7432d2a7fbabbdb13d So I guess the sha256sum and the given version protobuf do not match can anyone verify this Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-09-27 02:06:48,2017-09-28 19:08:01
PR,Remove the extra define from xsmm backwards config rule,,,gunan,2017-09-28 18:34:28,2017-09-28 19:42:09
PR,DO NOT MERGE experimental PR,,,yifeif,2017-09-26 20:09:26,2017-09-28 19:45:30
PR,Fixed typo in function documentation,sry recognized this tiny typo,,sb2nov,2017-09-28 17:08:03,2017-09-28 20:01:29
PR,Allow partial shape inference for tf nn conv2d transpose,This fix tries to address the issue raised in 8972 where it was not possible to infer a partial shape for tf nn conv2d transpose In case any dimensions are not defined the shape will be totally undefined This fix utilizes tensor util constant value as shape so that partial shape is possible This fix fixes 8972 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,yongtang,caisq,yongtang,yongtang,yongtang,sb2nov",2017-09-20 18:29:52,2017-09-28 20:03:20
IS,Why use tensorflow1 3 0GPU training to get the validation loss is much higher than the CPU training,when I use tf1 3 0 CPU vesion the validation loss is 0 54 but get 0 74 using GPU instead I can not handle it Cudnn version is 6 0,,aselle,2017-09-27 02:45:40,2017-09-28 20:11:04
PR,Fixing typo in default name argument for name scope,Looks like a typo to me and I think this could lead to unexpected behavior,,"drpngx,sb2nov,sb2nov",2017-08-29 05:16:44,2017-09-28 20:15:46
PR,android demo add check to SpeechActivity java for call requestPermissions only with API 23,requestPermissions call possible only with API 23 minSdkVersion set to 21 for the Project Hence check required otherwise on devices with API 21 and 22 we will get the error,,"ArtsiomCh,ArtsiomCh,petewarden,ArtsiomCh,yifeif,yifeif,drpngx,sb2nov,sb2nov",2017-09-02 19:16:12,2017-09-28 20:16:32
IS,Installing Tensorflow 1 3 0 succeeds even when the cuDNN version is not correct,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 4 TensorFlow installed from source or binary pip binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 5 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 5 1 GPU model and memory TITAN X Pascal 12GB Exact command to reproduce Install tensorflow pip install tensorflow gpu Try to use tensorflow python c import tensorflow Describe the problem When imported Tensorflow looks for libcudnn so 6 and does not find it since only 5 1 is installed and fails with an error message What I would expect to happen is a it either compiles against the version of libcudnn so actually available or b it tries to check whether the correct version exists at install time and the install fails with a helpful message if it does not This is also not documented in or in fact all it says for software requirements is cuDNN v3 We recommend version 5 1 which is what I had installed Thank you Source code logs N A,,,2017-09-28 17:10:41,2017-09-28 20:50:29
PR,Make tf pow work for integer inputs,Currently tf pow freezes if both inputs are integer tensors and y contains negative values For example the call tf pow 5 2 eval never finishes The cause is the implementation of pow in Eigen To get around this issue I have changed the underlying C functor to treat differently integer inputs However tf pow now returns float tensors on input integer tensors In order to pass the backwards compatibility test I had to create a new op IntegralPow for the case of integer inputs This mirrors the implementation of abs using Abs and ComplexAbs I have made this op hidden I have also added tests for the pow function in python This should fix issue 9560,,"codrut3,sb2nov,sb2nov,sb2nov,codrut3,sb2nov",2017-09-27 06:35:22,2017-09-28 20:50:50
PR,Updating the gemmlowp hash and location for cmake build in master,,,av8ramit,2017-09-28 20:40:44,2017-09-28 22:09:25
PR,Revert Updating the gemmlowp hash and location for cmake build in master,Reverts tensorflow tensorflow 13369,,"av8ramit,av8ramit",2017-09-28 22:48:50,2017-09-28 23:32:32
IS,tensorflow inference in iOS produces EXC BAD ACCESS error when memory mapped graph is used,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 OSX Sierra 10 12 5 TensorFlow installed from source or binary source binary tested both TensorFlow version use command below 1 1 0 Bazel version if compiling from source 0 5 1 homebrew CUDA cuDNN version CPU version used GPU model and memory CPU version used Exact command to reproduce Apologies if I posted an issue not appropriate here I asked this issue on stackoverflow a week ago but seems that no one interested in this issue I tested both iOS simple and camera example in tensorflow GitHub repo and they worked well I checked those projects and recognized that camera example can use memory mapped graph if I modify constant variable model uses memory mapping to true while simple example cannot So I modified simple example source to implement same function as camera example and it seems that the mmapped graph loaded without problem but when I run inference with session Run method the app gave me EXE BAD ACCESS error I think I have done everything what I can do but still same error No idea what else I can do for I'm not good at iOS nor tensorflow core functions Could someone guide me how can I resolve this FYI run inference with optimized or quantized graph with model uses memory mapping set to false works well a here is message I get when i execute session Run method You can find original unmodified simple example project here also you can find LoadImageFromFile method here,,"skye,petewarden",2017-06-26 02:06:56,2017-09-29 01:00:24
IS,Unecessary type checking for shape invariants in tf while loop,Apologies in advance if this is not the right place to post this or I did something wrong I am new to GitHhub issues and TensorFlow Describe the problem In tf while loop when passing in shape invariants it is not easily possible to specify a shape invariant for a state variable belonging to a BasicLSTMCell This is because the tf while loop makes a nest assert same structure loop vars shape invariants call and uses the default parameter type check True what this means however is that there is no way to manually pass a nested tuple in to specify an invariant for the state For example if the shape invariant for the LSTM state in the shape invariants tuple is tuple tf TensorShape None size for size in lstm cell state size then tf while loop fails with the exception TypeError The two structures do not have the same sequence type First structure has type class 'tensorflow python ops rnn cell impl LSTMStateTuple' while second structure has type type 'tuple' However LSTMStateTuple is simply a named tuple so why does this not work You can circumvent this restriction with the following code tf contrib rnn LSTMStateTuple tuple tf TensorShape None size for size in lstm cell state size But this seems like a hack and just feels wrong I think that either type checking should be turned off for the purposes of shape invariants or some more intelligent type checking should be applied Would this make sense,,skye,2017-06-28 15:51:48,2017-09-29 01:00:29
IS,Input Pipeline for High performance Model,Describe the problem When using data flow op RecordInput in input pipeline on distributed TensorFlow every input thread seems load all files in the data dir to the local buffer after shuffling and left shifting all matched file names in data dir L139 Based on the code it seems like data input for each epoch ends with loading all files instead of part of the files on every worker If I understand correctly each input thread from each worker task should read a portion of the files which should be the shift ratio file num It will be very helpful if anyone can explain this,,aselle,2017-09-25 16:25:00,2017-09-29 03:08:00
IS,How to use the output of the graph as a parameter of the loss function,Is there any example about using the output of the graph as a parameter of the loss function For example summary str train acc train sess run train step cross entropy merged summary op accuracy feed dict x batch xs y batch ys keep prob 0 7 acc train is the accuracy of the current minibatch output of the graph I want to use the value of the acc train in the loss function the cross entropy loss is a customized function cross entropy tf reduce mean cross entropy loss logits prediction one hot labels y accuracy acc train Is there any example about this Thanks,,,2017-09-29 01:29:38,2017-09-29 03:57:27
IS,Using CheckpointReader from another language,asimshankar Is the checkpoint reader class checkpoint reader h currently exposed through any dynamic library,,"eaplatanios,asimshankar,eaplatanios",2017-09-27 16:03:57,2017-09-29 07:39:47
IS,parameterized docker build sh fails,Issue Executing parameterized docker build sh fails to generate new docker image throws out multiple error messages System information I have used a stock example script provided in TensorFlow Windows 10 professional TensorFlow not installed looking for generating a dockerfile TensorFlow version 1 3 latest eventually looking for this version Python version 3 eventually looking for this version Bazel version not yet installed CUDA cuDNN version not relevant CPU install GPU model and memory not relevant CPU install Set up Command triggering issue sh opt parameterized docker build sh Error messages opt parameterized docker build sh 70 opt parameterized docker build sh Bad substitution opt parameterized docker build sh 71 opt parameterized docker build sh source not found opt parameterized docker build sh 81 opt parameterized docker build sh to lower not found opt parameterized docker build sh 82 opt parameterized docker build sh to lower not found opt parameterized docker build sh 83 opt parameterized docker build sh to lower not found opt parameterized docker build sh 84 opt parameterized docker build sh to lower not found Required build parameters TF DOCKER BUILD TYPE TF DOCKER BUILD IS DEVEL TF DOCKER BUILD DEVEL BRANCH Optional build parameters TF DOCKER BUILD CENTRAL PIP TF DOCKER BUILD IMAGE NAME TF DOCKER BUILD VERSION TF DOCKER BUILD PORT TF DOCKER BUILD PUSH CMD opt parameterized docker build sh 102 opt parameterized docker build sh not found opt parameterized docker build sh 114 opt parameterized docker build sh not found opt parameterized docker build sh 121 opt parameterized docker build sh not found opt parameterized docker build sh 124 opt parameterized docker build sh die not found opt parameterized docker build sh 128 opt parameterized docker build sh not found opt parameterized docker build sh 130 opt parameterized docker build sh not found opt parameterized docker build sh 141 opt parameterized docker build sh die not found opt parameterized docker build sh 145 opt parameterized docker build sh not found opt parameterized docker build sh 147 opt parameterized docker build sh not found opt parameterized docker build sh 150 opt parameterized docker build sh die not found opt parameterized docker build sh 156 opt parameterized docker build sh not found FINAL IMAGE NAME tensorflow tensorflow FINAL TAG latest Original Dockerfile Dockerfile Docker build will occur in temporary directory tmp tmp IItoQQJuhx cp error reading ' proc 1 task 1 personality' Operation not permitted cp error reading ' proc 1 task 1 syscall' Operation not permitted cp cannot open ' proc 1 task 1 mem' for reading Permission denied cp error reading ' proc 1 task 1 clear refs' Invalid argument,,,2017-09-28 09:52:36,2017-09-29 10:01:20
PR,expose build default serving input fn,For 12508 I find that build default serving input fn is hidden like 12568 I do not know whether it is intentional CF pr 12617,,"facaiy,drpngx,sb2nov",2017-08-27 00:26:36,2017-09-29 14:16:17
IS,Tensor Flow Installation issue couldnot find a version that satisfies the requirement tensorflow,I am trying to install Tensorflow through anaconda Following is the error when I try to install couldnot find a version that satisfies the requirement tensorflow I tried to create two sessions with Python 3 5 and Python 3 6 but both of them returns the error identically Code used in the activated sessions pip install tensorflow Screenshot1 Python 3 6 Environment name tenflow image Screenshot2 Python 3 6 Environment name tflow image,,"Carmezim,Carmezim",2017-09-27 13:55:13,2017-09-29 14:39:20
PR,Branch 170099939,,,"sb2nov,sb2nov,sb2nov,ebrevdo,sb2nov,sb2nov,sb2nov,sb2nov",2017-09-26 20:46:10,2017-09-29 17:26:24
IS,After installing tenserflow the following error is generated Python 3 6 2 v3 6 2 5fd33b5 Jul 8 2017 04 57 36 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tenserflow as tf Traceback most recent call last File stdin line 1 in module ModuleNotFoundError No module named 'tenserflow',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information No Custom code written Only codes that have been used are from Tensorflow official documentation as opposed to using a stock example script provided in TensorFlow Windows 10 Enterprise x64 e g Linux Ubuntu 16 04 Tensorflow installed from cmd using pip3 install command source or binary TensorFlow with CPU support only Python version 3 6 2 Bazel version if compiling from source CUDA cuDNN version GPU Intel HD Graphics 5500 RAM 8GB Total Graphics Memory 4161MB pip3 install upgrade tensorflow You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem After I install Tensorflow using the command pip3 install upgrade tensorflow the installation completes without any issues When I put in the line import tensorflow as tf in the pyton interactive shell I get the following error File stdin line 1 in module ModuleNotFoundError No module named 'tensorflow' Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"carlthome,carlthome,carlthome",2017-09-25 05:39:53,2017-09-29 17:56:53
IS,Error with conditional labelling of summary,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip install tensorflow upgrade TensorFlow version use command below 1 3 0 Python version Python 2 7 12 Bazel version if compiling from source CUDA cuDNN version Cuda compilation tools release 7 5 V7 5 17 GPU model and memory NVIDIA 1070 16G Exact command to reproduce python model wgraph2 py Describe the problem I am attempting to vary my labels for the summary conditional on some tf bool data type I get an error when I attempt to use the tf cond Per this problem should have been fixed in version 1 1 0 lukaszkaiser This was due to summaries not working with tf conds right Should be corrected in 1 1 0 please take a look and reopen if you see this again Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem text2 tf cast 'blah' tf string text summary tf summary text NULL text2 works fine without conditional rightness tf cast True tf bool text summary tf cond rightness lambda tf summary text TRUE text2 lambda tf summary text FALSE text2 breaks with error below Error File usr local lib python2 7 dist packages tensorflow python client session py line 895 in run run metadata ptr File usr local lib python2 7 dist packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1321 in do run options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Retval 0 does not have value,,,2017-09-28 21:01:00,2017-09-29 18:07:54
PR,Cifar10,,,sb2nov,2017-09-29 04:47:22,2017-09-29 20:36:36
PR,ENH row shape supports unknown dim in Dataset dense to sparse batch,see issue 13216 What changes were proposed in this pull request eg row shape 20 1 10 row shape 20 None 10 How to test x add test cases pass all tests,,"facaiy,mrry,facaiy,facaiy,mrry,facaiy,sb2nov,facaiy,mrry",2017-09-24 00:05:02,2017-09-29 20:41:11
PR,Add new op BytesInUse similar to MaxBytesInUse,Adding BytesInUse This is more useful than MaxBytesInUse for getting peak memory for a given session run call because the latter gives maximum memory usage over lifetime of allocator which can span multiple session run calls multiple session objects,,"yaroslavvb,wujingyue,wujingyue,wujingyue,wujingyue,wujingyue,yaroslavvb,yaroslavvb,yaroslavvb,yaroslavvb,sb2nov,sb2nov,yaroslavvb,sb2nov",2017-09-17 23:02:48,2017-09-29 20:43:31
PR,Java API Generics Phase 2,This is the big change for generics The main classes like Tensor and Output acquire type parameters The test programs have been updated accordingly Existing code written against the non generic API should still mostly work but will generate raw types warnings The setup of the tables in the Types class from phase 1 has been centralized into Types itself to ensure it happens early enough,,"andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,asimshankar,asimshankar,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,andrewcmyers,asimshankar,andrewcmyers,andrewcmyers,asimshankar,andrewcmyers,asimshankar,asimshankar,andrewcmyers,frankchn,andrewcmyers,rmlarsen,rmlarsen,andrewcmyers,andrewcmyers,rmlarsen,rmlarsen,asimshankar,martinwicke,andrewcmyers,martinwicke,andrewcmyers,martinwicke,martinwicke,andrewcmyers,drpngx,andrewcmyers,asimshankar,asimshankar,asimshankar",2017-07-16 18:09:58,2017-09-29 20:44:18
PR,Improve input tensor structure validation algorithm,Existing code that does input tensor validation is unable to check slices sizes properly Consider this input float32 1 2 3 4 1 3 1 2 3 2 3 4 NewTensor currently treat this input as valid one This patch fixes this behaviour and also simplifies the check by removing unnecessary for cycles,,"anight,jhseu,anight,gunan,sb2nov,sb2nov",2017-09-19 11:14:20,2017-09-29 20:44:53
PR,Rearranging statements,Highlights It generates informative error,,"yifeif,yifeif,martinwicke,aselle,ispirmustafa,gunan,martinwicke,gunan",2017-09-07 20:41:27,2017-09-29 22:36:10
PR,Branch 170050380,,,"sb2nov,sb2nov",2017-09-29 23:03:38,2017-09-29 23:48:49
IS,How to save the network graph into a file,I want to save the network graph not the weights Is there any tool to export the network to a file like json,,yaroslavvb,2017-09-28 07:55:27,2017-09-29 23:50:49
IS,wrong path for retrain py,python tensorflow tensorflow examples image retraining retrain py bottleneck dir bottlenecks model dir inception summaries dir training summaries long output graph retrained graph pb output labels retrained labels txt image dir flower photos The path is wrong for retrain py with 4000 iterations default Provided the reader is following the article path should be python retrain py bottleneck dir bottlenecks model dir inception summaries dir training summaries long output graph retrained graph pb output labels retrained labels txt image dir flower photos,,,2017-06-24 07:45:09,2017-09-30 01:03:02
IS,Issue while backpropagating through sparse tensor dense multiply,I have a simple network defined as follows h1 tf sparse tensor dense matmul x W1 h2 tf matmul h1 W2 y tf matmul h2 W3 loss tf nn l2 loss y y train tf train AdamOptimizer learning rate lr minimize loss where x is a sparseTensor rest are dense Dimensions shapes of W1 1000 200 W2 200 400 and W3 400 500 When I run the following sess run train feed dict x X y Y where X is sparseTensor of shape N 1000 and Y is a tensor of shape N 500 I get an error saying OOM when allocating tensor with shape 3684773 200 This is happening while the the the gradient for W is being computed 3684773 also happens to be the number of non zero elements in X Note 1 When I compute gradients using tf gradients they work completely fine 2 When I run the same network using dense X and dense multiply tf matmul it works completely fine,,,2017-06-24 18:11:49,2017-09-30 01:03:06
IS,Tensorflow Error Cannot convert value dtype ' f4' to a TensorFlow DType,I receive an error when testing a Neural Style Transformation project with Tensorflow OpenCV using the lion test image The source of test project is Both Tensorflow and OpenCV packages were installed and compiled from source The training model used is imagenet vgg verydeep 19 mat and the runtime environment runs on a s390x CPU and does not use any CUDA support The current Python environment is 2 7 under Docker Linux Ubuntu 16 Run command bash stylize image sh image input lion jpg styles kandinsky jpg The error message at log is Is this a known issue,,"yaroslavvb,facaiy,yaroslavvb",2017-09-29 19:27:32,2017-09-30 01:31:53
PR,Branch 170086044,,,"sb2nov,sb2nov",2017-09-29 22:26:25,2017-09-30 03:00:37
PR,Branch 170073555,,,"sb2nov,sb2nov",2017-09-29 23:00:01,2017-09-30 03:00:44
PR,Branch 170099782,,,sb2nov,2017-09-29 23:40:09,2017-09-30 03:00:57
PR,Branch 170096704,,,"sb2nov,sb2nov",2017-09-29 19:58:58,2017-09-30 03:01:14
PR,Branch 170136839,,,"sb2nov,sb2nov,sb2nov",2017-09-29 23:47:58,2017-09-30 03:04:58
PR,Extracted time series regression head,Extracted the head for time series estimators This is the baby step to make sure the implementation is modeled after the ones in tf estimator canned cc,,"terrytangyuan,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,terrytangyuan,terrytangyuan,allenlavoie,terrytangyuan,terrytangyuan,sb2nov,allenlavoie,terrytangyuan,allenlavoie,terrytangyuan,terrytangyuan,allenlavoie,sb2nov,sb2nov,gunan,terrytangyuan",2017-09-24 17:38:31,2017-09-30 03:07:00
PR,Change tmp filename behavior in contrib ffmpeg to support simultaneous decodes,Encountered ill defined behavior when trying to decode two audio files in a single call to sess run Changed GetTempFilename to use mkstemps instead of getpid Old behavior demonstrated below Source code,,"sb2nov,drpngx",2017-09-30 00:02:30,2017-09-30 03:07:38
PR,Updating install golang sh bumping to 1 9,,,"ctava,caisq,sb2nov,sb2nov,sb2nov",2017-09-23 13:22:19,2017-09-30 03:09:12
PR,Branch 170216177,,,sb2nov,2017-09-30 03:42:05,2017-09-30 05:44:57
PR,Branch 170200011,,,sb2nov,2017-09-30 03:03:05,2017-09-30 05:45:03
PR,Branch 170226583,,,sb2nov,2017-09-30 00:11:38,2017-09-30 05:45:10
PR,Branch 170517511,,,"sb2nov,sb2nov,sb2nov",2017-09-29 20:10:12,2017-09-30 05:45:18
PR,Branch 170349499,,,"sb2nov,sb2nov,sb2nov",2017-09-29 18:01:19,2017-09-30 05:45:24
PR,Branch 170368495,,,"sb2nov,terrytangyuan,terrytangyuan,sb2nov,terrytangyuan,sb2nov,sb2nov,sb2nov,sb2nov,sb2nov,sb2nov,sb2nov",2017-09-28 18:32:43,2017-09-30 05:45:31
IS,Feature tf decode csv support NA values,I found many people prefer to using NA null or NULL or other string as missing value in HIVE table But tf decode csv cannot handle the case So I suggest to add na value argument like pd read csv,,facaiy,2017-09-13 02:26:33,2017-09-30 06:01:29
IS,BUG variable wo not update in input fn or outside Estimator,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 11 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Describe the problem Sometimes we will preprocess our data before feeding them into Estimator For example text data will be split or truncated at first and then we might create a shallow convolution layer for it However it seems that those variables if created wo not update in training I create a tiny code below by using input fn to clarify my question variable w seems its initial value after training Source code logs code img width 701 alt screen shot 2017 09 30 at 5 40 29 pm src,,"facaiy,facaiy",2017-09-30 09:46:05,2017-09-30 10:31:19
IS,slim learning train can not restore variables if new variable have created,Look at my code In the model ckpt slim train init fn test ckpt there is a map 'x y' 1 0 'x z' 2 0 'y z' 3 0 and I use get variables to restore include 'x' to restore variable x y and x z which are in model ckpt slim train init fn test ckpt but I create a new variable loss which is not in model ckpt slim train init fn test ckpt the code raise an error Ca not find key loss in check point file So I can not understand why check point file should have key loss does init fn not pass variables to restore to tf train Saver Is it a bug View the assign from checkpoint fn L659 it indeed uses assign from checkpoint fn to initialize tf train Saver And there is another parameter saver in slim learning train L729 it is just used to save L774 parameters of model not restore So what is wrong,,,2017-09-27 14:16:28,2017-09-30 13:24:22
IS,Is it wrong design of slim learning train,Look at this issue see my commit,,,2017-09-30 09:35:24,2017-09-30 13:26:27
IS,tf losses log losses calculation may be incorrect,L409 here we are only considering one extreme that the value of prediction can be zero missing out probably that it can be one also If the variables predictions value is 1 then this would return a log loss of log 1 1e 7 4 3429446044209946e 08 wherein if such occurs multiple times than it can indicate a lower loss I suggest clipping the value between 0 0000001 0 9999999,,,2017-08-20 10:23:44,2017-09-30 18:50:13
PR,Branch 170584354 2,,,sb2nov,2017-10-01 06:49:03,2017-10-01 06:51:26
PR,Fix typos,This PR fixes some typos correclty lenght identifer and obejct,,taehoonlee,2017-10-01 05:35:40,2017-10-01 14:27:14
PR,fix typo,,,,2017-09-30 08:53:22,2017-10-01 14:45:09
PR,Branch 170207579,,,sb2nov,2017-09-30 05:53:31,2017-10-01 21:08:59
PR,Branch 170213262,,,sb2nov,2017-09-30 05:56:37,2017-10-01 21:09:06
PR,Branch 170207994,,,"sb2nov,gunan",2017-09-30 06:43:55,2017-10-01 21:09:13
PR,Branch 170208694,,,sb2nov,2017-09-30 06:46:57,2017-10-01 21:09:31
PR,Branch 170208694 2,,,sb2nov,2017-09-30 07:40:02,2017-10-01 21:09:39
IS,The problem in saving and restoring LSTM models,I have trained a LSTM model and saved it as a small part of another model the key code as follows everything looks normal when i restore it saver restore sess saver path but when i run the epoch and reach to the code sess run op it throws an error saying that FailedPreconditionError see above for traceback Attempting to use uninitialized value RNN model RNN multi rnn cell cell 0 basic lstm cell kernel and i checked out the ckpt files and found that there was not any variables about LSTM cells so i wonder if Saver save could save the variables in LSTM cells Or i just had a wrong practice,,,2017-10-02 02:48:43,2017-10-02 03:53:23
PR,Fix the Docker GPU build adds a symlink library path,I was running a slightly modified build script the last time this passed so you may want to test it again,,"allenlavoie,flx42,gunan,allenlavoie,flx42",2017-09-30 01:23:22,2017-10-02 07:19:24
PR,R0 12,,,sb2nov,2017-09-30 06:09:51,2017-10-02 07:28:20
PR,Updating the dockerfile with the new LD LIBRARY PATH,,,"av8ramit,allenlavoie,av8ramit,av8ramit,gunan,av8ramit,av8ramit,gunan,av8ramit,allenlavoie,allenlavoie,gunan,allenlavoie,allenlavoie,allenlavoie,gunan",2017-09-28 22:08:21,2017-10-02 07:30:47
IS,Trying to run 2 fullyconnected ipynb but neural net does not learn,I'm trying to run that notebook as it is but model does not learn at all Initially I got right results like in sample but now I'm instantly getting such output when train a multinomial logistic regression using simple gradient descent Initialized Loss at step 0 24 628622 Training accuracy 9 7 Validation accuracy 10 0 Loss at step 100 35 364712 Training accuracy 9 9 Validation accuracy 9 6 Loss at step 200 38 703053 Training accuracy 9 9 Validation accuracy 10 0 Loss at step 300 30 087294 Training accuracy 10 1 Validation accuracy 10 0 Loss at step 400 35 924911 Training accuracy 9 9 Validation accuracy 10 0 Loss at step 500 38 568333 Training accuracy 10 5 Validation accuracy 10 0 Loss at step 600 31 410255 Training accuracy 10 8 Validation accuracy 10 0 Loss at step 700 42 134827 Training accuracy 10 1 Validation accuracy 10 0 Loss at step 800 26 819206 Training accuracy 9 9 Validation accuracy 10 0 Test accuracy 10 0 When I switch to switch to stochastic gradient descent training I get simmilar output Restarting kernel and even VM does not work I also tried to delete preveously generated pickle and generate it from scratch but it also does not help What might cause my neural net to stop learning at some point,,,2017-09-28 15:39:10,2017-10-02 09:38:29
IS,Leaky ReLU as part of tf nn,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source bazel release 0 5 4 CUDA cuDNN version 8 0 GPU model and memory GeForce 940MX 4Gb Exact command to reproduce N A Describe the problem A leaky relu function could be part of the standard tensorflow package under tf nn or some other non contrib module It could be something like Custom leaky relus which is what people do now may be largely non efficient See for example the discussion in,,"yaroslavvb,ebrevdo,rryan",2017-09-22 12:21:15,2017-10-02 15:47:12
PR,Update protobuf to 3 4 1,This change is required for compatibility with the upcoming Bazel 0 7 There seem to be no issues in tensorflow itself but there are in the old version of the protobuf repository,,"sb2nov,gunan,gunan,sb2nov",2017-09-27 10:47:00,2017-10-02 16:50:45
PR,Fix up compatibility issues with bazel 0 6 0,In this pull request set is simply replaced with depset since set is obsolete in bazel 0 6 0,,gunan,2017-10-02 13:22:17,2017-10-02 17:05:16
IS,bazel version 0 6 0 unable to build latest stable release v1 3 1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 3 1 Python version 3 5 Bazel version if compiling from source 0 6 0 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel build tensorflow tools pip package build pip package Describe the problem With bazel version 0 6 0 building on the latest stable tagged release v1 3 1 is not possible I get the following error This problem does not exist on master It would be very useful to have even a tiny stable release v1 3 2 or something to include this fix for those of us that like to build against a stable release,,"yaroslavvb,yaroslavvb,martinwicke,damienmg,damienmg,martinwicke,damienmg,gunan",2017-09-29 09:44:08,2017-10-02 17:05:34
PR,Rename set to depset,set is deprecated in Bazel starting from 0 6 0 Fixes 13377,,gunan,2017-10-02 10:57:44,2017-10-02 17:05:34
PR,Changed hyperlinks from http to https,Change links in Windows CPU only Windows GPU and Android https,,"sb2nov,gunan",2017-09-30 05:16:12,2017-10-02 17:19:39
PR,Branch 170584354,,,"sb2nov,sb2nov,sb2nov,frankchn,sb2nov,sb2nov,sb2nov,sb2nov,gunan,sb2nov,gunan,sb2nov,sb2nov",2017-09-30 16:48:33,2017-10-02 17:26:42
IS,'train x train y sess run train x train y ' leads machine run slowly,Hi Team My program run without error but it seems not work while my GPU shows running The main code are as follows def main file name batch size iter times x tf placeholder 'float' batch size 32 32 3 y tf placeholder 'float' shape batch size 10 predictions inference op x keep prob 0 5 predictions tf cast predictions tf float32 cost tf reduce sum tf nn softmax cross entropy with logits labels y logits predictions correct prediction tf equal y predictions accuracy tf reduce mean tf cast correct prediction 'float' train tf train GradientDescentOptimizer 0 01 minimize cost init tf global variables initializer sess tf Session sess run init for i in xrange iter times train x train y read data fetch data file name batch size train x train y sess run train x train y if i 10 0 train accuracy accuracy eval feed dict x train x y train y print d step accuarcy is f i sess run train accuracy sess run train main 'train tfrecords' 5 2000 This net is based on VGG without the 3rd 4th 5th hidden layers and the dataset is SVHN I do not know how to deal with this phenomenon,,yaroslavvb,2017-09-29 12:42:38,2017-10-02 17:27:09
PR,Branch 170594836,,,"sb2nov,sb2nov,sb2nov,drpngx,drpngx,sb2nov,drpngx,caisq,drpngx,sb2nov,gunan,sb2nov",2017-10-01 21:05:10,2017-10-02 17:30:20
IS,tfdbg does not work with sparse tensors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version Python 2 7 6 Bazel version if compiling from source CUDA cuDNN version 8 0 61 5 1 10 GPU model and memory Nvidia TITAN X Pascal 12G Exact command to reproduce python sparse debug py debug Describe the problem There seems to be a bug using tensorflow debugger with sparse tensors Below is just a simple example it fails when run with or without the debug option It works when LocalCLIDebugWrapperSession line is removed This prevents the use of the debugger while using sparse placeholders unless I'm missing something This issue also reports the same error but is not related to tfdbg Source code logs sparse debug py,,"caisq,caisq,caisq,caisq",2017-08-06 13:24:21,2017-10-02 17:31:09
IS,no such package ' local config cuda cuda',Please go to Stack Overflow for help and support System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu Server 16 04 LTS Linux PowerEdge R810 4 4 0 87 generic 110 Ubuntu SMP Tue Jul 18 12 55 35 UTC 2017 x86 64 x86 64 x86 64 GNU Linux TensorFlow installed from source or binary Source TensorFlow version use command below master r1 3 r1 2 1 Python version 2 7 Bazel version if compiling from source Build label 0 5 3 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Jul 28 08 34 59 2017 1501230899 Build timestamp 1501230899 Build timestamp as int 1501230899 CUDA cuDNN version CUDA 8 cuDNN 6 GPU model and memory GTX 1080 8gb Exact command to reproduce configure bazel build c opt config cuda tensorflow tools pip package build pip package Premade script,,"reedwm,reedwm,Mistobaan,reedwm,gunan,reedwm,gunan,damienmg,gunan",2017-07-28 22:21:58,2017-10-02 19:24:27
IS,Remove frame length restrictions in tf contrib signal stft inverse stft,So far tf contrib signal stft does not allow a larger fft length than frame length I think it is worth to allow this option by zero padding the input frames matching fft length since it is the usual proceeding that provides a smooth time freq representation,,"rryan,rryan,rryan",2017-09-28 15:48:02,2017-10-02 20:21:34
IS,Dataset Shuffle does not work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below Python version python 3 5 Bazel version if compiling from source Build label 0 5 4 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Aug 25 10 00 00 2017 1503655200 Build timestamp 1503655200 Build timestamp as int 1503655200 CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION tensorflow import tf VERSION 1 3 0 tf GIT VERSION b'v1 3 0 rc1 2408 ge9d5ee1' tf COMPILER VERSION b'v1 3 0 rc1 2408 ge9d5ee1' Describe the problem Shuffle from Dataset does not work Source code logs The following files can be used to reproduce problem,,"mrry,mrry,mrry",2017-10-02 13:13:38,2017-10-02 21:04:18
PR,Fix typos,This PR fixes some typos Explicitely ouput Dimensiton occurences partiton unknwon and Summmary,,"taehoonlee,frankchn",2017-10-02 07:56:14,2017-10-02 23:00:55
PR,Initialize fetchTensors to fix NullPointerException,fetchTensors should not be null This was broken by the refactoring in,,"sb2nov,asimshankar",2017-09-30 20:35:46,2017-10-02 23:02:24
PR,Branch 170752644,,,"frankchn,frankchn",2017-10-02 21:37:24,2017-10-02 23:33:10
PR,Allow tfexample decoder BoundingBox to be created from dense tensor,Modife the tensor to items method on the BoundingBox so that it can be created from dense tensors as well as sparse tensors which are currently required,,"sb2nov,rmlarsen,frankchn",2017-09-30 03:08:37,2017-10-03 00:20:08
IS,Passing CPU value along with GPU tensor,Hello i'm trying to pass a CPU value or a block of values from one custom op into another along with a GPU tensor but the framework seems to be converting everything to GPU tensor There does not seem to be a mechanism for passing mixed GPU CPU op results right now,,yaroslavvb,2017-09-27 05:22:43,2017-10-03 02:35:30
IS,Tensorflow does NOT utilize the memory from two GPUs in Windows 10,Tensorflow Version 1 3 0 OS Windows 10 GPUs Nvidia Quadro M4000 2 with 8G GPU memory for each GPU modes one for WDDM one for TCC I tested the official codes at I just add the GPU constraints in the main function as def main unused argv os environ 'TF ENABLE WINOGRAD NONFUSED' '1' For this line visible divice list set to only 0 and 0 1 can only support the same batch size config tf ConfigProto gpu options tf GPUOptions visible device list '0 1' resnet classifier tf estimator Estimator model fn imagenet model fn model dir FLAGS model dir config tf contrib learn RunConfig session config config for cycle in range FLAGS train steps FLAGS steps per eval tensors to log 'learning rate' 'learning rate' 'cross entropy' 'cross entropy' 'train accuracy' 'train accuracy' logging hook tf train LoggingTensorHook tensors tensors to log every n iter 100 print 'Starting a training cycle ' resnet classifier train input fn lambda input fn tf estimator ModeKeys TRAIN steps FLAGS first cycle steps or FLAGS steps per eval hooks logging hook FLAGS first cycle steps None print 'Starting to evaluate ' eval results resnet classifier evaluate input fn lambda input fn tf estimator ModeKeys EVAL print eval results In the training process if I set the visible device list to 0 1 or 0 only both can run successfully with batch size 48 but BOTH failed with batch size 49 This indicates that the second GPU is memory is not utilized as batch size could not be bigger when using two GPUs I have use Nvidia smi to confirm that only one or two GPUs are used in the above experiments My questions are 1 Is there any way that I can use bigger batch size when using two GPUs 2 If the answer for Q1 is No in Windows is there any way to do it in Linux I am not familiar with Linux In Linux can I set all GPUs to TCC mode Will the batch size be bigger when two GPUs are both in TCC mode Thank you,,"asimshankar,asimshankar,asimshankar,asimshankar",2017-10-01 18:46:40,2017-10-03 04:50:28
IS,Error Raised contradicting to the documentation,Hi This Line L35 L36 says the variable can be left empty but when done raises this error TypeError print tensors in checkpoint file takes exactly 3 arguments 2 given,,asimshankar,2017-10-02 20:22:54,2017-10-03 04:56:29
IS,Install tensorflow gpu in Ubuntun16 04 meet some problem,Successfully installed tensorflow gpu 1 3 0 t91 ubuntu pengyulong python Python 3 5 2 default Nov 17 2016 17 05 23 GCC 5 4 0 20160609 on linux Type help copyright credits or license for more information import tensorflow Traceback most recent call last File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home t91 pengyulong tensorflow lib python3 5 imp py line 242 in load module return load dynamic name filename file File home t91 pengyulong tensorflow lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcusolver so 8 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow init py line 24 in module from tensorflow python import File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home t91 pengyulong tensorflow lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home t91 pengyulong tensorflow lib python3 5 imp py line 242 in load module return load dynamic name filename file File home t91 pengyulong tensorflow lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcusolver so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help P S run this Machine configure list GPU P100 4 cuda9 0 cudnn7 0,,Carmezim,2017-09-30 09:22:24,2017-10-03 04:58:48
IS,An exception has occurred use tb to see the full traceback and low accuracy,tf issue The accuracy I get for sklearn and tensorflow is 0 428571 And after that I get a line that says An exception has occurred use tb to see the full traceback What should I do What is the accuracy that I am supposed to get,,asimshankar,2017-10-01 15:42:09,2017-10-03 06:10:29
IS,How to use config gpu options per process gpu memory fraction in tf estimator Estimator config config,I want to limit the total memory of each GPU in mnist config tf ConfigProto config gpu options per process gpu memory fraction 0 4 session tf Session config config and I added the above code to the mnis py here is the modified code in mnis py def main unused argv config tf ConfigProto config gpu options per process gpu memory fraction 0 4 mnist classifier tf estimator Estimator model fn mnist model fn model dir FLAGS model dir config config but I get the below error Traceback most recent call last File mnist py line 231 in module tf app run File usr local lib python2 7 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File mnist py line 206 in main model fn mnist model fn model dir FLAGS model dir config config File usr local lib python2 7 dist packages tensorflow python estimator estimator py line 142 in init config ValueError config must be an instance of RunConfig but provided gpu options per process gpu memory fraction 0 4 My question is How to use config gpu options per process gpu memory fraction in tf estimator Estimator config config,,"asimshankar,ispirmustafa,ispirmustafa",2017-10-03 05:20:50,2017-10-03 06:18:15
IS,bug docs tf Estimator 'train' method is missing,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Used doc OS Platform and Distribution versions etc details cat etc issue Darwin PEDS 0MAHH2C LT 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 8 1 0 clang 802 0 42 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Library Developer CommandLineTools usr bin uname a Darwin PEDS 0MAHH2C LT 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 check pips numpy 1 13 1 protobuf 3 3 0 tensorflow 1 2 1 check for virtualenv False tensorflow import tf VERSION 1 2 1 tf GIT VERSION v1 2 0 5 g435cdfc tf COMPILER VERSION v1 2 0 5 g435cdfc Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found No GPU details Exact command to reproduce I am modifying this script that works 8888 notebooks keras tfest keras estimator Integration 20of 20Keras 20with 20Tensorflow ipynb documentation as referenced below The resulting code is following details coding utf 8 import sys sys path append data dlituiev target2 from inception import get model from keras models import Sequential Model from keras layers import Dense Dropout Activation Flatten InputLayer Reshape Input import tensorflow as tf from tensorflow python framework ops import get graph from inputs from tensorflow contrib learn python learn estimators import model fn as model fn lib import numpy as np from keras import backend as K K set image dim ordering 'tf' BATCH SIZE 4 n classes 10 final activation 'linear' lr 1e 4 opt name Adadelta epochs 20 HEIGHT WIDTH 512 512 def get model model Sequential model add InputLayer input shape 512 512 1 batch size BATCH SIZE model add Reshape 512 512 model add Flatten model add Dense n classes activation arelu' return model g tf Graph with g as default model get model model build funcmodel model model def model fn features labels params optimizer params optimizer opt params params get opt params x tf placeholder tf float32 shape model layers 0 input shape print features features shape logyhat funcmodel features if mode tf estimator ModeKeys TRAIN or mode tf estimator ModeKeys EVAL loss tf contrib keras backend categorical crossentropy loss tf nn softmax cross entropy with logits labels labels logits logyhat else loss None if mode tf estimator ModeKeys TRAIN optimizer getattr tf train optimizer train op optimizer opt params minimize loss else train op None if mode tf estimator ModeKeys PREDICT predictions tf nn softmax logyhat else predictions None return tf estimator EstimatorSpec mode mode predictions predictions loss loss train op train op return model fn lib ModelFnOps mode mode predictions predictions loss loss train op train op eval metric ops eval metric ops def parser record keys to features 'height' tf FixedLenFeature tf int64 'width' tf FixedLenFeature tf int64 'image raw' tf FixedLenFeature tf string 'label' tf FixedLenFeature tf int64 features tf parse single example record features keys to features Convert from a scalar string tensor whose single string has length mnist IMAGE PIXELS to a uint8 tensor with shape mnist IMAGE PIXELS image tf decode raw features 'image raw' tf float32 annotation tf decode raw features 'mask raw' tf uint8 height tf cast features 'height' tf int32 width tf cast features 'width' tf int32 image shape tf stack height width 1 image shape tf stack HEIGHT WIDTH 1 annotation shape tf pack height width 1 image tf reshape image image shape label tf cast features label tf int32 return image label def get dataset inp fn filenames epochs 20 batch size 2 buffer size 100 def dataset input fn dataset tf contrib data TFRecordDataset filenames Use tf parse single example to extract data from a tf Example protocol buffer and perform any additional per record preprocessing Use Dataset map to build a pair of a feature dictionary and a label tensor for each example dataset dataset map parser dataset dataset shuffle buffer size buffer size dataset dataset batch batch size dataset dataset repeat epochs iterator dataset make one shot iterator features is a dictionary in which each value is a batch of values for that feature labels is a batch of labels features labels iterator get next return features labels return dataset input fn def get optimizer opt name Adadelta kwargs lr kwargs pop lr 1e 4 opt name opt name if opt name endswith Optimizer else opt name title Optimizer optimizer getattr tf train opt name return optimizer lr kwargs from tensorflow contrib learn python learn estimators import estimator LEARNING RATE 0 001 Set model params model params opt params learning rate LEARNING RATE 'optimizer' get optimizer inpfun get dataset inp fn example tfrecords epochs epochs batch size BATCH SIZE Instantiate Estimator est estimator Estimator model fn model fn params model params print help est Option 1 est train input fn inpfun steps 5000 Option 2 est fit input fn inpfun steps 5000 details Describe the problem In this manual it implies that tf Estimator has a method train When I instantiate an estimator and run est train input fn inpfun steps 5000 I am getting AttributeError 'Estimator' object has no attribute 'train',,"aselle,aselle,facaiy",2017-09-25 06:15:03,2017-10-03 07:17:30
IS,tensorflow contrib data Dataset,Issue with tensorflow contrib data module screenshot from 2017 09 30 10 25 36,,asimshankar,2017-09-30 05:02:11,2017-10-03 07:55:46
IS,ValueError No gradients provided for any variable check your graph for ops that do not support gradients,I am green in a tensorflow I do not know where it is wrong here is a warning ValueError No gradients provided for any variable check your graph for ops that do not support gradients between variables here is my code import tensorflow as tf import numpy as np import pandas as pd import math from sklearn import tree from sklearn cross validation import train test split COLUMNS CLD A DDI DFS A DFS B deg1 deg2 y filename D outputs train csv file pd read csv filename skipinitialspace True skiprows 0 names COLUMNS n samples file 'CLD A' 'DDI' 'DFS A' 'DFS B' wouldeg1' wouldeg2' n samples n samples as matrix n features file 'y' n features n features as matrix train X test X train y test y train test split n samples n features test size 0 8 random state 0 x tf placeholder tf int32 shape None 6 y tf placeholder tf int32 shape None 1 l1 tf layers dense x 10 tf nn relu hidden layer output tf layers dense l1 1 loss tf losses mean squared error y output optimizer tf train GradientDescentOptimizer learning rate 0 01 train op optimizer minimize loss with tf Session as sess init tf global variables initializer sess tf Session sess run init for i in range 1000 total loss 0 for i in range len train X feed x train X y train y sess run train op feed dict x train X y train y if i 100 0 print sess run loss feed x train X y train y,,"carlthome,asimshankar",2017-09-23 11:37:25,2017-10-03 09:45:15
IS,MatMul in TensorFlow is slower than dot product in numpy,I am observing that on my machine tf matmul in tensorflow is running significantly slower than dot product in numpy I have GTX 1080 GPU and expecting tf matmul to be at least as fast as when running the code using CPU numpy Environment Info Operating System,,yaroslavvb,2017-09-29 06:41:16,2017-10-03 12:46:46
PR,Add SavedModel support to tfcompile,This might be a little bit of a hacky way to add support but it appears to work Long term it would be better to make SavedModel a first class citizen,,"jhseu,tatatodd,drpngx,sb2nov,sb2nov,tatatodd,carlthome",2017-08-03 22:30:22,2017-10-03 16:02:02
PR,Merge pull request 1 from tensorflow master,Mise jour,,,2017-10-03 16:06:42,2017-10-03 16:11:06
PR,Java API Generics Phase 3,Added the utility Tensors class Updated tests to use it Updated scripts for generating Tensors java and the types directory Note that these are still run manually but remain helpful because maintaining so many methods and their documentation is a headache Added missing checking for attempts to create tensors from arrays of boxed primitives and a test case,,"andrewcmyers,asimshankar,asimshankar,asimshankar,asimshankar,andrewcmyers,andrewcmyers,sb2nov,asimshankar,asimshankar,asimshankar,asimshankar",2017-09-30 14:20:20,2017-10-03 19:55:14
PR,Fixing a typo in the docs for math ops,,,av8ramit,2017-10-03 21:00:29,2017-10-03 21:05:32
IS,ModuleNotFoundError No module named ' pywrap tensorflow internal',System information custom code No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Pro 10 0 15063 TensorFlow installed from source or binary binary pip TensorFlow version use command below tensorflow gpu 1 2 0 cp36 cp36m win amd64 wh CUDA cuDNN version 8 0 6 1 8 0 GPU model and memory Geforce 1080 Ti 11GB Exact command to reproduce import tensorflow Describe the problem Importing tensorflow fails immediately on import with the following log I'm running Python 3 6 1 from Anaconda I installed tensorflow gpu with pip install tensorflow gpu I have installed the CUDA cuDNN libraries per this guide Not sure what I am missing here Any help would be most appreciated Tensorflow CPU works great however This seems limited to the GPU install Thank you in advance Source code logs,,"skye,martinwicke,meteorcloudy,meteorcloudy",2017-06-25 17:57:23,2017-10-03 21:08:02
PR,Branch 170899880,,,"frankchn,frankchn,frankchn",2017-10-03 20:10:35,2017-10-03 21:25:08
IS,Bug in 1 3 Preventing Export of Canned Estimators,System information TensorFlow v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 Describe the problem See below Stack Overflow Page Use case 2 is what this bug is about The model appears to export but when attempting to perform predictions on new data the following error message is rendered ValueError Got unexpected keys in input dict 'feature1' 'feature2' 'feature3' Source code logs Code to store the model python from tensorflow contrib import predictor predict fn predictor from saved model servable model path predictions predict fn trainfeatures1 print predictions ''' Error message 2017 10 03 21 23 37 175 INFO Restoring parameters from b'DLModels 1507065657 variables variables' ValueError Traceback most recent call last ipython input 3479 70528b4cfb46 in module 1 from tensorflow contrib import predictor 2 predict fn predictor from saved model servable model path 3 predictions predict fn trainfeatures1 4 print predictions opt miniconda lib python3 5 site packages tensorflow contrib predictor predictor py in call self input dict 68 if unexpected keys 69 raise ValueError 'Got unexpected keys in input dict ' format 70 unexpected keys 71 72 feed dict ValueError Got unexpected keys in input dict 'feature1' 'feature2' 'feature3',,"martinwicke,martinwicke,martinwicke",2017-10-03 21:46:11,2017-10-03 22:08:44
PR,Rename set to depset 13443,Fixes 13377,,av8ramit,2017-10-03 21:20:17,2017-10-03 23:01:52
PR,Remove unnecessary specification for default kernel name,This line does not effect in any cases The docker container for latest py2 is working well even without this line Although it is written 'python2' the docker container for latest py3 is working parameterized docker build sh or other scripts are not overwriting the line It should be removed or overwritten when the images are built,,frankchn,2017-10-03 13:00:07,2017-10-03 23:21:24
PR,remove warning for forward decl,replace struct with class to remove warning,,"horance-liu,frankchn",2017-10-03 07:59:19,2017-10-03 23:21:36
PR,GetConvolveAlgorithms fixup take 2,Attention Move loop to toggle tensor ops inside GetConvolveAlgorithms functions Also tensor ops are not included in the returned list if they are not supported by the cuDNN or GPU architecture versions This is a re submit of PR 13252 which seems to have been accidentally squashed during the merge at hash 37800b9,,"nluehr,tfboyd,tfboyd,yifeif,yifeif,yifeif,frankchn",2017-10-03 17:07:51,2017-10-03 23:22:48
PR,Branch 170919783,,,"frankchn,frankchn",2017-10-03 22:26:08,2017-10-04 00:02:22
IS,Windows nightly build Dataset from generator fails with pyfunc error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 windows 7 TensorFlow installed from source or binary pip TensorFlow version 1 4 0 dev20170929 Python version 3 5 2 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce see below Describe the problem As described in the SO question the code EDIT Maybe related to,,"mrry,mrry",2017-10-01 13:44:27,2017-10-04 00:03:08
IS,Allow creating global tf FIFOQueue in deep frame contexts,Let is say I'm building a graph It is a pretty deep graph with many nested while loops Let is also say I have some template abstraction that allows me to create a tf FIFOQueue on demand deep in my nested while loops as I encounter things I want to send out of the graph This template allows me to infer the shape automatically from the tensors as they are encountered rather than to have to write a bunch of painful boilerplate to define all the queues and their corresponding shapes up front This is currently not possible with TensorFlow because this gives this error tensorflow python framework errors impl InvalidArgumentError The node 'fifo queue DequeueMany' has inputs from different frames The input 'while fifo queue' is in frame 'while while ' The input 'fifo queue DequeueMany n' is in frame '' I want to create a FIFOQueue in the global frame so I do not get this error In addition the documentation never explains what a frame even is Having undocumented restrictions that suddenly explode without warning is a sign of leaky abstractions and very frustrating for users,,,2017-10-03 23:51:51,2017-10-04 00:14:55
IS,tf rnn contrib ops missing in Java API,I am trying to run an LSTM built with the Python API exported to to protobuf and evaluated in Java After I updated my python scripts to use tf contrib rnn LSTMBlockCell LSTMBlockFusedCell etc cell implementations the Java portion stopped working and started throwing Evaluating the graph in Python works swimmingly I did not see anything on stack overflow There are a couple tickets on github which might be related 11847 and 12566 TF Version Java and python 1 3 0 Python Version 2 7,,asimshankar,2017-10-03 21:26:26,2017-10-04 00:41:35
PR,MKL DNN open source integration,This is a modified version of tensorflow to integrate with MKL DNN open source This pull request has one op convolution and the build setup to build MKL DNN as a third party library,,"mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,mahmoud-abuzaina,mahmoud-abuzaina,gunan,mahmoud-abuzaina,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,drpngx,agramesh1,gunan,gunan,gunan,gunan,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,mahmoud-abuzaina,sb2nov,mahmoud-abuzaina,gunan,sb2nov,gunan,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,drpngx,mahmoud-abuzaina,gunan,mahmoud-abuzaina,gunan,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,gunan",2017-09-18 23:25:19,2017-10-04 03:59:46
IS,cannot create an object of the class tf layers Dense,I want to create an object of the class tf layers Dense but do not want to do the feedforward step immediately i e not tf layers dense input units Because I want to first declare these modules layers in a class and then to have several member functions apply1 x y apply2 x y to use these layers But when I did in tensorflow tf layers Dense units it returned layer tf layers Dense 100 AttributeError 'module' object has no attribute 'Dense' How can I fix that Thanks,,asimshankar,2017-10-03 15:42:59,2017-10-04 04:41:02
IS,Tensorflow Windows 64bit build for Python 2 7,Dear All I happened to have seemingly successfully built tensorflow 1 3 1 CPU only for Python 2 7 64bit with Visual Studio 2015 on Windows Apart from numerous minor manual tweaks the main things that I had to do are the following modify tensorflow 1 3 1 tensorflow contrib cmake tools create def file py modify tensorflow 1 3 1 tensorflow tools git gen git source py modify some of the automatically generated py files copy some folders like tensorflow core profiler to tensorflow python profiler for the final distribution package add blank init py files in some folders for the final distribution package translate some Cmake build routines to Matlab as it was easier for me to debug p I have tested some example codes and found to be running as expected I however believe to make thorough tests to claim whether my build is 100 okay or not I have found in different forums that many users had struggled to build for Python 2 7 64bit in Windows and even if built ended up with import errors missing files etc I do not know whether they had finally succeeded or not So for those who are really desperate to have one I have shared the wheel package here Please beware that there is a high possibility of ABI mismatch if used Acknowledgement I would like to acknowledge Wingware for providing me a professional license for Wing IDE which I have used and in general use extensively for debugging purposes in Python Disclaimer The above shared wheel package is for illustrative purposes only which I hope will provide some useful information regarding the build process It is supplied AS IS without any warranties and support I assume no responsibility or liability for its use of any kind,,asimshankar,2017-10-03 12:56:56,2017-10-04 04:44:19
IS,Training Mini batches of data without labels for unsupervised learning problem,Hi Everyone Has anyone trained mini batches of data for an unsupervised learning problem The feed dict uses the label and in an unsupervised setting How do you overcome that Could we use fake labels that never contribute to the loss function Basically I want to iterate over my huge dataset and then optimize a custom loss function However I could not figure out how to retain my training parameters weights when using a new mini batch from the data explicitly For example the whole dataset is 6000 points and the mini batch size is 600 Currently for every mini batch I could only use new independent weight parameters because the weights are initialized based on the data points from this mini batch When we optimize the loss over the first mini batch of 600 data points we get some optimized weights How does one use these weights to optimize the next mini batch of 600 data points and so on The problem is we cannot use a shared global variable Any help or pointers in this regard would be really appreciated Thanks in advance,,asimshankar,2017-09-23 19:28:38,2017-10-04 04:55:16
PR,Fix tf signal tests on pip packages,,,"gunan,frankchn,rryan,gunan",2017-10-04 04:00:15,2017-10-04 05:53:42
IS,Issues in training the model on macOS Sierra,hello i want to create a AI chatbot using the tensorflow seq2seq model So when i try to train the model there are two issues that i want to ask about 1 why i'm getting this WARNING WARNING tensorflow From Users emansaad Desktop AI chtabot Victor eng victor seq2seq model py 129 in init all variables from tensorflow python ops variables is deprecated and will be removed after 2017 03 02 2 the temperature of my MAC book pro macOS Sierra is getting very high and the fans are running to cool the device is that normal,,asimshankar,2017-10-03 15:44:34,2017-10-04 07:42:10
PR,Branch 170960975,,,"frankchn,frankchn",2017-10-04 05:54:40,2017-10-04 15:43:04
IS,Compilation fails with config sycl due to missing comma in tensorflow core kernels training ops cc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary source TensorFlow version use command below master from github Python version 2 7 Bazel version if compiling from source bazel release 0 5 4 CUDA cuDNN version No GPU model and memory AMD Radeon TM R9 380 Series Exact command to reproduce bazel build config opt config sycl tensorflow tools pip package build pip package Describe the problem Bug in in line 2551 resulting from a missing comma Instead of ctx 0 use exclusive lock false var it should read ctx 0 use exclusive lock false var Source code logs When compiling with opencl enabled config sycl the bazel build command will result in an error,,,2017-09-27 20:06:20,2017-10-04 15:43:35
PR,Eigen BiasAdd and BiasAddGrad Fix for NCHW Format,,,"mdfaijul,sb2nov,sb2nov,mdfaijul,sb2nov,vivek-rane,sb2nov,vivek-rane",2017-09-19 16:19:43,2017-10-04 16:42:53
IS,ImportError No module named 'tensorflowvisu',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-10-04 10:21:58,2017-10-04 16:45:54
IS,Having issues with bazel build with respect to patch,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I'm just compiling OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Redhat 7 TensorFlow installed from source or binary Installing from source TensorFlow version use command below Tried 1 0 1 3 and latest Python version 2 7 10 Bazel version if compiling from source 0 5 3 CUDA cuDNN version cuda 8 cudnn 5 GPU model and memory Exact command to reproduce bazel output base cache build c opt copt msse4 1 copt msse4 2 copt mavx copt mavx2 copt mfma config cuda tensorflow serving You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Trying to compile with and without GPU does not seem to work for me because of the patch command For r0 5 1 I can compile successfully without GPU but for the other later versions I am getting the following error ERROR error loading package 'tensorflow serving resources' Encountered error while reading extension file 'protobuf bzl' no such package ' protobuf ' Traceback most recent call last File serving 1 0 cache external org tensorflow tensorflow workspace bzl line 117 apply patch repo ctx repo ctx attr patch file File serving 1 0 cache external org tensorflow tensorflow workspace bzl line 108 in apply patch execute and check ret code repo ctx cmd File serving 1 0 cache external org tensorflow tensorflow workspace bzl line 92 in execute and check ret code fail Non zero return code 1 when Non zero return code 2 when executing 'patch p1 d serving 1 0 cache external protobuf i serving 1 0 cache external org tensorflow third party protobuf add noinlines patch' Stdout patching file src google protobuf compiler cpp cpp file cc Hunk 1 succeeded at 701 with fuzz 1 offset 144 lines Hunk 2 succeeded at 803 offset 147 lines Hunk 3 succeeded at 884 offset 147 lines Stderr patch setting attribute security selinux for security selinux Permission denied Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-10-04 15:06:39,2017-10-04 17:06:27
IS,tf Session list devices seems to return an int64 for device memory limit bytes and leaks,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary 1 3 0 GPU TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory GeForce GTX 960M Exact command to reproduce Describe the problem The memory limit bytes attribute seems to be wrapping an int64 pointer as opposed to a int64 and swig seems to think it is leaking this pointer Also in the docs its referred to as memory limit list devices Source code logs N A,,"sjperkins,allenlavoie",2017-10-04 08:34:40,2017-10-04 17:28:07
IS,Building for tensorflow dll failed because architectures sm35 are not supported,Hi I am trying to compile the dynamic library tensorflow dll with cmake for windows 10 and GPU enabled However the library tf core gpu kernels failed because of the following error Unable to compile CudaAtomicAdd for complex64 architectures sm35 are not supported I am building for a device with a card graphic Gforce 1080Ti compute 61 So my configuration in Visual Studio is Cuda C C Device Code generation compute 61 sm 61 But I am still having the error Is it related with any other configuration It would be great if someone could help with this issue Thanks in advance,,"ebrevdo,mrry,mrry,mrry",2017-10-02 15:16:16,2017-10-04 17:28:21
PR,Merge fixes related to Bazel depset to r1 3 branch,Currently unable to build branch r1 3 with recommended version of Bazel Cherry picking two changes that change set to depset within tensorflow and within a library Tensorflow depends on,,"case540,case540,gunan,gunan,caisq,av8ramit",2017-10-04 03:08:48,2017-10-04 18:37:54
PR,Branch 171047652,,,"frankchn,frankchn",2017-10-04 19:52:01,2017-10-04 20:49:57
IS,TF AddGradients gradients returns wrong result when multiple outputs specified,System information Darwin Mac Admin local 15 6 0 Darwin Kernel Version 15 6 0 Thu Jun 23 18 25 34 PDT 2016 root xnu 3248 60 10 1 RELEASE X86 64 x86 64 Mac OS X 10 11 6 Describe the problem Hi I have added a unit test for TF AddGradients API see code below which is similar to this python test L337 In the test I provide two outputs y 0 x 0 2 y 1 y 0 8 where input x 0 3 According to the documentation L1018 result should be calculated by formula d y 1 y 2 dx 1 and be equal to 17502 but the API prints 6 What am I missing Thanks Source code logs,,"asimshankar,suharshs,suharshs,suharshs",2017-09-20 16:04:58,2017-10-04 20:50:56
PR,Updating the install sources file with a supported configs table,This is an attempt to fix b 28192343 It will also help with issues like I'm completely open to all criticism with moving it somewhere else and formatting,,"av8ramit,gunan,gunan,gunan,gunan,av8ramit,av8ramit,av8ramit,av8ramit,gunan,gunan,gunan,av8ramit,av8ramit,av8ramit,frankchn",2017-10-02 19:35:20,2017-10-04 22:17:55
PR,Use AllClose instead of AllEqual in layers tests,While simple implementations of convolution e g gemm based will produce exact results in these tests general implementations only guarantee floating point precision One of these tests was previously observed to fail with a max error of 1e 7,,"nluehr,drpngx,sb2nov,nluehr",2017-09-15 20:13:39,2017-10-04 23:14:52
IS,crosstool wrapper driver is not gcc failed building tensorflow tools graph transforms transform graph,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 commit 635196 Python version 2 7 Bazel version if compiling from source not complied from source but Build label 0 6 0 CUDA cuDNN version CUDA 8 0 cudnn6 0 GPU model and memory GTX 1080 Ti Exact command to reproduce bazel build tensorflow tools graph transforms transform graph verbose failures Describe the problem Build tensorflow from source successful verified it works but cannot build the tool transform graph ERROR home local ANT luxial tensorflow tensorflow tools graph transforms BUILD 222 1 Linking of rule ' tensorflow tools graph transforms transform graph' failed Exit 1 crosstool wrapper driver is not gcc failed error executing command cd home local ANT luxial cache bazel bazel luxial ce09802cfa8c7dbfadcb21edd190af0e execroot org tensorflow exec env CUDA TOOLKIT PATH usr local cuda CUDNN INSTALL PATH usr local cuda 8 0 GCC HOST COMPILER PATH usr bin gcc PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 6 1 TF CUDA VERSION 8 0 TF CUDNN VERSION 6 TF NEED CUDA 1 TF NEED OPENCL 0 external local config cuda crosstool clang bin crosstool wrapper driver is not gcc o bazel out local linux opt bin tensorflow tools graph transforms transform graph ' Wl rpath ORIGIN solib local U S Stensorflow Stools Sgraph Utransforms Ctransform Ugraph Utensorflow' ' Wl rpath ORIGIN solib local U local Uconfig Ucuda S Scuda Ccu blas Uexternal Slocal Uconfig Ucuda Scuda Scuda Slib' ' Wl rpath ORIGIN solib local U local Uconfig Ucuda S Scuda Ccusolver Uexternal Slocal Uconfig Ucuda Scuda Scu da Slib' ' Wl rpath ORIGIN solib local U local Uconfig Ucuda S Scuda Ccudart Uexternal Slocal Uconfig Ucuda Scuda Scuda Slib' Lbazel out local linux opt bin solib l ocal U S Stensorflow Stools Sgraph Utransforms Ctransform Ugraph Utensorflow Lbazel out local linux opt bin solib local U local Uconfig Ucuda S Scuda Ccublas Uexternal Sloca l Uconfig Ucuda Scuda Scuda Slib Lbazel out local linux opt bin solib local U local Uconfig Ucuda S Scuda Ccusolver Uexternal Slocal Uconfig Ucuda Scuda Scuda Slib Lbazel out local linux opt bin solib local U local Uconfig Ucuda S Scuda Ccudart Uexternal Slocal Uconfig Ucuda Scuda Scuda Slib ' Wl rpath ORIGIN rpath ORIGIN rpath ORIGIN ' Wl z muldefs Wl z muldefs Wl rpath local config cuda cuda lib64 Wl rpath local config cuda cuda extras CUPTI lib64 pthread Wl no as needed B usr bin fPIC pie Wl z relro z now no canonical prefixes pass exit codes ' Wl build id md5' ' Wl hash style gnu' Wl gc sections Wl bazel out local linux opt bin tensorflow tools graph transforms transform graph 2 params What I tried Basically everything in 8790 4365 817 1 export LD LIBRARY PATH usr local cuda 8 0 lib64 LD LIBRARY PATH LD LIBRARY PATH 2 Upgrade Bazel current build label 0 6 0 3 bazel clean expunge 4 Adding fPIC to the options in third party gpus crosstool CROSSTOOL nvcc tpl line 60 5 Add cpu compiler flags append ' fno use linker plugin' in third party gpus crosstool clang bin crosstool wrapper driver is not gcc tpl None of them solve the issue,,,2017-10-04 03:32:04,2017-10-05 00:11:24
IS,Quantization causes some operations to be missing in the graph,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 2 1 Bazel version if compiling from source 5 4 CUDA cuDNN version 8 0 61 5 1 GPU model and memory Titan X Pascal Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am currently trying to evaluate the performance of a quantized imagenet pretrained models based on what is available from TF slim For my inception models the quantization works ok except that if we use quantize nodes the performance becomes 20x worse and accuracy drops Totally the opposite of what we want However for the resnet and VGG architectures it gave me this error Which I did not encounter when evaluating my quantized inception models I am suspecting this might be due to a conversion error during quantization that does not work for some operations that are contained within the VGG 16 and resnet v1 50 architectures as defined here VGG 16 L131 Resnet v1 50 L241 Yet due to the limited error traceback produced I can not seem to identify what went wrong Because the op name is very strange something I never named or seen in the model is definition I suspect it is a quantization op I do not really know how to reproduce or find this op if I cannot import my graph def to analyze the graph variables at all Thank you,,,2017-06-29 15:26:24,2017-10-05 13:12:19
IS,Train a classifier error tensorflow python framework errors impl NotFoundError,I train my classifier but when I'm going to rate an image this error appears root e7bfbff82a10 tf files python label image py new maca 2Q jpg Traceback most recent call last File label image py line 11 in module image data tf gfile FastGFile image path 'rb' read File usr local lib python2 7 dist packages tensorflow python lib io file io py line 115 in read self preread check File usr local lib python2 7 dist packages tensorflow python lib io file io py line 75 in preread check compat as bytes self name 1024 512 status File usr lib python2 7 contextlib py line 24 in exit self gen next File usr local lib python2 7 dist packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl NotFoundError new maca 2Q jpg I follow all steps of code lab TensorFlow for poets but I still have this problem,,skye,2017-06-29 22:29:01,2017-10-05 13:12:26
PR,Re instate the plugin BUILD,This change re instates the plugin BUILD link which was removed in commit 7de939bb74c5edbc2f45e77a5d4696e70bb59e5b,,"DavidNorman,drpngx,kayzhu,DavidNorman,drpngx,kayzhu,jart,DavidNorman,gunan,allenlavoie,DavidNorman,DavidNorman,allenlavoie,drpngx,kayzhu,gunan,gunan,drpngx,DavidNorman",2017-09-25 11:30:08,2017-10-05 15:46:27
PR,Use config monolithic for the Android CI build,Avoids building some code for op generation could you test it,,"allenlavoie,av8ramit",2017-10-05 17:01:02,2017-10-05 18:16:18
IS,Iterator get next returning a tensor of shape,System information Have I written custom code Yes OS Platform and Distribution Windows 10 also tested on Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below b'unknown' 1 3 0 Python version 3 5 3 CUDA cuDNN version 8 0 6 0 Describe the problem Hello I am currently trying to use the Dataset API with TFRecords Using a tested dataset I made and refactoring working code I wanted to switch from queues to Datasets With the following code the last line will raise a TypeError 'Tensor' object is not iterable iterator get next returns in this case a tensor with shape but I believe it should return a tuple of batched sequences and labels as defined in my parse function I tried with every iterator in or out of a session but no change Is it a bug or am I doing something wrong Examples from decoding image data and resizing it really suggest this is the way to go Thanks Quentin,,"mrry,mrry",2017-10-05 18:12:58,2017-10-05 20:22:32
PR,Make code Python 2 and 3 compatible,Update the Python implementation so that both Python 2 and Python 3 environment can execute,,"frankchn,frankchn",2017-10-04 16:13:15,2017-10-05 21:22:02
PR,Give accumulate n op a gradient version 2,This pull request is a restructuring of the changes in to address high level comments Two major changes to call out vis a vis the previous PR Instead of replacing accumulate n this PR now adds a new op accumulate n v2 This new op is defined under contrib framework Refactoring changes have been broken out into a separate PR Overall this pull request addresses issue 10607 by adding a gradient to the existing accumulate n operator I followed the approach suggested by rewrite accumulate n as an atomic op which has a gradient defined for it and which gets rewritten by the runtime into the current implementation Previously this op had been implemented in Python as a constellation of lower level ops some of which are not differentiable Implementation Details I have added a new C op AccumulateNV2 which serves as a placeholder for type inference and gradient computation A new rewrite implemented in accumulate n optimizer cc replaces this placeholder with a group of AssignAdd ops and some additional ops that create initialize and destroy temporary variables I wrote a new Python wrapper function accumulate n v2 that has the same signature as the original accumulate n function Unlike the original accumulate n v2 only validates its arguments and creates an instance of the AccumulateNV2 placeholder op Testing I added a more complete set of tests for accumulate n in a previous pull request to ensure that the op would still be correct after the changes in the current pull request I copied all of the existing tests for accumulate n into a test suite for the new accumulate n v2 op see tensorflow contrib framework python ops accumulate n v2 test py I also added one additional test to verify that accumulate n v2 now has a gradient All the tests under tensorflow python currently pass on my MacOS and Linux test machines Things to Note The semantics of the new implementation are broadly the same as the original with the exception of one corner case The original implementation allowed all the inputs to accumulate n to have an undefined shape My new code requires that at least one input have a defined shape or that the user provides a shape using the shape argument to the accumulate n function I had to put the graph rewrite code into the main build to get the rewrite to compile and run properly It looks like some part of the API for adding an optimizer pass instantiates some static global data structures and can not be called from a dynamically linked library,,"frreiss,alextp,alextp,frreiss,frreiss,sb2nov,jhseu,alextp,alextp",2017-09-26 23:50:42,2017-10-05 21:22:27
PR,PREP migrate ErfGrad to c side,see 12686 How was this patch tested x add unit tests x pass all tests,,"facaiy,facaiy,facaiy,drpngx,facaiy,suharshs,suharshs,suharshs,suharshs,facaiy,facaiy,kbsriram,kbsriram,facaiy,facaiy,suharshs,facaiy,facaiy,facaiy,kbsriram,facaiy,kbsriram,facaiy,drpngx,facaiy,suharshs,kbsriram,sb2nov,sb2nov,facaiy,sb2nov,facaiy,sb2nov,sb2nov,frankchn,facaiy,frankchn,facaiy,facaiy,frankchn",2017-09-07 10:29:24,2017-10-05 21:22:45
PR,model dir keyword argument repeated,In adding regularization to prevent overfitting the code snippet repeats the model dir keyword argument causing a syntax error if you try to run it SyntaxError keyword argument repeated This removes the second occurrence of the model dir param,,frankchn,2017-10-04 21:34:06,2017-10-05 21:23:05
PR,Branch 171199546,,,"av8ramit,av8ramit,av8ramit,yaroslavvb,akshayka",2017-10-05 20:38:48,2017-10-05 22:12:09
PR,Make GCS and HDFS default build options,,,"case540,case540",2017-10-05 20:40:08,2017-10-05 22:57:43
PR,Branch 171231427 for 1 4 rc0,,,"av8ramit,av8ramit",2017-10-06 00:19:05,2017-10-06 00:45:54
IS,Downloading and building imagenet from scratch says wget command not found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using scripts provided with tensorflow to download and build imagenet from scratch OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 12 Bazel version if compiling from source NA CUDA cuDNN version 8 0 GPU model and memory Nvidia GRID M6 8Q 8GB Exact command to reproduce bazel bin inception download and preprocess imagenet DATA DIR Describe the problem I am trying to train inception v3 net for imagenet dataset using instructions at getting started After setting the download path using following command Running above command fails saying it cannot find wget root docker container data workspace models inception bazel bin inception download and preprocess imagenet DATA DIR In order to download the imagenet data you have to create an account with image net org This will get you a username and an access key You can set the IMAGENET USERNAME and IMAGENET ACCESS KEY environment variables or you can enter the credentials here Username my username Access key my password Saving downloaded files to data imagenet data raw data Downloading bounding box annotations bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 58 wget command not found bazel bin inception download and preprocess imagenet runfiles inception inception data download imagenet sh line 64 wget command not found,,,2017-07-02 07:14:43,2017-10-06 02:39:45
IS,contribution 3d geometric transformations,Hi I wonder if you see purpose in adding 3d geometric transformations to contrib such as those available in transforms3d library I have written a few of those in tensorflow for one of my projects and I wonder if it would be worth doing some refactoring and documentation to make it contribution worthy I have implemented them using tf python functions I have not done any lower level performance optimisation is that fine,,,2017-07-06 13:34:18,2017-10-06 02:39:52
PR,Fix small typo in docs of learn runner,,,case540,2017-10-06 01:43:28,2017-10-06 04:22:59
IS,AttributeError in distributed training,Im am running tensorflow gpu '0 12 1' installed in a virtualenv on Debian 9 1 with cuda 8 and cudnn 5 1 I tried to run the tutorial from I started 2 servers and 2 workers like in the tutorial The servers started as expected I run this command to start a worker,,yaroslavvb,2017-10-05 18:08:31,2017-10-06 04:24:41
PR,Branch 171234659,frankchn Doing a push so we can cut the 1 4 branch Hope you do not mind,,"av8ramit,yifeif,frankchn",2017-10-06 00:48:00,2017-10-06 15:15:17
IS,Why is gen ctc op not visible in the github repository,I want to take a look at the core of the ctc loss implementation and looking at ctc ops py shows it is imported from the gen ctc ops module but that module is impossible to find in the github repository Where can I find it Thanks,,"yaroslavvb,yaroslavvb",2017-10-06 14:44:42,2017-10-06 15:59:03
IS,Float variable in loop not incremented properly,Hi I am running the following code in tensorflow import tensorflow as tf count tf get variable count shape dtype tf float32 trainable False tf assign count 0 i tf get variable i shape dtype tf int32 trainable False tf assign i 0 cond lambda i count tf less i 5 body lambda i count tf add i 1 tf add count 1 i count tf while loop cond body i count shape invariants tf TensorShape None tf TensorShape None init tf global variables initializer with tf Session as session session run init print i session run i count session run count The expected result is that both count and i have value 5 However for count I get always different strange results like 6 18427 5 47266 5 81323 However when I change the datatype of count to tf int32 it works as expected Ubuntu 16 04 64 Bit TF Version v1 2 0 5 g435cdfc 1 2 1 Python 3 5 2,,mrry,2017-10-06 14:41:27,2017-10-06 16:03:05
PR,Simplify random selection of context words for word2vec example,Use random sample to simplify random selection of context words,,"frankchn,frankchn",2017-10-02 21:11:28,2017-10-06 16:58:42
PR,R1 3,I meant to merge to my own branch not to r1 3 please ignore first success attempt to use OpenCV in Tensorflow C,,av8ramit,2017-10-06 15:45:03,2017-10-06 17:27:00
IS,Importing TF in Python yields 'cannot import name 'build info',System information Fedora 26 x64 4 13 4 200 fc26 x86 64 Tensorflow installed from source,,"mrry,mrry,mrry,mrry",2017-10-06 15:00:17,2017-10-06 17:27:49
PR,Add an actionable error message for build info ImportError,This import statement is now the first point where we attempt to import a generated file and hence could see a failure if the user tries to import tensorflow from the root of the git repository source tree When this import fails raise a more actionable error message Fixes 13526,,"mrry,mrry",2017-10-06 15:51:10,2017-10-06 17:27:50
IS,skip some single example when reading tfrecords,I have created several tfrecords files that containing images labels or other information When reading tfrecords can I skip some samples according to the information after tf parse single example For example I want to select those samples with certain labels or those sample with the image size larger than the threshold I do not know how to do it in the current version I hope you will support this feature in the future,,"mrry,mrry",2017-10-06 16:27:12,2017-10-06 17:41:43
PR,Simplify random selection of context words for word2vec example,Use random sample to simplify random selection of context words,,frankchn,2017-10-06 16:57:08,2017-10-06 22:16:29
PR,Clean up our libcuda stub when building the GPU Docker container,A sensible suggestion by,,"allenlavoie,allenlavoie,gunan",2017-10-02 23:08:02,2017-10-06 22:53:54
PR,Update release notes for TensorFlow 1 4,,,"case540,av8ramit",2017-10-06 22:30:50,2017-10-06 23:32:55
PR,Update version strings for TensorFlow 1 4 rc0,Strings were updated by tensorflow tools ci build update version py script Hand edited several pom xml files missed by the script,,case540,2017-10-06 23:16:13,2017-10-06 23:33:13
PR,Modified README for docker,Please accept my PR I'm trying to get a hacktoberfest tshirt and I'm new to opensource just trying to get my feet wet with how PRs work on github I was skimming alot of information about docker and tensorflow online and when I came to the section of the readme I changed I had to stop and read carefully for a second to think about what was happening there when I should have just skipped over it and kept going Just added a comment that made it even more explicit that this code snipped is outdated and not recommended,,"frankchn,frankchn,frankchn",2017-10-06 02:07:23,2017-10-06 23:35:35
PR,updated instructions for libcupti for CUDA Toolkit 8 0,,,"kashif,gunan,kashif,sb2nov,gunan",2017-09-30 08:51:37,2017-10-06 23:36:45
PR,Update README md with tf nightly gpu,,,av8ramit,2017-10-06 22:54:29,2017-10-06 23:57:01
IS,Tensorflow not detecting my GPU,hi did you managed to resolve the issue I have the same problem able to use GPU before updating tensorflow to V1 3 0 I have also upgraded my Cudnn to V6 My CUDA is v8 0 so I do not seem to understand where the problem is coming from I can verify that my tensorflow is GPU version because I used tfBInaryUrl for Python2 7 PGU support Aside this I have also installed several times with 'pip install tensorflow gpu' and I still cannot run my codes on gpu Theano works fine and I could run code with GPU if I use theano When I tried to force the computation to be run on GPU my codes would not run and now I got this mesage Device mapping no known devices The frustrating thing is that I was using the GPU before I upgraded to v1 3 0 I would appreciate any help as regards this problem,,aselle,2017-09-17 01:32:40,2017-10-07 00:12:22
PR,Branch 171343275,,,"frankchn,frankchn,frankchn,frankchn,frankchn",2017-10-06 21:48:23,2017-10-07 00:13:12
IS,Weights and biases not being updated,I have already tried stackoverflow I have made this neural net to figure out whether a house is a good buy or a bad buy For some reasons the code is not updating weights and biases My loss stays same This is my code import pandas as pd import tensorflow as tf data pd read csv E workspace py datasets good bad buy csv features data drop 'index' 'good buy' axis 1 lbls data drop 'index' 'area' 'bathrooms' 'price' isq price' axis 1 features features 0 20 lbls lbls 0 20 print features print lbls n examples len lbls Model Hyper parameters epochs 100 learning rate 0 1 batch size 1 input data tf placeholder 'float' None 4 labels tf placeholder 'float' None 1 weights 'hl1' tf Variable tf random normal 4 10 'hl2' tf Variable tf random normal 10 10 'hl3' tf Variable tf random normal 10 4 'ol' tf Variable tf random normal 4 1 biases 'hl1' tf Variable tf random normal 10 'hl2' tf Variable tf random normal 10 'hl3' tf Variable tf random normal 4 'ol' tf Variable tf random normal 1 hl1 tf nn relu tf add tf matmul input data weights 'hl1' biases 'hl1' hl2 tf nn relu tf add tf matmul hl1 weights 'hl2' biases 'hl2' hl3 tf nn relu tf add tf matmul hl2 weights 'hl3' biases 'hl3' ol tf nn sigmoid tf add tf matmul hl3 weights 'ol' biases 'ol' loss tf reduce mean labels ol 2 train tf train AdamOptimizer learning rate minimize loss sess tf Session sess run tf global variables initializer iterations int n examples batch size for epoch no in range epochs ptr 0 for iteration no in range iterations epoch input features ptr ptr batch size epoch label lbls ptr ptr batch size ptr ptr batch size err sess run train loss feed dict input data features labels lbls print Error at epoch epoch no err print sess run ol feed dict input data 2104 3 399900 190 0665 This is the dataset Features area bathrooms price sq price 0 2104 3 399900 190 066540 1 1600 3 329900 206 187500 2 2400 3 369000 153 750000 3 1416 2 232000 163 841808 4 3000 4 539900 179 966667 5 1985 4 299900 151 083123 6 1534 3 314900 205 280313 7 1427 3 198999 139 452698 8 1380 3 212000 153 623188 9 1494 3 242500 162 315930 10 1940 4 239999 123 710825 11 2000 3 347000 173 500000 12 1890 3 329999 174 602645 13 4478 5 699900 156 297454 14 1268 3 259900 204 968454 15 2300 4 449900 195 608696 16 1320 2 299900 227 196970 17 1236 3 199900 161 731392 18 2609 4 499998 191 643542 19 3031 4 599000 197 624546 labels good buy 0 1 0 1 0 0 2 1 0 3 0 0 4 1 0 5 0 0 6 0 0 7 1 0 8 0 0 9 0 0 10 1 0 11 1 0 12 1 0 13 1 0 14 0 0 15 1 0 16 0 0 17 1 0 18 1 0 19 1 0 Any suggestions on how to fix this,,aselle,2017-09-17 14:48:10,2017-10-07 00:40:41
IS,Extremely slow first epoch,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary PIP tensorflow gpu 1 2 1 TensorFlow version use command below 1 2 1 Python version Python 3 6 2 CUDA cuDNN version CUDA Version 8 0 61 cuDNN Version 5 1 10 GPU model and memory GTX 1080ti x 2 11171MiB each Describe the problem When training model only First epoch after executing training script is extremely slow More specifically It takes 12 hours while second and third epoch after executed takes 2 5 hours with my environment and dataset I uploaded this issue because similar issue in stackoverflow is not handled long time In more detail my code uses model with 1d convolution layers tf nn conv1d tf bias add tf nn relu as model tf ctc loss as loss function Data is served with tf PaddingFIFOQueue tf QueueBase dequeue many and each data has different size Here is what I tried First I also assumed that pool allocator makes this problem like above stackoverflow link but now I think this issue is not from pool allocator 1 Uses tcmalloc LD PRELOAD usr lib libtcmalloc so which is suggested in here topic discuss ja7FlGrvh E 2 Uses BFC allocator type With TF CPU ALLOCATOR USE BFC true And I tried tf ConfigProto gpu options allocator type 'BFC' also 3 Build tensorflow from source with modified initial pool size limit 100 to 10000 Which is hard coded in here L187 And all trying was ineffective Except extremely slow first epoch everything was fine Weights of model is trained well save and load checkpoint and continuing training or inferencing is also fine without any warning and error Is it one of avoidable characteristic of Tensorflow or bugs Thank you for your reading If you need any more information please notify me,,"ppwwyyxx,aselle,aselle,aselle,ppwwyyxx,mrry",2017-09-18 06:48:28,2017-10-07 00:50:12
IS,ConnectionError HTTPSConnectionPool host istorage googleapis com' port 443 Max retries exceeded with url tensorflow linux gpu tensorflow gpu 1 2 1 cp27 none linux x86 64 whl Caused by class isocket error' Errno 101 Network is unreachable,I have downloaded and removed Tensorflow a few times in order to try and fix a problems with my numpy package I now get the error above when I try and download tensorflow Is there a max amount of times I can download it is that why I am getting this error Here is the traceback Exception Traceback most recent call last File home slkapur tensorflow local lib python2 7 site packages pip basecommand py line 122 in main status self run options args File home slkapur tensorflow local lib python2 7 site packages pip commands install py line 278 in run requirement set prepare files finder force root egg info self bundle bundle self bundle File home slkapur tensorflow local lib python2 7 site packages pip req py line 1197 in prepare files do download File home slkapur tensorflow local lib python2 7 site packages pip req py line 1375 in unpack url self session File home slkapur tensorflow local lib python2 7 site packages pip download py line 546 in unpack http url resp session get target url stream True File home slkapur tensorflow local lib python2 7 site packages pip vendor requests sessions py line 395 in get return self request 'GET' url kwargs File home slkapur tensorflow local lib python2 7 site packages pip download py line 237 in request return super PipSession self request method url args kwargs File home slkapur tensorflow local lib python2 7 site packages pip vendor requests sessions py line 383 in request resp self send prep send kwargs File home slkapur tensorflow local lib python2 7 site packages pip vendor requests sessions py line 486 in send r adapter send request kwargs File home slkapur tensorflow local lib python2 7 site packages pip vendor requests adapters py line 378 in send raise ConnectionError e ConnectionError HTTPSConnectionPool host istorage googleapis com' port 443 Max retries exceeded with url tensorflow linux cpu tensorflow 1 2 1 cp27 none linux x86 64 whl Caused by class isocket error' Errno 101 Network is unreachable Storing debug log for failure in tmp tmp2du06v,,,2017-06-30 16:46:29,2017-10-07 01:01:18
IS,Ran out of memory when running ROLO on tensorflow,Hello Environment ubuntu 14 04 Nvidia 740M 2Gb 8Gb RAM Cuda 7 5 TF 0 8 0 I tensorflow stream executor dso loader cc 105 successfully opened CUDA library libcublas so locally I tensorflow stream executor dso loader cc 105 successfully opened CUDA library libcudnn so locally I tensorflow stream executor dso loader cc 105 successfully opened CUDA library libcufft so locally I tensorflow stream executor dso loader cc 105 successfully opened CUDA library libcuda so 1 locally I tensorflow stream executor dso loader cc 105 successfully opened CUDA library libcurand so locally ROLO init Utils init self cfgPath Default running ROLO test Building ROLO graph I tensorflow stream executor cuda cuda gpu executor cc 900 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero I tensorflow core common runtime gpu gpu init cc 102 Found device 0 with properties name GeForce GT 740M major 3 minor 5 memoryClockRate GHz 1 0325 pciBusID 0000 0a 00 0 Total memory 1 96GiB Free memory 1 81GiB I tensorflow core common runtime gpu gpu init cc 126 DMA 0 I tensorflow core common runtime gpu gpu init cc 136 0 Y I tensorflow core common runtime gpu gpu device cc 755 Creating TensorFlow device gpu 0 device 0 name GeForce GT 740M pci bus id 0000 0a 00 0 I tensorflow core common runtime gpu gpu device cc 755 Creating TensorFlow device gpu 0 device 0 name GeForce GT 740M pci bus id 0000 0a 00 0 E tensorflow stream executor cuda cuda driver cc 932 failed to allocate 1 00G 1073741824 bytes from device CUDA ERROR OUT OF MEMORY E tensorflow stream executor cuda cuda driver cc 932 failed to allocate 921 60M 966367744 bytes from device CUDA ERROR OUT OF MEMORY E tensorflow stream executor cuda cuda driver cc 932 failed to allocate 829 44M 869731072 bytes from device CUDA ERROR OUT OF MEMORY Loading complete 'TESTING ROLO on video sequence ' 'Human2' I tensorflow core common runtime gpu gpu device cc 755 Creating TensorFlow device gpu 0 device 0 name GeForce GT 740M pci bus id 0000 0a 00 0 I tensorflow core common runtime bfc allocator cc 635 Bin 256 Total Chunks 1 Chunks in use 0 256B allocated for chunks 24B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 512 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 1024 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 2048 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 4096 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 8192 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 16384 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 32768 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 65536 Total Chunks 1 Chunks in use 0 96 2KiB allocated for chunks 96 1KiB client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 131072 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 262144 Total Chunks 1 Chunks in use 0 442 5KiB allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 524288 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 1048576 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 2097152 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 4194304 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 8388608 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 16777216 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 33554432 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 67108864 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 134217728 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 635 Bin 268435456 Total Chunks 0 Chunks in use 0 0B allocated for chunks 0B client requested for chunks 0B in use in bin 0B client requested in use in bin I tensorflow core common runtime bfc allocator cc 652 Bin for 513 50MiB was 256 00MiB Chunk State I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015c0000 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015c0100 of size 65792 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015d0200 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015d0300 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015d0400 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015d0500 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015d0600 of size 98560 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015e8700 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015e8800 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015e8900 of size 65792 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015f8a00 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x5015f8b00 of size 98560 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501610c00 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501610d00 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501610e00 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501610f00 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501611100 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501629300 of size 256 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501629400 of size 65792 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501639500 of size 98560 I tensorflow core common runtime bfc allocator cc 679 Free at 0x501611000 of size 256 I tensorflow core common runtime bfc allocator cc 679 Free at 0x501611200 of size 98560 I tensorflow core common runtime bfc allocator cc 679 Free at 0x501651600 of size 453120 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x501dc0000 of size 1073741824 I tensorflow core common runtime bfc allocator cc 670 Chunk at 0x541dc0000 of size 704482304 I tensorflow core common runtime bfc allocator cc 685 Summary of in use Chunks by size I tensorflow core common runtime bfc allocator cc 688 14 Chunks of size 256 totalling 3 5KiB I tensorflow core common runtime bfc allocator cc 688 3 Chunks of size 65792 totalling 192 8KiB I tensorflow core common runtime bfc allocator cc 688 3 Chunks of size 98560 totalling 288 8KiB I tensorflow core common runtime bfc allocator cc 688 1 Chunks of size 704482304 totalling 671 85MiB I tensorflow core common runtime bfc allocator cc 688 1 Chunks of size 1073741824 totalling 1 00GiB I tensorflow core common runtime bfc allocator cc 692 Sum Total of in use chunks 1 66GiB I tensorflow core common runtime bfc allocator cc 694 Stats Limit 1739522048 InUse 1778720768 MaxInUse 1778819584 NumAllocs 37 MaxAllocSize 1073741824 W tensorflow core common runtime bfc allocator cc 270 xxxxxxxxxxxxxxxxxxxxxxxxxxxxx xxxxxxxxx W tensorflow core common runtime bfc allocator cc 271 Ran out of memory trying to allocate 513 50MiB See logs for memory state W tensorflow core framework op kernel cc 900 Resource exhausted OOM when allocating tensor with shape 8204 16408 Traceback most recent call last File experiments testing ROLO network test all py line 276 in module main ' ' File experiments testing ROLO network test all py line 272 in main ROLO TF argvs File experiments testing ROLO network test all py line 93 in init self ROLO argvs File experiments testing ROLO network test all py line 267 in ROLO self testing x path y path File experiments testing ROLO network test all py line 157 in testing sess run init File usr local lib python2 7 dist packages tensorflow python client session py line 340 in run run metadata ptr File usr local lib python2 7 dist packages tensorflow python client session py line 564 in run feed dict string options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 637 in do run target list options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 659 in do call e code tensorflow python framework errors ResourceExhaustedError OOM when allocating tensor with shape 8204 16408 Node RNN LSTMCell W 0 Initializer random uniform mul Mul T DT FLOAT class loc RNN LSTMCell W 0 device job localhost replica 0 task 0 gpu 0 RNN LSTMCell W 0 Initializer random uniform RandomUniform RNN LSTMCell W 0 Initializer random uniform sub Caused by op u'RNN LSTMCell W 0 Initializer random uniform mul' defined at File experiments testing ROLO network test all py line 276 in module main ' ' File experiments testing ROLO network test all py line 272 in main ROLO TF argvs File experiments testing ROLO network test all py line 93 in init self ROLO argvs File experiments testing ROLO network test all py line 236 in ROLO self build networks File experiments testing ROLO network test all py line 125 in build networks self lstm module self LSTM single 'lstm test' self x self istate self weights self biases File experiments testing ROLO network test all py line 108 in LSTM single outputs state tf nn rnn cell X step state File usr local lib python2 7 dist packages tensorflow python ops rnn py line 143 in rnn output state call cell File usr local lib python2 7 dist packages tensorflow python ops rnn py line 136 in lambda call cell lambda cell input state File usr local lib python2 7 dist packages tensorflow python ops rnn cell py line 352 in call dtype self num unit shards File usr local lib python2 7 dist packages tensorflow python ops rnn cell py line 216 in get concat variable sharded variable get sharded variable name shape dtype num shards File usr local lib python2 7 dist packages tensorflow python ops rnn cell py line 246 in get sharded variable dtype dtype File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 339 in get variable collections collections File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 262 in get variable collections collections caching device caching device File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 158 in get variable dtype variable dtype File usr local lib python2 7 dist packages tensorflow python ops variables py line 209 in init dtype dtype File usr local lib python2 7 dist packages tensorflow python ops variables py line 275 in init from args self initial value ops convert to tensor initial value File usr local lib python2 7 dist packages tensorflow python ops variable scope py line 149 in lambda init val lambda initializer shape as list dtype dtype File usr local lib python2 7 dist packages tensorflow python ops init ops py line 200 in initializer dtype seed seed File usr local lib python2 7 dist packages tensorflow python ops random ops py line 183 in random uniform return math ops add rnd maxval minval minval name name File usr local lib python2 7 dist packages tensorflow python ops math ops py line 518 in binary op wrapper return func x y name name File usr local lib python2 7 dist packages tensorflow python ops gen math ops py line 1039 in mul return op def lib apply op Mul x x y y name name File usr local lib python2 7 dist packages tensorflow python ops op def library py line 655 in apply op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 2154 in create op original op self default original op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 1154 in init self traceback extract stack,,,2017-07-07 14:17:07,2017-10-07 01:01:23
IS,how to restore the certain variable scope Variables into another certain variable scope,Now I have trained a model A and I need two model A instances because one of them just is fixed and untrainable for outputting and another is trainable for next network I design two variable scope A train and A untrain I pre trained A model in variable scope A untrain and restore the model also in this scope code like Now I need to restore the same model A parameters into the same model in scope A train but I cannot follow the previous code because the ckpt files restore the params like A untrain input w1 instread of A train input w1 I want to know if there is a solution to my problem OR a better solution to make two instances which one is trainable and another is untrainable Thanks a lot EDIT 1 I know I can realize my need use code like saver train tf train Saver 'A untrain input w1' A train input w1 but it will be unpractical when my variables amount is large so I need to use the variable scope to restore instead of the specific variables' names,,"yaroslavvb,asimshankar",2017-10-07 15:29:50,2017-10-07 18:10:17
IS,When using placeholder in MonitoredTrainingSession summary called at first and not feed placeholder error,System information cat etc issue VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE check pips numpy 1 13 3 protobuf 3 4 0 tensorflow gpu 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv True tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda 8 0 lib64 DYLD LIBRARY PATH is unset nvidia smi Fri Oct 6 11 16 46 2017 NVIDIA SMI 375 66 Driver Version 375 66 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX TIT Off 0000 01 00 0 Off N A 0 54C P0 52W 250W 0MiB 12205MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage No running processes found cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 44 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 Describe the problem I am using MonitoredTrainingSession With both tf summary scalar 'test' d in graph and checkpoint dir ' temp' as param the error occurs I assume it tries to summary all at the first and run tf summary scalar 'test' d But I just want to run a and b to get the value not activate any things relate to placeholder h For people who will ask why you can not just feed a int code of real I want to do is at last I think this is a bug or I do it in a wrong way Source code logs,,asimshankar,2017-10-06 02:39:09,2017-10-07 19:31:58
IS,Dynamic loading freeing GPU devices,I wonder whether there are any on going works or plans on dynamic loading freeing GPUs What I mean by dynamic loading is a client side feature code sess load device code like below I'm trying to test whether I can run code BaseGPUDeviceFactory CreateDevices code after the session is created but if there are any better ways would you please give me some hints,,"yaroslavvb,asimshankar",2017-09-28 06:47:12,2017-10-07 19:34:16
IS,Diagnosis after running tensorflow self check py,Hello After running tensorflow self check py with Jupyter I get the following message ERROR Failed to import the TensorFlow module Python version is 3 5 TensorFlow is installed at c users gmagen appdata local programs python python35 lib site packages tensorflow All required DLLs appear to be present Please open an issue on the TensorFlow GitHub page An exception has occurred use tb to see the full traceback SystemExit 1 How do I solve it,,"yaroslavvb,asimshankar",2017-09-27 17:16:23,2017-10-07 19:34:46
PR,Fix a small typo,This PR fixes a small typo categort category Thanks for the awesome project,,,2017-10-07 07:17:27,2017-10-08 01:28:45
PR,Fix typos,This PR fixes some typos initalizers fileds mutli beacuse and summmary,,taehoonlee,2017-10-07 06:05:41,2017-10-08 01:29:37
PR,Fix broken link in performance guide,This fix fixes broken link in performance guide as models repo moved slim to models research slim Data Data Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-10-07 17:09:20,2017-10-08 02:44:54
PR,Pin TensorBoard 0 4 to tf nightly,See also which pins 0 4 to TF 1 4,,jart,2017-10-07 01:30:18,2017-10-08 05:55:05
PR,WIP BUG fix inconsistent scope for tensorflow python layers base Layer,It is proposed to fix 13429 however I'm not sure whether it is the best solution I will finish the PR when I get back from holiday next week How to test add test case pass all tests,,"facaiy,frankchn,frankchn,lukaszkaiser,facaiy,lukaszkaiser,facaiy",2017-10-06 05:49:00,2017-10-08 08:05:51
IS,Hello every one please i got an error in my code here is the error please can someone help me how to fix it thanks but saw tensor s p ValueError prefix tensor must be either a scalar or vector but saw tensor Tensor batch size 0 dtype int32,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,yaroslavvb,2017-10-08 13:47:19,2017-10-08 14:04:02
IS,What the wrong with sess run,I want to test a single test sample into a graph but unfortunately I got nothing If i just put a batch size of test sample the result is good why is it Furthermore if i just copy a single test sample multiple times the result is also nothing x reconstruction sess run t x r feed dict t z r z batch x reconstruction 0 Out 42 array 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 1 00000000e 00 I just take the a test sample from z batch running the graph x reconstruction 1 sess run t x r feed dict t z r z batch 0 reshape 1 2 x reconstruction 1 Out 44 array 2 21053764e 01 2 20187426e 01 2 38173127e 01 2 24671751e 01 2 32440352e 01 2 28797898e 01 2 25955158e 01 2 28772879e 01 2 28901237e 01 2 22546220e 01 2 15402722e 01 2 31919050e 01 2 24671602e 01 2 24030137e 01 2 37917259e 01 2 35338598e 01 2 11188301e 01 2 30172306e 01 2 26653352e 01 2 27616981e 01 2 25351438e 01 2 26480648e 01 2 29957879e 01 2 28425398e 01 Why is there a big difference between the same implementation,,yaroslavvb,2017-10-08 07:20:59,2017-10-08 14:04:28
IS,RDMA verbs stuck in some nodes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I made custom distributed inception code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Unmodified source with RDMA Verbs enabled TensorFlow version use command below 1 3 0 rc1 Python version 2 7 12 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 5 1 5 GPU model and memory NVIDIA TITAN Xp PCIe 12GB 4 per node The code works for normal grpc but stuck between some nodes not between all nodes I have tested all nodes with ib write bw and ibv rc pingpong communication between all of the nodes works fine,,byronyi,2017-08-04 11:25:00,2017-10-08 15:17:14
PR,Change dim to axis for cosine distance,This fix changes dim to axis for cosine distance so that the args are consistent with other methods in TensorFlow The backward compatibility has been maintained in the fix This fix fixes 8205 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,martinwicke,martinwicke,yongtang,yongtang,yongtang,yongtang,yifeif,yongtang,drpngx,yongtang,sb2nov,martinwicke,yongtang,martinwicke,martinwicke,drpngx",2017-09-04 20:07:35,2017-10-08 21:19:49
IS,tf read file is not in the informed folder,the documentation below Says that this function is here But is not Thanks,,facaiy,2017-09-30 00:31:40,2017-10-08 23:56:15
IS,tf train Saver setting max to keep parameter to 0 or None unintended behavior,As the tf train Saver documentation says max to keep indicates the maximum number of recent checkpoint files to keep As new files are created older files are deleted If None or 0 all checkpoint files are kept Defaults to 5 that is the 5 most recent checkpoint files are kept However when I use max to keep 0 the checkpoint file attribute all model checkpoint paths only records the most recent checkpoint file and I'm unable to load older checkpoint files I believe this is due to the block,,facaiy,2017-09-29 15:44:39,2017-10-08 23:58:05
IS,In what cases a OpKernel instance may be accessed concurrently,In the documentation for adding new op it is said that Compute method of OpKernel should be thread safe because instances of your OpKernel may be accessed concurrently I want to know in what cases an instance may be accessed concurrently If the graph has no loop or any other control flow does this guarantee that every OpKernel instance is accessed only once for each forward backward pass Thank you,,yaroslavvb,2017-09-30 18:32:10,2017-10-09 00:04:14
IS,Two issues on tf nn ctc loss,Environments tf version 1 3 CPU version python 3 5 3 6 Win10 Ubuntu 16 04 To begin with we start from code import tensorflow as tf num classes batch size seq len 3 1 2 labels tf SparseTensor indices 0 0 values 0 dense shape 1 1 inputs tf zeros seq len batch size num classes loss tf nn ctc loss labels inputs seq len print tf InteractiveSession run loss tf nn ctc loss behaves as expected and print the correct answer 1 09861231 Issue one How to calculate the ctc loss of a sequence with all blanks The tf nn ctc loss API requires that values num labels so we have no way to achieve it If I do change the values in the above example to num classes 1 the reserved blank ID tf nn ctc loss has no complain and returns the wrong answer 0 81093025 The correct answer is 2 log 3 The code to reproduce issue one is as below import tensorflow as tf num classes batch size seq len 3 1 2 labels tf SparseTensor indices 0 0 values 2 dense shape 1 1 inputs tf zeros seq len batch size num classes loss tf nn ctc loss labels inputs seq len print tf InteractiveSession run loss Issue two Let is change the sequence length to 1 as below import tensorflow as tf num classes batch size seq len 3 1 1 labels tf SparseTensor indices 0 0 values 2 dense shape 1 1 inputs tf zeros seq len batch size num classes loss tf nn ctc loss labels inputs seq len print tf InteractiveSession run loss and run the code again This code gives the correct answer log 3 in Ubuntu but crashes in Win10 with message Kernel died restarting,,ebrevdo,2017-10-03 01:23:57,2017-10-09 00:12:23
IS,Feature Request collections scope,The is currently no way to assign variables to collections during creation time other than specifying in the explicit function call to tf get variable or tf Variable This is problematic anytime you would like to use existing functions that create variables as part of their calls and you want those variables to be part of a certain collection It is even more problematic when you want variables to not be members of GraphKeys GLOBAL VARIABLES because this is the default for the tf get variable and tf Variable,,yaroslavvb,2017-10-05 06:15:17,2017-10-09 00:23:01
PR,Fix broken link in performance models,This fix fixes broken link in performance models as models repo moved inception to models research inception getting started getting started Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-10-08 20:59:17,2017-10-09 00:23:04
IS,how to condition encoder final hidden state on the inputs of RNN dynamic decoder with ScheduledOutputTrainingHelper,Hi I'm trying to use tensorflow to code RDD encoder and decoder and with different length sequence inputs so hope both encoder and decoder can be dynamic Additionally a decoder inputs is conditioned by the encoder final hidden states context vector which is similar to the Related Paper see picture a in page 3 The decoder is trying to fully inference during training with feeding previous outputs and context vector as inputs at each step class RNNEncoder Decoder object def init self input dim context dim output dim hidden dim layers stacked count learning rate self graph tf get default graph self input dim input dim self output dim output dim self context dim context dim self hidden dim hidden dim self layers stacked count layers stacked count self learning rate learning rate self sampling probability tf constant dtype tf float32 value 1 0 batch size sequence length input dimension self enc inp tf placeholder tf float32 None None self input dim name 'encoder inputs' self expected out tf placeholder tf float32 None None self output dim name 'expected outs' fullly inference during trianing self dec inp tf zeros like self expected out dtype tf float32 name wouldecoder inputs' seq length tf reduce sum tf sign tf reduce max tf abs self enc inp 2 1 self seq length tf cast seq length tf int32 with tf variable scope 'RNNEncoderDecoder' with tf variable scope Enocder as encoder varscope create encoder LSTM cell encoder cells for i in range self layers stacked count with tf variable scope 'EncoderCell ' format i encoder cells append tf nn rnn cell LSTMCell self hidden dim use peepholes True self encoder cell tf nn rnn cell MultiRNNCell encoder cells ruuning dynamic rnn encoder enc state tf nn dynamic rnn cell self encoder cell initial state None dtype tf float32 inputs self enc inp sequence length self seq length extract top layer hidden state as feature representation self context vector enc state 1 h cell state0 tf zeros like enc state 0 c dtype tf float32 hidden state0 tf zeros like enc state 0 h dtype tf float32 dec init state enc state 1 pass the top layer state of enocder to the bottom layer of decoder tf nn rnn cell LSTMStateTuple cell state0 hidden state0 condition extracted features on decoder inputs with a shape that matches decoder inputs in all but potentially the final dimension tile context vector from batch size context dim to batch size decoder sequence length context dim context vector shape tf shape self context vector context vector reshaped tf reshape self context vector context vector shape 0 1 context vector shape 1 enc inp shape tf shape self enc inp self auxiliary inputs tf tile context vector reshaped multiples 1 enc inp shape 1 1 with tf variable scope Deocder as decoder varscope create decoder LSTM cell decoder cells for i in range self layers stacked count with tf variable scope 'DecoderCell ' format i decoder cells append tf nn rnn cell LSTMCell self hidden dim use peepholes True self decoder cell tf nn rnn cell MultiRNNCell decoder cells dec out dense Dense units self output dim activation None use bias False kernel initializer tf truncated normal initializer dtype tf float32 stddev 1 0 math sqrt float self hidden dim name wouldec outp linear projection' training helper tf contrib seq2seq ScheduledOutputTrainingHelper inputs self dec inp sequence length self seq length auxiliary inputs self auxiliary inputs condtional on inputs sampling probability 1 0 for fullly inference name 'feeding conditional input' decoder tf contrib seq2seq BasicDecoder cell self decoder cell helper training helper initial state dec init state output layer dec out dense outputs final seq lengths tf contrib seq2seq dynamic decode decoder decoder impute finished True self outputs outputs optimize loss part def get decoder prediction self X session feed dict self enc inp X feed dict update self expected out X run self outputs return session run run feed dict feed dict RNN test RNNEncoder Decoder input dim 1 context dim 32 output dim 1 hidden dim 32 layers stacked count 2 learning rate 0 01 Without auxiliary inputs self auxiliary inputs it running successfully But with auxiliary inputs self auxiliary inputs I got following error ValueError Traceback most recent call last ipython input 3 02522a01f0d8 in module 9 hidden dim hidden dim 10 layers stacked count layers stacked count 11 learning rate learning rate 12 ipython input 2 86494b8d99fa in init self input dim context dim output dim hidden dim layers stacked count learning rate 98 99 outputs final seq lengths tf contrib seq2seq dynamic decode decoder decoder 100 impute finished True 101 102 self outputs outputs Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow contrib seq2seq python ops decoder py in dynamic decode decoder output time major impute finished maximum iterations parallel iterations swap memory scope 284 285 parallel iterations parallel iterations 286 swap memory swap memory 287 288 final outputs ta res 1 Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops control flow ops py in while loop cond body loop vars shape invariants parallel iterations back prop swap memory name 2773 context WhileContext parallel iterations back prop swap memory name 2774 ops add to collection ops GraphKeys WHILE CONTEXT context 2775 result context BuildLoop cond body loop vars shape invariants 2776 return result 2777 Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops control flow ops py in BuildLoop self pred body loop vars shape invariants 2602 self Enter 2603 original body result exit vars self BuildLoop 2604 pred body original loop vars loop vars shape invariants 2605 finally 2606 self Exit Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops control flow ops py in BuildLoop self pred body original loop vars loop vars shape invariants 2552 structure original loop vars 2553 flat sequence vars for body with tensor arrays 2554 body result body packed vars for body 2555 if not nest is sequence body result 2556 body result body result Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow contrib seq2seq python ops decoder py in body time outputs ta state inputs finished sequence lengths 232 233 next outputs decoder state next inputs 234 decoder finished decoder step time inputs state 235 next finished math ops logical or decoder finished finished 236 if maximum iterations is not None Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow contrib seq2seq python ops basic decoder py in step self time inputs state name 137 138 with ops name scope name BasicDecoderStep time inputs state 139 cell outputs cell state self cell inputs state 140 if self output layer is not None 141 cell outputs self output layer cell outputs Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops rnn cell impl py in call self inputs state scope 178 with vs variable scope vs get variable scope 179 custom getter self rnn get variable 180 return super RNNCell self call inputs state 181 182 def rnn get variable self getter args kwargs Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python layers base py in call self inputs args kwargs 448 Check input assumptions set after layer building e g input shape 449 self assert input compatibility inputs 450 outputs self call inputs args kwargs 451 452 Apply activity regularization Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops rnn cell impl py in call self inputs state 936 1 cell state size 937 cur state pos cell state size 938 cur inp new state cell cur inp cur state 939 new states append new state 940 Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops rnn cell impl py in call self inputs state scope 178 with vs variable scope vs get variable scope 179 custom getter self rnn get variable 180 return super RNNCell self call inputs state 181 182 def rnn get variable self getter args kwargs Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python layers base py in call self inputs args kwargs 448 Check input assumptions set after layer building e g input shape 449 self assert input compatibility inputs 450 outputs self call inputs args kwargs 451 452 Apply activity regularization Library Frameworks Python framework Versions 3 5 lib python3 5 site packages tensorflow python ops rnn cell impl py in call self inputs state 554 input size inputs get shape with rank 2 1 555 if input size value is None 556 raise ValueError Could not infer input size from inputs get shape 1 557 scope vs get variable scope 558 with vs variable scope scope initializer self initializer as unit scope ValueError Could not infer input size from inputs get shape 1 I'm just getting start to use tensforflow so could anyone help me with Is this a correct way to condition the last hidden state of encoder on the inputs of decoder and why the inputs of decoder become None after I feed the auxiliary inputs as the error,,,2017-10-07 00:25:25,2017-10-09 00:32:03
IS,Problem importing Tensorflow in Windows 10 64bits,Hello everybody I'm new in Tensorflow So forgive me for any mistakes that a make I'm importing Tensorfow gpu in Windows but I'm getting the message bellow System information OS Platform and Distribution Windows 10 64 bits TensorFlow installed from pip TensorFlow version 1 3 Python version 3 6 2 v3 6 2 5fd33b5 Jul 8 2017 04 57 36 CUDA 9 0 176 cuDNN version I have tried with version 5 6 and 7 GPU model and memory 1050 4GB Exact command to reproduce import tensorflow PS all the path settings have been set The error message C Windows system32 python Python 3 6 2 v3 6 2 5fd33b5 Jul 8 2017 04 57 36 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow Traceback most recent call last File C python lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C python lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed N o foi poss vel encontrar o m dulo especificado During handling of the above exception another exception occurred Traceback most recent call last File C python lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C python lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C python lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C python lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C python lib site packages tensorflow init py line 24 in module from tensorflow python import File C python lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C python lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C python lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C python lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed N o foi poss vel encontrar o m dulo especificado During handling of the above exception another exception occurred Traceback most recent call last File C python lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C python lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C python lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C python lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,mrry,2017-10-07 18:45:16,2017-10-09 00:47:11
IS,How to set include path and lib path when building custom code on macOS,Firstly I set CC usr local bin gcc 6 and CXX usr local bin g 6 Then I built tensorflow from source using sh tensorflow contrib makefile build all ios sh on macOS 10 12 5 and it done successfully Lastly I built a test cpp using CMake but it failed The reasons I guess maybe 1 Tensorflow built using default clang but not g 6 So how to set compiler when using tensorflow contrib makefile build all ios sh 2 The include and lib path in CMakeLists txt may be wrong,,,2017-09-26 07:50:26,2017-10-09 04:27:59
PR,Fix for AVX2 support in Visual Studio,This is a fix for issue 10199 Visual Studio 2015 possibly other versions lacks definitions for mm256 extract epi8 16 32 or 64 in the immintrin h header nor in the associated runtime so it must be implemented manually For wider portability these functions are renamed based on their required extraction indices These intrinsics should be just as fast as the externally linked versions provided by GCC,,"frankchn,gunan,gunan,mrry,gunan",2017-10-06 14:58:10,2017-10-09 13:27:01
PR,Fix unevaluated link in Reading data docs,In the pull out in Reading from files there is a link that is unevaluated due to beginning with a instead of a,,frankchn,2017-10-06 19:21:56,2017-10-09 13:27:25
PR,Added missing in train and evaluate doc,,,terrytangyuan,2017-10-07 15:08:25,2017-10-09 13:34:13
PR,update from origin,get the latest commits from original tensorflow,,,2017-10-09 14:32:36,2017-10-09 14:35:00
IS,AttributeError 'SummaryMetadata' object has no attribute wouldisplay name' windows10 64bit install tensorflow 1 3 0rc0 in Anaconda python36 with tensorflow tensorboard 0 1 7 on win10,My laptop OS is windows10 64bit install tensorflow 1 3 0rc0 in Anaconda python36 with tensorflow tensorboard 0 1 7 in it when run command tensorboard logdir path to logs met below error,,reedwm,2017-10-09 14:28:57,2017-10-09 16:32:40
IS,Assign requires shapes of both tensors to match,im trying to run the voice recognition example for some reason specifying a clip duration ms diffren from 1000 generate an error while freezing the model so running python tensorflow examples speech commands freeze py wanted words yes clip duration ms 2800 sample rate 16000 window size ms 20 start checkpoint notebooks yesmodel conv ckpt 10 output file notebooks yesmodel conv frozen pb generate the following message Error Assign requires shapes of both tensors to match lhs shape 320000 3 rhs shape 62720 3 any idea what im doing wrong,,reedwm,2017-10-09 12:58:14,2017-10-09 16:36:18
PR,Fix for the IOU metric,Previously the IOU metric under estimated the true value as described here This pull request proposes a fix following the suggestion of The score is now only taking into account classes that actually appear in the sample The new code works like this a We compute how many classes appear in the sample b We compute the score for every class If the denominator is 0 then the nominator will be 0 as well To avoid a zero division we set the denominator to 1 so the result will be 0 1 0 c Instead of taking the mean over all scores we sum up all scores and divide by the previously computed number of classes in the sample,,"alextp,alextp,alextp,alextp,alextp,alextp,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,sb2nov,drpngx",2017-08-30 19:17:27,2017-10-09 16:48:15
PR,Fixing the name of the disabled test,,,av8ramit,2017-10-09 17:36:45,2017-10-09 17:44:45
IS,KeyError Could not find enum google protobuf MethodOptions IdempotencyLevel,Hello I am using macOS sierra 10 2 6 with tensorflow 1 3 0 TF was working fine until sometime ago but as of today I get the error below when trying to import Has anyone had the same problem Here are the logs KeyError Traceback most recent call last ipython input 1 a649b509054f in module 1 import tensorflow Users antoniocampello anaconda lib python3 5 site packages tensorflow init py in module 22 23 pylint disable wildcard import 24 from tensorflow python import 25 pylint enable wildcard import 26 Users antoniocampello anaconda lib python3 5 site packages tensorflow python init py in module 52 53 Protocol buffers 54 from tensorflow core framework graph pb2 import 55 from tensorflow core framework node def pb2 import 56 from tensorflow core framework summary pb2 import Users antoniocampello anaconda lib python3 5 site packages tensorflow core framework graph pb2 py in module 8 from google protobuf import reflection as reflection 9 from google protobuf import symbol database as symbol database 10 from google protobuf import descriptor pb2 11 protoc insertion point imports 12 Users antoniocampello anaconda lib python3 5 site packages google protobuf descriptor pb2 py in module 237 options None 238 serialized start 4644 239 serialized end 4724 240 241 sym db RegisterEnumDescriptor METHODOPTIONS IDEMPOTENCYLEVEL Users antoniocampello anaconda lib python3 5 site packages google protobuf descriptor py in new cls name full name filename values containing type options file serialized start serialized end 597 serialized start None serialized end None 598 message Message CheckCalledFromGeneratedFile 599 return message default pool FindEnumTypeByName full name 600 601 def init self name full name filename values KeyError Could not find enum google protobuf MethodOptions IdempotencyLevel,,"yaroslavvb,reedwm,gunan",2017-10-06 18:15:58,2017-10-09 17:48:00
PR,Fixing the name of the disabled test,,,av8ramit,2017-10-09 17:45:58,2017-10-09 17:48:58
IS,InvalidArgumentError Expected image JPEG PNG or GIF got unknown format starting with '255',System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 1 0 Python version 2 7 12 Describe the problem trying to feed a model an image encoded in string as the model require that as an input string how i can solve that any help,,"asimshankar,asimshankar",2017-10-09 13:50:40,2017-10-09 18:01:23
PR,top level estimator docs update to match dnn py,see 13570,,,2017-10-08 16:37:18,2017-10-09 18:20:56
IS,tensorflow multi GPU lstm ValueError None values not supported,I am trying to implement a Multi GPU LSTM Using the muti gpu cifar10 My code is present here How ever when i run the code I got the following issues Traceback most recent call last File multi gpu lstm py line 227 in module tf app run File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File multi gpu lstm py line 224 in main training File multi gpu lstm py line 164 in training tower grads avg average gradients tower grads File multi gpu lstm py line 105 in average gradients expanded g tf expand dims g 0 File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python ops array ops py line 168 in expand dims return gen array ops expand dims input axis name File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python ops gen array ops py line 1051 in expand dims result op def lib apply op ExpandDims input input dim dim name name File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python framework op def library py line 504 in apply op values as ref input arg is ref dtype name File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python framework ops py line 702 in internal convert to tensor ret conversion func value dtype dtype name name as ref as ref File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python framework constant op py line 110 in constant tensor conversion function return constant v dtype dtype name name File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python framework constant op py line 99 in constant tensor util make tensor proto value dtype dtype shape shape verify shape verify shape File BIGDATA app TensorFlow python venv py2 9 gpu lib python2 7 site packages tensorflow python framework tensor util py line 360 in make tensor proto raise ValueError None values not supported ValueError None values not supported The problem is raised at this line expanded g tf expand dims g 0 it is because g gets None values if I modify to if g is not None expanded g tf expand dims g 0 everything work very fine After investigation I have realized grads get None value at this line grads optimizer compute gradients loss op When I print grads this is what I got tf Tensor 'Tower 0 gradients Tower 0 lstm MatMul grad tuple control dependency 1 0' shape 28 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac80ff32110 tf Tensor 'Tower 0 gradients Tower 0 lstm MatMul 1 grad tuple control dependency 1 0' shape 1 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac810ad1f90 tf Tensor 'Tower 0 gradients Tower 0 lstm add grad tuple control dependency 1 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac810ad19d0 tf Tensor 'Tower 0 gradients Tower 0 lstm add 1 grad tuple control dependency 1 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac810ae9d50 tf Tensor 'Tower 0 gradients Tower 0 lstm rnn while multi rnn cell cell 0 lstm cell lstm cell MatMul Enter grad b acc 3 0' shape 2 4 dtype float32 tensorflow python ops variables Variable object at 0x2ac814428c50 tf Tensor 'Tower 0 gradients Tower 0 lstm rnn while multi rnn cell cell 0 lstm cell BiasAdd Enter grad b acc 3 0' shape 4 dtype float32 tensorflow python ops variables Variable object at 0x2ac814438bd0 tf Tensor 'Tower 0 gradients Tower 0 lstm rnn while multi rnn cell cell 0 lstm cell mul Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac814446650 tf Tensor 'Tower 0 gradients Tower 0 lstm rnn while multi rnn cell cell 0 lstm cell mul 2 Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac814446690 tf Tensor 'Tower 0 gradients Tower 0 lstm rnn while multi rnn cell cell 0 lstm cell mul 4 Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac8144466d0 None tensorflow python ops variables Variable object at 0x2ac80ff32110 None tensorflow python ops variables Variable object at 0x2ac810ad1f90 None tensorflow python ops variables Variable object at 0x2ac810ad19d0 None tensorflow python ops variables Variable object at 0x2ac810ae9d50 tf Tensor 'Tower 1 gradients Tower 1 lstm rnn while multi rnn cell cell 0 lstm cell lstm cell MatMul Enter grad b acc 3 0' shape 2 4 dtype float32 tensorflow python ops variables Variable object at 0x2ac814428c50 tf Tensor 'Tower 1 gradients Tower 1 lstm rnn while multi rnn cell cell 0 lstm cell BiasAdd Enter grad b acc 3 0' shape 4 dtype float32 tensorflow python ops variables Variable object at 0x2ac814438bd0 tf Tensor 'Tower 1 gradients Tower 1 lstm rnn while multi rnn cell cell 0 lstm cell mul Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac814446650 tf Tensor 'Tower 1 gradients Tower 1 lstm rnn while multi rnn cell cell 0 lstm cell mul 2 Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac814446690 tf Tensor 'Tower 1 gradients Tower 1 lstm rnn while multi rnn cell cell 0 lstm cell mul 4 Enter grad b acc 3 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac8144466d0 tf Tensor 'Tower 1 gradients Tower 1 lstm MatMul grad tuple control dependency 1 0' shape 28 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac80ff32150 tf Tensor 'Tower 1 gradients Tower 1 lstm MatMul 1 grad tuple control dependency 1 0' shape 1 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac8152d9b90 tf Tensor 'Tower 1 gradients Tower 1 lstm add grad tuple control dependency 1 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac8152d9c50 tf Tensor 'Tower 1 gradients Tower 1 lstm add 1 grad tuple control dependency 1 0' shape 1 dtype float32 tensorflow python ops variables Variable object at 0x2ac8152fd090 We can clearly see that some None value from grads I do not know why but it seems to be very strange to be I think its probably related to some variable that are wrongly set PLEASE HELP ME TO FIND OUT,,reedwm,2017-09-30 03:14:40,2017-10-09 18:27:30
IS,Tensorflow Session Connects to Multiple Targets,I posted a question on SO where I wonder if a Tensorflow Session could connect to two or more than two targets at the same time It looks the feature is not supported yet Can we make a feature request on it,,"yaroslavvb,yaroslavvb",2017-10-09 17:15:11,2017-10-09 18:30:54
PR,Pin TensorBoard 0 4 to TensorFlow 1 4,See also,,"jart,gunan,jart,jart",2017-10-07 01:11:46,2017-10-09 21:10:17
IS,module 'tensorflow contrib tfprof' has no attribute 'ProfileContext',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary binary TensorFlow version use command below tensorflow gpu 1 3 0 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version not relevant GPU model and memory not relevant Exact command to reproduce not relevant Describe the problem Production machine not hooked up to Internet Used pip3 to install tensorflow gpu 1 3 0 cp35 cp35m win amd64 whl It looks the profile code may be missing from the wheel When run tensorflow with the following code Source code logs It appears that the examples in the Readme md may be obsolete,,"reedwm,reedwm",2017-10-09 21:15:37,2017-10-09 22:17:38
IS,cifar 10 multi gpu train code is not doing synchronization correctly,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 3 5 2 CUDA cuDNN version irrelevant GPU model and memory irrelevant Exact command to reproduce irrelevant Describe the problem Recently I am trying to implement some new synchronization models and during the research process I came across the cifar 10 multi gpu train code It seems that on this line L196 The synchronization point only collects gradients from each worker and do averaging It does not provide a synchronization barrier as tf train SyncReplicaOptimizer does In this way there may be some stale gradient exists E g on worker 1 it computes to local step 104 while on worker 2 it only computes to local step 91 Please correct me if I am wrong here,,reedwm,2017-10-09 18:48:53,2017-10-09 22:32:08
PR,Revert Implementing ghost batch norm as defined in,chrisying fyi Reverting in case we want to change the parameter name and semantics,,jhseu,2017-10-09 21:06:07,2017-10-09 23:49:20
IS,Estimator classification export feature request input single string Tensor input limitation,Within class ClassificationOutput contains the as signature def method I was wondering why there is a limitation that this method only allows recievor tensors of length 1 L109 L118 For example the following code should seemingly just work for the model created from the wide and deep model tutorial,,"skye,martinwicke,nfiedel,martinwicke,martinwicke",2017-08-17 18:44:46,2017-10-09 23:54:30
IS,tensorflow batch norm used when rank 4,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 2 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version 8 GPU model and memory Titan X Pascal Exact command to reproduce See code snippet You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I am using slim batch norm from layers and trying to understand the code flow in my use case It looks to me like the logic that decides whether to use fused batch norm or the base class will only use the fused batch norm in my case if the input rank is 2 The code description sounds like it should also be used if rank is 4 and the function itself fused batch norm supports rank of 4 but the logic seems to prevent calling it If my input is rank 4 it looks like the code will use the fused implementation in normalization layers BatchNormalization Is my understanding of the logic correct Is this the expected and proper behavior I am wondering if the the condition rank 2 should actually be rank in 2 4 If the latter is correct then this would be a potential bug If the original is correct then why have rank in 2 4 for determining feature supported Issue posted to stack overflow and cited as a bug to report which tensorflow batch norm 46620919 Source code logs,,reedwm,2017-10-09 16:55:09,2017-10-10 01:45:18
IS,tf estimator Quickstart web doc needs syncing with GitHub,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 11 6 TensorFlow installed from source or binary conda forge TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Copy and paste code sample and run on a Jupter Notebook The code sample on GitHub works The code sample on Tensorflow documentation does not My guess is that the web documentation requires syncing with Github version You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem This is regarding possibly out dated web documentation not synced with the correct GitHub version The code sample on Tensorflow documentation does not run on Python 3 6 TensorFlow v1 3 The code sample on GitHub works probably more up to date Source code logs If you copy and paste the code sample from web documentation and run on a Jupter notebook you get again this has been addressed in GitHub repo sample code Just not the web doc So possible just need a refresh of the code sample on the web doc i e replace the current web doc with the GitHub doc Thanks,,"yaroslavvb,asimshankar,MarkDaoust",2017-10-08 12:59:11,2017-10-10 02:50:10
IS,ImportError cannot import name bayesflow,I am trying to use the command cell tf contrib rnn BasicLSTMCell state size state is tuple True However it keeps telling me ImportError cannot import name bayesflow Detail is shown as below ImportError Traceback most recent call last ipython input 47 316021e54a93 in module 4 labels series tf reshape x batch size 1 for x in labels series 5 Forward passes 6 cell tf contrib rnn BasicLSTMCell state size 7 states series current state tf contrib rnn cell inputs series init state 8 anaconda lib python2 7 site packages tensorflow python util lazy loader pyc in getattr self item 51 52 def getattr self item 53 module self load 54 return getattr module item 55 anaconda lib python2 7 site packages tensorflow python util lazy loader pyc in load self 40 def load self 41 Import the target module and insert it into the parent is namespace 42 module importlib import module self name 43 self parent module globals self local name module 44 anaconda lib python2 7 importlib init pyc in import module name package 35 level 1 36 name resolve name name level package level 37 import name 38 return sys modules name anaconda lib python2 7 site packages tensorflow contrib init py in module 20 21 Add projects here they will show up under tf contrib 22 from tensorflow contrib import bayesflow 23 from tensorflow contrib import cloud 24 from tensorflow contrib import compiler ImportError cannot import name bayesflow Anybody know how to fix it Much appreciated in advance Xin,,tatatodd,2017-06-19 00:24:28,2017-10-10 12:49:15
IS,Feature Multi dimensional input in LSTM,Current input format for RNN Cell ie LSTM is it would be useful to have multi dimensionnal input as below batch size Sequence length extra dim1,,,2017-07-07 17:29:29,2017-10-10 12:49:19
IS,bazel build tensorflow examples android tensorflow demo,when i run bazel build tensorflow examples android tensorflow demo i get the result as follow INFO Found 1 target ERROR missing input file ' androidsdk build tools 24 0 3 lib dx jar' ERROR home zhu tensorflow tensorflow examples android BUILD 63 1 tensorflow examples android tensorflow demo missing input file ' androidsdk build tools 24 0 3 lib dx jar' Target tensorflow examples android tensorflow demo failed to build Use verbose failures to see the command lines of failed build steps ERROR home zhu tensorflow tensorflow examples android BUILD 63 1 1 input file s do not exist INFO Elapsed time 18 794s Critical Path 0 60s,,,2017-07-08 13:11:27,2017-10-10 12:49:24
PR,Fix typos,This PR fixes some typos overriden explictly corresonding accross and contructor,,taehoonlee,2017-10-10 13:28:07,2017-10-10 14:11:47
PR,Disable iterator ops test on Windows for 1 4 release,testRemoteIteratorUsingRemoteCallOpDirectSessionGPUCPU test is failing with TypeError only integer scalar arrays can be converted to a scalar index on the Windows GPU Release bot Disabling test,,"case540,av8ramit,case540,gunan",2017-10-10 17:01:31,2017-10-10 18:03:46
PR,Add a tf contrib image translate function,Opening as a replacement for 10748 Made a small simplification,,"ringw,vrv,ringw,ebrevdo,ebrevdo,ringw,ringw,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ringw,ringw,ringw,ringw,ringw,ringw,ringw,ahundt,ringw,ahundt,drpngx,ringw,drpngx,ringw,drpngx,sb2nov,drpngx,ringw,ringw,gunan,ringw",2017-08-15 21:12:36,2017-10-10 18:11:04
PR,Branch 171672655,,,"caisq,caisq",2017-10-10 14:28:30,2017-10-10 20:03:36
PR,Branch 171718021,,,"caisq,caisq",2017-10-10 20:02:10,2017-10-10 21:16:55
IS,sparse softmax cross entropy with logits wrong annotation,L1661 It should be If logits are scalars need to have rank 1 or if the rank of the labels is not equal to the rank of the logits minus one,,asimshankar,2017-10-09 04:53:41,2017-10-10 21:17:27
PR,Branch 171489827,,,"caisq,caisq,caisq",2017-10-09 13:43:56,2017-10-10 21:54:45
PR,Add contributing authors to 1 4 Release notes,Thanks,,"case540,av8ramit,av8ramit",2017-10-10 23:39:36,2017-10-10 23:45:42
PR,Rewrite matrix set diag GPU kernel,Base new implementation on matrix diag op,,"gunan,gunan,gunan,gunan,rmlarsen,rmlarsen",2017-10-10 02:30:54,2017-10-11 00:11:43
IS,tf contrib data Dataset generated by slicing and dicing very large images,Hi writing here as requested by for further tf contrib data feature requests I would like to create a Dataset by cutting up and preprocessing very large images I did this Which works does not go out of memory but now I am loading the same huge image multiple times in a row which is slow Any ideas,,"mrry,yongtang,tatatodd",2017-10-06 16:59:22,2017-10-11 00:44:57
IS,Using an LSTM CTC Tensorflow Model in Android,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 8 1 TensorFlow installed from source or binary Anaconda Install Prebuilt libraries were used for Tensorflow Android TensorFlow version use command below 1 2 1 Python version Python 3 5 3 Anaconda custom 64 bit Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Describe the problem I have succeeded in training my bi lstm ctc tensorflow model and now I want to use it for my handwriting recognition android application Here is the part of the code that defines the graph I used I have no ideas on what these error messages tell me nor how to resolve these,,"selcouthlyBlue,tatatodd,selcouthlyBlue",2017-10-09 08:04:24,2017-10-11 00:53:12
IS,AttributeError 'SummaryMetadata' object has no attribute wouldisplay name' OS windows Python36 tensorflow 1 3 0rc0 tensorflow tensorboard 0 1 7,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatatodd,2017-10-09 14:23:03,2017-10-11 00:55:30
IS,Unable to open table file Data loss file is too short to be an sstable,I am trying simple save and restore operation in tensorflow Here is link to Jupyter Notebook url The following line generates error new all saver restore sess data path Here is error message Here link to data file url It is not clear to me what is wrong Error is reproducible Here some details of my setup OS Win 7 64 bit Tensorflow installed through anaconda enviroment Python 3 5 Tensorflow version 1 3 0 No GPU 2 cores CPU,,tatatodd,2017-10-09 16:42:26,2017-10-11 00:56:43
IS,How to display Runtime Statistics in Tensorboard using Estimator API in a distributed environment,Hello I am running in the the same issue than described in this stack overflow question I know that GitHub is used for features requests and bugs but this question did not get an answer and I am not the only one running in the problem This is how the doc illustrates how to add and save Runtime statistics Given that there is no evident way to call sess run in the training phase with the Estimator API I am genuinely wondering how to write this kind of summary is there a workaround I was thinking about using a SessionRunHook to create something to pass to the EstimatorSpec but I am really not familiar with that,,tatatodd,2017-10-09 18:26:46,2017-10-11 00:59:10
IS,SSD mobilenet trained model with custom data only recognize images in short distances,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version 2 7 Bazel version if compiling from source na CUDA cuDNN version CUDA Version 8 0 61 GPU model and memory name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 683 pciBusID 0000 01 00 0 Total memory 10 91GiB Free memory 10 75GiB Exact command to reproduce Describe the problem I have trained a model with a custom dataset Garfield images with Tensorflow Object Detection API ssd mobilenet v1 model and referring it in the android sample application available on Tensorflow repository The application can only detected the images in distances less or equal 20cm approximately Do you have any clue about I can improve the model to perform recognitions in longer distances about 30cm or more I do not know with this limitation is related with input size I'm using tested with images with 300x300 and 68x68 or any custom data augmentation is needed to improve that Source code logs SSD with Mobilenet v1 configured for Oxford IIIT Pets Dataset Users should configure the fine tune checkpoint field in the train config as well as the label map path and input path fields in the train input reader and eval input reader Search for PATH TO BE CONFIGURED to find the fields that should be configured model ssd num classes 1 box coder faster rcnn box coder y scale 10 0 x scale 10 0 height scale 5 0 width scale 5 0 matcher argmax matcher matched threshold 0 5 unmatched threshold 0 5 ignore thresholds false negatives lower than unmatched true force match for each row true similarity calculator iou similarity anchor generator ssd anchor generator num layers 6 min scale 0 2 max scale 0 95 aspect ratios 1 0 aspect ratios 2 0 aspect ratios 0 5 aspect ratios 3 0 aspect ratios 0 3333 image resizer fixed shape resizer height 68 width 68 box predictor convolutional box predictor min depth 0 max depth 0 num layers before predictor 0 use dropout false dropout keep probability 0 8 kernel size 1 box code size 4 apply sigmoid to scores false conv hyperparams activation RELU 6 regularizer l2 regularizer weight 0 00004 initializer truncated normal initializer stddev 0 03 mean 0 0 batch norm train true scale true center true decay 0 9997 epsilon 0 001 feature extractor type issd mobilenet v1' min depth 16 depth multiplier 1 0 conv hyperparams activation RELU 6 regularizer l2 regularizer weight 0 00004 initializer truncated normal initializer stddev 0 03 mean 0 0 batch norm train true scale true center true decay 0 9997 epsilon 0 001 loss classification loss weighted sigmoid anchorwise output true localization loss weighted smooth l1 anchorwise output true hard example miner num hard examples 3000 iou threshold 0 99 loss type CLASSIFICATION max negatives per positive 3 min negatives per image 0 classification weight 1 0 localization weight 1 0 normalize loss by num matches true post processing batch non max suppression score threshold 1e 8 iou threshold 0 6 max detections per class 100 max total detections 100 score converter SIGMOID train config batch size 24 optimizer rms prop optimizer learning rate exponential decay learning rate initial learning rate 0 004 decay steps 800720 decay factor 0 95 momentum optimizer value 0 9 decay 0 9 epsilon 1 0 fine tune checkpoint home oliveira tf oda checkpoints ssd mobilenet v1 coco 11 06 2017 model ckpt from detection checkpoint true Note The below line limits the training process to 200K steps which we empirically found to be sufficient enough to train the pets dataset This effectively bypasses the learning rate schedule the learning rate will never decay Remove the below line to train indefinitely num steps 200000 data augmentation options random horizontal flip data augmentation options ssd random crop train input reader tf record input reader input path data tf oda garfield dataset pascal train garfield 68 record label map path data tf oda garfield data pascal label map garfield pbtxt eval config num examples 2000 Note The below line limits the evaluation process to 10 evaluations Remove the below line to evaluate indefinitely max evals 10 eval input reader tf record input reader input path data tf oda garfield dataset pascal val garfield 68 record label map path data tf oda garfield data pascal label map garfield pbtxt shuffle false num readers 1,,tatatodd,2017-10-10 20:04:10,2017-10-11 01:00:41
IS,Tensorflow GPU installation Error,GPU 1050Ti OS windows 10 Cuda tool kit version 9 0 cuDNN version 8 0 tensorflow gpu verision 1 3 after installing CUDA tool kit v 90 checked 'bandwith test' C Program Files NVIDIA Corporation NVSMI nvidia smi exe Path Path variables C Program Files NVIDIA GPU Computing Toolkit CUDA v9 0 bin C Program Files NVIDIA GPU Computing Toolkit CUDA v9 0 libnvvp C Program Files cuda bin created a virtual environment 'tensorflow gpu' conda install tensorflow gpu to check the tensorflow installation import tensorflow as tf to check the devices available from tensorflow python client import device lib device lib list local devices it show only CPU not the GPU stack please help me out where i am getting wrong in the virtual environment 'tensorflow gpu' some times when i load import tensorflow as tf it thoughs dll missing error Please help me out almost spent 3 4 days in it C WINDOWS system32 python Python 3 6 1 Anaconda custom 64 bit default May 11 2017 13 25 24 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Anaconda 3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Anaconda 3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Program Files Anaconda 3 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Program Files Anaconda 3 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Program Files Anaconda 3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Program Files Anaconda 3 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Program Files Anaconda 3 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"asimshankar,tatatodd",2017-10-02 10:49:02,2017-10-11 03:46:44
PR,Added support for Python3 Raspberry Pi CI builds,Updates the Docker and install scripts to use Python 3 4 in the cross compilation toolchain so we can set up nightly CI builds for Python3 wheels for the Raspberry Pi,,"petewarden,ebrevdo,ebrevdo,petewarden,gunan,petewarden,gunan,caisq,caisq,gunan",2017-10-10 19:44:59,2017-10-11 06:50:30
IS,Cannot register 2 metrics with the same name error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Swift API for TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 6 16G29 Darwin MacBookPro local 16 7 0 Darwin Kernel Version 16 7 0 TensorFlow installed from source or binary source TensorFlow version use command below master branch d864489 Python version Python 2 7 13 Bazel version if compiling from source bazel release 0 5 4 CUDA cuDNN version no GPU model and memory no Exact command to reproduce Dear TensorFlow contributors I am working on swift height level API for TensorFlow To provide that I am using system module require system libraries to provide access to C and C API C API is clear in swift code for C library I am writing my own wrappers After update master branch I can not pass tests in my framework Launch tests leads to error Cannot register 2 metrics with the same name tensorflow cc saved model load attempt count My guess is After commit a674130 ''Expose C API symbols on OS X all C API available on C library more info You can see all C interfaces are available at C library nm bazel bin tensorflow libtensorflow cc so grep 'TF New' 000000000000f5f0 T TF NewBuffer 000000000000f610 T TF NewBufferFromString 000000000000f6b0 T TF NewDeprecatedSession 00000000000176f0 T TF NewGraph 0000000000017aa0 T TF NewImportGraphDefOptions 0000000000013190 T TF NewOperation 000000000001a170 T TF NewSession 000000000000f500 T TF NewSessionOptions 000000000000ea90 T TF NewStatus 000000000000ee80 T TF NewTensor 0000000000018a70 T TF NewWhile 000000000001cbb0 t ZZ22TF NewBufferFromStringEN3 08 invokeEPvm So my question request is 1 Is it well considered and final decision to provide C API in C library 2 Will it be default and public configuration to provide C API in C library 3 Is there any way to configure and build tensorflow library without changing tools tf env collect sh file Thank you for your work,,"asimshankar,tatatodd,asimshankar,asimshankar,asimshankar",2017-10-06 13:23:02,2017-10-11 07:50:02
IS,INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP,Hi all I use Python 2 7 13 and Tensorflow 1 3 0 on CPU I want to use DensNet url for regression problem My data contains 60000 jpeg images with 37 float labels for each image I saved my data into tfrecords files by def Read Labels label path labels csv pd read csv label path labels np array labels csv return labels 1 def load image addr read an image and resize to 224 224 img cv2 imread addr img cv2 resize img 224 224 interpolation cv2 INTER CUBIC img cv2 cvtColor img cv2 COLOR BGR2RGB img img astype np float32 return img def Shuffle images with labels shuffle data photo filenames labels if shuffle data c list zip photo filenames labels shuffle c addrs labels zip c return addrs labels def image to tfexample mine image data image format height width label return tf train Example features tf train Features feature 'image encoded' bytes feature image data 'image format' bytes feature image format 'image class label' float feature label 'image height' int64 feature height 'image width' int64 feature width def convert dataset split name filenames labels dataset dir assert split name in 'train' 'validation' num per shard int math ceil len filenames float NUM SHARDS with tf Graph as default for shard id in range NUM SHARDS output filename get dataset filename dataset path split name shard id with tf python io TFRecordWriter output filename as tfrecord writer start ndx shard id num per shard end ndx min shard id 1 num per shard len filenames for i in range start ndx end ndx sys stdout write ' r Converting image d d shard d' i 1 len filenames shard id sys stdout flush img load image filenames i image data tf compat as bytes img tostring label labels i example image to tfexample mine image data image format height width label Serialize to string and write on the file tfrecord writer write example SerializeToString sys stdout write ' n' sys stdout flush def run dataset dir labels Read Labels dataset dir ' training labels csv' photo filenames get filenames and classes dataset dir ' images training' shuffle data True photo filenames labels Shuffle images with labels shuffle data photo filenames labels training filenames photo filenames NUM VALIDATION training labels labels NUM VALIDATION validation filenames photo filenames NUM VALIDATION validation labels labels NUM VALIDATION convert dataset 'train' training filenames training labels dataset path convert dataset 'validation' validation filenames validation labels dataset path print ' nFinished converting the Flowers dataset ' And I decode it by with tf Session as sess feature 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'jpeg' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 filename queue tf train string input producer data path num epochs 1 reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example features feature image tf decode raw features 'image encoded' tf float32 print image get shape label tf cast features 'image class label' tf float32 image tf reshape image 224 224 3 images labels tf train shuffle batch image label batch size 10 capacity 30 num threads 1 min after dequeue 10 init op tf group tf global variables initializer tf local variables initializer sess run init op coord tf train Coordinator threads tf train start queue runners coord coord for batch index in range 6 img lbl sess run images labels img img astype np uint8 print img shape for j in range 6 plt subplot 2 3 j 1 plt imshow img j plt show coord request stop coord join threads It is all fine up to this point But when I use the bellow commands for decoding TFRecord files reader tf TFRecordReader keys to features 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'raw' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 items to handlers 'image' slim tfexample decoder Image 'image encoded' 'label' slim tfexample decoder Tensor 'image class label' decoder slim tfexample decoder TFExampleDecoder keys to features items to handlers I get the following error INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP Node case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert Assert T DT STRING summarize 3 device job localhost replica 0 task 0 cpu 0 case If 0 decode image cond jpeg cond png cond gif is bmp case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert data 0 INFO tensorflow Caught OutOfRangeError Stopping Training INFO sensorflow Finished training Saving model to disk To use Densenet for my problem I should fix this error first Could anybody please help me out of this problem This code works perfectly for the datasets like flowers MNIST and CIFAR10 available at url but does not work for my data,,,2017-10-11 10:52:53,2017-10-11 10:57:00
IS,INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP Node case If 0 decode image cond jpeg cond png cond gif,Hi all I use Python 2 7 13 and Tensorflow 1 3 0 on CPU I want to use DensNet url for regression problem My data contains 60000 jpeg images with 37 float labels for each image I saved my data into tfrecords files by def Read Labels label path labels csv pd read csv label path labels np array labels csv return labels 1 def load image addr read an image and resize to 224 224 img cv2 imread addr img cv2 resize img 224 224 interpolation cv2 INTER CUBIC img cv2 cvtColor img cv2 COLOR BGR2RGB img img astype np float32 return img def Shuffle images with labels shuffle data photo filenames labels if shuffle data c list zip photo filenames labels shuffle c addrs labels zip c return addrs labels def image to tfexample mine image data image format height width label return tf train Example features tf train Features feature 'image encoded' bytes feature image data 'image format' bytes feature image format 'image class label' float feature label 'image height' int64 feature height 'image width' int64 feature width def convert dataset split name filenames labels dataset dir assert split name in 'train' 'validation' num per shard int math ceil len filenames float NUM SHARDS with tf Graph as default for shard id in range NUM SHARDS output filename get dataset filename dataset path split name shard id with tf python io TFRecordWriter output filename as tfrecord writer start ndx shard id num per shard end ndx min shard id 1 num per shard len filenames for i in range start ndx end ndx sys stdout write ' r Converting image d d shard d' i 1 len filenames shard id sys stdout flush img load image filenames i image data tf compat as bytes img tostring label labels i example image to tfexample mine image data image format height width label Serialize to string and write on the file tfrecord writer write example SerializeToString sys stdout write ' n' sys stdout flush def run dataset dir labels Read Labels dataset dir ' training labels csv' photo filenames get filenames and classes dataset dir ' images training' shuffle data True photo filenames labels Shuffle images with labels shuffle data photo filenames labels training filenames photo filenames NUM VALIDATION training labels labels NUM VALIDATION validation filenames photo filenames NUM VALIDATION validation labels labels NUM VALIDATION convert dataset 'train' training filenames training labels dataset path convert dataset 'validation' validation filenames validation labels dataset path print ' nFinished converting the Flowers dataset ' And I decode it by with tf Session as sess feature 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'jpeg' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 filename queue tf train string input producer data path num epochs 1 reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example features feature image tf decode raw features 'image encoded' tf float32 print image get shape label tf cast features 'image class label' tf float32 image tf reshape image 224 224 3 images labels tf train shuffle batch image label batch size 10 capacity 30 num threads 1 min after dequeue 10 init op tf group tf global variables initializer tf local variables initializer sess run init op coord tf train Coordinator threads tf train start queue runners coord coord for batch index in range 6 img lbl sess run images labels img img astype np uint8 print img shape for j in range 6 plt subplot 2 3 j 1 plt imshow img j plt show coord request stop coord join threads It is all fine up to this point But when I use the bellow commands for decoding TFRecord files reader tf TFRecordReader keys to features 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'raw' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 items to handlers 'image' slim tfexample decoder Image 'image encoded' 'label' slim tfexample decoder Tensor 'image class label' decoder slim tfexample decoder TFExampleDecoder keys to features items to handlers I get the following error INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP Node case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert Assert T DT STRING summarize 3 device job localhost replica 0 task 0 cpu 0 case If 0 decode image cond jpeg cond png cond gif is bmp case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert data 0 INFO tensorflow Caught OutOfRangeError Stopping Training INFO sensorflow Finished training Saving model to disk To use Densenet for my problem I should fix this error first Could anybody please help me out of this problem This code works perfectly for the datasets like flowers MNIST and CIFAR10 available at url but does not work for my data,,,2017-10-11 10:52:06,2017-10-11 10:57:21
IS,ImportError DLL load failed The specified module could not be found While attempting to import TensorFlow,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"Carmezim,mrry,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,mrry",2017-09-27 19:51:26,2017-10-11 14:08:51
PR,add the missing closing parenthesis to code snippet,,,,2017-10-11 13:37:18,2017-10-11 14:30:24
IS,speech demo is not working on duration different from 1000ms,hi when i try to use a different data set different duration on the speech recognition demo the training works well but the freeze part crash with the message Assign requires shapes of both tensors to match tried almost everything delete the temp directory pass the same param from train to freeze make sure that all wav file are with the same size used the nightly docker used the latest python nothing worked my guess is that the problem is in the loading part any idea what next,,,2017-10-11 09:28:50,2017-10-11 14:37:21
IS,w9wang2,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-11 14:15:41,2017-10-11 15:13:20
PR,Add ReceptiveField class and coordinate conversion methods,This PR adds a ReceptiveField class which supports coordinate conversion from the input to the feature space and vice versa while maintaining backwards compatibility,,"tillahoffmann,tillahoffmann,tillahoffmann,sb2nov,martinwicke,tillahoffmann,martinwicke,tillahoffmann,martinwicke",2017-09-22 17:52:34,2017-10-11 15:56:19
PR,Merge pull request 1 from tensorflow master,pull,,,2017-10-11 15:55:44,2017-10-11 15:56:19
IS,Ca not run new ops in new session after sess run RuntimeError,Scenario 1 runtime error during session run 2 create new session 3 new session fails to evaluate any tensor giving same runtime error as in step 1 The following example fails to evaluate tf constant with error tensorflow python framework errors impl InvalidArgumentError Cannot assign a device for operation 'Diag Using 12 day old version from this commit,,"yaroslavvb,facaiy,facaiy,tatatodd,asimshankar,skye",2017-10-04 17:29:12,2017-10-11 16:52:37
PR,Update installation instructions for conda install to include pip,This branch updates the installation instructions for conda install to include pip as well in order to prevent the usage of the pip installed in the root conda environment,,,2017-10-07 16:43:57,2017-10-11 17:03:48
PR,Branch 171836140,,,"caisq,caisq",2017-10-11 17:15:59,2017-10-11 18:57:10
IS,Something wrong while using C Session Run api,I use tensorflow C api to run my model I flower this reference label image In my model the outputs' shape is 2d I run model like this std vector Tensor outputs status session Run m feed dict model wav outputs outputs However I get this tensorflow core framework tensor shape cc 44 Check failed NDIMS dims 1 vs 2 Asking for tensor of 1 dimensions from a tensor of 2 dimensions Could anybody tell me how to fix this,,reedwm,2017-10-11 09:29:46,2017-10-11 19:39:51
IS,Why the parameters are not stored on ps server for distributed tensorflow,Please see more detail on stackoverflow I do not start ps server and parameters are stored on worker server,,reedwm,2017-10-11 08:00:14,2017-10-11 19:41:31
IS,None value for gradient of Tensorflow variables which is used in the network,I want to develop a custom Seq2Seq in tensorflow and I have created this part of network wflat0 tf get variable wflat0 shape 1024 1024 initializer LinearInitializer bflat0 tf get variable bflat0 shape 1024 initializer BiasInitializer l0flat selu tf matmul x wflat0 bflat0 x tf reshape l0flat shape 0 shape 1 1024 x tf unstack x constant Lstm cell 1 lstm cell tf contrib rnn LayerNormBasicLSTMCell LSTMHiddenSize forget bias 1 0 dropout keep prob 0 9 outputs states tf contrib rnn static rnn lstm cell x dtype tf float32 decoder tf contrib rnn LayerNormBasicLSTMCell LSTMHiddenSize forget bias 1 0 dropout keep prob 0 9 y tf unstack tf reshape self y tf shape self y 0 tf shape self y 1 1 constant Lstm cell 1 decoutputs decstates tf contrib rnn static rnn decoder y dtype tf float32 wflat1 tf get variable wflat1 shape LSTMHiddenSize 128 initializer LinearInitializer bflat1 tf get variable bflat1 shape 128 initializer BiasInitializer shapes tf shape decoutputs decoutputs tf transpose decoutputs perm 1 0 2 decoutputs tf reshape decoutputs shapes 0 shapes 1 shapes 2 self sss decoutputs l1flat selu tf matmul decoutputs wflat1 bflat1 wflat2 tf get variable wflat2 shape 128 1 initializer LinearInitializer bflat2 tf get variable bflat2 shape 1 initializer BiasInitializer l2flat tf matmul l1flat wflat2 bflat2 l2flat tf reshape l2flat constant batchsize constant Lstm cell self sigout tf nn softmax l2flat self out l2flat cost tf reduce sum tf nn softmax cross entropy with logits logits self out labels self y and this network create NAN output after first update iteration for large sequence and it just works for small sequence so I have decided to add gradient clipping and when I was developing that I have found that most of the variables have a none gradient as you can see in this picture Imag e of computed Gradient how could it possible that some variables which take participate in loss function have a none gradient is this a bug,,reedwm,2017-10-11 04:45:03,2017-10-11 19:42:20
IS,The value of a feed cannot be a tf Tensor object Acceptable feed values include Python scalars str,When i feed the value unfortunately it is a tensor i have already known that i should convert it to a array or other types to feed But if i use sess run or eval The speed makes me crazy for the shape is 3600 14 25500 if other ways are available,,reedwm,2017-10-11 02:40:40,2017-10-11 19:45:13
IS,build android,ERROR home wangmeng RSTensorFlow mobile tensorflow examples android BUILD 67 1 Building tensorflow examples android libtensorflow demo jar 23 source files failed Worker process sent response with exit code 1 tensorflow examples android src org tensorflow demo StylizeActivity java 365 error constructor TensorFlowInferenceInterface in class TensorFlowInferenceInterface cannot be applied to given types inferenceInterface new TensorFlowInferenceInterface getAssets MODEL FILE required no arguments found AssetManager String reason actual and formal argument lists differ in length tensorflow examples android src org tensorflow demo StylizeActivity java 544 error cannot find symbol inferenceInterface feed symbol method feed String float int int int int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo StylizeActivity java 546 error cannot find symbol inferenceInterface feed STYLE NODE styleVals NUM STYLES symbol method feed String float int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo StylizeActivity java 548 error cannot find symbol inferenceInterface run new String OUTPUT NODE isDebug symbol method run String boolean location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo StylizeActivity java 549 error cannot find symbol inferenceInterface fetch OUTPUT NODE floatValues symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowImageClassifier java 90 error constructor TensorFlowInferenceInterface in class TensorFlowInferenceInterface cannot be applied to given types c inferenceInterface new TensorFlowInferenceInterface assetManager modelFilename required no arguments found AssetManager String reason actual and formal argument lists differ in length tensorflow examples android src org tensorflow demo TensorFlowImageClassifier java 93 error cannot find symbol final Operation operation c inferenceInterface graphOperation outputName symbol method graphOperation String location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowImageClassifier java 132 error cannot find symbol inferenceInterface feed inputName floatValues 1 inputSize inputSize 3 symbol method feed String float int int int int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowImageClassifier java 137 error cannot find symbol inferenceInterface run outputNames logStats symbol method run String boolean location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowImageClassifier java 142 error cannot find symbol inferenceInterface fetch outputName outputs symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowMultiBoxDetector java 90 error constructor TensorFlowInferenceInterface in class TensorFlowInferenceInterface cannot be applied to given types d inferenceInterface new TensorFlowInferenceInterface assetManager modelFilename required no arguments found AssetManager String reason actual and formal argument lists differ in length tensorflow examples android src org tensorflow demo TensorFlowMultiBoxDetector java 221 error cannot find symbol inferenceInterface feed inputName floatValues 1 inputSize inputSize 3 symbol method feed String float int int int int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowMultiBoxDetector java 226 error cannot find symbol inferenceInterface run outputNames logStats symbol method run String boolean location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowMultiBoxDetector java 233 error cannot find symbol inferenceInterface fetch outputNames 0 outputLocationsEncoding symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowMultiBoxDetector java 234 error cannot find symbol inferenceInterface fetch outputNames 1 outputScoresEncoding symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 68 error constructor TensorFlowInferenceInterface in class TensorFlowInferenceInterface cannot be applied to given types d inferenceInterface new TensorFlowInferenceInterface assetManager modelFilename required no arguments found AssetManager String reason actual and formal argument lists differ in length tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 98 error cannot find symbol inferenceInterface feed inputName bytePixels 1 inputSize inputSize 3 symbol method feed String byte int int int int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 105 error cannot find symbol inferenceInterface run outputNames logStats symbol method run String boolean location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 114 error cannot find symbol inferenceInterface fetch outputNames 3 numDetectionsArray symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 119 error cannot find symbol inferenceInterface fetch outputNames 0 boxes symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 120 error cannot find symbol inferenceInterface fetch outputNames 1 scores symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowSingleShotDetector java 121 error cannot find symbol inferenceInterface fetch outputNames 2 classes symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowYoloDetector java 107 error constructor TensorFlowInferenceInterface in class TensorFlowInferenceInterface cannot be applied to given types d inferenceInterface new TensorFlowInferenceInterface assetManager modelFilename required no arguments found AssetManager String reason actual and formal argument lists differ in length tensorflow examples android src org tensorflow demo TensorFlowYoloDetector java 154 error cannot find symbol inferenceInterface feed inputName floatValues 1 inputSize inputSize 3 symbol method feed String float int int int int location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowYoloDetector java 161 error cannot find symbol inferenceInterface run outputNames logStats symbol method run String boolean location variable inferenceInterface of type TensorFlowInferenceInterface tensorflow examples android src org tensorflow demo TensorFlowYoloDetector java 172 error cannot find symbol inferenceInterface fetch outputNames 0 output symbol method fetch String float location variable inferenceInterface of type TensorFlowInferenceInterface Target tensorflow examples android tensorflow demo failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 19 243s Critical Path 7 19s FAILED Build did NOT complete successfully,,"andrewharp,reedwm,gunan,gunan,andrewharp,andrewharp",2017-08-10 07:55:38,2017-10-11 22:23:22
IS,Error while building android project from tensorflow examples,Error Users sagarsuri tensorflow tensorflow core BUILD 194 1 Failed to get cached inputs Could not determine containing package for external protobuf src google protobuf stubs common h I am getting the above error while building Android project which is provided in the examples folder I executed this command to pull tensorflow project to my mac git clone depth 1,,"andrewharp,andrewharp,andrewharp,andrewharp,andrewharp",2017-07-30 12:45:14,2017-10-11 22:24:59
PR,Fixes and additions to release notes,Added line about Keras moving into core Added line about CUDA cuDNN versions Added line about custom ops,,case540,2017-10-11 22:35:00,2017-10-11 22:52:02
IS,Error in creating the final binary using AOT compilation for CPU backend,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 rc1 2665 g242b0f1 Python version Python3 Bazel version if compiling from source 0 6 0 CUDA cuDNN version No GPU model and memory No Exact command to reproduce bazel build tensorflow compiler aot tests my binary Describe the problem I simply followed the tutorial here According to Step 1 and 2 I compiled the subgraph and generated the header test graph tfmatmul h and object test graph tfmatmul o files using tfcompile According to Step 3 I used the example code named as my code cc to invoke the subgraph According to Step 4 I added the code snippet cc binary to the existing BUILD file tensorflow compiler aot tests BUILD and tried to create the final binary with the command bazel build tensorflow compiler aot tests my binary but I got the following error undeclared inclusion s in rule ' tensorflow compiler aot tests my binary' this rule is missing dependency declarations for the following files included by 'tensorflow compiler aot tests my code cc' ' home tensorFlow src tensorflow tensorflow compiler aot tests test graph tfmatmul h' Source code logs my code cc exactly the same as in the tutorial,,"asimshankar,tatatodd,tatatodd,tatatodd,tatatodd",2017-10-04 03:57:43,2017-10-12 00:06:55
IS,Tensorflow binary seems compiled to use SIMD instructions like AVX2 and FMA but actually not,I found similar issues mentioned as 8037 7778 etc but the issue seems not solved the warnings did disappear after building with the necessary optimization options but they appeared again when I followed this tutorial to the last step So is the tensorflow binary compiled to use the SIMD instructions or not System information Have I written custom code No OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version v1 3 0 rc1 3000 g840dcae Python version Python3 Bazel version 0 6 0 CPU Intel Core i7 4770 Haswell architecture supporting AVX2 and FMA GPU No Compiler gcc 5 4 0 Issue reproducing 1 Building tensorflow from source Configure only jemalloc and XLA JIT support are ticked The default optimization flag is march native therefore was not specified Build pip package Finally it will print INFO From Executing genrule tensorflow compiler aot tests gen test graph tfmatmul 2017 10 05 15 15 29 233159 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA An error will also occur but that is another issue 13482 So is the tensorflow binary compiled to use the SIMD instructions SSE4 1 SSE4 2 AVX AVX2 FMA or not May I have your advice,,"tatatodd,tatatodd,tatatodd,carlthome,carlthome",2017-10-05 06:00:22,2017-10-12 00:27:03
IS,Extracting weight values from output graph pb,Hi this is not a bug more of request for a tutorial or guidance I have asked this question multiple times on Stackoverflow and can not seem to get any responses nor views My past questions on tensorflow also did not get much views on Stackoverflow I think this is because tensorflow is still relatively new and it is hard to find knowledgeable people I'm sorry to post here but I do not know where else to ask I have been at it for a few days and looked the tutorials on the official site but I could not find any I used inceptionV 3 for transfer learning and now I have a output graph pb I want to extract all the weights and biases for each layer but I can not seem to find a way to do this I have gone over most the tutorials in tensorflow models And most blogs or stackoverflows posts show how to deal with 'meta and ckpt graphs but not on pb graphs I have attempted this I have cloned the repository properly and the saved model utils is within the tools folder so not sure why I m getting an import error Any help would be appreciated and once again sorry for posting here,,mrry,2017-10-12 00:13:18,2017-10-12 00:56:00
IS,TFRecord parse multiple times using parse example,In order to parse a sequence of example I am using the following code in tensorflow sequence len 10 filename queue tf train string input producer 'foo tfrecords' reader tf TFRecordReader seralized example reader read up to filename queue sequence len features tf parse example seralized example features 'feature raw' tf VarLenFeature dtype tf float32 feature features 'feature raw' values This will give me a sequence of 10 examples But I want to read the first 10 example sequence in on gpu the next one in the next gpu and so on However when I do that using tf device as follows I get the same data in all the gpus sequence len 10 data filename queue tf train string input producer 'foo tfrecords' reader tf TFRecordReader for g in range num gpus with tf device ' gpu d' g seralized example reader read up to filename queue sequence len features tf parse example seralized example features 'feature raw' tf VarLenFeature dtype tf float32 feature features 'feature raw' values data append feature How to deal with this,,jart,2017-07-08 07:46:25,2017-10-12 00:57:41
IS,INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP Node case If 0 decode image cond jpeg cond png cond gif,Hi all I use Python 2 7 13 and Tensorflow 1 3 0 on CPU I want to use DensNet url for regression problem My data contains 60000 jpeg images with 37 float labels for each image I saved my data into tfrecords files by def Read Labels label path labels csv pd read csv label path labels np array labels csv return labels 1 def load image addr read an image and resize to 224 224 img cv2 imread addr img cv2 resize img 224 224 interpolation cv2 INTER CUBIC img cv2 cvtColor img cv2 COLOR BGR2RGB img img astype np float32 return img def Shuffle images with labels shuffle data photo filenames labels if shuffle data c list zip photo filenames labels shuffle c addrs labels zip c return addrs labels def image to tfexample mine image data image format height width label return tf train Example features tf train Features feature 'image encoded' bytes feature image data 'image format' bytes feature image format 'image class label' float feature label 'image height' int64 feature height 'image width' int64 feature width def convert dataset split name filenames labels dataset dir assert split name in 'train' 'validation' num per shard int math ceil len filenames float NUM SHARDS with tf Graph as default for shard id in range NUM SHARDS output filename get dataset filename dataset path split name shard id with tf python io TFRecordWriter output filename as tfrecord writer start ndx shard id num per shard end ndx min shard id 1 num per shard len filenames for i in range start ndx end ndx sys stdout write ' r Converting image d d shard d' i 1 len filenames shard id sys stdout flush img load image filenames i image data tf compat as bytes img tostring label labels i example image to tfexample mine image data image format height width label Serialize to string and write on the file tfrecord writer write example SerializeToString sys stdout write ' n' sys stdout flush def run dataset dir labels Read Labels dataset dir ' training labels csv' photo filenames get filenames and classes dataset dir ' images training' shuffle data True photo filenames labels Shuffle images with labels shuffle data photo filenames labels training filenames photo filenames NUM VALIDATION training labels labels NUM VALIDATION validation filenames photo filenames NUM VALIDATION validation labels labels NUM VALIDATION convert dataset 'train' training filenames training labels dataset path convert dataset 'validation' validation filenames validation labels dataset path print ' nFinished converting the Flowers dataset ' And I decode it by with tf Session as sess feature 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'jpeg' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 filename queue tf train string input producer data path num epochs 1 reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example features feature image tf decode raw features 'image encoded' tf float32 print image get shape label tf cast features 'image class label' tf float32 image tf reshape image 224 224 3 images labels tf train shuffle batch image label batch size 10 capacity 30 num threads 1 min after dequeue 10 init op tf group tf global variables initializer tf local variables initializer sess run init op coord tf train Coordinator threads tf train start queue runners coord coord for batch index in range 6 img lbl sess run images labels img img astype np uint8 print img shape for j in range 6 plt subplot 2 3 j 1 plt imshow img j plt show coord request stop coord join threads It is all fine up to this point But when I use the bellow commands for decoding TFRecord files reader tf TFRecordReader keys to features 'image encoded' tf FixedLenFeature tf string default value '' 'image format' tf FixedLenFeature tf string default value 'raw' 'image class label' tf FixedLenFeature 37 tf float32 default value tf zeros 37 dtype tf float32 items to handlers 'image' slim tfexample decoder Image 'image encoded' 'label' slim tfexample decoder Tensor 'image class label' decoder slim tfexample decoder TFExampleDecoder keys to features items to handlers I get the following error INFO tensorflow Error reported to Coordinator class 'tensorflow python framework errors impl InvalidArgumentError' assertion failed Unable to decode bytes as JPEG PNG GIF or BMP Node case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert Assert T DT STRING summarize 3 device job localhost replica 0 task 0 cpu 0 case If 0 decode image cond jpeg cond png cond gif is bmp case If 0 decode image cond jpeg cond png cond gif Assert 1 Assert data 0 INFO tensorflow Caught OutOfRangeError Stopping Training INFO sensorflow Finished training Saving model to disk To use Densenet for my problem I should fix this error first Could anybody please help me out of this problem This code works perfectly for the datasets like flowers MNIST and CIFAR10 available at url but does not work for my data,,tatatodd,2017-10-11 10:49:45,2017-10-12 00:58:18
IS,Failed build tensorflow with bazel failed with error SQLite will not work correctly with the ffast math option of GCC,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 04 TensorFlow installed from source or binary TensorFlow version use command below commit 1ad5e692e2fc218ca0b2a9a461c19762fdc9674b master branch Python version Python 2 7 13 Bazel version if compiling from source 0 6 1 CUDA cuDNN version GPU model and memory Exact command to reproduce build tensorflow bazel build config mkl copt g copt DEIGEN USE VML copt mavx2 copt mfma copt O3 verbose failures copt Ofast copt L opt intel gcc lib64 s c opt tensorflow tools pip package build pip package You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request During the build process it failed with the message ERROR root cache bazel bazel root 33016bcb7111d180c7dd9b171742c7e7 external sqlite archive BUILD bazel 9 1 C compilation of rule ' sqlite archive sqlite' failed Exit 1 gcc failed error executing command cd root cache bazel bazel root 33016bcb7111d180c7dd9b171742c7e7 execroot org tensorflow exec env PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF NEED CUDA 0 TF NEED OPENCL 0 usr bin gcc U FORTIFY SOURCE fstack protector Wall B usr bin B usr bin Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections DEIGEN USE VML g DEIGEN USE VML mavx2 mfma O3 Ofast L opt intel gcc lib64 MD MF bazel out local opt bin external sqlite archive objs sqlite external sqlite archive sqlite3 pic d fPIC iquote external sqlite archive iquote bazel out local opt genfiles external sqlite archive iquote external bazel tools iquote bazel out local opt genfiles external bazel tools isystem external sqlite archive isystem bazel out local opt genfiles external sqlite archive isystem external bazel tools tools cpp gcc3 fno canonical system headers Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c external sqlite archive sqlite3 c o bazel out local opt bin external sqlite archive objs sqlite external sqlite archive sqlite3 pic o external sqlite archive sqlite3 c In function isqlite3IsNaN' external sqlite archive sqlite3 c 28276 3 error error SQLite will not work correctly with the ffast math option of GCC error SQLite will not work correctly with the ffast math option of GCC Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 75 602s Critical Path 59 11s FAILED Build did NOT complete successfully Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatatodd,2017-10-11 13:57:27,2017-10-12 01:19:43
IS,get shape does not work for output of tf image resize nearest neighbor,Hello everyone Following the issue 7932 I have also noticed that get shape does not work when using tf image resize nearest neighbor I use linux 16 06 and TF in 1 3 0 1 3 1 1 4 0 dev20171008 and I have the same error The error is quite easy to understand The fact that tf image resize nearest neighbor is unable to compute correctly get shape leads to some problematic behavior For information it is absolutely to launch the session with the FC layer in the script it completely fails,,tatatodd,2017-10-11 15:15:17,2017-10-12 01:51:17
IS,bug tf nn embedding lookup returns 0 when ids out of range,It seems tf nn embedding lookup will simply return tensor of zeros when ids out of range larger than the embedding table size The emb will be tensor of zeros I am not sure if this is a bug or by design for efficiency concern It would be nice if there is a runtime exception That will do a big favor in avoiding hidden bugs that lead to performance degeneration I am running tensorflow gpu 1 3 0 in Ubuntu 16 04,,tatatodd,2017-10-11 18:10:52,2017-10-12 01:55:42
IS,error in docs,The docs here for bounding boxes have an error The paragraph reading For example if an image is 100 x 200 pixels and the bounding box is 0 1 0 2 0 5 0 9 the bottom left and upper right coordinates of the bounding box will be 10 40 to 50 180 would better go something like For example if an image is 100 x 200 pixels and the bounding box is 0 1 0 2 0 5 0 9 the upper left and bottom right coordinates of the bounding box will be 10 40 to 50 180 using a somewhat idiosyncratic y x notation or 40 10 to 180 50 using the rather more common x y notation for points in a plane All this is with 'usual' coordinate axes origin in the top left corner increasing x to right and increasing y going down,,aselle,2017-07-29 08:44:32,2017-10-12 04:41:22
IS,What is the difference between function eval and sess run,Codes are as follows When I use aresult self test prediction eval feed dict self tf test samples samples ' it works fine while in aresult sess run self test prediction feed dict self tf test samples samples ' it shows error 'ValueError operands could not be broadcast together with shapes 10 10 9 9 ' SO what is difference between function eval and sess run,,mrry,2017-10-12 02:08:59,2017-10-12 13:05:36
IS,tensorflow 1 3 0 build with bazel failed on redhat7 4BU1,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 redhat 7 4BU1 TensorFlow installed from source or binary TensorFlow version use command below 1 3 0 Python version Python 2 7 5 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request build tensorflow with bazel failed bazel build config mkl copt g copt DEIGEN USE VML copt mavx2 copt mfma copt O3 verbose failures copt Ofast copt L opt intel gcc lib64 s c opt tensorflow tools pip package build pip package failed message WARNING ignoring http proxy in environment ERROR root cache bazel bazel root 6093305914d4a581ed00c0f6c06f975b external io bazel rules closure closure private defs bzl 27 16 The set constructor for depsets is deprecated and will be removed Please use the depset constructor instead You can temporarily enable the deprecated set constructor by passing the flag incompatible disallow set constructor false ERROR error loading package '' Extension file 'closure private defs bzl' has errors what is more see the bazel info root unassigned hostname tensorflow 1 3 0 bazel info WARNING ignoring http proxy in environment Extracting Bazel installation ERROR root cache bazel bazel root 6093305914d4a581ed00c0f6c06f975b external io bazel rules closure closure private defs bzl 27 16 The set constructor for depsets is deprecated and will be removed Please use the depset constructor instead You can temporarily enable the deprecated set constructor by passing the flag incompatible disallow set constructor false ERROR error loading package '' Extension file 'closure private defs bzl' has errors how did I install bazel on redhat add the bazel repo then yum install bazel Is something wrong with the bazel Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-12 09:27:14,2017-10-12 13:11:56
IS,tf string input producer does not work with tf placeholder,In a scenario it is intended to dynamically change the file names of tensorflow record files as indicated by the following code OS version Redhat 7 3 Python version 2 7 5 Tensorflow version 1 3 file0 csv and file1 csv are quite simple csv files just with two lines 0 1 0 0 9 1,,"tatatodd,mrry",2017-10-12 00:18:34,2017-10-12 14:15:30
PR,Docker MAINTAINER instruction is deprecated,maintainer deprecated We should use LABEL maintainer instead,,,2017-10-12 13:08:20,2017-10-12 15:17:48
PR,R1 3,,,,2017-10-12 09:01:58,2017-10-12 16:21:39
PR,Add missing default config setting in aws BUILD,Fix,,"meteorcloudy,meteorcloudy,gunan,meteorcloudy",2017-10-12 13:14:32,2017-10-12 16:23:44
IS,AttributeError 'GFile' object has no attribute 'writelines,Hi when i try to execute this code from tensorflow python platform import gfile with gfile GFile s s target path len d len q mode w as tokens file tokens file writelines results I obtain the following error AttributeError 'GFile' object has no attribute 'writelines' Why GFile have not writelines attribute in verision 1 2 What method should i use instead Thanks a lot,,"reedwm,reedwm,vrv,vrv",2017-10-12 08:43:52,2017-10-12 17:12:59
PR,configure py Disable AWS support on Windows by default,This is a follow up to,,meteorcloudy,2017-10-12 16:35:43,2017-10-12 17:47:51
IS,Fail to build android example,Hi I have the same problem System information bazel version Build label 0 5 4 homebrew java version 1 8 0 144 android sdk platforms android 26 android sdk system images android 26 android ndk r14b workspace config android sdk repository name androidsdk api level 26 build tools version 26 0 1 path Users akrasnoperov Library Android sdk android ndk repository name androidndk path Users akrasnoperov Library Android android ndk r14b api level 14 Describe the problem Error when I run bazel build c opt tensorflow examples android tensorflow demo Source code logs bazel build c opt tensorflow examples android tensorflow demo ERROR private var tmp bazel akrasnoperov 8a0891b65f3fddb9d9a6d9e66927aea5 external androidsdk BUILD bazel 64 1 Traceback most recent call last File private var tmp bazel akrasnoperov 8a0891b65f3fddb9d9a6d9e66927aea5 external androidsdk BUILD bazel line 64 create system images filegroups system image dirs system ima File private var tmp bazel akrasnoperov 8a0891b65f3fddb9d9a6d9e66927aea5 external bazel tools tools android android sdk repository template bzl line 298 in create system images filegroups int apidir split 1 invalid literal for int with base 10 MNC ERROR private var tmp bazel akrasnoperov 8a0891b65f3fddb9d9a6d9e66927aea5 external androidsdk BUILD bazel 8 1 Target ' androidsdk build tools 26 0 1 lib dx jar' contains an error and its package is in error and referenced by ' androidsdk dx jar' ERROR private var tmp bazel akrasnoperov 8a0891b65f3fddb9d9a6d9e66927aea5 external androidsdk BUILD bazel 8 1 Target ' androidsdk dx jar' contains an error and its package is in error and referenced by ' androidsdk dx jar import' ERROR Users akrasnoperov Developer Repo tensorflow WORKSPACE 20 1 Target ' androidsdk dx jar import' contains an error and its package is in error and referenced by ' external android dx jar import' ERROR Analysis of target ' tensorflow examples android tensorflow demo' failed build aborted INFO Elapsed time 0 463s,,andrewharp,2017-09-19 20:26:34,2017-10-12 18:24:36
PR,Fix for a regression in graph rewrite pass MKL,Changed CPU device string from cpu to CPU to re enable MKL graph rewrite pass that was disabled by a prior commit,,"agramesh1,mahmoud-abuzaina,rmlarsen,rmlarsen,caisq,rmlarsen,caisq,gunan,mahmoud-abuzaina,rmlarsen,rmlarsen,gunan,rmlarsen,rmlarsen,av8ramit",2017-10-08 05:31:32,2017-10-12 19:07:35
IS,StochasticTensor strange behavior,I have noticed strange behavior of StochasticTensor Please look at this peace of code inputs tf placeholder shape 1 10 name inputs dtype tf float32 outputs tf layers dense inputs units 10 use bias False activation tf nn sigmoid outputs st StochasticTensor distributions Bernoulli probs outputs dtype tf int32 outputs tf reshape outputs shape 1 init op tf group tf global variables initializer tf local variables initializer with tf Session as sess sess run init op x np random rand 1 10 tf set random seed 2017 z1 sess run outputs feed dict inputs x tf set random seed 2017 z2 sess run outputs feed dict inputs x print z1 print z2 As the result I get 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 But numpy sampling has another behavior np random seed 2017 x np random randint 0 10 size 10 np random seed 2017 y np random randint 0 10 size 10 print x print y And again the result 9 6 8 2 3 7 8 0 8 6 9 6 8 2 3 7 8 0 8 6 Is it an issue P S Tensorflow v1 3 0 rc2 20 g0787eee,,"yaroslavvb,yaroslavvb,ebrevdo,yaroslavvb,ebrevdo,reedwm",2017-10-03 20:15:02,2017-10-12 21:56:46
PR,Configurable upper bound for MKL CPU allocator,Multiple ways to configure upper bound on the MKL cpu allocator Default is 64 GB Overridden by DRAM capacity if available Overridden by user configured limit if set through an environment variable,,"jbobba,rmlarsen,rmlarsen,rmlarsen,rmlarsen,jbobba,rmlarsen,gunan,jbobba,rmlarsen,rmlarsen,rmlarsen,rmlarsen,gunan,rmlarsen,jbobba,gunan,jbobba,gunan,jbobba,rmlarsen",2017-10-10 19:35:33,2017-10-12 23:01:32
PR,Add a new MKL build script for linux,,,gunan,2017-10-12 22:48:39,2017-10-12 23:28:50
PR,Enable vectorization on z13,Enable vectorization on z13 to improve performance,,"namrata-ibm,caisq",2017-10-12 09:30:06,2017-10-13 00:59:48
PR,Fix cuDNN version string in CUDA9 cuDNN7 docker image,,,gunan,2017-10-12 23:45:02,2017-10-13 02:03:17
PR,Configurable upper bound for MKL allocator,Multiple ways to configure upper bound on the MKL cpu allocator Default is 64 GB Overridden by DRAM capacity if available Overridden by user configured limit if set through an environment variable New PR to get around CLA issues with previous PR,,"jbobba,gunan,caisq",2017-10-12 22:52:47,2017-10-13 02:03:41
PR,add code sample on inspect checkpoint variables,Tested in Jupyter Notebook,,,2017-10-12 09:46:01,2017-10-13 03:37:55
IS,No OpKernel was registered to support Op 'Assign' running nightlypi stable build on raspberry pi 3,I am running the tensorflow backend to keras on a raspberry pi 3 with the lastest Stretch The tensorflow 1 3 build is When running the Adam optimizer I'm seeing the following error tensorflow python framework errors impl InvalidArgumentError No OpKernel was registered to support Op 'Assign' with these attrs Registered devices CPU Registered kernels device 'CPU' T in DT FLOAT device 'CPU' T in DT INT32 Node Adam 2 iterations Assign Assign T DT INT64 class loc Adam 2 iterations use locking true validate shape true Adam 2 iterations Adam 2 iterations initial value What can I do to solve this,,tatatodd,2017-10-12 05:29:52,2017-10-13 04:33:24
IS,ValueError Cannot feed value of shape 128 for Tensor 'Placeholder 142 0' which has shape ' 3433,Hello after several unsuccesfull tries I would like to ask your help in solving this error I am trying to train a deep autoencoder network by using a local csv file that is then transformed by the csv and the numpy libraries into a numpy array But this data is never feeding into my placeholder is tensor Here is an abstract of the deep autoencoder class Deep Autoencoder def init self input dim n nodes hl 32 16 1 epochs 400 batch size 128 learning rate 0 02 n examples 10 Hyperparameters self input dim input dim self epochs epochs self batch size batch size self learning rate learning rate self n examples n examples Input and target placeholders X tf placeholder 'float' None self input dim Y tf placeholder 'float' None self input dim self X X print self X self X self Y Y print self Y self Y def train neural network self data targets with tf Session as sess sess run tf global variables initializer for epoch in range self epochs epoch loss 0 i 0 Let is train it in batch mode while i len data start i end i self batch size batch x np array data start end print type batch x type batch x print len batch x len batch x batch y np array targets start end print type batch y type batch y print len batch y len batch y hidden c sess run self encoded self optimizer self cost feed dict self X batch x self Y batch y epoch loss c i self batch size self saver save sess iselfautoencoder ckpt' print 'Accuracy' self accuracy eval self X data self Y targets Here I create the input data and below you can see that I will printout their main features for your info note that I am actually interested on column 3 only features DeepAE create feature sets filename Train x np array features DeepAE 0 Train y np array features DeepAE 1 print type Train x type Train x print type Train x T 3 type Train x T 3 print len Train x len Train x print len Train x T 3 len Train x T 3 print shape Train x Train x shape print type Train y type Train y print type Train y T 3 type Train y T 3 print len Train y len Train y print len Train y T 3 len Train y T 3 print shape Train y Train y shape And here I run the code DAE Deep Autoencoder input dim len Train x DAE train neural network Train x T 3 Train y T 3 These are the printouts fyi type Train x class 'numpy ndarray' type Train x T 3 class 'numpy ndarray' len Train x 3433 len Train x T 3 3433 shape Train x 3433 5 type Train y class 'numpy ndarray' type Train y T 3 class 'numpy ndarray' len Train y 3433 len Train y T 3 3433 shape Train y 3433 5 self X Tensor Placeholder 142 0 shape 3433 dtype float32 self Y Tensor Placeholder 143 0 shape 3433 dtype float32 type batch x class 'numpy ndarray' len batch x 128 type batch y class 'numpy ndarray' len batch y 128 And finally the error ValueError Cannot feed value of shape 128 for Tensor 'Placeholder 142 0' which has shape ' 3433 ' and yes I'm at placeholder 143 that meas a lot of failures reshaping the batch and or the tensor transposing one and or the other looking for workarounds on internet Do not hesitate to ask for more info if needed,,tatatodd,2017-10-12 17:03:19,2017-10-13 04:43:42
PR,Branch 172057283,,,"gunan,gunan",2017-10-13 06:27:51,2017-10-13 07:09:12
PR,Branch 172045110,,,"caisq,caisq",2017-10-13 03:07:15,2017-10-13 11:42:42
IS,TensorArray grad bug,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 6 1 Describe the problem tf TensorArray in some cases does not correctly passes the gradient See the test case Source code logs This fails Strangely if you add something like y y 1 before taking the gradient it passes,,"alextp,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-09-28 07:49:12,2017-10-13 11:43:13
PR,Fix documentation error in tf reverse docstring 1,The first example in the tf reverse docstring causes a ValueError as shown below tf reverse requires axis to be 1D 1 is not 1D it is 0D it should be 1,,"frankchn,frankchn",2017-10-05 01:52:58,2017-10-13 13:31:47
PR,Merge pull request 1 from tensorflow master,Updated on 2017 10 13,,,2017-10-13 06:08:26,2017-10-13 14:27:13
IS,tf train import meta graph works strangely compared to restored session with tf train Supervisor,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 1 0 13 g8ddd727 1 1 0 Python version Python 3 4 3 CUDA cuDNN version CUDA GPU model and memory GeForce GTX TITAN X major 5 minor 2 memoryClockRate GHz 1 076 pciBusID 0000 02 00 0 Total memory 11 92GiB Describe the problem Working on GANs in tensorflow I would like to load a generator from a different saved session and graph in order to do some new ops on this part of the graph that has been trained I use tf train import meta graph but it works strangely compared to restored session with tf train Supervisor It seems like the tf train Supervisor reassigns the tensors in a better way I would have guessed that the generator would have been successfully loaded or not but not in such a strange way I do not know if it is a bug Source code logs When I use tf train import meta graph I had this on tensorboard yo2 It seems like the tf train Supervisor reassigns the tensors in a better way I would have guessed that the generator would have been successfully loaded or not but not in such a strange way The problem is that I can not use the second method if I want to do some new stuffs with the generator such as inverting it through another training but his time on z optim because it does not want to add new nodes to the graph when it has not found it in previous training checkpoint Btw I had to change z optim in tf random normal number ini z batch imgs number 100 mean 0 0 stddev 1 0 name 'random z' for that same reason Do you have an any idea of why such a thing occurs Or any other suggestion in loading the generator,,reedwm,2017-10-12 09:23:18,2017-10-13 14:57:00
PR,Fix deadlocks in Staging Areas,Previously notify one was used to notify inserters and removers waiting to insert and remove elements into the Staging Areas This could result in deadlock when many removers where waiting for different keys in the case of the MapStagingArea or were waiting on either peeks or get operations in the StagingArea For example if two removers were waiting for keys 2 and 3 in a MapStaging Area respectively and 2 was inserted but only 3 is remover was notified it is possible that 2 is remover would never be notified resulting in deadlock Thus both should be notified Similarly in the case of the StagingArea with a remover and a peeker wanting to remove the last element and peek at a specific element respectively it is not clear which one should be notified due to an insert Thus both should be notified Additionally all inserters are now notified when an element is removed Consider the case where two inserters are waiting to small elements into the Staging Area and a remover removes a single large element As there may be space for both insertion elements both inserters should be notified,,"sjperkins,sjperkins,caisq,caisq,caisq",2017-10-13 10:29:16,2017-10-13 16:40:11
PR,Always add bias term to the output of LayerNormBasicLSTMCell,These would solve the problem of referring untrained bias term during inference with self layer norm False Issue ref 13600,,ebrevdo,2017-10-13 14:58:16,2017-10-13 17:03:31
PR,XLA Reorder the parameters in a map inline operation according to the parameter number,The inliner not typically in use has a fault where it does not spot that the parameters within the mapped operation are not in the same order as the actual parameter numbers on the operands i e the mapped operation looks like Previously the operands were passed to the clone in the order that they were supplied to the binary op not the order as defined by the parameter numbers This fixes the issue which could be potentially be called b 35786417,,"DavidNorman,caisq,DavidNorman,DavidNorman,DavidNorman,caisq,caisq",2017-10-09 11:18:17,2017-10-13 17:08:06
PR,Improve shape inference for tf slice,This fix is an effort to address the issue raised by 4590 where improvement of shape inference for tf slice is needed When one of the size element is unknwon the output shape is completely unknwon with right rank Note this fix does not handle the case where one of the size element is 1 and one of the size element is unknown However it is an improvement nevertheless Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,caisq,caisq,yongtang,caisq",2017-10-08 03:32:52,2017-10-13 17:08:56
IS,MaxPoolingOp only supports NHWC ERROR in my benchmark we would use NCHW dataformat,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 rc0 Python version 2 7 13 Bazel version if compiling from source 0 6 1 CUDA cuDNN version GPU model and memory Exact command to reproduce numactl m 1 python tensorflow models image convnet benchmark alexnet benchmark alexnet MKL py batch size 256 num batches 100 forward backward only cpu knl 2 1 tee tensorflow alexnet mkl txt You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I have compiled tensorflow with bazel 0 6 1 and install it on my xeon phi TM platform Meanwhile I have got a benchmark related with alexnet When I run the benchmark I got the error 2017 10 12 09 38 14 503463 E tensorflow core common runtime executor cc 643 Executor failed to create kernel Invalid argument Default MaxPoolingOp only supports NHWC Node pool1 MaxPool T DT FLOAT data format NCHW ksize 1 1 3 3 padding VALID strides 1 1 2 2 device job localhost replica 0 task 0 device CPU 0 conv1 Also I find that in the benchmark it has take both NCHW and NHWC data format into consideration So the benchmark should support both data format I could not figure out why is this error relates with out compile process or might I need to add some other option into the compile process Here is my compile command bazel build config mkl copt g copt DEIGEN USE VML copt mavx2 copt mfma copt O3 verbose failures copt L opt intel gcc lib64 s c opt tensorflow tools pip package build pip package anyone could help Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"tatatodd,mahmoud-abuzaina,tatatodd,mahmoud-abuzaina",2017-10-12 14:07:22,2017-10-13 18:25:34
IS,hexagon graph execution has put checks for inputs to be of square dimensions why is it so,OS Ubuntu 16 04 64bits Android Version 7 1 Nougat NDK Version android ndk r12b HEXAGON SDK 3 1 nnlib source I want to test against input shape 1 640 480 3 Below check is returning with error as it is looking for square dimensions L136 CHECK fsize WIDTH 1 WIDTH 3 header size I am not sure whether I can comment that and I did following that I got this error L147 any plans for standard interface to change 1 input shape 2 model filename 3 Image filename thanks,,,2017-06-15 17:13:42,2017-10-13 19:24:08
PR,Branch 172118528,,,"gunan,gunan",2017-10-13 18:24:53,2017-10-13 19:29:24
PR,Branch 172118528,,,"gunan,gunan",2017-10-13 18:24:53,2017-10-13 19:29:24
PR,Cherry pick Fix for a regression in graph rewrite pass MKL into 1 4 branch,,,"case540,gunan",2017-10-12 21:21:24,2017-10-13 19:30:37
PR,Merge changes from 1 4 rc0 back into master,These contains mostly release note additions and some version string updates,,"case540,case540,av8ramit,jhseu,case540",2017-10-12 21:13:29,2017-10-13 19:33:40
IS,Problem with CuDNN RNNs on Windows,OS Windows10 Keras version master as of today 2 08 Tensorflow backend version master as of today 1 4rc0 GPU Geforce GTX 1080Ti 11GB Cuda version v8 0 cuDNN version cudnn 8 0 windows10 x64 v6 0 First opened as a Keras GitHub issue here includes full code and error output Francois Chollet suggested that this may be a Windows TF problem Hi I tried keras layers CuDNNLSTM after seeing fchollet is tweet the other day I have the latest Keras and Tensorflow but there is a tensorflow problem with the Op 'CudnnRNN' not being registered Have I missed something Thanks,,,2017-10-13 18:02:26,2017-10-14 00:18:03
PR,Add cudnn rnn ops to the Windows build,Fixes 13696,,"mrry,av8ramit,mrry,av8ramit,caisq",2017-10-13 20:59:42,2017-10-14 00:18:03
IS,TensorFlow 1 3 0 GPU for Windows does not work for 2 NVIDIA P4s,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 factory production machine TensorFlow installed from source or binary tensorflow gpu 1 3 0 cp35 cp35m win amd64 whl TensorFlow version use command below 1 3 0 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version Cuda release 8 0 V8 0 60 cuDNN 6 GPU model and memory 2 NVIDIA Tesla P4s same as specs Exact command to reproduce Describe the problem We are currently evaluating Tensorflow as a possible replacement for Caffe but we seem to have run into a problem with running multiple P4s on a production system Our production systems are offline so I had to install a Python wheel of the GPU version TF framework which works fine until I try to use 2 GPUs for training where I get the error message 2017 10 05 13 53 42 989423 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 1 and 0 P4s are installed and working correctly I do not understand why peer to peer GPU access is required for using GPUs We can run multiple GPUs on our Caffe implementation,,"mrry,mrry,mrry",2017-10-13 16:05:26,2017-10-14 00:27:36
PR,Reenable tests that use matrix set diag op,,,gunan,2017-10-14 04:38:00,2017-10-14 05:24:28
IS,cd,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-14 04:30:25,2017-10-14 16:30:02
PR,Fix typos in datasets guide,I think recommend recommended is definitely necessary are to is are apparently both technically accepted usages but is is far more common and I believe are will sound jarring here to most native English speakers,,mrry,2017-10-13 23:42:40,2017-10-14 18:19:53
PR,Update version strings for 1 4 0rc1,,,"case540,case540,caisq",2017-10-14 00:18:16,2017-10-14 19:33:08
IS,Import Error on Windows 10 No module named ' pywrap tensorflow internal',System information OS Windows 10 64 Tensorflow version 1 3 GPU version Python 3 5 4 CUDA 8 0 cudart64 80 dll CUDNN 6 0 cudnn64 6 dll GPU GeForce GTX 1070 Installation Process Issue I followed the guide provided on for the installation via Anaconda The installation seems to be successful but upon running the following command in the console import tensorflow as tf I am getting the following error BEGIN ERROR MESSAGE Traceback most recent call last File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in swig import helper return importlib import module mname File C Users Eric AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 24 in module pywrap tensorflow internal swig import helper File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 23 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Eric AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in swig import helper return importlib import module mname File C Users Eric AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 24 in module pywrap tensorflow internal swig import helper File C Users Eric AppData Local conda conda envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 23 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Eric AppData Local conda conda envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime END ERROR MESSAGE Attempted Fixes Ensuring that cudart64 80 dll and cudnn64 6 dll locations are appended into PATH Appending DLL to PATHEXT Ensuring that the following dependencies are available and their location in PATH This list is sourced from user mrry is reply in KERNEL32 dll WSOCK32 dll WS2 32 dll SHLWAPI dll python35 dll MSVCP140 dll VCRUNTIME140 dll api ms win crt runtime l1 1 0 dll api ms win crt heap l1 1 0 dll api ms win crt utility l1 1 0 dll api ms win crt stdio l1 1 0 dll api ms win crt string l1 1 0 dll api ms win crt math l1 1 0 dll api ms win crt convert l1 1 0 dll api ms win crt environment l1 1 0 dll api ms win crt filesystem l1 1 0 dll api ms win crt time l1 1 0 dll Any help would be greatly appreciated,,"reedwm,mrry,mrry,mrry,mrry",2017-10-12 23:06:07,2017-10-14 19:48:12
PR,Updating install golang sh bumping to 1 9 1,,,"ctava,caisq,caisq",2017-10-14 14:34:57,2017-10-14 21:50:50
IS,Feature request bitwise operations on boolean tensors,Currently bitwise operations such as OR AND only take integers It would be nice to be able to feed boolean tensors e g tf zeros 4 dtype tf bool or to be able to bitcast an axis of a boolean tensor to an int,,facaiy,2017-10-14 20:42:20,2017-10-15 01:41:41
PR,Remaining cherry picks for 1 4 0rc1,Java doc fixes Fixes for S3 file system and making S3 file system a default build option when running configure,,"case540,case540,case540,av8ramit,av8ramit,case540",2017-10-13 21:12:49,2017-10-15 02:25:06
PR,Tidy up tf tests cmake and reenable tests that are not failing anymore,,,"gunan,mrry,mrry,gunan",2017-10-14 05:28:26,2017-10-15 04:13:45
IS,Error while installing Tensorflow on Mac via terminal,I am trying to install Tensorflow on my mac via the terminal using the tutorial and commands that are provided by the official website linked below pip installation However when running the pip install tensorflow the pip install tensorflow gpu command i get the same error picture is attached img width 820 alt screen shot 2017 10 14 at 11 24 00 pm src img width 1182 alt screen shot 2017 10 14 at 11 23 41 pm src I am not sure why this error is occurring Any help that can be provided would be appreciated,,gunan,2017-10-15 03:24:23,2017-10-15 05:11:31
IS,config mkl leads to libmklml intel so cannot open shared object file No such file or directory,I compiled passing config mkl to bazel it compiles fine and i get the whl file i install it with pip correctly but when i launch a python session and type import tensorflow as tf i get ImportError libmklml intel so cannot open shared object file No such file or directory Any ideas,,gunan,2017-10-14 08:04:17,2017-10-15 05:12:11
IS,Linux compile v1 1 0 failed,ERROR home fesun cache bazel bazel fesun c44abb322eef8ca1d3dd1c34fcda8c3a external io bazel rules closure closure private defs bzl 27 16 The set constructor for depsets is deprecated and will be removed Please use the depset constructor instead You can temporarily enable the deprecated set constructor by passing the flag incompatible disallow set constructor false ERROR error loading package '' Extension file 'closure private defs bzl' has errors ERROR error loading package '' Extension file 'closure private defs bzl' has errors I added the flag incompatible disallow set constructor false for all bazel command call then DEBUG home fesun cache bazel bazel fesun c44abb322eef8ca1d3dd1c34fcda8c3a external bazel tools tools build defs pkg pkg bzl 197 9 tensorflow tools lib package libtensorflow jni you provided a non dictionary to the pkg tar files attribute This attribute was renamed to srcs Consider renaming it in your BUILD file DEBUG home fesun cache bazel bazel fesun c44abb322eef8ca1d3dd1c34fcda8c3a external bazel tools tools build defs pkg pkg bzl 197 9 tensorflow tools lib package cheaders you provided a non dictionary to the pkg tar files attribute This attribute was renamed to srcs Consider renaming it in your BUILD file DEBUG home fesun cache bazel bazel fesun c44abb322eef8ca1d3dd1c34fcda8c3a external bazel tools tools build defs pkg pkg bzl 197 9 tensorflow tools lib package clib you provided a non dictionary to the pkg tar files attribute This attribute was renamed to srcs Consider renaming it in your BUILD file DEBUG home fesun cache bazel bazel fesun c44abb322eef8ca1d3dd1c34fcda8c3a external bazel tools tools build defs pkg pkg bzl 197 9 tensorflow tools lib package clicenses you provided a non dictionary to the pkg tar files attribute This attribute was renamed to srcs Consider renaming it in your BUILD file ERROR home fesun tensorflow tensorflow core kernels BUILD 59 14 Traceback most recent call last File home fesun tensorflow tensorflow core kernels BUILD line 54 config setting name xsmm backward values File home fesun tensorflow tensorflow core kernels BUILD line 59 in config setting define tensorflow xsmm 1 define tensorflow xsmm backward 1 Duplicated key define when creating dictionary ERROR package contains errors tensorflow core kernels ERROR error loading package 'tensorflow core kernels' Package 'tensorflow core kernels' contains errors Any solution for this,,"reedwm,gunan",2017-10-13 11:56:43,2017-10-15 05:16:14
IS,can any one reproduce this problew with tf gather,x tf constant 0 22 0 3 0 1 0 11 0 4 0 5 0 6 0 99 0 8 0 9 0 43 0 21 indices tf constant 1 2 0 1 2 3 b tf gather nd x indices sess tf InteractiveSession cc sess run b feed dict print cc with tensorflow 1 0 1 it gets array 0 0 0 dtype float32 is it a bug in 1 0 1 but with higher version it gets right,,gunan,2017-10-13 09:02:13,2017-10-15 05:18:35
IS,parameterized docker build sh fails,Issue Executing parameterized docker build sh fails to generate new docker image throws error message System information I have used a stock example script provided in TensorFlow Windows 10 professional TensorFlow install as docker image tensorflow tensorflow 1 3 0 devel py3 TensorFlow version 1 3 Python version 3 Bazel version 0 5 0 CUDA cuDNN version not relevant CPU install GPU model and memory not relevant CPU install Set up Command triggering issue tensorflow tensorflow tools docker parameterized docker build sh Error messages Required build parameters TF DOCKER BUILD TYPE cpu TF DOCKER BUILD IS DEVEL no TF DOCKER BUILD DEVEL BRANCH NO Optional build parameters TF DOCKER BUILD CENTRAL PIP TF DOCKER BUILD IMAGE NAME TF DOCKER BUILD VERSION TF DOCKER BUILD PORT TF DOCKER BUILD PUSH CMD ERROR docker is not available on path,,"caisq,gunan",2017-09-29 12:25:10,2017-10-15 05:33:06
IS,ERROR Failed to import the TensorFlow module,I was trying to install tensorflow gpu Using the tensorflow self check it says all the required DLLs are present but I still have an import error I get the same error if I try to import numpy There seems to be an issue with my conda command as well Any help is greatly appreciated to resolve this issue Thanks PS C Users andrew Documents python tensorflow self check py ERROR Failed to import the TensorFlow module Python version is 3 6 TensorFlow is installed at C Users andre Anaconda3 lib site packages tensorflow All required DLLs appear to be present Please open an issue on the TensorFlow GitHub page PS C Users andrew Documents conda create n tensorflow gpu python 3 6 usage conda h keygen sign unsign verify unpack install install scripts convert version help conda error invalid choice 'create' choose from 'keygen' isign' 'unsign' haverify' 'unpack' 'install' 'install scripts' 'convert' haversion' 'help',,gunan,2017-09-29 20:34:23,2017-10-15 05:33:38
IS,Potential Bug in CUDA implementation of matrix set diag on Windows,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution Windows 10 64 bit TensorFlow installed from binary TensorFlow version use command below b'unknown' 1 3 0 Python version 3 6 2 CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory Nvidia GTX 1060 6GB Describe the problem I ran into this while trying to run the code at It seems that tf matrix set diag can cause tensorflow to crash when run on GPU under Windows I am able to run other complex models on GPU so it seems as though my environment is configured correctly for CUDA Source code logs Error log here for normal execution error log txt The log from running with cuda memcheck shows what looks like an issue with a null pointer buried deep inside Eigen error log cuda memcheck txt,,gunan,2017-09-27 07:12:59,2017-10-15 05:37:44
IS,Intel MKL FATAL ERROR Cannot load mkl intel thread dll,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below tensorflow 1 3 0 cp36 cp36m win amd64 whl Python version 3 6 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory GT 650M Exact command to reproduce python followed by import tensorflow as tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I followed exactly on how to install Tensorflow but whenever I try to do something involving Tnesorflow this error comes up I installed Tensorflow using Anaconda 4 4 I first typed conda create n tensorflow python 3 6 then activate tensorflow then pip install ignore installed upgrade tensorflow After that I typed python then import tensorflow as tf I get this error Intel MKL FATAL ERROR Cannot load mkl intel thread dll untitled Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2017-09-26 16:26:42,2017-10-15 05:39:12
IS,setuptools pip wheel failed with error code 2,How can I do it Thanks,,"aselle,gunan",2017-09-26 02:05:25,2017-10-15 05:42:48
IS,issue while installing tensorflow,sws sws Aspire 5830T source activate tensorflow tensorflow sws sws Aspire 5830T export TF BINARY URL tensorflow sws sws Aspire 5830T tensorflow pip3 install ignore installed upgrade TF BINARY URL bash syntax error near unexpected token ' tensorflow sws sws Aspire 5830T tensorflow pip3 install ignore installed upgrade TF BINARY URL bash syntax error near unexpected token ' tensorflow sws sws Aspire 5830T tensorflow pip3 install ignore installed upgrade TF BINARY URL bash syntax error near unexpected token ' tensorflow sws sws Aspire 5830T pip3 install ignore installed upgrade TF BINARY URL Collecting tensorflow 0 12 1 from Downloading 43 1MB 100 43 1MB 22kB s Collecting protobuf 3 1 0 from tensorflow 0 12 1 Downloading protobuf 3 4 0 cp35 cp35m manylinux1 x86 64 whl 6 2MB 100 6 2MB 124kB s Collecting wheel 0 26 from tensorflow 0 12 1 Downloading wheel 0 30 0 py2 py3 none any whl 49kB 100 51kB 3 6MB s Collecting numpy 1 11 0 from tensorflow 0 12 1 Downloading numpy 1 13 1 cp35 cp35m manylinux1 x86 64 whl 16 9MB 100 16 9MB 62kB s Collecting six 1 10 0 from tensorflow 0 12 1 Using cached six 1 11 0 py2 py3 none any whl Collecting setuptools from protobuf 3 1 0 tensorflow 0 12 1 Downloading setuptools 36 5 0 py2 py3 none any whl 478kB 100 481kB 202kB s Installing collected packages six setuptools protobuf wheel numpy tensorflow Exception Traceback most recent call last File usr local lib python3 5 site packages pip basecommand py line 215 in main status self run options args File usr local lib python3 5 site packages pip commands install py line 342 in run prefix options prefix path File usr local lib python3 5 site packages pip req req set py line 784 in install kwargs File usr local lib python3 5 site packages pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File usr local lib python3 5 site packages pip req req install py line 1064 in move wheel files isolated self isolated File usr local lib python3 5 site packages pip wheel py line 345 in move wheel files clobber source lib dir True File usr local lib python3 5 site packages pip wheel py line 323 in clobber shutil copyfile srcfile destfile File usr local lib python3 5 shutil py line 115 in copyfile with open dst 'wb' as fdst PermissionError Errno 13 Permission denied ' usr local lib python3 5 site packages six py' tensorflow sws sws Aspire 5830T pip3 install ignore installed upgrade TF BINARY URL Collecting tensorflow 0 12 1 from Using cached Collecting six 1 10 0 from tensorflow 0 12 1 Using cached six 1 11 0 py2 py3 none any whl Collecting wheel 0 26 from tensorflow 0 12 1 Using cached wheel 0 30 0 py2 py3 none any whl Collecting numpy 1 11 0 from tensorflow 0 12 1 Using cached numpy 1 13 1 cp35 cp35m manylinux1 x86 64 whl Collecting protobuf 3 1 0 from tensorflow 0 12 1 Using cached protobuf 3 4 0 cp35 cp35m manylinux1 x86 64 whl Collecting setuptools from protobuf 3 1 0 tensorflow 0 12 1 Using cached setuptools 36 5 0 py2 py3 none any whl Installing collected packages six wheel numpy setuptools protobuf tensorflow Exception Traceback most recent call last File usr local lib python3 5 site packages pip basecommand py line 215 in main status self run options args File usr local lib python3 5 site packages pip commands install py line 342 in run prefix options prefix path File usr local lib python3 5 site packages pip req req set py line 784 in install kwargs File usr local lib python3 5 site packages pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File usr local lib python3 5 site packages pip req req install py line 1064 in move wheel files isolated self isolated File usr local lib python3 5 site packages pip wheel py line 345 in move wheel files clobber source lib dir True File usr local lib python3 5 site packages pip wheel py line 329 in clobber os utime destfile st st atime st st mtime PermissionError Errno 1 Operation not permitted,,"aselle,gunan",2017-09-25 10:15:31,2017-10-15 05:43:19
IS,commit 5c7f9e3 breaks windows bazel build,commit 5c7f9e316d8c7735308a217310350d416d7498cc in 13224 breaks windows bazel build First rpath linkopts in tensorflow tensorflow bzl should not add rpath args to link exe Second the link command generated from bazel is incorrect link exe nologo OUT bazel out host bin tensorflow python gen set ops py wrappers cc exe Lbazel out host bin solib x64 windows U S Stensorflow Spython Cgen Uset Uops Upy Uwrappers Ucc Utensorflow tensorflow framework SUBSYSTEM CONSOLE pthread MACHINE X64 out host bin tensorflow python gen set ops py wrappers cc exe 2 params DEFAULTLIB msvcrt lib The addDynamicInputLinkOptions function in src main java com google devtools build lib rules cpp CppLinkActionBuilder java does not support Windows,,"snnn,allenlavoie,allenlavoie,gunan",2017-09-22 07:48:09,2017-10-15 05:44:06
IS,Build fails at patch command different line endings,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 8 1 64bit TensorFlow installed from source or binary I'm trying to build from source to use CPU optimizations TensorFlow version use command below 1 3 cloned from master Python version 3 6 1 Bazel version if compiling from source 0 5 4 CUDA cuDNN version CPU only Describe the problem I'm trying to build TensorFlow from source to use CPU optimizations I was getting patch error exactly as in Issue 10435 so I used the recommended solution issuecomment 306422472 by adding binary to patch call at workspace bzl function apply patch The tensorflow core is now loaded bur I get another error with tensorflow contrib session bundle see log Source code logs,,"aselle,gunan,meteorcloudy,meteorcloudy,aselle,gunan",2017-09-18 17:37:17,2017-10-15 05:52:17
IS,pip error while training model on cloud,The replica master 0 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip 9 013O build setup py' The replica worker 0 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip QNtwDr build setup py' The replica worker 1 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip pA8eBo build setup py' The replica worker 2 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip Xk5nGm build setup py' The replica worker 3 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip 3VkzR6 build setup py' The replica worker 4 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip NIf2Jb build setup py' The replica worker 5 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip RlyPFQ build setup py' The replica worker 6 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip QXzr7y build setup py' The replica worker 7 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip FvkZhP build setup py' The replica worker 8 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip Ue8 oJ build setup py' The replica ps 0 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip AxLdZ1 build setup py' The replica ps 1 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip 7nE9PF build setup py' The replica ps 2 exited with a non zero status of 1 Termination reason Error Traceback most recent call last File string line 1 in module IOError Errno 2 No such file or directory ' tmp pip GSkkn1 build setup py' To find out more about why your job exited please check the logs,,gunan,2017-09-13 02:12:43,2017-10-15 05:59:33
PR,Fixed incorrect hooks doc in EvalSpec,,,"terrytangyuan,xiejw",2017-10-14 21:30:06,2017-10-15 06:09:37
PR,Boring ssl update,As per Ping Also what is the standard way of getting the checksum I used sha256sum on the file I downloaded The patch to the BUILD file is no longer applicable I'm not sure if we still need that patch Any comments,,"tjingrant,caisq,tjingrant,caisq,tjingrant,gunan,Nayana-ibm,gunan,tjingrant,gunan,Nayana-ibm",2017-10-11 16:08:09,2017-10-15 06:10:20
PR,more pythonic,remove semicolons,,"frankchn,caisq,gunan",2017-10-06 21:44:49,2017-10-15 06:12:03
PR,Skeleton code for annotation processor,Add build changes and skeleton code with test harness for the Operator annotation processor This change focuses on build and test related changes and generates an empty Ops class Please see 7149 for the master tracking issue,,"kbsriram,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,kbsriram,kbsriram,kbsriram,kbsriram,kbsriram,kbsriram,kbsriram,kbsriram,asimshankar,asimshankar,kbsriram,kbsriram,kbsriram,asimshankar,kbsriram,kbsriram,drpngx,sb2nov,kbsriram,asimshankar,kbsriram,asimshankar",2017-09-05 21:22:07,2017-10-15 06:14:05
PR,Disable the newly failing windows GPU tests,,,"gunan,gunan",2017-10-15 04:24:54,2017-10-15 13:34:12
PR,DO NOT MERGE infra experiment,,,"yifeif,caisq,yifeif",2017-10-06 20:51:50,2017-10-15 16:30:08
PR,Support reversing bool sequence,This PR tries to fix issue 13717,,"betterenvi,ebrevdo,ebrevdo,ebrevdo,caisq,betterenvi,caisq",2017-10-14 16:48:41,2017-10-15 17:25:08
IS,CMake build with Dtensorflow BUILD ALL KERNELS OFF does not work,Problem When building Tensorflow via CMake specifying option tensorflow BUILD ALL KERNELS OFF leads to failed linker step due to unresolved external functions because many important files that are not kernels but are necessary are not included in build is list of sources like ops util cc but also other files Reproduction Follow instruction in specify Dtensorflow BUILD ALL KERNELS OFF to cmake,,"mrry,yongtang",2017-08-02 18:23:36,2017-10-15 17:28:21
PR,Fix cmake build with Dtensorflow BUILD ALL KERNELS OFF error,This fix tries to address the issue raised in 11975 where cmake with Dtensorflow BUILD ALL KERNELS OFF will throw out an error The issue is casued by ops util cc which is needed even if all kernels are OFF This fix fixes the issue with cmake file update This fix fixes 11975 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq",2017-10-14 19:22:10,2017-10-15 17:28:21
IS,Build Tensorflow on Windows with MT option,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 release Python version 3 6 Bazel version if compiling from source using CMake 3 9 1 Exact command to reproduce I am not really sure if that is supposed to work so it can be considered a feature request I would really like to build tensorflow with MT to make my application as portable as possible Currently I build tensorflow dll with Visual Studio 2017 and default switches MD and therefore the resulting application requires Microsoft Redistributable C libraries for Visual Studio 2017 If building with MT is supposed to work maybe someone could give me a hint how to get it right and then we can close the issue I guess digging into build options of every third party library and adding MT there,,"mrry,gunan,gunan",2017-09-18 16:09:46,2017-10-15 17:44:24
PR,Update documentation for uint16 support in tf resize ops,This fix tries to address the different between the registered kernels and the documentation differnet for uint16 support of tf resize area tf resize bicubic tf resize bilinear tf resize nearest neighbor Though uint16 is supported in the kernel it is not documented in image ops cc Unit test cases are also missing for uint16 and float16 This fix added the missing entries in tests and docs Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq",2017-10-14 19:21:14,2017-10-15 19:01:47
IS,Force tensor evaluation inside while loop scan and others,Hello everyone I had big plans for tf while loop until I discovered that it is impossible to re evaluate tensor inside it Let is dive into the the issue and potential useful feature I created v variable and tensor sq which equals to v 2 In fact we do not have control over them they are our input as x and y and we know that y depends on x I would like to assign new value inside TensorFlow loop to x equavalent to v at example and evaluate fresh y sq inside example at each iteration of the loop Meanwhile we can do other evaluations inside while loop but most important is that I need to update x and get updated y Currently assigning operation does not propagate updates down to the dependant nodes and it should not but when someone calls tensor depending on value which were updated via assign inside while loop I suppose the tensor node must detect this change and evaluate new tensor value again Thanks,,"tatatodd,skye,skye,ebrevdo,ebrevdo,ebrevdo,ebrevdo,skye,ebrevdo,mrry,ebrevdo,ebrevdo,alextp,alextp,alextp,alextp,alextp",2017-10-10 22:21:20,2017-10-15 19:17:15
IS,tf reverse sequence does not support bool sequence,It seems that tf reverse sequence can not reverse bool sequence,,"yongtang,betterenvi",2017-10-14 16:39:49,2017-10-16 01:15:41
IS,Build error with boringssl,With the most recent master bazel build fails with Ubuntu 16 04 gcc version 5 4 0 20160609 Ubuntu 5 4 0 6ubuntu1 16 04 4 and bazel 0 6 1 I think the issue is caused by the recent changes of the patch in boringssl with in PR 13638,,yongtang,2017-10-15 20:49:29,2017-10-16 02:00:26
PR,Fix build error with boringssl,This fix tries to fix build error with boringssl on Ubuntu 16 04 gcc version 5 4 0 20160609 Ubuntu 5 4 0 6ubuntu1 16 04 4 and bazel 0 6 1 This fix is related to PR 13638 This fix fixes 13733 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,gunan,yongtang,caisq,yongtang,yongtang",2017-10-15 20:51:19,2017-10-16 02:00:26
PR,Update CUB to 1 7 4,Was working on 13731 and noticed that the CUB version is 1 7 3 This fix updates CUB to 1 7 4 which consists of bug fixes in radix sort Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,yongtang,caisq",2017-10-15 14:21:58,2017-10-16 02:17:57
PR,Branch 172270804,,,caisq,2017-10-16 01:42:11,2017-10-16 03:03:29
IS,Building custom op instructions out of date,Following instructions here To try to rebuild this op First I ran into issue with nsync headers fixed by following issuecomment 328829250 Then while trying to load the so file I run into tensorflow python framework errors impl NotFoundError max align bytes op so undefined symbol ZTIN10tensorflow8OpKernelE So the definition for tensorflow OpKernel is missing tf commit cc,,"yaroslavvb,allenlavoie,allenlavoie,yaroslavvb,allenlavoie,allenlavoie",2017-10-10 14:51:48,2017-10-16 03:04:35
IS,conv2d transpose crashes on GPU with zero size batch,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary installed with conda install tensorflow gpu TensorFlow version use command below b'unknown' 1 3 0 Python version 3 5 2 Bazel version if compiling from source N A CUDA cuDNN version 8 0 6 0 GPU model and memory GTX 980 Exact command to reproduce See below Describe the problem Execute the script below It works correctly when running on a CPU but on a GPU it crashes with this error,,"reedwm,reedwm",2017-10-11 19:54:10,2017-10-16 03:04:35
IS,FeatureRequest TFDBG change default limit depth for recursive checking tensors,Hi Recently I was debugging with TFDBG for a neural network training It is pretty useful however when I want to check some ill conditioned tensors and their parent by default TFDBG give me its parents up to a recursive level of 20 i e limit depth 20 by default I could solve the problem by putting a d 1 to check its immediate parent each time but it is quite annoying to input this every time Would you consider adding a feature in this TFDBG allowing us to set a default value for recursive retrieval of a tensor is input nodes My TensorFlow version is,,caisq,2017-10-02 19:13:40,2017-10-16 03:04:36
IS,tensorflow core lib io record reader h 83 19 error use of undeclared identifier 'InputStreamInterface' std unique ptr InputStreamInterface input stream,When try to build iOS dependencies got this error I simply run,,"mrry,mrry,mrry,mrry",2017-10-14 03:32:28,2017-10-16 03:40:52
PR,tfdbg add persistent config cherry pick to r1 4,Add two persistent UI configurations backed by a file at tfdbg config by default graph recursion depth which controls the recursive output of li lo commands mouse mode which controls the mouse state of the CursesUI Add config command to set and inspect the persistent configuration E g config show config set graph recursion depth 3 config set mouse mode False Fixes 13449 PiperOrigin RevId 172270804,,"caisq,gunan",2017-10-16 03:11:33,2017-10-16 04:32:18
IS,Failed to load the native TensorFlow runtime,my python version is 3 5 2 cuda version is 8 0 and cudnn version is 6 14 but when I import tensorflow I have get the follow error message how I can solve it,,"Carmezim,Carmezim,Carmezim",2017-10-14 14:52:27,2017-10-16 13:39:18
PR,Fix typos,This PR fixes some typos a a for for tranpose from from and to to,,taehoonlee,2017-10-16 12:57:56,2017-10-16 14:02:46
IS,,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-16 04:12:41,2017-10-16 15:18:46
IS,extremly sucks cockie madness,totally sucks because of its cookie popup dialog which jumps into one is face each time one goes to a different page on this site NO matter whether one has already clicked clicked OK or something else No way to do any research on such annoying site,,"asimshankar,asimshankar,gunan",2017-10-07 12:23:34,2017-10-16 15:42:20
PR,Minor fix to MKL allocator to address a build regression,Uses char instead of char to deal with build issues related to allocator strings,,"jbobba,jbobba,rmlarsen,rmlarsen",2017-10-13 18:18:28,2017-10-16 17:31:30
PR,Enable setting HDFS user,Following issue add enable TensorFlow to access HDFS as a specific HDFS user instead of the the system user owning the Tf process,,"jhseu,caisq,jhseu,jhseu",2017-10-12 08:12:22,2017-10-16 17:31:37
PR,fixed type error API r1 3 document tf truncatediv,It was just type error from ' 7 5 1' to ' 7 5 1',,"rmlarsen,rmlarsen",2017-10-14 10:37:13,2017-10-16 17:31:59
PR,Add freeze graph to CONSOLE SCRIPTS,Make freeze graph accessible from command line from pip package,,yifeif,2017-10-16 04:59:00,2017-10-16 17:45:33
IS,Decoding and resizing image is giving unknown tensor shape,I'm trying to load two images one is png and another is jpg to tensorflow and resize them to 100x100 pixel size using tf image pad to bounding box so that they will be of same size and can be used for training Here is my code But some how the resized image size is not proper It is displaying height and width but not depth I mean channels Output 100 100 height width are 100 but depth is ' ' and Surprisingly It is giving same output for invalid paths also Eg IMAGES PATH 'images ' What Am I doing wrong Please help,,drpngx,2017-10-16 07:09:35,2017-10-16 18:55:01
PR,Add fast tensor util cpp to gitignore,While working on building TensorFlow I noticed that a file fast tensor util cpp is generated This fix adds fast tensor util cpp to gitignore so that it will not be added inadvertently when adding commit with git add A Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-10-16 15:16:10,2017-10-16 19:37:41
IS,Importing tensorflow after import pytorch crashes inside tensorflow port TestCPUFeature,TF version PyTorch version '0 2 0 4' whatever is installed by default yesterday Crashing code,,"yaroslavvb,allenlavoie,drpngx",2017-10-10 21:15:27,2017-10-16 20:09:28
IS,Android Error 68 13 Failed to resolve org tensorflow tensorflow android,Error 68 13 Failed to resolve org tensorflow tensorflow android Are there some problems with remote repository screenshot 1,,"kbsriram,asimshankar,asimshankar,andrewharp,drpngx,kbsriram,andrewharp,andrewharp",2017-10-12 06:25:36,2017-10-16 20:12:13
PR,Creating a patch for the wrong links that still point to dev,,,av8ramit,2017-10-16 17:44:03,2017-10-16 20:33:55
IS,Broken download links of the Windows GPU,Hi Windows GPU download link are broken,,"reedwm,av8ramit,gunan,av8ramit",2017-08-13 00:14:11,2017-10-16 20:51:27
IS,The pip upgrade in windows does not get up to date tensorflow codes on github,Tensorflow version 1 3 OS Windows 10 When I use pip upgrade to get tensorflow the codes I got did not reflect the newest updates in Github For example in tensorflow tensorflow contrib layers python layers layers py the up to date batch norm function supports not None param regularizers However the codes updated by pip still not support param regularizers as the codes are not up to date Is there any other way to get the most updated tensorflow in Windows Thank you,,"aselle,aselle,gunan,av8ramit",2017-09-26 15:46:26,2017-10-16 21:08:38
IS,Error during compilation of tensorflow GPU using bazel 0 5 3,Using Bazel 0 5 3 from installer both sh and deb on Ubuntu 16 04 to compile tensorflow gpu I get the following error that fails compilation Encountered error while reading extension file 'cuda build defs bzl' no such package ' local config cuda cuda' Traceback most recent call last File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 1039 create local cuda repository repository ctx File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 976 in create local cuda repository host compiler includes repository ctx cc File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 145 in host compiler includes get cxx inc directories repository ctx cc File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 120 in get cxx inc directories set includes cpp depsets cannot contain mutable items WARNING Target pattern parsing failed ERROR error loading package 'tensorflow tools pip package' Encountered error while reading extension file 'cuda build defs bzl' no such package ' local config cuda cuda' Traceback most recent call last File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 1039 create local cuda repository repository ctx File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 976 in create local cuda repository host compiler includes repository ctx cc File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 145 in host compiler includes get cxx inc directories repository ctx cc File home nicola Software tensorflow gpu tensorflow third party gpus cuda configure bzl line 120 in get cxx inc directories set includes cpp Compilation proceeds just fine using Bazel 0 5 2 Note the error occurs when I try to compile ANY version of tensorflow tested 1 2 1 1 3rc0 1 3rc1 git System information Have I written custom code No OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version v1 2 0 2210 g49961e5 1 2 1 v 1 3 rc0 rc1 HEAD Python version 3 5 2 Bazel version Both 0 5 2 and 0 5 3 from deb installer and sh installer CUDA cuDNN version CUDA 8 CuDNN 6 1 GPU model and memory GeForce 1050Ti 4Gb Describe the problem Make sure you clean the bazel cache Install bazel 0 5 2 from installer deb or sh Try compilation of tensorflow gpu it should work fine Remove bazel 0 5 2 and clean its cache Instal bazel 0 5 3 from installer deb or sh Repeat compilation of tensorflow and the error appears preventing the full compilation,,"allenlavoie,allenlavoie,allenlavoie,av8ramit,av8ramit,ahundt,ahundt,av8ramit",2017-07-29 16:54:10,2017-10-16 21:16:40
PR,Fix dev remnants 1 4,,,"av8ramit,vrv",2017-10-16 18:10:03,2017-10-16 21:56:39
PR,Fix broken link in debugger doc,See I'm not sure if this is the correct syntax to make the link render But it is my best guess based on examining other files,,"jart,vrv",2017-10-16 21:45:22,2017-10-16 21:57:16
PR,Fix ambiguous type comparison in s3 crypto cc,We were seeing the following compilation error on Windows builds tensorflow contrib s3 s3 crypto cc 74 error C2666 istd fpos Mbstatet operator ' 3 overloads have similar conversions could be 'bool std fpos Mbstatet operator std streamoff const' or 'bool std fpos Mbstatet operator const std fpos Mbstatet,,"case540,vrv",2017-10-16 21:53:37,2017-10-16 22:46:36
PR,Revert Fix broken link in debugger doc,Reverts tensorflow tensorflow 13757,,vrv,2017-10-16 22:49:40,2017-10-16 22:50:37
PR,Update README md,Update information about local builds and TensorFlow is CI system,,"gunan,gunan,gunan,vrv,gunan,gunan,gunan",2017-10-13 14:04:32,2017-10-16 23:00:56
PR,Branch 172380659,,,"vrv,vrv",2017-10-16 22:15:34,2017-10-16 23:19:32
IS,type error in tensorflow document API r1 3 tf truncatediv,Cause this issue is not about tensorflow itself please excuse my ignoring some conventions Plus as you know the postage can cost more than the goods once I try to contribute to documentation via committing so as to correct a tiny error Please let me use this channel to comment problematic document Truncation designates that negative numbers will round fractional quantities toward zero I e 7 5 1 This matches C semantics but it is different than Python semantics See FloorDiv for a division function that matches Python Semantics I e 7 5 1 should be I e 7 5 1,,"reedwm,reedwm",2017-10-13 08:57:08,2017-10-16 23:58:01
PR,Add GPU and CPU implementation of tf histogram fixed width,This fix adds the GPU and CPU implementation of tf histogram fixed width The previous implementation was done in python This fix adds C kernel for GPU and CPU The GPU version uses CUB is API cub DeviceHistogram HistogramRange The range is constructed from the upper lower limit and step size HistogramEven could not be used directly as the edge case is different The CPU version uses a transform to map the input into the bucket index then did a bin count Note the output type of int64 on GPU is not supported yet as atomicAdd has no int64 at the moment Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,rmlarsen,yongtang,rmlarsen,yongtang,rmlarsen,gunan,yongtang,yongtang,yongtang",2017-10-15 13:53:47,2017-10-17 00:19:27
PR,tfdbg release notes in r1 4,,,caisq,2017-10-16 03:57:38,2017-10-17 01:09:04
IS,Tensorflow No valid folders of images found at XXXXX,So I have a semi custom code written for a new biomedical program that I am developing I am trying to get my model to begin retraining and I am getting this problem out of nowhere whenever I run python retrain py bottleneck dir tf files bottlenecks how many training steps 100 model dir tf files inception output graph tf files retrained graph pb output labels tf files retrained labels txt image dir tf files ct The 'ct' folder in question and giving me issues and has a stockpile of images I have made sure that the folder does not have any other files in it creating the issue of tensor not picking up the image first Furthermore I have ensured that each file has been converted to a jpg I have no hyphens or dashes in the subfolders and they are all lowercased no spaces Below are the following inputs that are giving me troubles I have scoured the net for different answers to this problem and after troubleshooting the above mentioned attributes I still am finding the same error message incur Thanks in advance root 8c16ee553d5a tf files python retrain py bottleneck dir tf files bottlenecks how many training steps 100 model dir tf files inception output graph tf files retrained graph pb output labels tf files retrained labels txt image dir Users maisiemullin tf files ct 2017 06 25 16 43 47 433755 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 06 25 16 43 47 443444 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 06 25 16 43 47 443724 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations Image directory ' Users maisiemullin tf files ct' not found Traceback most recent call last File retrain py line 1062 in module tf app run main main argv sys argv 0 unparsed File usr local lib python2 7 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File retrain py line 784 in main class count len image lists keys AttributeError 'NoneType' object has no attribute 'keys' root 8c16ee553d5a tf files,,,2017-06-25 16:50:03,2017-10-17 01:33:34
IS,Error in table lookup from tf contrib lookup when using dataset api,System information OS Platform and Distribution e g Linux Ubuntu 16 04 All platforms TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 6 2 7 I try the following code,,mrry,2017-07-15 02:28:46,2017-10-17 01:33:41
PR,Branch 172408922,,,"vrv,vrv,vrv",2017-10-17 02:04:17,2017-10-17 03:25:30
IS,GraphDef ParseFromString error,I load a graph pb saved by tf train write graph sess graph as graph def FLAGS model dir 'graph pb' as text False via blow code But an error occur Why,,,2017-10-16 11:38:58,2017-10-17 03:36:52
IS,Changing compiler to gcc not works,In my macOS I have set export CC usr local bin gcc 6 and export CXX usr local bin g 6 Then I built tensorflow from source using sh tensorflow contrib makefile build all ios sh But I saw it also compile using clang So how to change compiler,,"martinwicke,facaiy",2017-09-28 06:14:33,2017-10-17 05:33:45
IS,tf sparse add does not work for tf SparseTensor that has tf Variable as values,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 2 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN7 GPU model and memory 4x GTX1080ti Exact command to reproduce see below Describe the problem tf sparse add raises RuntimeError for tf SparseTensor that has tf Variable as values Simplest example code to reproduce the problem import numpy as np import scipy sparse as sp import tensorflow as tf A sp random 100 100 vals tf Variable tf ones A nnz A tf tf SparseTensor np column stack A row A col vals A shape tf sparse add A tf A tf raises RuntimeError Running this snippet produces the following error message RuntimeError Traceback most recent call last ipython input 177 3d37a994a045 in module 6 vals tf Variable tf ones A nnz 7 A tf tf SparseTensor np column stack A row A col vals A shape 8 tf sparse add A tf A tf raises RuntimeError conda envs rml lib python3 6 site packages tensorflow python ops sparse ops py in sparse add a b thresh 297 b convert to sparse tensor b 298 thresh ops convert to tensor 299 thresh dtype a values dtype real dtype name thresh 300 output ind output val output shape gen sparse ops sparse add 301 a indices a values a dense shape conda envs rml lib python3 6 site packages tensorflow python framework ops py in convert to tensor value dtype name preferred dtype 609 name name 610 preferred dtype preferred dtype 611 as ref False 612 613 conda envs rml lib python3 6 site packages tensorflow python framework ops py in internal convert to tensor value dtype name as ref preferred dtype 688 dtype requested s actual s 689 error prefix conversion func base type 690 dtype name ret dtype name 691 return ret 692 raise TypeError sCannot convert r with type s to Tensor RuntimeError thresh Conversion function function constant tensor conversion function at 0x7fe50a9c0ea0 for type class 'object' returned incompatible dtype requested float32 ref actual float32 I found a workaround but I strongly believe that this is not the intended behavior zero tensor tf SparseTensor np column stack 0 0 0 0 A shape A tf tf sparse add A tf zero tensor still same RuntimeError A tf tf sparse add zero tensor A tf does not change the value of A tf tf sparse add A tf A tf works Source code logs Output of the log file cat etc issue Linux 4 10 0 33 generic 37 16 04 1 Ubuntu SMP Fri Aug 11 14 07 24 UTC 2017 x86 64 x86 64 x86 64 GNU Linux cat etc issue Linux 4 10 0 33 generic 37 16 04 1 Ubuntu SMP Fri Aug 11 14 07 24 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux 4 10 0 33 generic 37 16 04 1 Ubuntu SMP Fri Aug 11 14 07 24 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 4 0 tensorflow gpu 1 3 0 tensorflow tensorboard 0 1 6 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda 8 0 lib64 DYLD LIBRARY PATH is unset nvidia smi Wed Oct 4 17 59 42 2017 NVIDIA SMI 375 82 Driver Version 375 82 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 108 Off 0000 02 00 0 Off N A 20 33C P2 58W 250W 445MiB 11172MiB 0 Default 1 GeForce GTX 108 Off 0000 03 00 0 Off N A 20 32C P2 57W 250W 153MiB 11172MiB 0 Default 2 GeForce GTX 108 Off 0000 83 00 0 Off N A 20 31C P8 10W 250W 8671MiB 11172MiB 0 Default 3 GeForce GTX 108 Off 0000 84 00 0 Off N A 20 37C P8 9W 250W 153MiB 11172MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 19158 C 443MiB 1 19158 C 151MiB 2 20686 C 8669MiB 3 20686 C 151MiB cuda libs usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7,,tatatodd,2017-10-04 16:40:40,2017-10-17 10:20:05
IS,QuantConv2D,Hi I have followed the documentation and TF Github code and could not find the relation between QuantizedConv2D to GEMMlowp Does QuantizedConv2D use implicitly in a way the QuantizedMatMul quantized matmul op cc under the hood where the latter calls GemmlowpMultiply explicitly Otherwise how the QuantizedConv2D using the great benefit of google GEMM HW platform specific implementation,,,2017-10-17 12:15:55,2017-10-17 14:11:14
IS,How are threads bound to physical cores in TensorFlow runtime and inter intra threadpools,Hi all If one CPU has 8 cores and each core has two threads does TF runtime use the OS threads scheduler to match the logical cores and threads to the physical cores and threads Or does it has its own policy to match the threads and cores Does TF only recognize cores and but not the whole device CPU like the system does The OS only knows the number id of cores and sockets and does not know how many CPU devices Does the device in TF correspond to the physical core e g TF recognizes 8 devices in the above CPU I found out that there are inter intra global and local threadpools in tensorflow core common runtime local device cc and tensorflow core common runtime dirrect session cc Does that mean each device or core have its own local inter intra threadpool and there is only one inter intra global threadpool in the whole TF runtime Thank you for your time,,,2017-10-16 23:20:52,2017-10-17 14:46:13
IS,no module,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-17 14:57:10,2017-10-17 15:32:52
IS,NET ERR CERT COMMON NAME INVALID visiting,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Chrome mac os latest TensorFlow installed from source or binary N A TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I'm following a tensorflow tutorial The tutorial references 'Speech Commands dataset' which points to I follow that link in chrome and get Your connection is not private Attackers might be trying to steal your information from download tensorflow org for example passwords messages or credit cards Learn more NET ERR CERT COMMON NAME INVALID Subject storage googleapis com Issuer Google Internet Authority G2 Expires on Dec 26 2017 Current date Oct 13 2017 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"martinwicke,martinwicke",2017-10-14 00:08:14,2017-10-17 15:42:27
IS,tf reduce sum gives value error when given int64 as input,Passing a tensor of dtype int64 into tf reduce sum I receive the following error Tensor loss diff 0 shape 50 dtype int64 ValueError Invalid type tf int64 for loss Sum 0 expected tf float32 tf float64 tf float16 According to the documents from input tensor The tensor to reduce Should have numeric type As int64 is a numeric type I am not sure what is wrong To create the diff tensor I do Where predictions is of type int64 and my targets placeholder is also of type int64 Is this a tensorflow error or an error on my end,,"facaiy,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-10-16 22:57:06,2017-10-17 16:40:35
IS,no module named models rnn translate,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-10-17 14:57:33,2017-10-17 16:52:13
IS,How can I do multples input Api c,Hi guys I am trying to make build my project in c The model use CTC and I do not have idea with re writte code for main cc So It has input four values Tensor the input 0 shape 128 64 1 dtype float32 Tensor the labels 0 shape 16 dtype float32 Tensor input length 0 shape 1 dtype int64 Tensor label length 0 shape 1 dtype int64 I am use url as model base for new code however the input is erro Can someone help me Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Linux Ubuntu 16 04 TensorFlow installed by git alfer compiling TensorFlow 1 3 0 Python version 3 5 Bazel version 0 6 1 CUDA cuDNN version GPU Titan X pascal 12GB You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I a m triyng create a image ocr mobilie as tensorflow CTC Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-10-17 13:07:31,2017-10-17 16:54:06
IS,TypeError in freeze graph tool while trying to freeze a graph in Tensorflow 1 3,I train a tf contrib learn estimator specifically DNNLinearCombineRegressor in Python and saved the model s parameters and graph by specifying model dir when defining the estimator My estimator uses embedding and real valued feature columns and a custom input fn to parse the data After training is done I try to freeze the graph using the CLI as mentioned in this post and get this error TypeError names to saveables must be a dict mapping string names to Tensors Variables Not a variable Tensor dnn hiddenlayer 0 biases 0 shape 10 dtype float32 in saver py in the function ValidateAndSliceInputs Is this because I am using an input fn with pandas dataframe or is it because of the tf feature columns that I am using I want to freeze the graph so that predict scores doesnt reload the graph variables from checkpoint file everytime for prediction I am using Tensorflow 1 3 with Anaconda Python 3 5 on Windows 10 Thanks in advance,,drpngx,2017-10-17 14:24:14,2017-10-17 16:55:05
IS,Feature request Profiling with multiple workers in distributed settings and visualizing them individually,Hi I am running Tensorflow in distributed settings only using CPUs with multiple workers and parameter servers I would like to find a way to generate timeline information of individual workers parameter servers and visualize them together to check on potential scaling issues Currently I can generate timeline traces containing the profiles of all the parameter servers and a single worker But visualizing all the workers in the same timeline trace would be beneficial Thank you,,,2017-10-13 08:15:47,2017-10-17 18:22:35
IS,Does this version support the CUDA 9 0,Does this version support the CUDA 9 0 Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-16 21:14:31,2017-10-17 18:27:46
IS,libtensorflow cc so need to work on single but not specific core feature request,I use self builded libtensorflow cc so shared library in my c model player program I builded so for cpu only usage But by default in runtime it uses all cores But I want to use only one core If i run my program through taskset for example I can use specific mask taskset c 0 my program param1 param2 And it will perfectly work but only on 0 th core of my cpu And if I run several parallel programs with theese parameters all of them will work on 0 th core while another cores are free I need that for my service for several parallel program works on different cores How can I build libtensorflow cc so WITHOUT multi threading Or maybe how can I configure it for single core but I repeat not specific core Thank you,,,2017-10-16 08:02:46,2017-10-17 18:42:13
PR,Fix 13731 by adding HistogramdFixedWidth in hidden ops txt and create the python wrapper,This fix fixes the build breaks in 13731 The issue was caused by the fact that API compatibility requires a default value for nbins 100 while the test utility code in contrib need to pass a tensor not through attribute This fix adds HistogramdFixedWidth in hidden ops txt so that histogram fixed width is hidden in gen math ops py Then histogram fixed width calls the hidden gen math ops histogram fixed width In this way both api compatibility and test utility code in contrib requires no changes See comment issuecomment 337186002 for reference Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,gunan",2017-10-17 11:31:14,2017-10-17 19:22:21
PR,the comment is confusing,I find the comment say that embedding shape is num encoder symbols x input size I was so confused and checked the source code I believe it will be better to change the input size to embedding size,,,2017-10-17 03:21:10,2017-10-17 19:22:46
PR,Revert Add GPU and CPU implementation of tf histogram fixed width,13731 This reverts commit 528457ea3cbe4edfbd3eb90c303b2a1408fe8d65 The failing test is tensorflow contrib distributions poisson lognormal test poisson lognormal test page log See comment issuecomment 337127918 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,gunan,vrv",2017-10-17 09:06:44,2017-10-17 19:23:07
PR,Improve shape inference with DecodeAndCropJpeg,While working on improving shape inference for several other ops in 13561 and 13193 I noticed that DecodeAndCropJpeg does not inference shape even though crop size might have already be provided In that case the shape will be h w channel and h w is part of the crop window in input This fix updates the shape function in DecodeAndCropJpeg for improving shape inference The test has also been updated to cover the changes Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,vrv,yongtang,vrv,mingxingtan,vrv",2017-10-16 16:03:02,2017-10-17 19:23:30
PR,AddSign and PowerSign optimizers for contrib opt,Added optimizers with update rules from,,"vrv,vrv",2017-10-15 04:00:44,2017-10-17 19:25:37
PR,Utility class for outputing formatting generated source code,The following class is used in an upcoming PR for generating Java operation wrappers but is generic and useful enough to take place in the core library This way any source code generated from C can make use of it,,"karllessard,asimshankar,karllessard,asimshankar,karllessard",2017-10-16 14:37:22,2017-10-17 20:33:14
IS,monotonic attention is buggy,System information Have I written custom code Yes OS Platform and Distribution Manjaro Linux kernel 4 13 5 TensorFlow installed from binary TensorFlow version use command below 1 3 1 4 nightly 11 oct Python version 3 6 Bazel version if compiling from source CUDA cuDNN version cuda8 cudnn 7 6 GPU model and memory gtx 1080 the problem The two monotonic attention mechanisms LuongMonotonicAttention and BahdanauMonotonicAttention do not seem to work as expected on my task In the case of LuongMonotonicAttention the alignment that I obtain looks like a horizontal line drawn on the first row of the image However the alignment has a diagonal shape using BahdanauAttention or LuongAttention and I am instantiating these classes with the same parameters In the case of BahdanauMonotonicAttention I simply receive an error message Is there any preprocessing I should do in addition to the non monotonic case,,"reedwm,ebrevdo",2017-10-12 21:02:34,2017-10-17 21:17:54
IS,tf image pad to bounding box crashes when passed bounds with dtype int64,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary from pip in virtualenv TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version '3 5 2 default Nov 17 2016 17 05 23 n GCC 5 4 0 20160609 ' Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Description Passing arguments of type int64 to tf image pad to bounding box triggers a crash of the python interpreter This is a bug because the type required by tf image pad to bounding box not documented anywhere and just causes a crash with a cryptic error message Sources Logs The following snippet crashes the whole python interpreter with a core dump import tensorflow as tf i tf constant 0 0 3 3 dtype tf int64 img tf ones 1 1 1 dtype tf float32 sess tf Session sess run tf image pad to bounding box img i 0 i 1 i 2 i 3 And leaves the following 2017 10 05 13 51 24 789715 F tensorflow core framework tensor cc 493 Check failed dtype expected dtype 9 vs 3,,"yaroslavvb,yongtang,asimshankar",2017-10-05 18:06:45,2017-10-17 21:35:52
PR,Fix crash when tf pad is used with int64 paddings,This fix tries to fix the issue raised in 13506 where int64 data types for bounds in tf image pad to bounding box crashes The reason of the crash is caused by the fact that int64 was directly converted into int32 without passing through kernel registeration This fix fixes the issue by adding typename Tpadding to the template and adds appropriate kernels This fix fixes 13506 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rryan,rryan,yongtang,yongtang,frankchn,rryan,rryan,yongtang,rryan,rryan,benoitsteiner",2017-10-06 05:21:25,2017-10-17 21:35:52
IS,Import Error Tensorflow is looking for wrong shared library libnvidia fatbinaryloader so 375 88,System information OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from Binary TensorFlow version 1 3 0 Python version 2 7 CUDA cuDNN version 6 GPU model and memory GTX 840M 2GB Exact command to reproduce import tensorflow as tf When ever I try to import tensorflow 1 3 0 I encounter a ImportError where the system is unable to locate the shared library libnvidia fatbinaryloader so 375 88 I have looked in usr lib nvidia 375 and found that another version of the so exists 375 66 The issue is resolved if I downgrade to tensorflow version 1 2 1,,"tatatodd,allenlavoie,allenlavoie,gunan",2017-10-11 09:55:33,2017-10-18 03:53:59
PR,Branch 172543319,,,"vrv,vrv",2017-10-18 01:28:34,2017-10-18 05:40:11
PR,Branch 172556044,,,"vrv,vrv,vrv",2017-10-18 04:30:47,2017-10-18 05:44:34
IS,BeamSearchDecoder incorrectly truncates results when used with dynamic decode,System information irrelevant for this bug Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 Any TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 2 Continuum Analytics Inc Bazel version if compiling from source N A CUDA cuDNN version irrelevant GPU model and memory irrelevant Exact command to reproduce irrelevant Describe the problem tf contrib seq2seq BeamSearchDecoder incorrectly truncates some of the results because the same index was previously used for a beam member that ended at a earlier step The root of the problem is that the while loop body in dynamic decode assumes that sequences are independent and will finish only once In the same time BeamSearchDecoder creates a tree like structure where a beam index can be reused in a later step for a state that originates from a different parent index This causes the decoding loop to sometimes record the wrong sequence length for a beam member Then this wrong sequence length is passed to BeamSearchDecoder finalize which returns a truncated sequence Source code logs I use the following code to workaround the problem This causes the right sequence to be returned but still the length returned by dynamic decode is wrong,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-10-06 20:53:52,2017-10-18 05:45:06
PR,Fix minor typos in TF Boosted Trees,Fix minor typos in TF Boosted Trees,,,2017-10-17 20:53:48,2017-10-18 05:46:24
IS,Feature Request need to support dynamically RDMA gid setting in tensorflow tensorflow contrib verbs rdma cc,In tensorflow tensorflow contrib verbs rdma cc when calling ibv query gid the gid index field is hard coded as 0 which could not work well in real world To fix this it is better to add a user specified option,,,2017-10-18 08:23:38,2017-10-18 08:37:33
IS,Cannot install Tensorflow with specific GCC version,I'm trying to install Tensorflow 1 3 without success System information OS Platform and Distribution e g Linux Ubuntu 16 04 Gentoo TensorFlow installed from source or binary Trying from source TensorFlow version use command below 1 3 Python version 3 4 5 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 5 1 5 GPU model and memory GTX 960 Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem I'm trying to install Tensorflow 1 3 branch r1 3 from sources on my Gentoo machine The problem with the default compiler is that it it is a version 6 3 that is not supported by Tensorflow I have tried and got an error indicating that GCC later than 5 are not supported Therefore I need to specify a specific GCC version I'm setting it via CC CXX and in the installation for CUDA build action env GCC HOST COMPILER PATH usr bin gcc 5 4 0 But when I try to run bazel I got the following error gcc 5 4 0 error trying to exec 'cc1' execvp No such file or directory What can I do to install Tensorflow using usr bin gcc 5 4 0 and usr bin g 5 4 0 rather than usr bin gcc I have seen this f0faf5139819e2c6d7b0437d9e03ffce71c7d6e5 that seems releated but in my case this is already done And it seems to be used for clang compilation anyway Source code logs Loading complete Analyzing WARNING home wichtounet dev tensorflow13 tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' No longer supported Switch to SavedModel immediately WARNING home wichtounet dev tensorflow13 tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle gc' No longer supported Switch to SavedModel immediately Found 1 target Building 3 255 Writing file external snappy libsnappy a 2 params for host ERROR home wichtounet cache bazel bazel wichtounet bb5d0ce0cffd837b9339296f34d5478c external nasm BUILD bazel 8 1 C compilation of rule ' nasm nasm' failed crosstool wrapper driver is not gcc failed error executing command external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter remaining 34 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 gcc 5 4 0 error trying to exec 'cc1' execvp No such file or directory Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps Elapsed time 0 285s Critical Path 0 08s,,,2017-10-17 08:18:29,2017-10-18 12:13:20
PR,Add int64 axis support for tf cumsum and tf cumprod,This fix adds int64 axis support for tf cumsum and tf cumprod Though int64 is the registered data type for axis Tidx in math ops cpp the corresponding kernel is not available The issue could be described as This fix adds the missing kernels and adds additional test cases for them Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang",2017-10-17 20:15:31,2017-10-18 16:18:01
PR,add swish activation function to python ops,Swish activation function swish x x sigmoid x has just been published by the Google Brain team This is a simple implementation of the same in TF is python interface Ref,,"lakshayg,vrv,lakshayg",2017-10-18 15:22:18,2017-10-18 16:20:57
PR,gitignore ignore build files relevant for iOS sample apps,,,,2017-10-18 15:50:12,2017-10-18 16:22:45
IS,Tensorflow not detecting GPU even when CUDA is installed,Hi there I am running the following on Ubuntu 16 04 LTS and I have GPU 1070 and tensorflow version 1 0 1 installed and checked through conda list I am trying to run a simple piece of code in tf with tf device ' gpu 0' a tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 2 3 name 'a' b tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 3 2 name 'b' c tf matmul a b with tf Session as sess print sess run c And I am getting the following error InvalidArgumentError see above for traceback Cannot assign a device to node 'MatMul 1' Could not satisfy explicit device specification ' device GPU 0' because no devices matching that specification are registered in this process available devices job localhost replica 0 task 0 cpu 0 Regarding the CUDA installed I have the following information obtained by running nvcc version nvcc NVIDIA R Cuda compiler driver Copyright c 2005 2016 NVIDIA Corporation Built on Tue Jan 10 13 22 03 CST 2017 Cuda compilation tools release 8 0 V8 0 61 Theano is able to detect and use GPU Using gpu device 0 GeForce GTX 1070 CNMeM is disabled cuDNN 5110 How to get TF to use the GPU Or what CUDA version should I install to make it work with GPU I understand this is not the platform to ask questions related to CUDA but if someone can point me in the right direction then it will be helpful Thank You,,drpngx,2017-10-17 23:04:26,2017-10-18 17:53:57
PR,Add nth element op,This PR tries to settle the issue 13360 and add NthElement op in kernel and tf nn nth element wrapper for python As in std nth element this op finds values of the n th order statistic for the last dmension which the n th order statistic is equal to its n th smallest value Median is not a reduce fold operation technically this op could be a effective foundation of building reduce median or other quantile function This PR support CPU device only The internal implementation is based on std nth element which has fast average performance of O n and may has worst average performance of O n by introselect in some implementations like GCC 4 7 according to this blog I believe it is efficient enough in most of case And I enhance it in batch mode by multi thread I also add the unit tests both in core ops nn ops test cc and python kernel tests nth element op test py and register the gradient op accordingly The reason why I choose putting it in nn module is that I noticed tf nn top k which has the similar function did the same Furthermore I'm glad to contribute reduce median based on this op in the future If there is anything I need to modify please let me know Thank you for your review,,"jinze1994,alextp,jinze1994,alextp,jinze1994,alextp,caisq,jinze1994,alextp,jinze1994,alextp,jinze1994,vrv,jinze1994,alextp",2017-10-14 16:58:35,2017-10-18 18:22:25
PR,Allow num parameter in tf linspace to be int64,According to the API tf linspace is defined for num int32 or int64 However the C kernel only allows int32 even though the op in core ops math ops permits int64 too So I slightly changed the kernel to allow int64 too I also added tests for RangeOp and LinSpaceOp The following code shows the issue,,"codrut3,vrv,vrv,vrv,codrut3,vrv",2017-10-16 20:34:04,2017-10-18 18:23:02
PR,Update boringssl to a0fb951d2a26a8ee746b52f3ba81ab011a0af778,This fix update boringssl to a0fb951d2a26a8ee746b52f3ba81ab011a0af778 which contains bug fix related to 13733 See issuecomment 337440239 for update details Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,vrv,vrv,vrv,vrv,yongtang,vrv",2017-10-18 04:51:14,2017-10-18 19:10:56
IS,Tensorflow hangs during run call on some machines,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Debian 9 1 TensorFlow installed from source or binary Both TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 3 Bazel version if compiling from source 0 6 1 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce,,,2017-10-14 16:09:31,2017-10-18 19:15:42
IS,I do not understand why I get these errors when i used dict instead of and how could I solve it,This is the code is very similar to tensorflow tutorial but uses estimator instead of classifier 6 Definition del model def model fn1 features labels mode None params None config None 6 1 Connect the first hidden layer to the features x with relu activation hidden tf layers dense features x 10 activation tf nn relu 6 2 Connect the second hidden layer to the first hidden with elu activation hidden1 tf layers dense hidden 10 activation tf nn relu 6 3 Connect output to the the second hidden layer without activation out y tf layers dense hidden1 22 out y tf reshape out y 1 22 6 4 Provide an estimator spec for ModeKeys PREDICT if mode tf estimator ModeKeys PREDICT return tf estimator EstimatorSpec mode mode predictions '' out y predictions dict out y 6 5 Calculate loss using mean squared error and another approach loss tf losses mean squared error labels out y 6 6 Training sub graph optimizer tf train GradientDescentOptimizer learning rate 0 01 train op optimizer minimize loss loss global step tf train get global step 6 7 Calculate root mean squared error as additional eval metric eval metric ops rmse tf metrics root mean squared error tf cast labels tf float64 out y 6 8 Provide an estimator spec for ModeKeys EVAL and ModeKeys TRAIN modes return tf estimator EstimatorSpec mode mode loss loss train op train op eval metric ops eval metric ops 7 Creation of an estimator estimator1 tf estimator Estimator model fn model fn1 params None model dir ' home jennydariska targetDirectory project 1 project1 test ' 8 Running of our model with tf Session as session input fn tf estimator inputs numpy input fn x x x train y y train shuffle True num epochs None train input fn tf estimator inputs numpy input fn x x x train y y train num epochs None shuffle False eval input fn tf estimator inputs numpy input fn x x x eval y y eval num epochs 1 shuffle False 8 1 Training of the estimator estimator1 train input fn input fn steps 5000 8 2 Evaluation of how well our model did train metrics estimator1 evaluate input fn train input fn steps 500 eval metrics estimator1 evaluate input fn eval input fn print train metrics r train metrics print eval metrics r eval metrics print Loss s eval metrics loss 8 3 Prediction for the news samples predict input fn tf estimator inputs numpy input fn x x new samples num epochs 1 shuffle False predictions estimator1 predict input fn predict input fn print predictions for i in enumerate predictions print Prediction s i when i use i get this error ERROR tensorflow Object was never used type class 'tensorflow python framework ops Tensor' tf Tensor areport uninitialized variables 1 boolean mask Gather 0' shape dtype string If you want to mark it as used call its mark used method when i use dict i get this TypeError 'Tensor' object is not iterable I can not figure out where the problem lies,,,2017-10-17 11:00:46,2017-10-18 19:19:12
IS,Figure out CUDA and cuDNN versions,So I'm setting up an image for a group to be used in the cloud Given that there certain cloud related things which we do not have premissions to we want to be able to verify that Tensorflow is using indeed what we intended However there does not seem to be any comprehensive way of understanding at the moment what exactly is it using The output after creating a session is Does this means the cuda fails since I do not see any succesffully loaded libcuda or anthing like that Does it even load cuDNN Is there any way to directly check it once is enough do not need to be printed every time I did not find any documentations and there was not too much here in the issues except people not beeing able to do it,,,2017-10-18 11:00:20,2017-10-18 19:21:07
IS,freeze model graph failure,I can generate the pbtxt but freeze model graph failure I use tensorflow1 2 File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 178 in module Main File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 117 in Main module space FindModuleSpace File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 91 in FindModuleSpace sys argv 0 AssertionError Cannot find runfiles directory for Users gouwei tensorflow bazel bin tensorflow python tools freeze graph Traceback most recent call last File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 178 in module Main File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 117 in Main module space FindModuleSpace File Users gouwei tensorflow bazel bin tensorflow python tools freeze graph line 91 in FindModuleSpace sys argv 0 AssertionError Cannot find runfiles directory for Users gouwei tensorflow bazel bin tensorflow python tools freeze graph,,,2017-10-15 09:26:38,2017-10-18 19:22:42
IS,Packages missing in current channels tensorflow,I typed the following in the Anaconda Prompt conda create name IntroToTensorFlow python 3 anaconda source activate IntroToTensorFlow conda install c conda forge tensorflow Then it shows Packages missing in current channels tensorflow,,yaroslavvb,2017-10-17 02:53:15,2017-10-18 19:25:52
IS,error,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-17 23:06:04,2017-10-18 19:26:46
IS,graph editor uses deprecated API,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 TensorFlow installed from source or binary Source TensorFlow version use command below b'v1 3 0 21 gc701d19b2' 1 3 0 Python version 3 6 0 Bazel version if compiling from source 0 5 1 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See below You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem When I use graph editor my console fills up with dozens of repetitions of the following error message,,yaroslavvb,2017-10-16 19:17:59,2017-10-18 19:28:51
IS,Feature request Prevent predict scores in tf contrib learn estimators from reloading graph variables from checkpoint file everytime,Hi there I am using tf contrib learn DNNLinearCombinedRegressor with wide and deep feature columns in Tesnorflow 1 3 I use an input fn to parse pandas dataframes to this regressor for training I have both real and categorical features and so my deep feature columns are made of sparse columns with embedding as well as real valued columns After training I want to use the trained model for prediction in another application I can call estimator predict scores function to do this but it seems very slow Mainly because it seems to be reloading the graph variables from last checkpoint file created during training everytime it is called Can we prevent this for faster predictions so that it reloads the variables only the first time it is called My application is simple and I would like to not use Tensorflow serving Thanks,,"facaiy,martinwicke",2017-10-17 18:25:47,2017-10-18 19:42:18
PR,Add missing uint16 type registration for ops CropAndResize CropAndResizeGradBoxes,This fix adds missing uint16 type registration in image ops cc for CropAndResize and CropAndResizeGradBoxes The kernel of uint16 is available for CropAndResize and CropAndResizeGradBoxes though it is missing in image ops cc This fix addresses this issue This fix also adds incomplete test cases for CropAndResize Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv",2017-10-18 16:30:25,2017-10-18 19:48:14
IS,What will happen if one of the worker becomes dead in distribute tensorflow,Hi I deployed a distribute tensorflow cluster to train a Deep Neural Network system but in the training process one of the worker broke down for some unknown reason maybe the bad network while the other workers were still training data their training progresses did not stop and continued going on And after I restarted the broken worker the ps node could send data to the broken worker the broken worker also could train data with other workers but the amazing thing happened the good workers' training progresses were set to zero and they began to retrain the data with the broken worker node So my previous training progresses were all gone That is to say the tarining process restarted is there anybody know how to solve this problem My tensorflow version 0 10 0 Thanks in advance,,,2017-10-18 14:47:30,2017-10-18 22:05:35
IS,Steps in getting started guide are incorrect,Hi would appreciate if someone can help me get started It must be something very trivial but as a beginner I did not find an answer anywhere Looking for help 1 I had to refer to stack overflow for basic installation on windows 2 Even after that I get error as below just trying import tensorflow as tf This is same as which is closed and I could not find a solution anywhere Please let me know if more information is needed I am looking forward to get started successfully and learn tensor flow System information import tensorflow as tf windows 10 binary command below does not work downloaded the latest version just now Python version 3 6 3 Bazel version if compiling from source CUDA cuDNN version no idea GPU model and memory NA 32GB TAM Exact command to reproduce import tensorflow as tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION above command does not work and gives the same error,,,2017-09-12 08:48:18,2017-10-18 22:55:39
PR,Branch 172647355,vrv the release needed a push so I hope you do not mind went ahead and did one early and there was a conflict with the setup py file I updated the protobuf version but kept TensorBoard as is Please let me know if that is okay,,"av8ramit,jart",2017-10-18 21:42:06,2017-10-18 23:10:43
IS,program could not run in docker but could run on local machine,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS7 in local machine Ubuntu 16 04 2 LTS in docker image TensorFlow installed from source or binary TensorFlow version use command below v1 3 0 rc0 33 g6f0d70e 1 3 0 rc1 Python version 3 5 3 Bazel version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory M40 24G Describe the problem I could run my program on local machine but can not run on docker ubuntu image the stacktrace of the program in nvidia docker the 213 of 32 1 213 in stacktrace may change to 160 or other number as I change the GPU type M40 11G P100 15G in nvidia docker In local machine it could run without the stacktrace above,,,2017-10-17 09:47:26,2017-10-19 02:24:28
PR,Disable flaky tests in cmake build,,,"gunan,gunan,gunan,vrv,gunan,vrv",2017-10-18 18:22:41,2017-10-19 03:47:57
PR,Cherry pick in additional bug fixes to r1 4 branch,Fixes to Datasets S3 file system and a change to no longer set random seed in Estimator run config,,"case540,av8ramit,case540,vrv,vrv",2017-10-18 16:53:53,2017-10-19 06:16:50
IS,Feature Request Scripts for build tensorflow with FORTIFY,FORTIFY is an important security feature that can help us discover hidden bugs This is success story from Android Please do the same thing for tensorflow provide a checked build with FORTIFY turned on publicly,,"snnn,drpngx,snnn,drpngx",2017-10-18 09:45:56,2017-10-19 11:26:01
IS,Parsing TFRecords bug in TensorFlow v1 2,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra 10 13 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version 2 7 10 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See below Describe the problem I believe there is a bug in TensorFlow v1 2 The code below runs fine in v1 4 while erroring out in v1 2 Here is the code And again this works fine in TensorFlow v1 4 0rc0 that I tested Let me know if I should provide any more info,,"mrry,mrry,mrry,mrry,mrry,mrry,mrry",2017-10-16 17:03:41,2017-10-19 11:45:36
PR,R1 3,On Windows after reinstalling Anaconda3 I run the command conda create n tensorflow python 3 5 to create a tensorflow environment within Anaconda installation in the hidden user appdata folder Then I opened the new and updated navigator of anaconda Changed the environment from root to tensorflow I was given the option to install Spyder That I did Within minutes it installed Spyder within the tensorflow environment The first two Tensorflow programs in the guide ran perfectly and smoothly,,vrv,2017-10-19 12:22:31,2017-10-19 16:32:07
PR,fix the issue libcuda so 1 not found and add some minor changes,The newer version of Bazel i e when it comes to configure TensorFlow since it outputs more information that sometimes could be helpful such as TF BUILD INFO container type gpu command source HEAD bedfe8ac14bddbf21c5acf80d55abff9df4a7967 source remote origin OS Linux kernel 4 4 0 92 generic architecture x86 64 processor Intel R Xeon R CPU E5 2698 v4 2 20GHz processor count 80 memory total 528276076 kB swap total 0 kB Bazel version Build label 0 6 1 Java version 1 8 0 131 Python version 2 7 12 gpp version g Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 swig version NVIDIA driver version 384 81 CUDA device count 0 CUDA device names CUDA toolkit version V9 0 176,,"gunan,gunan,gunan,gunan,gunan,gunan,flx42,gunan,flx42,vrv,gunan,gunan,gunan",2017-10-18 16:28:29,2017-10-19 18:10:27
PR,Branch 172798007,,,"vrv,vrv,vrv,case540",2017-10-19 23:00:59,2017-10-20 00:34:13
PR,Fixes build breakage,,,"alextp,vrv",2017-10-20 00:53:53,2017-10-20 02:14:45
PR,Update resnet py,Test with mnist test set Previously it was testing on the training set,,gunan,2017-10-19 04:10:54,2017-10-20 02:20:45
PR,Cherry pick to disable S3 on windows and renamed serving input fn arg,,,case540,2017-10-20 00:50:32,2017-10-20 02:21:52
PR,Fix MPI and Verbs compilation when not using GPUs,Code compilation would fail when building without CUDA support but with MPI and or Verbs support This PR adds the required dependencies directly into the MPI Verbs BUILD files and fixes those compilation errors,,"jbedorf,vrv,jbedorf,vrv,vrv,allenlavoie,jbedorf,vrv",2017-10-18 08:44:31,2017-10-20 02:27:14
PR,Fix casting to size t for mkl conv filter dims,Here is the output from clang regarding explicit casting int64 to size t After modifying those lines I was able to compile successfully for CPU w MKL XLA,,vrv,2017-10-19 13:56:16,2017-10-20 03:24:14
PR,Add int64 out idx support for listdiff list diff setdiff1d,This fix tries to add int64 out idx support for listdiff list diff setdiff1d As was specified in docs tf setdiff1d doc it is possible to specify tf int32 or tf int64 for the type of the output idx However the tf int64 kernel has not been registered As a consequence an error will be thrown out if tf int64 is used This fix adds int64 out idx support for listdiff list diff setdiff1d Related test cases have been updated as well Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv,vrv,yongtang,vrv",2017-10-19 21:01:44,2017-10-20 03:34:54
PR,Fix makefile download dependencies sh on OSX,wget expects parameters before the URL on OSX tested on version 1 16 and 1 19 It would fail trying to use P as a URL Resolving p failed nodename nor servname provided or not known wget unable to resolve host address p,,"powderluv,vrv",2017-10-20 04:02:27,2017-10-20 06:07:56
IS,How to feed SparseTensor in C API,I trained model via python After training done I want to load the model and its checkpoint for prediction via C But I can not find any solutions about how to feed SparseTensor or Example in C API python train code In C all solutions I have found is to feed vector pair string Tensor into session Run However in my model I do not know which function in C I should use Thanks,,reedwm,2017-10-13 09:28:07,2017-10-20 07:13:03
IS,tf contrib data Dataset does not handle well with last elements with is fewer than batch size,tf contrib data Dataset does not handle well with last elements with is fewer than batch size Maybe batch size 10 but last batch has 9 elements,,"mrry,mrry",2017-10-16 11:09:18,2017-10-20 10:18:16
PR,Add GPU support and improve performance for tf diag and tf diag part,This PR tries to settle the issue 13491 and makes some contribution for tf diag and tf diag part Add GPU support Using a simple transfer trick makes code clear and easy to be parallel Rewrite the CPU code using the recent rewrite of matrix band part as a template which getting rid of the Eigen generator mechanism remove the restriction which the input rank is at most 3 Implementation of transfer trick can be described as follows According to the tf diag op definition output i1 ik i1 ik input i1 ik Let the rank of input is s1 sk then any offset of input is pointer can be represented by coordinate i1 ik where index i1 s2 sk i2 s3 sk ik Let new index is the offset of output is pointer with coordinate i1 ik i1 ik then we have Let size s1 sk we finally have new index index 1 size which is the transfer function we use below This trick make our implementations clear and easy to be parallel If there is anything I need to modify please let me know Thank you for your review,,"jinze1994,jinze1994,jinze1994,ekelsen,jinze1994,caisq,jinze1994,jinze1994,jinze1994,jinze1994,jinze1994,jinze1994,jinze1994,jinze1994,rmlarsen,jinze1994",2017-10-12 15:08:35,2017-10-20 15:20:03
IS,AttributeError module 'tensorflow' has no attribute 'estimator',Hi for some reason 'estimator' is not an attribute of 'tensorflow' when I test it on Mac When I try tf estimator Estimator model fn I get this error AttributeError module 'tensorflow' has no attribute 'estimator' This works fine in Linux though Upgrading pip conda tensorflow did not affect this behavior Is there a workaround Thanks System information Mac OS X 10 9 5 x86 64 apple darwin13 4 0 TensorFlow installed from binary TensorFlow version v1 3 0 rc1 3628 g49f9c6f89 1 5 0 dev20171020 Python 3 6 3,,,2017-10-20 15:44:43,2017-10-20 18:49:38
IS,cudnnGRU is training placeholder,When creating a model with batch normalisation I can supply a place holder for the is training param like so Error message TypeError Expected bool for argument 'is training' not tf Tensor 'Placeholder 2 0' shape unknown dtype bool,,,2017-10-20 18:02:46,2017-10-20 19:38:07
IS,while loop gradient failure with ints,This is puzzling gives the correct gradient ie grad 0 is tf Tensor 'gradients while Enter grad Exit 0' shape dtype float32 This is on tensorflow VERSION 1 3 0,,,2017-10-19 02:29:04,2017-10-20 19:40:28
IS,GPU Question dtype supports,According to gpu currently only supports floats In NLP tasks however there is no way around looking up the embedding matrix with int typed indices So I wonder if it on your shortlist to extend to int support If not how to get around the index lookup issue Thanks,,,2017-10-19 00:06:32,2017-10-20 19:42:15
PR,Add PlainSessionCreator,Not sure if this is desirable but I found this improves the usability of the SessionCreator interface When I use a factory to create session it is helpful that it can at least create session in the simplest way An example usage would be to write a train function that takes a SessionCreator and a bunch of other things,,"ppwwyyxx,ppwwyyxx",2017-10-19 19:08:14,2017-10-20 19:43:54
IS,CUDA 9RC cuDNN7,Things have moved forward I strongly suggest building from head with CUDA 9 and cuDNN 7 All of the necessary codes should be in the TF 1 4 tag but given we are still working on new features for FP16 I would build from head if that is of interest I do not like to share anything I have not personally tested as I know how frustrating trying to get things to compile can be Everything below this line is OUT DATED as of 19 OCT This is an unofficial and very not supported patch to make it possible to compile TensorFlow with CUDA9RC and cuDNN 7 or CUDA8 cuDNN 7 During testing on V100 Volta and ResNet 50 FP32 using CUDA 9RC cuDNN 7 was significantly faster than CUDA 8 cuDNN 6 which was not a surprise I am about to test on P100s I am sharing this patch informally so those that are interested can play with cuDNN 7 as well as CUDA 9RC before we have the official release As we have more interesting code e g FP16 models I will share it in this issue I expect NVIDIA will start to submit official cuDNN 7 patches very soon Note This patch may work on more recent versions of TensorFlow but it will likely bit rot so keep that in mind Apply the cuDNN 7 patch and then fast forwarding the branch might be the best approach My git skills are not strong so do what you think is best 1 Download the patches 0001 CUDA 9 0 and cuDNN 7 0 support patch eigen f3a22f35b044 cuda9 diff 2 Clone the tensorflow repo I have run this process myself on Ubuntu 14 04 with Python 2 7 Thank for NVIDIA for the early patch and who created most of these instructions If you are using Python 2 7 and gcc 4 8 here is a whl where I followed the instructions above and one with CUDA 8 and cuDNN 7 which I have yet to test Stress again this was created by me and not the TensorFlow build team My our goal is to engage with anyone that wants to try this out and try to have a little fun,,"tfboyd,byronyi,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,npanpaliya,npanpaliya,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,reedwm",2017-08-22 04:20:42,2017-10-20 20:07:12
PR,Update the C API guide Doc only should be in 1 4,Includes a documentation fix for 1 4 cc binary tf cc binary to avoid undefined symbols Adds the standard warning at the top that people may want the master branch Fixes,,allenlavoie,2017-10-20 16:54:02,2017-10-20 21:00:29
PR,updated unit test case,The following PR contains the required unit test case regarding issue and it also has a fix in another pull request,,"shreyneil,vrv,shreyneil",2017-10-20 19:37:27,2017-10-20 21:00:59
IS,wrong tf svd documentation in tensorflow 1 3 0 version,In tf svd documentation it was said that the tensorflow implementation of svd is simply np linalg svd in fact it was not the same in tensorflow the index for V matrix is transposed different from np linalg svd default setting Funny thing is this type of problem is a famous bug in matlab code people usually write which is row selection and transpose is not equal to transpose then column selection code demonstration,,"yaroslavvb,yaroslavvb,rmlarsen,rmlarsen,yaroslavvb",2017-09-25 19:27:24,2017-10-20 21:20:58
IS,compile source code fail on mac,System information OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version Python 2 7 10 Bazel version if compiling from source macbookpro tensorflow fredlee bazel version Build label 0 7 0 homebrew Build target bazel out darwin x86 64 opt bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Thu Oct 19 09 12 48 2017 1508404368 Build timestamp 1508404368 Build timestamp as int 1508404368 CUDA cuDNN version no GPU model and memory no Exact command to reproduce step by step according to this guide step1 git clone step2 cd tensorflow configure step3 create an example as step4 bazel run c opt tensorflow cc example example it return ld symbol s not found for architecture x86 64 clang error linker command failed with exit code 1 use v to see invocation Target tensorflow cc example example failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 3083 675s Critical Path 306 19s ERROR Build failed Not running target compile log compile log zip can you tell me how to make it work thanks best wishes,,"allenlavoie,drpngx,allenlavoie,MarkDaoust,allenlavoie",2017-10-20 09:57:04,2017-10-20 21:33:23
PR,Fix tf py func and Dataset from generator on Python 3,Cherry pick to make Dataset from generator work on Python 3 when the generator yields unicode strings,,"mrry,vrv,mrry,vrv,case540,mrry,case540,mrry",2017-10-20 04:19:38,2017-10-20 21:42:47
PR,Branch 172924803,,,"vrv,vrv,vrv,vrv",2017-10-20 20:32:08,2017-10-20 23:06:42
IS,No gradient defined for Relu6Grad,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes MWE below is not a stock example OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary Miniconda TensorFlow version use command below print tf GIT VERSION tf VERSION 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 13 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 61 CuDNN 5 1 10 GPU model and memory GeForce GTX TITAN X Total Memory 11 91GiB Exact command to reproduce See below Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request One can not apply the gradient operator to a nn Relu6 more than once Applying it once gives a Relu6Grad node applying it a second time i e applying it to the Relu6Grad throws an error Unless I have messed up my math quiet possible Relu6 is infinitely differentiable except at 2 points albeit very boring f x relu6 x df dx 1 if 0 x 6 else 0 d2f dxx 0 all further derivatives also 0 How ever it is marginally more interesting if one is applying the chain rule to it f x1 x2 relu6 x1 x2 df dx1 x2 if 0 x1 x2 6 else 0 d2f dx1x2 1 if 0 x1 x2 6 else 0 This is a feature request to make the gradient of Relu6Grad defined Source code logs MWE,,"aselle,facaiy",2017-09-19 04:40:33,2017-10-20 23:08:49
PR,ENH add Relu6GradGrad,Fix 13144,,"facaiy,alextp,facaiy,alextp,facaiy,facaiy,facaiy,facaiy,alextp,facaiy,alextp,facaiy,alextp,vrv,facaiy,vrv,facaiy,vrv",2017-09-24 03:37:11,2017-10-20 23:08:49
PR,Add known Dataset issue to RELEASE md,Adding info about issue using Unicode strings with Datasets to 1 4 release notes,,case540,2017-10-20 22:08:45,2017-10-20 23:10:17
PR,Merge two GPU kernel launching to one in DiagOp,The PR is the following update for the discussion discussion r146011795 of 13666 which tries to merge two GPU kernel launching to one launching in DiagOp as suggested,,"jinze1994,vrv",2017-10-20 17:54:28,2017-10-20 23:12:32
PR,Fix issues where int64 crops could not be passed to batch to space,This fix tries to address the issue where int64 crops could not be passed to batch to space even though both int32 and int64 are specified as supported in the docs tf batch to space doc The reason is that BatchToSpace kernel puts a constraint of int32 to crops data types This fix removed the constraint so that int64 crops could be supported NOTE Just removing the constraint should work and it is not necessary to add specification to the kernel class template as SubtleMustCopyFlat called in the class already correctly handled both int32 and int64 cases Besides other data types e g float or double will not be passed to the kernel as they are guarded by the specification in array ops cc Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv,vrv,vrv",2017-10-20 18:28:06,2017-10-20 23:36:32
PR,Variable name for the eager test,,,"alextp,vrv",2017-10-20 23:04:34,2017-10-20 23:57:14
PR,Fix crash when int64 axis is passed to tf reduce sum,This fix tries to fix the crash triggered by int64 axis passed to tf reduce sum The issue is caused by the fact that shape inference in common shape fns cc only assumes int32 without proper handling of diffent types In math ops cc both int32 and int64 are mentioned NOTE that this fix does not address the issue that int64 is not supported To allow int64 axis it is more than adding a template in ReductionOp as the type of the axis seems to be decided by some other ways in Eigen Will investigate that later This fix merely fixed the crash so that an error message will return without exit from the python program No OpKernel was registered to support Op 'Sum' with these attrs Still its worth to at least allow the program not to exit in case an error happens Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv",2017-10-20 18:31:16,2017-10-21 00:40:41
PR,Fix import of spatial softmax from tensorflow contrib layers,Currently spatial softmax cannot be imported from tensorflow contrib layers but has to be imported all the way from tensorflow contrib layers python layers,,"martinwicke,vrv",2017-10-19 14:37:52,2017-10-21 00:44:09
IS,compile failure with config mkl,Building from git 27767d8e9c1325979cf32ff5b81c10df9006fd57 with TF NEED MKL 1 and TF DOWNLOAD MKL 1 It seems d835d677ade78a41e0e097f67c87b6ab8588a90a introduced a compile failure,,,2017-10-17 19:39:35,2017-10-21 12:38:15
IS,android tensorflow demo build error external fft2d fft fftsg c 641 10 fatal error 'math h' file not found,Hi I succeeded build and install TensorFlow from sources with the link below But I could not build 'android tensorflow demo' under the guidance of the link below bazel build c opt tensorflow examples android tensorflow demo System information Have I written custom code as opposed to using a stock example script provided in TensorFlow none OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 11 6 TensorFlow installed from source or binary source TensorFlow version use command below tf VERSION 1 4 0 rc0 tf GIT VERSION b'v1 3 0 rc1 3399 g7cdd26f' tf COMPILER VERSION b'v1 3 0 rc1 3399 g7cdd26f' Python version 3 6 Bazel version if compiling from source Build label 0 6 1 homebrew CUDA cuDNN version none GPU model and memory none Exact command to reproduce bazel build c opt tensorflow examples android tensorflow demo Describe the problem I could not build 'android tensorflow demo' under the guidance of the link below bazel build c opt tensorflow examples android tensorflow demo My System OSX system has 'math h' header in Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include math h folder And I can check fftsg o fftsg d file below path bazel out host bin external fft2d objs fft2d external fft2d fft And fftsg d have math h path vi fftsg d bazel out host bin external fft2d objs fft2d external fft2d fft fftsg o external fft2d fft fftsg c Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include math h Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include sys cdefs h Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include sys symbol aliasing h Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include sys posix availability h Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include Availability h Applications Xcode app Contents Developer Platforms MacOSX platform Developer SDKs MacOSX10 12 sdk usr include AvailabilityInternal h By the way why do errors occur when building tensorflow demo Source code logs ERROR private var tmp bazel leebongjun 3584e4473c72a5166d05587429923d11 external fft2d BUILD bazel 21 1 C compilation of rule ' fft2d fft2d' failed Exit 1 external fft2d fft fftsg c 641 10 fatal error 'math h' file not found include math h 1 error generated Target tensorflow examples android tensorflow demo failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 2 271s Critical Path 0 39s,,drpngx,2017-10-15 06:28:52,2017-10-21 15:17:55
PR,Fix doc in TF CALL when invoked in mobile platform,This is a small doc fix that includes bool as part of the types that is supported in mobile as bool is clearly invoked in the following define See Ln 105 and Ln 135 in mobile platform Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-10-21 16:23:29,2017-10-21 17:06:46
PR,Update layers test py,Hello I have merged the two pull requests i have made earlier and with reference to the issue Please suggest if any more changes are required,,"shreyneil,vrv,shreyneil,vrv,vrv",2017-10-21 07:47:09,2017-10-21 17:15:38
IS,Error unknown op in C,I load a simple graph c a b in C and do prediction for c It gives right result but some errors unknown op occur What is the problem OS macOS 10 12 6 Tensorflow master build from source using makefile build all ios sh prediction cpp code,,"drpngx,drpngx,drpngx",2017-10-17 04:45:44,2017-10-21 18:58:29
IS,feature request more efficient tf eye,tf eye n creates a constant of size n 4 A better implementation would use Fill instead of constant This is similar to issue issuecomment 333893186 where zeros is getting refactored to use Fill instead of constant,,"yaroslavvb,drpngx,drpngx,drpngx,facaiy,yaroslavvb,drpngx",2017-10-18 23:03:59,2017-10-21 19:00:39
IS,how can i use TF SetTarget or TF SetConfig to set the number of threads in c code,Source code logs this is my c code TF SessionOptions sess opts TF NewSessionOptions std string str intra op parallelism threads 4 TF SetConfig sess opts void str c str str size status if TF GetCode status TF OK printf ERROR s n TF Message status this is the debug output Successfully imported graph ERROR Unparseable ConfigProto,,"drpngx,drpngx",2017-10-20 08:59:41,2017-10-21 19:13:16
IS,Variable rnn multi rnn cell cell 0 gru cell gates kernel already exists disallowed,Hello I wrote this code def rnn inputs FLAGS input data with tf variable scope 'rnn inputs' reuse True W input tf get variable W input FLAGS en vocab size FLAGS num hidden units num examples seq len num hidden units embeddings tf nn embedding lookup W input input data return embeddings def rnn softmax FLAGS outputs with tf variable scope 'rnn softmax' reuse True W softmax tf get variable W softmax FLAGS num hidden units FLAGS num classes b softmax tf get variable b softmax FLAGS num classes logits tf matmul outputs W softmax b softmax return logits class model object def init self FLAGS Placeholders self inputs X tf placeholder tf int32 shape None None name 'inputs X' self targets y tf placeholder tf float32 shape None None name 'targets y' self seq lens tf placeholder tf int32 shape None name iseq lens' self dropout tf placeholder tf float32 RNN cell stacked cell rnn cell FLAGS self dropout Inputs to RNN with tf variable scope 'rnn inputs' reuse True W input tf get variable W input FLAGS en vocab size FLAGS num hidden units inputs rnn inputs FLAGS self inputs X initial state stacked cell zero state FLAGS batch size tf float32 Outputs from RNN all outputs state tf nn dynamic rnn cell stacked cell inputs inputs sequence length self seq lens dtype tf float32 state has the last RELEVANT output automatically since we fed in seq len 0 because state is a tuple with a tensor inside it outputs state 0 Process RNN outputs with tf variable scope 'rnn softmax' reuse True W softmax tf get variable W softmax FLAGS num hidden units FLAGS num classes b softmax tf get variable b softmax FLAGS num classes Logits logits rnn softmax FLAGS outputs probabilities tf nn softmax logits self accuracy tf equal tf argmax self targets y 1 tf argmax logits 1 Loss self loss tf reduce mean tf nn sigmoid cross entropy with logits logits logits labels self targets y Optimization self lr tf Variable 0 0 trainable False trainable vars tf trainable variables clip the gradient to avoid vanishing or blowing up gradients grads tf clip by global norm tf gradients self loss trainable vars FLAGS max gradient norm optimizer tf train AdamOptimizer self lr self train optimizer optimizer apply gradients zip grads trainable vars Below are values we will use for sampling generating the sentiment after each word this is taking all the ouputs for the first input sequence only 1 input sequence since we are sampling sampling outputs all outputs 0 Logits sampling logits rnn softmax FLAGS sampling outputs self sampling probabilities tf nn softmax sampling logits Components for model saving self global step tf Variable 0 trainable False self saver tf train Saver tf all variables def step self sess batch X batch seq lens batch y None dropout 0 0 forward only True sampling False input feed self inputs X batch X self targets y batch y self seq lens batch seq lens self dropout dropout if forward only if not sampling output feed self loss self accuracy elif sampling input feed self inputs X batch X self seq lens batch seq lens self dropout dropout output feed self sampling probabilities else training output feed self train optimizer self loss self accuracy outputs sess run output feed input feed if forward only if not sampling return outputs 0 outputs 1 elif sampling return outputs 0 else training return outputs 0 outputs 1 outputs 2 But I faced this error while training ValueError Traceback most recent call last ipython input 19 93fd337a0d5c in module 1 train ipython input 18 62be6fa1e73e in train 9 10 Load old model or create new one 11 model create model sess FLAGS 12 13 Train results ipython input 17 0c9c27ad52d3 in create model sess FLAGS 1 def create model sess FLAGS 2 3 text model model FLAGS 4 5 ckpt tf train get checkpoint state FLAGS ckpt dir ipython input 15 bd33cb4f9d34 in init self FLAGS 18 with tf variable scope 'rnn inputs' reuse True 19 W input tf get variable W input 20 FLAGS en vocab size FLAGS num hidden units 21 22 inputs rnn inputs FLAGS self inputs X C Users Prof subhasis Anaconda31 lib site packages tensorflow python ops variable scope py in get variable name shape dtype initializer regularizer trainable collections caching device partitioner validate shape use resource custom getter 1063 collections collections caching device caching device 1064 partitioner partitioner validate shape validate shape 1065 use resource use resource custom getter custom getter 1066 get variable or local docstring 1067 s C Users Prof subhasis Anaconda31 lib site packages tensorflow python ops variable scope py in get variable self var store name shape dtype initializer regularizer reuse trainable collections caching device partitioner validate shape use resource custom getter 960 collections collections caching device caching device 961 partitioner partitioner validate shape validate shape 962 use resource use resource custom getter custom getter 963 964 def get partitioned variable self C Users Prof subhasis Anaconda31 lib site packages tensorflow python ops variable scope py in get variable self name shape dtype initializer regularizer reuse trainable collections caching device partitioner validate shape use resource custom getter 365 reuse reuse trainable trainable collections collections 366 caching device caching device partitioner partitioner 367 validate shape validate shape use resource use resource 368 369 def get partitioned variable C Users Prof subhasis Anaconda31 lib site packages tensorflow python ops variable scope py in true getter name shape dtype initializer regularizer reuse trainable collections caching device partitioner validate shape use resource 350 trainable trainable collections collections 351 caching device caching device validate shape validate shape 352 use resource use resource 353 354 if custom getter is not None C Users Prof subhasis Anaconda31 lib site packages tensorflow python ops variable scope py in get single variable self name shape dtype initializer regularizer partition info reuse trainable collections caching device validate shape use resource 680 raise ValueError Variable s does not exist or was not created with 681 tf get variable Did you mean to set reuse None in 682 VarScope name 683 if not shape is fully defined and not initializing from value 684 raise ValueError Shape of a new variable s must be fully defined ValueError Variable rnn inputs W input does not exist or was not created with tf get variable Did you mean to set reuse None in VarScope So I set reuse None but it showed another error ValueError Variable rnn inputs W input already exists disallowed Did you mean to set reuse True in VarScope Originally defined at File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework ops py line 1269 in init self traceback extract stack File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework ops py line 2506 in create op original op self default original op op def op def File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework op def library py line 767 in apply op op def op def I again set back reuse True which should be the case but this is error this time Variable rnn multi rnn cell cell 0 gru cell gates kernel already exists disallowed Did you mean to set reuse True in VarScope Originally defined at File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework ops py line 1269 in init self traceback extract stack File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework ops py line 2506 in create op original op self default original op op def op def File C Users Prof subhasis Anaconda31 lib site packages tensorflow python framework op def library py line 767 in apply op op def op def Can anybody help me with this,,drpngx,2017-10-21 15:20:17,2017-10-21 19:19:24
PR,Give each variable a unique name in accumulate n v2 eager test,,,"vrv,vrv",2017-10-21 17:44:26,2017-10-21 20:43:02
IS,tf image crop and resize return 0 values when using GPU on Jetson TX2,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-21 20:37:40,2017-10-21 20:47:29
IS,A very weird bug of tf debug Non Ok status env NewWritableFile file path f status Resource exaustated,System information Have I written custom code Yes OS Platform and Distribution CentOS TensorFlow installed from source or binary binary TensorFlow version 1 2 Python version 3 4 When I run the seq2seq model I got the nan loss Thus I use tf debug to find out where the problem occurs I use tf debug by sv tf train Supervisor logdir FLAGS log root is chief True saver saver summary op None save summaries secs 60 save model secs FLAGS checkpoint secs sess sv prepare or wait for session config tf ConfigProto allow soft placement True sess tf debug LocalCLIDebugWrapperSession sess sess add tensor filter has inf or nan tf debug has inf or nan But it got such logs and exit tfdebug Non OK status env NewWritableFile file path f status Resource exaustated tmp tfdbg 9 gcc3sc gradients output Reshape 1 grad Reshape 0 DebugIdentity 150023213 Aborted core dumped I think it is kind of issue related to tf debug and it may be new since I can not find anything when I google the error,,"asimshankar,asimshankar",2017-07-20 02:33:02,2017-10-22 01:25:48
IS,No OpKernel was registered to support Op 'StridedSlice',Wrong usage Fixed I trained a model via python and load the freeze model for prediction using c When running prediction binary some errors occur OS macOS 10 12 6 Tensorflow master built from source via makefile build all ios sh Deadly error,,"facaiy,facaiy,facaiy,facaiy",2017-10-17 05:32:14,2017-10-22 01:26:45
PR,Branch 172965466,,,"vrv,vrv,vrv,vrv,gunan,vrv,vrv",2017-10-21 17:05:26,2017-10-22 04:58:24
PR,R1 3,,,,2017-10-22 04:20:35,2017-10-22 05:04:26
PR,Update protobuf cmake to b04e5cba356212e4e8c66c61bbe0c3a20537c5b9,This fix tries to address the issue raised in 8187 where protobuf cmake used different version as bazel The reason for discrepancy was due to the fact that a customerized protobuf was needed with Windows patch Since the patch has been merged in it makes sense to update protobuf cmake so that the same version of cmake is used This fix fixes 8187 Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv",2017-10-22 00:24:17,2017-10-22 05:05:19
IS,tf image resize bicubic is 2x slower than opencv resize interpolation INTER CUBIC,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 3 Bazel version if compiling from source CUDA cuDNN version 8 6 GPU model and memory GCP Tesla P100 16Gb Exact command to reproduce tf image resize bicubic is 2x slower than opencv resize when used on input data with lots of channels 40 channels opencv 152 23ms tf 297 71ms With three channels they perform about the same opencv 11 02ms tf 11 76ms,,"reedwm,reedwm,yongtang",2017-10-13 16:16:20,2017-10-22 05:14:41
PR,Improve resize bicubic performance by reorganizing loops,This fix tries to address the issue raised in 13693 where performance of resize bicubic is subpar compared with opencv This fix rearranges the loops so that the logic for num channel 40 and num channel 3 are similar Before this PR num channel 3 is treated specially It looks like manual unrolling will improve the performance for num channel 3 So this PR keeps num channel 3 as a special case Pre fix This fix fixes 13693 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,vrv",2017-10-19 21:06:01,2017-10-22 05:14:41
PR,Add int64 axis support for reduction ops,This fix is a follow up to PR 13863 In PR 13863 the program crash is fixed if int64 axis is passed to reduction ops e g reduce sum reduce max etc However it does not process the case of int64 axis support it merely fixes the crash This fix adds the support for int64 axis of reduction ops reduce sum reduce prod reduce mean reduce max reduce min reduce all reduce any Test cases have been added as well Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,vrv",2017-10-21 22:13:10,2017-10-22 06:01:42
PR,protobuf lib path bug fix for benckmark on osx,bug info If not fixed usr local lib will before tensorflow contrib makefile gen protobuf host lib in the library search path It will cause undefined symbol problem of protobuf when building benchmark because of incompatibility of system installed protobuf fix Have tested on maxOS 10 12 6,,"vrv,vrv,vrv",2017-10-21 13:09:37,2017-10-22 06:02:51
PR,Update node def proto comments,The device field had outdated comments Note We could consider adding tpu as an example here e g gpu cpu tpu Thoughts,,"tayo,vrv,tayo,vrv,vrv,tadeegan,tayo,vrv",2017-10-21 00:20:05,2017-10-22 06:08:18
IS,No OpKernel was registered to support Op 'SegmentSum',ENV OSX 10 12 6 No GPU Tensorflow master Built from source by tensorflow contrib makefile build all linux sh Error info,,,2017-10-22 04:16:17,2017-10-22 12:59:55
PR,add segment reduction ops to tf op files,fix problem No OpKernel was registered to support Op 'SegmentSum',,vrv,2017-10-22 12:56:35,2017-10-22 19:05:08
IS,issue when installing Tensorflow,Hello I have tried to install tensorflow gpu version with pip3 install upgrade tensorflow gpu but I have got this error message can someone help me,,"Carmezim,drpngx,drpngx",2017-10-19 19:58:56,2017-10-22 23:51:38
IS,Feature Request Getting a collection of variable from specific Graph,Hi For debug purposes I need to create a collection variables from a specific graph I have defined my model in a predefined graph using something like pg tf Graph with pg as default I define my session as sess tf Session config config graph pg If I need to create a collection of trainable variable in graph pg I try to use tf get collection tf GraphKeys TRAINABLE VARIABLES or simply tf trainable variables It does not return anything If I do the same experiment using the default wouldefault graph' and without using 'with' constructs I am able to get the collection of variables I suspect tf get variables is not looking in pg I believe a method for extracting collection of variables from a given graph or device would be useful for everybody If the feature already exist please accept my apology for wasting your precious time I did check on stack overflow and other avenues suggested by Google Regards,,,2017-10-23 01:09:38,2017-10-23 01:14:45
IS,tfdbg does not work with tensorflow GPU version,Could the dear developers confirm that tfdbg works with tensorflow GPU version or not At least on my platform it does not work OS Red Hat Enterprise Linux Workstation release 7 3 Maipo Python Python 2 7 5 tensorflow 1 4 0rc0 compiled from source with CUDA enabled CUDA 8 0 61 cuDNN8 7 0 1 nVidia Quadro P5000 the code for reproducing the problem is as follows The phenomenon is after invoking stepper and steps for several steps it is reporting segmentation fault and exit I just wonder is it due to GPU issue,,"caisq,caisq",2017-10-22 11:33:01,2017-10-23 01:54:31
PR,nsync lib name change,Now the lib name is nsync a It will cause problem lnsync not found in cmake So change it to libnsync a,,"vrv,vrv,vrv",2017-10-22 04:54:33,2017-10-23 03:07:36
PR,Add int64 type multiples support for tf tile,In the doc of tf tile tf tile doc both int32 and int64 are supported for multiples However the kernel for int64 is not registered yet This fix adds the support of int64 multiples so that the behavior matches the description of the docs Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,vrv,yongtang,yongtang,vrv,yongtang,yongtang,vrv",2017-10-21 17:24:15,2017-10-23 05:33:19
PR,Add int64 padding support for MirrorPad,This fix adds int64 padding support for MirrorPad In the array ops cc the MirrorPad MirrorPadGrad has been specified as supporting int64 padding The related kernels does not have the int64 padding registered though This fix adds the int64 padding support This fix also adds additional test cases for coverage Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv",2017-10-22 23:22:22,2017-10-23 05:50:07
PR,Add int64 shape support on GPU for stateless random ops,This fix adds int64 shape support on GPU for stateless random ops StatelessRandomUniform StatelessRandomNormal StatelessTruncatedNormal The int64 shape for stateless random ops is already supported on CPU with int32 int64 processed properly through MakeShape However on GPU a type constraint TypeConstraint int32 T has been improperly added Such a type constraint actually prevents an int64 shape type to run on GPU As a comparision no type constraint on CPU This fix removes the type constraint and allows int64 shape to be run on GPU This fix also adds test cases for int64 shape support on stateless random ops Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,yongtang,vrv",2017-10-22 23:23:49,2017-10-23 05:50:21
PR,Add int64 Tperm type support for Transpose,This fix adds int64 Tperm support for Transpose In array ops cc Transpose and ConjugateTranspose have been specified as accepting int32 and int64 perm types However only int32 kernels has been registered This fix adds the int64 perm support by removing the constraint on Tperm resolve the type at runtime and copying the data type accordingly to correctly handle the int64 int32 types Additional tests have been added as well Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv",2017-10-22 23:30:18,2017-10-23 06:02:29
IS,Why do custom read op only works on test session,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 12 from anaconda Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce I'm using a cpu only tensorflow Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I wrote an custom kernel op in tensorflow for reading csv format data It works just fine in the TestCase with the sess object return by test session function When I turn to normal codes the reader op returns the same result every time Then I put some debug printing at the beginning of the MyOp Compute function It seems like after the first run the sess run myop never calls the MyOp Compute function at all Then I return to my test cases if I replace the session object with an tf Session instead of self test session it failed the same way Source code logs to share more details here is my mini demo codes major codes in test cases,,"drpngx,drpngx,drpngx,mrry",2017-10-21 17:21:08,2017-10-23 14:48:36
IS,feature request set some dimension in row shape to the maximum in each batch in tf contrib data Dataset dense to sparse batch,The docstring says row shape A tf TensorShape or tf int64 vector tensor like object representing the equivalent dense shape of a row in the resulting tf SparseTensor Each element of this dataset must have the same rank as row shape and must have size less than or equal to row shape in each dimension The row shape must be the same for every batch so if the elements are sequences it is necessary to know the maximum length beforehand It would be nice if it was possible to set some dimension of row shape to 1 meaning that this dimension will be the maximum for each batch just like padded batch,,"mrry,facaiy,mrry,facaiy,DjangoPeng,mrry",2017-09-21 17:13:06,2017-10-23 15:43:03
IS,deadlock in fork because of OpenBlas,TensorFlow 1 3 0 v1 3 0 rc2 20 g0787eee I'm not exactly sure whether this is a TF specific problem or OpenBlas specific or at what place this should be fixed At some part in my code I want to start a subprocess via Popen and it uses fork internally Before that I already initialized the TF session and thus have initialized the thread pools The fork will cause a deadlock because OpenBlas has used pthread atfork to register blas thread shutdown to do some cleanup which will wait for a lock which probably was acquired by some of the other threads at that time Stacktrace This OpenBLAS issue and this Sage issue might be related Basically the Sage solution is to disable the multi threading support of OpenBLAS by setting OMP NUM THREADS 1 but I actually want to use the multi threading support if possible,,"yaroslavvb,ppwwyyxx,yaroslavvb,drpngx,skye",2017-10-18 09:47:29,2017-10-23 16:05:20
PR,R1 3,,,,2017-10-23 06:17:41,2017-10-23 16:52:14
IS,In the estimator of Tensorflow how does it work when model fn is called multiple times,def model fn features labels mode params Model function for Estimator Connect the first hidden layer to input layer features x with relu activation first hidden layer tf layers dense features x 10 activation tf nn relu Connect the second hidden layer to first hidden layer with relu second hidden layer tf layers dense first hidden layer 10 activation tf nn relu Connect the output layer to second hidden layer no activation fn output layer tf layers dense second hidden layer 1 Reshape output layer to 1 dim Tensor to return predictions predictions tf reshape output layer 1 Provide an estimator spec for ModeKeys PREDICT if mode tf estimator ModeKeys PREDICT return tf estimator EstimatorSpec mode mode predictions ages predictions Calculate loss using mean squared error loss tf losses mean squared error labels predictions Calculate root mean squared error as additional eval metric eval metric ops rmse tf metrics root mean squared error tf cast labels tf float64 predictions optimizer tf train GradientDescentOptimizer learning rate params learning rate train op optimizer minimize loss loss global step tf train get global step Provide an estimator spec for ModeKeys EVAL and ModeKeys TRAIN modes return tf estimator EstimatorSpec mode mode loss loss train op train op eval metric ops eval metric ops Above is an example of the model fn used by Tensorflow is Estimator 1 As mentioned in the tutorial this model fn could be called in different context train predict evaluate However I'm a bit confused because each time the model fn is called instead of reusing existing graph it seems to create a new graph or create new node in the graph For example firstly I called model fn under TRAIN mode then I called model fn with PREDICT mode How can I make sure the PREDICT one is reusing the weight of the trained values 1,,"drpngx,MarkDaoust,drpngx,MarkDaoust,MarkDaoust,MarkDaoust,MarkDaoust,drpngx,martinwicke,ispirmustafa,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke",2017-10-22 03:27:24,2017-10-23 16:55:59
IS,Custom Reader Op Undeclared Inclusions,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom Code OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 4 0 Python version 2 7 Bazel version if compiling from source 0 6 1 CUDA cuDNN version Laptop CPU GPU model and memory Laptop CPU Exact command to reproduce bazel build c opt tensorflow core user ops rest api so cxxopt D GLIBCXX USE CXX11 ABI 0 Describe the problem I am getting undeclared inclusions for files in the tensorflow core framework directory I am not sure why this is happening since the user ops op lib in the tensorflow core BUILD has framework as its dependency Is there a missing dependency that needs to be added Source code logs BUILD File In tensorflow core user ops undeclared inclusion s in rule ' tensorflow core user ops rest api dependencies' this rule is missing dependency declarations for the following files included by 'tensorflow core user ops rest api cc' 'bazel out local opt genfiles tensorflow core framework op def pb h' 'bazel out local opt genfiles tensorflow core framework attr value pb h' 'bazel out local opt genfiles tensorflow core framework tensor pb h' 'bazel out local opt genfiles tensorflow core framework resource handle pb h' 'bazel out local opt genfiles tensorflow core framework tensor shape pb h' 'bazel out local opt genfiles tensorflow core framework types pb h' 'bazel out local opt genfiles tensorflow core lib core error codes pb h' 'bazel out local opt genfiles tensorflow core framework step stats pb h' 'bazel out local opt genfiles tensorflow core framework allocation description pb h' 'bazel out local opt genfiles tensorflow core framework tensor description pb h',,"allenlavoie,allenlavoie",2017-10-18 21:44:01,2017-10-23 17:12:30
PR,Branch 173060283,,,"vrv,vrv,yifeif,vrv,vrv",2017-10-23 03:31:26,2017-10-23 17:22:43
IS,tensorflow python framework errors impl InvalidArgumentError,I have run a tensorflow code which always give following errors tensorflow python framework errors impl InvalidArgumentError The node wouldiv 1' has inputs from different frames The input 'while Mean 1' is in frame 'while while ' The input wouldiv 1 y' is in frame '' And I have searched for a long time but find no proper solutions I really wonder that anyone could give me some advice,,drpngx,2017-10-23 13:02:51,2017-10-23 17:49:35
PR,Branch 173127955,,,"benoitsteiner,gunan,benoitsteiner,gunan",2017-10-23 16:50:46,2017-10-23 18:46:37
PR,Remove deprecated 32bit IOS builds,Apple has stopped supporting 32bit iOS builds staring with iOS11 Building these binaries are pretty much useless on iOS but saves a lot of time by just building arm64 and x86 64 TEST build ios libraries with build all ios sh,,"powderluv,vrv,petewarden,powderluv,powderluv",2017-10-20 22:35:48,2017-10-23 19:32:32
PR,Update build all ios sh to support per arch builds,,,"powderluv,powderluv,powderluv",2017-10-23 14:54:18,2017-10-23 19:41:34
IS,Inconsistent Result of SyncReplicaOptimizer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac Sierra 10 12 6 TensorFlow installed from source or binary Binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 5 2 Anaconda custom x86 64 Bazel version if compiling from source CUDA cuDNN version Not used GPU model and memory Not used Exact command to reproduce python synchronous sgd py see below Describe the problem Training a trivial model of 2 layer fully connected MNIST with one parameter server thread and one worker thread to reproduce this issue The file is linked here We run python synchronized sgd py and python async sgd py one after one in the same terminal so that they receive same random results to recreate the bug The only difference in the two files below is async comment out 10 trivial lines from sync Please diff I make sure both trainer receive the exactly same data for each batch and I also fixed the random seed As a results both model shall get exactly the same output However they do not The problem is after the first step the two models are in sync At exactly the second run of the train op this train op of the sync replica does not update the model nor does it update the global step resulting in output I read through the source code of SyncReplicaOptimizer and find out that the train op returned by that optimizer is a Assign operation which could be only executed after the grads were applied and global steps enqueued So sync and async with only one process should be exactly the same This behavior is mysterious to me now Not sure if I got anything wrong,,skye,2017-10-21 22:37:03,2017-10-23 22:25:10
IS,Build Error Unable to clone jsoncpp repo all others seem to be working,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Source from master branch TensorFlow version use command below Python version 3 6 2 Bazel version if compiling from source cmake 3 9 4 CUDA cuDNN version CUDA 9 0 cuDNN 7 GPU model and memory GTX 1080 Exact command to reproduce MSBuild filelogger m 4 p Configuration Release tf python build pip package vcxproj You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I have been trying to build the TensorFlow pip package For some reason while I have verified that the build is able to clone the other git repos the jsoncpp one seems to be killing my build Source code logs 42 CustomBuild Creating directories for 'jsoncpp' 42 CustomBuild Performing download step git clone for 'jsoncpp' 42 CustomBuild fatal could not create work tree dir 'jsoncpp' Permission denied 42 CustomBuild fatal could not create work tree dir 'jsoncpp' Permission denied 42 CustomBuild fatal could not create work tree dir 'jsoncpp' Permission denied 42 CustomBuild Had to git clone more than once 3 times 42 CustomBuild CMake Error at C Users Bryce Documents Programming os clones tensorflow tensorflow contrib cmake build jsoncpp tmp jsoncpp gitclone cmake 66 message Failed to clone repository '' And later on C Program Files x86 Microsoft Visual Studio 2017 Community Common7 IDE VC VCTargets Microsoft CppCommon targets 171 5 error MSB6006 cmd exe exited with code 1 C Users Bryce Documents Programming os clones tensorflow tensorflow contrib cmake build jsoncpp vcxproj msbuild log,,skye,2017-10-22 04:09:15,2017-10-23 22:26:05
IS,Conditional input to a sequence to sequence model word character hybrid network,I need to create a sequence to sequence model where in the encoder and decoder are both LSTM networks but the encoder takes the inputs from either of the following cases 1 Normal vector representation of a word Embedding vector when the word input is present in the vocabulary 2 Output of another LSTM network when the word is out of vocabulary and a separate character based LSTM is used to generate an embedding on the fly Consider the following example sentence The brown fox jumped over the lazy dog Assume these are the words present in the vocabulary The brown jumped over dog These words are fed to the seq2seq encoder as such out of vocabulary OOV words are fox lazy These words are passed to a character LSTM and the output of the same is passed to the seq2seq model along with the above words These both word level and character level encoder needs to be trained end to end simultaneously How do we model the input layer of the seq2seq model to achieve this scenario Reference paper,,"skye,skye",2017-10-22 16:54:43,2017-10-23 22:27:37
IS,Examples of GANs using tensorflow estimator,I found all the estimator examples in the tutorial assumes there is x features and y labels However in the context of GANs based method there is no y in the dataset Would there be any example of GANs using tensorflow estimator,,,2017-10-23 20:57:01,2017-10-23 22:48:52
IS,can not able to build android tensorflow inference java file in tensorflow,iam not able to android tensorflow inference java jar file in tensorflow using bazel when i build i got the following error how can i solve this bazel build tensorflow contrib android android tensorflow inference java Loading package Loading complete Analyzing Loading package tensorflow java Loading package third party java jarjar Loading package third party py six Loading package src main native windows Loading package ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 64 1 Traceback most recent call last File C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel line 64 create system images filegroups system image dirs system ima File C tools msys64 tmp bazel deemsys 28x4acs5 external bazel tools tools android android sdk repository template bzl line 298 in create system images filegroups int apidir split 1 invalid literal for int with base 10 N ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msvc' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msys' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msvc' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msys' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msvc' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msys' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msvc' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk windows msys' contains an error and its package is in error and referenced by ' androidsdk sdk 26' ERROR C tools msys64 tmp bazel deemsys 28x4acs5 external androidsdk BUILD bazel 8 1 Target ' androidsdk sdk 26' contains an error and its package is in error and referenced by ' androidsdk sdk' ERROR E arisai1 tensor tensorflow WORKSPACE 20 1 Target ' androidsdk sdk' contains an error and its package is in error and referenced by ' external android sdk' ERROR Analysis of target ' tensorflow contrib android android tensorflow inference java' failed build aborted Elapsed time 25 324s,,"skye,andrewharp",2017-10-23 12:03:20,2017-10-23 22:55:12
IS,'Numpy dangling symbolic links' when building from source,System information Fedora 26 x64 TensorFlow installed from source TensorFlow version commit 53e7541cf7efa61ba22c9f042e07031d87c8f145 oct 23 11 46 Python version 3 6 Bazel version 0 5 4 CUDA 8 0 cuDNN 8 0 v7 GPU model GTX 1060 bazel build c opt copt march native config cuda tensorflow tools pip package build pip package,,,2017-10-23 22:03:54,2017-10-23 22:57:02
PR,make data file configurable issue 13876,Fix issue 13876 Add fname argument to set the data file of CIFAR10 dataset Please check if it is acceptable to add the flexibility in this way If so I would like to update the cifar100 py mnist py and so on Should I make the PR in keras repo or here Do you think whether it is necessary to add the untar argument,,"DjangoPeng,DjangoPeng,fchollet,DjangoPeng",2017-10-23 12:26:17,2017-10-23 23:26:09
IS,Tensorflow error while building using gpu,ERROR home overlord cache bazel bazel overlord 38c05a5232666f398e07b83e8b030232 external lmdb BUILD bazel 8 1 C compilation of rule ' lmdb lmdb' failed crosstool wrapper driver is not gcc failed error executing command external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter remaining 33 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 external lmdb midl c In function 'MDB ID mdb midl alloc int ' external lmdb midl c 105 47 error invalid conversion from 'void ' to 'MDB IDL aka long unsigned int ' fpermissive MDB IDL ids malloc num 2 sizeof MDB ID external lmdb midl c In function 'void mdb midl shrink MDB ID ' external lmdb midl c 123 58 error invalid conversion from 'void ' to 'MDB IDL aka long unsigned int ' fpermissive ids realloc ids MDB IDL UM MAX 2 sizeof MDB ID external lmdb midl c In function 'int mdb midl grow MDB ID int ' external lmdb midl c 134 54 error invalid conversion from 'void ' to 'MDB IDL aka long unsigned int ' fpermissive idn realloc idn idn num 2 sizeof MDB ID external lmdb midl c In function 'int mdb midl need MDB ID unsigned int ' external lmdb midl c 148 50 error invalid conversion from 'void ' to 'MDB IDL aka long unsigned int ' fpermissive if ids realloc ids 1 num sizeof MDB ID Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps,,reedwm,2017-07-23 15:25:55,2017-10-24 01:38:12
PR,Use instead of to set MAKEFILES DIR to fix Android build flakiness,This change should fix Android build flakiness we see with error fatal error google protobuf stubs common h No such file or directory,,"annarev,gunan,annarev",2017-10-24 05:00:55,2017-10-24 06:30:09
IS,tensorflow android library 1 4 0 rc0 seems to contain tensorflow 1 3 0 rc2,For my work I require the new String Tensor feature introduced for the Java API in tensorflow 1 4 I tested my network with my Java code on my Desktop which works fine using org tensorflow tensorflow 1 4 0 rc0 However when I use the same code in an Android project using org tensorflow tensorflow android 1 4 0 rc0 I get the following error leading me to the guess that the wrong version was packaged I also downloaded the org tensorflow tensorflow android 1 4 0 rc0 from maven central and had a look at the class files They look like the class files from the 1 3 0 version Furthermore when looking at the Tensor and Tensorflow classes you can see that the version displayed in the error message above is actually read from the native library Do you agree or did I miss something If you do agree can you please upload a real 1 4 0 rc0 to maven central,,"andreas-eberle,drpngx,av8ramit,case540,andreas-eberle,andreas-eberle",2017-10-18 14:54:43,2017-10-24 08:29:38
PR,Fix AWS SDK missing symbols on Linux PPC,TF on linux ppc64le builds but when loading the environment some AWS related symbols are missing and thus resulting in a failure to load TF This patch adds the same file inclusions macro definitions to linux ppc as one does to linux x86 and this seems to fix the problem Error message reads,,"tjingrant,tjingrant,caisq",2017-10-19 14:26:54,2017-10-24 13:34:35
PR,Dockerfile devel Fixed broken bazel LICENSE url,no more txt extension to the bazel LICENSE file this results in HTTP 404 error during docker build,,,2017-10-24 13:08:31,2017-10-24 13:36:28
IS,Error in documentation programmers guide variables md,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 No TensorFlow installed from source or binary binary TensorFlow version use command below r1 3 Python version Irrelevant Bazel version if compiling from source Irrelevant CUDA cuDNN version Irrelevant GPU model and memory Irrelevant Exact command to reproduce Irrelevant Indentation is wrong The example code snippets from the bottom of chapter PROGRAMMERS' GUIDE Variables,,,2017-10-24 15:59:49,2017-10-24 16:05:51
PR,make smart cond api public and reusable,Fix 13903 Move the implementation of smart cond and constant value from tensorflow python layers utils to tensorflow python ops control flow ops and add corresponding test and expose smart cond to tensorflow python ops standard ops should I implement the API in this way or not As I think ops should be lower level API than layers and smart cond should be a kind of ops It is my first time to contribute to TensorFlow Please feel free to correct me if there is any problem with the design and codes,,,2017-10-24 05:27:18,2017-10-24 18:40:27
IS,How can I use all of cpu cores in android,Hi Thank your for your work In my app I use tensorflow to classify But CPU usage are lower just about 30 My device has 4 cores I want to use all CPUs to reduce cost time I try to modify intra op parallelism threads and inter op parallelism threads when compile the libtensorflow inference so And use TF SetConfig to set TF SessionOptions But it does not work Can you give me some advice thank you,,skye,2017-10-24 11:13:45,2017-10-24 19:33:31
IS,Create Model file for Object face Recognition in C,I am doing research on face Recognition using tensorflow Can I please know how how to use the code to create model file for face recognition Task required in C I have 5 folders each folder has 4 images of a particular person I would like to train the images and generate a model file from scratch I would then like to use the model file for recognizing one of the 5 persons Steps followed 1 Issues 1 Its in Python but I wanted in C 2 It is not training the model file from scratch 2 Issue Resolved Model can be trained from scratch Unresolved Issue Its in Python but I wanted in C Please help me in creating the model file in C,,skye,2017-10-24 12:08:03,2017-10-24 19:35:27
PR,Fix a typo of Jenkins,,,,2017-10-24 20:16:27,2017-10-24 20:59:28
PR,R1 3,,,av8ramit,2017-10-23 21:10:52,2017-10-24 23:43:17
PR,Use 'LABEL maintainer ' in Dockerfile,This fix is a follow up of 13661 to replace MAINTAINER with LABEL maintainer in Dockerfile The keyword MAINTAINER has long been deprecated and is replaced by LABEL which is much more flexible and is easily searchable through docker inspect This fix replaces remaining MAINTAINER with LABEL Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-10-24 23:50:01,2017-10-25 00:45:18
IS,tf Print return type,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 2 7 Exact command to reproduce Describe the problem tf Print is supposed to be an identity operation so I assume it should not change type from list to Tensor If we are not supposed to pass a list it should raise an error instead of changing the type,,"aselle,aselle,aselle,vrv,ebrevdo,aselle,ebrevdo",2017-07-23 19:11:43,2017-10-25 01:01:52
IS,ERROR Failed to load Skylark extension ' tensorflow workspace bzl',Environment info Operating System Ubuntu 16 04 Bazel version 0 5 2 python version 3 5 2 tensorflow version 1 2 0 Hello When I try this command bazel build tensorflow examples label image label image bazel bin tensorflow examples label image label image graph tmp output graph pb labels tmp output labels txt output layer final result image HOME piscine nvxpool cad image 182022 259650 1987 3303 jpg input layer Mul output layer 'final result' I have this error ERROR Failed to load Skylark extension ' tensorflow workspace bzl' It usually happens when the repository is not defined prior to being used Maybe repository '' was defined later in your WORKSPACE file ERROR cycles detected during target parsing I do not understand because before restarting my computer this command worked Do you have any ideas For information before restarting my computer I try this tutorial The section Getting Started Do you think the problem comes from there Thanks,,aselle,2017-07-24 07:08:20,2017-10-25 01:01:57
IS,First time of inference very slow on iOS,Describe the problem I tried to run the inference graph on iOS However the first run was very slow It gets faster at the subsequent runs My test inference graph is very simple and just with two features as input and run a logistic regression on it The first run on session run will take about 15ms to run The subsequent runs starting from the second run can go downs as low as 0 2ms I have seen a similar issue raise here topic discuss PDIBnp1ftxk Is it a common problem on the c runtime what cause this problem Is it the lib level initialization issue or the graph level I was not able to find any support about this on stackoverflow Can we have an option to prepare the graph in optimized state in order to eliminate problem with slow first run,,reedwm,2017-07-24 09:31:04,2017-10-25 01:02:01
IS,TimeDistributed keras wrapper broken in 1 4rc1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS Sierra TensorFlow installed from source or binary binary TensorFlow version use command below 1 4rc1 Python version 3 6 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See below Describe the problem Two issues I have found when testing the TimeDistributed wrapper in release 1 4rc1 I figure I would wrap them pun intended in one issue since they are both occur on the TimeDistributed wrapper See simple code examples below which both work fine in version 1 3 Source code logs,,fchollet,2017-10-24 21:36:27,2017-10-25 02:02:27
IS,Callback in tf Print to access raw data,System information Have I written custom code No OS Win 10 TensorFlow installed from binary TensorFlow version 1 3 0 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version CPU GPU model and memory CPU Exact command to reproduce Feature request The tf Print op lets us print tensor values when it gets evaluated However it does not provide any way to access the raw data programmatically AFAIK there is no way to access this data during computation Please correct me if I'm wrong With Theano I was able to provide a custom callback to the printing facility to access the tensor values when tensor was evaluated This is extremely useful for image tensors for instance to be able to plot them at evaluation time With TF I cannot do that Basically what I am proposing is adding a custom callback parameter to the op If callback is undefined tf Print behavior remains identical Otherwise tf Print will call the callback with values message name,,mrry,2017-10-25 04:05:31,2017-10-25 05:49:23
IS,ImportError cannot import name gen checkpoint ops,System information Have I written custom code No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary via pip TensorFlow version use command below 1 3 0 Python version 2 7 12 Exact command to reproduce from tensorflow contrib tensorboard plugins import projector Describe the problem Been following this tuturial from TF website to visualize embeddings using Tensorboard When running the code to add metadata the following error log returns The files gen checkpoint ops py and gen checkpoint ops pyc exist in the specified directory Would appreciate any hint,,,2017-10-24 11:31:30,2017-10-25 09:12:20
IS,import tensorflow error No Module Named ' pywrap tensorflow internal',Dear All I am new to the CNNs and Tensorflow I wanted to start my journey from Keras At this moment I facing problems with onstalling Tensorflow I am using Windows 10 I installed CUDA 9 with cuDNN 7 and was getting the following errors The I unstalled it and installed tensorflow gpu which automatically installs CUDA 8 with cuDNN 6 and I am still facing the same issue I tried installing Microsoft Visual C 2015 Redistributable Update 3 but with no results My Python version is 3 5 4 and I am using Anaconda 3 Do you have any ideas what else can I check Here is the error Traceback most recent call last File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Adam Anaconda3 envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Adam Anaconda3 envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Adam Anaconda3 envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 985 in gcd import File frozen importlib bootstrap line 968 in find and load File frozen importlib bootstrap line 957 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 938 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Adam Anaconda3 envs tensorflow lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Adam Anaconda3 envs tensorflow lib importlib init py line 126 in import module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,"Carmezim,Carmezim,Carmezim",2017-10-25 12:59:28,2017-10-25 15:36:35
IS,Build failure CUDA8 cudNN8 v7,System information Fedora 26 x64 TensorFlow installed from source TensorFlow version commit 53e7541cf7efa61ba22c9f042e07031d87c8f145 oct 23 11 46 Python version 3 6 Bazel version 0 5 4 CUDA 8 0 cuDNN 8 0 v7 GPU model GTX 1060 bazel build c opt copt march native config cuda tensorflow tools pip package build pip package Have tried bazel clean,,"skye,skye,skye,gunan,yifeif",2017-10-23 22:58:36,2017-10-25 17:20:42
IS,A unexpected read op is in my pb It make convertion to dlc fail,I want to conver the pb to dlc but fail I find a unexpected read op between the const and the op why how can I remove the read op conver error message home nubiaml snpe sdk snpe 1 2 2 lib python converters tensorflow layers eltwise py 105 RuntimeWarning error code 1002 error message Layer paramter value is invalid Layer layer2 Mul at least two inputs required have 1 error component Model Validation line no 582 thread id 140151840044864 output name home nubiaml snpe sdk snpe 1 2 2 lib python converters tensorflow layers eltwise py 83 RuntimeWarning error code 1002 error message Layer paramter value is invalid Layer output output at least two inputs required have 1 error component Model Validation line no 582 thread id 140151840044864 output name the code which save the pb import tensorflow as tf from tensorflow python framework graph util import convert variables to constants with tf name scope input X tf placeholder tf float32 shape None 1 name input with tf name scope layer2 a tf Variable tf zeros 1 1 tf float32 name a ax X a with tf name scope output b tf Variable tf zeros 1 1 tf float32 name b h tf add ax b name output y tf placeholder tf float32 shape None 1 name y J tf reduce mean tf square h y 2 optimizer tf train GradientDescentOptimizer 0 1 train optimizer minimize J var list a b sess tf Session sess run tf global variables initializer for i in range 10000 sess run train J feed dict X 1 2 y 1 2 print sess run a b graph convert variables to constants sess sess graph def output output tf train write graph graph ' ' 'graph pb' as text False sess close,,skye,2017-10-25 08:46:04,2017-10-25 17:26:26
PR,Update device string comments in node def proto,Clarifying comments for valid device string in NodeDef as discussed in PR 13874 Notes 1 The device string is as returned by device py to string 2 parse from string in device py seems currently allows an empty string for device type line 167 This commit reflects that Is this actually intended behavior 3 I notice our regex convention does not use ' ' e g XX instead of X,,"tayo,benoitsteiner",2017-10-25 16:46:54,2017-10-25 21:18:11
IS,tf contrib layers flatten has neither name nor reuse parameter,I think tf contrib layers flatten is just a special case of tf reshape However while tf reshape has name parameter tf contrib layers flatten does not have one Also neither of them has reuse parameter Is tf contrib layers flatten a deprecated API,,"skye,fchollet",2017-10-24 21:30:33,2017-10-25 21:20:25
IS,Doubt in definition of state returned by dynamic rnn for LSTM cell in tensorflow,Describe the problem Can someone tell me whether the state returned by the dynamic rnn function for a LSTM cell is h c or is c h c cell state h hidden state,,,2017-10-24 10:46:37,2017-10-25 21:21:39
PR,Update layers py,I have added a check on beta with reference to the following issue raised Please verify and get back Thank you I will add update the unit test cases to verify this patch,,"shreyneil,vrv,vrv,vrv,vrv,vrv,shreyneil,vrv",2017-10-19 11:18:05,2017-10-25 21:25:56
PR,Updated tf svd documentation to state u s v',Updated tf svd documentation to state the index for V matrix is transposed,,"rmlarsen,rmlarsen,rmlarsen,yaroslavvb,rmlarsen,rmlarsen,facaiy,rmlarsen,rmlarsen,rmlarsen,yaroslavvb,rmlarsen,vrv,rmlarsen",2017-10-20 07:32:08,2017-10-25 21:27:47
PR,WIP ENH only master is allowed to export model,Fix 13849 If the proposition is accepted I will add the corresponding test case later How to test add unit test pass all tests,,"facaiy,xiejw,facaiy,facaiy,xiejw,facaiy,xiejw,vrv",2017-10-20 08:26:08,2017-10-25 21:28:54
IS,Tensorboard not displaying event files,Hi all First time posting please forgive and correct me if i do anything wrong or stupid I have an issue where I am training a model but tensorboard is not displaying any data from the event files I have done everything in my knowledge Yes I read the tensorboard ReadMe FAQ frequently asked questions url I start the train process with the folowing command cmd started in folder with the directories tf files and flower photos int it python retrain py bottleneck dir tf files bottlenecks model dir tf files models mobilenet 0 50 224 summaries dir tf files training summaries mobilenet 0 50 224 output graph tf files retrained graph pb output labels tf files retrained labels txt architecture mobilenet 0 50 224 image dir flower photos retrain start 1 retrain start 2 retrain finish The retraining finishes successfully Tensorboard i start with the command tensorboard logdir i temp learningtf tf files training summaries start tensorboard The command above with inspect give me the following output tensorboard inspect 1 tensorboard inspect 2 As you can see tensorboard does not display anything Im quite confused tensorboard webinterface Here are the event files I'm talking about If these are not the files you need post a reply and tell my which files i need to upload please the i hope right files zip If you need eny further Info on this case please let me know Thanks for any help in advance,,,2017-10-24 19:03:31,2017-10-25 21:29:17
PR,Branch 173415707,,,"benoitsteiner,rmlarsen",2017-10-25 18:28:01,2017-10-25 21:32:50
IS,build tensorflow for gpu faild,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below r1 3 Python version 3 5 Bazel version if compiling from source 0 7 0 CUDA cuDNN version CUDA9 0 cuDNN7 GPU model and memory GTX 660M 2G memory Describe the problem I'm building tensorflow for gpu from source according to the official guide but alway faild error message show in below ERROR home dangerous cache bazel bazel dangerous 821f9ca421a3e885f021819a154f9a6e external nccl archive BUILD 33 1 output 'external nccl archive objs nccl external nccl archive src broadcast cu pic o' was not created ERROR home dangerous cache bazel bazel dangerous 821f9ca421a3e885f021819a154f9a6e external nccl archive BUILD 33 1 not all outputs were created or valid Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps,,caisq,2017-10-23 12:58:11,2017-10-25 21:33:22
PR,Fix typos,This PR fixes some typos prediciton iteraton,,"taehoonlee,benoitsteiner",2017-10-25 14:58:17,2017-10-25 22:11:59
IS,tf contrib distributions NegativeBinomial numerical stability inf,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I'm working on a negative binomial regression model and ran into inf nan values during training I was able to trace it back to the NegativeBinomial implementation and specificially when dealing with relatively large probability logits Example to demonstrate the issue which gives the correct probabilities for arbitrarily large probability logits I do not feel like creating a PR since I'm not convinced this is the most elegant solution and not sure whether this problem might exist at other placed in the code base for example other distribution types For now I made my own copy of BinomialDistribution with this fix included and I would like to invite you to verify the issue check the math and perhaps come up with a better solution Thanks,,"reedwm,jvdillon,jvdillon",2017-08-17 20:33:23,2017-10-25 22:35:32
IS,tf contrib distributions Additional Distributions,Are there plans to add additional distributions in the tf contrib distributions module like Scaled Inverse Chi Sq LKJ Gumbel etc Could mirror the distribution list supported by STAN,,"tatatodd,jvdillon",2017-08-06 05:46:33,2017-10-25 22:55:20
IS,Unstable numerics in MvNormal KL,L302 This line should look like this It yields NaN in grad KL q p if q p,,"asimshankar,jvdillon,jvdillon",2017-10-01 11:38:05,2017-10-25 23:46:31
PR,Fix mnist softmax tutorial W should be randomly initialized should,Fix mnist softmax tutorial W should be randomly initialized should not be initialized as zeros Otherwise you will get a symmetric NN But maybe for simplicity we can ignore this mistake,,MarkDaoust,2017-10-24 02:34:41,2017-10-26 00:53:16
IS,no input tensor in mobilenet v1 1 0 224 ckpt,I am newbie in TF and slim Sorry if this a basic question I downloaded mobilenet v1 1 0 224 ckpt built latest TF and TF slim tree and ran tensorflow tensorflow python tools inspect checkpoint py on it I dont find input tensors that are usually 224 224 3 or 112 112 3 etc size Am I missing something here mobilenet txt,,aselle,2017-07-24 07:53:11,2017-10-26 01:06:54
IS,Feature request have optimizers handle complex tensors,When a tensor that contains complex values reaches an optimizer it is cast to real This means that the net will not learn features that depend on the imaginary part of the tensor While we wait for the possible feature is there a workaround that you recommend I'm thinking of separating the real and imaginary parts before feeding the optimizer like turning a complex tensor C into R I would that work,,aselle,2017-07-26 03:00:12,2017-10-26 01:06:59
PR,Branch 173194115,,,"caisq,caisq,caisq,benoitsteiner,caisq",2017-10-24 01:50:01,2017-10-26 01:22:47
PR,Support fold batch norm for atrous conv2d,As we can fold batch norm with convolution we should also fold batch norm with atrous convolution which has not been implemented issue 13989,,,2017-10-26 09:16:50,2017-10-26 09:39:26
IS,How to output each class accuracy through modifing,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-26 10:55:01,2017-10-26 10:55:56
IS,GRU cell implementation different from Reference paper Cho 14,Hello I have been looking through GRUCell implementation on Tensorflow at tensorflow tensorflow python ops rnn cell impl py and got a bit confused The output of GRUCell is implemented as new h u state 1 u c However from the reference paper Cho 14 at I think it should be like new h 1 u state u c I am not sure if this is a bug or an intended variation from the reference Thank you,,drpngx,2017-10-19 01:57:38,2017-10-26 15:49:37
IS,Feature missing Ability to get Tensorboard output from provided estimators,This is opened here since it relates to Estimator and canned estimator models not providing a method to get output for TB 3 It should not be a TensorBoard issue And I attempted to get an answer at Stackoverflow here 46065066 I have been using the estimator interface in TF 1 3 including the creation of the data input function training input fn tf estimator inputs pandas input fn x training data y training label batch size 64 shuffle True num epochs None and building the NN dnnclassifier tf estimator DNNClassifier feature columns dnn features hidden units 1024 500 100 n classes 2 model dir ' tmp ccsprop' optimizer tf train ProximalAdagradOptimizer learning rate 0 001 l1 regularization strength 0 01 and executing it dnnclassifier train input fn training input fn steps 1500 After much searching I see no easy way to add tensorboard output without resorting to recreating the model from scratch and indicated here Following some of the help on SO TBcall tf train SummarySaverHook save steps 10 output dir ' tb' summary op tf summary merge all dnnclassifier train input fn training input fn steps 1500 hooks TBcall that gives this error Exactly one of scaffold or summary op must be provided The answer on SO has now been edited to show code from creating a model from scratch it seems So is there no way to get basic info from tf estimator DNNClassifier to Tensorboard And more generically from other tf estimators One would expect the canned estimators to provide this For model introspection and tuning,,"k-w-w,dandelionmane,martinwicke,ispirmustafa,martinwicke,martinwicke",2017-09-11 17:42:05,2017-10-26 16:09:53
IS,,,,,2017-10-26 17:16:45,2017-10-26 17:17:15
PR,Fix list formatting,Markdown needs a blank line before the list to render it correctly replace,,"MarkDaoust,benoitsteiner",2017-10-26 13:06:46,2017-10-26 17:26:44
PR,Add links and fix typos,Add links to the docs in GitHub to make it easier for contributors to find them Also fix some typos in the names of GitHub and TensorFlow and standardise capitalisation in headings,,benoitsteiner,2017-10-23 22:21:08,2017-10-26 17:43:15
PR,Branch 173553770,,,"benoitsteiner,benoitsteiner",2017-10-26 17:48:11,2017-10-26 18:18:48
PR,Branch 173560463,,,benoitsteiner,2017-10-26 18:08:05,2017-10-26 19:45:46
PR,R1 3,,,av8ramit,2017-10-26 04:17:02,2017-10-26 20:48:51
IS,ImportError libmpich so 12 cannot open shared object file No such file or directory,System information OS Ubuntu 17 10 TensorFlow installed from source TensorFlow version use command below r1 3 Python version 3 6 CUDA cuDNN version 8 0 6 When I try to import tensorflow I get error It did not work,,"skye,skye",2017-10-25 05:57:08,2017-10-26 21:26:58
IS,How to output each class accuracy,Using slim I can get the evaluation output Top 1 and Top 5 But how to calculate the accuracy for each class and output them Thanks,,Carmezim,2017-10-26 11:23:48,2017-10-26 21:58:29
IS,Compiling from source configure issue finding cudnn,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source 0 7 0 CUDA cuDNN version 7 GPU model and memory Nvidia 1070 8GB Exact command to reproduce On configure When following the building from source installation instructions the first step involves running a configure During this script you are prompted for the versions and locations of features you want support for in the build When getting down to the CUDA SKD version you will get something like Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to default to CUDA 8 0 9 0 I'm using 9 0 Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 7 0 I'm using 7 0 However if you type 7 0 you get the following Invalid path to cuDNN toolkit Neither of the following two files can be found usr local cuda 9 0 lib64 libcudnn so 7 0 usr local cuda 9 0 libcudnn so 7 0 usr lib x86 64 linux gnu libcudnn so 7 0 But if you answer the following as Please specify the cuDNN version you want to use Leave empty to default to cuDNN 6 0 7 It works The actual name is libcudnn so 7 can can not find libcudnn so 7 0 Otherwise it wo not find it and it looks like you have installed incorrectly Can we get a fix for this,,martinwicke,2017-10-26 10:30:14,2017-10-26 23:29:40
IS,Error when install tf from source,Branch master Command bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures Error Info Target tensorflow tools pip package build pip package failed to build ERROR home tianhz project tensorflow tensorflow tools pip package BUILD 139 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 crosstool wrapper driver is not gcc failed error executing command cd home tianhz cache bazel bazel FAREAST tianhz 1aaf3c53d4483e0897f98d9f35329906 execroot org tensorflow exec env CUDA TOOLKIT PATH usr local cuda 8 0 CUDNN INSTALL PATH usr local cuda 8 0 GCC HOST COMPILER PATH usr bin gcc PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 3 0 TF CUDA VERSION 8 0 TF CUDNN VERSION 5 1 10 TF NEED CUDA 1 TF NEED OPENCL 0 external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 DNDEBUG ffunction sections fdata sections ' march native' ' std c 11' ' march native' MD MF bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic d ' frandom seed bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic o' fPIC DEIGEN MPL2 ONLY DTENSORFLOW USE JEMALLOC DTF USE SNAPPY iquote iquote bazel out local linux opt genfiles iquote external nsync iquote bazel out local linux opt genfiles external nsync iquote external bazel tools iquote bazel out local linux opt genfiles external bazel tools iquote external jemalloc iquote bazel out local linux opt genfiles external jemalloc iquote external eigen archive iquote bazel out local linux opt genfiles external eigen archive iquote external local config sycl iquote bazel out local linux opt genfiles external local config sycl iquote external gif archive iquote bazel out local linux opt genfiles external gif archive iquote external jpeg iquote bazel out local linux opt genfiles external jpeg iquote external protobuf archive iquote bazel out local linux opt genfiles external protobuf archive iquote external com googlesource code re2 iquote bazel out local linux opt genfiles external com googlesource code re2 iquote external farmhash archive iquote bazel out local linux opt genfiles external farmhash archive iquote external fft2d iquote bazel out local linux opt genfiles external fft2d iquote external highwayhash iquote bazel out local linux opt genfiles external highwayhash iquote external png archive iquote bazel out local linux opt genfiles external png archive iquote external zlib archive iquote bazel out local linux opt genfiles external zlib archive iquote external local config cuda iquote bazel out local linux opt genfiles external local config cuda isystem external nsync public isystem bazel out local linux opt genfiles external nsync public isystem external bazel tools tools cpp gcc3 isystem external jemalloc include isystem bazel out local linux opt genfiles external jemalloc include isystem external eigen archive isystem bazel out local linux opt genfiles external eigen archive isystem external gif archive lib isystem bazel out local linux opt genfiles external gif archive lib isystem external protobuf archive src isystem bazel out local linux opt genfiles external protobuf archive src isystem external farmhash archive src isystem bazel out local linux opt genfiles external farmhash archive src isystem external png archive isystem bazel out local linux opt genfiles external png archive isystem external zlib archive isystem bazel out local linux opt genfiles external zlib archive isystem external local config cuda cuda isystem bazel out local linux opt genfiles external local config cuda cuda isystem external local config cuda cuda cuda include isystem bazel out local linux opt genfiles external local config cuda cuda cuda include no canonical prefixes Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' fno canonical system headers c tensorflow stream executor cuda cuda dnn cc o bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic o M INFO Elapsed time 654 834s Critical Path 213 07s M FAILED Build did NOT complete successfully M Other info Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below master r1 4 Python version 2 7 Bazel version if compiling from source 0 7 0 CUDA cuDNN version CUDA 8 0 cnDNN 5 1 10,,martinwicke,2017-10-23 11:46:50,2017-10-26 23:55:18
IS,Feature request only master is allowed to export for tf contrib learn Experiment,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 11 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 nightly 1 3 0 Python version 2 7 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem When using tf contrib learn Experiment for distributed training it seems that all workers ps and master try to export model when finished However this will cause write conflict when model dir is on hdfs because all write the same file to the same location Hence I propose that only master is allowed to export model I can work on it if tensorflowers are agreed Source code logs,,"facaiy,xiejw,facaiy",2017-10-20 07:27:05,2017-10-27 01:09:59
IS,TF fails to build on PowerPC Issues with BoringSSL,BoringSSL does not seem to have their own issue board So I'm guessing here is the closest alternative System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 LTS TensorFlow installed from source or binary source github master 10c871ed92a1d9b36c5e2e3a674d5812c67e82a1 TensorFlow version use command below does not compile Python version 2 7 12 Bazel version if compiling from source 0 6 1 CUDA cuDNN version not relevant GPU model and memory Nvidia K40 Exact command to reproduce,,"tjingrant,reedwm,gunan,tjingrant,gunan,tjingrant,gunan,tjingrant,gunan",2017-10-09 16:19:14,2017-10-27 01:30:41
IS,compile tensorflow 1 4 0 rc1 failed with error SWIGing tensorflow python tensorflow i failed Segmentation fault swig failed error executing command,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 beta2 TensorFlow installed from source or binary source TensorFlow version use command below TensorFlow 1 4 0 rc1 Python version Python 2 7 14 Bazel version if compiling from source bazel 0 6 0 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel build config mkl copt g copt DEIGEN USE VML copt mavx2 copt mfma copt O3 verbose failures copt L opt intel gcc lib64 s c opt tensorflow tools pip package build pip package You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Failed to use bazel 0 6 0 to compile tensorflow 1 4 0 rc1 on Ubuntu 17 10beta2 1 install Bazel download bazel 0 6 0 installer linux x86 64 sh bash bazel 0 6 0 installer linux x86 64 sh to install bazel source usr local lib bazel bin bazel complete bash 2 compile tensorflow configure bazel build config mkl copt g copt DEIGEN USE VML copt mavx2 copt mfma copt O3 verbose failures copt L opt intel gcc lib64 s c opt tensorflow tools pip package build pip package 3 compile failed Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem ERROR home automation tensorflow 1 4 0 rc1 tensorflow python BUILD 2953 1 SWIGing tensorflow python tensorflow i failed Segmentation fault swig failed error executing command cd root cache bazel bazel root 35d546f7441fd09e73ff30ea3d9aa112 execroot org tensorflow exec env bazel out host bin external swig swig c python module pywrap tensorflow internal o bazel out local opt bin tensorflow python pywrap tensorflow internal cc outdir bazel out local opt bin tensorflow python ltensorflow python client device lib i ltensorflow python client events writer i ltensorflow python client tf session i ltensorflow python client tf sessionrun wrapper i ltensorflow python framework cpp shape inference i ltensorflow python framework python op gen i ltensorflow python grappler cluster i ltensorflow python grappler cost analyzer i ltensorflow python grappler item i ltensorflow python grappler model analyzer i ltensorflow python grappler tf optimizer i ltensorflow python lib core py func i ltensorflow python lib core strings i ltensorflow python lib io file io i ltensorflow python lib io py record reader i ltensorflow python lib io py record writer i ltensorflow python platform base i ltensorflow python pywrap tfe i ltensorflow python training quantize training i ltensorflow python training server lib i ltensorflow python util kernel registry i ltensorflow python util port i ltensorflow python util py checkpoint reader i ltensorflow python util stat summarizer i ltensorflow python util tfprof i ltensorflow python util transform graph i Ibazel out local opt genfiles Iexternal eigen archive Iexternal grpc Iexternal protobuf archive Iexternal swig Iexternal boringssl Ibazel out local opt genfiles external local config python Iexternal nsync Iexternal gemmlowp Iexternal jpeg Iexternal com googlesource code re2 Iexternal mkl Iexternal jsoncpp git Iexternal zlib archive Iexternal highwayhash Iexternal gif archive Iexternal mkl dnn Ibazel out local opt genfiles external jpeg Iexternal lmdb Iexternal png archive Iexternal farmhash archive Iexternal sqlite archive Iexternal swig Lib Iexternal swig Lib cffi Iexternal swig Lib python Iexternal swig Lib std Iexternal swig Lib typemaps tensorflow python tensorflow i swig failed error executing command cd root cache bazel bazel root 35d546f7441fd09e73ff30ea3d9aa112 execroot org tensorflow exec env bazel out host bin external swig swig c python module pywrap tensorflow internal o bazel out local opt bin tensorflow python pywrap tensorflow internal cc outdir bazel out local opt bin tensorflow python ltensorflow python client device lib i ltensorflow python client events writer i ltensorflow python client tf session i ltensorflow python client tf sessionrun wrapper i ltensorflow python framework cpp shape inference i ltensorflow python framework python op gen i ltensorflow python grappler cluster i ltensorflow python grappler cost analyzer i ltensorflow python grappler item i ltensorflow python grappler model analyzer i ltensorflow python grappler tf optimizer i ltensorflow python lib core py func i ltensorflow python lib core strings i ltensorflow python lib io file io i ltensorflow python lib io py record reader i ltensorflow python lib io py record writer i ltensorflow python platform base i ltensorflow python pywrap tfe i ltensorflow python training quantize training i ltensorflow python training server lib i ltensorflow python util kernel registry i ltensorflow python util port i ltensorflow python util py checkpoint reader i ltensorflow python util stat summarizer i ltensorflow python util tfprof i ltensorflow python util transform graph i Ibazel out local opt genfiles Iexternal eigen archive Iexternal grpc Iexternal protobuf archive Iexternal swig Iexternal boringssl Ibazel out local opt genfiles external local config python Iexternal nsync Iexternal gemmlowp Iexternal jpeg Iexternal com googlesource code re2 Iexternal mkl Iexternal jsoncpp git Iexternal zlib archive Iexternal highwayhash Iexternal gif archive Iexternal mkl dnn Ibazel out local opt genfiles external jpeg Iexternal lmdb Iexternal png archive Iexternal farmhash archive Iexternal sqlite archive Iexternal swig Lib Iexternal swig Lib cffi Iexternal swig Lib python Iexternal swig Lib std Iexternal swig Lib typemaps tensorflow python tensorflow i,,"martinwicke,martinwicke",2017-10-25 05:15:21,2017-10-27 02:22:22
PR,Standardised caps on Virtualenv,Standardised capitalisation of the name Virtualenv,,benoitsteiner,2017-10-24 03:31:45,2017-10-27 02:22:54
PR,Fix documentation error in tf size,tf size returns a symbolic Tensor not an integer,,"ozabluda,ozabluda,benoitsteiner",2017-10-26 22:19:33,2017-10-27 02:55:03
PR,Changed GPU driver version assumption,Fixes 9669,,"tedhtchang,benoitsteiner,benoitsteiner,benoitsteiner",2017-10-25 19:50:27,2017-10-27 02:56:19
PR,Add int64 type multiples support for TileGrad,This fix is a follow up of 13884 to add int64 type of multiples support for TileGrad for completeness cc Signed off by Yong Tang yong tang github outlook com,,"yongtang,vrv,caisq,yongtang",2017-10-23 15:36:30,2017-10-27 02:57:41
PR,Add clang style check as part of the sanity check,This fix is an effort to add clang style check as part of the sanity check NOTE Not sure if this PR is relevant so feel free to close it if it does not make sense In CONTRIBUTING md it has been advised to run clang format style google file cc so that Google coding style is conformed However there is no sanity check in the current Jenkins build so current cc and h files in the repo are not really conforming to the coding style This actually causes issues In case a PR is submitted with clang format style google file cc the reviewer may see additional unrelated changes which might be a distraction The developer may also spent additional time to manually check for any discrepancies manually with additional unrelated style changes This fix adds the clang format check to the ci build so that when ci sanity sh is running it will use clang format to make sure the code is conforming to the coding style as specified in CONTRIBUTING md One thing that might need to take notice is the header order of the Eigen library See issuecomment 338718110 for further details Basically if Eigen headers could be placed in any order then no additional steps are needed Otherwise it is always possible to place the Eigen headers at the top then leave one empty line like In this way even a run of clang format i style google file cc will still respect the order and leave Eigen header at the top This PR is experimeal so it only checks tensorflow core ops directory Other files could be added if this PR is OK This PR also sanitizes all files in tensorflow core ops directory so that it conforms to coding style requirement Signed off by Yong Tang yong tang github outlook com,,"yongtang,yifeif,yongtang,caisq,yongtang,yongtang,yifeif,gunan,yongtang,yifeif,yongtang,benoitsteiner,yongtang,yifeif,benoitsteiner",2017-10-23 20:48:51,2017-10-27 03:04:59
PR,iOS RPi Add the ability to choose ANDROID TYPES FULL,Some networks require full types instead of slim so remove the hard coding of SLIM in iOS and RPi It still defaults to building SLIM for them if not ENV var is specified but now you can build with ANDROID TYPES D ANDROID TYPES FULL tensorflow contrib makefile build all ios sh TEST Verify the D ANDROID TYPES SLIM flag is default and you can override with an env var,,"powderluv,benoitsteiner",2017-10-26 22:39:16,2017-10-27 03:12:36
PR,support DepthwiseConv2dNative at file tensorflow python tools optimiz,support DepthwiseConv2dNative op when use python tools optimize for inference py,,,2017-10-27 07:00:26,2017-10-27 07:48:08
IS,TFRecords and Inference issues,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary conda TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory Nvidia quadro M6000 Exact command to reproduce I converted my dataset into TFrecords and trained my model using a custom Network Everything was quite fine until i tried to use the trained model by running an inference with the checkpoint files and the problems started there Without using the tf contib data Dataset line it produces the following error Traceback most recent call last File home sysgen files TENSOR FROZEN UNFREEZING NET py line 159 in module create graph File home sysgen files TENSOR FROZEN UNFREEZING NET py line 28 in create graph tf import graph def graph def name '' File home sysgen anaconda2 lib python2 7 site packages tensorflow python framework importer py line 285 in import graph def raise ValueError 'No op named s in defined operations ' node op ValueError No op named Iterator in defined operations This was also the same issue which i faced even for freezing the whole graph without importing the Dataset module I'm not able to move forward Even a normal restoring operation with saver restore fails FYI I know how to solve the issue but my actual question is why it occurs and why was it not happening when i pickled the dataset and fed in the data,,,2017-10-27 07:20:20,2017-10-27 12:12:00
PR,Add SANITY STEPS DESC for do clang format check,This fix is a follow up to PR 13924 to add the corresponding description in SANITY STEPS DESC See comment discussion r147314599 for details Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq",2017-10-27 13:57:50,2017-10-27 14:31:34
IS,Mixture of multivariate distributions,Consider a mixture of 2 dimensional Gaussians in TensorFlow This works because each MultivariateNormalDiag distribution has a batch shape of It is compatible with the Categorical is batch shape Now consider a mixture of 2 dimensional Bernoulli is or Gamma is or Laplace or StudentT is We need an equivalent MultivariateBernoulli MultivariateGamma etc distribution which allows us to fix the batch shape and increase the event shape Are there plans to make such distributions available What about edge cases such as a matrixvariate k variate Bernoulli where additional parameter dimensions determine the batch shape and the event shape is fixed at 2 k Issue motivated by,,"dustinvtran,dustinvtran,jvdillon",2017-07-06 00:18:20,2017-10-27 16:39:54
PR,fix broken link,,,"larrytin,benoitsteiner",2017-10-27 13:53:08,2017-10-27 16:40:50
PR,Set reuse False instead of reuse None and add suggestion for tf AUTO REUSE,As per we would like to change the message that contains reuse None to reuse False and suggest the use of tf AUTO REUSE,,benoitsteiner,2017-10-27 04:13:11,2017-10-27 16:41:59
IS,tensorflow building graph very slow for more than two hours when looping,Describe the problem Tensorflow is really slow when using loops A very simple code can even last for hours and this is strange Can anyone help me with issue Source code logs,,skye,2017-10-26 00:49:16,2017-10-27 17:17:08
IS,Proper way to handle csv input for cpu training,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 12 from Anaconda Describe the problem I am training some classification model with an 32 cpu Ubuntu machine and one of the problem is to feed data fast enough to the training process I am trying to read data from some csv file but the default tf csv or tf data module seems to be slow A speed test for reading 1000000 row 17 column csv file shows a speed like tf decode csv with queue and theads 192 seconds tf data 164 seconds hand write cpp reading op 25 seconds pure python code with help from pandas 23 seconds It is fast enough to use pandas for one single file but it might face the GIL problem if try to speed up with more threads Codes can be found below I am not sure if I use it the right way is there any official benchmarks or guidelines for this Source code logs The speed test is run through speed test py,,skye,2017-10-26 12:12:34,2017-10-27 17:31:30
IS,tf train start queue runners cannot run under GPU,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION python 3 5 cuda 8 0 cudnn 5 1 tensorflow 1 2 1 gpu memory Usage 95 gpu Load 30 cpu load 85 Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request When using tf train start queue runners in trainning the trainning process automatically goes into cpu mode when use tf device ' gpu 0' an error accur thats could not find the data in queue so how should i use queue runners tfrecords in GPU Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Main Trainning Code with tf Session as sess with tf device ' gpu 0' sess run init saver tf train Saver coord tf train Coordinator threads tf train start queue runners sess sess coord coord global step 1 if isTrain tf train write graph sess graph def ' MaxoutModel ' model pb as text True ckpt tf train get checkpoint state ' MaxoutModel ' if ckpt and ckpt model checkpoint path saver restore sess ckpt model checkpoint path print 'Load Model OK ' else print 'Load Model Error ' pass for i in range 100 learning rate decay max learning rate 0 02 min learning rate 0 0001 decay speed 16000 learning rate min learning rate max learning rate min learning rate math exp i decay speed tra images tra labels sess run img batch label batch sess run train step X batch X Y batch Y lr learning rate keep prob 0 75 if i 20 0 cost sess run cross entropy X tra images Y tra labels keep prob 1 0 if i 20 0 and i 0 saver save sess save path ' BNModel model ckpt' global step global step 1 saver save sess save path ' BNModel model ckpt' global step global step 1,,,2017-10-27 07:03:51,2017-10-27 17:37:23
IS,Raspberry example DecodeJpeg issue with Inception Retraining model,Environment info Operating System raspbian Steps to reproduce 1 Follow the contrib makefile README to install the tensorflow raspbian core lib 2 Run the pi example both successfully 3 Create inception model generally with the Tensorflow For Poets in Ubuntu 16 04 4 Retrain the model and get aretrained graph pb' and aretrained labels txt' 5 Run the pi example with those two files by tensorflow contrib pi examples label image gen bin label image image xxx jpg graph retrained graph pb labels retrained labels txt and get error log Invalid argument No OpKernel was registered to support Op 'DecodeJpeg' with these attrs registered device CPU registered kernels no registered kernels Node DecodeJpeg DecodeJpeg acceptable fraction 1 channels 3 fancy upscaling true ratio 1 try recover truncated false DecodeJpeg contents related 2883 And I have also read your blog tensorflow for mobile poets Is raspberry pi a mobile device cuz when I run the command tensorflow python tools optimize for inference in the file made by contrib makefile README it suggested that no such file or dictionery Any comment on what I do wrong many thanks,,skye,2017-10-27 09:18:04,2017-10-27 17:47:46
IS,tf train MonitoredTrainingSession does not have request stop method,I can not use mon ses request stop,,skye,2017-10-27 10:38:45,2017-10-27 17:48:17
IS,Complex matrix inverse inconsistency error,If I run the following code I obtain the inverse of a complex matrix However If I reduce 1E 4 times the values of the matrix the results should be the same apart of the 1E4 factor However it returns similar errors to the one found in 13558 Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 3 6 CUDA cuDNN version 5 5 GPU model and memory Nvidia Gforce GTX 1080ti,,,2017-10-27 16:48:22,2017-10-27 17:52:06
IS,ValueError raised when using AdamOptimizer but not for GradientDescentOptimizer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 1 TensorFlow installed from source or binary binary TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Python version 3 5 0 Source code logs Taken from this issue issuecomment 314688444 the below code reproduces the error Running this gives the error ValueError Variable w Adam 2 does not exist or was not created with tf get variable Did you mean to set reuse None in VarScope but when train model is changed to return the GradientDescentOptimizer the code compiles correctly I have tried following all the advice in the issue that relates to this but have not had any luck,,"drpngx,drpngx,martinwicke,lukaszkaiser,lukaszkaiser,martinwicke",2017-10-21 18:35:54,2017-10-27 18:08:02
PR,Add link to datasets doc,Link to datasets doc to make it easier to find,,"MarkDaoust,benoitsteiner,benoitsteiner",2017-10-26 19:14:42,2017-10-27 20:23:31
PR,avoid confict when installing pip3,When using parameterized docker build sh to build a tensorflow docker image from nvidia cuda 9 0 cudnn7 devel ubuntu16 04 There is code L259 that change pip to pip3 which will cause an error while installing pip3 because it change python pip to python pip3 error install pip,,gunan,2017-10-27 06:37:27,2017-10-27 20:56:17
PR,Branch 173716375,,,"benoitsteiner,benoitsteiner",2017-10-27 21:18:41,2017-10-27 22:23:00
IS,s390x support for google nsync,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary building from source TensorFlow version use command below master Python version Python 2 7 12 Bazel version if compiling from source 0 6 1 Exact command to reproduce bazel build c opt tensorflow tools pip package build pip package Tensorflow master build is failing on s390x platform with an error below Recently google nsync is added to Tensorflow master as an external dependency So s390x support needs to be added to nsync module which includes code changes in BUILD file as well as adding source code in nsync package for s390x We could create platform specific subdirectory inside nysnc builds for s390x by executing tools mkmakefile sh script Also could build nsync separately on s390x by executing command make depend test However Tensorflow also uses code from platform specific sub directories available inside nsync platform which has source code containing assembly instructions Need information on how to generate similar code structure for s390x we could see ppc windows arm etc platforms are supported As we are not able to create an issue on nsync repository could you please let me know whom to contact for this Note In Tensorflow nsync dependency is added through this commit,,"Nayana-ibm,gunan,Nayana-ibm,Nayana-ibm,Nayana-ibm,Nayana-ibm,Nayana-ibm,Nayana-ibm,Nayana-ibm",2017-10-17 09:08:47,2017-10-27 22:49:41
IS,s390x Tensorflow CI build failure,Hello Tensorflow CI build fails with an error,,"Nayana-ibm,Nayana-ibm,Nayana-ibm,gunan,Nayana-ibm,Nayana-ibm,gunan",2017-10-23 10:48:44,2017-10-27 22:56:12
PR,Fix documentation error in tf size output type,out type can be any non quantized numeric type not just int32 or int64 Also some formatting changes and sync docstrings of size and size internal,,"ozabluda,benoitsteiner",2017-10-27 17:56:40,2017-10-27 23:08:47
PR,Add double support for tf decode csv,In the current tensorflow tf decode csv accepts float int32 int64 string but not double It seems adding double support makes sense as StringToNumber already support double type This fix adds double support for tf decode csv Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner,benoitsteiner",2017-10-27 14:31:25,2017-10-27 23:09:16
PR,Fix incorrect annotation tag in the docs of tf Variable,In tf Variable the annotation tag of compatiblity missing i should be compatibility without the fix the rendering of docs may be incorrect See add check numerics ops for an example of compatibility L68 L72 Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner,yongtang,benoitsteiner",2017-10-27 14:28:51,2017-10-27 23:09:32
PR,Fixing the sources docs in master,,,"av8ramit,benoitsteiner",2017-10-27 21:01:24,2017-10-27 23:29:22
PR,tf zeros does not accept a tensor argument,ValueError Shape must be rank 1 but is rank 0 for 'zeros 2' op 'Fill' with input shapes,,"larrytin,benoitsteiner,larrytin,larrytin,benoitsteiner",2017-10-27 07:09:36,2017-10-28 05:11:56
PR,Fix an ouput typo in ci sanity sh,In the last PR 13924 clang sanity check the output message should be changed due to the absence of Python code changes due to the absence of h or cc code changes Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner",2017-10-27 14:50:45,2017-10-28 05:12:39
IS,'module' object has no attribute 'BasicLSTMCell',Hello guys I'm adopting a project of version 1 1 0 to version 1 2 1 Looks like some APIs have changed I'm new to tensorflow could someone tell what is the new APIs for those old ones below from tensorflow contrib rnn python ops import core rnn cell impl as rnn cell core rnn cell impl does not exist but I need BasicLSTMCell is in rnn cell Thank you very much Eric,,,2017-07-28 00:14:13,2017-10-28 12:50:48
PR,Fixes build breakage,,,,2017-10-28 15:30:37,2017-10-28 15:30:45
IS,Feature request add tensor xyz methods that redirect to tf xyz tensor,Any TensorFlow API function func that takes tensor as a first argument could be implemented as tensor func This is implemented in PyTorch numpy and can make formulas more concise Transpose is a frequent special case that deserves a shortcut like T cc for numpy API wisdom Compare Numpy,,"yaroslavvb,shoyer,yaroslavvb",2017-10-28 19:29:51,2017-10-28 20:19:54
PR,Branch 173772851,,,caisq,2017-10-29 01:22:47,2017-10-29 02:12:25
PR,Fix position of arguments of nce loss calculation on tensorflow basic tutorial,The nce loss positional arguments in word2vec simple py are incorrect leading to the following traceback Traceback most recent call last File word2vec simple py line 168 in module num sampled vocabulary size File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops nn impl py line 1151 in nce loss name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops nn impl py line 981 in compute sampled logits sampled logits math ops matmul inputs sampled w transpose b True File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops math ops py line 1844 in matmul a b transpose a transpose a transpose b transpose b name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops gen math ops py line 1289 in mat mul transpose b transpose b name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework op def library py line 526 in apply op inferred from input arg type attr TypeError Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a' This patch fixes the positional arguments of nce loss and adds keyword arguments to make it more explicit,,,2017-10-29 04:13:27,2017-10-29 04:27:26
IS,why do not work this code,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem My source code is this import tensorflow as tf import random import matplotlib pyplot as plt import numpy as np tf set random seed 777 def MinMaxScaler data numerator data np min data 0 denominator np max data 0 np min data 0 noise term prevents the zero division return numerator denominator 1e 7 training epochs 19 batch size 50 xy np loadtxt 'train csv' delimiter ' ' dtype np float32 read training data set xy2 np loadtxt 'test csv' delimiter ' ' dtype np float32 read test data set train x batch train y batch tf train batch xy 1 xy 0 1 batch size 50 train x batch2 train y batch2 tf train batch xy2 1 xy2 0 1 batch size 50 print x data shape y data shape check data shape nb classes 10 0 9 labels X tf placeholder tf float32 None 784 Y tf placeholder tf float32 None nb classes W tf Variable tf random normal 784 nb classes name 'weight' b tf Variable tf random normal nb classes name 'bias' hypothesis tf nn softmax tf matmul X W b made hypothesis using softmax cost tf reduce mean tf reduce sum Y tf log hypothesis axis 1 optimizer tf train GradientDescentOptimizer learning rate 0 1 minimize cost Test model is correct tf equal tf arg max hypothesis 1 tf arg max Y 1 Calculate accuracy accuracy tf reduce mean tf cast is correct tf float32 with tf Session as sess initialize tensorflow variables sess run tf global variables initializer Trianing for epoch in range training epochs avg cost 0 total batch int 950 50 for i in range total batch batch xs batch ys sess run train x batch train y batch c sess run cost optimizer feed dict X batch xs Y batch ys avg cost c total batch print 'Epoch ' ' 04d' epoch 1 'cost ' ' 9f ' format avg cost print Learning finished batch xs2 batch ys2 sess run train x batch2 train y batch2 acc accuracy eval session sess feed dict X batch xs2 Y batch ys2 print f acc Instructions for updating Use argmax instead WARNING tensorflow From x wingide python shell 43 arg max from tensorflow python ops gen math ops is deprecated and will be removed in a future version Instructions for updating Use argmax instead 2017 10 29 17 41 38 014455 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 10 29 17 41 38 014701 W C tf jenkins home workspace rel win M windows PY 36 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations And do not working where is problem,,,2017-10-29 08:44:11,2017-10-29 09:15:03
PR,Fix a minor typo in readme,,,,2017-10-29 22:05:13,2017-10-30 00:36:48
IS,Using XLA JIT Compilation results in bad alloc error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 0 1 0 ge895d5c dirty 1 0 1 Python version Python 3 5 2 Bazel version if compiling from source Build label 0 4 5 non git CUDA cuDNN version 8 0 5 1 GPU model and memory NVIDIA TX2 Exact command to reproduce python3 script py,,aselle,2017-07-25 01:05:27,2017-10-30 01:10:45
IS,Feature request Exporting TensorBoard graphs to vector graphics formats,As recently discussed on the TensorFlow mailing list it would be nice if TensorBoard would include an export function that supports exporting the graph in a vector graphics format e g SVG or EPS or both in addition to the current PNG export function For instance I recently bumped into a case where I wanted to include the TensorBoard graph as an example output of a tutorial section on TensorBoard in my book and found that the PNG version is too low res and not very helpful so that I had to manually redraw it Also I like to include TensorBoard graphs in reports some times after applying some stylistic changes and recently stumbled upon a browser utility called SVG crowbar that can get the graph from TensorBoard in SVG format with some workarounds This indicates that it may already be in SVG format and it would be nice to allow to export it to disk for styling and generating high res figures,,"rasbt,asimshankar,rasbt",2017-10-28 00:19:27,2017-10-30 02:15:29
IS,How to get difference or square between two tensor,I define two subnets that output the tensor of the same dimension use functional model I want get difference between them for example tensor1 1 2 3 4 5 tensor2 1 1 1 1 1 output tensor1 tensor2 Can you tell me how to get difference between two tensor or square of one tensor Thank you very much,,asimshankar,2017-10-30 02:02:16,2017-10-30 02:15:44
IS,' tensorflow contrib verbs rdma,Build fails Thanks for help in advance 1 It must be a bug System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary yes TensorFlow version use command below Latest git Python version 2 7 13 Bazel version if compiling from source Build label 0 5 2 CUDA cuDNN version Built on Tue Jan 10 13 22 03 CST 2017 Cuda compilation tools release 8 0 V8 0 61 GPU model and memory GeForce GTX 860M 4044MiB Driver Version 375 66 Exact command to reproduce bazel build c opt copt mavx copt mavx2 copt mfma copt mfpmath both copt msse4 2 config cuda tensorflow tools pip package build pip package Describe the problem Build fails with carefully chosen configs Please specify the location of python Default is home op anaconda2 bin python input the desired Python library path to use Default is home op anaconda2 lib python2 7 site packages y jemalloc as malloc support n Google Cloud Platform n Hadoop File System support y XLA JIT support y VERBS support n OpenCL support y CUDA support CUDA SDK version 8 0 CUDA 8 0 toolkit is installed usr local cuda 8 0 cuDNN 6 0 cuDNN 6 library is installed usr local cuda 8 0 Please note that each additional compute capability significantly increases your build time and binary size Default is 5 0 clang as CUDA compiler y N n nvcc will be used as CUDA compiler gcc should be used by nvcc as the host compiler Default is usr bin gcc MPI support y N n flags to use during compilation when bazel option config opt is specified Default is march native Source code logs ERROR home op Downloads tensorflow tensorflow contrib verbs BUILD 136 1 C compilation of rule ' tensorflow contrib verbs rdma' failed crosstool wrapper driver is not gcc failed error executing command external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter remaining 150 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 In file included from tensorflow contrib verbs rdma cc 18 0 tensorflow contrib verbs rdma h 21 30 fatal error infiniband verbs h No such file or directory include infiniband verbs h compilation terminated Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 3203 696s Critical Path 206 50s,,,2017-07-30 21:42:50,2017-10-30 11:20:25
PR,grammer fixed,fixed a small typo,,,2017-10-30 11:33:44,2017-10-30 11:35:00
IS,TF v1 3 slower than v1 2 when used with ResNets,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow It is a custom code with fully convolutional ResNet using tf slim implementation with diluted kernels OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 8 9 TensorFlow installed from source or binary Binary pip TensorFlow version use command below 1 3 Python version Python 3 4 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory NVIDIA K40m 12Gb I run fully convolutional ResNet 101 on the images which vary in size When moving from TF 1 2 to TF 1 3 inference became about 3x slower With TF1 2 I use CUDA 8 0 and cudnn 5 1 To make sure variable sized images are processed fast I set env variable TF CUDNN USE AUTOTUNE 0 to switch off auto tuning of convolutions In case it is not to do with convolutions but the data loading here is how I feed the input data numpy arrays into the convnet Could you suggest how I can troubleshoot that,,ppwwyyxx,2017-09-26 14:35:24,2017-10-30 14:53:49
IS,Error E tensorflow core common runtime direct session cc 138 Internal failed initializing StreamExecutor for CUDA device ordinal 0 Internal failed call to cuDevicePrimaryCtxRetain CUDA ERROR INVALID DEVICE,Hi I am working on a remote machine with many GPU cards that has CUDA v8 0 61 and Cudnn 5 1 10 installed Upgrading these is not possible because of permission rights In my own environment I installed TensorFlow version 1 2 1 but I get the following error when launching a Session Any ideas on the error E tensorflow core common runtime direct session cc 138 Internal failed initializing StreamExecutor for CUDA device ordinal 0 Internal failed call to cuDevicePrimaryCtxRetain CUDA ERROR INVALID DEVICE Running tf Session multiple times results in the same error but will increase the number behind ordinal,,,2017-10-30 13:20:15,2017-10-30 15:01:59
IS,Unable to use NeonDepthwiseConv2dNativeOp,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-10-30 15:09:26,2017-10-30 15:10:22
IS,bug when try train object detection in gcloud ImportError No module named 'tensorflow python eager',System information I tried to train the model using tensorflow objdet api OS Platform and Distribution Linux Ubuntu 16 04 gcloud VM TensorFlow installed from python pip TensorFlow version 1 3 0 Python version 2 7 Bazel version if compiling from source CUDA 8 0 cuDNN 6 0 The typical installation steps followed Describe the problem when i trying to train the Mobilenet model the following error came up I already trained using the same steps in my local PC without any errors I could not find any solution related to this error Source code logs ragulh28 ubuntu1gpu project models research object detection python train py logtostderr train dir training pipeline config path ssd mobilenet v1 lap config Traceback most recent call last File train py line 49 in module from object detection import trainer File home ragulh28 project models research object detection trainer py line 33 in module from deployment import model deploy File home ragulh28 project models research slim deployment model deploy py line 106 in module from tensorflow python eager import context ImportError No module named eager,,"caisq,caisq,martinwicke,caisq,martinwicke,asimshankar,gunan",2017-10-29 12:27:20,2017-10-30 18:26:26
IS,Bazel build for CUDA failed on Ubuntu w lastest tip CUDNN 6 0 CUDA 8 0,Hi I am trying to build latest TF with CUDNN 6 0 CUDA 8 0 on Ubuntu 14 but it failed with the following error message I found some similar issue reported in the past not sure if the latest tip has fixed it Any suggestion would be appreciated Thanks Build Command build command for CUDA that failed bazel build config opt config cuda tensorflow tools pip package build pip package build for CPU works well bazel build config opt tensorflow tools pip package build pip package System Info bazel version Build label 0 5 4 CUDA 8 0 CUDNN 6 0 TF origin master latest sync as 10 26 17 cb7cb40 Merge pull request 13972 from taehoonlee fix typos Error message ERROR PROJECT ROOT tensorflow tensorflow stream executor BUILD 52 1 undeclared inclusion s in rule ' tensorflow stream executor cuda platform' this rule is missing dependency declarations for the following files included by 'tensorflow stream executor cuda cuda blas cc' ' usr local cuda include cublas api h' ' usr local cuda include driver types h' ' usr local cuda include host defines h' ' usr local cuda include cuComplex h' ' usr local cuda include vector types h' ' usr local cuda include builtin types h' ' usr local cuda include device types h' ' usr local cuda include surface types h' ' usr local cuda include texture types h' ' usr local cuda include cuda fp16 h' ' usr local cuda include library types h' tensorflow stream executor cuda cuda blas cc In function 'cudaDataType t perftools gputools cuda anonymous CUDAComputationType perftools gputools blas ComputationType ' tensorflow stream executor cuda cuda blas cc 527 1 warning control reaches end of non void function Wreturn type,,"skye,gunan",2017-10-26 16:18:07,2017-10-30 18:52:02
PR,small unseen typos,small typos fixed see the changed files,,andrewharp,2017-10-30 11:58:37,2017-10-30 20:37:07
IS,how can i get a specific version of tf,platform raspbian 8 0 problem I need this specific release of tensorflow and does anyone have the repository of that version it needs to be a source file because of some specific situation and some difficulties that hard to solve I have to compile it from source and get a consequence similar to git clone recurse submodules but in the version of 1 1 0 related after bazel build in this guidance the contributor gave the command like this sudo pip install tmp tensorflow pkg tensorflow 1 1 0 cp27 none linux armv7l whl I do not know whether this command will have some influence but an release can adapt to this command will be ideal many thx,,asimshankar,2017-10-30 16:30:21,2017-10-30 20:38:26
PR,Support weight column for time series regressor,,,"terrytangyuan,allenlavoie,terrytangyuan,allenlavoie,terrytangyuan,terrytangyuan",2017-09-30 20:16:15,2017-10-30 21:24:48
IS,ci build CPU tests failing locally,System information Running docker on macOS Sierra 10 12 3 summary from ci build sh output below,,"gunan,gunan,gunan",2017-10-28 01:09:47,2017-10-30 22:48:20
PR,Branch 173904309,,,"andrewharp,andrewharp,andrewharp,andrewharp",2017-10-30 17:36:50,2017-10-30 23:42:07
IS,Memory Leak While Reading from TFRecord,Problem As I mentioned in my previous issue I have memory leak in my code Finally I can write a sample code that can reproduce the problem Source code I can not find the reason Many thanks for your consideration System information OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from binary TensorFlow version 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 6 CUDA cuDNN version NA GPU model and memory NA,,"mrry,mrry,ebrevdo,ebrevdo",2017-10-26 14:25:34,2017-10-30 23:42:45
PR,Fix minor typo,,,"larrytin,benoitsteiner,benoitsteiner",2017-10-28 01:47:33,2017-10-31 01:10:11
PR,Typo fix in file 'fully connected feed py',,,benoitsteiner,2017-10-27 14:31:37,2017-10-31 01:54:15
IS,LayerNormBasicLSTMCell causes bias key not found in checkpoint when layer norm False,When initializing LayerNormBasicLSTMCell it has a parameter layer norm which controls whether we want to enable layer norm or not I assume layer norm True should be set during training and layer norm False for evaluation However if I use this in an Estimator due to the following line L1331 it will not initialize the bias term because layer norm True resulting in a NotFoundError when loading the saved checkpoint with layer norm False What should be the expected behavior of this Should this cell applies the bias anyway regardless the layer norm If we do not use the bias during training I see no points to use it during inference,,"tatatodd,ebrevdo,tatatodd,ebrevdo,lukaszkaiser,ekelsen",2017-10-10 04:35:52,2017-10-31 02:09:31
IS,iOS No OpKernel was registered to support Op 'Prod' with these attrs,I'm trying to load the faster rcnn resnet101 coco model from the Tensorflow Object Detection model zoo onto the iOS camera example Currently I'm running in to the issue with If I try the same steps with the model ssd mobilenet v1 coco from the same model zoo it works fine I have also tried the instructions from JieHe96 iOS Tensorflow ObjectDetection Example but runs into the exact same problem Can anyone help,,jart,2017-10-30 23:11:27,2017-10-31 04:46:41
IS,GPU underutilized using DNNClassifier,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using stock code OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary from pip TensorFlow version use command below 1 3 1 1 4rc1 master Python version 3 5 Bazel version if compiling from source 0 7 CUDA cuDNN version CUDA 8 cuDNN 6 0 GPU model and memory NVidia GeForce 1070 8GB Exact command to reproduce run the above code for the estimator or see below Describe the problem Running this code results in GPU use of up to 5 10 of GPU resources measured using nvidia smi Changing the network nodes wo not improve performance Using derived code but essentially the same on much larger datasets increases GPU performance up to 25 I would expect max GPU utilization Memory allocation is in any case 100 Source code logs The code used is from here reproduced with minor fixes it wo not run on python3 otherwise,,jart,2017-10-30 21:45:47,2017-10-31 04:55:20
IS,Custom OP Reader AttributeError 'module' object has no attribute aread',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom Code OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 4 0 Python version 2 7 Bazel version if compiling from source 0 6 1 CUDA cuDNN version Laptop CPU GPU model and memory Laptop CPU Exact command to reproduce,,"allenlavoie,jart",2017-10-30 21:00:02,2017-10-31 05:01:08
IS,CUDNN STATUS INTERNAL ERROR,Hi I did not do anything but find all my programs about tensorflow could not work That is very strange that my two computers has the same error at the same time The error is showed here 2017 10 30 17 55 23 525428 E tensorflow stream executor cuda cuda dnn cc 371 could not create cudnn handle CUDNN STATUS INTERNAL ERROR 2017 10 30 17 55 23 525452 E tensorflow stream executor cuda cuda dnn cc 338 could not destroy cudnn handle CUDNN STATUS BAD PARAM 2017 10 30 17 55 23 525458 F tensorflow core kernels conv ops cc 672 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo T algorithms Aborted core dumped Thanks so much,,asimshankar,2017-10-30 23:05:13,2017-10-31 05:22:53
IS,Compiling TensorFlow 1 4 0 GPU on Windows 10 x64,There does not seem to be any detailed documentation for how to compile TensorFlow 1 4 0 GPU on Windows 10 x64 I need to recompile TF to add missing functionality for a Windows 7 x64 production system I can use Bazel or CMake to compile something but how do I incorporate the Python and NVIDIA dependencies into that build How are the Windows wheels at compiled,,"Carmezim,Carmezim,Carmezim,mrry,mrry,mrry,Carmezim,mrry",2017-10-25 01:25:51,2017-10-31 05:28:54
PR,Disable clang format check,Different clang format version can cause different formats with the same style option This check might be too strict Disable for now,,"yifeif,yifeif,yifeif,yongtang,yifeif",2017-10-31 01:00:32,2017-10-31 06:23:19
IS,How to print shape of tensors in tf contrib learn Estimator,tf contrib learn Estimator and tf contrib learn Experiment are very convenience to build a model But how to debug the user defined model For example in the Abalone Age Predictor example how to print shape of 'first hidden layer' isecond hidden layer' and 'predictions' in user defined 'model fn' function It is easy to print shape of tensors if we build a model with session and an example is as follows a tf Variable tf zeros shape 2 3 4 with tf Session as sess print sess run tf shape a By the way I also tried to debug Abalone Age Predictor example with tf python debug LocalCLIDebugHook but 'first hidden layer' isecond hidden layer' and 'predictions' are not in debug window Many thanks in advance,,jart,2017-10-31 05:01:25,2017-10-31 07:03:12
IS,A problem about AttentionWrapper,Hi It is different to use Bahdanau Attention and Luong Attention in seq2seq model When I use Bahdanau Attention I found a problem The hint said that when use Bahdanau Attention need to set the output attention False when create AttentionWrapper But if I set this parameter False I cant get the attention information in every timestamp and can not calculate the logits from both attention and cell output Is there any good way to get the attention of every timestamp And if simply use cell output to get the logits is quite similar with the way which both use attention and cell output Thx a lot,,jart,2017-10-29 15:14:46,2017-10-31 07:04:11
IS,Possible Memory Leak with Pet variant Detection model on Android,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version Python 3 6 1 Anaconda custom 64 bit Bazel version if compiling from source Build label 0 5 4 homebrew CUDA cuDNN version Not used GPU model and memory Not used Exact command to reproduce X Describe the problem When loading a trained from scratch sdd mobilenet v1 frozen inference graph pb in place of file for the TF Detect app the screen goes blank white and crashes without an error logged I have been following the pet example and have gotten passed the GraphDef Invalid error s In my case the problem occurs after I TensorFlowInferenceInterface TensorFlow native methods not found attempting to load via tensorflow inference I TensorFlowInferenceInterface Successfully loaded TensorFlow native methods RunStats error may be ignored When loading my custom ssd mobilenet model 5621 labels I assume the model fails to load because it hangs on the white screen before crashing and I dont see I TensorFlowInferenceInterface Model load took 502ms TensorFlow version 1 4 0 rc1 I TensorFlowInferenceInterface Successfully loaded model from 'file' One notable difference is my model file is 432M while the example is 28M 432M Oct 26 22 34 frozen inference graph pb 28M Oct 20 23 04 ssd mobilenet v1 android export pb When loading my model I have enabled large heap the Android profiler shows the memory used increases to around 2GB until the crash I have tried using the transform graph util though any produced pb file gives GraphDef invalid or does not fix the issue img width 1264 alt screen shot 2017 10 28 at 4 48 20 pm src Here is a summary of the pb file bazel bin tensorflow tools graph transforms summarize graph in graph frozen inference graph pb Found 1 possible inputs name image tensor type uint8 4 shape 3 No variables spotted Found 4 possible outputs name detection boxes op Identity name detection scores op Identity name detection classes op Identity name num detections op Identity Found 87826925 87 83M const parameters 0 0 variable parameters and 90093 control edges Op types used 85323 Const 33735 Gather 28107 Minimum 22484 Maximum 16964 Reshape 11281 Cast 11265 Sub 11248 Greater 11242 Split 11242 Where 5696 Slice 5683 ConcatV2 5682 Mul 5675 StridedSlice 5659 Pack 5658 Shape 5654 Add 5628 Squeeze 5624 Unpack 5621 ZerosLike 5621 NonMaxSuppression 229 Identity 48 Fill 45 ExpandDims 37 Tile 35 Relu6 35 FusedBatchNorm 34 Conv2D 28 RealDiv 28 Range 28 Switch 23 Enter 13 Merge 13 DepthwiseConv2dNative 12 BiasAdd 9 TensorArrayV3 7 NextIteration 6 Sqrt 5 TensorArrayWriteV3 5 TensorArrayGatherV3 5 Exit 5 TensorArraySizeV3 5 Assert 4 TensorArrayScatterV3 4 Equal 4 TensorArrayReadV3 3 Rank 3 Transpose 2 All 2 Exp 2 GreaterEqual 2 LoopCond 2 Less 1 LogicalAnd 1 TopKV2 1 Size 1 ResizeBilinear 1 Placeholder 1 Sigmoid To use with tensorflow tools benchmark benchmark model try these arguments bazel run tensorflow tools benchmark benchmark model graph frozen inference graph pb show flops input layer image tensor input layer type uint8 input layer shape 1 1 1 3 output layer detection boxes detection scores detection classes num detections Is this a memory leak I do not think the app should be in the GB is Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem tensorflow examples android src org tensorflow demo TensorFlowObjectDetectionAPIModel java tensorflow examples android src org tensorflow demo DetectorActivity java from models models research object detection create pet tf record py models research object detection export inference graph py ssd mobilenet v1 config,,jart,2017-10-28 23:45:34,2017-10-31 07:07:54
IS,Feature request Exporting TensorBoard graphs to graphviz DOT files,As recently discussed on the TensorFlow mailing list it would be nice if TensorBoard would have an option to export a graph as graphviz DOT file This would allow users and developers to create e g Python packages based on pygraphviz that can further modify the graph structure such as simplifying or summarizing the graph ops into a publication ready figure etc For example scikit learn has such a function to export decision trees to DOT files maybe the source code is useful as an example L74,,"rasbt,rasbt,jart",2017-10-28 00:24:51,2017-10-31 07:18:06
IS,Feature request support convert python object to tensor automatical and can back to object in py func or other mechod,I want to use python object as tensor in Tensorflow and can convert it back to object when useing tf py func method to support using other python package,,jart,2017-10-29 13:33:43,2017-10-31 07:45:47
IS,Failed to run the benchmark model,System information Have I written custom code No OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from source TensorFlow version 'v1 3 0 rc1 1951 g04c318b' '1 3 0' Python version 2 7 12 Bazel version if compiling from source 0 5 0 CUDA cuDNN version 8 0 5 1 GPU model and memory Quadro M4000 8Gb Exact command to reproduce bazel bin tensorflow tools benchmark benchmark model graph inception5h tensorflow inception graph pb input layer input 0 input layer shape 1 224 224 3 input layer type float output layer output 0 show run order false show time false show memory false show summary false show flops true Problem I follow the instruction on to run the benchmark model on desktop but it failed when I set the show flops true The tensorflow inception graph pb is downloaded from the link provided on the page Logs my project ubuntu ubuntu desktop Desktop virtualroiflow tensorflow bazel bin tensorflow tools benchmark benchmark model graph inception5h tensorflow inception graph pb input layer input 0 input layer shape 1 224 224 3 input layer type float output layer output 0 show run order false show time false show memory false show summary false show flops true 2017 09 13 17 53 21 911797 I tensorflow tools benchmark benchmark model cc 426 Graph inception5h tensorflow inception graph pb 2017 09 13 17 53 21 911837 I tensorflow tools benchmark benchmark model cc 427 Input layers input 0 2017 09 13 17 53 21 911841 I tensorflow tools benchmark benchmark model cc 428 Input shapes 1 224 224 3 2017 09 13 17 53 21 911844 I tensorflow tools benchmark benchmark model cc 429 Input types float 2017 09 13 17 53 21 911846 I tensorflow tools benchmark benchmark model cc 430 Output layers output 0 2017 09 13 17 53 21 911852 I tensorflow tools benchmark benchmark model cc 431 Num runs 1000 2017 09 13 17 53 21 911870 I tensorflow tools benchmark benchmark model cc 432 Inter inference delay seconds 1 0 2017 09 13 17 53 21 911873 I tensorflow tools benchmark benchmark model cc 433 Inter benchmark delay seconds 1 0 2017 09 13 17 53 21 911877 I tensorflow tools benchmark benchmark model cc 435 Num threads 1 2017 09 13 17 53 21 911894 I tensorflow tools benchmark benchmark model cc 436 Benchmark name 2017 09 13 17 53 21 911897 I tensorflow tools benchmark benchmark model cc 437 Output prefix 2017 09 13 17 53 21 911900 I tensorflow tools benchmark benchmark model cc 438 Show sizes 0 2017 09 13 17 53 21 911917 I tensorflow tools benchmark benchmark model cc 439 Warmup runs 2 2017 09 13 17 53 21 911920 I tensorflow tools benchmark benchmark model cc 54 Loading TensorFlow 2017 09 13 17 53 21 911941 I tensorflow tools benchmark benchmark model cc 61 Got config 0 devices 2017 09 13 17 53 21 912358 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2017 09 13 17 53 22 022462 I tensorflow stream executor cuda cuda gpu executor cc 892 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 09 13 17 53 22 022832 I tensorflow core common runtime gpu gpu device cc 965 Found device 0 with properties name Quadro M4000 major 5 minor 2 memoryClockRate GHz 0 7725 pciBusID 0000 01 00 0 totalMemory 7 93GiB freeMemory 7 61GiB 2017 09 13 17 53 22 022864 I tensorflow core common runtime gpu gpu device cc 1055 Creating TensorFlow device device GPU 0 device 0 name Quadro M4000 pci bus id 0000 01 00 0 compute capability 5 2 2017 09 13 17 53 22 078421 E tensorflow core framework op kernel cc 1142 OpKernel 'op Fact device type CPU label sergey ' for unknown op Fact 2017 09 13 17 53 22 078460 E tensorflow core framework op kernel cc 1142 OpKernel 'op Fact device type CPU label Sergey ' for unknown op Fact 2017 09 13 17 53 22 078466 E tensorflow core framework op kernel cc 1142 OpKernel 'op Fact device type GPU host memory arg fact ' for unknown op Fact 2017 09 13 17 53 22 081269 I tensorflow tools benchmark benchmark model cc 291 Running benchmark for max 2 iterations max 1 seconds without detailed stat logging with 1s sleep between inferences 2017 09 13 17 53 22 173360 I tensorflow tools benchmark benchmark model cc 324 count 2 first 59501 curr 32424 min 32424 max 59501 avg 45962 5 std 13538 2017 09 13 17 53 22 173384 I tensorflow tools benchmark benchmark model cc 291 Running benchmark for max 1000 iterations max 10 seconds without detailed stat logging with 1s sleep between inferences 2017 09 13 17 53 32 199487 I tensorflow tools benchmark benchmark model cc 324 count 316 first 33259 curr 33929 min 29881 max 34487 avg 31683 6 std 684 2017 09 13 17 53 32 199512 I tensorflow tools benchmark benchmark model cc 291 Running benchmark for max 1000 iterations max 10 seconds with detailed stat logging with 1s sleep between inferences 2017 09 13 17 53 32 200083 I tensorflow stream executor dso loader cc 139 successfully opened CUDA library libcupti so 8 0 locally 2017 09 13 17 53 42 310948 I tensorflow tools benchmark benchmark model cc 324 count 316 first 51892 curr 32599 min 29882 max 51892 avg 31710 3 std 1338 2017 09 13 17 53 42 310986 I tensorflow tools benchmark benchmark model cc 538 Average inference timings in us Warmup 45962 no stats 31683 with stats 31710 2017 09 13 17 53 42 311006 I tensorflow core util stat summarizer cc 358 Number of nodes executed 141 2017 09 13 17 53 42 311157 I tensorflow core util stat summarizer cc 468 Summary by node type 2017 09 13 17 53 42 311162 I tensorflow core util stat summarizer cc 468 Node type count avg ms avg cdf mem KB times called 2017 09 13 17 53 42 311166 I tensorflow core util stat summarizer cc 468 Conv2D 22 35 377 76 119 76 119 10077 888 22 2017 09 13 17 53 42 311170 I tensorflow core util stat summarizer cc 468 LRN 2 4 296 9 243 85 362 3211 264 2 2017 09 13 17 53 42 311173 I tensorflow core util stat summarizer cc 468 MaxPool 6 3 124 6 722 92 084 3562 496 6 2017 09 13 17 53 42 311177 I tensorflow core util stat summarizer cc 468 BiasAdd 24 1 677 3 608 95 692 0 000 24 2017 09 13 17 53 42 311195 I tensorflow core util stat summarizer cc 468 Relu 23 0 740 1 592 97 285 0 000 23 2017 09 13 17 53 42 311199 I tensorflow core util stat summarizer cc 468 MatMul 2 0 703 1 513 98 797 8 128 2 2017 09 13 17 53 42 311216 I tensorflow core util stat summarizer cc 468 Concat 3 0 375 0 807 99 604 2706 368 3 2017 09 13 17 53 42 311220 I tensorflow core util stat summarizer cc 468 Const 51 0 082 0 176 99 781 0 000 51 2017 09 13 17 53 42 311225 I tensorflow core util stat summarizer cc 468 AvgPool 1 0 057 0 123 99 903 32 512 1 2017 09 13 17 53 42 311229 I tensorflow core util stat summarizer cc 468 Softmax 1 0 028 0 060 99 963 0 000 1 2017 09 13 17 53 42 311232 I tensorflow core util stat summarizer cc 468 NoOp 1 0 006 0 013 99 976 0 000 1 2017 09 13 17 53 42 311236 I tensorflow core util stat summarizer cc 468 Arg 1 0 004 0 009 99 985 0 000 1 2017 09 13 17 53 42 311252 I tensorflow core util stat summarizer cc 468 Retval 1 0 003 0 006 99 991 0 000 1 2017 09 13 17 53 42 311256 I tensorflow core util stat summarizer cc 468 Reshape 2 0 003 0 006 99 998 0 000 2 2017 09 13 17 53 42 311274 I tensorflow core util stat summarizer cc 468 Identity 1 0 001 0 002 100 000 0 000 1 2017 09 13 17 53 42 311278 I tensorflow core util stat summarizer cc 468 2017 09 13 17 53 42 416261 E tensorflow tools benchmark benchmark model cc 556 FLOPs calculation failed with Invalid argument You must feed a value for placeholder tensor 'input' with dtype float Node input Placeholder dtype DT FLOAT shape device job localhost replica 0 task 0 cpu 0,,reedwm,2017-09-13 09:59:12,2017-10-31 07:57:18
PR,R1 3,,,,2017-10-31 10:00:24,2017-10-31 10:01:04
PR,Update Scikit Flow link and description,,,"terrytangyuan,terrytangyuan",2017-10-27 16:32:46,2017-10-31 16:28:08
PR,Branch 174023371,,,"andrewharp,andrewharp",2017-10-31 13:43:21,2017-10-31 16:56:09
IS,Issues importing external tf library from project,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 TensorFlow installed from source or binary Source bazel TensorFlow version use command below 1 2 Python version Bazel version if compiling from source bazel version Build label 0 7 0 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Wed Oct 18 14 27 19 2017 1508336839 Build timestamp 1508336839 Build timestamp as int 1508336839 CUDA cuDNN version GPU model and memory 2x1080ti Exact command to reproduce I import tensorflow with Bazel into my workspace with The deps reference tensorflow which I do not have in my WORKSPACE bazel build tensorflow compiler tf2xla kernels gather op kernel float int32 succeeds bazel build tensorflow compiler tf2xla kernels gather op kernel float int32 fails Can the tf library reference targets more inteligently or am I making a mistake Example targets L313,,"tadeegan,tadeegan,tadeegan,skye,gunan,tadeegan,gunan,tadeegan,gunan,case540",2017-10-25 22:54:26,2017-10-31 17:13:17
PR,Resolve tensorflow relative to tensorflow repo,Fixes 13984,,"tadeegan,tadeegan,tadeegan,tadeegan,gunan,tadeegan,gunan,gunan",2017-10-30 18:26:29,2017-10-31 17:13:17
PR,eager Update broken links in guide md,,,asimshankar,2017-10-31 17:14:53,2017-10-31 17:17:52
PR,eager Update broken link in README,,,asimshankar,2017-10-31 17:16:40,2017-10-31 17:18:15
PR,Add apt key for ubuntu keyserver,,,yifeif,2017-10-31 00:09:19,2017-10-31 17:18:45
IS,Feature Request Add partial run and partial run setup to MonitoredSession,Hello as mentioned in the topic I wonder if there is a chance in the near future for MonitoredSession to support partial graph computation,,"reedwm,ispirmustafa,isaprykin",2017-10-11 11:01:37,2017-10-31 17:22:24
IS,Feature Request provide a option to not call SessionRunHook in sess run,Describe the problem It is not necessary to execute all the bundled SessionRunHooks in some cases For example sess run enqueue in another thread its better to have an option like this session run run hooks True I would like to contribute this if someone think its a good idea,,"skye,ispirmustafa,isaprykin",2017-08-17 01:39:15,2017-10-31 17:22:45
IS,API request MonitoredSession run without hooks,Currently it is not possible to run a MonitoredSession without also calling the before run and after run methods of session hooks But sometimes it is necessary For example I want to modify certain variables in the graph but sometimes the SummarySaverHook decides it is time to collect summary right when I am loading new values into the dependent variables and then Tensorboad shows inconsistent results A run without hooks method will be immensely helpful,,"ppwwyyxx,isaprykin",2017-08-02 16:00:03,2017-10-31 17:22:57
PR,R1 2,17 2 7,,,2017-10-29 08:03:21,2017-10-31 18:00:22
PR,Remove name scope from convolutional calls,Cherry picking conv layer fix to 1 4 branch,,"case540,case540,benoitsteiner,benoitsteiner,gunan,case540,case540,case540",2017-10-27 20:48:57,2017-10-31 18:04:36
PR,Merge v1 4 rc1 back into master branch,Mostly version string changes but also adds some documentation that was directly committed to r1 4 branch,,"case540,av8ramit,case540,case540,case540,case540,benoitsteiner,benoitsteiner,gunan,case540,gunan,case540",2017-10-24 23:31:47,2017-10-31 18:05:15
PR,Fix typos in Linear Model Tutorial samples and install sources md,1 test file name is undefined should be test file name 2 train file name is undefined should be train file name PiperOrigin RevId 173733442,,"case540,case540",2017-10-31 16:52:03,2017-10-31 18:08:30
IS,tf contrib boosted trees cannot be used in 1 4 0rc1,TF Version 1 4 0rc1 Py Version 2 7 OS Mac OS,,asimshankar,2017-10-30 10:10:41,2017-10-31 18:28:56
PR,Resolve tensorflow relative to tensorflow repo in tfcompile bzl,Do this so that tfcompile bzl can be correctly loaded from another Bazel project,,"case540,case540",2017-10-31 18:28:06,2017-10-31 19:44:23
PR,Update version strings to 1 4 0,,,case540,2017-10-31 18:24:56,2017-10-31 19:56:11
PR,Add tf sysconfig get compile flags tf sysconfig get link flags for custom operators,The goal is to make custom operators compilation a breeze,,"alsrgv,drpngx,drpngx,alsrgv,drpngx,drpngx,drpngx,alsrgv,alsrgv,alsrgv,drpngx,drpngx,drpngx,alsrgv,alsrgv,drpngx,alsrgv,drpngx,alsrgv,alsrgv,frankchn,alsrgv,alsrgv,alsrgv,drpngx,asimshankar,drpngx,drpngx,gunan,alsrgv,gunan,alsrgv,drpngx,alsrgv,alsrgv,gunan,alsrgv,gunan,alsrgv,alsrgv,alsrgv",2017-10-05 00:48:51,2017-10-31 20:18:18
PR,Add deprecation notes,Add or update deprecation notes to metrics op py and tensor util py Minor comment fix in lookup ops py,,"alanyee,drpngx,sb2nov,alanyee,sb2nov,drpngx,alanyee,drpngx,alanyee,drpngx,alanyee,drpngx,drpngx",2017-08-26 06:57:43,2017-10-31 22:17:47
IS,Tensorflow seq to seq Arabic chatbot,i'm working on an AI chatbot for Arabic Language I follow this tutorial in tensrflow seq to seq model So far everything is doing great where i trained the model on my Arabic data using GPU and test the pre trained model But the some of them answers were correct while other are unrelated at all So my questions are 1 the model uses GRU in creating the model should i change it to LSTM 2 i used the same tokenizer in the French to English translation tutorial should i change it and use an Arabic tokenizer 3 Even if i write an input it will reply with Arabic sentence what i need is if the inout is new to the chatbot it should say sorry i do not understand for example Basically is there are changes should be done to make the chatbot handles the Arabic language very well,,"Carmezim,asimshankar",2017-10-31 19:09:21,2017-11-01 00:16:51
IS,feature request for TensorFlow Speech Recognizer apk,the Android apk file is a great way to test TensorFlow Speech Recognizer It would be even more useful with the addition of these two features 1 once any word is detected specify the scores for all 10 words in the list 2 specify silence detection Thank you in advance to anyone who is able to add these features,,asimshankar,2017-10-31 17:31:10,2017-11-01 00:17:42
IS,Access denied to download faster rcnn nas 17 10 2017 tar gz trained on COCO from the network zoo found in object detection,Following is link on which it says the network is available to download But when i click the link to download it says access denied,,asimshankar,2017-10-31 11:35:08,2017-11-01 00:20:12
PR,Use 'LABEL maintainer ' in Dockerfile,Use 'LABEL maintainer ' in Dockerfile This fix is a follow up of 13961 to replace MAINTAINER with LABEL maintainer in Dockerfile The keyword MAINTAINER has long been deprecated and is replaced by LABEL which is much more flexible and is easily searchable through docker inspect This fix replaces remaining MAINTAINER with LABEL Signed off by Charlie Lewis clewis iqt org Additional MAITAINER LABEL Signed off by Charlie Lewis clewis iqt org,,"yifeif,yifeif",2017-10-31 17:58:01,2017-11-01 01:53:20
IS,There is a Error about Too many include files,when i try to built example label image main cc Visual studio will throw an error c1014 too many include files Click the message this error point to a file of Tensor can anybody tell me how to fix this problem thank you This is my first time to write English litter and i am not good at english wish you can understood what i said lol,,"jart,jart",2017-10-30 13:00:55,2017-11-01 03:52:51
IS,CNN gives core dumpped but for the same data LSTM is running successfully,screenshot from 2017 10 28 19 55 09 screenshot from 2017 10 28 19 54 17 cuda 7 5 and cudann 5 0 tensorflow 0 10 0 and keras 1 2 0 LSTM program runs successfully For CNN program it is showing the below error hHow to correct this,,asimshankar,2017-10-28 14:27:59,2017-11-01 04:18:15
PR,make gather cpu kernel to be multiple threads,related to 11709 On a single machine profiling the embedding lookup sparse with tfprof the result shows that gather Op takes a lot of time I checked the code and found that the CPU version gather op is single thread Then I modify the gather Op to multi threads the result shows about 6x speedup Profiling result,,"nolanliou,alextp,alextp,alextp,alextp,alextp,alextp,tatatodd,nolanliou,nolanliou,alextp,nolanliou,jhseu,nolanliou,jhseu,nolanliou,alextp,nolanliou,yaroslavvb,nolanliou,nolanliou,alextp,nolanliou,jhseu,nolanliou,alextp,nolanliou,alextp,nolanliou,alextp,gunan,nolanliou,martinwicke,alextp,alextp,nolanliou,yifeif,drpngx,nolanliou,drpngx,nolanliou,drpngx,nolanliou,drpngx,nolanliou,drpngx,drpngx,drpngx,nolanliou,drpngx,drpngx,nolanliou,drpngx,sb2nov,sb2nov,nolanliou,sb2nov,nolanliou,alextp,frankchn,alextp,drpngx,nolanliou,alextp,nolanliou,alextp,nolanliou,drpngx,drpngx,gunan,nolanliou,drpngx,alextp,nolanliou",2017-08-13 06:00:39,2017-11-01 06:35:19
PR,Add 'log progress' argument for tf estimator Estimator is evaluate function,The output of estimator evaluate can be unnecessarily verbose with logging level INFO and many batches to evaluate on The old tf contrib learn Estimator had the ability to pass the log progress False argument along to to tensorflow python training evaluation where it suppresses logging in the after run function This PR adds the same functionality for tf Estimator,,"xiejw,xiejw,caisq,xiejw,xiejw,xiejw,gunan",2017-10-13 17:47:04,2017-11-01 06:38:11
IS,tf train MonitoredTrainingSession does not have request stop method,When i use tf train MonitoredTrainingSession class like below I cannot use sess request stop to stop the sess because MonitoredTrainingSession does not have this method tensorflow version is 1 3,,"asimshankar,asimshankar",2017-10-29 13:24:08,2017-11-01 06:39:48
PR,Adding a feed for boolean tensors to TensorFlowInferenceInterface,For 13601 adding the requested implementation to TensorFlowInferenceInterface,,"asimshankar,asimshankar",2017-10-28 18:57:55,2017-11-01 06:40:38
PR,Update multinomial py,The previous calculation of log prob is unstable if the probs of Multinomial are close to zeros the math ops log will result in nan values,,"ebrevdo,ebrevdo,drpngx,sb2nov,jvdillon,gunan",2017-08-22 09:30:33,2017-11-01 09:01:25
IS,an API to tell TF ABI,This is a feature request TF pip packages might be built with different C ABI The released binaries are built with old ABI If a user manually compile it with gcc 5 the default is to use new CXX11 ABI unless explicitly changed As someone who wrote custom ops this could cause trouble the op has to be compiled with the same ABI otherwise there will be issues like 10714 9137 Therefore the user of my ops would need to be aware of what ABI he is using and change the flags manually I hope there is an API simply tells what ABI should be used when compiling user ops similar to tf sysconfig get include which tells what path to include,,"ppwwyyxx,yaroslavvb,tatatodd,ppwwyyxx,ppwwyyxx",2017-08-04 22:53:17,2017-11-01 15:05:25
IS,Unable to use tf multinomial in Android No OpKernel was registered to support Op 'Multinomial',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 6 Android APK 23 TensorFlow installed from source or binary pip TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Describe the problem I cannot use tf multinomial in Android while it works in mac The error message is in the next section I'm using tensorflow from TensorFlowSharp and ml agents in Unity Unity builds my game uisng tensorflow for Android Source code logs TFException No OpKernel was registered to support Op 'Multinomial' with these attrs Registered devices CPU Registered kernels no registered kernels Node multinomial Multinomial Multinomial T DT FLOAT seed 0 seed2 0 dense 2 MatMul multinomial Multinomial num samples at TensorFlow TFStatus CheckMaybeRaise TensorFlow TFStatus incomingStatus System Boolean last 0x0004a in 252020d87a4e4581ad2cfe3f9cc7a0ac 0,,jart,2017-11-01 10:16:58,2017-11-01 15:50:59
IS,Nameerror could not find operator mpisize in dynamic library mpi collectives so,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 with 4 4 kernel TensorFlow installed from source or binary source code TensorFlow version use command below latest git clone from github in 2017 10 30 Python version 2 7 Bazel version if compiling from source 0 70 latest CUDA cuDNN version 8 0 6 0 GPU model and memory tesla k40c Exact command to reproduce python c import tensforflow contrib mpi collectives,,jart,2017-11-01 09:10:20,2017-11-01 16:08:47
IS,feature request Adding c serving session api to c api,Or is it recommended to just use TF NewSession C API for session serving Is TF Session Run thread safe Thanks in advance,,jart,2017-11-01 04:52:01,2017-11-01 16:19:10
IS,Convolutional layers cannot be used multiple times,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source branch 1 4 TensorFlow version use command below 1 4 0 dev Python version 3 5 Bazel version if compiling from source 5 4 0 CUDA cuDNN version 8 0 6 0 GPU model and memory nVidia 1080Ti 11G Exact command to reproduce run the script below Describe the problem Keras convolutional layers cannot be used multiple times without creating a name conflict This is especially bad when trying to copy layers from one model to another See the second example below This was working a few weeks ago Here is a simple test case that used to work,,"martinwicke,fchollet,facaiy,fchollet,martinwicke",2017-10-18 22:31:43,2017-11-01 16:54:25
IS,tensorflow Makefile build does not support building arm64 v8a static library for Android,Currently tensorflow has only support build static library in armeabi v7a for Android And the build script has not support the other platforms yet as we can see in tensorflow tensorflow contrib makefile Makefile L219 Our team would like to build all the architecture for Android if possible and we tried to fixed the makefile that expect to link with our Android project but got many linking errors except armeabi v7a So I was just wondering if tensorflow will support those platform arm64 v8a x86 x88 64,,"gautam1858,gautam1858,andrewharp",2017-08-03 09:08:11,2017-11-01 17:01:16
PR,Support more Android arch in Makefile build,Adds support for various Android arch in Makefile build This resolves 11996,,"resec,andrewharp,andrewharp,resec,resec,drpngx,sb2nov,resec,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,gunan,andrewharp,drpngx",2017-09-05 05:05:38,2017-11-01 17:01:16
IS,time to restore saved model increases over time,System information Manjaro Linux TensorFlow installed with pip TensorFlow version v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 6 2 CUDA cuDNN version 8 0 61 3 7 0 3 1 GPU model and memory GeForce GTX 1080 8 GB Describe the problem Executing the code below in a loop slows down linearly with number of iteration as can be seen in the figures below The use case being a long running app where different models are loaded multiple times depending on user inputs import metagraph saver restore,,"jart,jart,jart,jart,jart",2017-11-01 15:22:41,2017-11-01 17:23:14
PR,fix broken link,,,"larrytin,yifeif",2017-10-31 05:10:37,2017-11-01 17:24:27
IS,Android No OpKernel was registered to support Op 'Cos' with these attrs Registered devices CPU Registered kernels no registered kernels Node stft hann window Cos Cos T DT FLOAT device device CPU 0 stft hann window truediv,I have exported a model to Android that uses stfts tf contrib signal stft transwav frame length 2048 frame step 512 fft length 2048 window fn functools partial tf contrib signal hann window periodic False pad end True the model works properly in pyhton but when i load it in Android using the downloaded compiled tensorflow compile 'org tensorflow tensorflow android ' I get this error FATAL EXCEPTION main Process org tensorflow demo PID 25836 java lang IllegalArgumentException No OpKernel was registered to support Op 'Cos' with these attrs Registered devices CPU Registered kernels no registered kernels Node stft hann window Cos Cos T DT FLOAT device device CPU 0 stft hann window truediv which comes from the hann window any recommended work around,,"jart,jart",2017-11-01 17:27:40,2017-11-01 17:31:31
IS,tf reshape fails for shapes containing non 32 bit precision TF integer types,Environment TensorFlow v1 3 0 rc2 20 g0787eee 1 3 0 running on Mac OS X v10 12 6 Issue Function tensorflow reshape works when provided a list based shape containing tf int32 but fails for e g tf int16 and tf int64 with error message TypeError List of Tensors when single Tensor expected Example,,"facaiy,facaiy,facaiy,facaiy,jart",2017-10-30 18:49:38,2017-11-01 17:55:16
IS,java API had no bool tensorflow how to add it to the session in java,i am doing transer the facenet to android the input is the img and the phase train is a bool data but the java api had no bool to be feed to session as i had down this and then the c write m phase tensor tensorflow Tensor tensorflow DT BOOL tensorflow TensorShape m phase tensor scalar bool false how to writen in java can somebody help me,,"asimshankar,yongtang,asimshankar",2017-10-10 06:47:32,2017-11-01 18:15:44
IS,build with tensorflow cc with cmake,I found as a good solution should somebody add it to official repository,,asimshankar,2017-11-01 15:54:59,2017-11-01 18:34:24
IS,The new version of the code about Wide and Deep model has not yet defined 'centered bias',Hi I'm reading the new version tensorflow code about Wide and deep model the model is in tf estimator DNNLinearCombinedClassifier In the tf contrib learn DNNLinearCombinedClassifier we can find that the variable 'centered bias' is defined in head py It s the bias of model is output However in the new version code eg the implemention based on 'tf feature column' and 'tf estimator' this variale has not been find It is only add dnn logits and linear logits Is it a bug or I do not find it thanks Xiangfu Shi,,asimshankar,2017-11-01 10:29:18,2017-11-01 18:42:10
PR,Add GCC Compiler version to issue template,As suggested in 13930,,yifeif,2017-10-30 23:17:35,2017-11-01 19:26:50
PR,experimental,,,,2017-10-29 16:55:37,2017-11-01 19:27:18
IS,begin shift axis not defined in tf contrib layers layer norm,The live version of tensorflow is api docs here Refer to begin shift axis which is not defined I assume this is a typo and is meant to be begin params axis Apologies if documentation bugs are supposed to be tracked elsewhere it is not clear how those should be reported,,yongtang,2017-10-25 17:52:35,2017-11-01 19:27:54
PR,Update docs for begin params axis,This fix fixes the issue raised in 13975 where begin shift axis should actually be begin params axis This fix fixes 13975 Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner,benoitsteiner,benoitsteiner,benoitsteiner,gunan,yongtang,gunan",2017-10-25 18:59:58,2017-11-01 19:27:54
PR,Initial add of docs for Tensorflow on Mobile,Cherry pick of mobile docs from master onto r1 4 PiperOrigin RevId 173980290,,MarkDaoust,2017-11-01 18:13:36,2017-11-01 20:21:14
PR,Make special math ndtri work with partially specified shapes,Current implementation of the special math ndtri function does not work with tensors of partially known shape which prevents one from computing Normal distribution is quantile function for non fixed size batches,,"vrv,vrv",2017-10-22 15:50:46,2017-11-01 23:35:45
PR,Make sure to set GLIBCXX USE CXX11 ABI 0 if it is not defined,This is necessary to make sure we can compile TensorFlow with gcc4 and compile custom operator with gcc5,,"alsrgv,jhseu,alsrgv",2017-11-01 17:30:26,2017-11-01 23:36:02
PR,Adding basic MKL DNN code,This PR includes basic code of MKL DNN integration in the graph rewrite and the convolution op It is the base for the upcoming MKL DNN kernels,,"mahmoud-abuzaina,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,gunan,mahmoud-abuzaina,mahmoud-abuzaina,gunan,mahmoud-abuzaina,gunan,mahmoud-abuzaina,yifeif,yifeif,mahmoud-abuzaina,gunan,gunan,mahmoud-abuzaina,gunan",2017-10-11 21:26:09,2017-11-01 23:37:25
PR,Dockerfile do not perform cleanup in a separate RUN statement,Cleanup must be performed in the same statement otherwise the build files are still stored in the upper layer and no space is reclaimed Signed off by Felix Abecassis fabecassis nvidia com Image size before the patch 8 21GB Image size after the patch 4 99GB,,"flx42,gunan,flx42,gunan,gunan,flx42,gunan,flx42,gunan,flx42,gunan",2017-10-30 18:06:30,2017-11-02 04:56:55
IS,fail to build tensorflow gpu by CUDA 9 0 cuDNN 7 at win10 envs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N OS Platform and Distribution e g Linux Ubuntu 16 04 window 10 64bit TensorFlow installed from source or binary source TensorFlow version use command below tensorflow 1 4 0 or tensorflow 1 3 0 Python version python 3 5 4 Bazel version if compiling from source cmake 3 6 3 CUDA cuDNN version CUDA 9 0 cuDNN 7 GPU model and memory gtx 1080ti 11GB Exact command to reproduce Describe the problem hello for i can not use tensorflow gpu packet at win10 so i try to build tensorflow gpu by win10 env then met those issue can anyone help me thanks first my environment win10 gtx 1080ti cuda 9 0 cuDNN 7 visual studio profession 2015 cmake 3 6 3 python 3 5 4 when i switch to tensorflow r1 4 and build by cmake at win10 environment issue accur that CUSTOMBUILD Internal error assertion failed at C dvs p4 build sw rel gpu drv r384 r384 00 drivers compiler edg EDG 4 12 src lookup c line 2652 C TF tensorflow tensorflow contrib cmake build tf core gpu kernels vcxproj 1 catastrophic error detected in the compilation of C Users ADMINI 1 AppData Local Temp tmpxft 00000c94 00000000 8 adjust contrast op gpu cu cpp4 ii Compilation aborted adjust contrast op gpu cu cc CUSTOMBUILD nvcc error 'cudafe ' died with status 0xC0000409 C TF tensorflow tensorflow contrib cmake build tf core gpu kernels vcxproj CMake Error at tf core gpu kernels generated adjust contrast op gpu cu cc obj Release cmake 267 message Error generating file C TF tensorflow tensorflow contrib cmake build CMakeFiles tf core gpu kernels dir core kernels Release tf core gpu kernels generated adjust contrast op gpu cu cc obj image above issue look like cuda compolie itself problem but when i switch tensorflow version to r1 3 another issue accur c tf test tensorflow tensorflow contrib cmake build external eigen archive eigen src Core util Macros h 416 fatal error C1017 C TF test tensorflow tensorflow contrib cmake build tf core gpu kernels vcxproj CMake Error at tf core gpu kernels generated adjust contrast op gpu cu cc obj Release cmake 267 message Error generating file C TF test tensorflow tensorflow contrib cmake build CMakeFiles tf core gpu kernels dir core kernels Release tf core gpu kernels generated adjust contrast op gpu cu cc obj image it look like the file adjust contrast op gpu cu cc have some problem but i can not find any error from it such above issues trouble me few days wish to someone help me going this try and success and strong expect google upgrade tensorflow support cuda 9 0 and cudnn 7 at win10 environment,,"Carmezim,Carmezim,jart",2017-10-31 15:12:03,2017-11-02 05:26:30
PR,NaN propagation for GPU pooling ops,Attention xq Changes the custom fwd maxpooling kernel to propagate NaNs This makes it match the behavior of CUDNN and ensures that CUDNN is bwd maxpooling kernel behaves as expected propagating NaNs Previous behavior can be restored with environment variable TF ENABLE MAXPOOL NANPROP 0 Changes the GPU bwd maxpool op tests to expect propagated NaNs matching the behavior of the CPU path,,"nluehr,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,nluehr,nluehr,zheng-xq,zheng-xq,zheng-xq,zheng-xq,nluehr,zheng-xq,nluehr,nluehr,jhseu,tfboyd,drpngx,nluehr,drpngx,nluehr,reedwm,nluehr,zheng-xq,drpngx,drpngx,yifeif,yifeif,yifeif",2017-08-22 23:14:07,2017-11-02 05:34:08
PR,Add explanation to assist in parameterized docker build sh use,Explains that using parameterized docker build sh is dependent upon running from an appropriate developer image,,"gunan,gunan,gunan,gunan,gunan,gunan,gunan,gunan,gunan",2017-09-29 10:13:49,2017-11-02 05:34:29
PR,Fix LMDBReader crash due to not fully cleanup,This PR fixed a bug in LMDBReader cleanup Some pointers were not reset and caused corruption when the LMDBReader opens the next file A test case is constructed to verify the case,,"bowang,jhseu,jhseu,bowang,bowang,sb2nov,bowang,bowang,bowang,jhseu,caisq,bowang,caisq,bowang,bowang,bowang,bowang,jhseu,bowang,bowang",2017-09-30 00:20:28,2017-11-02 05:36:34
IS,using batchnorm in conv2d discard the bias,Hi I observed that whenever I applied batch normalization to conv2d the bias variable are not created version Tensorflow 1 3 output tf Variable 'conv1 weights 0' shape 3 3 1024 128 dtype float32 ref tf Variable 'conv1 batch normalization beta 0' shape 128 dtype float32 ref tf Variable 'conv1 batch normalization gamma 0' shape 128 dtype float32 ref tf Variable 'conv2 weights 0' shape 3 3 1024 128 dtype float32 ref tf Variable 'conv2 biases 0' shape 128 dtype float32 ref no bias for conv1 Question Is it a bug or a feature edit I also observed the same behavior with mlp Thank you very much Florian,,,2017-11-02 05:58:16,2017-11-02 06:02:33
PR,Update model fn py,Remove and replace contrib framework and function,,"alanyee,ispirmustafa,alanyee,ispirmustafa,drpngx,sb2nov,alanyee,alanyee,drpngx,drpngx,alanyee,drpngx,gunan,drpngx,alanyee,gunan",2017-08-26 07:07:58,2017-11-02 06:14:28
PR,Non scalar Multinomial draws,This PR tries to fix the issue in 12804 where supports total count to be a non scalar tensor and broadcasts by map fn The reason why I use map fn to broadcast manually is that current tf multinomial sampler op do not support to produce different total count within a batch and map fn can enhance this underlying op effectively without modifying it It is a little dilemma if we modify the underlying op to support different total count within a batch because that will produce variable length draws within a batch unless we add a new function with different interface for multinomial sampler,,"jinze1994,jvdillon,jvdillon,jinze1994,jvdillon,jvdillon,jinze1994,sb2nov,jvdillon,sb2nov,sb2nov,jinze1994,jvdillon,jinze1994,jinze1994,sb2nov,jinze1994,jvdillon,jvdillon,vrv,jinze1994,jvdillon,jinze1994,jvdillon,vrv,jinze1994,gunan,gunan,jinze1994,gunan,jinze1994",2017-09-20 15:34:57,2017-11-02 06:15:25
PR,Cauchy Distribution,Added the cauchy distribution to contrib distributions The cauchy distribution is an example of a distribution with undefined moments I could not find an existing implementation to reference against so I'm not sure if my approach to this is correct please advise,,"jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,jvdillon,ebrevdo,ebrevdo,jvdillon,vrv,ebrevdo,ebrevdo,jvdillon",2017-10-22 02:30:51,2017-11-02 06:18:16
PR,Fix for 13498,skye I'm kind of indecisive it turns out P This is just your fix along with an equivalent fix for RemoveEdge I do not know if you want to merge it given that you might make changes to your fix but I'm putting here just in case The RemoveEdge fix is pretty much equivalent and since the method is not used in the graph constructor I did not change its call sites to use false for the update node def argument I'm not sure if that collides with anything else but I guess the tests can tell us something I did not run them on my laptop because they take forever and I can not use it in the meantime,,"eaplatanios,skye,skye,eaplatanios,eaplatanios,skye,skye,skye,skye,skye,skye,skye,eaplatanios,eaplatanios,eaplatanios,skye,skye,eaplatanios,skye,skye,eaplatanios,caisq,eaplatanios,skye,eaplatanios,eaplatanios,eaplatanios,eaplatanios,eaplatanios,gunan,gunan",2017-10-05 17:09:46,2017-11-02 06:23:04
IS,feature request Does android tensorflow make the without considering front camera and landscape mode,Fist bump I want to make a tensorflow application available in landscape also facing mode But during the development There was a problem that coordinates were displayed wrong when the front camera and landscape mode was used to detect the object after inference Do you have any reference code or other resources Have a nice day,,asimshankar,2017-10-31 14:30:45,2017-11-02 06:50:51
PR,Merge pull request 1 from tensorflow master,Updated on 2017 10 24,,benoitsteiner,2017-10-24 15:49:58,2017-11-02 07:16:28
IS,memory leak with tf image encode jpeg,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,mrry,2017-11-02 13:07:25,2017-11-02 14:48:47
IS,memory leak with tf image encode jpeg,I encountered an issue with tf image encode jpeg I got a lot of images to preprocess The code that caused the problem is like this for imagefile in image list im cv2 imread imagefile image data tf image encode jpeg im format 'rgb' The memory usage kept increasing as image encode jpeg was called Eventually the 256G mem server ran out of memory,,mrry,2017-11-02 13:20:32,2017-11-02 14:58:44
IS,Tensorflow hooks do not properly write events to HDFS,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Alpine Linux 3 6 2 running with Docker TensorFlow installed from source or binary Binary conda forge TensorFlow version use command below 1 3 0 Python version 3 6 3 Bazel version if compiling from source CUDA cuDNN version GPU model and memory using CPU Exact command to reproduce CLASSPATH HADOOP HOME bin hadoop classpath glob jupyter notebook Describe the problem I am reading files from hdfs and also want to use hdfs as model dir to store the tensorflow output Reading and writing of the checkpoints works fine However the the events file just gets created but it does not get updated with the evaluation events When I kill the notebook then the output is written but not in between Changing the model directory to a local one solves this Also adding an extra SummarySaverHook which points to a local directory did not help I am running my code using the instructions here Source code logs I normally use an Estimator with a custom model function but I reduced it to the following,,"jart,jart",2017-10-30 06:14:43,2017-11-02 16:51:31
PR,Fix discrepancy between docs and registered kernels for tf ones like tf zeros like,This fix tries to address the discrepancy between docs and registered kernels for tf ones like From the implementations the OnesLike ZerosLike are registered with all POD types However in the documentation several data types are missing uint8 int8 uint16 int16 bool This fix addresses the issue by adding missing types to documentation Signed off by Yong Tang yong tang github outlook com,,"yongtang,ebrevdo,yongtang,yongtang,yongtang,gunan",2017-10-09 21:51:14,2017-11-02 18:11:28
IS,r1 3 branch encountered error attempting build on Pi 2,OS is Ubuntu Mate 16 04 cannot quite decipher the problem yet Might try the Pi2 specific build line next System information,,"aselle,aselle,petewarden",2017-09-15 15:17:35,2017-11-02 21:15:57
PR,Fix bug variables outside wo not update in DNNLinearCombinedRegressor,This fix is an proposal for 13419 What changes were proposed in this pull request There are two solutions to fix the problem in my opinion all variables except of linear is optimized by dnn which one of optimizers does the variables left except of linear and dnn use is selected by user perhaps a new argument is needed The PR is implemented by the first one for simplicity How to test x add test case I have no idea of how to write it hence any suggestions will be appreciated pass all tests,,"facaiy,facaiy,sb2nov,facaiy,facaiy,facaiy",2017-09-30 11:27:36,2017-11-02 22:55:50
PR,Update cudnn rnn py,For addressing this issue issuecomment 340042335 Updating the path on line 33 to make import cudnn rnn work Change worked on Ubuntu,,"asimshankar,protoget,protoget,asimshankar,protoget",2017-10-27 20:32:25,2017-11-02 23:11:10
IS,layers based cuDNN RNN functionality not working,I'm trying to use the newly added layers style cuDNN RNN functionality I'm running TF 1 4 0 rc0 on Ubuntu with Pascal GPUs compiled from source with CUDA 8 and cuDNN 7 When trying to import the relevant library from tensorflow contrib cudnn rnn python layers import cudnn rnn I get the following error Note that the non layer based cuDNN RNN functionality works fine I e I can run this from tensorflow contrib cudnn rnn python ops import cudnn rnn ops and run cuDNN based RNNs with no problem otherwise,,"asimshankar,asimshankar",2017-10-26 15:14:22,2017-11-02 23:11:22
IS,what is this error stands for,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-11-02 09:22:14,2017-11-03 00:08:10
IS,tensorflow model convert to other dl tools,are there some tools that can convert tensorflow model to caffe mxnet or other dl tools,,asimshankar,2017-11-02 10:12:46,2017-11-03 00:13:33
IS,tf contrib boosted trees still cannot be used in official 1 4 0,Hi i have raised an issue event 1319398254 before however after i upgrade to official 1 4 0 the problem is still the same I am sorry about raising this again but GBDT in TF seems so appealing to users TF version 1 4 0 Py version 2 7 10 OS Mac OS The testing script i am using is,,,2017-11-02 21:54:20,2017-11-03 01:15:10
IS,List of functions could be improved with const std string or std string instead std string,After a quick scan in the latest tensorflow master branch here is the list of functions which could improve passing parameter by std string After a quick scan in the latest tensorflow master branch here is the list of functions which could improve passing parameter by std string 1 c c api function cc static string Normalize string name Suggestion string name 2 c c api function cc string NodeNameMapping Normalize string name Suggestion string name 3 compiler jit graph to functiondef cc string NormalizeHelper string name const Suggestion string name 4 compiler jit graph to functiondef cc string UniquifyHelper string name Suggestion const string 5 compiler jit graph to functiondef cc string NodeNameMapping NormalizeHelper string name const Suggestion string name 6 compiler jit graph to functiondef cc string NodeNameMapping UniquifyHelper string name Suggestion const string 7 compiler tf2xla dump graph cc string MakeUniquePath string name Suggestion string name 8 compiler xla service llvm ir llvm util cc string IrName string a Suggestion string a 9 compiler xla service llvm ir llvm util cc string SanitizeFunctionName string function name Suggestion string function name 10 compiler xla service llvm ir llvm util h string IrName string a Suggestion string a 11 compiler xla service llvm ir llvm util h string SanitizeFunctionName string function name Suggestion string function name 12 compiler xla util cc string SanitizeFileName string file name Suggestion string file name 13 compiler xla util h string SanitizeFileName string file name Suggestion string file name 14 contrib verbs rdma cc RdmaBuffer RdmaBuffer RdmaChannel channel string name Suggestion const string name 15 contrib verbs rdma cc RdmaAckBuffer RdmaAckBuffer RdmaChannel channel string name Suggestion const string name 16 contrib verbs rdma cc RdmaMessageBuffer RdmaMessageBuffer RdmaChannel channel string name Suggestion const string name 17 contrib verbs rdma cc RdmaTensorBuffer RdmaTensorBuffer RdmaChannel channel string name Suggestion const string name 18 contrib verbs rdma h explicit RdmaBuffer RdmaChannel channel string name Suggestion const string name 19 contrib verbs rdma h explicit RdmaAckBuffer RdmaChannel channel string name Suggestion const string name 20 contrib verbs rdma h explicit RdmaMessageBuffer RdmaChannel channel string name Suggestion const string name 21 contrib verbs rdma h explicit RdmaTensorBuffer RdmaChannel channel string name Suggestion const string name 22 core common runtime step stats collector cc static int ExtractGpuWithStreamAll string device name Suggestion string device name 23 core common runtime step stats collector cc static int ExtractGpuWithoutStream string device name Suggestion string device name 24 core kernels ops util cc string SanitizeThreadSuffix string suffix Suggestion const string suffix 25 core kernels ops util h string SanitizeThreadSuffix string suffix Suggestion const string suffix 26 core kernels xsmm conv2d cc static void chk libxsmm err libxsmm dnn err t status string msg Suggestion const string msg 27 stream executor platform cc PlatformKind PlatformKindFromString string kind Suggestion const string kind 28 stream executor platform h PlatformKind PlatformKindFromString string platform string Suggestion const string platform string,,"jart,jart,jart",2017-11-02 03:23:27,2017-11-03 01:45:06
PR,Fix broken code tag in tf contrib data README,,,nealwu,2017-11-02 23:50:31,2017-11-03 05:43:59
PR,typo fixed in CODE OF CONDUCT md,The spelling of behaviour is a non American variant For consistency consider replacing it with the American English spelling the word behaviour in located at line 16 as behavior so why typing it in two ways,,,2017-11-02 07:02:53,2017-11-03 05:49:07
PR,Adding equals and hashCode to Shape,Hello I know this is a bit of a simple and trivial pull request However for some other work I'm doing I wanted to compare Shape instances in some tests and I found that it did not work in the standard way Hence this pull request to just add an equals method It has some tests and also does hashCode because it is a common thing to do at the same time,,"asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,gunan,gunan,asimshankar,gunan",2017-10-13 15:03:37,2017-11-03 05:51:58
PR,Allow LMDB to be opened by multiple readers simultaneously,This PR is basically a one line change by adding MDB NOLOCK flag Since LMDBReader is read only we do not need locks LMDB by default creates a lock file in the same folder which prohibits the database to be opened by others,,"bowang,jhseu,jhseu,bowang,bowang,sb2nov,bowang,bowang,bowang,caisq,bowang,caisq,gunan,gunan,snnn",2017-09-30 01:17:15,2017-11-03 05:53:44
IS,RNNParamsSavable breaks when there is more than one RNN,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 3 5 Bazel version if compiling from source 5 2 CUDA cuDNN version 6 0 GPU model and memory Tesla K80 12gb Exact command to reproduce Describe the problem An exception is thrown ValueError At least two variables have the same name rnn1 rnn This works if there is only one RNN If I remove the name parameters the model will save however only one of the two RNNs will have their weights biases saved to the checkpoint as individual tensors so it will break if I try to restore two CudnnCompatibleGRUCell RNNs from this checkpoint As far as I can tell there is some kind of name clobbering happening within tf Saver maybe because RNNParamsSaveable set op to none for the super class,,"aselle,protoget",2017-09-23 00:24:10,2017-11-03 06:54:44
IS,Cannot deepcopy index table from file object,Tensorflow 1 4 0 Windows 10 Code Is it intended that this object cannot be deepcopied,,asimshankar,2017-11-02 15:41:28,2017-11-03 06:59:40
IS,Convert keras model to estimator model,ValueError 'Expected model argument to be a Model instance got ' keras engine training Model object at 0x00000230F36F0E10,,"asimshankar,asimshankar",2017-11-03 07:58:58,2017-11-03 08:11:20
IS,Getting wrong value with placeholder,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I have used code which is on the link OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 LTS TensorFlow installed from source or binary Installing with native pip tensorflow gpu TensorFlow version use command below '1 3 0' Python version Python 2 7 12 'v1 3 0 rc2 20 g0787eee' '1 3 0' Bazel version if compiling from source GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version CUDA release 8 0 V8 0 61 cuDNN CUDNN MAJOR 6 GPU model and memory GeForce 940MX Memory 2GB Driver Version 384 90 Describe the problem When I run at below code I think i am getting the wrong result Source code logs My Output 3 0 1 3 I think the true result should be 7 5 3 7 Logs Also when i type sess tf Session i am getting that output 2017 11 02 12 09 04 184601 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 11 02 12 09 04 184689 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 11 02 12 09 04 184717 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 11 02 12 09 04 184753 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 11 02 12 09 04 184805 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 11 02 12 09 04 368504 I tensorflow stream executor cuda cuda gpu executor cc 893 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 11 02 12 09 04 368855 I tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name GeForce 940MX major 5 minor 0 memoryClockRate GHz 1 2415 pciBusID 0000 01 00 0 Total memory 1 96GiB Free memory 1 53GiB 2017 11 02 12 09 04 368870 I tensorflow core common runtime gpu gpu device cc 976 DMA 0 2017 11 02 12 09 04 368874 I tensorflow core common runtime gpu gpu device cc 986 0 Y 2017 11 02 12 09 04 368882 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name GeForce 940MX pci bus id 0000 01 00 0,,"asimshankar,asimshankar",2017-11-02 09:16:34,2017-11-03 09:02:33
IS,Could not find any downloads that satisfy the requirement tensorflow,I cannot install Tensorflow using pip install tensorflow Installing TensorFlow on Ubuntu This guide explains how to install TensorFlow on Ubuntu These instructions might also work on other Linux variants but we have only tested and we only support these instructions on Ubuntu 14 04 or higher,,,2017-11-03 11:02:19,2017-11-03 13:09:15
IS,Feature tf image scale image and keep aspect ratio,Hi I'm working on a FCN Fully Convolutional Network and use Tensorflow for this work I have a lot of images in input and they have very different dimensions like 2340x4160 or 512x512 So my input need to be dynamic It is why I search a way to resize images for having the greater dimension to a specific value with respect to the aspect ratio Unfortunatly Tensorflow does not provide this feature or if I'm wrong please just ignore this issue So I write my own code It is probably not the most beautiful way to write this sorry if this code seems ugly If the feature already exist sorry but I search on git stackoverflow google and did not find any viable solution If you have any question or if I'm not clear ask to me Have a nice day,,"yongtang,yongtang,yongtang",2017-11-03 13:54:28,2017-11-03 15:26:42
IS,generator input fn for tensorflow estimator,I find there is numpy input fn and pandas input fn to construct the input fn for tensorflow estimator However sometimes I need a more flexible constructor that can create the input fn from a custom generator iterator It seems that Tensorflow does not have this feature currently There is a generator input fn diff 58e32b22d643f3a61d9bbeee2bec89b6R27 for tensorflow contrib learn but I think that is not compatible with Tensorflow Estimator Is there any plan to add generator input fn for tensorflow estimator,,"asimshankar,ispirmustafa,ispirmustafa,mrry",2017-11-01 03:11:57,2017-11-03 16:21:47
IS,64MB protobuf limit,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 5 Exact command to reproduce,,"drasmuss,mrry,drasmuss",2017-11-03 16:45:11,2017-11-03 17:14:48
IS,TensorFlow 1 4 gpu Linux Py36 not built with Py36,Installed TF 1 4 with pip install ignore installed upgrade Gives me this error on import home tom anaconda3 envs tf4 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds Similar error reported form Tensorboard home tom anaconda3 envs tf4 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds TensorBoard 0 4 0rc2 at 6006 Press CTRL C to quit,,mrry,2017-11-03 15:48:52,2017-11-03 17:39:55
IS,what is is forget bias,what is is forget bias I checked the basicllstmcell variable but I found the biases are 0 althought I changed forget bias to 0 or 1 I heard the func of it is that do not forget input of first time please feedback,,asimshankar,2017-11-03 17:59:38,2017-11-03 18:08:24
IS,Failed to run TensorFlow inference with inputs image tensor outputs detection boxes detection scores detection classes num detections,Facing this issue when running TFDetect app Even the app is crashing This issue i'm facing is when i'm running the example tensorflow android app,,"reedwm,reedwm,andrewharp,andrewharp",2017-10-12 14:07:04,2017-11-03 18:19:41
IS,Retraining the lower layers of the inception model for a better classifier,L26 Hi I am trying to use the inception model to learn to classify between about 200 different object types I tried the approach mentioned here which seems to only retrain the last few layer of the model and I can not get about 60 accuracy even when I am training the model I imagine if I pass on the gradient and change the weights in the lower layers that I will be able to improve the accuracy of the model when applied to my data set How do I go about doing this Any guidance on this being done else where would be extremely helpful,,asimshankar,2017-11-03 23:51:05,2017-11-04 00:18:09
IS,do fine tuning with my own image size,I would like to do transfer learning and fine tuning with some pretrained model in tensorflow contrib slim I searched some examples about this However almost all of these examples will resize images to the specified size that the model needs For example 224 224 is the size that vgg16 needed Will it be possible to set my own image size Like 512 512 In keras I can do this like following base model VGG16 include top False input shape 512 512 3 Up till now I have not found the solution can this be down in tensorflow and slim,,,2017-11-03 14:36:53,2017-11-04 02:28:20
PR,Branch 174534886,pushing internal commits,,andrewharp,2017-11-04 00:24:42,2017-11-04 02:38:39
PR,Upgrade gRPC,Update commit ID of grpc update bazel rc to force non use of ares resolver and also stop patching gRPC This should enable regular updates of gRPC since separate patches will no longer be needed Some changes below will be brought in separately by another commit and should rebase out cleanly,,"jhseu,jhseu,benoitsteiner,jhseu,jhseu,jhseu,jhseu,benoitsteiner,benoitsteiner,benoitsteiner,jhseu,gunan,gunan,gunan,gunan,gunan,gunan,jhseu,jhseu,gunan,gunan",2017-10-24 22:13:52,2017-11-04 02:56:37
PR,Bulleted lists need a leading blank line,,,"MarkDaoust,asimshankar",2017-11-03 19:29:50,2017-11-04 03:03:53
PR,R1 4,,,,2017-11-03 09:56:22,2017-11-04 03:04:27
PR,Dockerfile gpu use the runtime cuDNN v6 image,The generated Docker image will be approximately 900 MB smaller The Dockerfile switched to the devel image a long time ago to workaround a bug when looking up CUDA libraries This problem has been fixed in the meantime let me know if I'm missing something and there is a good reason to keep the devel image as a base,,"flx42,gunan",2017-11-02 22:00:43,2017-11-04 03:05:04
PR,fix typo,,,"larrytin,gunan",2017-11-02 02:21:25,2017-11-04 03:05:12
IS,Failure in TestNewTensor when running go test,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source branch 1 4 TensorFlow version use command below 1 4 0 dev Python version 3 5 Bazel version if compiling from source 5 4 0 CUDA cuDNN version 8 0 6 0 GPU model and memory nVidia 1080Ti 11G Exact command to reproduce go test v github com tensorflow tensorflow tensorflow go Describe the problem I'm trying to use the go bindings to the tensorflow c library When I run the tests I get a nil pointer dereference and a segfault The details are below Note that I have built the c library from source using the following options bazel build c opt config cuda config mkl c opt copt mavx copt mavx2 copt mfma copt mfpmath both copt msse4 2 c opt cxxopt D GLIBCXX USE CXX11 ABI 0 tensorflow libtensorflow so Source code logs When I run go test v github com tensorflow tensorflow tensorflow go I get the following error Adding some debugging it turns out that the TestNewTensor test fails when attempting to create the following tensor int64 2 0 int64 If I comment out that line the tests pass,,"asimshankar,asimshankar",2017-10-17 00:17:31,2017-11-04 03:09:38
PR,Handle nil return from TF TensorData,With some memory allocators attempting to allocate 0 bytes will return a null pointer This specifically happens when building tensorflow with mkl support If TF TensorData returns null the go code to create a slice from the data leads to a null pointer exception This fixes the issue by checking for the nil return and returning a slice zero value to nil to the caller Fixes 13764,,asimshankar,2017-10-30 04:07:36,2017-11-04 03:09:39
PR,added CMake install targets,This way you can use cmake to install tensorflow into some location It is easier to package tensorflow this way,,"mrry,mrry,mrry,mrry,av8ramit,mrry,vrv,mrry",2017-10-20 20:50:06,2017-11-04 03:16:21
PR,tensorflow go add in LDFLAGS to support android,This is required since the libtensorflow inference so generated by contrib android links against these libraries Go requires these to be specified when compiling against it,,"sb2nov,sb2nov,frankchn",2017-09-28 20:24:25,2017-11-04 03:26:43
IS,Compilation error since today morning with cudnn 5 1 10,System information Memory 16GB Processor Intel Core i7 7700HQ CPU 2 80GHz 8 GPU GeForce GTX 1060 PCIe SSE2 OS Type 64 bit Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source 0 5 4 CUDA cuDNN version CUDA 8 0 CUDNN 5 1 10 GPU model and memory GTX 1060 6GB Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package Describe the problem Since today morning I have been getting this error in compiling TF with cudnn 5 1 10 where it seems to be looking for a v6 file even though I have configured it to use 5 1 10 I do not see the same error when building with cudnn6 0 I compiled it last night with the same exact configuration and it was compiling fine I have even wiped my system clean and reinstalled the whole environment to make sure there were not any corrupted libraries But the error still persists Source code logs ERROR tensorflow tensorflow stream executor BUILD 52 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 tensorflow stream executor cuda cuda dnn cc In member function 'cudnnStatus t perftools gputools cuda wrap WrapperShim cudnnSetRNNDescriptor v6 operator perftools gputools cuda CUDAExecutor Args ' tensorflow stream executor cuda cuda dnn cc 140 30 error ' cudnnSetRNNDescriptor v6' has not been declared cudnnStatus t retval name args tensorflow stream executor cuda cuda dnn cc 235 3 note in expansion of macro 'PERFTOOLS GPUTOOLS CUDNN WRAP' macro cudnnSetRNNDescriptor v6 tensorflow stream executor cuda cuda dnn cc 240 1 note in expansion of macro 'CUDNN DNN ROUTINE EACH R5' CUDNN DNN ROUTINE EACH R5 PERFTOOLS GPUTOOLS CUDNN WRAP tensorflow stream executor cuda cuda dnn cc In function 'int perftools gputools cuda anonymous CudnnDataTypeToByteSize cudnnDataType t ' tensorflow stream executor cuda cuda dnn cc 902 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In member function 'int perftools gputools cuda CudnnRnnParamsDescriptor GetRegionCountPerLayer const' tensorflow stream executor cuda cuda dnn cc 1255 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnRNNInputMode t perftools gputools cuda anonymous ToCudnnRnnInputMode perftools gputools dnn RnnInputMode ' tensorflow stream executor cuda cuda dnn cc 865 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnDirectionMode t perftools gputools cuda anonymous ToCudnnRnnDirectionMode perftools gputools dnn RnnDirectionMode ' tensorflow stream executor cuda cuda dnn cc 877 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnRNNMode t perftools gputools cuda anonymous ToCudnnRnnMode perftools gputools dnn RnnMode ' tensorflow stream executor cuda cuda dnn cc 889 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnDataType t perftools gputools cuda anonymous ToCudnnDataType perftools gputools dnn DataType perftools gputools dnn DataLayout ' tensorflow stream executor cuda cuda dnn cc 853 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionFwdAlgo t perftools gputools cuda anonymous ToConvForwardAlgo perftools gputools dnn AlgorithmDesc ' tensorflow stream executor cuda cuda dnn cc 297 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionBwdDataAlgo t perftools gputools cuda anonymous ToConvBackwardDataAlgo perftools gputools dnn AlgorithmDesc ' tensorflow stream executor cuda cuda dnn cc 320 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionBwdFilterAlgo t perftools gputools cuda anonymous ToConvBackwardFilterAlgo perftools gputools dnn AlgorithmDesc ' tensorflow stream executor cuda cuda dnn cc 342 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc At global scope tensorflow stream executor cuda cuda dnn cc 560 13 warning 'bool perftools gputools cuda TensorOpMathEnabled ' defined but not used Wunused function static bool TensorOpMathEnabled tensorflow stream executor cuda cuda dnn cc 129 26 warning 'tensorflow thread ThreadPool perftools gputools cuda wrap GetCudaThreadpool ' defined but not used Wunused function static port ThreadPool GetCudaThreadpool tensorflow stream executor cuda cuda dnn cc 2001 20 warning 'perftools gputools dnn AlgorithmDesc perftools gputools cuda anonymous GetCudnnConvolutionForwardAlgorithm perftools gputools Stream perftools gputools cuda CUDAExecutor void int const perftools gputools dnn AlgorithmConfig bool const perftools gputools cuda ScopedTensorDescriptor const perftools gputools cuda ScopedFilterDescriptor const perftools gputools cuda ScopedConvolutionDescriptor const perftools gputools cuda ScopedTensorDescriptor perftools gputools ScratchAllocator perftools gputools DeviceMemory unsigned char ' defined but not used Wunused function dnn AlgorithmDesc GetCudnnConvolutionForwardAlgorithm Target tensorflow libtensorflow all so failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 666 701s Critical Path 125 43s,,,2017-09-22 21:24:37,2017-11-04 03:26:59
PR,Fix cudnn v6 function being used in cudnn v5 build,Fixes 13249,,"benbarsdell,sb2nov,sb2nov,nluehr,nluehr",2017-09-23 00:35:42,2017-11-04 03:26:59
PR,Clean up our libcuda stub when building the GPU Docker container,,,"case540,case540",2017-11-03 18:25:51,2017-11-04 03:50:30
PR,Remove duplicated com google absl workspace object,,,"gunan,gunan",2017-11-04 03:02:51,2017-11-04 04:05:08
PR,Remove duplicated com google absl workspace object 14238,,,gunan,2017-11-04 04:08:29,2017-11-04 04:08:37
PR,Disable flaky prefetching ops test,,,"gunan,gunan",2017-11-04 03:55:23,2017-11-04 05:13:41
PR,typo fixed in CONTRIBUTING md,The noun phrase contribution decision code seems to be missing a determiner before it Consider adding an article,,martinwicke,2017-11-04 11:09:26,2017-11-04 15:01:02
IS,Can Tensorflow 1 4 use CUDA 9,I upgraded to tensorflow 1 4 I found that this version can not load cudart64 90 dll when i import tensorflow in python It can work when i use tensorflow 1 4 rc 0 But now it goes error Could not find 'cudart64 80 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Download and install CUDA 8 0 from this URL,,asimshankar,2017-11-04 05:21:44,2017-11-04 19:12:46
PR,CMake Generate gen audio ops py,Fixes 14004,,mrry,2017-11-03 14:52:44,2017-11-04 19:45:52
PR,change set tf cunn version to set tf cudnn version,,,gunan,2017-11-02 07:13:59,2017-11-04 19:49:04
IS,tf contrib learn Experiment train monitors should be renamed,Should not train monitors be renamed to train hooks As far as I understand hooks replaced monitors I look at TF v1 4 0 rc1 tf contrib learn Experiment estimator train input fn eval input fn eval metrics None train steps None eval steps 100 train monitors None eval hooks None local eval frequency None eval delay secs 120 continuous eval throttle secs 60 min eval frequency None delay workers by global step False export strategies None train steps per iteration None checkpoint and export False,,asimshankar,2017-11-03 20:40:18,2017-11-04 20:02:22
IS,Network behaviour inconsistent with Layer w r t build,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes provided below OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary pip install tf nightly gpu TensorFlow version use command below git v1 3 0 rc1 4090 g4e75ae1 tf 1 5 0 dev20171103 Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 GPU model and memory GTX 1070 8GB Describe the problem The tf layers Layer class exposes a build method which can optionally be called prior to first call e g to construct variables in a different scope to where the call is made The documentation does not explicitly promise that layers are built during build and not elsewhere but this seems to be the pattern with the implemented layers and is very useful in a narrow set of circumstances The tensorflow python layers base Network class implements tf layers Layer and exposes the same method but there is no way to construct the constructor arguments without building constituent layers This is unexpected and misleading and prevents use of Network s where unbuilt Layer s are expected required A lazily built Network implementation would be greatly appreciated as would clarity on whether it is the intention that all classes implementing Layer should be build separately from their constructor Illustrative example basic lazy implementation below Source code,,"asimshankar,fchollet",2017-11-04 04:43:30,2017-11-04 21:12:02
PR,Add missing flags to tfdbg doc chart,Some command flags for tfdbg were not listed in the doc chart This commit adds the ones that are missing,,"pvaneck,caisq,pvaneck",2017-11-03 23:00:22,2017-11-04 22:02:00
PR,Update For more information in README,Change from lowercase to uppercase,,"PW486,PW486",2017-11-03 05:13:11,2017-11-05 05:42:36
PR,Fixes for Raspberry Pi cross compilation in CI Build,,,"petewarden,petewarden,gunan",2017-11-05 02:29:55,2017-11-05 05:47:31
PR,Update word2vec basic py in generate batch,File word2vec basic py line 139 in generate batch buffer data span TypeError sequence index must be integer not islice' got above messages running in python 2 7 updating line 139 from buffer data span to buffer extend data 0 span The updating has passed my own test and can works thanks,,gunan,2017-11-03 07:16:31,2017-11-05 06:07:47
PR,Update head py,Minor typo fix,,alanyee,2017-11-03 02:21:23,2017-11-05 06:09:13
PR,Fix typos,This PR fixes some typos tf constant tf placeholder,,,2017-11-01 11:41:12,2017-11-05 06:23:10
PR,typo fixed,there is an additional whitespace between ' the method ',,,2017-10-30 11:11:21,2017-11-05 06:26:48
PR,Update comments for variables in get started,This PR updates the comments in the Getting Started guide to make it more clear to which variables they refer to,,,2017-11-01 09:55:14,2017-11-05 06:27:58
PR,Add a GPU kernel for tf dynamic partition,This PR partially addresses issue 5965 The implementation follows closely the outline proposed by in the comments use cub to radix sort the information in partitions compute the dimension of the output and allocate it use tf gather to move data to the correct output tensor I wrote a benchmark test to compare it to the CPU implementation The speedup is substantial The gpu version runs 4 8 37 times faster with the biggest gain obtained for 1D data The benchmark tests used a 128MD data buffer either 1D or with 256 columns and num partitions was either 2 or 100 The drawback to the implementation is that it requires some additional device memory If I is the size of the input O the size of the output N the size of partitions and P the number of partitions the total memory cost is roughly I P max 5N O N so about 4N additional memory is needed in the worst case Most of it comes from using cub RadixSort However N is large only if data is 1D and this additional memory cost becomes prohibitive only for gigantic 1D vectors 512MB which I do not think is a common use case,,"codrut3,ekelsen,ekelsen,ekelsen,ekelsen,codrut3,codrut3,ekelsen,ekelsen,ekelsen,codrut3,codrut3,vrv,vrv,vrv,gunan,codrut3,vrv,gunan,codrut3,gunan,codrut3",2017-10-22 16:42:10,2017-11-05 06:33:32
PR,Add RDMA verbs configuration,RDAM configuration is now possible with the following environment variables RDMA DEVICE RDMA DEVICE PORT RDMA GID INDEX RDMA PKEY RDMA QUEUE DEPTH RDMA TIMEOUT RDMA RETRY CNT RDMA SL RDMA MTU and RDMA TRAFFIC CLASS,,"dariavel,byronyi,dariavel,dariavel,drpngx,drpngx,gunan,drpngx,gunan,gunan,gunan",2017-10-08 10:12:11,2017-11-05 06:35:16
IS,unique in special axis,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version cuDNN v5 1 GPU model and memory pascal titan x Exact command to reproduce None Feature Request For getting unique row we can use numpy is unique by specifying the axis However in tensorflow unique only support 1D tensor which is not convenient,,"drpngx,yongtang",2017-07-18 12:48:32,2017-11-05 06:38:57
PR,Add support of axis for tf unique,This fix tries to address the request from 11575 where axis was not supported for tf unique This fix adds support of axis for tf unique In this fix the additional input axis has been specified as an 1D vector so that it is possible to optionally provide an axis or not In case axis is provided no axis is used In case axis x is used axis for tf unique is x ref This fix fixes 11575 Signed off by Yong Tang yong tang github outlook com,,"yongtang,a-dai,a-dai,a-dai,yongtang,yongtang,yongtang,drpngx,caisq,yongtang,a-dai,yongtang,drpngx,drpngx,yongtang,yongtang,gunan,gunan,yongtang,yongtang,gunan",2017-09-11 01:52:41,2017-11-05 06:38:57
PR,In the line 240 the string 'conv 3' miss the d,I think the author missed the ' d' to name the related net scope so the correct code is net slim conv2d net 256 3 3 scope 'conv3 d' i 1 NOT net slim conv2d net 256 3 3 scope 'conv3 ' i 1,,"jhseu,martinwicke,drpngx,sb2nov,drpngx,gunan,gunan,gunan,martinwicke,gunan,gunan",2017-08-25 01:52:56,2017-11-05 06:52:05
IS,org tensorflow TensorFlowException Op type not registered 'Sum' in binary running on localhost Make sure the Op and Kernel are registered in the binary running in this process,System information Have I written custom code I worte a code that is based on this trying to produce mfcc works fine in python but i cannot make it work in Android OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version 1 4 2 Python version 2 7 Bazel version 0 7 0 Describe the problem i have reduced my graph to this PYTHON CODE that creates the pb import sugartensor as tf from tensorflow python framework import graph util from model import import data import os import sys from tensorflow contrib framework python ops import audio ops as contrib audio import functools from tensorflow contrib session bundle import exporter from tensorflow python tools import freeze graph global session config exportfilename 'out2 export mfcc only pb' with tf device ' cpu 0' session config tf ConfigProto allow soft placement True log device placement False tf app flags DEFINE integer 'export version' 1 haversion number of the exported model' session tf InteractiveSession session tf Session Run inference batch size 1 voca size data voca size sample rate 16000 0 wavdata tf placeholder tf float32 None name wav float input pcm tf expand dims wavdata 0 stfts tf contrib signal stft pcm frame length 2048 frame step 512 fft length 2048 window fn functools partial tf contrib signal hann window periodic False pad end True spectrograms tf abs stfts Warp the linear scale spectrograms into the mel scale num spectrogram bins stfts shape 1 value lower edge hertz upper edge hertz num mel bins 0 0 8000 0 128 linear to mel weight matrix tf contrib signal linear to mel weight matrix num mel bins num spectrogram bins sample rate lower edge hertz upper edge hertz mel spectrograms tf tensordot spectrograms linear to mel weight matrix 1 mel spectrograms set shape spectrograms shape 1 concatenate linear to mel weight matrix shape 1 Compute a stabilized log to get log magnitude mel scale spectrograms log mel spectrograms tf log mel spectrograms 1e 6 Compute MFCCs from log mel spectrograms and take the first 13 mfccs tf contrib signal mfccs from log mel spectrograms log mel spectrograms 20 seq len tf size mfccs sg int sg sum axis 2 name output node session run tf local variables initializer tf global variables initializer subgraph tf graph util extract sub graph session graph def output node frozen graph def graph util convert variables to constants session subgraph output node tf train write graph frozen graph def os path dirname exportfilename os path basename exportfilename as text False tf logging info 'Saved frozen graph to s' exportfilename END OF PYTHON CODE i manage to load it and test the created pb it in python i create libtensorflow inference so using print selective registration header as described in tensorflow tensorflow python tools print selective registration header py testing the code in Androids results in an Error when i load the model 11 03 16 15 31 790 8639 8639 org tensorflow demo E native executor cc 651 Executor failed to create kernel Not found No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 Registered no registered kernels Node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 11 03 16 15 31 790 8639 8639 org tensorflow demo E native executor cc 651 Executor failed to create kernel Not found No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 Registered no registered kernels Node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 11 03 16 15 31 800 8639 8639 org tensorflow demo E native executor cc 651 Executor failed to create kernel Not found No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 Registered no registered kernels Node Tensordot ListDiff 1 ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 3 Tensordot add 3 11 03 16 15 31 810 8639 8639 org tensorflow demo E native executor cc 651 Executor failed to create kernel Not found No registered 'ListDiff' OpKernel for CPU devices compatible with node Tensordot ListDiff ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 2 Tensordot add 1 Registered no registered kernels Node Tensordot ListDiff ListDiff T DT INT32 out idx DT INT32 device device CPU 0 Tensordot range 2 Tensordot add 1 11 03 16 15 31 870 8639 8639 org tensorflow demo E AndroidRuntime FATAL EXCEPTION main Process org tensorflow demo PID 8639 org tensorflow TensorFlowException Op type not registered 'Sum' in binary running on localhost Make sure the Op and Kernel are registered in the binary running in this process i see that both 'ListDiff' and 'Sum' ops are in the ops to register h file that is generated by the print selective registration header process is there a workaround for this,,,2017-11-03 14:52:05,2017-11-05 07:03:34
PR,Fix typos,This PR fixes some typos a same specifed signalled and compatiblity,,"taehoonlee,gunan",2017-11-03 08:07:40,2017-11-05 07:17:48
PR,Float16 half or Eigen half for conv3d ops,Registrations of conv3d operations with fp16 fp16 for batch norms in tf layers and tf contrib layers Related issue I do not understand how fp16 operations must be implemented in low level with CUDA and I did not make any additional optimizations There is no implementation for fused batch norm yet I copied part of code for dtypes from conv2d test to conv3d test and seems like all works With fp16 I get inf and large absolute errors with large numbers I suppose that it is fine At least CPU and GPU implementations return almost similar values I skip such cases in test Example of such case use gpu False dtype dtype 'float32' data format NDHWC expected 36564 0 38022 0 39480 0 37824 0 39354 0 40884 0 39084 0 40686 0 42288 0 46644 0 48678 0 50712 0 47904 0 50010 0 52116 0 49164 0 51342 0 53520 0 107124 0 112614 0 118104 0 108384 0 113946 0 119508 0 109644 0 115278 0 120912 0 117204 0 123270 0 129336 0 118464 0 124602 0 130740 0 119724 0 125934 0 132144 0 actual 36564 38022 39480 37824 39354 40884 39084 40686 42288 46644 48678 50712 47904 50010 52116 49164 51342 53520 107124 112614 118104 108384 113946 119508 109644 115278 120912 117204 123270 129336 118464 124602 130740 119724 125934 132144 use gpu False dtype dtype 'float16' data format NDHWC expected 36564 0 38022 0 39480 0 37824 0 39354 0 40884 0 39084 0 40686 0 42288 0 46644 0 48678 0 50712 0 47904 0 50010 0 52116 0 49164 0 51342 0 53520 0 107124 0 112614 0 118104 0 108384 0 113946 0 119508 0 109644 0 115278 0 120912 0 117204 0 123270 0 129336 0 118464 0 124602 0 130740 0 119724 0 125934 0 132144 0 actual 36544 38016 39488 37824 39360 40896 39072 40704 42304 46656 48672 50688 47936 50016 52128 49184 51328 53536 inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf fp16 using may result in inf values and large absolute errors when used with large numbers skipping use gpu True dtype dtype 'float32' data format NDHWC expected 36564 0 38022 0 39480 0 37824 0 39354 0 40884 0 39084 0 40686 0 42288 0 46644 0 48678 0 50712 0 47904 0 50010 0 52116 0 49164 0 51342 0 53520 0 107124 0 112614 0 118104 0 108384 0 113946 0 119508 0 109644 0 115278 0 120912 0 117204 0 123270 0 129336 0 118464 0 124602 0 130740 0 119724 0 125934 0 132144 0 actual 36564 38022 39480 37824 39354 40884 39084 40686 42288 46644 48678 50712 47904 50010 52116 49164 51342 53520 107124 112614 118104 108384 113946 119508 109644 115278 120912 117204 123270 129336 118464 124602 130740 119724 125934 132144 use gpu True dtype dtype 'float16' data format NDHWC expected 36564 0 38022 0 39480 0 37824 0 39354 0 40884 0 39084 0 40686 0 42288 0 46644 0 48678 0 50712 0 47904 0 50010 0 52116 0 49164 0 51342 0 53520 0 107124 0 112614 0 118104 0 108384 0 113946 0 119508 0 109644 0 115278 0 120912 0 117204 0 123270 0 129336 0 118464 0 124602 0 130740 0 119724 0 125934 0 132144 0 actual 36576 38016 39488 37824 39360 40896 39072 40672 42304 46656 48672 50720 47904 50016 52128 49152 51328 53504 inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf fp16 using may result in inf values and large absolute errors when used with large numbers skipping fp16 is not fully covered by tests because I not sure how to do it,,"yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm,yifeif,drpngx,sb2nov,yzhwang,drpngx,reedwm,reedwm",2017-09-05 23:07:16,2017-11-05 07:23:37
PR,Initial Haiku support,,,"gunan,martinwicke,martinwicke,gunan,gunan",2017-10-08 14:41:24,2017-11-05 07:27:26
PR,Minor change in tolerance to pass resnet v1 test test on ppc64le,As discussed here I am raising this PR to fix resnet v1 test failure Thanks Sandip,,"sandipmgiri,gunan,gunan",2017-10-30 08:49:41,2017-11-05 07:28:38
PR,Fix typo specified,typo fix specfied specified,,"ManHyuk,gunan,ManHyuk",2017-11-03 13:34:00,2017-11-05 09:02:49
PR,Update learning py,Replace variables for training util Replace tf variables with variables,,alanyee,2017-11-05 06:23:22,2017-11-05 09:24:59
IS,Issue with installing TensorFlow with pip,Hi I'm using Python 3 6 3 I'm trying to install TensorFlow using pip3 install upgrade tensorflow I get the following error Collecting tensorflow Could not find a version that satisfies the requirement tensorflow from versi ons No matching distribution found for tensorflow Could someone help to fix this,,"asimshankar,asimshankar,caisq",2017-11-04 19:45:37,2017-11-05 10:26:02
IS,Feature request GPU support for tf bincount,Hi In my opinion tf bincount is a very useful and simple function to build weighted histograms like in the example below but recently i learned that unfortunately does not have GPU support It could be very useful to run it on GPU since i can not figure any simple way to do a weighted histogram efficiently Thanks,,"asimshankar,ekelsen,ekelsen,ekelsen,ekelsen,yongtang",2017-07-17 15:36:05,2017-11-05 18:20:11
PR,Add GPU kernel for tf bincount,This fix tries to address the issue raised in 11554 where there is no GPU support for tf bincount This fix adds GPU support for tf bincount This fix fixes 11554 Signed off by Yong Tang yong tang github outlook com,,"yongtang,ekelsen,ekelsen,ekelsen,ekelsen,yongtang,yongtang,yongtang,yongtang,ekelsen,ekelsen,yongtang,yongtang,ekelsen,vrv,vrv,yongtang,ekelsen,yongtang,ringw,yongtang,yongtang,yongtang,vrv,ringw,yongtang,ringw,ringw,yongtang,yongtang,gunan,yongtang,yongtang,yongtang,gunan",2017-10-18 16:31:44,2017-11-05 18:20:11
PR,R1 4,,,,2017-11-05 22:06:19,2017-11-05 22:48:14
PR,Fix typo in mobile prepare models md,This fix fixes a typo in mobile prepare models md targetting targeting Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-11-05 16:33:19,2017-11-05 22:48:44
PR,Revert Upgrade gRPC 13958,This reverts commit fccc3d2365fca265d3c6cecf367a3b147b7b51dc FYI This fixes the build failure we see here This was missed because we do not build verbs in our PR tests which we should fix I verified this rollback fixes the build failures,,gunan,2017-11-05 21:45:19,2017-11-05 23:01:05
PR,Fix position of arguments of nce loss calculation,The nce loss positional arguments in word2vec simple py are incorrect leading to the following traceback Traceback most recent call last File word2vec simple py line 168 in num sampled vocabulary size File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops nn impl py line 1151 in nce loss name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops nn impl py line 981 in compute sampled logits sampled logits math ops matmul inputs sampled w transpose b True File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops math ops py line 1844 in matmul a b transpose a transpose a transpose b transpose b name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python ops gen math ops py line 1289 in mat mul transpose b transpose b name name File anaconda2 envs tensorflow lib python2 7 site packages tensorflow python framework op def library py line 526 in apply op inferred from input arg type attr TypeError Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a' This patch fixes the positional arguments of nce loss and adds keyword arguments to make it more explicit,,gunan,2017-10-29 04:26:50,2017-11-06 02:48:09
IS,'MultivariateNormalDiag' object has no attribute 'pdf' ERROR,Hi I am trying to use tf contrib distributions MultivariateNormalDiag as explained in the API macOS High Sierra TensorFlow version v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 6 1 Here is the code that throws the error mu1 tf to float tf fill batch size z dim 0 diag stdev1 tf to float tf fill batch size z dim 1 dist1 tf contrib distributions MultivariateNormalDiag mu1 diag stdev1 mu2 tf to float tf fill batch size z dim 1 diag stdev2 tf to float tf fill batch size z dim 1 dist2 tf contrib distributions MultivariateNormalDiag mu2 diag stdev2 z gmm dist1 pdf z dist2 pdf z And the error I get is AttributeError 'MultivariateNormalDiag' object has no attribute 'pdf' Does anybody have the same problem Thank you for you time,,asimshankar,2017-11-05 20:24:49,2017-11-06 03:51:20
PR,fix fused batchnorm test py,In file fused batchnorm test py the function reference training L39 use,,gunan,2017-10-30 17:35:52,2017-11-06 04:00:58
PR,Set macro instead of surpressing the warning for third party zlib BUILD,As described in issue 13188,,sb2nov,2017-09-22 17:05:01,2017-11-06 04:02:32
PR,Add gradient tests for tf maximum and tf minimum,Was looking into adding gradient tests for tf clip by value discussion r147542917 and then noticed that there is no gradient tests in math grad test py for tf maximum and tf minimum Think it makes sense to add a gradient test to cover tf maximum and tf minimum Signed off by Yong Tang yong tang github outlook com,,"yongtang,gunan",2017-10-29 17:44:15,2017-11-06 04:04:06
PR,Arbitrary dim for slice,Add arbitrary dim support for slice op There is still a compiling problem When build tensorflow core kernel slice op test I got the following errors It looks like there are some types which have not be instantiated However I can not find that where are these type used And simply add these instantiation is not a good idea Could you give some help,,"yanchen036,drpngx,yanchen036,drpngx,yanchen036,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,yanchen036,yanchen036,yanchen036,yanchen036,yanchen036,aselle,aselle,yanchen036,drpngx,yanchen036,drpngx,yanchen036,drpngx,yanchen036,gunan,girving,girving,drpngx,yanchen036,yanchen036,girving,drpngx,yanchen036,drpngx,yanchen036,drpngx,drpngx,yanchen036,yanchen036,rmlarsen,jhseu,martinwicke,martinwicke,yanchen036,drpngx,drpngx,yanchen036,sb2nov,drpngx,sb2nov,gunan,yanchen036,gunan",2017-06-29 14:31:31,2017-11-06 04:06:20
PR,Fix ProfileContext location in README,,,"bryant1410,bryant1410,drpngx,sb2nov,gunan",2017-08-22 15:23:25,2017-11-06 04:21:07
IS,Android No OpKernel was registered to support Op 'SparseToDense' with these attrs,I am trying to load a graph inside Android that I generated and frozen I keep getting this error whenever I try to run it,,"selcouthlyBlue,reedwm,selcouthlyBlue,petewarden,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue",2017-10-12 03:05:14,2017-11-06 04:21:30
PR,Fix failing build on Fedora 26 stropts h,Tensorflow branches 1 4 and master do not build on Fedora 26 When bazel builds curl as a third party package the file stropts h is always included while it is no longer present on many Linux distributions including Fedora Curl can be easily built without it by removing the HAVE STROPTS flag This problem was already mentioned tensorflow serving 320 The solution proposed there is to create an empty usr include stropts h as root Because that is not always possible just removing the HAVE STROPTS flag seems to be a better solution,,"gunan,gunan,gunan",2017-10-28 04:26:26,2017-11-06 04:33:28
PR,Eliminate ambiguity,batch size shape means the sum of two matrix,,"larrytin,gunan",2017-11-02 04:34:44,2017-11-06 04:53:39
IS,the version for windows,Hi could you build the new version of tensorflow for windows the cuda version just tensorflow 1 1,,mrry,2017-11-06 00:16:31,2017-11-06 05:41:13
IS,Cannot interpret feed dict key as tensor tensor tensor import input 0 shape 1 299 299 3 dtype float32 is not an element of this graph,I'm running label image py given at url on inception resnet v2 frozen graph When I run this code it is giving me the following error cannot interpret feed dict key as tensor tensor tensor import input 0 shape 1 299 299 3 dtype float32 is not an element of this graph But when I print the tensors there exists the above tensor in the graph Could anyone please help me with this Thanks in advance,,jart,2017-11-06 07:24:45,2017-11-06 08:15:41
IS,how can I print predictions in TF Slim is eval image classifier py,I want to print prediction results into txt files in TF Slim eval image classifier py I have tried many times but failed to do it Thank you in advance from future import absolute import from future import division from future import print function import math import tensorflow as tf from datasets import dataset factory from nets import nets factory from preprocessing import preprocessing factory slim tf contrib slim tf app flags DEFINE integer 'batch size' 100 'The number of samples in each batch ' tf app flags DEFINE integer 'max num batches' None 'Max number of batches to evaluate by default use all ' tf app flags DEFINE string 'master' '' 'The address of the TensorFlow master to use ' tf app flags DEFINE string 'checkpoint path' ' tmp tfmodel ' 'The directory where the model was written to or an absolute path to a ' 'checkpoint file ' tf app flags DEFINE string 'eval dir' ' tmp tfmodel ' 'Directory where the results are saved to ' tf app flags DEFINE integer 'num preprocessing threads' 4 'The number of threads used to create the batches ' tf app flags DEFINE string wouldataset name' 'imagenet' 'The name of the dataset to load ' tf app flags DEFINE string wouldataset split name' 'test' 'The name of the train test split ' tf app flags DEFINE string wouldataset dir' None 'The directory where the dataset files are stored ' tf app flags DEFINE integer 'labels offset' 0 'An offset for the labels in the dataset This flag is primarily used to ' 'evaluate the VGG and ResNet architectures which do not use a background ' 'class for the ImageNet dataset ' tf app flags DEFINE string 'model name' 'inception v3' 'The name of the architecture to evaluate ' tf app flags DEFINE string 'preprocessing name' None 'The name of the preprocessing to use If left ' 'as None then the model name flag is used ' tf app flags DEFINE float 'moving average decay' None 'The decay to use for the moving average ' 'If left as None then moving averages are not used ' tf app flags DEFINE integer 'eval image size' None 'Eval image size' FLAGS tf app flags FLAGS def main if not FLAGS dataset dir raise ValueError 'You must supply the dataset directory with dataset dir' tf logging set verbosity tf logging INFO with tf Graph as default tf global step slim get or create global step Select the dataset dataset dataset factory get dataset FLAGS dataset name FLAGS dataset split name FLAGS dataset dir Select the model network fn nets factory get network fn FLAGS model name num classes dataset num classes FLAGS labels offset is training False Create a dataset provider that loads data from the dataset provider slim dataset data provider DatasetDataProvider dataset shuffle False common queue capacity 2 FLAGS batch size common queue min FLAGS batch size image label provider get 'image' 'label' label FLAGS labels offset Select the preprocessing function preprocessing name FLAGS preprocessing name or FLAGS model name image preprocessing fn preprocessing factory get preprocessing preprocessing name is training False eval image size FLAGS eval image size or network fn default image size image image preprocessing fn image eval image size eval image size images labels tf train batch image label batch size FLAGS batch size num threads FLAGS num preprocessing threads capacity 5 FLAGS batch size Define the model logits network fn images if FLAGS moving average decay variable averages tf train ExponentialMovingAverage FLAGS moving average decay tf global step variables to restore variable averages variables to restore slim get model variables variables to restore tf global step op name tf global step else variables to restore slim get variables to restore predictions tf argmax logits 1 labels tf squeeze labels Define the metrics names to values names to updates slim metrics aggregate metric map 'Accuracy' slim metrics streaming accuracy predictions labels 'Recall 5' slim metrics streaming recall at k logits labels 5 Print the summaries to screen for name value in names to values items summary name 'eval s' name op tf summary scalar summary name value collections op tf Print op value summary name tf add to collection tf GraphKeys SUMMARIES op TODO sguada use num epochs 1 if FLAGS max num batches num batches FLAGS max num batches else This ensures that we make a single pass over all of the data num batches math ceil dataset num samples float FLAGS batch size if tf gfile IsDirectory FLAGS checkpoint path checkpoint path tf train latest checkpoint FLAGS checkpoint path else checkpoint path FLAGS checkpoint path tf logging info 'Evaluating s' checkpoint path slim evaluation evaluate once master FLAGS master checkpoint path checkpoint path logdir FLAGS eval dir num evals num batches eval op list names to updates values variables to restore variables to restore if name ' main ' tf app run,,jart,2017-11-06 07:08:19,2017-11-06 08:15:59
IS,How to realize model parallelism,I cannot find the model parallelism in the tensorflow there are many examples about data parallelism I write a programm to realize the model parallelism but it cannot work from future import print function import tensorflow as tf import numpy as np tf train ClusterSpec worker node1 2222 ps node2 2222 with tf device job ps task 0 weights tf Variable tf random normal 1 dtype tf float32 name 'weights' bias tf Variable tf ones 1 0 5 dtype tf float32 name 'bias' with tf device job worker task 0 X np random normal 0 100 100000 y X 0 5 10 np random normal 0 0 1 len X results weights X bias loss tf reduce mean tf square y results optimizer tf train GradientDescentOptimizer 0 1 train op optimizer minimize loss init tf global variables initializer with tf Session grpc 2222 as sess sess run init for in range 10000 Loss T sess run loss train op print Loss,,jart,2017-11-06 07:35:32,2017-11-06 08:16:16
IS,RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra 10 13 1 TensorFlow installed from source or binary pip3 install tensor flow TensorFlow version use command below 1 4 0 Python version 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source GCC stable 7 2 0 CUDA cuDNN version GPU model and memory Exact command to reproduce python3 c import tensorflow as tf print tf GIT VERSION tf VERSION You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Error after install Tensorflow python3 c import tensorflow as tf print tf GIT VERSION tf VERSION usr local Cellar python3 3 6 3 Frameworks Python framework Versions 3 6 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds v1 4 0 rc1 11 g130a514 1 4 0 getting this and ONE MORE error when running python3 c import keras print keras version Using TensorFlow backend usr local Cellar python3 3 6 3 Frameworks Python framework Versions 3 6 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds 2017 11 06 15 12 09 361728 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2 0 9 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-11-06 06:56:52,2017-11-06 08:26:17
PR,better visualization name,,,,2017-11-06 09:29:14,2017-11-06 09:29:23
IS,tensorflow contrib slim python slim nets resnet v1 test py test is failing with array mismatch error,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source TensorFlow version use command below TF 1 3 1 Python version Python 2 7 5 Bazel version if compiling from source bazel 0 5 4 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel test config opt tensorflow contrib slim python slim nets resnet v1 test Describe the problem This test is failing due to array mismatch error a single value in an array of 100 elements differing i e 0 69775391 VS expected 0 69799805 minor mismatch I feel this is not critical Hence I tried running this test by changing minor tolerance atol 1e 4 to atol 2e 4 and test is passing L389 Original output eval expected eval atol 1e 4 rtol 1e 4 Update to output eval expected eval atol 2e 4 rtol 1e 4 Is it OK to raise a PR with this changes Please provide your comments on this Thanks Source code logs bazel test config opt tensorflow contrib slim python slim nets resnet v1 test,,"sandipmgiri,skye,sandipmgiri,sandipmgiri",2017-10-26 10:25:25,2017-11-06 09:42:21
IS,tf gradients return NaN when batch norm is in inference mode is training False,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 11 Anaconda custom 64 bit Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version usr local cuda 8 0 libcudnn so 6 0 21 GPU model and memory GeForce GTX 1080 Exact command to reproduce I guess the issue comes from the slim batch norm when it is in inference mode and somehow tf gradients does not work anymore Why 1 vgg and lenet without batch norm layers work well 2 inception and resnet with batch norm layers return nan 3 inception and resnet work after I enforce the is training True of slim batch norm 4 it seems reasonable to ignore the possibility of the usage of tf gradients when batch norm is in inference mode,,ppwwyyxx,2017-11-06 05:07:46,2017-11-06 15:18:43
IS,Tensorflow splitting,I want to split tensor into two parts ipdb mean log std tf Tensor 'pi add 5 0' shape 2 dtype float32 Context is for number of samples and the other dimension is 2 I want to split along the second dimension into two tensorflow of shape 1 along that dimension What I tried ipdb tf slice mean log std 0 2 0 1 tf Tensor 'pi Slice 6 0' shape 0 1 dtype float32 ipdb tf slice mean log std 0 1 0 1 tf Tensor 'pi Slice 7 0' shape 0 1 dtype float32 ipdb I would expect the shape to be 1 and 1 for the above two splits,,jart,2017-11-06 02:04:14,2017-11-06 15:48:50
IS,error during install,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 windows10 TensorFlow installed from source or binary anaconda 5 0 0 TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem i'm trying to install tensorflow through anaconda 5 0 0 and i got this lines and i can not finish my install plz help me Source code logs Exception Traceback most recent call last File C ProgramData Anaconda3 lib site packages pip basecommand py line 215 in main status self run options args File C ProgramData Anaconda3 lib site packages pip commands install py line 342 in run prefix options prefix path File C ProgramData Anaconda3 lib site packages pip req req set py line 784 in install kwargs File C ProgramData Anaconda3 lib site packages pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File C ProgramData Anaconda3 lib site packages pip req req install py line 1064 in move wheel files isolated self isolated File C ProgramData Anaconda3 lib site packages pip wheel py line 345 in move wheel files clobber source lib dir True File C ProgramData Anaconda3 lib site packages pip wheel py line 323 in clobber shutil copyfile srcfile destfile File C ProgramData Anaconda3 lib shutil py line 121 in copyfile with open dst 'wb' as fdst PermissionError Errno 13 Permission denied 'C ProgramData Anaconda3 Lib site packages wheel archive py',,jart,2017-11-02 10:45:04,2017-11-06 16:17:32
IS,Compilation progress indicator is useless,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below master from around now Python version Bazel version if compiling from source 0 6 1 GCC Compiler version if compiling from source Apple LLVM 9 0 0 CUDA cuDNN version GPU model and memory Exact command to reproduce Any compilation e g bazel build tensorflow tools pip package build pip package Whenever I compile Tensorflow Bazel shows a nice progress indicator for example 1 428 1 437 Compiling tensorflow core kernels cast op impl int64 cc However that progress proceeds something like this 4 15 20 26 264 275 1 821 1 832 3 456 3 470 Pretty useless Compiling Tensorflow takes about 45 minutes on my system and it seems to want to do a complete recompile at the drop of a hat so it would be useful at least if I know whether I should wait for it or go and cook dinner Is there anything that could be done to improve this,,jart,2017-11-06 16:15:27,2017-11-06 16:34:41
IS,Neural Net regression in Tensorflow,Describe the problem Hi I am trying to perform a Neural Network in tensorflow for The Bike Sharing Dataset with a regresion model I checked out the tensorflow tutorials but I could not find a solution Something is wrong with the tf matmul and the input and targets matrix Source code logs Here is my repository and the dataset Thanks so much,,jart,2017-11-06 09:32:15,2017-11-06 16:37:48
IS,Concert keras model to tf Keras model,here is my original keras model def inference image tensor the input size is 90 30 3 x Conv2D 32 3 3 name 'conv1' image tensor x MaxPool2D 2 2 name 'pool1' x x BatchNormalization name 'bn1' x x Activation arelu' x x Conv2D 64 3 3 name 'conv2' x x MaxPool2D 2 2 name 'pool2' x x BatchNormalization name 'bn2' x x Activation arelu' x x Conv2D 64 3 3 name 'conv3' x x MaxPool2D 2 2 name 'pool3' x x BatchNormalization name 'bn3' x x Activation arelu' x x Flatten name 'flatte1' inputs x x Dense 256 name 'fc1' x max length of sentence x RepeatVector 7 name arepeat' x 2 GRU the output shape is None 7 256 x Bidirectional GRU units 128 name 'GRU' return sequences True x apply None 7 256 to all GRUs output None 7 16 x TimeDistributed Dense 16 name 'fc2' x x Activation isoftmax' x x Flatten name 'Flatten2' inputs x when I show my summary it print like this Layer type Output Shape Param input 1 InputLayer None 90 30 3 0 conv1 Conv2D None 88 28 32 896 pool1 MaxPooling2D None 44 14 32 0 bn1 BatchNormalization None 44 14 32 128 activation 1 Activation None 44 14 32 0 conv2 Conv2D None 42 12 64 18496 pool2 MaxPooling2D None 21 6 64 0 bn2 BatchNormalization None 21 6 64 256 activation 2 Activation None 21 6 64 0 conv3 Conv2D None 19 4 64 36928 pool3 MaxPooling2D None 9 2 64 0 bn3 BatchNormalization None 9 2 64 256 activation 3 Activation None 9 2 64 0 flatte1 Flatten None 1152 0 fc1 Dense None 256 295168 repeat RepeatVector None 7 256 0 bidirectional 1 Bidirection None 7 256 295680 time distributed 1 TimeDist None 7 16 4112 Flatten2 Flatten None 112 0 but when I change my codes to tf keras like this the architecture do not change repeat RepeatVector None 7 256 0 bidirectional 1 Bidirection None None 256 295680 time distributed 1 TimeDist None None 16 4112 activation 4 Activation None None 16 0 Flatten2 Flatten None None 0 Total params 651 920 Trainable params 651 600 Non trainable params 320 the output of bidirectional 1 is None None 256 I just wonder why the GRU output was flase And how can I change my code Thanks a lot,,jart,2017-11-04 05:02:57,2017-11-06 16:38:26
IS,Feature Request tf resume gradient,tf stop gradient provides a convenient way for various uses However sometimes it may be useful to resume the gradient passing after some conditions are met For example in Faster RCNN algorithm the RPN layers' gradients are stopped because they may cause unstable results in early rounds However this indicates that these layers' weights would be kept the initial random values forever If we could resume the gradients back propagation after several steps the results may be better Therefore I believe that the resume gradient function would be useful Thank you,,"ppwwyyxx,jart,ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx",2017-11-01 18:23:36,2017-11-06 16:45:15
IS,Suggestion Add Image Captioning Model Example for Android,This is a suggestion to add Android example for our deep learning based tensorflow android app which captions live camera frames in real time This app uses pre trained model generated using,,jart,2017-11-03 13:52:30,2017-11-06 17:25:37
IS,Tensorflow 1 4 Keras issue with respect to model fn,I have a model function which accepts Features targets and mode but when I add tf keras layers I'm currently getting Exception pred must be a Tensor a Variable or a Python bool But When I run the same code with out using tf keras but directly from keras i e from keras layers It is working Code Exception File D PyCharm Workspace Keras Exp finance complaints tensorflow tf finance complaints py line 149 in module finance classifier train input fn lambda input fn wouldataset train csv' batch size 32 repeat count 5 shuffle True File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python estimator estimator py line 302 in train loss self train model input fn hooks saving listeners File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python estimator estimator py line 711 in train model features labels model fn lib ModeKeys TRAIN self config File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python estimator estimator py line 694 in call model fn model fn results self model fn features features kwargs File D PyCharm Workspace Keras Exp finance complaints tensorflow tf finance complaints py line 108 in model fn f1 tf keras layers Dropout 0 2 embeds File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python keras impl keras engine topology py line 252 in call output super Layer self call inputs kwargs File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python layers base py line 575 in call outputs self call inputs args kwargs File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python keras impl keras layers core py line 118 in call output super Dropout self call inputs training training File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python layers core py line 300 in call lambda array ops identity inputs File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python layers utils py line 203 in smart cond pred value constant value pred File E Programs Anaconda3 envs tensorflow gpu lib site packages tensorflow python layers utils py line 233 in constant value raise TypeError ' pred must be a Tensor a Variable or a Python bool ' TypeError pred must be a Tensor a Variable or a Python bool,,jart,2017-11-03 02:26:47,2017-11-06 17:26:17
IS,Is something wrong about slim learning train,source code My code is so complex and very very long so I just describe my code logic I add two parameters run tensor and run placeholder to slim learning train the run tensor is the tensor I want to run and the run placeholder is placeholder I need to feed And I also add two parameters run tensor and run placeholder to train step L456 and train step is passed to slim learning train is train step fn So every training step I can run run tensor in the train step function and I'm sure I have fed the run placeholder but when I run the program it raise an error like I debug for long time and find it may be the line L779 I have updated tensorflow to 1 4 0 but I find my slim learning train only use sv stop threads close summary writer True without ignore live threads ignore live threads I find what is wrong it is tf summary scalar slim does not run summary op with feed dict Maybe I think slim need to support feed dict on every training step,,,2017-11-06 12:31:39,2017-11-06 19:14:28
IS,Failed to load the native TensorFlow runtime,when I import tensorflow gpu import tensorflow as tf this message occurs Traceback most recent call last File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File home wonjinlee local lib python3 5 site packages tensorflow init py line 24 in module from tensorflow python import File home wonjinlee local lib python3 5 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow py line 72 in module raise ImportError msg ImportError Traceback most recent call last File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home wonjinlee local lib python3 5 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,,2017-11-06 09:19:55,2017-11-06 19:19:29
IS,CUDA ERROR OUT OF MEMORY on multiple and single GPU set up 1080Ti,Hi I am having troubles running any tensorflow code on my 4x1080Ti GPU set up This is the code I am running just to reproduce the issue import tensorflow as tf a tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 2 3 name 'a' b tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 3 2 name 'b' c tf matmul a b gpu options tf GPUOptions per process gpu memory fraction 0 6 with or without this line of code sess tf Session config tf ConfigProto log device placement True gpu options gpu options print sess run c sess close But eventually my python session crashes with out of memory error The log allso indicate that When I force the session to only use one GPU using environment variable CUDA VISIBLE DEVICES 0 it becomes more stable but crashed later when I run an actual training code quite basic also System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Pro 64bits TensorFlow installed from source or binary binary TensorFlow version use command below b'unknown' 1 3 0 Python version Python 3 5 3 Intel Corporation Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version cuda 8 0 61 2 cuDNN 8 0 GPU model and memory 1080Ti 11GB Exact command to reproduce Here is the log C Users Riad Desktop Courses jupyter notebook W 11 33 32 835 NotebookApp All authentication is disabled Anyone who can connect to this server will be able to run code I 11 33 32 887 NotebookApp Serving notebooks from local directory C Users Riad Desktop Courses I 11 33 32 887 NotebookApp 0 active kernels I 11 33 32 888 NotebookApp The Jupyter Notebook is running at 8888 I 11 33 32 888 NotebookApp Use Control C to stop this server and shut down all kernels twice to skip confirmation W 11 34 06 855 NotebookApp 404 GET nbextensions widgets notebook js extension js v 20171103113331 192 168 100 9 15 23ms referer 8888 notebooks Untitled ipynb I 11 34 07 181 NotebookApp Kernel started a846f3bb 429b 49d9 b3dc 90e8d47d67fc 2017 11 03 11 34 25 408488 W C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 11 03 11 34 25 408577 W C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 11 03 11 34 26 328062 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 6705 pciBusID 0000 01 00 0 Total memory 11 00GiB Free memory 9 08GiB 2017 11 03 11 34 26 762169 W C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 523 A non primary context 00000171274F5980 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2017 11 03 11 34 26 763254 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 955 Found device 1 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 6705 pciBusID 0000 02 00 0 Total memory 11 00GiB Free memory 9 08GiB 2017 11 03 11 34 27 217289 W C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 523 A non primary context 00000171274EB2C0 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2017 11 03 11 34 27 218417 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 955 Found device 2 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 6705 pciBusID 0000 04 00 0 Total memory 11 00GiB Free memory 9 08GiB 2017 11 03 11 34 27 652094 W C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 523 A non primary context 000001712754BC30 exists before initializing the StreamExecutor We have not verified StreamExecutor works with that 2017 11 03 11 34 27 654175 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 955 Found device 3 with properties name GeForce GTX 1080 Ti major 6 minor 1 memoryClockRate GHz 1 6705 pciBusID 0000 05 00 0 Total memory 11 00GiB Free memory 9 08GiB 2017 11 03 11 34 27 654302 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 0 and 1 2017 11 03 11 34 27 654690 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 0 and 2 2017 11 03 11 34 27 654941 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 0 and 3 2017 11 03 11 34 27 655238 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 1 and 0 2017 11 03 11 34 27 655512 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 1 and 2 2017 11 03 11 34 27 655806 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 1 and 3 2017 11 03 11 34 27 656091 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 2 and 0 2017 11 03 11 34 27 656392 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 2 and 1 2017 11 03 11 34 27 656680 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 2 and 3 2017 11 03 11 34 27 656974 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 3 and 0 2017 11 03 11 34 27 657493 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 3 and 1 2017 11 03 11 34 27 657800 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 847 Peer access not supported between device ordinals 3 and 2 2017 11 03 11 34 27 658247 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 976 DMA 0 1 2 3 2017 11 03 11 34 27 658286 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 986 0 Y N N N 2017 11 03 11 34 27 658545 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 986 1 N Y N N 2017 11 03 11 34 27 658580 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 986 2 N N Y N 2017 11 03 11 34 27 658606 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 986 3 N N N Y 2017 11 03 11 34 27 658660 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 01 00 0 2017 11 03 11 34 27 658997 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 1 device 1 name GeForce GTX 1080 Ti pci bus id 0000 02 00 0 2017 11 03 11 34 27 659402 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 2 device 2 name GeForce GTX 1080 Ti pci bus id 0000 04 00 0 2017 11 03 11 34 27 659795 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 3 device 3 name GeForce GTX 1080 Ti pci bus id 0000 05 00 0 2017 11 03 11 34 28 549763 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 8 63G 9267854592 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 28 986715 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 7 77G 8341068800 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 29 440854 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 99G 7506961920 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 29 887158 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 29G 6756265472 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 135809 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 8 63G 9267854592 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 168426 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 7 77G 8341068800 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 201799 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 99G 7506961920 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 247813 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 29G 6756265472 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 287203 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 5 66G 6080638976 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 320556 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 5 10G 5472574976 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 357686 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 4 59G 4925317120 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 394005 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 4 13G 4432785408 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 426176 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 71G 3989506816 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 457480 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 34G 3590556160 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 491576 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 01G 3231500544 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 527402 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 71G 2908350464 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 561202 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 44G 2617515264 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 594297 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 19G 2355763712 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 628747 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 97G 2120187392 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 665536 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 78G 1908168704 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 707833 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 60G 1717351936 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 743971 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 44G 1545616640 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 779594 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 29G 1391055104 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 810792 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 17G 1251949568 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 841555 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 05G 1126754560 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 873425 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 967 10M 1014079232 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 943823 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 870 39M 912671488 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 30 977474 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 783 35M 821404416 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 010872 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 705 02M 739264000 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 041557 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 634 51M 665337600 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 101954 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 571 06M 598803968 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 132940 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 513 96M 538923776 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 152136 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 8 63G 9267854592 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 160670 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 7 77G 8341068800 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 161213 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 99G 7506961920 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 162127 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 6 29G 6756265472 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 163461 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 5 66G 6080638976 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 164258 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 5 10G 5472574976 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 212887 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 4 59G 4925317120 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 214000 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 4 13G 4432785408 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 214529 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 71G 3989506816 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 215007 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 34G 3590556160 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 215633 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 3 01G 3231500544 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 216019 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 71G 2908350464 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 216421 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 44G 2617515264 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 216896 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 2 19G 2355763712 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 217393 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 97G 2120187392 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 218201 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 78G 1908168704 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 219158 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 60G 1717351936 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 220334 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 44G 1545616640 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 223796 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 29G 1391055104 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 224705 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 17G 1251949568 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 228203 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 1 05G 1126754560 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 228790 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 967 10M 1014079232 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 240002 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 870 39M 912671488 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 240616 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 783 35M 821404416 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 241031 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 705 02M 739264000 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 241440 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 634 51M 665337600 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 241912 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 571 06M 598803968 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 243669 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 513 96M 538923776 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 244271 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 462 56M 485031424 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 370999 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 416 31M 436528384 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 371450 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 374 67M 392875520 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 382825 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 337 21M 353587968 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 383636 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 303 49M 318229248 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 384740 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 273 14M 286406400 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 446815 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 245 82M 257765888 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 447603 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 221 24M 231989504 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 448226 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 199 12M 208790784 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 448853 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 179 21M 187911936 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 449435 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 161 29M 169120768 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 450162 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 145 16M 152208896 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 456715 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 130 64M 136988160 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 457435 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 117 58M 123289344 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 457901 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 105 82M 110960640 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 458436 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 95 24M 99864576 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 458854 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 85 71M 89878272 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 459447 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 77 14M 80890624 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 460854 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 69 43M 72801792 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 461332 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 62 49M 65521664 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 461884 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 56 24M 58969600 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 462263 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 50 61M 53072640 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 462685 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 45 55M 47765504 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 463065 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 41 00M 42989056 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 465693 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 36 90M 38690304 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 466117 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 33 21M 34821376 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 466556 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 29 89M 31339264 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 474153 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 26 90M 28205568 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 474574 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 24 21M 25385216 bytes from device CUDA ERROR OUT OF MEMORY 2017 11 03 11 34 31 475153 E C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow stream executor cuda cuda driver cc 924 failed to allocate 21 79M 22846720 bytes from device CUDA ERROR OUT OF MEMORY Device mapping job localhost replica 0 task 0 gpu 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 01 00 0 job localhost replica 0 task 0 gpu 1 device 1 name GeForce GTX 1080 Ti pci bus id 0000 02 00 0 job localhost replica 0 task 0 gpu 2 device 2 name GeForce GTX 1080 Ti pci bus id 0000 04 00 0 job localhost replica 0 task 0 gpu 3 device 3 name GeForce GTX 1080 Ti pci bus id 0000 05 00 0 2017 11 03 11 34 31 586968 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime direct session cc 300 Device mapping job localhost replica 0 task 0 gpu 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 01 00 0 job localhost replica 0 task 0 gpu 1 device 1 name GeForce GTX 1080 Ti pci bus id 0000 02 00 0 job localhost replica 0 task 0 gpu 2 device 2 name GeForce GTX 1080 Ti pci bus id 0000 04 00 0 job localhost replica 0 task 0 gpu 3 device 3 name GeForce GTX 1080 Ti pci bus id 0000 05 00 0 MatMul MatMul job localhost replica 0 task 0 gpu 0 2017 11 03 11 34 31 596219 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime simple placer cc 872 MatMul MatMul job localhost replica 0 task 0 gpu 0 b Const job localhost replica 0 task 0 gpu 0 2017 11 03 11 34 31 674827 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime simple placer cc 872 b Const job localhost replica 0 task 0 gpu 0 a Const job localhost replica 0 task 0 gpu 0 2017 11 03 11 34 31 675394 I C tf jenkins home workspace rel win M windows gpu PY 35 tensorflow core common runtime simple placer cc 872 a Const job localhost replica 0 task 0 gpu 0 I 11 36 07 126 NotebookApp Saving file at Untitled ipynb,,"gunan,gunan",2017-11-03 21:15:47,2017-11-06 19:28:33
IS,How can I run a Tensorflow file on GPUs Error Cannot assign a device for operation 'eval step',Do you have any idea how can I run eval image classifier py 1 on GPUs Should I change any functions or do any modifications Or whether there exist any other specific functions for evaluation on GPUs I can already run train image classifier py 2 on GPUs because of having the associated flag for switching between CPU and GPU tf app flags DEFINE boolean 'clone on cpu' False 'Use CPUs to deploy clones ' I did try to add the same line to eval image classifier py but it had no effect I'm using Python 2 7 13 and Tensorflow 1 3 0 from future import absolute import from future import division from future import print function import math import tensorflow as tf from deployment import model deploy from datasets import dataset factory from nets import nets factory from preprocessing import preprocessing factory slim tf contrib slim tf app flags DEFINE integer 'batch size' 32 'The number of samples in each batch ' tf app flags DEFINE integer 'max num batches' None 'Max number of batches to evaluate by default use all ' tf app flags DEFINE string 'master' '' 'The address of the TensorFlow master to use ' tf app flags DEFINE string 'checkpoint path' ' ' 'The directory where the model was written to or an absolute path to a ' 'checkpoint file ' tf app flags DEFINE string 'eval dir' ' ' 'Directory where the results are saved to ' tf app flags DEFINE integer 'num clones' 1 'Number of model clones to deploy ' tf app flags DEFINE boolean 'clone on cpu' False 'Use CPUs to deploy clones ' tf app flags DEFINE integer 'worker replicas' 1 'Number of worker replicas ' tf app flags DEFINE integer 'num readers' 4 'The number of parallel readers that read data from the dataset ' tf app flags DEFINE integer 'num ps tasks' 0 'The number of parameter servers If the value is 0 then the parameters ' 'are handled locally by the worker ' tf app flags DEFINE integer 'num preprocessing threads' 4 'The number of threads used to create the batches ' tf app flags DEFINE string wouldataset name' ' ' 'The name of the dataset to load ' tf app flags DEFINE string wouldataset split name' 'validation' 'The name of the train test split ' tf app flags DEFINE string wouldataset dir' ' ' 'The directory where the dataset files are stored ' tf app flags DEFINE integer 'labels offset' 0 'An offset for the labels in the dataset This flag is primarily used to ' 'evaluate the VGG and ResNet architectures which do not use a background ' 'class for the ImageNet dataset ' tf app flags DEFINE string 'model name' wouldensenet161' 'The name of the architecture to evaluate ' tf app flags DEFINE string 'preprocessing name' None 'The name of the preprocessing to use If left ' 'as None then the model name flag is used ' tf app flags DEFINE float 'moving average decay' None 'The decay to use for the moving average ' 'If left as None then moving averages are not used ' tf app flags DEFINE integer 'eval image size' None 'Eval image size' FLAGS tf app flags FLAGS def main if not FLAGS dataset dir raise ValueError 'You must supply the dataset directory with dataset dir' Config model deploy tf logging set verbosity tf logging INFO with tf Graph as default deploy config model deploy DeploymentConfig num clones FLAGS num clones clone on cpu FLAGS clone on cpu replica id FLAGS task num replicas FLAGS worker replicas num ps tasks FLAGS num ps tasks Create global step with tf device deploy config variables device tf global step slim create global step Select the dataset dataset dataset factory get dataset FLAGS dataset name FLAGS dataset split name FLAGS dataset dir Select the model network fn nets factory get network fn FLAGS model name num classes dataset num classes FLAGS labels offset is training False Create a dataset provider that loads data from the dataset with tf device deploy config inputs device provider slim dataset data provider DatasetDataProvider dataset num readers FLAGS num readers shuffle False common queue capacity 2 FLAGS batch size common queue min FLAGS batch size image label provider get 'image' 'label' label FLAGS labels offset Select the preprocessing function preprocessing name FLAGS preprocessing name or FLAGS model name image preprocessing fn preprocessing factory get preprocessing preprocessing name is training False eval image size FLAGS eval image size or network fn default image size image image preprocessing fn image eval image size eval image size images labels tf train batch image label batch size FLAGS batch size num threads FLAGS num preprocessing threads capacity 5 FLAGS batch size batch queue slim prefetch queue prefetch queue images labels capacity 2 deploy config num clones Define the model def clone fn batch queue Allows data parallelism by creating multiple clones of network fn with tf device deploy config inputs device images labels batch queue dequeue logits end points network fn images logits tf squeeze logits Specify the loss function if 'AuxLogits' in end points tf losses mean squared error predictions end points 'AuxLogits' labels labels weights 0 4 scope 'aux loss' tf losses mean squared error predictions logits labels labels weights 1 0 return end points clones model deploy create clones deploy config clone fn batch queue first clone scope deploy config clone scope 0 Define the model logits network fn images if FLAGS moving average decay variable averages tf train ExponentialMovingAverage FLAGS moving average decay tf global step variables to restore variable averages variables to restore slim get model variables variables to restore tf global step op name tf global step else variables to restore slim get variables to restore logits tf squeeze logits Define the metrics predictions logits names to values names to updates slim metrics aggregate metric map 'Accuracy' tf metrics root mean squared error predictions labels 'Recall 5' slim metrics streaming recall logits labels Print the summaries to screen print ops summary ops for name value in names to values items summary name 'eval s' name op tf summary scalar summary name value collections op tf Print op value summary name summary ops append op print ops append tf Print value value summary name tf add to collection tf GraphKeys SUMMARIES op TODO sguada use num epochs 1 if FLAGS max num batches num batches FLAGS max num batches else This ensures that we make a single pass over all of the data num batches math ceil dataset num samples float FLAGS batch size if tf gfile IsDirectory FLAGS checkpoint path if tf train latest checkpoint FLAGS checkpoint path checkpoint path tf train latest checkpoint FLAGS checkpoint path else checkpoint path FLAGS checkpoint path eval interval secs 6 tf logging info 'Evaluating s' checkpoint path slim evaluation evaluation loop master FLAGS master checkpoint dir checkpoint path logdir FLAGS eval dir num evals num batches eval op list names to updates values print ops variables to restore variables to restore eval interval secs eval interval secs if name ' main ' tf app run I tried to use some code like Tensorflow tutorial as well Creates a graph with tf device ' gpu 2' a tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 2 3 name 'a' b tf constant 1 0 2 0 3 0 4 0 5 0 6 0 shape 3 2 name 'b' c tf matmul a b Creates a session with allow soft placement and log device placement set to True sess tf Session config tf ConfigProto allow soft placement True log device placement True Runs the op print sess run c I modified the code in this way from future import absolute import from future import division from future import print function import math import tensorflow as tf from datasets import dataset factory from nets import nets factory from preprocessing import preprocessing factory slim tf contrib slim tf app flags DEFINE integer 'batch size' 32 'The number of samples in each batch ' tf app flags DEFINE integer 'max num batches' None 'Max number of batches to evaluate by default use all ' tf app flags DEFINE string 'master' '' 'The address of the TensorFlow master to use ' tf app flags DEFINE string 'checkpoint path' ' ' 'The directory where the model was written to or an absolute path to a ' 'checkpoint file ' tf app flags DEFINE string 'eval dir' ' ' 'Directory where the results are saved to ' tf app flags DEFINE integer 'num preprocessing threads' 4 'The number of threads used to create the batches ' tf app flags DEFINE string wouldataset name' ' ' 'The name of the dataset to load ' tf app flags DEFINE string wouldataset split name' 'validation' 'The name of the train test split ' tf app flags DEFINE string wouldataset dir' ' ' 'The directory where the dataset files are stored ' tf app flags DEFINE integer 'labels offset' 0 'An offset for the labels in the dataset This flag is primarily used to ' 'evaluate the VGG and ResNet architectures which do not use a background ' 'class for the ImageNet dataset ' tf app flags DEFINE string 'model name' wouldensenet161' 'The name of the architecture to evaluate ' tf app flags DEFINE string 'preprocessing name' None 'The name of the preprocessing to use If left ' 'as None then the model name flag is used ' tf app flags DEFINE float 'moving average decay' None 'The decay to use for the moving average ' 'If left as None then moving averages are not used ' tf app flags DEFINE integer 'eval image size' None 'Eval image size' FLAGS tf app flags FLAGS Initialize all global and local variables init tf group tf global variables initializer tf local variables initializer def main if not FLAGS dataset dir raise ValueError 'You must supply the dataset directory with dataset dir' tf logging set verbosity tf logging INFO sess tf Session config tf ConfigProto allow soft placement True log device placement True with tf Graph as default tf device ' gpu 0' sess run init tf global step slim get or create global step Select the dataset dataset dataset factory get dataset FLAGS dataset name FLAGS dataset split name FLAGS dataset dir Select the model network fn nets factory get network fn FLAGS model name num classes dataset num classes FLAGS labels offset is training False Create a dataset provider that loads data from the dataset provider slim dataset data provider DatasetDataProvider dataset shuffle False common queue capacity 2 FLAGS batch size common queue min FLAGS batch size image label provider get 'image' 'label' label FLAGS labels offset Select the preprocessing function preprocessing name FLAGS preprocessing name or FLAGS model name image preprocessing fn preprocessing factory get preprocessing preprocessing name is training False eval image size FLAGS eval image size or network fn default image size image image preprocessing fn image eval image size eval image size images labels tf train batch image label batch size FLAGS batch size num threads FLAGS num preprocessing threads capacity 5 FLAGS batch size Define the model logits network fn images if FLAGS moving average decay variable averages tf train ExponentialMovingAverage FLAGS moving average decay tf global step variables to restore variable averages variables to restore slim get model variables variables to restore tf global step op name tf global step else variables to restore slim get variables to restore logits tf squeeze logits Define the metrics predictions logits names to values names to updates slim metrics aggregate metric map 'Accuracy' tf metrics root mean squared error predictions labels 'Recall 5' slim metrics streaming recall logits labels Print the summaries to screen print ops summary ops for name value in names to values items summary name 'eval s' name op tf summary scalar summary name value collections op tf Print op value summary name summary ops append op print ops append tf Print value value summary name tf add to collection tf GraphKeys SUMMARIES op TODO sguada use num epochs 1 if FLAGS max num batches num batches FLAGS max num batches else This ensures that we make a single pass over all of the data num batches math ceil dataset num samples float FLAGS batch size if tf gfile IsDirectory FLAGS checkpoint path if tf train latest checkpoint FLAGS checkpoint path checkpoint path tf train latest checkpoint FLAGS checkpoint path else checkpoint path FLAGS checkpoint path print checkpoint path eval interval secs 6 tf logging info 'Evaluating s' checkpoint path slim evaluation evaluation loop master FLAGS master checkpoint dir checkpoint path logdir FLAGS eval dir num evals num batches eval op list names to updates values print ops variables to restore variables to restore eval interval secs eval interval secs if name ' main ' tf app run When I run this code I face this error Traceback most recent call last File home zgholami test1 GZ Project GZ DenseNet TF slim eval image classifier py line 210 in module tf app run File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File home zgholami test1 GZ Project GZ DenseNet TF slim eval image classifier py line 206 in main eval interval secs 60 File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow contrib slim python slim evaluation py line 296 in evaluation loo p timeout timeout File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow contrib training python training evaluation py line 447 in evalua te repeatedly session creator session creator hooks hooks as session File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 668 in init stop grace period secs stop grace period secs File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 490 in init self sess RecoverableSession self coordinated creator File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 842 in init WrappedSession init self self create session File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 847 in create session return self sess creator create session File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 551 in create session self tf sess self session creator create session File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training monitored session py line 425 in create session init fn self scaffold init fn File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training session manager py line 273 in prepare session config config File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training session manager py line 189 in restore checkpoin t saver restore sess checkpoint filename with path File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training saver py line 1560 in restore self saver def filename tensor name save path File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python client session py line 895 in run run metadata ptr File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python client session py line 1321 in do run options run metadata File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Cannot assign a device for operation 'eval step' Could not satisfy explicit device s pecification ' device GPU 0' because no supported kernel for GPU devices is available Colocation Debug Info Colocation group had the following types and devices Const GPU CPU AssignAdd CPU VariableV2 CPU Identity GPU CPU Assign CPU IsVariableInitialized CPU Node eval step VariableV2 class loc eval step container dtype DT INT64 shape shared name device device GPU 0 Caused by op u'eval step' defined at File home zgholami test1 GZ Project GZ DenseNet TF slim eval image classifier py line 210 in module tf app run File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File home zgholami test1 GZ Project GZ DenseNet TF slim eval image classifier py line 206 in main eval interval secs 60 File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow contrib slim python slim evaluation py line 296 in evaluation loo p timeout timeout File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow contrib training python training evaluation py line 410 in evalua te repeatedly eval step get or create eval step File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python training evaluation py line 57 in get or create eval step collections ops GraphKeys LOCAL VARIABLES ops GraphKeys EVAL STEP File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variable scope py line 1065 in get variable use resource use resource custom getter custom getter File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variable scope py line 962 in get variable use resource use resource custom getter custom getter File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variable scope py line 367 in get variable validate shape validate shape use resource use resource File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variable scope py line 352 in true getter use resource use resource File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variable scope py line 725 in get single variable validate shape validate shape File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variables py line 199 in init expected shape expected shape File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops variables py line 283 in init from args name name File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops state ops py line 131 in variable op v2 shared name shared name File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python ops gen state ops py line 682 in variable v2 name name File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python framework op def library py line 767 in apply op op def op def File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File group pawsey0245 zgholami pyml lib python2 7 site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback Cannot assign a device for operation 'eval step' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available Colocation Debug Info Colocation group had the following types and devices Const GPU CPU AssignAdd CPU VariableV2 CPU Identity GPU CPU Assign CPU IsVariableInitialized CPU Node eval step VariableV2 class loc eval step container dtype DT INT64 shape shared name device device GPU 0 ERROR tensorflow Object was never used type class 'tensorflow python framework ops Tensor' tf Tensor areport uninitialized variables 1 boolean mask Gather 0' shape dtype string If you want to mark it as used call its mark used method 1 2,,,2017-10-30 08:21:45,2017-11-06 19:59:25
IS,padded batch fails on nested shapes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux fully updated TensorFlow installed from source or binary Source TensorFlow version use command below v1 3 0 rc1 4086 g028809769d 1 4 0 rc1 Python version 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source gcc GCC 7 2 0 CUDA cuDNN version cuda 9 0 176 4 cuDNN 7 0 3 1 GPU model and memory N A Exact command to reproduce Describe the problem Trying to use tf data Dataset padded batch fails with type error for any nested shape see stack overflow question Source code logs,,mrry,2017-11-06 19:49:18,2017-11-06 20:15:02
IS,java lang UnsatisfiedLinkError tensorflow native libraries 1509708652238 0 libtensorflow jni so lib64 libc so 6 version GLIBC 2 16' not found required bytensorflow native libraries 1509708652238 0 libtensorflow jni so,The exception is caught when I run Tensorflow API in java There is no GLIBC 2 16 The lowest version is 2 2 5 what should I do Could I package the so file by myself,,"asimshankar,asimshankar",2017-11-03 11:52:55,2017-11-06 20:59:48
PR,Fix batch dataset op test,,,"martinwicke,caisq,martinwicke,martinwicke",2017-11-06 18:30:52,2017-11-06 21:30:08
PR,Add Multi Dimentional LSTM,implementation of Multi Dimentional LSTM described in graves nips 2008 pdf,,"ebrevdo,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,vrv,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,drpngx,drpngx,sb2nov,martinwicke",2017-06-10 18:05:26,2017-11-06 21:59:42
IS,Feature request an op that returns timestamp,This is useful for stats tracking in distributed TensorFlow ie measuring TF communication latency between workers and plotting it in TensorBoard Perhaps it could be called CurrentTimestamp tf current timestamp,,"yaroslavvb,yaroslavvb",2017-11-03 20:38:04,2017-11-06 23:32:06
IS,Feature request tf edit distance return deletions substitutions insertions,Hi When analysing the performance of a speech recognition model it is very useful to know the distribution of deletions substitutions and insertions on the test set Could you make tf edit distance return these three metrics too in addition to the cheapest cost It appears to me that the cpp code L47 already computes them What do you think,,"ebrevdo,ebrevdo",2017-11-04 23:11:19,2017-11-06 23:34:31
IS,The tensorflow does not work suddenly,Hi I am so confused that the tensorflow cannot use today It is perfectly run yesterday and the days before I am sure that the coding are right It can run on other computers and before on my computer I tried reinstall the graphics driver cuda and cudnn but did not work Here is the problem when I run the program 2017 11 01 14 07 43 309592 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 11 01 14 07 43 309643 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 11 01 14 07 43 309660 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 11 01 14 07 43 309674 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 11 01 14 07 43 309693 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 11 01 14 07 43 453723 I tensorflow stream executor cuda cuda gpu executor cc 893 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 11 01 14 07 43 454015 I tensorflow core common runtime gpu gpu device cc 940 Found device 0 with properties name GeForce GTX 1080 major 6 minor 1 memoryClockRate GHz 1 835 pciBusID 0000 01 00 0 Total memory 7 92GiB Free memory 7 62GiB 2017 11 01 14 07 43 454027 I tensorflow core common runtime gpu gpu device cc 961 DMA 0 2017 11 01 14 07 43 454030 I tensorflow core common runtime gpu gpu device cc 971 0 Y 2017 11 01 14 07 43 454051 I tensorflow core common runtime gpu gpu device cc 1030 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 1080 pci bus id 0000 01 00 0 Recognition 2017 11 01 14 07 44 790433 E tensorflow stream executor cuda cuda dnn cc 359 could not create cudnn handle CUDNN STATUS INTERNAL ERROR 2017 11 01 14 07 44 790460 E tensorflow stream executor cuda cuda dnn cc 326 could not destroy cudnn handle CUDNN STATUS BAD PARAM 2017 11 01 14 07 44 790467 F tensorflow core kernels conv ops cc 671 Check failed stream parent GetConvolveAlgorithms algorithms Aborted core dumped Thanks so much,,gunan,2017-11-01 19:13:26,2017-11-06 23:36:24
IS,Tensors erroneously zero when an existing session is running on the same device,UPDATE Restarting my machine fixed the issue To reproduce run two processes with Stopping the first process will fix the problem immediately without needing to restart the second process System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 2 CUDA cuDNN version CUDA 8 cuDNN 5 1 10 GPU model and memory GeForce GTX 980 4GB,,,2017-11-05 04:03:59,2017-11-06 23:40:12
PR,Up,Sorry It was mistake,,,2017-11-06 23:44:53,2017-11-06 23:45:04
IS,The implementation in source code of Backpropagation in TensorFlow Conv2DBackpropFilter and Conv2DBackpropInput,Hi Since two operations Conv2DBackpropFilter and Conv2DBackpropInput count most of the time for lots of applications AlexNet VGG GAN Inception etc I am analyzing the complexity of these two operations back propagation in TensorFlow and I found out that there are three implementation versions custom fast and slot for Conv2DBackpropFilter and Conv2DBackpropInput While I profile all computations are passed to custom version instead of fast or slow which directly calls Eigen function SpatialConvolutionBackwardInput to do that The issue is Conv2DBackpropFilter uses Eigen TensorMap contract to do the tensor contraction and Conv2DBackpropInput uses Eigen MatrixMap transpose to do the matrix transposition in the Compute function Beside these two functions I did not see any convolutional operations which are needed for back propagation theoretically Beside convolutions what else would be run inside these two operations for back propagation Does anyone know how to analyze the computation complexity of back propagation operation in TensorFlow I am looking for any advise suggestion Thank you,,"asimshankar,asimshankar,angersson",2017-10-30 21:17:08,2017-11-06 23:46:59
PR,Updating the bazel version in the install from sources page,,,av8ramit,2017-11-06 18:44:17,2017-11-07 00:13:37
IS,Cannot interpret feed dict key as tensor tensor tensor import input 0 shape 1 299 299 3 dtype float32 is not an element of this graph,I'm running label image py code given at url for inference on an image using InceptionV3 model trained on my own dataset But it is giving the following error Cannot interpret feed dict key as tensor tensor tensor import input 0 shape 1 299 299 3 dtype float32 is not an element of this graph Could anyone please help me with this issue Thanks in advance,,angersson,2017-11-06 09:01:15,2017-11-07 00:34:57
IS,CUDA ERROR OUT OF MEMORY tensorflow 1 4,System information OS High Sierra 10 13 Tensorflow 1 4 Keras 2 0 9 CUDA 9 cuDNN 7 Describe the problem CUDA ERROR OUT OF MEMORY running tensorflow on GPU Simple program,,"angersson,angersson",2017-11-06 21:36:40,2017-11-07 00:43:07
PR,modrelu activation function,modrelu is widely used in complex domain It has been proved to be useful in several models The implementation calculate the magnitude and phases of complex numbers then apply biased relu on the magnitude,,"vrv,vrv,vrv,rmlarsen,rmlarsen,vrv,vrv,martinwicke,drpngx,sb2nov,martinwicke",2017-07-25 03:56:27,2017-11-07 00:56:36
PR,Modify implementation of tf nn batch normalization,Give a slightly different implementation of tf nn batch normalization so that per example gradients needed by differentially private stochastic gradient descent can be calculated for gamma and beta in batch norm layers,,"rmlarsen,jhseu,drpngx,sguada,sb2nov,drpngx,drpngx,drpngx,drpngx,sguada,martinwicke",2017-07-31 22:08:53,2017-11-07 00:57:31
IS,Possible Bug while loop map fn do not parallize,The parallel iterations parameter of while loop and map fn do not reduce the runtime as expected In comparison to the same operations created in a python loop while loop and map fn are at least 4 times slower while loop does not scale at all More details For my project I need to calculate a matrix blockwise I execute the calculation in a loop each loop iteration working on a small part of the matrix not accessing the rest of the matrix To achieve maximum performance the loop has to be executed in parallel In addition I need to control the number of parallel threads because of memory limitations I tried to use parallel iterations but changing this values does not change the runtime at all Using a python for loop to create the same number of operations and syncing them with control dependencies is around 4 times faster In contrast to while loop map fn is getting faster with bigger parallel iterations but remains noticeable slower then the python creation If this issue is known did not find anything at stackoverflow or here and not resolvable the documentation of while loop needs to be improved heavily to avoid this operation if the loop should be parallized Benchmark Code System information Ubuntu Tensorflow installed using pip version 1 3 tested on two different systems,,"reedwm,skye,skye,skye,skye",2017-09-09 17:27:27,2017-11-07 01:12:25
IS,SWIGing tensorflow python tensorflow i failed Exit 1 on Centos 6 2,Hi Trying to build on Centos 6 2 with the following command Is there any way to at least see what the error from swig is Running the reported command manually works fine,,angersson,2017-11-03 13:43:03,2017-11-07 01:14:09
IS,changes in ops to register h file does not effect resulting compilation,System information Have I written custom code OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version 1 4 Python version 2 7 Bazel version 0 7 0 Describe the problem I have been running print selective registration header to produce libtensorflow inference so for android as described in tensorflow tensorflow python tools print selective registration header py i saw that ops to register h was created correctly but the resulting libtensorflow inference so did not work in android and there were always missing kernel ops errors i repeated the process with a few different graphs and i have noticed that the ops to register h is being updated but there were no changes in the resulting libtensorflow inference so file i have tried all the possible bazel clean option and bazel dump thinking it is a bazel caching issue none helped i opened this issue thinking it is an android bug and closed it once i understood that the issue is that the result of the bazel build is worng can anyone check this out,,angersson,2017-11-06 07:11:12,2017-11-07 01:27:31
PR,Add 'axis' option for 'tf boolean mask ',This fix tries to address 9721 where it was not possible to pass an 'axis' option for 'tf boolean mask ' This fix fixes 9721 Signed off by Yong Tang yong tang github outlook com,,"yongtang,josh11b,josh11b,yongtang,yongtang,josh11b,langmore,langmore,josh11b,yongtang,jhseu,yongtang,drpngx,sb2nov,josh11b,yongtang,drpngx",2017-07-17 21:25:07,2017-11-07 01:34:43
PR,ONNX Support,As per We are porting a subset of our package of ONNX TF from here Specifically we want to enable users to do the following We are still working on fixing some of the tests as well as clearing as many TODO is as we can The ONNX RNN API changed very recently and we are still updating our implementations with respect to that We have not imported the ONNX package dependency as we would like to get TF team is opinion regarding whether how we should import ONNX package dependency The benefit is that we can check for the legality of ONNX node graph declaration,,tjingrant,2017-11-07 05:01:31,2017-11-07 05:04:32
IS,eager module has no attributes,My OS is Ubuntu 16 04 Python version is 3 5 Tensorflow version is 14 0 when I tried a simple code for TF Eager module import tensorflow as tf import tensorflow contrib eager as tfe tfe enable eager execution x 2 m tf matmul x x I got a error AttributeError module 'tensorflow contrib eager' has no attribute 'enable eager execution' So what is wrong,,,2017-11-07 08:11:48,2017-11-07 09:19:14
IS,TF 1 4 0 on MacOSX crash object was probably modified after being freed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 MacOSX 10 13 TensorFlow installed from source or binary binary via pip3 6 install tensorflow TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 3 via Homebrew Describe the problem TensorFlow crashes in some cases This occurred only now with version TF 1 4 0 It is a test of my test suite this one L459 I can try to come up with a reduced test case but maybe the current information is already enough to identify the problem On the terminal I see this This might be related to our own C operation which has worked fine so far we used it since TF 0 8 although of course this might be triggered only now by some race condition Is there anything new I need to take care of I think this NSync stuff is new,,allenlavoie,2017-11-06 10:33:10,2017-11-07 13:05:02
IS,WARNING tensorflow Input graph does not contain a QueueRunner That means predict yields forever This is probably a mistake,I have built a Custom Estimator and I created an input function using the Datasets API when I call Thank you,,"shreyneil,mrry,xiejw,xiejw",2017-07-19 18:48:40,2017-11-07 15:48:14
PR,OpenCL Uses Eigen implementation of asinh acosh and atanh,Eigen Bumps to the version that supports asinh acosh and atanh std numext simplifies SYCL kernel registration,,"lukeiwanski,benoitsteiner,drpngx,benoitsteiner,benoitsteiner,lukeiwanski,lukeiwanski,rmlarsen,martinwicke,lukeiwanski,drpngx,drpngx,drpngx,lukeiwanski,benoitsteiner,lukeiwanski,sb2nov,sb2nov,lukeiwanski,benoitsteiner,drpngx,martinwicke",2017-08-03 16:56:03,2017-11-07 16:25:29
IS,OS X tensorflow java image not found,i am running with Mac OS,,"asimshankar,asimshankar,asimshankar,asimshankar",2017-10-20 22:52:50,2017-11-07 16:47:03
IS,help with classifier predict and predicted classes,System information custom code no it is the one in system Apple OS Mac OsX 10 13 TensorFlow version 1 3 0 Python version 3 6 3 GPU model AMD FirePro D700 actually two such GPUs Describe the problem Dear all I am running the simple iris program under python 3 6 3 and tensorflow 1 3 0 The program executes correctly apart from the very last part i e the one related to the confusion matrix In fact the result I get for the confusion matrix is New Samples Class Predictions array b'1' dtype object array b'2' dtype object rather than the expected output New Samples Class Predictions 1 2 Has anything about confusion matrix changed in the latest release If so how should I modify that part of the code Thank you very much for your help Best regards Ivan Source code logs,,ispirmustafa,2017-10-24 16:56:53,2017-11-07 17:29:35
IS,Cannot reload tensorflow with importlib,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I just tried reloading tensorflow using importlib OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary tensorflow gpu from pip TensorFlow version use command below 1 3 0 Python version 3 6 2 CUDA cuDNN version CUDA 8 CuDNN 6 GPU model and memory GeForce GTX 960M 2GB Exact command to reproduce import tensorflow as tf import importlib importlib reload tf Describe the problem I wo not really call it a problem I was just trying to explore some part of tensorflow by checking out some stuffs I just thought of reloading the module but it wo not work I do not know if this is something that should work or it is just a side effect of how tensorflow is implemented Just adding it in in case it is something that should work Source code logs Traceback most recent call last File stdin line 1 in module File D VirtualEnv tensorflow lib importlib init py line 166 in reload bootstrap exec spec module File frozen importlib bootstrap line 608 in exec File frozen importlib bootstrap external line 678 in exec module File frozen importlib bootstrap line 205 in call with frames removed File D VirtualEnv tensorflow lib site packages tensorflow init py line 40 in module del python NameError name 'python' is not defined,,,2017-11-07 15:49:20,2017-11-07 17:30:31
IS,Supervisor does not initialize parameters,Hi It throws an exception when I tried to initialize parameters with tf train Supervisor where the net is contructed with tensorlayer The code is like this It seems that when I run initialize op init sess run init op it does not really work I use tensorflow v1 2 1 and python3 6,,"ppwwyyxx,ppwwyyxx",2017-11-07 12:09:30,2017-11-07 17:37:36
PR,Make LayerNormBasicLSTMCell compatible with datatypes other than float32,LayerNormBasicLSTMCell only supported float32 so far With this patch other datatypes such as float64 are available too The datatype does not have to be specified explicitly but it is deducted from the input data as it already happens for example for BasicLSTMCell,,"ebrevdo,drpngx,ebrevdo,ebrevdo,martinwicke,martinwicke",2017-08-11 09:45:42,2017-11-07 17:55:29
IS,DataLossError see above for traceback corrupted record at 46064268 Node parallel read ReaderReadV2 2 ReaderReadV2 device job localhost replica 0 task 0 cpu 0 parallel read TFRecordReaderV2 2 parallel read filenames,I am trying to train AlexNet from scratch through slim My setup is Python 2 7 12 Tensorflow 1 0 0 in a Linux16 04 system Below is my error report after 3 hours training screen shot 2017 11 07 at 12 57 15 A similar problem also exists when I train vgg 16 using slim May I know how to solve this,,,2017-11-07 18:01:47,2017-11-07 18:22:15
IS,tf metrics mean per class accuracy does not assume num classes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 5 g435cdfc' '1 2 1' Python version 2 7 6 CUDA cuDNN version 5 1 Exact command to reproduce Describe the problem When I run an Experiment with tf metrics mean per class accuracy as a metric I get the following error This is unexpected because all other metrics simply need predictions and labels Also num classes is already known by the graph in the model head,,"angersson,facaiy,alextp",2017-11-06 23:15:14,2017-11-07 18:23:18
IS,C model Saving after training not generating 'modelName meta' file for Prediction,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 17 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source 0 5 1 GCC Compiler version if compiling from source 6 0 3 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce session Run save Const 0 newModelFile save control dependency nullptr Describe the problem I am trying to train a model file in C and save the trained model file when I save the model file with below command in C session Run save Const 0 'newModelFile' save control dependency nullptr Following files are generated 1 newModelFile index 2 newModelFile data 00000 of 00001 But when the training and saving is done in Python with below command Following files are getting generated 1 newModelFile index 2 newModelFile data 00000 of 00001 3 newModelFile meta As we can see 'newModelFile meta' is not getting generated in C Requirement To do prediction in C from trained model file in C I have found the code in C which meets the above requirement at 43639305 BUT the code makes use of 'newModelFile meta' file which is not generated during training in C 1 Can I please know how to generate 'newModelFile meta' file in C to use it for prediction 2 Is there any other way to make predictions in c from the checkpoint files 3 Is there a way to generate pb in c after training instead of generating checkpoint files so that it can directly be loaded for prediction Stackoverflow,,,2017-11-07 09:58:45,2017-11-07 18:42:43
IS,tf layers generates an extra op when not specifying the name,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip install TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 2 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version 8 0 61 GPU model and memory GeForce GTX 1080 Ti 11GB Exact command to reproduce Describe the problem When using tf layers I notice that an extra op is generated when not specifying the name For example here is an example using tf layers dense dense 1 is an extra op Similar problem has been observed for tf layers conv2d also then the graph looks as expected image,,"angersson,fchollet,facaiy,angersson",2017-11-06 01:20:00,2017-11-07 18:58:09
IS,Does tensorflow support RowSparsePull and RowSparsePush when using embedding lookup sparse,,,angersson,2017-11-07 09:22:45,2017-11-07 19:26:48
IS,tensorflow python framework errors impl InvalidArgumentError Shape mismatch in tuple component 0,When I use tensorflow to build my own neural network and run it I meet a very strange error The error is that tensorflow python framework errors impl InvalidArgumentError Shape mismatch in tuple component 0 Expected 400 got 3200 I have no idea about how 3200 comes could anyone can help to fix this problem The input of the neural network is a 400 dimension vector Here is my code tf logging set verbosity tf logging INFO def cnn model fn features labels mode input layer tf reshape features 'inputs' 1 400 print features 'inputs' shape fc1 tf layers dense input layer 1024 activation tf nn relu fc2 tf layers dense fc1 1024 activation tf nn relu fc3 tf layers dense fc2 1024 activation tf nn relu fc4 tf layers dense fc3 1 activation tf nn sigmoid print fc4 shape labels tf reshape labels 1 1 fc4 tf reshape fc4 1 1 print labels shape print fc4 shape if mode in Modes PREDICT Modes EVAL print P and E pre fc4 if mode in Modes TRAIN Modes EVAL print 'T and E' global step tf contrib framework get or create global step loss tf losses mean squared error labels labels predictions fc4 tf summary scalar 'OptimizeLoss' loss if mode Modes PREDICT print 'P' predictions 'vaule' pre export outputs 'prediction' tf estimator export PredictOutput predictions return tf estimator EstimatorSpec mode predictions predictions export outputs export outputs if mode Modes TRAIN print 'T' optimizer tf train AdamOptimizer learning rate 0 01 print 'optimizer' train op optimizer minimize loss print 'train op' return tf estimator EstimatorSpec mode loss loss train op train op if mode Modes EVAL print 'E' eval metric ops 'accuracy' tf metrics accuray labels pre return tf estimator EstimatorSpec mode loss loss eval metric ops eval metric ops def build estimator model dir return tf estimator Estimator model fn cnn model fn model dir model dir config tf contrib learn RunConfig save checkpoints secs 60 def serving input fn inputs 'inputs' tf placeholder tf float32 None 400 return tf estimator export ServingInputReceiver inputs inputs def read and decode filename queue reader tf TFRecordReader serialized example reader read filename queue features tf parse single example serialized example features 'image raw' tf FixedLenFeature tf string 'label' tf FixedLenFeature tf float32 image tf decode raw features 'image raw' tf uint8 image set shape 400 print 'image' print image shape image tf cast image tf float32 label tf cast features 'label' tf float32 return image label def input fn filename batch size 100 filename queue tf train string input producer filename image label read and decode filename queue images labels tf train batch image label batch size batch size print images shape return 'inputs' images labels def get input fn filename batch size 100 return lambda input fn filename batch size def generate experiment fn data dir train batch size 100 eval batch size 100 train steps 5000 eval steps 100 experiment args def experiment fn output dir return Experiment build estimator output dir train input fn get input fn filename os path join data dir 'train tfrecords' batch size train batch size eval input fn get input fn filename os path join data dir 'test tfrecords' batch size eval batch size export strategies saved model export utils make export strategy serving input fn default output alternative key None exports to keep 1 train steps train steps eval steps eval steps experiment args return experiment fn if name ' main ' parser argparse ArgumentParser parser add argument ' data dir' help 'GCS or local path to training data' type str default ' Users hanjun Desktop OS scripts' required True parser add argument ' train batch size' help 'Batch size for training steps' type int default 100 parser add argument ' eval batch size' help 'Batch size for evaluation steps' type int default 100 parser add argument ' train steps' help 'Steps to run the training job for ' type int default 5000 parser add argument ' eval steps' help 'Number of steps to run evalution for at each checkpoint' default 100 type int parser add argument ' output dir' help 'GCS location to write checkpoints and export models' type str default ' Users hanjun Desktop OS Model' required True parser add argument ' job dir' help 'this model ignores this field but it is required by gcloud' default 'junk' parser add argument ' eval delay secs' help 'How long to wait before running first evaluation' default 10 type int parser add argument ' min eval frequency' help 'Minimum number of training steps between evaluations' default 1 type int args parser parse args arguments args dict unused args provided by service arguments pop 'job dir' None arguments pop 'job dir' None output dir arguments pop 'output dir' Run the training job learn runner run generate experiment fn arguments output dir,,angersson,2017-11-07 15:52:43,2017-11-07 19:27:20
IS,Issue while importing tensorflow,I am trying to import tensorflow in Ubuntu 14 04 having cuda 7 5 installed I am using tensorflow 1 4 There is issue related to importerror libcudart so 8 0 cannot open shared object file no such file or directory Kindly help screenshot from 2017 11 07 17 31 46 1,,angersson,2017-11-07 17:05:50,2017-11-07 19:27:41
PR,Branch 174861804,,,"martinwicke,martinwicke",2017-11-07 17:27:17,2017-11-07 19:35:24
IS,No error reported when a wrong argument name is inputted to tf app flags,The default behavior of tf app flags is when the user inputs a wrong undefined argument name the program just keeps running without throwing out any error about it For example The program just keeps running with weight path None and does not report the wrong argument of weights path which has a s appended Should we change this kind of default behavior In this case users may think they input the correct arguments to finetune the model but unfortunately it just trains from scratch,,"nolanliou,vrv,vrv,nolanliou,yilei,vrv,nolanliou,vrv,vrv",2017-06-30 22:32:39,2017-11-07 19:35:54
IS,SpaceToDepthGrad and DepthToSpaceGrad are not aware of data format,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA 8 0 cuDNN 6 GPU model and memory Exact command to reproduce tf depth to space and tf space to depth support data format 'NCHW' on GPU However SpaceToDepthGrad L626 and DepthToSpaceGrad L633 are not aware of data format Maybe they would need to propagate op get attr wouldata format' Source code logs,,asimshankar,2017-11-04 05:10:58,2017-11-07 19:35:54
PR,enable use of transform graph tool with contrib rnn,This is a simple fix for using contrib rnn with the transform graph and possibly other tools In particular it fixes the following error It is also possibly a remedy for issue 11847,,"jhseu,jhseu,drpngx,sb2nov,martinwicke",2017-08-24 18:59:31,2017-11-07 20:14:49
PR,Use keepdims and maintain backward compatible for keep dims,This fix tries to address the issue raised in 6815 where both keepdims and keep dims were used with inconsistency This fix changes related api to keepdims while at the same time maintain backward compatible for keep dims so that use will not be impacted Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,yongtang,drpngx,yongtang,drpngx,drpngx,yongtang,drpngx,drpngx,yongtang,martinwicke,yongtang,drpngx",2017-09-01 20:43:49,2017-11-07 20:35:34
IS,tf library syntax error ' ' operator applied to incompatible types select of string list,Forgive me if I'm missing something obvious here new to Bazel but the tf library Bazel rule seems to assume that tfcompile flags is a string while similar rules allow lists cc binary is copts for example This is a gotcha that probably could be fixed easily Example,,"carlthome,yongtang,yongtang,jart",2017-09-02 16:24:43,2017-11-07 20:42:16
PR,Allow tfcompile flags to be a list,This fix tries to fix the issue raised in 12767 where it was not possible to specify tfcompile flags as a list This fix uses join tfcompile flags or instead so that it is possible to specify the list This fix fixes 12767 Signed off by Yong Tang yong tang github outlook com,,"yongtang,jart,jart,yongtang,yifeif,yifeif,drpngx,sb2nov,drpngx,yongtang,martinwicke",2017-09-02 18:08:21,2017-11-07 20:42:16
PR,Revert Allow tfcompile flags to be a list,Reverts tensorflow tensorflow 12769 which breaks everything,,"martinwicke,martinwicke,yongtang",2017-11-07 20:54:23,2017-11-07 20:54:32
IS,speech commands using python speech recognition as input working example,using your sample code tensorflow examples speech commands label wav py I tweeked to use speech recognition as input that dumps wave data to trained network feel free to add to examples for others to use many thanks calvin ubuntu 16 04 python 2 7 pre from future import absolute import from future import division from future import print function import argparse import sys import tensorflow as tf import speech recognition as sr from tensorflow contrib framework python ops import audio ops as contrib audio FLAGS None def load graph filename with tf gfile FastGFile filename 'rb' as f graph def tf GraphDef graph def ParseFromString f read tf import graph def graph def name '' def load labels filename return line rstrip for line in tf gfile GFile filename def run graph wav data labels input layer name output layer name num top predictions with tf Session as sess softmax tensor sess graph get tensor by name output layer name predictions sess run softmax tensor input layer name wav data top k predictions argsort num top predictions 1 for node id in top k human string labels node id score predictions node id print ' s score 5f ' human string score return 0 def listen r source labels list audio r listen source run graph audio get wav data convert rate 16000 convert width 2 labels list FLAGS input name FLAGS output name FLAGS how many labels def main print istart' labels list load labels FLAGS labels load graph FLAGS graph r sr Recognizer with sr Microphone as source print Say something while 1 listen r source labels list print print 'emd' if name ' main ' parser argparse ArgumentParser parser add argument ' graph' type str default '' help 'Model to use for identification ' parser add argument ' labels' type str default '' help 'Path to file containing labels ' parser add argument ' input name' type str default 'wav data 0' help 'Name of WAVE data input node in model ' parser add argument ' output name' type str default 'labels softmax 0' help 'Name of node outputting a prediction in the model ' parser add argument ' how many labels' type int default 3 help 'Number of results to show ' FLAGS unparsed parser parse known args tf app run main main argv sys argv 0 unparsed pre,,,2017-09-21 01:49:20,2017-11-07 22:06:01
IS,Float16 not supported by Maxpool3D,I was trying to switch the training of my neural net to Mixed precision but while conv deconv3d layers are supporting the float16 type Maxpool3D layers still require a float32 input Can we expect these to support float16 precision soon Thanks,,,2017-11-07 22:07:06,2017-11-07 22:11:50
PR,Removing contrib tensorboard and its references,New pull request to master branch as requested at Cleaning up contrib tensorboard since Tensorboard have been moved and we do not need the contrib tensorboard additionally As mentioned before it creates confusion,,"yifeif,drpngx,sb2nov,martinwicke,jart",2017-09-03 19:30:11,2017-11-07 22:50:15
PR,Add support of drop negatives for tf unsorted segment sum,This fix tries to address the issue raised in 478 by adding the support of drop negatives for tf unsorted segment sum so that it is possible to skip entries when index 1 This fix fixes 478 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,yongtang,yongtang,drpngx,yongtang,drpngx,martinwicke,yongtang,martinwicke,yongtang,sb2nov,yongtang,drpngx,josh11b,yongtang,drpngx,yongtang,drpngx",2017-09-15 04:35:07,2017-11-07 23:10:56
PR,DataFeeder fails on default random state,Fixes len of unsized object error in DataFeeder L367 due to incorrect object type Tested with Python 3 5 and latest Tensorflow 1 1 0 Failed on Could not find any myself but is there any workaround for this,,"drpngx,drpngx,drpngx,martinwicke,yifeif,drpngx,frankchn,vrv,rmlarsen,rmlarsen,jhseu,sb2nov,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke",2017-06-15 05:55:22,2017-11-07 23:16:35
PR,y can be a dict for numpy input fn,The PR is opened for 12610 What changes were proposed in this pull request dict is accept for y as labels How was this patch tested x add unit test pass all tests,,"facaiy,martinwicke,facaiy,martinwicke,facaiy,facaiy,martinwicke,facaiy,martinwicke,facaiy,martinwicke,martinwicke,martinwicke,facaiy,facaiy,drpngx,drpngx,facaiy,martinwicke,facaiy,facaiy,facaiy,drpngx,facaiy,facaiy,martinwicke",2017-08-28 07:55:03,2017-11-07 23:21:15
PR,R1 4,,,av8ramit,2017-11-07 06:07:10,2017-11-07 23:26:34
PR,Merge 1 4 branch back into master,This merge only includes version string updates,,"case540,case540",2017-11-07 00:10:01,2017-11-07 23:26:53
PR,Add execute permission to import pb to tensorboard py,I used chmod x to add the execute permission TESTING Before this change you get a Permission denied error when trying to run import pb to tensorboard py After the change the script runs without needing to use chmod Tested on Mac OSX Sierra 10 12 6,,daj,2017-10-08 01:47:15,2017-11-07 23:35:56
PR,update dnn py to clarify outputs arg to predict fn,It is unclear what the valid values are for predict Since the 2 variants are predict classes and predict proba it is easy to think that the valid values are classes and proba which is untrue I think I have listed all the relevant values for DNNClassifier at least that is what the error msg told me when I used proba as my arg D,,martinwicke,2017-10-08 16:36:14,2017-11-07 23:38:08
PR,Add optional CheckpointSaverListener to MonitoredSession,,,"asimshankar,asimshankar,ispirmustafa,martinwicke",2017-09-25 23:05:49,2017-11-07 23:45:10
PR,Refactoring of canned estimators,Class specific model fn used by each canned estimator are replaced by common model fn and common combined model fn functions and moved to utils py together with common classifier head and regression head functions Canned estimators are then refactored to use these common functions which simplified their code and increased readability,,"ispirmustafa,martinwicke,ispirmustafa",2017-09-24 18:17:46,2017-11-08 00:16:28
IS,Build from source documentation is incorrect,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version 3 6 3 Bazel version if compiling from source 4 5 GCC Compiler version if compiling from source 4 8 CUDA cuDNN version 8 6 GPU model and memory nvidia Exact command to reproduce bazel build config opt config cuda verbose failures tensorflow tools pip package build pip package Describe the problem Documentation is incorrect Tested source configurations lists bazel 0 4 5 for tensorflow 1 4 0 Tensorflow 1 4 0 rejects this version of bazel with an error message Current Bazel version is 0 4 5 expected at least 0 5 4 Source code logs,,"asimshankar,gunan,av8ramit,av8ramit,av8ramit",2017-11-03 20:51:24,2017-11-08 00:28:08
PR,Code Cleanup for Makefile iOS Build,Just cleanup the coding of Makefile iOS Build should be reducing maintenance effort The Makefile part is skipped for the moment I will finish it later not in this PR I am planning to add automatic Selective Registration to Makefile build by only specifying the graph file path to both Android and iOS I think the biggest usage of this Makefile is custom building Once I finish the coding will raise a PR,,"resec,powderluv,resec,resec,resec,powderluv",2017-11-07 03:37:01,2017-11-08 00:43:08
PR,Improve CRF documentation,This PR aims to improve documentation of CRF decoding introduced in,,betterenvi,2017-10-12 14:18:41,2017-11-08 00:56:03
PR,ImgBot optimizes images,Hey there I have just optimized all of your images They are the same dimensions and quality as before only they take up less space now tensorflow examples android res drawable xxhdpi ic launcher png 16 04 tensorflow contrib factorization g3doc gmm png 61 79 tensorflow core profiler g3doc profiler ui jpg 12 02 tensorflow contrib pi examples label image data grace hopper jpg 4 83 tensorflow contrib factorization g3doc kmeans png 61 21 tensorflow contrib factorization g3doc wals png 3 51 tensorflow core profiler g3doc code timeline png 39 87 tensorflow contrib kernel methods g3doc acc vs outdim png 13 7 tensorflow core lib png testdata lena rgba png 5 21 tensorflow contrib kernel methods g3doc acc vs trn time png 14 03 tensorflow contrib kernel methods g3doc kernel mapping png 2 08 tensorflow contrib linear optimizer kernels g3doc newton png 38 51 tensorflow core lib jpeg testdata medium jpg 7 52 tensorflow core profiler g3doc graph timeline png 0 3 tensorflow contrib learn python learn estimators g3doc svm png 57 3 tensorflow core lib jpeg testdata small jpg 26 06 tensorflow core profiler g3doc scope timeline png 45 94 tensorflow examples android res drawable hdpi ic action info png 23 61 tensorflow examples ios benchmark data grace hopper jpg 11 77 tensorflow examples label image data grace hopper jpg 4 83 tensorflow contrib linear optimizer kernels g3doc mod newton png 34 1 tensorflow examples android res drawable mdpi ic launcher png 8 74 tensorflow examples android res drawable hdpi ic launcher png 10 83 tensorflow examples ios camera data grace hopper jpg 11 77 tensorflow examples android res drawable xhdpi ic action info png 23 69 tensorflow examples multibox detector data surfers jpg 8 2 tensorflow examples android res drawable hdpi tile 9 png 30 1 tensorflow examples android res drawable xhdpi ic launcher png 12 39 tensorflow contrib linear optimizer kernels g3doc newton compare experiment png 35 35 tensorflow examples android res drawable mdpi ic action info png 23 61 tensorflow examples tutorials deepdream pilatus800 jpg 35 75 tensorflow contrib verbs design diagram png 44 22 tensorflow examples ios simple data grace hopper jpg 11 77 tensorflow examples android res drawable xxhdpi ic action info png 25 65 tensorflow core lib png testdata lena gray png 24 95,,"drpngx,sb2nov,drpngx,MarkDaoust,martinwicke,martinwicke",2017-09-12 04:38:13,2017-11-08 00:59:11
PR,Protobuf must be compiled with the same version,Added CXX g 4 8 to make command On Raspberry PI protobuf must be compiled with the same gcc version as tensorflow otherwise compile stops with error see tensorflow tensorflow 5684,,"caisq,martinwicke",2017-10-08 21:12:19,2017-11-08 01:00:16
PR,Batch normalization dtype depends on inputs dtype,Make the batch normalization layer dtype be the same type as the inputs before it was always float32,,"caisq,fchollet",2017-10-10 15:48:04,2017-11-08 01:01:44
PR,Branch 174921332,,,"martinwicke,martinwicke,martinwicke",2017-11-08 00:04:10,2017-11-08 05:02:26
PR,Bag of words,,,,2017-11-08 07:58:26,2017-11-08 08:04:06
IS,tensorflow tensorflow 1 4 0 devel gpu uses libcuda so stub at runtime,Issue was caused by Please backport into r1 4,,"flx42,flx42,gunan,case540,flx42,case540,case540,gunan",2017-11-03 18:02:54,2017-11-08 09:29:31
PR,Fix duplicate symbol CreateGPUTracerEv,Closes 12699,,"martinwicke,drpngx,drpngx,sb2nov,martinwicke,martinwicke",2017-08-30 08:27:24,2017-11-08 17:12:32
PR,OpenCL SYCL Add support for triSYCL in TensorFlow,Add the ability to use triSYCL as the SYCL implementation in TensorFlow when OpenCL SYCL support is enabled relates to 22 Note that triSYCL is still work in progress and many features are missing currently only the host device can be used triSYCL triSYCL 51 ComputeCPP is a much more reliable way of using SYCL with TensorFlow,,"a-doumoulakis,gunan,benoitsteiner,benoitsteiner,benoitsteiner,sb2nov,benoitsteiner,benoitsteiner,benoitsteiner,gunan,martinwicke",2017-09-07 14:53:10,2017-11-08 17:17:07
PR,Disable flaky multinomial test,,,"martinwicke,martinwicke,martinwicke,gunan",2017-11-07 22:21:47,2017-11-08 17:21:10
PR,Calculate largest max rather than smallest max in quantized add op cc,I think this is a simple error that just did not get spotted,,martinwicke,2017-10-10 08:27:38,2017-11-08 17:22:25
IS,What is the instruction of checking which version of cuda and cudnn the tensorflow is running on,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below 1 4 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory Tesla P100 PCIE 16GB Exact command to reproduce Describe the problem What is the instruction of checking which version of cuda and cudnn the tensorflow is running on like the tensorflow version could be checked by the instruction tf version I want to check my tensorflow 1 4 running on the 8 0 cuda and 6 0 cudnn not running on the 9 0 cuda and 7 0 cudnn,,,2017-11-08 13:31:01,2017-11-08 17:23:41
PR,golang added Session ListDevices method,Implemented Session ListDevices method,,"anight,anight",2017-11-08 15:32:42,2017-11-08 17:23:59
IS,how to use java client to request tensorflow serving for wide deep model or how to use java to load wide deep model and predict,i have write python client to request wide deep model by tensorflow serving successful but i am am doubt how to use java to resolve it because example and document is too lack,,,2017-11-08 07:02:41,2017-11-08 17:24:45
PR,Fix inconsistent tensor ranks in linear predictions,When mixing sparse feature columns and dense tensors of features linear predictions behave abnormaly without this fix and is unusable,,"sb2nov,jart,martinwicke,jart",2017-09-24 20:18:12,2017-11-08 17:26:04
IS,The efficiency of data access,def test tf with tf Session as sess array tf ones 1024 5 dtype tf float32 t0 time clock out 0 for i in range array shape 0 out array i out sess run out t1 time clock print test tf out t1 t0 def test np array np ones 1024 5 dtype np float32 print array shape t0 time clock out 0 for i in range array shape 0 out array i t1 time clock print test np out t1 t0 console output 'test tf ' array 1024 1024 1024 1024 1024 dtype float32 2 395962 1024 5 'test np ' array 1024 1024 1024 1024 1024 dtype float32 0 0008499999999997954 how to speed up the data access,,yaroslavvb,2017-11-08 07:41:42,2017-11-08 17:53:48
IS,Cannot build TF 1 4 with CUDNN 1 4,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Centos 7 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 3 4 5 Bazel version if compiling from source 0 7 0 non git GCC Compiler version if compiling from source 4 9 CUDA cuDNN version 8 0 5 0 5 GPU model and memory Tesla K80 Exact command to reproduce bazel build config opt config cuda config mkl tensorflow tools pip package build pip packag Describe the problem I'm trying to install Tensorflow 1 4 from sources with CUDA 8 0 and CUDNN 5 0 5 It is indicated in the documentation that it should work with CUDNN 3 and higher Unfortunately it does not work and ends up with an error that seems to indicate that CUDNN v6 is needed I may be wrong on the cause of the error Here is the error Is there anything I can do to install TF 1 4 using CUDNN 5 Thanks,,,2017-11-08 12:39:26,2017-11-08 18:26:44
IS,CUBLAS STATUS ALLOC FAILED when attempting to train linear regressor,System information This is my code Windows 10 x64 installed tensorflow using pip tensorflow gpu v1 4 0 Python 3 6 0 CUDA v8 0 Cudunn v6 0 EVGA GTX 980 SC ATX 4GB Describe the problem Whenever I try to train a linear regression network with this dataset it gives me a CUDA error saying CUBLAS STATUS ALLOC FAILED I suspect it is not because I'm using too much memory as when it does occasionally work it always maxes out my gpu memory usage no matter what size the network is I have included my script and my data file that i ran it with and a log of the error occurring error log Here is my source predictlaptimes txt just pretend it is a python file And here is my data carnumbers txt pretend it is a csv file Github wo not let me upload py or csv files for some reason Looking online I found a solution by changing the allow growth option to True I added this line to my code regressor session options gpu options allow growth True And now it runs without any problems,,angersson,2017-11-08 04:00:44,2017-11-08 18:41:57
IS,Is my code right to use batch normalization layers in tensorflow,I have two inputs qi pos qi neg with the same shape They should be processed by the two mlp layers and finally get two results which acts as score Here is my codes Below is the loss definition It seems all right with tf name scope 'predictions' sim diff pos pair sim neg pair sim predictions tf sigmoid sim diff self infers pos pair sim loss and optim with tf name scope 'loss' self loss nn layers cross entropy loss with reg self labels self preds tf summary scalar 'loss' self loss I am not sure whether I have use the BN layers in right way I mean that the BN parameters are derived from the hidden units from the two separate parts which are based on qi pos and qi neg tensors as inputs Anyway anyone could help check it,,angersson,2017-11-08 05:51:03,2017-11-08 18:42:28
IS,pip3 syntax error,I put in the code in python but it does not work i made sure that pip3 and python is updated and installed but it gives me this pip3 install tensorflow File stdin line 1 pip3 install tensorflow SyntaxError invalid syntax pip install tensorflow File stdin line 1 pip install tensorflow SyntaxError invalid syntax pip3 install upgrade tensorflow File stdin line 1 pip3 install upgrade tensorflow SyntaxError invalid syntax pip3 install upgrade tensorflow File stdin line 1 pip3 install upgrade tensorflow I tryed multiple times,,angersson,2017-11-08 18:09:20,2017-11-08 18:45:07
IS,Java API and Node js java lang IllegalArgumentException graphDef and prefix cannot be null,I'm using node java to run the JAVA API within a Node js application Most of the work is done in Java but I have some issues when loading the graph through node using the Java api graph importGraphDef I get a java lang IllegalArgumentException graphDef and prefix cannot be null I'm loading the inception graph as a binary file tensorflow inception graph pb and passing it to the api like,,angersson,2017-11-08 09:03:03,2017-11-08 18:54:07
PR,Revert OpenCL SYCL Add support for triSYCL in TensorFlow,Reverts tensorflow tensorflow 12882,,"gunan,gunan,gunan",2017-11-08 20:25:05,2017-11-08 20:28:23
IS,No half precision support for DepthwiseConv2Native,Hi I'm trying to convert a network from float32 to float16 Conversion is done postmortem for inference only I converted both weights and activation tensors to float16 When trying to run inference I get the following error tensorflow python framework errors impl InvalidArgumentError No OpKernel was registered to support Op 'DepthwiseConv2dNative' with these attrs Registered devices CPU GPU Registered kernels device 'CPU' label 'neon' T in DT FLOAT device 'CPU' T in DT DOUBLE device 'CPU' T in DT FLOAT device 'GPU' T in DT DOUBLE device 'GPU' T in DT FLOAT Assuming that this op is not implemented for float16 what is the easiest way to bypass this issue implement a python op run time is not very crucial implement a CPU version of this op cast to f32 and cast back to f16 System details OS Platform Ubuntu 14 04 TensorFlow installed from binary TensorFlow version 1 3 0 rc2 CUDA cuDNN version cuda 8 0 cudnn 6 0,,"skye,suharshs,yongtang",2017-08-16 12:50:42,2017-11-08 20:41:04
IS,float16 depthwise conv support,It seems that the current implementation of depthwise convolution does not support half precision local lib python2 7 site packages tensorflow python ops gen nn ops pyc in depthwise conv2d native input filter strides padding data format name TypeError Value passed to parameter 'input' has DataType float16 not in list of allowed values float32 float64 Any chances of having float16 support for this important op anytime soon So training on P100s would be faster,,,2017-07-14 15:55:26,2017-11-08 20:41:04
PR,Add half precision support for DepthwiseConv2dNative,This fix tries to address the request raised in 12327 so that float16 is supported for DepthwiseConv2dNative This fix fixes 12327 This fix fixes 11502 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,yongtang,yongtang,yongtang,yongtang,drpngx,drpngx,drpngx,yongtang,sb2nov,sb2nov,yongtang,sb2nov,yongtang,drpngx,drpngx,yongtang,drpngx,yongtang,martinwicke,martinwicke",2017-09-11 18:06:59,2017-11-08 20:41:04
PR,Looks like an rc1 string got into master Here is the fix,,,av8ramit,2017-11-08 20:19:23,2017-11-08 20:41:21
IS,Unable to read saved model from SMB directory,I am using Tensorflow GPU version 1 1 0 my model can run well if I save it to computer is hard drives However if I save checkpoint files to a samba network drive I can not restore it and here are the logs 2017 11 08 17 25 27 795833 I tensorflow core common runtime gpu gpu device cc 977 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 1070 pci bus id 0000 01 00 0 2017 11 08 17 26 13 335734 W tensorflow core framework op kernel cc 1152 Unavailable path to network drive runs 1510129519 checkpoints model 100 index 2017 11 08 17 26 13 339605 W tensorflow core framework op kernel cc 1152 Unknown path to network drive runs 1510129519 checkpoints model 100 index Input output error 2017 11 08 17 26 13 361089 W tensorflow core framework op kernel cc 1152 Unavailable path to network drive runs 1510129519 checkpoints model 100 index Node save RestoreV2 2 RestoreV2 dtypes DT INT32 device job localhost replica 0 task 0 cpu 0 recv save Const 0 save RestoreV2 2 tensor names save RestoreV2 2 shape and slices C C C C C C2017 11 08 17 26 58 362630 W tensorflow core framework op kernel cc 1152 Unavailable path to network drive runs 1510129519 checkpoints model 100 index Many thanks,,angersson,2017-11-08 14:14:16,2017-11-08 20:41:49
IS,Docker installation version compatibility issues,I am trying to setup tensorflow in Windows 10 machine inside Docker The command I ran is docker run it p 8888 8888 gcr io tensorflow tensorflow Error response C Program Files Docker Toolbox docker exe Error response from daemon client is newer than server client API version 1 24 server API version 1 22 Surprisingly I did not get a lot many threads on this issue,,aselle,2017-07-31 18:47:13,2017-11-08 20:48:47
IS,Ca not access predictions,System information OS Platform and Distribution Windows 10 TensorFlow installed from binary TensorFlow version Tensorflow 1 4 0 Python version Python 3 6 CUDA cuDNN version CUDA 8 cuDNN 6 GPU model and memory GTX M950 Describe the problem When trying to print the predictions from DNNClassifier class i only get generator object Estimator predict at 0x000001AFE1E24EB8 I used the exact code written in the Tensorflow tutorials Source code logs train input fn tf estimator inputs numpy input fn x x np array X train y y train num epochs None shuffle False test input fn tf estimator inputs numpy input fn x x np array X test y None shuffle False classifier train input fn train input fn steps 100 preds classifier predict input fn test input fn print preds,,angersson,2017-11-08 20:06:45,2017-11-08 20:48:58
IS,Mixed precision not enabled with TF1 4 on Tesla V100,Hi there I was interested in testing my neural net an Autoencoder that serves as a generator a CNN as a discriminator that uses 3dconv deconv layers with the new Volta architecture and benefit from the Mixed Precision training I compiled the most recent source code of Tensorflow 1 4 with CUDA 9 and CudNN 7 0 and cast all the trainable variables used by my conv deconv layers to tf float16 Also all my input and output tensors have sizes that are multiple of 8 I have two issues so far I do not see any substantial speed improvement the training time is roughly similar to when using tf float32 My understanding is that with the Volta and cuDNN 7 0 Mixed Precision should be automatically detected by TF and hence should use Tensor Core math Am I wrong or is there anything I should do to enable it FYI I also tried the TF1 5 nighlty build and it seems that it is even slower than my custom 1 4 I also noticed that the Maxpool3D layers are not supporting TF float16 yet and need a float32 input Any plan to change that anytime soon Thanks for your support,,"angersson,yaroslavvb,yaroslavvb,angersson",2017-11-07 17:37:57,2017-11-08 20:53:45
IS,Keras application Tensor is not an element of this graph on eval after train,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 13 1 TensorFlow installed from source or binary pip TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 3 CUDA cuDNN version N A CPU only Exact command to reproduce Describe the problem Using the estimator API and using tf keras applications VGG16 and it is output for transfer learning I get an exception raised of TypeError Cannot interpret feed dict key as Tensor Tensor Tensor vgg base Placeholder 0 shape 3 3 3 64 dtype float32 is not an element of this graph when the model is run a second time This is raised when it runs the eval step after train from tf estimator train and evaluate See source code for model and estimator output This also occurs if I re run the train and evaluate a second time I am running in a Jupyter notebook and my assumption about memory is that if I do a Kernel Restart it will run a training run again without the error but cannot be run in two executions without this See for full notebook but main parts for estimator model and output are below Source code logs Estimator Model,,,2017-11-08 09:42:53,2017-11-08 22:12:49
IS,How can I export the model as serving format,I want to get the serving model format for using server To export estimator m there are four steps 1 Define estimator is features 2 Create a feature config 3 Build an export input fn suitable for use in serving 4 Export the model using export savedmodel I try to use export dir base serving save model feature spec 'times' tf placeholder tf float32 name 'times' serving input fn tf estimator export build parsing serving input receiver fn feature spec estimator export savedmodel export dir base serving input fn But I encountered an error like this Traceback most recent call last File E MyProject Py tensorFlow time series predict train lstm multivariate py line 231 in module estimator export savedmodel export dir base serving input fn File H ProgramFiles Anaconda3 envs tensorflow lib site packages tensorflow python estimator estimator py line 504 in export savedmodel serving input receiver serving input receiver fn File H ProgramFiles Anaconda3 envs tensorflow lib site packages tensorflow python estimator export export py line 142 in serving input receiver fn features parsing ops parse example serialized tf example feature spec File H ProgramFiles Anaconda3 envs tensorflow lib site packages tensorflow python ops parsing ops py line 577 in parse example VarLenFeature SparseFeature FixedLenFeature FixedLenSequenceFeature File H ProgramFiles Anaconda3 envs tensorflow lib site packages tensorflow python ops parsing ops py line 291 in features to raw params raise ValueError Invalid feature s s key feature ValueError Invalid feature times Tensor times 0 dtype float32 How should I use it correctly Thanks so much,,,2017-11-08 08:03:15,2017-11-08 22:13:51
PR,Fix sycl BUILD bazel syntax error,Fix build issues from 12882,,"yifeif,gunan,gunan,gunan",2017-11-08 19:48:18,2017-11-08 22:19:12
IS,how to use java client to request tensorflow serving for wide deep model or how to use java to load wide deep model and predict,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-08 04:30:41,2017-11-08 22:20:48
IS,Build is broken at HEAD,From ci bazel io mac and Linux After configuring Bisecting blame fe197f7dc5bd3b986141bcdaa27928206e74741a cc,,"damienmg,gunan",2017-11-08 18:38:07,2017-11-08 22:24:32
IS,Cannot make an input layer that takes scalars with the keras functional api,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source branch 1 4 TensorFlow version use command below 1 4 0 dev Python version 3 5 Bazel version if compiling from source 5 4 0 CUDA cuDNN version 8 0 6 0 GPU model and memory nVidia 1080Ti 11G Exact command to reproduce run the script below Describe the problem The following is an attempt to use the keras functional api to make a model that accepts scalars as input,,fchollet,2017-11-08 21:09:07,2017-11-08 22:28:48
IS,tf python keras can not import np utils,Typically i'm able to replace any from keras X import Y with from tensorflow python keras X import Y This works with most things but it does not translates to keras utils I can run from keras utils import np utils But the following fails from tensorflow python keras utils import np utils The workaround is just to use from tensorflow python keras impl keras utils import np utils Unsure if this is intended or not I guess I would consider this either a bug fix or a feature request,,"skye,fchollet",2017-10-26 18:49:45,2017-11-08 22:29:43
IS,TF 1 3 keras TimeDistributed wrapper issue rnn got an unexpected keyword argument 'input length',When I use TimeDistributed wrapper from keras I'm getting unexpected keyword argument 'input length' System Info Windows 10 TF 1 3 0 Python 3 5 Code Exception Traceback most recent call last File D PlayGround Git Coding2Fun Blog DeepLearning Quora NLP model py line 103 in module nn train input fn train input fn steps 100 File D Programs Anaconda envs tensorflow lib site packages tensorflow python estimator estimator py line 241 in train loss self train model input fn input fn hooks hooks File D Programs Anaconda envs tensorflow lib site packages tensorflow python estimator estimator py line 630 in train model model fn lib ModeKeys TRAIN File D Programs Anaconda envs tensorflow lib site packages tensorflow python estimator estimator py line 615 in call model fn model fn results self model fn features features kwargs File D PlayGround Git Coding2Fun Blog DeepLearning Quora NLP model py line 38 in model fn q1 tf contrib keras layers TimeDistributed layers Dense EMBEDDING DIM activation arelu' q1 File D Programs Anaconda envs tensorflow lib site packages tensorflow contrib keras python keras engine topology py line 396 in call output super Layer self call inputs kwargs File D Programs Anaconda envs tensorflow lib site packages tensorflow python layers base py line 450 in call outputs self call inputs args kwargs File D Programs Anaconda envs tensorflow lib site packages tensorflow contrib keras python keras layers wrappers py line 208 in call unroll False TypeError rnn got an unexpected keyword argument 'input length',,"jart,fchollet",2017-09-01 02:39:41,2017-11-08 22:33:02
PR,golang added Session ListDevices method,Implemented Session ListDevices method,,"anight,anight",2017-11-08 17:24:41,2017-11-08 22:34:29
IS,Problem with parameters use bias True and bias initializer None,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 3 LTS TensorFlow installed from source or binary pip install TensorFlow version use command below tensorflow 1 3 0 Python version Python 3 5 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Something weird is happening when I'm using both the parameter use bias and bias initializer like this And I got output like this may differ at different runtime 3 28321671 3 28321671 3 28321671 3 28321671 As far as I'm concerned the output element should all be integers not floating numbers I know setting the use bias to True does not agree with setting bias initializer to None in the first place since it is contradictory But bad things happen when we ignore the use bias and use the default value at the same time setting the bias initializer to None Source code logs The source code above should be enough to reproduce the output,,"facaiy,fchollet",2017-10-27 09:24:14,2017-11-08 22:34:58
PR,Fix typo Copybara Experiment DO NOT MERGE,Fix typo in tensorflow python client session clusterspec prop test py,,yifeif,2017-11-08 19:34:51,2017-11-08 23:02:58
PR,add a note on numpy compatibility,np mean has a dtype parameter that could be used to specify the output type By default this is dtype float64 On the other hand tf reduce mean has an aggressive type inference from input tensor This should be clear in the Numpy compatibility section,,martinwicke,2017-10-24 08:15:35,2017-11-09 01:14:51
IS,tensorflow gpu looks for the wrong driver version,System information OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version 1 4 Python version 2 7 12 CUDA cuDNN version 8 0 6 0 GPU model and memory GTX 1060 GPU driver version 387 12 Exact command to reproduce import tensorflow as tf Problem It looks for the wrong version of libnvidia fatbinaryloader so xxx xx,,"angersson,angersson",2017-11-08 23:15:32,2017-11-09 01:17:42
PR,Windows TensorFlow,Windows TensorFlow TensorFlow TensorFlow CPU TensorFlow NVIDIA GPU GPU CPU TensorFlow TensorFlow TensorFlow 5 10 NVIDIA GPU GPU TensorFlow TensorFlow GPU CPU NVIDIA GPU TensorFlow GPU TensorFlow GPU TensorFlow NVIDIA CUDA Toolkit 8 0 NVIDIA Cuda NVIDIA PATH CUDA Toolkit 8 0 NVIDIA cuDNN v6 1 NVIDIA cuDNN CUDA DLL cuDNN DLL PATH CUDA Compute Capability 3 0 GPU NVIDIA GPU cuDNN cuDNN64 6 dll TensorFlow cuDNN TensorFlow TensorFlow pip Anaconda pip TensorFlow virtual environment pip pip Python pip Python pip pip TensorFlow Anaconda conda virtural environment Anaconda pip TensorFlow conda conda TensorFlow conda conda pip Python Python 3 5 x 64 bit from python org Python 3 6 x 64 bit from python org Windows TensorFlow Python3 5 x Python 3 6 x Python 3 pip3 TensorFlow TensorFlow pip3 CPU TensorFlow C pip3 install upgrade tensorflow GPU TensorFlow C pip3 install upgrade tensorflow gpu Anaconda Anaconda Anaconda TensorFlow 1 Anaconda Anaconda 2 tensorflow conda C conda create n tensorflow pip python 3 5 3 conda C activate tensorflow tensorflow C Your prompt should change 4 conda TensorFlow CPU TensorFlow tensorflow C pip install ignore installed upgrade tensorflow GPU TensorFlow tensorflow C pip install ignore installed upgrade tensorflow gpu Stack Overflow TensorFlow Stack Overflow Stack Overflow Stack Overflow Stack Overflow tensorflow Stack Overflow 41007279 stream executor dso loader cc Could not open CUDA library nvcuda dll 41007279 stream executor cuda cuda dnn cc Unable to load cuDNN DSO 42006320 ImportError Traceback most recent call last File tensorflow core framework graph pb2 py line 6 in br from google protobuf import descriptor as descriptor br ImportError cannot import name wouldescriptor' 42011070 No module named pywrap tensorflow 42217532 OpKernel 'op BestSplits device type CPU ' for unknown op BestSplits 43134753 The TensorFlow library was not compiled to use SSE instructions,,yifeif,2017-11-08 13:00:04,2017-11-09 02:42:29
PR,Add int64 input tensor support for tf invert permutation,This fix tries to add int64 input tensor support for tf invert permutation In the docs of the TensorFlow it was specified that the input tensor x could be either int32 or int64 However int64 was actually not supported This fix adds the int64 support by adding template to the class InvertPermutationOp so that both int64 and int32 could be processed This fix also adds additional test cases so that changes could be covered Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,martinwicke,martinwicke",2017-10-28 23:40:59,2017-11-09 05:56:19
PR,Fix a broken link in Threading and Queues docs,The link to Datasets in Threading and Queues seems to be broken This fix attempts to fix the broken link Signed off by Yong Tang yong tang github outlook com,,"yongtang,gunan",2017-11-01 18:02:49,2017-11-09 06:46:43
PR,Allow FilterFloat to pass None values,Tensorflow 1 3 tf constant with dtype float32 float64 float16 may have inconsistent behavior 13827 This fix allows FilterFloat to allow None values to pass We add tf float16 into the TF TO IS OK dictionary We add tests for convert to tensor and tensor util,,"vrv,vrv,mrry,vrv,MarkDaoust,mrry,alextp,alextp,MarkDaoust,alextp,alextp",2017-10-19 16:47:26,2017-11-09 06:49:32
PR,Add multitask optimizer wrapper and global norm gradient clipper,12453,,"ilya-edrenkin,sb2nov,sb2nov,ilya-edrenkin,alextp,ilya-edrenkin,alextp,ilya-edrenkin,alextp,ilya-edrenkin,alextp,alextp,alextp,gunan,ilya-edrenkin,gunan,caisq,caisq,ilya-edrenkin,caisq,gunan,ilya-edrenkin",2017-09-24 17:27:52,2017-11-09 06:50:21
PR,CMake Linux support for GPU build,There had been some fixes for Linux Enable to specify or find related libraries cuda cudnn Enable find package CUDA Address the Linux Cmake parser issue with TF EXTRA CUDA CAPABILITIES 3 0 3 5 5 2 Improve the method to find static libraries Enable tf stream executor for Linux CMake build by linking to libgomp Adjust pywarp tensorflow lib configuration Hide build option not recognized at Linux toolchains Add resampler cu cc files Do not use tf core kernels cpu only for Linux it is for Windows only Tested with OBS open build service rpmbuild for bare metal minimal packages are installed x64 Linux Signed off by MyungJoo Ham myungjoo ham samsung com,,"myungjoo,mrry,mrry,mrry,mrry,mrry,mrry,mrry,myungjoo,myungjoo,myungjoo,myungjoo,myungjoo,myungjoo,myungjoo,petewarden,mrry,mrry,mrry,mrry,myungjoo,myungjoo,myungjoo,myungjoo,myungjoo,mrry,mrry,gunan",2017-10-27 06:15:35,2017-11-09 06:51:25
PR,Allow build all ios sh to build just one arch,This change allows build all ios sh to take an a flag with a specific arch so you dont have to waste time building unwanted architectures 32bit etc TEST tensorflow contrib makefile build all ios sh builds fat lib tensorflow contrib makefile build all ios sh a arm64 only arm64,,"powderluv,powderluv,powderluv,powderluv,powderluv,gunan,gunan,powderluv,gunan",2017-10-24 23:19:15,2017-11-09 06:52:20
PR,Add fp16 support to fused batchnorm op,Attention xq This commit adds a mixed precision fused batch norm v2 op The inputs and outputs are fp16 while the scale offset mean and variance are kept in fp32 The tf nn fused batch norm op has been modified to use the v2 fused batchnorm whenever inputs are fp16 this does not affect compatibility because fp16 was not previously supported The high level layers API has also been updated to store the scale offset mean and variance variables as fp32,,"nluehr,reedwm,reedwm,reedwm,nluehr,nluehr,nluehr,reedwm,nluehr,reedwm,nluehr,reedwm,reedwm,reedwm,reedwm,reedwm,nluehr,nluehr,nluehr,nluehr,nluehr,gunan,nluehr,gunan,gunan,gunan,gunan,nluehr,gunan,nluehr,gunan",2017-09-29 21:40:21,2017-11-09 06:53:20
PR,Update golang to 1 9 2 in install golang sh,This fix updates install golang sh to 1 9 2 see release go1 9 minor Signed off by Yong Tang yong tang github outlook com,,"yongtang,asimshankar",2017-10-31 14:17:05,2017-11-09 07:00:24
PR,Add go format check as part of the sanity check,In go it is very common to format the code with gofmt s w file go This fix adds the gofmt check as part of the sanity check There was only one file tensorflow go tensor go in the whole tensorflow go directory that is not properly formatted This fix formatted tensorflow go tensor go with gofmt s w as well It is also possible to check the format status in Signed off by Yong Tang yong tang github outlook com,,"yongtang,asimshankar,yongtang,asimshankar",2017-10-27 18:26:16,2017-11-09 07:01:09
PR,minor eager notebook examples cleanup,Minor eager notebook examples cleanup See,,"asimshankar,asimshankar",2017-11-06 03:01:20,2017-11-09 07:01:51
PR,golang 2x speedup for encodeTensor,before go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 200 6792809 ns op PASS ok github com tensorflow tensorflow tensorflow go 2 116s after go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 500 3269740 ns op PASS ok github com tensorflow tensorflow tensorflow go 2 021s,,"anight,asimshankar,yongtang",2017-11-08 16:31:32,2017-11-09 07:02:54
PR,Remove non fused version of adjust hue as GPU kernel is already in place,Was looking into adding batch support for tf image random hue 8926 and noticed that the non fused version of adjust hue was still in place The non fused is for non GPU support of adjust hue As GPU kernel for AdjustHue has already been added in PR 6818 I think it makes sense to remove the non fused version Besides the env TF ADJUST HUE FUSED seems not in use anyway This fix removed non fused version of adjust hue as GPU kernel is already in place Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke",2017-11-02 14:10:43,2017-11-09 07:08:58
IS,The weights argument in Keras is Embedding does not work,I am using Tensorflow 1 4 0 According to this blog post we can use the weights argument in the call to Embedding to specify some matrix that represents a pre trained word embeddings see the section titled Preparing the Embedding Layer However this code does not work,,,2017-11-09 06:04:00,2017-11-09 08:02:48
IS,cmake build type is hard coded in grpc cmake,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Server 2012 TensorFlow installed from source or binary Source TensorFlow version use command below 92838685241ca22ea2797e937e380bdbe8325784 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source VS 2015 CUDA cuDNN version None GPU model and memory None Exact command to reproduce D src tensorflow b packages cmake bin cmake G Visual Studio 14 2015 Win64 D src tensorflow s tensorflow contrib cmake DCMAKE BUILD TYPE Debug DPYTHON EXECUTABLE D src tensorflow b packages python python exe DPYTHON LIBRARIES D src tensorflow b packages python libs python35 lib DSWIG EXECUTABLE D src tensorflow b packages swigwin 3 0 9 tools swigwin 3 0 9 swig exe Dtensorflow BUILD SHARED LIB ON Dtensorflow BUILD PYTHON TESTS OFF Then build tensorflow vcxproj Describe the problem build failed Source code logs,,snnn,2017-11-09 11:16:36,2017-11-09 11:19:10
IS,tf estimator EstimatorSpec does not have evaluation hooks parameter,I planned to visualize the evaluation result in tensorboard Therefore I need to create the evaluation hook using tf train SummarySaverHook in model fn and pass it into the EstimatorSpec However EstimatorSpec does not accept evaluation hooks for now It only has training hooks Will evaluation hooks be added in future versions,,"skye,martinwicke,ispirmustafa,martinwicke",2017-10-27 20:20:09,2017-11-09 15:37:27
PR,Revert golang 2x speedup for encodeTensor,Reverts tensorflow tensorflow 14368 This makes go test fail,,"martinwicke,martinwicke",2017-11-09 16:30:35,2017-11-09 16:33:07
IS,MonitoredTrainingSession does not initialize after restore,Describe the problem local init op can be passed to the SessionManager through the scaffold argument in MonitoredTrainingSession From the doc is from session manager The local init op is an Operation that is run always after a new session was created This does not work as expected in the below example Exact command to reproduce The first time you run this two variables a1 and a2 will be initialized by the implied default initializer from the MonitoredTrainingSession and a checkpoint file will be written to disk for only a1 expected behavior no errors The second time you run this it should load a1 from the previous checkpoint and initialize a2 through the local init op given through the scaffold But it does not instead RuntimeError Init operations did not make model ready for local init Init op group deps init fn None error Variables not initialized global step a2 A hack that circumvents the problem by not using local init op is suggested here as well as a reiteration of the expected behavior System information TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version 2 7 10,,,2017-11-09 05:31:44,2017-11-09 16:56:50
PR,Add implementation of conv1d transpose,This fix tries to address the issue raised in 8729 by providing the implementation of conv1d transpose This fix fixes 8729 Signed off by Yong Tang yong tang github outlook com,,"yongtang,alextp,sb2nov,sb2nov,yongtang,sb2nov,yongtang,alextp,yongtang,yongtang,alextp,martinwicke,martinwicke",2017-09-17 22:29:43,2017-11-09 16:58:55
IS,tf nn l2 normalize takes dim instead of axis,At master tf nn l2 normalize still takes the axis parameter as dim Everything else has been standardized on axis so it would be nice if this one was axis too Since dim can not be changed for backwards compatibility reasons presumably the right approach is adding an extra axis argument and requiring that at most one of them is set Is that right,,"girving,yongtang,yongtang,girving",2017-11-02 21:59:16,2017-11-09 17:15:38
PR,Change dim to axis for tf nn softmax and tf nn log softmax,This fix tries to address the issue raised in 7391 where dim was not changed to axis for tf nn softmax and tf nn log softmax This is inconsistent with other ops in tensorflow This fix adds axis while at the same time keeps dim so that backward compatibility is maintained This fix fixes 7391 This fix fixes 14191 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,aselle,aselle,yongtang,yongtang,yongtang,drpngx,yongtang,asimshankar,yongtang,drpngx,yongtang,drpngx,yongtang,martinwicke,yongtang,martinwicke,yongtang,asimshankar,martinwicke,martinwicke,yongtang,martinwicke,martinwicke,martinwicke,girving",2017-08-30 23:21:53,2017-11-09 17:15:38
PR,Add int64 Tdim support for ExpandDims,This fix tries to add int64 Tdim support for ExpandDims In array ops cc ExpandDims registers both int32 and int64 support for Tdim However only int32 kernel for ExpandDims has been supported This fix addresses the discrepancy by adding the support of int64 Tdim for ExpandDims Additional tests has also been added to cover the changes Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke",2017-11-03 17:48:26,2017-11-09 17:16:38
PR,Fix typo Copybara Experiment DO NOT MERGE,Fix typo in tensorflow python client timeline py,,yifeif,2017-11-08 23:05:03,2017-11-09 17:25:05
PR,Keep the document consistent,,,larrytin,2017-11-06 04:57:59,2017-11-09 17:55:29
PR,typo fixed did't did not,typo fixed,,,2017-11-06 06:48:35,2017-11-09 17:56:48
PR,Allow tfcompile flags to be a list,This PR is a follow up to 12769 and 14333 to address the issue raised in 12767 so that it is possible to specify the flag with This PR will fix 12767 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke",2017-11-07 23:23:57,2017-11-09 18:05:04
IS,MKL inference numbers are incorrect,In Performance Guide Comparing Compiler Optimizations comparing compiler optimizations the numbers shared for inference on InceptionV3 and ResNet 50 models are exactly the same I'm assuming this is incorrect,,"tfboyd,tfboyd,tfboyd,gunan,tfboyd,yaroslavvb,tfboyd,tfboyd",2017-09-14 21:51:27,2017-11-09 18:10:16
IS,Error Execution failed for task ' buildNativeBazel',This problem occured with the android example in android studio A problem occurred starting process 'command ' usr local bin bazel'',,angersson,2017-11-09 06:16:33,2017-11-09 18:14:03
IS,Ca not get support template,I seem to have lost the support template when I open issues in tensorflow on Chrome Any way to get it back,,,2017-11-09 17:31:23,2017-11-09 18:14:18
IS,Failed to connect to dl google com port 443 Operation timed out,when I run the simple project of ios I just run pod install but I get the error message of the title however if I copy the url to my safari it download speed is fast who can help me By the way my ruby cocoapods all are newest thx,,angersson,2017-11-09 11:33:02,2017-11-09 18:15:43
IS,tf name scope is not propagated to variables created by Keras layers,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 12 6 TensorFlow installed from source or binary BINARY TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem When using Keras layers in combination with tf name scope a name a name is added to the name of the layers I would also expect it to be added to the name of the weights variables that Keras creates internally However that is not the case Having an automatic way of adding a name scope to the weights is highly desirable though Source code logs Output Executing a name returns test input 1 0 as expected tf trainable variables returns tf Variable wouldense kernel 0' shape 5 5 dtype float32 ref tf Variable wouldense bias 0' shape 5 dtype float32 ref,,"angersson,facaiy,facaiy,facaiy,angersson",2017-11-08 12:53:33,2017-11-09 18:17:57
PR,PIC flag for Makefile built Android Static Library,Currently if we build a shared lib with ndk r12b and android api 21 and the shared lib is linking Makefile built tensorflow android static library the android ndk hints that the tensorflow and nsync lib is not complied with fPIC option this PR fix the problem It only impacts the android build,,"resec,sb2nov,martinwicke,martinwicke",2017-09-11 03:03:51,2017-11-09 18:25:32
PR,Added missing parts for uint32 and uint64 support to golang bindings,Added missing parts for uint32 and uint64 support to golang bindings,,"anight,martinwicke,asimshankar",2017-11-07 20:17:05,2017-11-09 18:28:01
IS,can eager mode make use of multi thread automatically,just like session mode config tf ConfigProto device count CPU 4 inter op parallelism threads 1 intra op parallelism threads 4 log device placement True with tf Session config config as sess,,,2017-11-09 19:11:57,2017-11-09 19:21:38
IS,Error importing Tensorflow,I have tensorflow 1 4 0rc1 installed I get errors when I tried to import tensorflow in my project Can someone help me how to solve this error Thanks,,,2017-11-09 18:37:26,2017-11-09 19:21:55
IS,Is there a clean way to upgrade my TF built from sources in production env from current 1 31 to 1 4,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-09 14:54:55,2017-11-09 19:22:25
IS,Unable to compile tensorflow in Win Debug mode,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Server 2012 TensorFlow installed from source or binary Source TensorFlow version use command below 92838685241ca22ea2797e937e380bdbe8325784 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source VS 2015 CUDA cuDNN version None GPU model and memory None Exact command to reproduce D src tensorflow b packages cmake bin cmake G Visual Studio 14 2015 Win64 D src tensorflow s tensorflow contrib cmake DCMAKE BUILD TYPE Debug DPYTHON EXECUTABLE D src tensorflow b packages python python exe DPYTHON LIBRARIES D src tensorflow b packages python libs python35 lib DSWIG EXECUTABLE D src tensorflow b packages swigwin 3 0 9 tools swigwin 3 0 9 swig exe Dtensorflow BUILD SHARED LIB ON Dtensorflow BUILD PYTHON TESTS OFF Then build tensorflow vcxproj Describe the problem build failed Source code logs,,snnn,2017-11-09 09:15:56,2017-11-09 19:35:55
IS,TF Detect app doesnt work with my own weights,Hello guys I followed the instruction of object detection android app and successfully run the app using the pretrained tiny yolo voc Now I have trained another model by myself with my own dataset 1class using Darknet Then I convert the weights file to pb type format using the Darkflow command flow model cfg yolo 1class cfg load bin yolo marker 1class weights savepb verbalise Using the summerize graph tool I checked the yolo marker 1class pb has the same 'input' and 'output' node After i manually copy this pb file into the asset folder and click Run button I had this error which is not happened when I build when the pretrained tiny yolo voc pb Can anyone help me please 1,,,2017-11-09 08:10:55,2017-11-09 19:38:24
IS,cuda 8 0 is not available now on NVIDIA is website,latest cuda version is 9 0 x but what tf depends on is 8 0 x and it seems that nvidia does not provide downloading site for 8 0 now how can i solve this problem,,angersson,2017-11-09 19:55:16,2017-11-09 19:57:53
PR,Add GPU support for Bucketize op,This fix tries to add GPU support for Bucketize op Before this PR only CPU implementation is available This PR add GPU implementation with a CUDA kernel Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen,rmlarsen,rmlarsen,yongtang,yongtang,yongtang,yongtang,rmlarsen,rmlarsen,yongtang,yongtang,yongtang,rmlarsen,rmlarsen",2017-10-23 15:47:16,2017-11-09 20:13:15
IS,Run mnist with summaries py error can not open shared object libcupti so 8 o,error info as below 2017 07 31 11 18 47 859639 I tensorflow stream executor dso loader cc 129 Could not open CUDA library libcupti so 8 0 LD LIBRARY PATH 2017 07 31 11 18 47 859724 F tensorflow stream executor lib statusor h 205 Non OK status status status Failed precondition could not dlopen DSO libcupti so 8 0 dlerror libcupti so 8 0 cannot open shared object file No such file or directory I have add the path to libcupti so 8 0 to LD LIBRARY PATH but no use export LD LIBRARY PATH usr local cuda extras CUPTI lib64 LD LIBRARY PATH if you have any ideas to solve this please leave your message,,yaroslavvb,2017-07-31 03:32:09,2017-11-09 20:27:23
IS,tf r1 3 show Warning Info when saving checkpoint,I met some warn info show above when saving checkpoint all code here log like this WARNING tensorflow Error encountered when serializing model variables Type is unsupported or the types of the items do not match field type in CollectionDef 'Tensor' object has no attribute 'to proto' this log occur in r1 3 but do not occur in r1 2 tf do save a checkpoint But I am not sure the checkpoint has been saved correctly when this log occur,,,2017-08-01 03:52:11,2017-11-09 20:27:27
PR,Fixes for Python3 Raspberry Pi CI Build,Passes a needed environment variable through to the build script,,"petewarden,petewarden,gunan,petewarden,gunan,petewarden,petewarden,gunan",2017-11-08 01:18:35,2017-11-09 20:52:43
IS,CPU Build Fails on OSX Sierra,I'm getting a cpu only Bazel build failure on OSX TensorFlow has already been configure would with default options Message below,,"gunan,girving,girving,girving,girving,girving,girving",2017-09-21 19:53:12,2017-11-09 21:08:29
PR,Data type support for seq2seq attention mechanisms,Got an exception like the following when I was trying to use tf float16 in my seq2seq model with Bahdanau Attention to allocate less memory on GPU ValueError Tensor conversion requested dtype float32 for Tensor with dtype float16 'Tensor decoder 1 BahdanauAttention mul 0 shape 2048 dtype float16 ' Inserted dtype argument to attention mechanisms that is used in Dense layer of both query layer and memory layer Default is tf float32,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,rmlarsen,rmlarsen,drpngx,drpngx,sb2nov,ebrevdo,ebrevdo,martinwicke,martinwicke,drpngx",2017-08-03 15:40:55,2017-11-09 22:19:32
IS,name scope is indistinguishable from string type,variable scope yields a class VariableScope when entered while name scope yields a string Will tensorflow plan to introduce a class like VariableScope say NameScope in the future Thanks,,"facaiy,martinwicke",2017-11-09 09:51:55,2017-11-09 22:27:02
IS,tensorflow master install from sources does not install with pip3,System information OS Platform and Distribution Ubuntu 17 04 TensorFlow installed from source TensorFlow version tensorflow master Python version 3 5 3 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 4 9 4 CUDA cuDNN version 8 0 GPU model and memory NVIDIA 1080 Describe the problem The bazel commands only appear to build Python 2 7 packages not Python 3 5 packages To reproduce Following Installing TensorFlow from Sources Ubuntu I get this bazel configuration from running configure I build and install with Importing tensorflow with Python3 fails,,"angersson,angersson,angersson",2017-11-09 18:39:22,2017-11-09 22:39:19
IS,Adaptive optmizers do not work well with multi head networks when some labels are missing,Use case we have a multi task network with many outputs Each example in the dataset has only subset of the labels non existing loss components are masked out A single optimizer is used because the presence of particular labels in the example stream is statically unknown Problem masked loss components give zero gradient estimates for the corresponding variables That breaks adaptive optimizers Momentum Adam because steps are taken and slots are corrupted with the incoming zero gradient estimates The desired behaviour is do nothing for variables and corresponding slots that were effectively unused in the forward pass like it is done for the embeddings using the IndexedSlices trick Related problem tf global norm tf clip by global norm are also affected by these stray zero gradient estimates Minimal example demonstration,,"ilya-edrenkin,martinwicke,alextp,ilya-edrenkin,ilya-edrenkin,alextp,ilya-edrenkin,ilya-edrenkin,ilya-edrenkin,ilya-edrenkin,ilya-edrenkin,ilya-edrenkin",2017-08-21 16:46:57,2017-11-09 22:42:16
PR,MKL Fixing a regression in slice op,Fixing a build runtime issue in MKL Slice op caused by another PR,,"mahmoud-abuzaina,mahmoud-abuzaina,gunan,gunan,martinwicke,martinwicke,mahmoud-abuzaina,martinwicke",2017-11-07 18:15:14,2017-11-09 22:45:52
PR,Clarify low latency model stride length,first filter stride y 4 has no effect since first filter height input time size If cnn one fstride4 should be used then first filter stride x should be 4 instead However during my experimentation cnn one fstride4 provided significantly worse results than the current TF impl so I think the impl is fine This small fix just clarifies that the model is not striding in the time dimension,,martinwicke,2017-10-14 00:21:12,2017-11-09 22:46:55
PR,Fix typo Copybara Experiment DO NOT MERGE,Fix typo in tensorflow python layers base test py,,yifeif,2017-11-09 17:28:36,2017-11-09 22:50:16
IS,Keras model trainable weights does not return all trainable weights,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 12 6 TensorFlow installed from source or binary BINARY TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem When creating a Keras model where two towers are merged with help of a Lambda layer not all trainable weights are added to trainable weights Source code logs The code below creates a model with four trainable variables 2 weights and 2 biases However model trainable weights returns only one weight and one bias Output tf Variable wouldense kernel 0' shape 64 5 dtype float32 ref tf Variable wouldense bias 0' shape 5 dtype float32 ref,,"angersson,fchollet",2017-11-08 12:23:58,2017-11-10 00:48:59
PR,mmap file,I added a memory mapped file option for the model file Since the model files have to be copied out of the apk due to assets directory readonly status and inability to create the FileChannel directly it is assumed that you have done so to internal storage with the same context that is passed into the overloaded constructor Internal storage eliminates problems of SD card not being present or M runtime permissions requests but is also in danger of being full etc Expansion files are the only other option but this requires a download from the play store which is an extra step I therefore did the most simple thing,,"andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,andrewharp,yifeif,andrewharp,martinwicke,martinwicke",2017-09-08 23:51:15,2017-11-10 00:53:42
IS,Bug when using estimator with tf data Dataset from tensor slices,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 dev20171026 Python version 3 6 3 Describe the problem When I use tf data and from tensor slices with estimator to build dataset from ndarray tf estimator will use much memory peak 6900MB final 4600MB with simple mnist cnn and create very huge event files events out tfevents 1 28GB graph pbtxt 1 20GB model ckpt 1 meta 370MB Then I use cifar10 input pipeline from resnet as input fn everything back to normal Source code logs replace code in notebook cell 6 with code below,,"asimshankar,jsimsa",2017-10-28 03:21:31,2017-11-10 01:18:26
PR,Fix Jenkins build error tensorflow go test on HEAD,This fix fixes Jenkins build error of tensorflow go test on HEAD introduced by 14368 cc The error was introduced by 14368 because Uint32 and Uint64 has not been supported by TensorFlow yet See Ln 74 of tensorflow go tensor test go Compare Ln 334 and 316 of tensorflow go tensor go before this PR Signed off by Yong Tang yong tang github outlook com,,"yongtang,anight,martinwicke,anight,yongtang",2017-11-09 14:04:51,2017-11-10 01:48:59
IS,Some errors in docker tf notebooks,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 TensorFlow installed from source or binary docker images TensorFlow version use command below latest Describe the problem it is just a documentation problem in in section the code again in the comments I do think to update weights you should use weights weights grads learning rate I think using is not a right choice And another one is also in this section you should use bias with x instead of x with bias That is all,,,2017-11-10 02:24:25,2017-11-10 05:18:55
IS,Errors and warnings through op kernel cc and core grappler utils cc,Description of the problem I installed tensorflow from sources There was no errors during configure as well as build But I get the several errors E and warnings W But if I run neural network example from the repository here I get several warnings but the code runs gives output as expected In the logs below I show the two examples First one on the command line trying to run Hello World I get the few errors of the form op some operation device type CPU for unknown op some operation Exact op is are in the log below Second one example from the repository here I get warnings W saying that MatMul 1 fused is not in the graph Files involved are 1 tensorflow core framework op kernel cc 1142 2 tensorflow core grappler utils cc 48 log for neural network code from examples Successfully downloaded train images idx3 ubyte gz 9912422 bytes Extracting tmp data train images idx3 ubyte gz Successfully downloaded train labels idx1 ubyte gz 28881 bytes Extracting tmp data train labels idx1 ubyte gz Successfully downloaded t10k images idx3 ubyte gz 1648877 bytes Extracting tmp data t10k images idx3 ubyte gz Successfully downloaded t10k labels idx1 ubyte gz 4542 bytes Extracting tmp data t10k labels idx1 ubyte gz WARNING tensorflow Using temporary folder as model directory tmp tmpvak s5 3 2017 11 09 22 31 36 069140 I tensorflow stream executor cuda cuda gpu executor cc 900 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 11 09 22 31 36 069505 I tensorflow core common runtime gpu gpu device cc 1061 Found device 0 with properties name GeForce GTX 1050 major 6 minor 1 memoryClockRate GHz 1 493 pciBusID 0000 01 00 0 totalMemory 3 95GiB freeMemory 3 50GiB 2017 11 09 22 31 36 069519 I tensorflow core common runtime gpu gpu device cc 1151 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1050 pci bus id 0000 01 00 0 compute capability 6 1 2017 11 09 22 31 36 368840 W tensorflow core grappler utils cc 48 Node dense 3 MatMul fused is not in the graph 2017 11 09 22 31 36 368900 W tensorflow core grappler utils cc 48 Node dense 2 MatMul fused is not in the graph 2017 11 09 22 31 36 368918 W tensorflow core grappler utils cc 48 Node dense MatMul fused is not in the graph 2017 11 09 22 31 36 368996 W tensorflow core grappler utils cc 48 Node gradients dense 3 MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 369024 W tensorflow core grappler utils cc 48 Node gradients dense 3 MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 36 369045 W tensorflow core grappler utils cc 48 Node gradients dense 2 MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 369074 W tensorflow core grappler utils cc 48 Node gradients dense 2 MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 36 369097 W tensorflow core grappler utils cc 48 Node gradients dense MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 369122 W tensorflow core grappler utils cc 48 Node gradients dense MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 36 526452 W tensorflow core grappler utils cc 48 Node dense 3 MatMul fused is not in the graph 2017 11 09 22 31 36 526488 W tensorflow core grappler utils cc 48 Node dense 2 MatMul fused is not in the graph 2017 11 09 22 31 36 526504 W tensorflow core grappler utils cc 48 Node dense MatMul fused is not in the graph 2017 11 09 22 31 36 526534 W tensorflow core grappler utils cc 48 Node gradients dense 3 MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 526543 W tensorflow core grappler utils cc 48 Node gradients dense 3 MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 36 526562 W tensorflow core grappler utils cc 48 Node gradients dense 2 MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 526570 W tensorflow core grappler utils cc 48 Node gradients dense 2 MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 36 526589 W tensorflow core grappler utils cc 48 Node gradients dense MatMul grad MatMul 1 fused is not in the graph 2017 11 09 22 31 36 526597 W tensorflow core grappler utils cc 48 Node gradients dense MatMul grad MatMul fused is not in the graph 2017 11 09 22 31 38 129805 I tensorflow core common runtime gpu gpu device cc 1151 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1050 pci bus id 0000 01 00 0 compute capability 6 1 2017 11 09 22 31 38 168010 W tensorflow core grappler utils cc 48 Node dense 3 MatMul fused is not in the graph 2017 11 09 22 31 38 168065 W tensorflow core grappler utils cc 48 Node dense 2 MatMul fused is not in the graph 2017 11 09 22 31 38 168081 W tensorflow core grappler utils cc 48 Node dense MatMul fused is not in the graph Testing Accuracy 0 9167 System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version 3 6 1 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version CUDA 8 0 cuDNN 6 1 GPU model and memory GTX 1050 4GB Exact command to reproduce sample code to validate installation,,,2017-11-10 03:36:38,2017-11-10 05:20:21
PR,code comments error in docker notebook,in related with issue 14430 1 changed x with bias to bias with x for clear understanding 2 changed weights updated comments in code for an error,,,2017-11-10 07:00:15,2017-11-10 07:29:18
IS,tensorflow python framework errors impl InternalError Failed to create session,I am running some preparation code with tf it seems it does not to much memory for it But tensorflow lab huang zhongyi gpu 2 workspace vae npvc python build py 452 files found Processing Tensor ReaderReadV2 0 shape dtype string 2017 11 10 12 24 55 938368 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 11 10 12 24 55 938398 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 11 10 12 24 55 938408 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 11 10 12 24 55 938427 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 11 10 12 24 55 938435 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 11 10 12 24 57 272601 E tensorflow core common runtime direct session cc 138 Internal failed initializing StreamExecutor for CUDA device ordinal 0 Internal failed call to cuDevicePrimaryCtxRetain CUDA ERROR OUT OF MEMORY total memory reported 8508145664 Traceback most recent call last File build py line 100 in module main File build py line 24 in main with sv managed session as sess File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 contextlib py line 59 in enter return next self gen File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training supervisor py line 964 in managed session self stop close summary writer close summary writer File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training supervisor py line 792 in stop stop grace period secs self stop grace secs File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training coordinator py line 389 in join six reraise self exc info to raise File home lab huang zhongyi local lib python3 5 site packages six py line 693 in reraise raise value File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training supervisor py line 953 in managed session start standard services start standard services File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training supervisor py line 708 in prepare or wait for session init feed dict self init feed dict init fn self init fn File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training session manager py line 273 in prepare session config config File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python training session manager py line 178 in restore checkpoint sess session Session self target graph self graph config config File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python client session py line 1292 in init super Session self init target graph config config File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python client session py line 562 in init self session tf session TF NewDeprecatedSession opts status File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 contextlib py line 66 in exit next self gen File home lab huang zhongyi anaconda3 envs tensorflow lib python3 5 site packages tensorflow python framework errors impl py line 466 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl InternalError Failed to create session and when I checkout nvidia smi some GPUs still have many memory NVIDIA SMI 375 66 Driver Version 375 66 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 1080 On 0000 04 00 0 Off N A 49 69C P2 57W 180W 8046MiB 8114MiB 45 Default 1 GeForce GTX 1080 On 0000 05 00 0 Off N A 48 69C P2 53W 180W 7393MiB 8114MiB 0 Default 2 GeForce GTX 1080 On 0000 08 00 0 Off N A 53 72C P2 54W 180W 7917MiB 8114MiB 19 Default 3 GeForce GTX 1080 On 0000 09 00 0 Off N A 60 76C P2 54W 180W 7413MiB 8114MiB 0 Default 4 GeForce GTX 1080 On 0000 84 00 0 Off N A 24 41C P8 12W 180W 2684MiB 8114MiB 0 Default 5 GeForce GTX 1080 On 0000 85 00 0 Off N A 24 35C P8 12W 180W 1895MiB 8114MiB 0 Default 6 GeForce GTX 1080 On 0000 88 00 0 Off N A 67 82C P2 163W 180W 6105MiB 8114MiB 88 Default 7 GeForce GTX 1080 On 0000 89 00 0 Off N A 67 82C P2 144W 180W 6097MiB 8114MiB 89 Default and here is the code Thank you all so much I am really just a beginner,,,2017-11-10 04:22:12,2017-11-10 08:09:01
PR,Add curses install note for Windows in tfdbg docs,On Windows using the curses UI with tfdbg is a nicer experience than the suggested readline so I thought it would be worthwhile to include a note in the documentation about Windows curses installation,,"pvaneck,caisq,caisq,caisq",2017-11-08 02:21:35,2017-11-10 13:53:27
IS,Session run hangs in child thread if something was executed in main thread first,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Confirmed on Mac OS X 10 12 6 Ubuntu 16 04 on GCP TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version Anaconda Python 3 6 1 GPU model and memory no gpu Describe the problem Session run hangs in thread if it has executed something in the main thread If we do not execute the first calculate something in the main thread or execute it after we submitted to the pool everything works Only when first calculating something in the main thread and then in the child thread does tensorflow hang Reproducing example,,mrry,2017-11-10 08:16:12,2017-11-10 16:06:06
PR,Branch 175277161,,,yifeif,2017-11-10 15:34:14,2017-11-10 17:18:08
PR,Fix typo Copybara Experiment DO NOT MERGE,Fix typo in tensorflow python framework function py,,yifeif,2017-11-09 22:52:02,2017-11-10 17:18:35
IS,Feature request Allow for custom hooks in Slim is evaluate once to support TFDBG,System information TensorFlow version v1 3 0 rc2 20 g0787eee Describe the problem The evaluation functions provided by contrib slim python slim are wrappers around methods from contrib training python training contrib slim python slim evaluation loop provides argument hooks which attaches custom hooks to the evaluation loop This can be used to hook the TFDBG debugger into evaluation contrib slim python slim evaluation once however does not provide the argument even though the underlying contrib training python training evaluate once does support the argument The code to extend the hooks with custom hooks is already there in contrib slim python slim evaluation loop but that fix somehow was not applied to contrib slim python slim evaluation once The request is to implement the addition of custom hooks to contrib slim python slim evaluation once so that TFDBG can be used with this method This is a really easy fix that adds a lot of functionality,,caisq,2017-10-02 12:48:54,2017-11-10 17:18:37
IS,tfe Network created inside variable scopes,This is a feature request Currently tfe Network cannot be created under variable scopes This is particularly useful to still have when composing very complicated models,,"jart,asimshankar,allenlavoie",2017-11-01 21:54:49,2017-11-10 17:18:37
IS,Can not import graph after transform graph with quantize nodes,System information What is the top level directory of the model you are using models object detection Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 rc0 Bazel version if compiling from source 0 7 0 CUDA cuDNN version 375 82 GPU model and memory GeForce GTX 770 4GB Exact command to reproduce,,,2017-11-10 10:31:50,2017-11-10 17:34:41
IS,tensorflow python framework errors impl NotFoundError,I got this erros I tried to convert csv to tfrecord with kimvlvl cmlabUbuntu object detection python3 generate tfrecord py csv input data train labels csv output path datacord Traceback most recent call last File generate tfrecord py line 107 in module tf app run File usr local lib python3 5 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File generate tfrecord py line 98 in main tf example create tf example group path File generate tfrecord py line 53 in create tf example encoded jpg fid read File usr local lib python3 5 dist packages tensorflow python lib io file io py line 118 in read self preread check File usr local lib python3 5 dist packages tensorflow python lib io file io py line 78 in preread check compat as bytes self name 1024 512 status File usr lib python3 5 contextlib py line 66 in exit next self gen File usr local lib python3 5 dist packages tensorflow python framework errors impl py line 466 in raise exception ostatus pywrap tensorflow TF GetCode status tensorflow python framework errors impl NotFoundError home kimvlvl object detection images 0265 png I cheacked all the names and labels of xxx png please help,,angersson,2017-11-10 01:32:24,2017-11-10 18:53:39
IS,Is it a bug of tf summary image,Look at the code But it prints 0,,"ppwwyyxx,angersson",2017-11-10 14:27:40,2017-11-10 18:57:17
IS,OpKernel errors after building tensorflow from sources,Instead of using pip to install pre built tensorflow library I downloaded the sources and manually built the library to support using my machine is CPU SIMD instructions SSE4 1 SSE4 2 AVX AVX2 FMA I have installed tensorflow from sources using the official documentation PrepareMac But now I'm facing an array of OpKernel errors when I use tensorflow here is a screenshot of my terminal img width 1264 alt screen shot 2017 11 10 at 9 39 24 pm src Although I ran the following commands pip3 install upgrade ' tmp tensorflow pkg tensorflow 1 4 0 cp35 cp35m macosx 10 6 intel whl' pip3 install upgrade '' tensorflow still raises the same errors when being imported in a session Any help Operating System OS X El Captain 10 Versions of installed libraries nltk 3 2 1 numpy 1 13 3 olefile 0 44 pandas 0 20 0 pigar 0 7 1 Pillow 4 0 0 pip 9 0 1 pipreqs 0 4 9 protobuf 3 4 0 pyparsing 2 1 10 python dateutil 2 6 0 python xlib 0 18 pytz 2016 10 PyYAML 3 12 requests 2 18 4 scikit learn 0 18 1 scipy 0 18 1 setuptools 36 7 0 six 1 11 0 sklearn 0 0 tensorboard 1 0 0a5 tensorflow 1 4 0 tensorflow tensorboard 0 4 0rc2 Theano 0 8 2 urllib3 1 22 Werkzeug 0 12 2 wheel 0 30 0 yarg 0 1 9,,mrry,2017-11-10 19:50:43,2017-11-10 20:01:25
PR,Installing TensorFlow for C,Installing TensorFlow for C TensorFlow c api h C API API C TensorFlow Linux Mac OS X C TensorFlow C TensorFlow 1 C TensoFlow CPU S GPU S TensorFlow install linux determine which tensorflow to install Installing TensorFlow on Linux install mac determine which tensorflow to install Installing TensorFlow on Mac OS 2 shell TensorFlow C usr local lib TF TYPE cpu Change to gpu for GPU support OS linux Change to darwin for Mac OS TARGET DIRECTORY usr local curl L TF TYPE OS x86 64 1 4 0 rc0 tar gz sudo tar C TARGET DIRECTORY xz tar TensorFlow C TARGET DIRECTORY lib usr local TARGET DIRECTORY tar TensorFlow C usr local lib TARGET DIRECTORY 3 usr local TARGET DIRECTORY ldconfig pre b sudo ldconfig b pre TARGET DIRECTORY mydir mydir lib pre b export LIBRARY PATH LIBRARY PATH mydir lib b For both Linux and Mac OS X b export LD LIBRARY PATH LD LIBRARY PATH mydir lib b For Linux only b export DYLD LIBRARY PATH DYLD LIBRARY PATH mydir lib b For Mac OS X only pre hello tf c hello tf c pre b gcc hello tf c b pre pre b a out b Hello from TensorFlow C library version i number i pre gcc TensorFlow C gcc I L TARGET LIBRARY usr local gcc pre b gcc I usr local include L usr local lib hello tf c ltensorflow b pre a out export StackOverflow www stackoverflow com questions tagged tensorflow,,martinwicke,2017-11-09 08:43:12,2017-11-10 21:06:01
PR,Revert Branch 175277161,Reverts tensorflow tensorflow 14453 This push appears to have reverted a bunch of PRs,,martinwicke,2017-11-10 20:26:28,2017-11-10 21:23:54
IS,Oversampling functionality in dataset API,Hello I would like to ask if current API of datasets allows for implementation of oversampling algorithm I deal with highly imbalanced class problem I was thinking that it would be nice to oversample specific classes during dataset parsing i e online generation I have seen the implementation for rejection resample function however this removes samples instead of duplicating them and its slows down batch generation when target distribution is much different then initial one The thing I would like to achieve is to take an example look at its class probability decide if duplicate it or not Then call dataset shuffle dataset batch and get iterator The best in my opinion approach would be to oversample low probable classes and subsample most probable ones I would like to do it online since it is more flexible Just wondering if this is possible with current API,,"mrry,angersson,mrry",2017-11-10 14:47:09,2017-11-10 21:32:02
IS,keras model with tf keras layers Conv2D layers compiled with tf losses softmax cross entropy loss does not converge,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow simple MNIST model in keras OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 8 TensorFlow installed from source or binary binary from pip TensorFlow version use command below 1 4 Python version 3 5 3 Describe the problem When using tf losses softmax cross entropy in a tf keras model with tf keras layers Conv2D layer model fit does not converge although no exception raised loss does not change When change loss function to tf keras losses categorical crossentropy or layer to tf layers Conv2D it converges quickly Source code logs model fit log Train on 50000 samples validate on 10000 samples Epoch 1 5 50000 50000 84s loss 2 3622 acc 0 0986 val loss 2 3662 val acc 0 0950 Epoch 2 5 50000 50000 83s loss 2 3633 acc 0 0978 val loss 2 3662 val acc 0 0950 Epoch 3 5 50000 50000 83s loss 2 3633 acc 0 0978 val loss 2 3662 val acc 0 0950 Epoch 4 5 50000 50000 83s loss 2 3633 acc 0 0978 val loss 2 3662 val acc 0 0950 Epoch 5 5 50000 50000 84s loss 2 3633 acc 0 0978 val loss 2 3662 val acc 0 0950 9984 10000 ETA 0s Test loss 2 362950 Test accuracy 0 098200,,"angersson,angersson,ppwwyyxx",2017-11-09 11:05:43,2017-11-10 21:38:46
PR,Add named contacts to Code of Conduct,,,,2017-11-10 21:36:27,2017-11-10 21:55:48
IS,Mac Changes in fast math flags LLVM API cause XLA enabled build to fail,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 13 High Sierra TensorFlow installed from source or binary Source TensorFlow version use command below HEAD Python version 3 6 2 7 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 9 0 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Follow instructions in docs and build optimized for native architecture with XLA enabled assumes fix in Describe the problem LLVM latest release v5 0 0 does not include recent fast math flags LLVM API changes already updated diff 866fd5845e79e513efd00ed931aa56f5L559 into TensorFlow codebase Next LLVM release v5 0 1 scheduled for the end of November in the meanwhile besides building LLVM with CMake there is no solution but to wait Disclaimer I'm new to LLVM and stuff so if I'm missing something I apologize and appreciate any insight,,"Carmezim,tatatodd,jlebar,Carmezim",2017-11-10 13:03:03,2017-11-10 22:01:45
PR,Fix license declaration for Python headers,This appears to be a legacy package so we might want to consider deleting it at some point too cc,,jart,2017-11-10 22:43:10,2017-11-10 22:45:00
IS,Apparent incorrect behavior from resize to range in models preprocessor py,From the comments for resize to range The output size can be described by two cases 1 If the image can be rescaled so its minimum dimension is equal to the provided value without the other dimension exceeding max dimension then do so 2 Otherwise resize so the largest dimension is equal to max dimension This logic would yield the wrong behavior for images with an aspect ratio near 1 For instance if we had a 1200x1200 image and we had settings min dimension 600 and max dimension 1024 it seems that the desired behavior would be to rescale the image to 1024x1024 Instead following the logic above the image would be rescaled to 600x600 Am I missing something,,nealwu,2017-11-10 18:27:40,2017-11-10 23:09:32
PR,Sync Branch 175311543,tensorflow jenkins test this please,,"aselle,martinwicke,aselle,gunan,gunan,martinwicke",2017-11-10 19:22:33,2017-11-10 23:37:52
PR,Branch 175324895,,,yifeif,2017-11-10 23:39:51,2017-11-11 00:48:26
PR,Update docs for r1 4,,,nealwu,2017-11-11 01:29:29,2017-11-11 02:22:46
PR,Fix 14324 and another compile error with mkl,This fix fixes 14324 and another compile error with mkl below ERROR home zhang tensorflow tensorflow core kernels BUILD 780 1 C compilation of rule ' tensorflow core kernels slice op' failed Exit 1 tensorflow core kernels slice op cc In member function 'void tensorflow MklSliceOp Device T HandleCase4D tensorflow OpKernelContext const tensorflow gtl ArraySlice long long int const tensorflow gtl ArraySlice long long int tensorflow Tensor ' tensorflow core kernels slice op cc 393 50 error 'input' was not declared in this scope context eigen device Device result input begin size Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps Update Found a similar PR 14329 has been posted already But this fix improves that fix by removing redundant code Should I close this PR and create a new one to improve that fix,,"qmick,qmick",2017-11-08 17:08:15,2017-11-11 04:12:46
IS,tf train ExponentialMovingAverage variables to restore,When I view the API doc tf train ExponentialMovingAverage variables to restore variables to restore It said If a variable has a moving average use the moving average variable name as the restore name otherwise use the variable name but I test it is wrong Look the code Variable c do not has a moving average but in variables to restore it use key shadow name either Who can tell me what is wrong,,"reedwm,sguada,sguada,sguada",2017-07-28 02:03:50,2017-11-11 15:01:51
IS,My trained checkpoint does not work,python3 tests test snapshot py lsp out lsp alexnet imagenet small checkpoint 370000 data 00000 of 00001 But it shows this error Data loss not an sstable bad magic number perhaps your file is in a different file format and you need to use a different restore operator Traceback most recent call last DataLossError see above for traceback Unable to open table file out lsp alexnet imagenet small checkpoint 370000 data 00000 of 00001 Data loss not an sstable bad magic number perhaps your file is in a different file format and you need to use a different restore operator,,,2017-11-11 12:42:54,2017-11-11 18:08:03
IS,TowerLoss Multiple GPU will hurt final accuracy performance so much when doing image finetune is it a bug,From the paper Show and Tell Lessons learned from the 2015 MSCOCO Image Captioning Challenge Writer say Training was done using a single GPU Nvidia K20 and step time was about 3 seconds Thus training took over 3 weeks parallelizing training yielded somewhat worse results though it increased the speed to convergence For my applications I find tower loss is ok when you do anything without finetune image mode even if you use image model inception resnet nasnet etc is fine But if you do finetune either for image caption or image classification the performance will hurt a lot using mulitple gpu wether increase total batch size or keep total batch size the same as single gpu might not convergent Is it a known bug can we avoid this,,,2017-11-11 15:32:32,2017-11-11 18:08:43
PR,R0 10,,,,2017-11-11 12:39:07,2017-11-11 21:18:16
PR,Merge internal changes,,,"aselle,aselle,aselle,aselle,aselle",2017-11-11 00:28:35,2017-11-12 00:19:28
PR,Sync from internal More Limited Tests,tensorflow jenkins please test this,,"aselle,martinwicke,martinwicke",2017-11-11 20:53:17,2017-11-12 01:21:57
IS,n 6,Had the wrong window highlighted hit enter and opened this issue by mistake Can be removed,,,2017-11-12 09:11:50,2017-11-12 09:12:27
IS,tensorboard not deployed,It appears Tensorboard is not installed under the following condictions Win 10 GPU Cuda 8 Anaconda 1 6 9 NEW installation of TF GPU as per instructions at Thanks for checking,,,2017-11-13 09:17:50,2017-11-13 09:19:41
IS,Feature Request C gradient for Prod PR done,Pull request opened,,"theflofly,drpngx",2017-11-12 09:48:46,2017-11-13 17:58:22
IS,Problem to install tensorflow,Hello I am trying to install the tensorflow to use it in the digits of nvdia and am having this problem Exception Traceback most recent call last File home felipe local lib python2 7 site packages pip basecommand py line 215 in main status self run options args File home felipe local lib python2 7 site packages pip commands install py line 342 in run prefix options prefix path File home felipe local lib python2 7 site packages pip req req set py line 784 in install kwargs File home felipe local lib python2 7 site packages pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File home felipe local lib python2 7 site packages pip req req install py line 1064 in move wheel files isolated self isolated File home felipe local lib python2 7 site packages pip wheel py line 345 in move wheel files clobber source lib dir True File home felipe local lib python2 7 site packages pip wheel py line 316 in clobber ensure dir destdir File home felipe local lib python2 7 site packages pip utils init py line 83 in ensure dir os makedirs path File usr lib python2 7 os py line 157 in makedirs mkdir name mode OSError Errno 13 Permiss o negada ' usr local lib python2 7 dist packages funcsigs 1 0 2 dist info',,,2017-11-11 21:41:24,2017-11-13 18:41:04
PR,Fix a stray hyphen and add an SO link,To help address 14455,,"angersson,martinwicke,angersson,angersson,martinwicke",2017-11-10 21:19:47,2017-11-13 19:19:45
IS,Support grayscale bmp images,The current implementation only supports 3 RGB or 4 ARGB channel BMP images However grayscale images are also often used for machine learning stuff Therefore it would be great to be able to read 1 channel BMP images See L71,,"andreas-eberle,skye,andreas-eberle,yongtang,andreas-eberle,andreas-eberle",2017-10-24 09:55:19,2017-11-13 22:35:28
PR,Add support for grayscale bmp image,This fix tries to address the issue raised in 13942 to support grayscale bmp image Previously only channels of 3 or 4 are supported in bmp decoding This fix adds the support to have 1 channel grayscale image This fix fixes 13942 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,yongtang,yongtang,martinwicke,martinwicke",2017-11-06 17:29:48,2017-11-13 22:35:28
PR,Ios,,,"petewarden,petewarden,petewarden,petewarden",2017-11-13 21:28:41,2017-11-14 01:11:24
IS,Fetaure Request Layer normalization for NCHW NHWC with fast gpu kernel,tf contrib layers layer norm is slow and only supports NHWC layout It is beneficial to have a fast gpu kernel for layer normalization that supports both NCHW and NHWC I think layer normalization is quite useful when the minibatch is extremely small or comprises only one sample in which case batch norm renorm does not work and when local receptive fields is desired in which case instance norm is bad,,,2017-11-13 22:23:30,2017-11-14 01:26:13
PR,Add correct gradle repository,,,aselle,2017-11-14 02:01:44,2017-11-14 04:53:38
IS,Mac Build fails with XLA errors,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac High Sierra 10 13 TensorFlow installed from source or binary Source TensorFlow version use command below HEAD at c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce 1 Clone repo at head 2 configure 3 build with CPU support only and native arch optimization Building TensorFlow at TensorFlow c44f67a7ed5870fe8a1c0d6257ce597ca2ef7564 HEAD yields the errors below related to XLA optimized for Intel R Core TM i7 7700HQ,,"Carmezim,asimshankar,Carmezim,DavidNorman,Carmezim,Carmezim,DavidNorman,asimshankar,Carmezim",2017-10-31 15:51:01,2017-11-14 05:36:06
PR,Fix XLA compilation on OSX,The double versions of these functions are overloaded on OSX which means we need an explicit cast to disambiguate them Fixes 14127 For compilation to actually succeed PR 14137 needs to be merged too,,"DavidNorman,DavidNorman,DavidNorman,powderluv,Carmezim,martinwicke",2017-11-06 11:21:03,2017-11-14 05:36:06
PR,Fix formatting in readme,flx42 thanks for letting me know,,gunan,2017-11-03 05:36:56,2017-11-14 05:50:16
PR,Add op tf contrib ffmpeg decode video,This fix tries to address the request raised in 6265 where it was not possible to decode video like the existing op of decode audio This fix adds the support of tf contrib ffmpeg decode video by invoking ffmpeg the same fashion as tf contrib ffmpeg decode audo so that video could be stored in the tensor frames height width channel At the moment the output format is RGB24 This fix fixes 6265 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,drpngx,drpngx,drpngx,yongtang,yongtang,yongtang,sb2nov,yongtang,drpngx,yongtang,yongtang,yongtang,martinwicke,yongtang,martinwicke,yongtang,martinwicke,martinwicke,yongtang,martinwicke,yongtang,yongtang",2017-09-22 19:03:26,2017-11-14 06:10:27
PR,Fix Python auto configure build support,7ccfbdf caused our Python autoconf to no longer be auto This was likely due to the helper function get env var which has now been removed I also used this change as an opportunity to apply DRY and remove some legacy documentation This change blocks tensorflow tensorboard 719 CC,,"jart,gunan,martinwicke,martinwicke,martinwicke",2017-11-10 21:42:46,2017-11-14 06:13:55
PR,Implement shape constraints for Cross,This fix implements shape constrainsts for Cross as was specified in the TODO Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,rmlarsen",2017-11-01 15:52:29,2017-11-14 06:29:49
IS,bazel build can not install tensor flow,I did bazel build config opt config cuda tensorflow tools pip package build pip package and this is what I got ERROR home simon Downloads tensorflow tensorflow contrib rnn BUILD 259 1 Illegal ambiguous match on configurable attribute copts in tensorflow contrib rnn gen gru ops py wrappers cc cuda using clang cuda using nvcc Multiple matches are not allowed unless one is unambiguously more specialized ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted home simon Downloads tensorflow tensorflow contrib rnn BUILD 259 1 Illegal ambiguous match on configurable attribute copts in tensorflow contrib rnn gen gru ops py wrappers cc cuda using clang cuda using nvcc Multiple matches are not allowed unless one is unambiguously more specialized INFO Elapsed time 0 454s FAILED Build did NOT complete successfully 0 packages loaded currently loading tensorflow python What do I Do,,,2017-11-13 21:41:04,2017-11-14 07:47:49
IS,tensorflow python saver test is failing in Windows Bazel build,I found out that TF SAVER LENIENT NAMES environment variable set at L2474 is not propagated to the C module L597 The test passes when running with test env TF SAVER LENIENT NAMES True This is only happening in the Bazel build but not in the CMake build We need to investigate the reason,,"meteorcloudy,gunan,meteorcloudy,meteorcloudy,gunan,gunan,snnn,meteorcloudy,meteorcloudy",2017-09-06 10:56:31,2017-11-14 10:51:03
IS,Log version of the SoftmaxFunctor implementation is numerically unstable,The following code in the log version of SoftmaxFunctor should use reduce logsumexp instead of exp sum log,,,2017-11-14 14:10:16,2017-11-14 14:20:17
PR,Branch 175638087,,,"jhseu,jhseu,jhseu",2017-11-14 07:17:24,2017-11-14 17:24:46
PR,Changes to the TF mobile docs for TFLite and a new intro for TFLite,PiperOrigin RevId 175638087,,jhseu,2017-11-14 17:29:28,2017-11-14 18:36:21
PR,Partially synchronize from internal,,,"aselle,aselle,aselle",2017-11-14 08:07:50,2017-11-14 18:39:47
IS,feature request time out option for tf Data from generator,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 7 TensorFlow installed from source or binary pip installed tensorflow gpu binary TensorFlow version use command below 1 40 Python version 3 5 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA8 cuDNN6 0 GPU model and memory gtx980m 8g Quadro 4000M 8g Exact command to reproduce from generator Describe the problem Unnecessary background I previously using a customized python function to load one epoch of images from disc perform pre processing and data augmentation and return as generator and feed into corresponding placeholder via feed dict This function worked out fine for 100 000 steps I recently refactored my codes using tf Data and put the exact same function into the tf Data from generator function However the pipeline would stuck indefinitely every 200 epochs 3 000 steps or so just before it should break out from except tf errors OutOfRangeError also it is not throwing any exception which could be cached by except Exception as e However by manually pressing enter the program would continue to run while dumping out a full screen of getNext error messages from previous runs Unfortunately I can not supply any customized pre processing functions and data to help you debug this bug and I am not sure it is reproduce able with a reduced example since the occurrence seems rather arbitrary Feature wish I am hoping for a time out feature for the general tf Data class to break out from bad loops I suppose any customized solution would involve using standalone thread which could interfere with tf threadpool therefore this feature must be supported in the tf scope,,mrry,2017-11-14 06:08:20,2017-11-14 19:33:50
PR,Part1 of contrib lite documentation,,,aselle,2017-11-14 19:49:37,2017-11-14 19:55:41
PR,Replace the docker check with an OS check,PiperOrigin RevId 174057778,,av8ramit,2017-11-09 20:51:25,2017-11-14 20:12:45
IS,Tensorflow installation error,Hi I installed tensorflow for cpu and while trying to run command to check the version of tensor i am prompted error message Please help me to get this resolved Please see below the log Microsoft Windows Version 6 2 9200 c 2012 Microsoft Corporation All rights reserved C WINDOWS system32 python Python 3 5 2 v3 5 2 4def2a2901a5 Jun 25 2016 22 18 55 MSC v 1900 64 bit AM D64 on win32 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python init p y line 66 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 21 in module pywrap tensorflow swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 20 in swig import helper return importlib import module ' pywrap tensorflow' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Program Files Python35 lib site packages tensorflow init py lin e 24 in module from tensorflow python import File C Program Files Python35 lib site packages tensorflow python init p y line 72 in module raise ImportError msg ImportError Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 18 in swig import helper return importlib import module mname File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level File frozen importlib bootstrap line 986 in gcd import File frozen importlib bootstrap line 969 in find and load File frozen importlib bootstrap line 958 in find and load unlocked File frozen importlib bootstrap line 666 in load unlocked File frozen importlib bootstrap line 577 in module from spec File frozen importlib bootstrap external line 906 in create module File frozen importlib bootstrap line 222 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Program Files Python35 lib site packages tensorflow python init p y line 66 in module from tensorflow python import pywrap tensorflow File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 21 in module pywrap tensorflow swig import helper File C Program Files Python35 lib site packages tensorflow python pywrap ten sorflow py line 20 in swig import helper return importlib import module ' pywrap tensorflow' File C Program Files Python35 lib importlib init py line 126 in impor t module return bootstrap gcd import name level package level ImportError No module named ' pywrap tensorflow' Failed to load the native TensorFlow runtime See arted os setup md import error for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,,2017-08-06 14:09:50,2017-11-14 20:16:54
IS,distribute tensorflow programe failed when increase worker number,I run a distribute tensorflow programe with 5 ps and 20 workers It work normal when I increase the worker number to 50 the programe fail the error log as follow I do not know how to debug this problem 2017 08 07 03 51 42 191472 E tensorflow core distributed runtime master cc 251 Master init Unavailable created 1502077902 191300911 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg 2017 08 07 03 51 42 735190 E tensorflow core distributed runtime master cc 251 Master init Unavailable created 1502077902 735079403 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg 2017 08 07 03 51 43 224557 E tensorflow core distributed runtime master cc 251 Master init Unavailable created 1502077903 224418940 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg 2017 08 07 03 51 43 630253 I tensorflow core distributed runtime master cc 203 CreateSession still waiting for response from worker job ps replica 0 task 1 2017 08 07 03 51 43 630305 I tensorflow core distributed runtime master cc 203 CreateSession still waiting for response from worker job ps replica 0 task 4 2017 08 07 03 51 45 901058 E tensorflow core distributed runtime master cc 251 Master init Unavailable created 1502077905 900893611 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg 2017 08 07 03 51 49 926346 E tensorflow core distributed runtime master cc 251 Master init Unavailable created 1502077909 926169663 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg Traceback most recent call last File home xiangqin oxq tensorflow train ps py line 117 in module tf app run File usr local lib python2 7 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File home xiangqin oxq tensorflow train ps py line 106 in main with sv prepare or wait for session server target config sess config max wait secs 600 as sess File usr local lib python2 7 dist packages tensorflow python training supervisor py line 714 in prepare or wait for session max wait secs max wait secs File usr local lib python2 7 dist packages tensorflow python training session manager py line 384 in wait for session sess File usr local lib python2 7 dist packages tensorflow python training session manager py line 467 in try run local init op sess run self local init op File usr local lib python2 7 dist packages tensorflow python client session py line 786 in run run metadata ptr File usr local lib python2 7 dist packages tensorflow python client session py line 994 in run feed dict string options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1044 in do run target list options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1064 in do call raise type e node def op message tensorflow python framework errors impl UnavailableError created 1502077902 191300911 description OS Error errno 104 file external grpc src core lib iomgr tcp posix c file line 229 grpc status 14 os error Connection reset by peer syscall recvmsg,,yaroslavvb,2017-08-07 13:42:02,2017-11-14 20:16:58
IS,Error Building project tf core framework,26 Build started Project tf core framework Configuration Debug x64 26 Generating force rebuild 26 26 Generating E AIMLDL TensorFlow tensorflow tensorflow core util version info cc 26 The system cannot find the path specified 26 C Program Files x86 MSBuild Microsoft Cpp v4 0 V140 Microsoft CppCommon targets 171 5 error MSB6006 cmd exe exited with code 3 When I try to build the tf label image example project tf core framework errors out with code 3 Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,skye,2017-08-10 23:37:48,2017-11-14 20:17:03
IS,Anyone working with tensorflow in visual studio I am facing some issues integrating tensorflow in vs2017 I can run the code of tensorflow in cmd but could not run it on vs I hope someone comes up with a solution Thanks in advance,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,rohan100jain,2017-08-11 17:41:50,2017-11-14 20:17:08
IS,an error occurred which is No algorithm without scratch worked when using tensorflow to train data,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below '1 2 1' Python version 3 6 2 Bazel version if compiling from source CUDA cuDNN version cuda 8 0 cudnn 5 1 GPU model and memory nvidia Tesla K80 11G Describe the problem when I use tensorflow to train my model an error always occur when my my data size is larger than 250 250 250 Source code logs this is my code,,skye,2017-08-13 14:17:04,2017-11-14 20:17:12
PR,TFLite doc fixes,,,aselle,2017-11-14 20:23:14,2017-11-14 20:24:42
IS,Difference between distribute and local machine version when training by tensorflow,I use a common DNN network with less than 4 layers for a regression task When I test my codes in local single machine with CPU everything is fine But when I train it on distribute system which uses 30 machines' CPU and in the asynchronous parameters update way all the layers' output values including the last prediction values come into Nan The learning rate in local and distribute training are both 0 01 I changed it to 0 0001 in distribute way it seems fine that the outputs are in normal range I am confused about why learning rate cause this phenomenon Any friend can try to explain it Thanks The label is a float ranging from 0 to 1 Most of them falls into 0 1 to 0 3,,yaroslavvb,2017-11-12 10:37:54,2017-11-14 21:20:26
IS,The result of tf control dependencies is undetermined,Sometimes 0 and sometimes 2,,"ppwwyyxx,ppwwyyxx",2017-11-12 14:36:29,2017-11-14 21:36:21
PR,Fix speech hotword model links,,,aselle,2017-11-14 22:13:06,2017-11-15 02:19:36
IS,Error CUDNN STATUS INTERNAL ERROR Any help is appreciated,Dears I am struglling with tensorflow installation I have GeForce GTX1080 Ubuntu16 04 cuda 9 cudnn7 nvidia driver 384 98 I try to run the mnist samle coud from cudd samples v7 and I got this error Error CUDNN STATUS INTERNAL ERROR here is nvidia smi NVIDIA SMI 384 98 Driver Version 384 98 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 108 Off 00000000 03 00 0 On N A 30 47C P8 13W 250W 581MiB 11171MiB 1 Default 1 GeForce GTX 108 Off 00000000 04 00 0 Off N A 23 36C P8 9W 250W 2MiB 11172MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 1390 G usr lib xorg Xorg 331MiB 0 2158 G compiz 196MiB 0 2878 G token 04563B517E2C68A632F4C6B61B846229 51MiB nvcc V nvcc NVIDIA R Cuda compiler driver Copyright c 2005 2017 NVIDIA Corporation Built on Fri Sep 1 21 08 03 CDT 2017 Cuda compilation tools release 9 0 V9 0 176 Please help,,,2017-11-12 19:18:34,2017-11-15 04:00:22
IS,FATAL EXCEPTION on running the custom app after including libraries java lang UnsatisfiedLinkError,java lang UnsatisfiedLinkError com android tools fd runtime IncrementalClassLoader DelegateClassLoader DexPathList dex file data data com example iiti earcheck files instant run dex slice support annotations 25 0 1 ef28e13c9736d79b0dc9b87816fdb5d73ab6b4a6 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 9 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 8 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 7 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 6 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 5 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 4 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 3 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 2 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 1 classes dex dex file data data com example iiti earcheck files instant run dex slice slice 0 classes dex dex file data data com example iiti earcheck files instant run dex slice org tensorflow tensorflow android 1 4 0 d5862dbeef875a2fd03edd55b52916408a0fdae3 classes dex dex file data data com example iiti earcheck files instant run dex slice libandroid tensorflow inference java 8b98de511efe4c9135a05cbc7896de53b57dba53 classes dex dex file data data com example iiti earcheck files instant run dex slice internal impl 25 0 1 fe869e8b718f7d011b42911906bd8102f80b5a3e classes dex dex file data data com example iiti earcheck files instant run dex slice internal impl 25 0 1 e684d856bf1ea2afc0785de8b2275aa12611114e classes dex dex file data data com example iiti earcheck files instant run dex slice internal impl 25 0 1 aa673af4dcf22bcd43d00f80c8888302b9bc278f classes dex dex file data data com example iiti earcheck files instant run dex slice internal impl 25 0 1 73c7d1a62ae7807eb7fd020f01cc2e0e5fd6f9f0 classes dex dex file data data com example iiti earcheck files instant run dex slice internal impl 25 0 1 2002db2ec303ce7ff6c3fba7cf2a064df60d63e4 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support vector drawable 25 0 1 6f89a35e510cd2b99a51cac7fbf50945d73d2434 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support v4 25 0 1 7519131df48ff71670e81da58ca765ab77bce972 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support media compat 25 0 1 d42d2937b0925301d8bc24c4d82fa264d601340d classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support fragment 25 0 1 130afa5cd91643b7e407f699e25e8953be2af0b8 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support core utils 25 0 1 39638966b982d2402411d64d18981a4ce8677c1f classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support core ui 25 0 1 a6406a5ff5aa24fae58de96cd3218c571f49607d classes dex dex file data data com example iiti earcheck files instant run dex slice com android support support compat 25 0 1 5b463be571b727968d5b5d68f9c9b17d4dd40809 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support appcompat v7 25 0 1 17a51234c0d6cd6e15ec23d8be2aa38790811b00 classes dex dex file data data com example iiti earcheck files instant run dex slice com android support animated vector drawable 25 0 1 df8c5ec44495c7c6a687ebfe83e9e46b0bcc5d42 classes dex nativeLibraryDirectories data app com example iiti earcheck Help,,,2017-11-12 10:53:05,2017-11-15 04:36:12
PR,Model average replicas optimizer,We have implemented a new replicas optimizer ModelAverageOptimizer to reduce cross node communication cost It is mentioned in the following issue Model Average In a typical synchronous training environment N replica synchronous training gradients will be averaged each step and then applied to the variables after that replicas can fetch the new variables and continue However in a model average training environment model parameters will be averaged every 'ma intervals' steps In the interval between two average operation each worker trained its local model there are no data transfer at all between workers or ps which can significantly accerlate parallel training Reference BMUF Reference BMUF brings in 'Momentum' and can also work with a Nesterov momentum scheme on the based of Model Average method block momentum rate It brings in the historical blockwise gradients The block momentum is usually set according to the number of workers block momentum 1 0 1 0 num of workers The default value is 0 0 When using default value the naive ModelAverage method is applied the original learning rate of local optimizer should be multiply by num of workers While when the value is 0 0 1 0 the BMUF method is applied the learning rate of local optimizer can be unchanged use Nesterov means the Nesterov style momentum update is applied on the block level The default value is true This can accelerate training with non zero block momentum rate block learning rate block learning rate is always 1 0 or slightly higher than 1 0 Thanks,,"jhseu,mrry,jhseu,drpngx,sb2nov,martinwicke,vrv",2017-07-18 13:59:11,2017-11-15 06:12:59
PR,Add LayerNormBasicGRUCell,LayerNormBasicGRUCell add layer normalization to basic GRU unit Layer Normalization implementation is based on Layer Normalization Jimmy Lei Ba Jamie Ryan Kiros Geoffrey E Hinton and is applied before the internal nonlinearities,,,2017-11-15 08:48:55,2017-11-15 09:32:31
IS,modify tensorflow core protobuf config proto,I try to modify config proto I want to change per process gpu memory fraction from 1 to 0 2 I modified it and builded it After I modified it I compiled by using bazel But I got error and I cannot compile,,"qmick,mrry",2017-11-15 09:22:24,2017-11-15 15:16:28
IS,Links in tensorflow tensorflow contrib lite g3doc models md are not working,The links in tensorflow tensorflow contrib lite g3doc models md are not working please fix it When I click the Link get the error AccessDenied I try to modify the link from to it works But for inception model I do not know how to fix it need your help,,,2017-11-15 06:19:27,2017-11-15 18:26:46
IS,Unable to download quantized Mobilenet TensorFlow Lite model,Describe the problem I am trying to build TensorFlow Lite Android app was following the instruction building in android studio using tensorflow lite aar from jcenter Download the quantized Mobilenet TensorFlow Lite model from here unzip and copy mobilenet quant v1 224 tflite to the assets directory tensorflow contrib lite java demo app src main assets however the link is not open to the public,,,2017-11-15 19:57:10,2017-11-15 20:10:31
IS,Build Custom GPU Op Failed with TF 1 3 1,System information Have I written custom code YES OS Platform and Distribution Ubuntu 14 04 LTS TensorFlow installed from source TensorFlow version 1 3 1 Python version 2 7 6 Bazel version 0 5 4 GCC Compiler version 4 8 4 CUDA cuDNN version 7 5 6 0 GPU model and memory Geforce GTX TITAN X 12GB Exact command to reproduce,,,2017-11-14 08:56:48,2017-11-15 20:32:21
PR,added reuse in kwargs checking for reusing shared variable,When I am implementing DeepID2 from Deep Learning Face Representation by Joint Identification Verification by Yi Sun Xiaogang Wang and Xiaoou Tang I realise that using same architecture for two inputs two face image and sharing weight if I did not misunderstand when feedforward there is a layer called locally connected convolution and only keras implemented LocallyConnected2D when I trying to reuse weight but failed because the layer did not allow reuse as a kwargs so when I added it it seems working I am not expert in deep learning so I am not sure if I am doing it correct so I'm always trying any way,,jhseu,2017-11-07 10:04:23,2017-11-15 23:54:41
PR,Typo fixed in RELEASE md,The spelling of backwards is a non American variant For consistency consider replacing it with the American English spelling,,jhseu,2017-11-08 18:45:37,2017-11-16 01:21:24
PR,Fix a build error in windows debug build,Required by std Debug range FwdIt in std lower bound function Fix 14396,,"snnn,mrry,mrry",2017-11-09 11:04:53,2017-11-16 01:27:09
IS,Failed to calculate FLOPs for Tensorflow Object Detection API SSD Mobilenet SSD Inception,System information Have I written custom code No OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from source TensorFlow version 'v1 3 0 rc1 1951 g04c318b' '1 3 0' Python version 2 7 12 Bazel version if compiling from source 0 7 0 CUDA cuDNN version 8 0 6 0 GPU model and memory Tesla K40 12Gb Exact command to reproduce bazel bin tensorflow tools benchmark benchmark model graph ssd inception pb input layer image tensor input layer shape 1 224 224 3 input layer type uint8 output layer detection boxes detection scores detection classes num detections show flops true Problem The ssd inception pb is one of the model that trained from Tensorflow object detection API When I tried the FLOPs calculation it failed with Invalid argument Tried to fetch data for ' FeatureExtractor Assert Assert' which produces no output To run to a node but not fetch any data pass ' FeatureExtractor Assert Assert' as an argument to the 'target node names' argument of the Session Run API Logs 2017 11 14 19 01 29 405289 E tensorflow tools benchmark benchmark model cc 593 FLOPs calculation failed with Invalid argument Tried to fetch data for ' FeatureExtractor Assert Assert' which produces no output To run to a node but not fetch any data pass ' FeatureExtractor Assert Assert' as an argument to the 'target node names' argument of the Session Run API,,,2017-11-14 11:10:50,2017-11-16 01:33:56
IS,Is it possible to optimize the network is likelihood function over a function of parameters Or putting it the other way can we optimize a function of parameter instead of parameters,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-15 10:04:05,2017-11-16 01:40:52
IS,Nan in summary histogram error for training images if faster rcnn resnet101 coco 11 06 2017 model is used,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version cudnn 8 0 GPU model and memory GeForce GTX 1060 6GB Exact command to reproduce python train py logtostderr train dir training path to training directory pipeline config path training faster rcnn resnet101 config path to config file You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request InvalidArgumentError see above for traceback Nan in summary histogram for FirstStageFeatureExtractor resnet v1 101 block3 unit 6 bottleneck v1 conv2 weights 1 Node FirstStageFeatureExtractor resnet v1 101 block3 unit 6 bottleneck v1 conv2 weights 1 HistogramSummary T DT FLOAT device job localhost replica 0 task 0 cpu 0 FirstStageFeatureExtractor resnet v1 101 block3 unit 6 bottleneck v1 conv2 weights 1 tag FirstStageFeatureExtractor resnet v1 101 block3 unit 6 bottleneck v1 conv2 weights read Node FirstStageFeatureExtractor resnet v1 101 block3 unit 16 bottleneck v1 conv3 BatchNorm gamma read 777 Recv client terminated false recv device job localhost replica 0 task 0 gpu 0 send device job localhost replica 0 task 0 cpu 0 send device incarnation 1 tensor name edge 2768 FirstStageFeatureExtractor resnet v1 101 block3 unit 16 bottleneck v1 conv3 BatchNorm gamma read tensor type DT FLOAT device job localhost replica 0 task 0 gpu 0 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-14 12:10:46,2017-11-16 01:48:11
PR,Fix strides format for data format in contrib layers separable convolution2d,Addresses feature request from issue 10432 Continuation of feature implementation initial changes did not address the case where num outputs None in which case strides and the input channels must be reformulated according to data format The previous commit is rmlarsen d52e15a I created a previous PR 12120 for a similar issue that fixed in the above commit but the strides were still mismatched to data format I thought it would be cleaner if I just made a new PR Edit I thought it would be cleaner because my CLA would be recognized but it still has not See the comment below,,"sguada,jhseu,drpngx,sb2nov,drpngx,martinwicke,drpngx,martinwicke",2017-08-14 18:02:41,2017-11-16 02:06:35
PR,Disable slice op test,,,"gunan,jhseu",2017-11-15 21:31:49,2017-11-16 02:26:51
PR,Fix the mac build,This test times out at 300 seconds It takes almost exactly 300 seconds,,"jhseu,jhseu",2017-11-16 01:44:15,2017-11-16 02:29:21
PR,R1 4,,,jhseu,2017-11-14 08:36:27,2017-11-16 02:48:14
IS,Linking error Undefined symbols for architecture x86 64 nsync nsync mu init nsync nsync mu s on iOS,Hello I downloaded the latest release 1 4 0 and builded it for iOS with build all ios sh and can successfully build libtensorflow core a libprotobuf lite a and libprotobuf a but error happened when link these libs to iOS project the detail info as follows can anybody know how to fix it thanks Undefined symbols for architecture x86 64 nsync nsync mu init nsync nsync mu s referenced from tensorflow Env Env in libtensorflow core a env o GLOBAL sub I allocator cc in libtensorflow core a allocator o tensorflow SessionFactory Register std 1 basic string char std 1 char traits char std 1 allocator char const tensorflow SessionFactory in libtensorflow core a session factory o tensorflow SessionFactory GetFactory tensorflow SessionOptions const tensorflow SessionFactory in libtensorflow core a session factory o tensorflow TrackingAllocator TrackingAllocator tensorflow Allocator bool in libtensorflow core a tracking allocator o tensorflow TrackingAllocator TrackingAllocator tensorflow Allocator bool in libtensorflow core a tracking allocator o nsync nsync mu lock nsync nsync mu s referenced from tensorflow FileSystemRegistryImpl Register std 1 basic string char std 1 char traits char std 1 allocator char const std 1 function tensorflow FileSystem in libtensorflow core a env o tensorflow FileSystemRegistryImpl Lookup std 1 basic string char std 1 char traits char std 1 allocator char const in libtensorflow core a env o tensorflow FileSystemRegistryImpl GetRegisteredFileSystemSchemes std 1 vector std 1 basic string char std 1 char traits char std 1 allocator char std 1 allocator std 1 basic string char std 1 char traits char std 1 allocator char in libtensorflow core a env o tensorflow CPUAllocator AllocateRaw unsigned long unsigned long in libtensorflow core a allocator o tensorflow CPUAllocator DeallocateRaw void in libtensorflow core a allocator o tensorflow CPUAllocator GetStats tensorflow AllocatorStats in libtensorflow core a allocator o tensorflow SessionFactory Register std 1 basic string char std 1 char traits char std 1 allocator char const tensorflow SessionFactory in libtensorflow core a session factory o nsync nsync mu unlock nsync nsync mu s referenced from tensorflow FileSystemRegistryImpl Register std 1 basic string char std 1 char traits char std 1 allocator char const std 1 function tensorflow FileSystem in libtensorflow core a env o tensorflow FileSystemRegistryImpl Lookup std 1 basic string char std 1 char traits char std 1 allocator char const in libtensorflow core a env o tensorflow FileSystemRegistryImpl GetRegisteredFileSystemSchemes std 1 vector std 1 basic string char std 1 char traits char std 1 allocator char std 1 allocator std 1 basic string char std 1 char traits char std 1 allocator char in libtensorflow core a env o tensorflow CPUAllocator AllocateRaw unsigned long unsigned long in libtensorflow core a allocator o tensorflow CPUAllocator DeallocateRaw void in libtensorflow core a allocator o tensorflow CPUAllocator GetStats tensorflow AllocatorStats in libtensorflow core a allocator o tensorflow SessionFactory Register std 1 basic string char std 1 char traits char std 1 allocator char const tensorflow SessionFactory in libtensorflow core a session factory o ld symbol s not found for architecture x86 64 clang error linker command failed with exit code 1 use v to see invocation,,,2017-11-16 03:03:18,2017-11-16 04:16:43
IS,tensorflow python session clusterspec prop test is failing with GPU support,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source TensorFlow version use command below TF1 3 1 Python version Python 2 7 5 Bazel version if compiling from source Bazel 0 5 4 GCC Compiler version if compiling from source gcc 4 8 5 CUDA cuDNN version cuda 8 0 and cuDNN 6 0 21 GPU model and memory 0 Tesla P100 SXM2 16276MiB 1 Tesla P100 SXM2 16276MiB Exact command to reproduce bazel test config opt config cuda k tensorflow python session clusterspec prop test Describe the problem This test passed successfully with CPU only However its failing with GPU support getting assertion error 1 0 I was debugging this test failure and found following code fails for GPU L86 L92,,"sandipmgiri,yaroslavvb,sandipmgiri",2017-11-13 09:19:33,2017-11-16 04:58:48
IS,FAIL common runtime direct session with tracking alloc test with GPU support,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 ppc64le TensorFlow installed from source or binary Installed from source TensorFlow version use command below TF 1 3 1 Python version Python 2 7 5 Bazel version if compiling from source Bazel 0 5 4 CUDA cuDNN version cuda 8 0 and cuDNN 6 0 21 GPU model and memory 0 Tesla P100 SXM2 16276MiB 1 Tesla P100 SXM2 16276MiB Exact command to reproduce bazel test config opt config cuda k tensorflow core common runtime direct session with tracking alloc test Describe the problem This test passed successfully with CPU only However its failing for GPU getting following error F tensorflow core common runtime direct session with tracking alloc test cc 141 Check failed cost models size 1 2 vs 1 Test expects cost models size '1' but we are getting '2' with GPU I was looking into this test failure and I found some relevant discussion links 1 Here mentioned this test is marked for no gpu 2 Here I found following comments The aim of this test is to ensure that there is at least one cost model that of the CPU as if there are no cost models then the test should fail and there is no point in trying to run the other tests on the cost model The number of cost models provided by a session should matches the number of devices used by that session When additional devices are present there will be more than one cost model so we should not be checking for equality but rather that the number of cost models is at least one As per above comments I think we should raise a PR with following changes to pass on GPU as well L141 Original CHECK EQ cost models size 1 Updated to CHECK GE cost models size 1 Please provide your comments on this Thanks Source code logs,,"sandipmgiri,yaroslavvb,sandipmgiri",2017-11-15 09:13:29,2017-11-16 05:02:19
IS,bazel build command failed for tensorflow serving,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 docker container TensorFlow installed from source or binary TensorFlow version use command below 1 3 0 Python version 3 5 2 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel build c opt jobs 1 local resources 5 2 0 2 0 verbose failures tensorflow serving cat etc issue Linux 25b038d948eb 4 9 49 moby 1 SMP Wed Sep 27 23 17 17 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker Yes compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux 25b038d948eb 4 9 49 moby 1 SMP Wed Sep 27 23 17 17 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi env collect sh line 105 nvidia smi command not found cuda libs cat etc issue Linux 25b038d948eb 4 9 49 moby 1 SMP Wed Sep 27 23 17 17 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker Yes compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux 25b038d948eb 4 9 49 moby 1 SMP Wed Sep 27 23 17 17 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi bash nvidia smi command not found cuda libs Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am facing issues while running bazel build command in order to install tensorflow serving in the docker container COMMAND RAN bazel build c opt jobs 1 local resources 5 2 0 2 0 verbose failures tensorflow serving ERROR root cache bazel bazel root f8d1071c69ea316497c31e40fe01608c external inception model inception slim BUILD 55 1 Converting to Python 3 external inception model inception slim ops py failed Exit 1 2to3 failed error executing command cd root cache bazel bazel root f8d1071c69ea316497c31e40fe01608c execroot tf serving exec env bazel out host bin external bazel tools tools python 2to3 no diffs nobackups write output dir bazel out local py3 opt genfiles python3 external inception model inception slim write unchanged files external inception model inception slim ops py I am trying to create a tensorflow serving container with python3 and tensorflow 1 3 I have successfully create tensorflow serving with python2 and tested mnist and inception models,,,2017-11-16 06:12:17,2017-11-16 06:31:51
PR,XLA Rename symbols for OS X only it does not have sincos,On OS X the sincos and sincosf are apparently not present There is a sincos and sincosf This change creates an alias for them on OS X,,"DavidNorman,DavidNorman,DavidNorman",2017-10-31 17:26:59,2017-11-16 08:12:00
IS,how to change the gpu fraction per process from default 1 to 0 5 or 0 7,I want to change the gpu fraction per process from default 1 to 0 5 or 0 7 Not by adding the below in my code Is there other method to change it in the tensorflow source file In the case of Keras I can change it by modifying keras json file I spent a lot of time to find the way though I cannot find the way Is it impossible,,"yaroslavvb,yaroslavvb",2017-11-15 13:58:23,2017-11-16 09:28:35
PR,R1 4,,,,2017-11-16 16:52:31,2017-11-16 18:15:32
PR,Simplify imports,,,jhseu,2017-11-16 17:10:09,2017-11-16 18:18:41
PR,Speech commands Add num classes label count when constructing the,confusion matrix This seems like it should fix an issue where you get unlucky the batch does not contain the largest label and the returned matrix is smaller than other runs,,mrry,2017-11-16 00:21:41,2017-11-16 18:19:48
PR,minor spelling tweaks in headers,,,"brettkoonce,jhseu",2017-11-15 06:18:41,2017-11-16 18:20:06
IS,Bug Inclusion missing in TF 1 4 BUILD file for mpi component,System information I'm compiling TF from sources to have AVX512F instruction support OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary source 11 14 2017 TensorFlow version use command below 1 4 0 Python version 3 6 1 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 0 7 0 3 GPU model and memory GTX 1080Ti CPU i9 7900x Exact command to reproduce bazel build config mkl config cuda copt O3 cxxopt D GLIBCXX USE CXX11 ABI 0 copt DOMPI SKIP MPICXX tensorflow tools pip package build pip package Describe the problem error in compile build ERROR home tadeusz temp TF14a tensorflow master tensorflow contrib mpi BUILD 60 1 undeclared inclusion s in rule ' tensorflow contrib mpi mpi rendezvous mgr' this rule is missing dependency declarations for the following files included by 'tensorflow contrib mpi mpi rendezvous mgr cc' ' home tadeusz temp TF14a tensorflow master tensorflow core distributed runtime tensor coding h' In file included from tensorflow core platform default logging h 24 0 from tensorflow core platform logging h 25 from tensorflow core lib gtl array slice internal h 32 from tensorflow core lib gtl array slice h 101 from tensorflow core lib strings str util h 23 from tensorflow contrib mpi mpi utils h 25 from tensorflow contrib mpi mpi rendezvous mgr h 33 from tensorflow contrib mpi mpi rendezvous mgr cc 18 tensorflow core util tensor format h In instantiation of 'T tensorflow GetTensorDim tensorflow gtl ArraySlice T tensorflow TensorFormat char with T long long int ' tensorflow core util tensor format h 372 47 required from here tensorflow core util tensor format h 340 29 warning comparison between signed and unsigned integer expressions Wsign compare Source code logs the following helps in file tensorflow contrib mpi BUILD,,"rohan100jain,jbedorf,jbedorf",2017-11-14 19:23:45,2017-11-16 18:20:18
PR,Fix MPI compilation,Fixes 14558 introduced by 2ce0b9149741105795083c4bae8fb0b85cb9659d,,"jbedorf,jhseu",2017-11-15 15:54:27,2017-11-16 18:20:18
PR,Branch 175983704,,,"jhseu,jhseu",2017-11-16 18:49:44,2017-11-16 20:33:28
IS,Target ' llvm support' is not visible from target ' org tensorflow tensorflow compiler xla client compile only client',I was doing an XLA compilation that worked before TensorFlow 1 4 but now errors with ERROR home travis build carl project cache bazel external org tensorflow tensorflow compiler xla client BUILD 107 1 Target ' llvm support' is not visible from target ' org tensorflow tensorflow compiler xla client compile only client' This is how I get tfcompile,,"carlthome,angersson,carlthome,carlthome,hawkinsp,jart,carlthome",2017-11-10 12:14:40,2017-11-16 20:34:10
IS,tf Dataset Iterator console flood when using CUDA builds,System information Have I written custom code Yes OS Platform and Distribution Manjaro linux Arch Linux repo TensorFlow installed from source or binary binary TensorFlow version 1 3 0 Python version 3 6 2 Bazel version CUDA cuDNN version cuda 8 0 61 cudnn 7 0 1 cudnn6 6 0 21 GPU model and memory Nvidia 1080 GTX 8GB Exact command to reproduce The problem When using a tensorflow wheel built with cuda support my app prints the following warning message at the end of a training epoch 2017 08 19 14 01 18 214060 W tensorflow core framework op kernel cc 1192 Out of range End of sequence Node IteratorGetNext IteratorGetNext output shapes 132 output types DT FLOAT DT INT64 DT INT64 DT INT64 device job localhost replica 0 task 0 cpu 0 Iterator The code trains a seq2seq model and I assume the message gets printed somewhere downstream of seq2seq dynamic decode The message still gets printed even when the NN cells are not wrapped with a tf contrib rnn DeviceWrapper with device field indicating a GPU only works fine on non cuda builds All of this happens while the code is protected with the try except statements Now the only cheeky thing is that I am using the binaries from Arch Linux repositories but these are far from being dodgy python tensorflow python tensorflow cuda The build script This problem was in tensorflow 1 2 and persists in tensorflow 1 3 Also tested on a laptop without dedicated gpu but same OS and packages works fine,,"ebrevdo,ebrevdo,mrry,mrry,ebrevdo,ebrevdo,mrry,betterenvi,mrry",2017-08-19 13:34:25,2017-11-16 20:34:10
PR,Merge of two internal changes,175695370 by A Unique TensorFlower Implements shared embedding columns and adds some tests 175695349 by A Unique TensorFlower Implements tf metrics true negatives adds missing tests and does some cleanup in tf contrib metrics This is 2 of the 3 commits in from staging c674e27bfd68a6c990e694b6afd901bfeeaa006d,,"aselle,jhseu",2017-11-14 19:51:15,2017-11-16 20:50:51
PR,Update wide md,,,"larrytin,jhseu",2017-11-14 13:52:54,2017-11-16 20:55:02
PR,fix broken link,,,"larrytin,jhseu,larrytin",2017-11-14 08:52:23,2017-11-16 20:57:37
PR,1 4 1 patch release update version string,,,av8ramit,2017-11-16 19:59:48,2017-11-16 20:59:17
PR,Correct space in ValueError for input rank,The current error message is ValueError 'Inputs should have rank 4Received input shape ' ' n ' where a space is missing so the change would result in ValueError 'Inputs should have rank 4 Received input shape ' ' n ',,jhseu,2017-11-12 17:22:23,2017-11-16 21:44:05
PR,Disable for generated examples zip test in open source,,,jhseu,2017-11-16 20:37:56,2017-11-16 22:51:05
PR,ONNX Support Run ONNX nodes using TF,As per Authors of ONNX TF package Arpith Jacob Tian Jin Gheorghe Teodor Bercea from IBM Research Objective We are porting a subset of our package of ONNX TF from here Specifically we want to enable users to do the following Current support for ONNX This implementation passes all the backend tests here except for RNN It supports all the models in the ONNX model zoo What we will be doing We are still working on fixing some of the tests as well as clearing as many TODO is as we can The ONNX RNN API changed very recently and we may do another PR for RNN support We would like your opinions We have not imported the ONNX package dependency as we would like to get TF team is opinion regarding whether how we should import ONNX package dependency The benefit is that we can check for the legality of ONNX node graph declaration Also we need a bunch of Proto definition like GraphProto TensorProto jacob,,"tjingrant,tjingrant,jhseu",2017-11-07 05:07:40,2017-11-16 23:57:02
IS,help me with tensorflow,wxf wxf K56L source activate tensorflow tensorflow wxf wxf K56L python Python 2 7 14 Anaconda Inc default Nov 8 2017 22 44 41 GCC 7 2 0 on linux2 Type help copyright credits or license for more information import tensorflow as tf Traceback most recent call last File stdin line 1 in module File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow python pywrap tensorflow py line 72 in module raise ImportError msg ImportError Traceback most recent call last File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home wxf anaconda2 envs tensorflow lib python2 7 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,gunan,2017-11-16 07:57:36,2017-11-17 06:31:23
IS,Undefined symbols cblas sgemm on iOS,Hello I downloaded the latest release 1 4 0 and builded it for iOS with build all ios sh and can successfully build libtensorflow core a libprotobuf lite a and libprotobuf a and added the libtensorflow core a with force load but error happened when link these libs to iOS project the detail info as follows can anybody know how to fix it thanks Undefined symbols for architecture arm64 cblas sgemm referenced from tensorflow Conv2DUsingGemmOp float tensorflow anonymous namespace Im2ColConvFunctor float float float FastGemmFunctor float float float Compute tensorflow OpKernelContext in libtensorflow core a conv ops using gemm o tensorflow FusedResizeConv2DUsingGemmOp float tensorflow anonymous namespace FusedResizeAndPadConvFunctor float float float FastGemmFunctor float float float tensorflow anonymous namespace SamplingMode 0 true Compute tensorflow OpKernelContext in libtensorflow core a conv ops fused o tensorflow FusedResizeConv2DUsingGemmOp float tensorflow anonymous namespace FusedResizeAndPadConvFunctor float float float FastGemmFunctor float float float tensorflow anonymous namespace SamplingMode 1 false Compute tensorflow OpKernelContext in libtensorflow core a conv ops fused o ld symbol s not found for architecture arm64 clang error linker command failed with exit code 1 use v to see invocation,,,2017-11-16 09:27:30,2017-11-17 07:38:01
IS,Why cannot use tf Print,I just want to print out the executing data like this t But I got Cannot assign a device for operation 'Print' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available I'm sure this piece of code can work in python console with tf device ' gpu 0' assigned Anyone help,,"caisq,ppwwyyxx",2017-11-16 03:43:41,2017-11-17 08:14:27
PR,Branch 176031889,,,jhseu,2017-11-16 23:51:56,2017-11-17 18:30:32
PR,iOS Camera example for TensorFlow Lite,The code is derived from the TensorFlow mobile camera example in tensorflow tensorflow examples ios camera,,"miaout17,miaout17",2017-11-15 18:04:01,2017-11-17 18:30:59
PR,typo s cesnus census,,,jhseu,2017-11-15 16:51:16,2017-11-17 18:31:16
PR,minor spelling tweaks,,,"brettkoonce,jhseu",2017-11-14 22:46:08,2017-11-17 18:31:52
PR,Exporting tensorflow package for cmake,This PR is based on the PR 13867 It provides the usage of cmake find package Therefore it should be easier to intergrate the prebuilt tensorflow code into existing external projects 1 What about a version control mechanism Cons Has to be manually changed in every new version 2 Supplying some examples with the installed version This examples should not be prebuilt furthermore they should be built with an installed tensorflow,,"mrry,mrry",2017-11-14 16:50:58,2017-11-17 18:32:01
IS,Windows Bazel build is failing due to compiling error for tensorflow compiler xla util,This dependency exists even when xla is disabled changed xla data proto which somehow caused this problem Because the code is generated by protobuf I'm not sure if this is a protobuf bug,,"meteorcloudy,meteorcloudy,alextp,meteorcloudy,alextp",2017-11-14 13:53:15,2017-11-17 18:34:07
PR,Move ptr util to core util,Break the dependency of core onto XLA Fixes 14549,,gunan,2017-11-17 07:44:05,2017-11-17 18:34:07
IS,'Model' object has no attribute 'container nodes',Problem Environment System Ubuntu 16 04 Tensorflow gpu bin v1 4 0 rc1 11 g130a514 1 4 0,,qmick,2017-11-14 10:16:22,2017-11-17 18:34:20
PR,Fix a bug of model to dot,This patch fixes 14542,,"qmick,qmick",2017-11-14 16:07:47,2017-11-17 18:34:20
PR,Fix the wrong ValurError formatting in convolutional py,This commit makes the error message of the build function of Conv2DTranspose a complete string which is more human readable,,,2017-11-14 14:20:41,2017-11-17 18:34:37
PR,Removes non existent link,,,larrytin,2017-11-14 08:56:05,2017-11-17 18:34:47
PR,fix broken section links in the document,,,,2017-11-14 01:07:04,2017-11-17 18:35:01
IS,Is tensorflow Lite support for detection like SSD,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-17 06:28:08,2017-11-17 19:02:48
IS,crash,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-17 09:46:57,2017-11-17 19:03:44
IS,Incorrect second derivative for softmax cross entropy,System information I have written custom code OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below tensorflow gpu 1 2 1 python version 2 7 12 CUDA cuDNN version CUDA version 8 0 and CUDNN version is 8 0 GPU model and memory GeForce GTX 750 2GB Incorrect second derivative for softmax cross entropy Source code logs,,"caisq,alextp,ebrevdo,qmick,alextp,alextp,alextp,alextp",2017-11-17 01:23:36,2017-11-17 19:19:33
IS,Windows Speech commands tutorial does not work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I'm running python tensorflow examples speech commands train py OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 x64 TensorFlow installed from source or binary pip install tf nightly tf nightly 1 5 0 dev20171026 cp35 cp35m win amd64 whl TensorFlow version use command below b'unknown' 1 5 0 dev20171026 Python version Python 3 5 4 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 1 x64 GPU model and memory 2x Nvidia GTX 670 2GB Exact command to reproduce python tensorflow examples speech commands train py Describe the problem It appears that the currently nightlies or 1 4 0rc1 do not contain the gen audio ops module However the documentation for r1 4 or master or appears to indicate that the speech commands demo should work Related 13031 Source code logs,,"mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry,mrry",2017-10-26 17:38:06,2017-11-17 19:29:14
PR,Portable path parsing in speech commands input data py,Convert some code using a regular expression with ' ' characters into code that uses os path methods and therefore handles ' ' characters in Windows paths Fixes 14004,,"mrry,mrry,mrry",2017-11-13 15:44:58,2017-11-17 19:29:14
PR,Java Remove obsolete Input interface,Input interface is obsolete and has been replaced by Operand a long time ago It probably came back to life as a result of a merge I guess,,"karllessard,asimshankar,asimshankar",2017-11-13 12:13:32,2017-11-17 19:29:51
PR,Java Add support for shape list attributes,This allows passing a list of shapes as an attribute to an operation Some operation wrappers cannot be generated without it,,"karllessard,asimshankar,karllessard,asimshankar,asimshankar",2017-11-17 04:28:44,2017-11-17 20:43:23
PR,PrefetchDatasetOp checks buffer size in c side,alternative pr for 14447 check buffer size in c side How to test x add test case x pass all tests,,"facaiy,mrry",2017-11-13 05:06:02,2017-11-17 20:46:27
PR,Add missing conv1d in tf contrib layers,Currently conv1d exists in tf layers but does not in tf contrib layers,,taehoonlee,2017-11-13 07:19:39,2017-11-17 20:54:36
PR,Fix typos,This PR fixes some typos mutli accomodate ouput conjuction accross simplifed and seperately,,taehoonlee,2017-11-13 10:58:09,2017-11-17 20:55:57
PR,fix assert shallow structure for dicts,The function tensorflow python data util nest flatten up to used in tf data Dataset from generator does not compare the dict keys only the length of the dict This PR fix tensorflow python data util assert shallow structure that is used in tensorflow python data util nest flatten up to but there may also other function that have such a bug,,"boeddeker,boeddeker,mrry",2017-11-12 14:37:39,2017-11-17 20:56:43
PR,use with when calling TFRecordWriter,TFRecordWriter supports enter and exit Calling it through with is more pythonic and does cleanup in case something throws an uncaught exception,,qmick,2017-11-12 14:13:10,2017-11-17 20:56:54
IS,tf nn sparse softmax cross entropy with logits documentation error,It looks like there may be a documentation error in tf nn sparse softmax cross entropy with logits It mentions ValueError If logits are scalars need to have rank 1 or if the rank of the labels is not equal to the rank of the labels minus one Based on the argument requirements above I believe this should read ValueError If logits are scalars need to have rank 1 or if the rank of the labels is not equal to the rank of the logits minus one,,facaiy,2017-11-10 14:43:35,2017-11-17 20:57:04
PR,Fixed incorrect documentation in tf contrib nn deprecated flipped spa,rse softmax cross entropy with logits where it referenced labels rather than logits I was looking to fix 14450 but was unable to because it seems the site documentation is not the same as the in file documentation in master which is correct in that case It seems someone fixed it in master but the change was not made to 1 4 However incidentally I noticed this identical error on tf contrib nn deprecated flipped sparse softmax cross entropy with logits In this case the error is on both the in file documentation and the website documentation,,,2017-11-11 15:15:28,2017-11-17 20:57:04
PR,Revert Add missing conv1d in tf contrib layers,Reverts tensorflow tensorflow 14513 Actually we should not be modifying tf contrib layers at this point Reverting,,jhseu,2017-11-17 20:56:22,2017-11-17 21:06:05
PR,Added mode to input function arguments,,,"k-w-w,k-w-w",2017-11-15 01:28:27,2017-11-17 21:13:53
PR,Typo,fix typo dissassemble disassemble,,"ManHyuk,jhseu",2017-11-10 05:54:13,2017-11-17 22:24:33
IS,libtensorflow cc so linker issues with release 1 4 Undefined reference,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes code similar to the example label image cc OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary From source TensorFlow version use command below 1 4 0 Python version 3 6 1 Bazel version if compiling from source 0 7 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce build libtensorflow cc so from command bazel build config opt config mkl copt mavx copt mavx2 copt mfma copt msse4 2 tensorflow libtensorflow cc so tensorflow tools pip package build pip package Describe the problem After successfully build the library try to compile my code with the library using following gcc command g I usr local include L usr local lib ltensorflow std c 11 rtclassifier cc result in 'undefined reference to tensorflow GraphDef GraphDef ' error Source code logs tmp ccxBMZph o In function LoadGraph std cxx11 basic string char std char traits char std allocator char const std unique ptr tensorflow Session std default delete tensorflow Session ' tl classifier cc text 0x90 undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0xa4 undefined reference to tensorflow Env Default ' tl classifier cc text 0xc4 undefined reference to tensorflow ReadBinaryProto tensorflow Env std cxx11 basic string char std char traits char std allocator char const google protobuf MessageLite ' tl classifier cc text 0x15e undefined reference to tensorflow SessionOptions SessionOptions ' tl classifier cc text 0x16d undefined reference to tensorflow NewSession tensorflow SessionOptions const ' tl classifier cc text 0x22a undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x2b7 undefined reference to tensorflow GraphDef GraphDef ' tmp ccxBMZph o In function ReadTensorFromImageFile std cxx11 basic string char std char traits char std allocator char const int int float float std vector tensorflow Tensor std allocator tensorflow Tensor ' tl classifier cc text 0x332 undefined reference to tensorflow Scope NewRootScope ' tl classifier cc text 0x3dd undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x3fd undefined reference to tensorflow ops ReadFile ReadFile tensorflow Scope const tensorflow Input ' tl classifier cc text 0x40c undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x504 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x528 undefined reference to tensorflow ops DecodePng DecodePng tensorflow Scope const tensorflow Input tensorflow ops DecodePng Attrs const ' tl classifier cc text 0x587 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x671 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x691 undefined reference to tensorflow ops DecodeGif DecodeGif tensorflow Scope const tensorflow Input ' tl classifier cc text 0x6f4 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x714 undefined reference to tensorflow ops Squeeze Squeeze tensorflow Scope const tensorflow Input ' tl classifier cc text 0x773 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x7be undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x867 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x88b undefined reference to tensorflow ops DecodeJpeg DecodeJpeg tensorflow Scope const tensorflow Input tensorflow ops DecodeJpeg Attrs const ' tl classifier cc text 0x8ea undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x97a undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x99c undefined reference to tensorflow ops Cast Cast tensorflow Scope const tensorflow Input tensorflow DataType ' tl classifier cc text 0x9ab undefined reference to tensorflow Scope Scope ' tl classifier cc text 0xa38 undefined reference to tensorflow ops ExpandDims ExpandDims tensorflow Scope const tensorflow Input tensorflow Input ' tl classifier cc text 0xaea undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0xb0a undefined reference to tensorflow ops Const tensorflow Scope const tensorflow Input Initializer const ' tl classifier cc text 0xb60 undefined reference to tensorflow ops ResizeBilinear ResizeBilinear tensorflow Scope const tensorflow Input tensorflow Input ' tl classifier cc text 0xb9c undefined reference to tensorflow Scope Scope ' tl classifier cc text 0xc9c undefined reference to tensorflow ops Subtract Subtract tensorflow Scope const tensorflow Input tensorflow Input ' tl classifier cc text 0xcd5 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0xcf9 undefined reference to tensorflow ops Div Div tensorflow Scope const tensorflow Input tensorflow Input ' tl classifier cc text 0xd17 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0xdbb undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0xddb undefined reference to tensorflow Scope ToGraphDef tensorflow GraphDef const' tl classifier cc text 0xe3e undefined reference to tensorflow SessionOptions SessionOptions ' tl classifier cc text 0xe4d undefined reference to tensorflow NewSession tensorflow SessionOptions const ' tl classifier cc text 0x109e undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x1116 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1175 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x11b4 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1216 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1275 undefined reference to tensorflow Scope Scope ' tmp ccxBMZph o tl classifier cc text 0x12d7 more undefined references to tensorflow Scope Scope ' follow tmp ccxBMZph o In function ReadTensorFromImageFile std cxx11 basic string char std char traits char std allocator char const int int float float std vector tensorflow Tensor std allocator tensorflow Tensor ' tl classifier cc text 0x15ee undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x167a undefined reference to tensorflow Scope Scope ' tmp ccxBMZph o In function GetTopLabels std vector tensorflow Tensor std allocator tensorflow Tensor const int tensorflow Tensor tensorflow Tensor ' tl classifier cc text 0x18fe undefined reference to tensorflow Scope NewRootScope ' tl classifier cc text 0x1999 undefined reference to tensorflow Scope WithOpName std cxx11 basic string char std char traits char std allocator char const const' tl classifier cc text 0x19bd undefined reference to tensorflow ops TopK TopK tensorflow Scope const tensorflow Input tensorflow Input ' tl classifier cc text 0x19db undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1a08 undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x1a28 undefined reference to tensorflow Scope ToGraphDef tensorflow GraphDef const' tl classifier cc text 0x1a8b undefined reference to tensorflow SessionOptions SessionOptions ' tl classifier cc text 0x1a9a undefined reference to tensorflow NewSession tensorflow SessionOptions const ' tl classifier cc text 0x1d7e undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x1d9c undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1de4 undefined reference to tensorflow Scope Scope ' tl classifier cc text 0x1f1a undefined reference to tensorflow GraphDef GraphDef ' tl classifier cc text 0x1f3d undefined reference to tensorflow Scope Scope ' tmp ccxBMZph o In function PrintTopLabels std vector tensorflow Tensor std allocator tensorflow Tensor const std cxx11 basic string char std char traits char std allocator char const ' tl classifier cc text 0x1ff4 undefined reference to tensorflow internal LogMessage LogMessage char const int int ' tl classifier cc text 0x201c undefined reference to tensorflow internal LogMessage LogMessage ' tl classifier cc text 0x2081 undefined reference to tensorflow Tensor Tensor ' tl classifier cc text 0x2090 undefined reference to tensorflow Tensor Tensor ' tl classifier cc text 0x21ed undefined reference to tensorflow internal LogMessage LogMessage char const int int ' tl classifier cc text 0x225a undefined reference to tensorflow internal LogMessage LogMessage ' tl classifier cc text 0x2284 undefined reference to tensorflow Tensor Tensor ' tl classifier cc text 0x2293 undefined reference to tensorflow Tensor Tensor ' tl classifier cc text 0x22e2 undefined reference to tensorflow internal LogMessage LogMessage ',,"allenlavoie,allenlavoie,allenlavoie",2017-11-16 19:06:47,2017-11-17 22:51:42
PR,Fix parameter pack expansion in ptr util,,,"gunan,gunan",2017-11-17 22:23:22,2017-11-17 23:39:15
PR,typo fixed,It appears that you are missing a comma after the introductory phrase In the last few years Consider adding a comma,,,2017-11-17 18:38:35,2017-11-18 00:28:44
PR,Fix up link to ios md in docs,Fix up the broken link so it points at the ios docs correctly instead of 404,,,2017-11-17 00:22:42,2017-11-18 00:29:15
PR,Update AUTHORS,,,,2017-11-18 08:36:22,2017-11-18 08:37:02
IS,Which c source code Should I modify to allocate GPU memory dynamically,I am using Spark with tensorflow Spark make many tensorflow process so I want tensorflow to allocate GPU memory dynamically Adding the below code is not workin g for me Although I found the way to set gpu memory fraction in 'tensorflow tensorflow core common runtime gpu gpu device cc' I want to set 'allow growth' in c source Which part shoud I modify,,,2017-11-16 07:33:42,2017-11-18 16:02:35
IS,Wrong link in tensorflow for poets codelab,3 There is a link for Inception V3 model pointing to pre trained models which 404 is I assume it can point to instead img width 375 alt screen shot 2017 11 11 at 06 37 47 src I would have sent a PR fixing the link but the codelab text does not seem to be available on anywhere Github,,"drpngx,MarkDaoust",2017-11-11 06:38:33,2017-11-18 21:20:55
IS,i'm a newcomer and met the following problem,i install tensorflow following the guide explanation in www tensorflow org install install windows System information OS Platform and Distribution win10 TensorFlow installed from source or binary source TensorFlow version use command below i use the following command pip3 install upgrade tensorflow gpu Python version 3 5 2 CUDA cuDNN version cuda 8 0 cudnn 8 0 GPU model and memory GTX1070 8g i download the source successfully and when i enter the following short program inside the python interactive shell import tensorflow as tf it goes wrong Traceback most recent call last File E SoftWare Python lib site packages tensorflow python platform self check py line 87 in preload check ctypes WinDLL build info cudnn dll name File E SoftWare Python lib ctypes init py line 347 in init self handle dlopen self name mode OSError WinError 126 Could not find the specified module During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File E SoftWare Python lib site packages tensorflow init py line 24 in module from tensorflow python import File E SoftWare Python lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File E SoftWare Python lib site packages tensorflow python pywrap tensorflow py line 30 in module self check preload check File E SoftWare Python lib site packages tensorflow python platform self check py line 97 in preload check build info cudnn dll name build info cudnn version number ImportError Could not find 'cudnn64 6 dll' TensorFlow requires that this DLL be installed in a directory that is named in your PATH environment variable Note that installing cuDNN is a separate step from installing CUDA and this DLL is often found in a different directory from the CUDA DLLs You may install the necessary DLL by downloading cuDNN 6 from this URL in my file sys the dll file is name is cudnn64 5 dll and following is my path image i can find my msvcp140 dll please help thx,,qmick,2017-11-18 08:11:13,2017-11-18 23:18:27
IS,Why did you call BasicLSTMCell a cell and not a layer,BasicLSTMCell is actually a layer as for a layer in MLPs of LSTM units Each of these LSTM units contains a cell Each cell of an LSTM unit contains a scalar value for the CEC and a scalar representing the previous state People are usually first introduced to MLPs or feed forward and fully connected neural networks before being introduced to RNNs and in particular LSTMs Why would you call BasicLSTMCell a cell if it can be thought more intuitively at least for me as a layer of LSTM units as I describe them above containing just one scalar based cell Would not it be less ambiguous to call a BasicLSTMCell BasicLSTMLayer Moreover the first parameter to BasicLSTMCell is init method is num units i e the number of LSTM units i e the number of LSTM cells and gates if we have 3 gates for every LSTM unit then the total number of gates in one layer of LSTMs is 3 num units It almost seems that you created TF to make it as confusing as possible to make it seem hard It also almost seems that the person who wrote the name of the class BasicLSTMCell is a different person of the person who wrote its init method What is going on A little bit of consistency for once no A similar argument can be said for MultiRNNCell which a lot more intuitively can be thought as a sequence of layers Request Change classes such as BasicLSTMCell and MultiRNNCell to have more descriptive names of what they actually are in future versions of TF Then change the corresponding documentation to be more compliant with these changes,,"ebrevdo,ebrevdo",2017-11-18 17:15:30,2017-11-19 07:45:30
PR,Fix pip package tests,They depend on a testonly package so they break pip test runs for nightly and releases,,"gunan,gunan",2017-11-18 08:06:17,2017-11-19 07:52:32
PR,added my name as a contributors,,,"caisq,gunan",2017-11-18 20:18:03,2017-11-19 07:57:04
IS,Support dynamic partition in loss function,System information Python 3 6 1 Ubuntu 16 04 TF 1 3 Describe the problem I am trying to implement a loss function in Tensorflow similar to the Theano loss function described here I have tried several code but they all lead to runtime error Seems that dynamically sized tensors are not supported in loss function I have tried various optimizers including adam without success When tested standalone the function works fine and produces results similar to a numpy based implementation Source code logs Here is one code I tried import tensorflow as tf def pair loss y true y pred y true tf cast y true tf int32 parts tf dynamic partition y pred y true 2 y pos parts 1 y neg parts 0 y pos tf expand dims y pos 0 y neg tf expand dims y neg 1 out tf sigmoid y neg y pos return tf reduce mean out axis 1 Here is the theano code for reference import theano def calc auroc loss pred vr y vr pos pred vr pred vr y vr nonzero neg pred vr pred vr theano tensor eq y vr 0 nonzero pred diffs vr pos pred vr dimshuffle 0 'x' neg pred vr dimshuffle 'x' 0 num pairs vr theano tensor sum theano tensor eq y vr 1 theano tensor sum theano tensor eq y vr 0 auroc vr theano tensor sum theano tensor nnet sigmoid pred diffs vr num pairs vr return auroc vr,,"ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx",2017-11-17 14:05:50,2017-11-20 14:34:45
IS,tf data Dataset padded batch does not work with nested elements,System information TF 1 4 pip install Python version 3 5 2 Anaconda Problem description tf data Dataset padded batch fails if a dataset element has some nested structure instead of being a tensor Dataset API is supposed to work with Estimator is input fn functionality which should return features and labels as separate python objects and it is very inconvenient to merge everything into a single tensor make a batch and then split Source import tensorflow as tf print tf version dataset tf data Dataset range 100 dataset dataset map lambda x 'x' tf fill tf cast x tf int32 x 'y' tf fill tf cast x tf int32 x dataset dataset padded batch 4 padded shapes None iterator dataset make one shot iterator next element iterator get next with tf train MonitoredSession as sess print sess run next element print sess run next element Actual TypeError Traceback most recent call last ipython input 38 bb9f335976ed in module 2 dataset dataset map lambda x 'x' tf fill tf cast x tf int32 x 3 'y' tf fill tf cast x tf int32 x 4 dataset dataset padded batch 4 padded shapes None 5 6 iterator dataset make one shot iterator anaconda3 lib python3 5 site packages tensorflow python data ops dataset ops py in padded batch self batch size padded shapes padding values 693 A Dataset 694 695 return PaddedBatchDataset self batch size padded shapes padding values 696 697 def map self map func num parallel calls None anaconda3 lib python3 5 site packages tensorflow python data ops dataset ops py in init self input dataset batch size padded shapes padding values 1290 self default padding input dataset 1291 self padded shapes nest map structure up to 1292 input dataset output shapes partial shape to tensor padded shapes 1293 self padding values nest map structure up to 1294 input dataset output shapes padding value to tensor padding values anaconda3 lib python3 5 site packages tensorflow python data util nest py in map structure up to shallow tree func inputs 510 raise ValueError Cannot map over no sequences 511 for input tree in inputs 512 assert shallow structure shallow tree input tree 513 514 Flatten each input separately apply the function to corresponding elements anaconda3 lib python3 5 site packages tensorflow python data util nest py in assert shallow structure shallow tree input tree check types 354 raise TypeError 355 If shallow structure is a sequence input must also be a sequence 356 Input has type s type input tree 357 358 if check types and not isinstance input tree type shallow tree TypeError If shallow structure is a sequence input must also be a sequence Input has type class 'list' Expected It should produce dictionary where x and y values are batch tensors with proper paddings,,mrry,2017-11-19 14:53:21,2017-11-20 17:24:50
PR,enum34 is only required for Python 3 4,I ran into problems when building TensorFlow 1 4 0 on top of Python 3 6 3 because enum34 is pulled in but not compatible with Python 3 6 i e python c 'import tensorflow' lead to See also,,"gunan,caisq,gunan,yifeif,gunan,gunan",2017-11-09 20:46:05,2017-11-20 19:17:07
PR,Avoid using illegal characters in checkpoint file names in normalizat,ion test,,"gunan,gunan",2017-11-18 00:31:44,2017-11-20 19:33:08
PR,MKL Faster CPU implementation of batch matmul kernel using MKL cblas apis,,,"jbobba,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,jbobba,jbobba,rmlarsen,jbobba,rmlarsen,rmlarsen",2017-11-07 22:08:12,2017-11-20 20:13:07
PR,Use cub ReduceByKey to count partition indices,This implements a suggestion made by in the comments for 13905 It replaces the previously custom made counting method and is likely more efficient In order to use cub ReduceByKey properly I defined a specialization of TransformOutputIterator that only allows writes in a bounded interval This is needed in the case of wrong inputs I have also added tests for the GPU kernel covering the case of wrong inputs,,"codrut3,ekelsen,ekelsen,codrut3",2017-11-17 19:25:18,2017-11-20 20:58:54
PR,XLA Fix build issue with TensorShape constructor,The TensorShape requires a default provided constructor This change uses the same style of providing that as is seen elsewhere in the code OS possibly only OS X,,"DavidNorman,DavidNorman",2017-11-17 08:44:28,2017-11-20 20:59:11
PR,Add feature get placeholders,Add a new API that can get all placeholders of a graph easily as 14374 requires,,"qmick,qmick,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,qmick",2017-11-14 09:42:58,2017-11-20 20:59:40
PR,Fix typo,fix typo initialize initialize,,ManHyuk,2017-11-10 05:42:40,2017-11-20 20:59:58
PR,code comments error in docker notebook,as is related with issue 14430 1 changed x with bias to bias with x for clear understanding 2 changed weights updated comments in code for an error 3 added lecun is repo for mnist data for there would be no connection no good connection for google,,,2017-11-10 07:16:19,2017-11-20 21:00:08
PR,Added checkpoint V1 test for SaveRestoreShardedTest,It seems that the V1 path of the SaveRestoreShardedTest test is not executed but the code is there This patch will execute the V1 path,,tedhtchang,2017-11-11 00:50:48,2017-11-20 21:00:20
PR,Fixing download dependencies sh bugs for generating TFLite iOS exmaples,Root cause The script downloads files for building TFLite for iOS example It writes to downloads directory and conflicts with the visibility rule in BUILD,,"miaout17,miaout17,miaout17,miaout17",2017-11-16 18:59:28,2017-11-20 22:56:22
PR,R1 1,,,,2017-11-20 23:48:07,2017-11-21 00:02:59
IS,Python tests in tensorflow python keras are failing on Windows,Theses tests are not running in CMake build on Windows so it is only detected by Bazel,,"meteorcloudy,reedwm,mrry,gunan,gunan,mrry,fchollet,gunan",2017-09-11 08:46:29,2017-11-21 00:07:17
PR,Fix all tests under python keras on windows,Fixes 12959,,"gunan,mrry,mrry,mrry,gunan,gunan,gunan,fchollet,gunan,martinwicke,gunan,gunan,gunan,gunan,gunan,fchollet",2017-11-10 07:04:45,2017-11-21 00:07:17
IS,when validate my tensorflow installation using hello tensorflow stack smashing detected python terminated Aborted core dumped,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary installed from native pip3 for Python 3 5 GPU support TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version Python 3 5 2 Bazel version if compiling from source GCC 4 4 7 20120313 Red Hat 4 4 7 1 GCC Compiler version if compiling from source CUDA cuDNN version Cuda compilation tools release 9 0 V9 0 176 GPU model and memory name GeForce GTX 1080 Ti totalMemory 10 91GiB freeMemory 10 51GiB Describe the problem when validate my tensorflow installation using hello tensorflow stack smashing detected python terminated Aborted core dumped Source code logs python import tensorflow as tf hello tf constant 'Hello TensorFlow ' sess tf Session print sess run hello screenshot from 2017 11 19 15 21 37,,,2017-11-19 07:46:21,2017-11-21 01:15:18
IS,NameError global name 'xrange' is not defined in Python 3 and solution proposal,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 Docker image TensorFlow installed from source or binary pip install TensorFlow version use command below 1 4 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Running the example code under python 3 6 in Docker environment I got xrange error NameError global name 'xrange' is not defined in Python 3 I propose to change every xrange to range under the 3 x versions patch for xrange find opt conda lib python3 6 site packages tensorflow contrib boosted trees type f print0 xargs 0 sed i is xrange range g' Source code logs NameError global name 'xrange' is not defined in Python 3,,mrry,2017-11-20 14:46:53,2017-11-21 09:30:53
IS,Test case with multiple threads do not work in TF 1 4,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 RedHat7 2 TensorFlow installed from source or binary tensorflow gpu binary TensorFlow version use command below r1 4 Python version python 2 7 CUDA cuDNN version CUDA 8 0 CUDNN 6 0 GPU model and memory NVIDIA K80 Exact command to reproduce python tensorflow python training sync replicas optimizer test py Describe the problem When I start a test case for sync optimizer it always shows that ps 0 ps 1 worker 1 are not ready It seems this only happens in TF 1 4 Source code logs Source Code Logs 2017 11 21 18 37 58 627374 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties 6 1673 name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 0000 06 00 0 totalMemory 11 17GiB freeMemory 11 11GiB 2017 11 21 18 37 58 874015 I tensorflow core common runtime gpu gpu device cc 1030 Found device 1 with properties name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 0000 07 00 0 totalMemory 11 17GiB freeMemory 11 11GiB 2017 11 21 18 37 58 874455 I tensorflow core common runtime gpu gpu device cc 1045 Device peer to peer matrix 2017 11 21 18 37 58 874488 I tensorflow core common runtime gpu gpu device cc 1051 DMA 0 1 2017 11 21 18 37 58 874499 I tensorflow core common runtime gpu gpu device cc 1061 0 Y Y 2017 11 21 18 37 58 874505 I tensorflow core common runtime gpu gpu device cc 1061 1 Y Y 2017 11 21 18 37 58 874523 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K80 pci bus id 0000 06 00 0 compute capability 3 7 2017 11 21 18 37 58 874532 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla K80 pci bus id 0000 07 00 0 compute capability 3 7 E1121 18 37 59 075062187 32596 ev epoll1 linux c 1051 grpc epoll fd 31 2017 11 21 18 37 59 081712 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 17358 1 localhost 24102 2017 11 21 18 37 59 081747 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 15405 1 localhost 17501 2017 11 21 18 37 59 083912 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 15405 2017 11 21 18 37 59 084202 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K80 pci bus id 0000 06 00 0 compute capability 3 7 2017 11 21 18 37 59 084222 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla K80 pci bus id 0000 07 00 0 compute capability 3 7 2017 11 21 18 37 59 090916 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 17358 1 localhost 24102 2017 11 21 18 37 59 090943 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 15405 1 localhost 17501 2017 11 21 18 37 59 091077 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 17501 2017 11 21 18 37 59 091268 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K80 pci bus id 0000 06 00 0 compute capability 3 7 2017 11 21 18 37 59 091286 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla K80 pci bus id 0000 07 00 0 compute capability 3 7 2017 11 21 18 37 59 097254 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 17358 1 localhost 24102 2017 11 21 18 37 59 097277 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 15405 1 localhost 17501 2017 11 21 18 37 59 097399 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 17358 2017 11 21 18 37 59 097548 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K80 pci bus id 0000 06 00 0 compute capability 3 7 2017 11 21 18 37 59 097566 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 1 device 1 name Tesla K80 pci bus id 0000 07 00 0 compute capability 3 7 2017 11 21 18 37 59 104080 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 17358 1 localhost 24102 2017 11 21 18 37 59 104127 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 15405 1 localhost 17501 2017 11 21 18 37 59 104281 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 24102 2017 11 21 18 38 09 222879 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 0 2017 11 21 18 38 09 222931 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 1 2017 11 21 18 38 09 222941 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job worker replica 0 task 1 2017 11 21 18 38 19 223062 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 0 2017 11 21 18 38 19 223102 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 1 2017 11 21 18 38 19 223110 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job worker replica 0 task 1 2017 11 21 18 38 29 223253 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 0 2017 11 21 18 38 29 223284 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 1 2017 11 21 18 38 29 223291 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job worker replica 0 task 1 2017 11 21 18 38 39 223379 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 0 2017 11 21 18 38 39 224059 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job ps replica 0 task 1 2017 11 21 18 38 39 224068 I tensorflow core distributed runtime master cc 221 CreateSession still waiting for response from worker job worker replica 0 task 1,,,2017-11-21 10:39:41,2017-11-21 11:45:04
PR,change bazel mirror to mirror bazel,grep v bazel mirror do you mean to not use mirror to download mirror links in workspace bzl is marked as mirror bazel not bazel mirror after this change the download speed enhanced,,,2017-11-21 08:32:26,2017-11-21 12:53:24
IS,Hi,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-21 12:42:01,2017-11-21 14:12:35
IS,tf TensorShape concatenation converts shape information to values,Tensorflow 1 4 0 Example code Is it intended that this works and produces the output where the shape information gets converted into actual values,,"mrry,mrry,mrry",2017-11-21 14:47:25,2017-11-21 15:11:09
IS,Tensorflow Python,Hi This is my code for tensorflow serve python client,,shivaniag,2017-11-16 20:40:19,2017-11-21 15:41:43
IS,tensorflow lite how to set input shapes param with batchsize when gen the pb lite file,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below lastest master Python version 2 7 Describe the problem my python train script input tensor define as below tf placeholder dtype tf float32 shape None 440 name conf input features tensor when i execute bazel run config opt tensorflow contrib lite toco toco others input shapes None 440 an error show as below 2017 11 17 17 00 10 285456 F tensorflow contrib lite toco model cmdline flags cc 269 Check failed absl SimpleAtoi dim str size Failed to parse input shape None 440 how i can set input batch size thx,,shivaniag,2017-11-17 09:02:36,2017-11-21 15:46:35
IS,Downgrade to Bazel 0 4 2 for Tensorflow r1 0,Hello I need to checkout to Tensorflow r1 0 and as suggested the Bazel version should be 0 4 2 I have already installed Bazel and after upgrade bazel version is 0 7 0 Do you know the steps so I can downgrade to Bazel 0 4 2 I have tried with apt get install bazel 0 4 2 but this does not work and I have also tried to uninstall by executing the command rm fr bazel bazelrc and deleting relevant data in cache bazel folder but this did not also work Any suggestions Thank you in advance,,shivaniag,2017-11-21 12:52:55,2017-11-21 18:09:18
IS,,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-21 18:09:23,2017-11-21 18:10:07
PR,Fixed typo in usage docstring,Changed tf SyncReplicasOptimizer to tf train SyncReplicasOptimizer in usage example,,yifeif,2017-11-21 18:43:41,2017-11-21 18:48:58
PR,Revert Fixed typo in usage docstring,Reverts tensorflow tensorflow 14765 Sorry did not realize this was sent to r1 2 please fix the issue in master Thanks,,yifeif,2017-11-21 19:15:27,2017-11-21 19:17:25
PR,remove duplicated code,I'm remove duplicated code and to avoid missing when adding new error code,,"horance-liu,jhseu,skye,horance-liu,jhseu",2017-11-09 09:34:31,2017-11-21 19:19:10
PR,Use the known fixed size of the tensor array instead of the dynamic one,For compatibility with XLA The tensorarray size operator produces graphs which are not caompatible with XLA The size of the tensor array is known explicitly so by using that size we can avoid the incompatibility The other examples of stack used in this file are not the same and do not need adjusting,,"DavidNorman,ebrevdo,DavidNorman,jhseu,DavidNorman,jhseu,ebrevdo",2017-11-17 11:26:19,2017-11-21 19:20:34
PR,fix tf contrib slim nets vgg will not work,init py of slim module do not import nets module so tf contrib slim nets vgg will not work change to this another way of correcting this is change init py but change documentation is the easy way,,,2017-11-21 13:59:33,2017-11-21 20:03:18
PR,Only install enum34 on Python 3 4 versions,Python 3 6 sometimes has issues with enum34 because the standard library relies on enum features not in enum34 see for more details cc,,"alanhdu,gunan,alanhdu,alanhdu,yifeif,yifeif,alanhdu,yifeif,gunan",2017-11-20 16:39:32,2017-11-21 22:30:30
IS,tf contrib ffmpeg decode audio console flood,When we evaluate the tensor returned by tensorflow contrib ffmpeg decode audio the ffmpeg log shows up in the terminal leading to a flood of messages when decoding a large number of files Asked here as well I could not find an easy way such as an environment variable for ffmpeg to turn off the output log there is only a command line argument loglevel but TF is decode audio does not support it Currently using ffmpeg 3 4 gcc 7 2 0 and tensorflow 1 4 0 on linux Issue filed as instructed here issuecomment 345836714,,yongtang,2017-11-20 22:36:59,2017-11-21 22:45:30
PR,Fixed typo in usage docstring,Changed tf SyncReplicasOptimizer to tf train SyncReplicasOptimizer,,,2017-11-21 19:24:40,2017-11-21 22:56:23
PR,Have tf nightly depend on tb nightly,TensorBoard now has an automated nightly release process,,"jart,gunan,jart,gunan,jart,gunan,yifeif,jart,jart,jart",2017-11-21 03:40:36,2017-11-22 01:03:51
IS,Bug tf contrib layers layer norm third party implementation does not reflect the original paper,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory Titan X Exact command to reproduce Describe the problem In the original layer normalization paper it is been said that beta gamma should have the same dimension as hidden variable see the lines below Eq 4 in Page 3 Based on current implementation there is no such option that reflects the original paper Please run the following source code to verify that Also see the comment 3671 Source code logs import tensorflow as tf layer norm tf contrib layers layer norm batch size 10 hidden dim 5 input tf zeros batch size hidden dim dtype tf float32 output layer norm input tf trainable variables,,"rohan100jain,xodus7,xodus7,xodus7,xodus7,xodus7",2017-11-14 20:38:10,2017-11-22 02:07:42
IS,ImageUtils convertYUV420SPToARGB8888 resulting distorted image,Hi I did some modification in TF detect android app to detect person from loaded picture rather than clicking it by camera Not using cameraActivity Everything is working fine except the function named ImageUtils convertYUV420SPToARGB8888 This function returns distorted image please find attachment actual image actual image After converting image from YUV 4 2 0 to ARGB converted image Sharing part of code below newbitmap Bitmap createScaledBitmap bitmap 640 480 false ByteArrayOutputStream output new ByteArrayOutputStream newbitmap compress Bitmap CompressFormat JPEG 100 output imgbytes output toByteArray imageConverter new Runnable public void run ImageUtils convertYUV420SPToARGB8888 imgbytes previewWidth previewHeight rgbBytes,,,2017-11-20 12:28:02,2017-11-22 04:19:55
IS,v2 to v1,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-11-22 03:46:04,2017-11-22 04:50:39
PR,Add str Label to bazel macros,When using tensorflow as a submodule in bazel importing bazel rules from tensorflow bzl is not working The main reason is that some of the dependencies are hard coded instead of using str Label and this makes bazel to generate dependencies like tensorflow instead of tensorflow Most of bzl files under tensorflow use Label mechanism to allow supermodule to import tensorflow bazel rules like tf cc test etc but there were two files that did not use the Label mechanism and these two files block supermodule to import tensorflow bazel rules This change updates those files to unblock bazel rule importing,,,2017-11-21 01:14:45,2017-11-22 04:52:11
PR,Fixing download dependencies sh bugs for generating TFLite iOS exmaples,This is the 2nd try for 14631 To verify this git clean fdx to clean all local files run tensorflow contrib lite download dependencies sh Verify that you see download dependencies sh completed successfully so the script is completed Verify these files are downloaded to correct location tensorflow contrib lite examples ios camera data labels txt tensorflow contrib lite examples ios camera data mobilenet quant v1 224 tflite tensorflow contrib lite examples ios simple data labels txt tensorflow contrib lite examples ios simple data mobilenet v1 1 0 224 tflite Run tensorflow contrib lite build ios universal lib sh to verify the library can be built,,"miaout17,miaout17",2017-11-20 23:28:17,2017-11-22 04:53:59
PR,CMake Do not build tests for RE2,Issue 14691 shows a build error on Windows in the RE2 tests Since we do not run these tests and they seem to be causing problems on some platforms do not build them as part of the TensorFlow build,,mrry,2017-11-18 23:16:53,2017-11-22 04:55:22
PR,fix misspellings,Fixed some typos,,chris-chris,2017-11-19 10:35:37,2017-11-22 04:56:38
PR,Fix docstring of variable scope,Add missing to docstring,,qmick,2017-11-20 03:54:30,2017-11-22 04:57:24
PR,Add str Label to bazel macros,This is a similar pull request to but for r1 4 branch not master When using tensorflow as a submodule in bazel importing bazel rules from tensorflow bzl is not working The main reason is that some of the dependencies are hard coded instead of using str Label and this makes bazel to generate dependencies like tensorflow instead of tensorflow Most of bzl files under tensorflow use Label mechanism to allow supermodule to import tensorflow bazel rules like tf cc test etc but there were two files that did not use the Label mechanism and these two files block supermodule to import tensorflow bazel rules This change updates those files to unblock bazel rule importing,,gunan,2017-11-21 01:23:04,2017-11-22 05:43:59
PR,Add back whitespace,When tfcompile flags was changed so it could be not just a string but also a list of strings the initial white space was erroneously removed probably a misunderstanding of str join meaning out object would consume the first flag E g this would no longer work,,"carlthome,carlthome,gunan",2017-11-20 13:12:25,2017-11-22 05:44:28
IS,Android Failed to resolve org tensorflow tensorflow lite,Hi I am trying to run tensorflow lite application on my android device I get the following error when syncing gradle project Failed to resolve org tensorflow tensorflow lite Any clues on why this is happening My system information is OS Windows 7 64 bit Android Studio 3 0 1 Android SDK Platform tools 26 0 2 Android SDK Tools 26 1 1 Thanks in advance,,,2017-11-22 05:48:28,2017-11-22 05:57:16
PR,Update docs for using Docker with GPU with nvidia docker2,Update docs to reflect the current version of nvidia docker version 2 For reference,,"gunan,gunan,gunan,flx42",2017-11-20 10:25:02,2017-11-22 07:04:24
PR,Change ndimage imread to imageio imread,Scipy will not support imread from 1 0 0 as its document says Change to imageio imread and add its correspond exception,,yifeif,2017-11-20 07:17:27,2017-11-22 07:13:19
IS,Using GPU mnist deep py throws OOM when allocating tensor with shape,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I am using the mnist deep py with tensorflow 1 4 0 OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 Tensorflow 1 4 0 binary installation Linux Ubuntu 16 04 Tensorflow 1 4 0 built form source TensorFlow installed from source or binary Windows 10 installed with TF binary Linux Ubuntu 16 04 TF built from source TensorFlow version use command below 1 4 0 Python version 3 6 2 on Windows 10 3 5 2 on Linux Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version CUDA 8 0 CuDNN 6 0 GPU model and memory For Windows 10 NVIDIA GeForce 940MX For Linux HW similar to NVIDIA Jetson TX2 Exact command to reproduce python mnist deep py Describe the problem The mnist deep py sample given in Tensorflow examples tutorials works fine when run on CPU But when the same example is run using GPU an OOM occurs when trying to allocate memory for tensor specifically 10000 in both the cases It does not matter if one increases decreases the number of iterations to train the model the OOM occurs even after a single iteration is executed The other examples like mnist py mnist softmax py mnist softmax xla py etc runs properly without any issues on the GPU I have also tried to use the config proto options but none of them seem to help Source code logs Windows 10 tensor name edge 75 Mean 1 tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0 Caused by op 'conv1 Conv2D' defined at File mnist deep py line 176 in module tf app run main main argv sys argv 0 unparsed File C Program Files Python36 lib site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File mnist deep py line 137 in main y conv keep prob deepnn x File mnist deep py line 63 in deepnn h conv1 tf nn relu conv2d x image W conv1 b conv1 File mnist deep py line 105 in conv2d return tf nn conv2d x W strides 1 1 1 1 padding 'SAME' File C Program Files Python36 lib site packages tensorflow python ops gen nn ops py line 630 in conv2d data format data format name name File C Program Files Python36 lib site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 2956 in create op op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 10000 32 28 28 Node conv1 Conv2D Conv2D T DT FLOAT data format NHWC padding SAME strides 1 1 1 1 use cudnn on gpu true device job localhost replica 0 task 0 device GPU 0 reshape Reshape conv1 Variable read Node Mean 1 7 Recv client terminated false recv device job localhost replica 0 task 0 device CPU 0 send device job localhost replica 0 task 0 device GPU 0 send device incarnation 1 tensor name edge 75 Mean 1 tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0 Linux tensor name edge 75 Mean 1 tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0 Caused by op 'conv1 Conv2D' defined at File mnist deep py line 176 in module tf app run main main argv sys argv 0 unparsed File C Program Files Python36 lib site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File mnist deep py line 137 in main y conv keep prob deepnn x File mnist deep py line 63 in deepnn h conv1 tf nn relu conv2d x image W conv1 b conv1 File mnist deep py line 105 in conv2d return tf nn conv2d x W strides 1 1 1 1 padding 'SAME' File C Program Files Python36 lib site packages tensorflow python ops gen nn ops py line 630 in conv2d data format data format name name File C Program Files Python36 lib site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 2956 in create op op def op def File C Program Files Python36 lib site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 10000 32 28 28 Node conv1 Conv2D Conv2D T DT FLOAT data format NHWC padding SAME strides 1 1 1 1 use cudnn on gpu true device job localhost replica 0 task 0 device GPU 0 reshape Reshape conv1 Variable read Node Mean 1 7 Recv client terminated false recv device job localhost replica 0 task 0 device CPU 0 send device job localhost replica 0 task 0 device GPU 0 send device incarnation 1 tensor name edge 75 Mean 1 tensor type DT FLOAT device job localhost replica 0 task 0 device CPU 0 Further detailed logs can be attached if needed Your help and pointers to solve this will be much appreciated,,"qmick,qmick,qmick",2017-11-20 14:02:11,2017-11-22 08:14:13
IS,Error Too many value to unpack during export savedmodel in tensorflow,TensorFlow 1 4 0 sendingcurrency tf feature column categorical column with vocabulary list isendincurrency' vocabulary list 'AUD' 'EUR' 'GBP' 'USD' recievercurrency tf feature column categorical column with vocabulary list arecievercurrency' vocabulary list 'AUD' 'EUR' 'GBP' 'INR' 'NZD' 'USD' 'XCD' 'XOF' CBRate tf feature column numeric column CBRate dtype tf float32 linear features sendingcurrency recievercurrency CBRate regressor tf contrib learn LinearRegressor feature columns linear features config tf contrib learn RunConfig model dir tmp akhil feature spec tf feature column make parse example spec linear features export input fn tf estimator export build parsing serving input receiver fn feature spec model export savedmodel tmp akhil serving input fn export input fn,,,2017-11-22 13:49:58,2017-11-22 15:42:23
IS,XLA AOT tfcompile failure due to undeclared inclusions in cc binary rule,This happens on a freshly cloned TensorFlow master with Bazel 0 7 on Ubuntu 17 04 I'm not comfortable with Bazel yet but building worked fine with earlier TensorFlow versions Stuff started to become wonky somewhere around when was introduced throughout tfcompile bzl I think,,"carlthome,carlthome",2017-11-22 14:45:08,2017-11-22 15:42:51
IS,Unable to install Tensorflow on Ubuntu Anaconda error trace,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 5 4 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce You can collect some of this information using our environment capture script Describe the problem I am installing the latest version of tensorflow 1 4 0 and I am getting an error when I try to install it inside a conda environment conda create n py36 tensorflow python 3 6 source activate py36 tensorflow pip install ignore installed upgrade the above are the commands I ran and below is the error trace I am getting Source code logs Logs ubuntuvm ubuntuvm conda create n py36 tensorflow python 3 6 Fetching package metadata Solving package specifications Package plan for installation in environment home ubuntuvm anaconda3 envs py36 tensorflow The following NEW packages will be INSTALLED ca certificates 2017 08 26 h1d4fec5 0 certifi 2017 7 27 1 py36h8b7b77e 0 libedit 3 1 heed3624 0 libffi 3 2 1 hd88cf55 4 libgcc ng 7 2 0 h7cc24e2 2 libstdcxx ng 7 2 0 h7a57d05 2 ncurses 6 0 h9df7e31 2 openssl 1 0 2m h26d622b 1 pip 9 0 1 py36h6c6f9ce 4 python 3 6 3 h1284df2 4 readline 7 0 ha6073c6 4 setuptools 36 5 0 py36he42e2e1 0 sqlite 3 20 1 hb898158 2 tk 8 6 7 hc745277 3 wheel 0 29 0 py36he7f4e38 1 xz 5 2 3 h55aa19d 2 zlib 1 2 11 ha838bed 2 Proceed y n y,,"gunan,gunan",2017-11-17 11:44:24,2017-11-22 16:29:15
PR,Fix nccl BUILD on Windows,Bazel does not allow a random file name in linkopts attribute so use DEFAULTLIB option to specify ws2 32 lib,,meteorcloudy,2017-11-22 10:29:53,2017-11-22 17:46:51
PR,Fixes to windows builds,Disable failing data utils test in cmake and bazel builds Disable session partial run test in bazel build It is already not running under cmake build Increase cmake build log verbosity as we still canot see the root cause of failures,,"gunan,gunan",2017-11-22 18:48:34,2017-11-22 19:36:30
IS,bazel 0 5 4 says ERROR infinite symlink expansion detected,Hi I just tried to update my build script that worked perfectly fine on 1 2 1 and 1 3 0 and it fails with a not understandable error Everything is exactly the same build is done in a clean ephemeral environment The only difference is that I updated bazel to 0 5 4 per TF configure script request,,,2017-11-21 22:20:43,2017-11-22 20:05:20
PR,Remove useless statements in Dockerfiles,'CMD bin bash ' is not useful since it is already provided by the base ubuntu image 'RUN bin bash ' looks like a typo and just creates an extra empty layer Signed off by Felix Abecassis fabecassis nvidia com,,"flx42,flx42",2017-11-22 20:16:26,2017-11-22 20:22:46
PR,Also ignore no oss tags in windows builds,,,gunan,2017-11-22 20:35:12,2017-11-22 20:45:39
PR,execute command properly in bash exe on windows,On windows using bazel,,,2017-11-21 07:54:52,2017-11-22 20:46:40
PR,Update Custom Op instructions to use tf sysconfg flags,,,"alsrgv,jhseu,alsrgv,alsrgv",2017-11-07 01:20:17,2017-11-22 20:58:14
PR,Branch 176676125,,,"yifeif,yifeif",2017-11-22 19:38:34,2017-11-22 22:49:05
PR,Branch 176709725,,,yifeif,2017-11-23 00:37:48,2017-11-23 04:35:18
PR,make the link be more perfect,,,,2017-11-23 04:34:48,2017-11-23 04:35:51
IS,compile grpc fail to download something from china,Is there anyone give me advice on solving the problem and give some other https to download,,,2017-11-22 07:34:01,2017-11-23 06:09:17
IS,third party eigen3 unsupported Eigen CXX11,when testing tensorflow dll in vs2015 but vs2015 can not recongnize third party eigen3 unsupported Eigen CXX11 Tensor I succeeded in compiling tf1 4 on windows 10 vs2015 cuda8 0 cudnn5 1 tensorflow lib and tensorflow dll are there the error log E tensorflow2 third party eigen3 unsupported Eigen CXX11 Tensor 1 fatal error C1014 1024 My win32 console program does nothing only include some files src code as follow include memory include string include vector include tensorflow core framework tensor h include tensorflow core framework graph pb h include tensorflow core public session h,,,2017-11-23 06:38:42,2017-11-23 08:04:04
IS,How to use tf nn dropout to implement embedding dropout,Recent papers in language modeling use a specific form of embedding dropout that was proposed in this paper The paper also proposed variational recurrent dropout which was discussed already in this issue In embedding dropout the same dropout mask is used at each timestep and entire words are dropped i e the whole word vector of a word is set to zero This behavior can be achieved by providing a noise shape to tf nn dropout In addition the same words are dropped throughout a sequence Since we repeat the same mask at each time step we drop the same words throughout the sequence i e we drop word types at random rather than word tokens as an example the sentence the dog and the cat might become dog and cat or the and the cat but never dog and the cat I could not find a way to implement this functionality of embedding dropout efficiently Are there any plans to incorporate these advances,,,2017-11-21 08:01:09,2017-11-23 11:54:12
PR,PrefetchDataset with buffer size 0 results in deadlock,Hey I experimented with tf data Dataset prefetch and found that an assert inside the code is missing When buffer size is zero I got a deadlock Here is a toy example to reproduce my bug,,"boeddeker,mrry,facaiy,mrry,facaiy,mrry,facaiy,boeddeker,facaiy,boeddeker,boeddeker,facaiy,boeddeker,facaiy,boeddeker",2017-11-10 13:05:48,2017-11-23 12:52:52
IS,Feature request adding spectral functions for preserving phase information,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes attempting to OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 0 Python version 3 5 4 Bazel version if compiling from source N A CUDA cuDNN version CUDA v8 0 60 cuDNN 6 0 GPU model and memory GTX 1060 6 GB Exact command to reproduce N A Describe the problem I am working on a data processing pipeline directly in my tensorflow graph In that case I would like to use continuous wavelet transforms CWT in order to transform time series data into scalograms instead of spectrograms in order to increase time frequency resolution I can only find a single API for performing the CWT that is compatible directly with TF but unfortunately it is not 'enough' since the tf conv2 operator does not work with inputs of different types real complex I therefore am trying to fix my own op using TF is standard ops but have hit a snag The spectral ops rfft and irfft only return and accept positive frequency components and for my purpose I would have to apply phase transformations of the spectrum resulting in non Hermitian symmetry in which case I cannot use the tf spectral irfft to inverse transform So what I request are spectral ops that return and accept the full complex spectra of input signals Source code logs N A,,"rryan,rryan,rryan",2017-10-25 18:30:17,2017-11-23 16:41:09
PR,1,ERROR PR,,,2017-11-23 02:37:02,2017-11-23 20:06:01
PR,TFLite Add unsupported op Equal and ExpandDims,,,,2017-11-22 15:30:59,2017-11-24 03:01:01
PR,TFLite Add unsupported op Equal and ExpandDims,,,,2017-11-24 03:01:09,2017-11-24 08:31:31
PR,change bazel mirror to mirror bazel,grep v bazel mirror do you mean to not use mirror to download mirror links in workspace bzl is marked as mirror bazel not bazel mirror after this change the download speed enhanced i already signed as contributor,,"jart,yifeif,jart,jart,jart,jart,jart,yifeif,jart,jart",2017-11-21 12:54:20,2017-11-24 12:52:58
PR,change bazel mirror to mirror bazel,thank to for letting me know how to do pull req,,,2017-11-24 13:03:29,2017-11-24 13:05:11
IS,how to make shear transform in tensorflow like tensorflow image random flip left right image,in keras you can make shear transform by random shear in keras preprocessing image but how to make shear transform in tensorflow what I want is something like tensorflow image random flip left right image in tensorflow it will be done by tf contrib image transform,,,2017-11-23 08:51:41,2017-11-24 13:09:14
PR,change bazel mirror to mirror bazel,this time i added email,,,2017-11-24 13:22:19,2017-11-24 13:31:49
IS,input dims not a constant expression in slice op cc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Debian 9 0 with a Gentoo Prefix TensorFlow installed from source or binary source TensorFlow version use command below c81acfb025abe417d80ffa677edfe2dd1bcda58e 15 hours old Python version 3 6 3 Bazel version if compiling from source 0 6 1 GCC Compiler version if compiling from source 6 4 0 CUDA cuDNN version no CUDA GPU model and memory no GPU Exact command to reproduce bazel build config mkl config opt tensorflow tools pip package build pip package Describe the problem It seems that 8011eda4b7 merged a C error in file tensorflow core kernels slice op cc line 255 L255 As seen line 232 L232 input dims is a constant const but is not a constant expression constexpr thus it should not be used as a template parameter Source code logs,,,2017-11-07 17:00:57,2017-11-24 13:48:31
PR,fix overpadding in MixtureSameFamily,This fixes pad mix dims when mixture distribution does not have scalar batch size previous version would add too many dimensions,,,2017-11-24 20:03:42,2017-11-24 20:30:41
IS,android library not loading saved model due to invalid graphdef error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 x TensorFlow installed from source or binary Using VirtualEnv as described on website TensorFlow version use command below 1 4 also tried 1 0 and 1 2 Python version 2 7 1 2 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce I have a bug where a frozen model will not load in an android app The code is at In ChatActivity on line 39 I load an model that is trivial and built by running cd nn python train noop py epochs 5 save words freeze That loads thus showing the Android app is setup correctly for loading models On line 40 I load a model that I got from your tensorflow demo That also loads showing that complex models can be loaded On line 41 I load the model that I actually want to load and that fails with the error invalid GraphDef That model is build by running 'cd nn python train py epochs 5 save words freeze Why is that not loading It loads under python on ubuntu and can generate samples The bug is repoducable by running the app after syncing you do not need to run the training,,,2017-11-20 07:03:37,2017-11-25 23:41:11
IS,AUC result of tf metrics auc doesnot match with sklearn is,My tensorflow version is 'v1 3 0 rc1 4263 gc81acfb' '1 4 0 rc1' and the system is Rehat with gcc version 4 8 5 20150623 Red Hat 4 8 5 16 I run the program use CPU only I wrote a NN use tensorflow for binary classification I create the an auc op in the following way Are there anything wrong in the way I use tf metrics auc When I run the auc op it returns a tuple with two values and I do not which one is the correct auc But both of them are not equal with sklearn is I once wrote an program to calculate auc and it was exactly the same with sklearn is even in 1M data thus I tend to think sklearn is result is the ground truth,,"facaiy,facaiy",2017-11-23 12:16:19,2017-11-26 02:18:37
IS,What if we do not install tensorflow under a new environment,How come we need to install tensorflow as a separate environment If we do it this way many common libraries are not available when tensorflow is activated image Most of the common libraries such as matplotlib panda etc are not within tensorflow environment So we have to install again to use them image So why not just install under root so we do not have to re install all those libraries under the new environment Thanks,,"facaiy,facaiy",2017-11-25 20:14:15,2017-11-26 05:28:15
IS,How to get the preivous batch after running Iteration get next in tensorflow,This problem is in the stackoverflow I hope someone to help me to solve it Thanks,,,2017-11-25 13:03:36,2017-11-26 14:07:59
IS,Computation of Mean IoU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary Source TensorFlow version use command below r1 2 Python version 3 5 Describe the problem I believe that the calculation of the IoU metric in tf metrics mean iou is incorrect Consider an image which can have 3 classes sky road building In one image there is no building and everything has been perfectly classified as either sky or road so the tp fn fp for buildings is zero To avoid divisions by zero in the IoU calculation tp tp fn fp the current implementation sets the denominator to 1 This causes a result of 0 because tp 0 and we are computing 0 0 1 Both the sky and road class get a score of 1 so the overall image gets a mean iou score of 2 3 even though every single pixel was correctly classified I propose to change the metric so that when the denominator is 0 the result is 1 I can send a pull request if this is needed Source code logs Complete example as a unit test class TestMetrics tf test TestCase def get data self label int64 tf constant 0 1 2 2 1 0 2 1 0 0 1 2 2 2 2 2 2 2 1 1 1 1 1 1 dtype tf int64 predicted perfect int64 tf constant 1 1 2 2 1 2 2 1 9 3 1 2 2 2 2 2 2 2 1 1 1 1 1 1 dtype tf int64 return label int64 predicted perfect int64 def test iou metric self with self test session l p self get data num classes 9 weights tf cast tf not equal l 0 tf int32 iou update op tf metrics mean iou l 1 p 1 num classes weights weights tf global variables initializer run tf local variables initializer run update op eval self assertAlmostEqual iou eval 1 Currently this test fails with 0 222 is not equal to 1,,reedwm,2017-08-15 12:43:05,2017-11-26 16:38:53
IS,how to build tensorflow lite into a static c library using android ndk,I want to write some c test binary using tensorflow lite from the README md I can only see how to build the demo app Could you please tell me how to build tensorflow lite into a static library using android ndk,,shivaniag,2017-11-18 09:16:11,2017-11-27 01:19:37
PR,fix typos,intialized initialized,,ManHyuk,2017-11-27 05:34:46,2017-11-27 08:30:07
IS,Feature request Tensorflow lite on memory constrained bare metal systems,I'm interested in running Tensorflow Lite on devices with limited memory resources and possibly no operating systems abstractions available This means removing any dependencies on file systems threads synchronization primitives etc and keeping the binary size as small as possible I do not know if you discuss your roadmap openly here but I'm wondering whether this is something that is planned for TFLite If not I may go ahead and try to implement this myself,,"carlthome,rongjiecomputer",2017-11-23 10:11:35,2017-11-27 08:51:53
PR,Create new file,,,,2017-11-27 11:07:47,2017-11-27 14:37:54
PR,Branch 176796142,,,caisq,2017-11-24 01:04:23,2017-11-27 15:12:05
IS,tensorflow terminate called after throwing an instance of istd system error',Hi I am training a resNet50 with tensorflow using a shared server with these properties ubuntu 16 04 3 gtx 1080 gpus tensorflow 1 3 python 2 7 CUDA 8 0 4 CUDNN 6 but always after two epochs and during the third epoch I encounter this error terminate called after throwing an instance of istd system error' what Resource temporarily unavailable Aborted core dumped with adding some print in my code I have found where is the problem this is convert tfrecord to dataset filenames balanced t tfrecords dataset tf contrib data TFRecordDataset filenames def parser record keys to features label tf FixedLenFeature tf string default value mhot label raw tf FixedLenFeature tf string default value mel spec raw tf FixedLenFeature tf string default value parsed tf parse single example record keys to features mel spec1d tf decode raw parsed 'mel spec raw' tf float64 label tf cast parsed label tf string mhot label tf decode raw parsed 'mhot label raw' tf float64 mel spec tf reshape mel spec1d 96 64 aa mel spec return mel data mel spec mhot label dataset dataset map parser dataset dataset batch batch size dataset dataset repeat 3 iterator dataset make one shot iterator and this is my input pipline while True try features labels sess run iterator get next except tf errors OutOfRangeError print end of training dataset due to my prints output the error is for this line features labels sess run iterator get next but I dont see any problem can you help me now reproduce replace any tfrecord with mine,,mrry,2017-11-26 04:58:59,2017-11-27 16:10:44
IS,segmentation fault due to pytorch and tensorflow conflictions,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 8 jessie TensorFlow installed from source or binary from Anaconda with command pip install ignore installed upgrade TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 4 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version cuda 8 0 GPU model and memory TITAN Xp 12G Exact command to reproduce This fails has no problem Also Importing tensorflow before torch seems fine as well However if I import pytorch before tensorflow it fails and reported a segmentation error as shown above,,"allenlavoie,shivaniag",2017-11-22 22:10:45,2017-11-27 16:42:37
IS,Feature request Control order of 'feature column input layer',On master 80e7c9f45c It seems that the mapping of features to columns in dense the input matrix is always sorted by the alphabetical order of the feature names It would be nice is this was customizable perhaps by respecting the order of the feature columns in the second argument to input layer Mainly useful for debugging and introspecting the network to know which columns correspond to which features eg I also tried giving the features as an OrderedDict but input layer does not seem to care about the ordering in that situation either,,"facaiy,ispirmustafa,facaiy,ispirmustafa,ispirmustafa,facaiy",2017-11-21 19:28:10,2017-11-27 17:23:12
IS,how to extract parameters of sim batch norm,using slim batch norm for normalize and here are the batch norm params image in this way i think all the trainable variables beta gamma moving mean moving variance was stored and when i print elements in tf trainable variables here is the result image missing gamma i extracted the output tensor of the first layer and manually calculate correspond feature map through these parameters its not the same but can be transformed into the same through linear transformation so i'm sure there is something wrong with batch norm params where can i find the correct ones,,shivaniag,2017-11-23 08:06:02,2017-11-27 18:48:58
IS,TypeError call got an unexpected keyword argument 'input c',I am using tensorflow contrib cudnn rnn python ops cudnn rnn ops CudnnGRU as cudnn cell But when I call cudnn cell as follows hiddens output h output c cudnn cell inputs input h init state input c init state params cudnn params is training True an error occurs saying that input c was an unexpected keyword But I have checked the source code and I'am certain that there is a keyword argument 'input c',,"facaiy,shivaniag",2017-11-22 13:04:04,2017-11-27 19:28:53
PR,Added Ubuntu 16 04 Dockerfile with TF 1 4 optimized for CPU with Inte,l R MKL This is an Ubuntu 16 04 Container running Tensorflow 1 4 with Intel MKL To test on a system with Docker installed do this as root Build the container Needs to be done only once takes about 20 minutes This will bind a directory in the container at host to root on the host machine Run your tests and benchmarks,,"claynerobison,claynerobison,claynerobison,claynerobison,claynerobison,claynerobison,gunan,gunan,gunan,gunan,gunan,claynerobison,claynerobison,claynerobison,gunan,claynerobison,claynerobison,claynerobison,gunan,gunan,claynerobison,gunan,claynerobison,gunan",2017-11-10 22:02:02,2017-11-27 21:08:17
PR,TFLite get closer to build with Bazel on Windows,Bazel cannot yet build TensorFlow Lite on Windows but this commit gets us closer In this commit make the Wno implicit fallthrough compiler flag in flatbuffers' BUILD file be conditional to non Windows builds because MSVC does not know this flag fix the Bazel build command in README md by removing single quotes around cxxflags because it is not needed on Bash and is harmful on Windows because cmd exe does not remove the single quotes fix non ASCII quotes and apostrophes as well as some formatting issues in README md See,,"laszlocsomor,laszlocsomor,meteorcloudy,gunan,laszlocsomor,gunan,laszlocsomor,gunan",2017-11-22 10:57:01,2017-11-27 22:40:31
PR,Branch 176732156,,,"sb2nov,sb2nov,sb2nov",2017-11-27 20:06:44,2017-11-28 00:36:37
PR,Branch 176791620,,,"sb2nov,sb2nov",2017-11-27 19:31:23,2017-11-28 00:36:53
IS,Go SIGABRT when running go test using tensorflow 1 4 compiled form source,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Archlinux TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version 3 6 Bazel version if compiling from source Build label 0 7 0 non git GCC Compiler version if compiling from source gcc 6 CUDA cuDNN version CUDA 9 cuDNN 7 GPU model and memory Dual Nvidia 1080 Ti Exact command to reproduce,,asimshankar,2017-11-14 12:25:24,2017-11-28 01:22:07
IS,tensorboard ImportError cannot import name 'run main',I install the tensorflow on Mac from source but when I run the tensorboard and got a error like this Pro 2 Desktop xxh tensorboard Traceback most recent call last File Users xxh anaconda3 bin tensorboard line 7 in module from tensorboard main import run main ImportError cannot import name 'run main' How to fix it,,tatatodd,2017-11-24 06:06:31,2017-11-28 02:05:15
IS,A bug in tensorflow r1 4 when applying MultiRNNCell,System information TensorFlow installed from source TensorFlow version r1 4 Python version 3 5 4 Bazel version 0 5 4 GCC Compiler version 5 4 0 CUDA cuDNN version 9 0 5 0 GPU model and memory GeForce GTX 1080 Describe the problem when applying the MultiRNNCell as below an error occurs The code went well in tensorflow r1 3 Source code input list is a list of tensor with shape None 8 n hidden 32 lstm tf nn rnn cell BasicLSTMCell n hidden stacked lstm tf nn rnn cell MultiRNNCell lstm 2 outputs states tf nn static rnn stacked lstm input list dtype tf float32 error ValueError Dimensions must be equal but are 64 and 40 for 'rnn rnn multi rnn cell cell 0 cell 0 basic lstm cell MatMul 1' op 'MatMul' with input shapes 64 40 128 However when only applying one single lstm i works well opinions when calculating the basiclstmcell will be called where a class named Linear will be initialized as an example in my case the variable self weight in this class will be initialized as 40 128 32 8 32 4 code from rnn cell impl py if self linear is None self linear Linear inputs h 4 self num units True But when MultiRNNCell is the case for example a 2 layers lstm in the second layer the weight should be 64 128 'h' in last layer 32 'o' in last layer 32 Disappointingly the weight will only be initialized once and stay with the shape 40 128 due to the sentence if self linear is None So that the reason why such error occurs i try to comment out this sentence but since share variable mechanism is related it dose not work and induces other problem ValueError Trying to share variable rnn multi rnn cell cell 0 basic lstm cell kernel but specified shape 64 128 and found shape 40 128 Any idea how to solve this problem efficiently,,,2017-11-27 03:16:15,2017-11-28 02:45:31
IS,Non deterministic result using a pre trained word embedding in TensorFlow,I use pre trained word embedding to initialize embedding in tensorflow but got a non deterministic result However if I fix the seed and use random initialization the result is almost the same What is the problem here Thanks The code is here init embedding is the pre trained word embedding,,tatatodd,2017-11-27 07:52:04,2017-11-28 02:46:48
IS,Functionality Available Dataset Input perform slicing along time axis,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary from pip TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 1 GPU model and memory k2200 Exact command to reproduce Describe the problem Currently as many suggested when we want to train LSTM to predict the values of next time step we would better slice all the samples along time axis to tuples of lookback numbers of values target predicted values as x y then store all these in a variable in RAM or as data file in disk Then we build dataset to point to either form However this method makes LSTM stateless Currently our scheme to stateful LSTM is as follows for an input signal 1 2 3 4 5 6 9 10 11 we initialize LSTM and set state to 0 feed 1 2 3 4 to train tf nn dynamic rnn then feed 2 3 4 5 8 9 10 11 until end of this sequence In this batch we have a number Batch size like 32 of signals like this and they will be processed in parallel in GPU by TF In the next batch of new signal samples we reset LSTM with initial state being 0 And then repeat this process In this way we think that given 8 9 10 to the model to predict next value as 11 it is helpful for the model to choose whether to utilize the information of its current state whether it is at beginning of a series of signal zero initial or it is at middle of a signal sequence Currently before version 1 4 we built two generators one batch generator is to generate a batch of signals The other time slicer is to generate x y shape of batch size max time step number of features along time axis by using the data yield by the batch generator In version 1 4 we find Dataset Estimator and Experiment pipeline powerful Is there a way to implement the same idea using such pipeline Thanks,,"mrry,mrry",2017-11-27 08:49:04,2017-11-28 02:48:36
IS,Crossentropy loss function with weights by sample and by category and outcome,In my loss function I would like to weight each sample differently and in each sample each category should be weighted differently as well depending on the outcome Meaning if in a cross entropy the one hot is correctly specified a different weight needs to be applied than when the output is incorrect So I would need two weights per category A tensor with rank 3 One dimension for the samples a second dimension for the amount of classes and a third dimension that differentiates between correct and incorrect match I have seen that with sparse softmax cross entropy it is possible to pass in a weight that serves as a coefficient for positive examples This is a good start but I would need to pass in a tensor instead to treat each sample differently weighted cross entropy with logits seems to work in a very similar way but does not offer that functionality Is this a feature that could be added,,tatatodd,2017-11-27 11:31:51,2017-11-28 02:49:56
IS,Very different CPU usage allocation behavior when using slightly different CPUs,I am running the same exact model on two largely similar systems let is call them system A and B However TF is behavior is very different On system A CPU utilization is around 60 on a 12 core system while on system B CPU utilization is only around 8 Moreover on system A the same model runs about 10x slower than system B even though it is using far fewer CPU resources The systems are similar in that they are both running Ubuntu 14 04 TensorFlow 1 4 0 compiled from source Python 2 7 gcc 4 8 4 What is different System A Bazel 0 6 0 2x E5 2643 v3 System B Bazel 0 7 0 2x E5 2643 v4 Why would they behave so differently,,"tatatodd,yaroslavvb,tatatodd",2017-11-27 16:57:43,2017-11-28 03:00:36
IS,'output' does not exist in model 'file',I was retrain a inception model with food images i got the final test prediction and retrained graph pb retrained labels txt file i check the prediction using command prompt in windows and its work but i was put the retrained graph ph and retrained labels txt files into android studio asset folder for deploying mobile i got the exception like output' does not exist in model 'file Can anyone help me solve this issue,,shivaniag,2017-11-23 06:43:18,2017-11-28 04:41:23
IS,LayerRNNCell call method incompatible with tuple of tensors,I'm trying to build a custom LSTM cell that should accept a tuple of tensors in the call method However as part of the dynamic rnn loop LayerRNNCell is call method requires that inputs be a 2 D tensor with shape batch size input size which is incompatible with a tuple of tensors Is there a way around this or can the call 1 method be expanded to be more flexible The error that I receive ValueError Layer action conditioned lstm cell 1 expects 1 inputs but it received 2 input tensors Linux Ubuntu 16 04 TensorFlow versions 'v1 3 0 rc1 5211 gab0fcac' '1 5 0 dev20171127',,"tatatodd,ebrevdo",2017-11-27 20:59:18,2017-11-28 05:52:14
IS,Eager Ca not take gradient of element wise tf functions,Maybe I'm missing something but taking the gradient of functions like tf sin and tf log in eager mode is failing on a recent master 80e7c9f45c,,"facaiy,asimshankar",2017-11-23 09:33:17,2017-11-28 10:30:43
IS,BUG embedding lookup can not convert out of index into zeros vector when embedding matrix is placed on CPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 GPU model and memory nvidia geforce gtx 1080 ti Exact command to reproduce Describe the problem embedding lookup can not convert out of index into zeros vector when embedding matrix is placed on CPU when the matrix is placed on GPU embedding lookup method automatically convert out of index components into zeros vector but it does not work when the matrix is placed on CPU Source code logs import tensorflow as tf inputs tf placeholder tf int32 None None with tf device ' cpu' when tf device ' gpu' it is okay embedding matrix tf get variable 'embedding matrix' 5 2 dtype tf float32 initializer tf contrib layers xavier initializer embedded tf nn embedding lookup embedding matrix inputs inputs test 1 2 10 sess tf Session sess run tf global variables initializer res sess run embedded feed dict inputs inputs test print res,,,2017-11-28 14:27:21,2017-11-28 14:33:42
IS,Running label wav py from Simple Audio Recognition on Windows 7 64 is generating errors CRITICAL tensorflow Audio file does not exist CRITICAL tensorflow Labels file does not exist CRITICAL tensorflow Graph file does not exist,Windows 7 64 GPU Nvidia M2000M Python 3 5 4 tensorflow 1 5 0 dev20171120 I was following the Simple Audio Tutorial After retraining and freezing the model I was trying to run the script label wav py The script produces an error CRITICAL tensorflow Audio file does not exist CRITICAL tensorflow Labels file does not exist CRITICAL tensorflow Graph file does not exist C Users bbb738 python tensorflow tensorflow examples speech commands label wav py graph tmp my frozen graph pb labels tmp speech commands train conv labels txt wav tmp speech dataset left a5d485dc nohash 0 wav CRITICAL tensorflow Audio file does not exist CRITICAL tensorflow Labels file does not exist CRITICAL tensorflow Graph file does not exist Traceback most recent call last File tensorflow tensorflow examples speech commands label wav py line 135 in module tf app run main main argv sys argv 0 unparsed File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python p latform app py line 129 in run sys exit main argv File tensorflow tensorflow examples speech commands label wav py line 107 in main FLAGS output name FLAGS how many labels File tensorflow tensorflow examples speech commands label wav py line 93 in label wav labels list load labels labels File tensorflow tensorflow examples speech commands label wav py line 58 in load labels return line rstrip for line in tf gfile GFile filename File tensorflow tensorflow examples speech commands label wav py line 58 in listcomp return line rstrip for line in tf gfile GFile filename File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python l ib io file io py line 214 in next return self next File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python l ib io file io py line 208 in next retval self readline File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python l ib io file io py line 177 in readline self preread check File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python l ib io file io py line 79 in preread check compat as bytes self name 1024 512 status File C Users bbb738 AppData Local Programs Python Python35 lib site packages tensorflow python f ramework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl NotFoundError NewRandomAccessFile failed to Create Open The system cannot find the path specified No such process,,"mrry,mrry,mrry,mrry,mrry,mrry",2017-11-27 08:43:50,2017-11-28 15:43:41
IS,Setup py on CentOS7 pywrap tensorflow internal error,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS7 TensorFlow installed from source or binary Setup py TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version GPU model and memory Exact command to reproduce import tensorflow as tf You can collect some of this information using our environment capture script tf env collect sh output cat etc issue Linux rs control1 3 10 0 327 36 1 el7 x86 64 1 SMP Sun Sep 18 13 04 29 UTC 2016 x86 64 x86 64 x86 64 GNU Linux VERSION 7 Core VERSION ID 7 CENTOS MANTISBT PROJECT VERSION 7 REDHAT SUPPORT PRODUCT VERSION 7 are we in docker No compiler c GCC 4 8 5 20150623 Red Hat 4 8 5 16 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux rs control1 3 10 0 327 36 1 el7 x86 64 1 SMP Sun Sep 18 13 04 29 UTC 2016 x86 64 x86 64 x86 64 GNU Linux check pips check for virtualenv False tensorflow import Traceback most recent call last File string line 1 in module File usr local python tgt 201701 lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File usr local python tgt 201701 lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local python tgt 201701 lib python2 7 site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File usr local python tgt 201701 lib python2 7 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import ImportError No module named pywrap tensorflow internal Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Installing using setup py works until trying to import tensorflow causing an Import Error for pywrap tensorflow internal Dependencies I believe are met and using setup py because I'm building this into an rpm to deploy to different nodes and clusters Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Simply running setup py and then import tensorflow as tf produces Import Error Traceback most recent call last File tmp check tf py line 1 in module import tensorflow as tf File usr local python tgt 201701 lib python2 7 site packages tensorflow init py line 24 in module from tensorflow python import File usr local python tgt 201701 lib python2 7 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local python tgt 201701 lib python2 7 site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File usr local python tgt 201701 lib python2 7 site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import ImportError No module named pywrap tensorflow internal,,,2017-11-22 16:51:15,2017-11-28 16:52:33
IS,tensorflow lite build for iOS,error download dependencies sh line 50 1 Usage download and extract URL DIR how to do it,,aselle,2017-11-24 04:11:43,2017-11-28 17:10:42
IS,Tensorflow lite does not support Gather Op with multiple dims,Hello Following up this SO question which did not get too much attention I'm filling this form as a question feature request System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 macOS builing and trying to use TF Lite for iOS TensorFlow installed from source or binary Source TensorFlow version use command below Latest made a pull from HEAD 3 days ago Python version 2 7 14 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source clang 9 0 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel bin tensorflow contrib lite toco toco ' input file Users valentinradu Playgrounds char rnn tensorflow remote save latest graph frz pb' ' output file Users valentinradu Playgrounds char rnn tensorflow remote save latest graph tflite' ' input format TENSORFLOW GRAPHDEF' ' output format TFLITE' ' input type FLOAT' ' inference type FLOAT' ' input shapes 1 128 1 50 50' ' input arrays state in data in' ' output arrays state out data out' Describe the problem I have a trained rnn that I try to use on mobile Problem is when I use toco to convert my pb file to tflite it fails with the following error message Having a look over the source code that generated that exception I think it is because of the toco is lack of support for multidimensional inputs But I'm not sure If so will this be added later Source code logs The repository I user to train the model can be found in full here,,gargn,2017-11-21 02:48:21,2017-11-28 17:23:24
IS,Is it possible to extend normal operators like add minus with convolution like operating,This is a feature request and so far I have not got any solution from tensorflow source code or websites like stackoverflow It may be confusing to state the problem like my title so I am going to give it a demo 1 The input matrix A has shape of 5 5 and the operation matrix B has shape of 3 3 2 In convolution manner tf nn conv2d A B padding 'VALID' will compute like this create a sliding window C with the same size of the filter matrix B on matrix A and apply computation DOT C B for all possible position of C on A All obtained product of B and C form the matrix of convolution result 3 Here if we enables the users to replace the DOT C B with other element wise operators like ADD C B or user defined ones it will enable tons of more creative layer designs to explore the power of AI A more flexiable interface will help users to avoid building his own operators by hacking the ops lib Sorry for interruption If this request get passed I hope I can help implementing it,,aselle,2017-11-26 13:53:35,2017-11-28 17:24:20
IS,bug report CMakeList config error,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem When using cmake config to build tensorflow under windows after enabling gpu following error appears after checking tf core framwork cmake it is requesting to remove tensorflow source dir tensorflow core platform default gpu tracer cc from core resources However this file is missing from the latest tensorflow Commenting this line help to finish cmake config but I do not think this is a good practice Would the development team consider to update the cmake file Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,aselle,2017-11-27 02:42:54,2017-11-28 17:53:59
IS,Estimators cause Out of range warning on FIFOQueue and fail to run all training steps,System information OS Platform and Distribution e g Linux Ubuntu 16 04 4 13 12 1 ARCH TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 0 Python version 3 6 3 CUDA cuDNN version 9 0 176 4 7 0 3 1 GPU model and memory 1080 1070 Describe the problem Trying to use estimators with a trivially small network fails to train for more than one step due to FIFOQueue closing with insufficient elements Source code logs In the following example I try to train a single neuron for 1000 steps at a time set size changes the training set is size With set size 1000 I would expect training to complete 1000 steps however only 8 steps are completed and an Out of range warning is printed Setting set size to 10 leads to only a single step being completed I would expect at least 10 steps to complete possible all 1000 if the input fn is called repeatedly to fill a queue not sure what default behaviour is supposed to be Setting set size 1000000 allows the entire 1k training steps to complete code warning 2017 11 23 11 23 52 370395 W tensorflow core framework op kernel cc 1192 Out of range FIFOQueue ' 2 enqueue input fifo queue' is closed and has insufficient elements requested 128 current size 0 Node fifo queue DequeueUpTo QueueDequeueUpToV2 component types DT INT64 DT DOUBLE DT DOUBLE timeout ms 1 device job localhost replica 0 task 0 device CPU 0 enqueue input fifo queue fifo queue DequeueUpTo n Edit This may be due to something in tf estimator inputs numpy input fn as creating the input fn manually does not cause the warning and early termination of training,,"tatatodd,ispirmustafa",2017-11-23 16:25:39,2017-11-28 18:07:39
IS,tensorflow contrib lite download dependencies sh does not finish without error,for tensorflow contrib lite download dependencies sh I can not run successfully with commit 049a34d692095b7e137bca27d2445415314ceaf7 And I rollback to 4b4b51cdd9e8c3c748b76dd8649bcd5556e84d76 everything is good,,"miaout17,miaout17,miaout17",2017-11-20 11:12:19,2017-11-28 18:22:34
IS,Feature Request Support for Flutter,I recently moved from native development to Flutter seeing Google backing its development Since both TensorFlow and Flutter is by Google will there be a support for Flutter in Future,,"shivaniag,asimshankar",2017-11-25 04:18:23,2017-11-28 19:07:24
PR,Tensor roll op implementation,Closes 10761 Added a tf roll op that works similarly to numpy is np roll This was a feature requested in 10761 and was marked as contributions welcome Usage Rolls the elements of a tensor by the offsets of shift along the dimensions of axis Elements that roll passed the last position will wrap around to the first For example If anyone has a clue of what might be the problem I would appreciate the help The code for the gpu implementation is on this branch on my fork roll op gpu Thanks,,"drpngx,drpngx,drpngx,aselle,drpngx,aselle,martinwicke,martinwicke,martinwicke",2017-09-03 21:02:21,2017-11-28 19:47:48
PR,Branch 177191521,,,sb2nov,2017-11-28 19:38:12,2017-11-28 20:30:07
PR,softmax cross entropy Improve docstring,Improve docstring of softmax cross entropy,,,2017-11-28 07:40:24,2017-11-28 20:44:56
PR,Merge pull request 1 from tensorflow master,just merge,,,2017-11-28 13:27:31,2017-11-28 20:45:55
IS,How to scale the weights at runtime in tensorflow,I have asked this questione in the stackoverflow Thanks for your help,,tatatodd,2017-11-28 12:22:27,2017-11-28 21:09:59
PR,Explicitly pass label count to confusion matrix,If batch size gets small enough there can be not enough classes in the validation batch and auto inference on each step may return different sizes of the confustion matrices and their addition will fail,,,2017-10-29 14:00:31,2017-11-28 21:52:28
IS,If I import cv2 tf global variables initializer will be very slow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 3 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 0 Python version 2 7 12 CUDA cuDNN version CUDA Version 8 0 61 GPU model and memory NVIDIA GTX 1080Ti 12G Describe the problem If I import cv2 tf global variables initializer will be very slow about 143s You can run my test code below when import cv2 is commented out the time is about 5s The version of opencv is 2 4 13 4 Source code logs,,"ppwwyyxx,aselle",2017-11-24 13:40:56,2017-11-28 22:16:37
IS,failed to bazel build tensorflow lite,build tensorflow lite demo with bazel output base data wjx bazel tensorflow output output user root data wjx bazel tensorflow build cxxopt ' std c 11' tensorflow contrib lite java demo app src main TfLiteCameraDemo Environment OS ubuntu 16 04 tf version tensorflow 1 4 master python 2 7 12 AndroidSDK 27 BuildToolsVersion 27 0 1 NDK android ndk r14e ERROR data wjx bazel tensorflow output external androidsdk com android support BUILD 4277 1 Merging Android resources for com android support support compat 25 2 0 failed Exit 1 Nov 20 2017 1 31 06 AM com google devtools build android AndroidResourceMergingAction main SEVERE Unexpected java io IOException Mount point not found at sun nio fs LinuxFileStore findMountEntry LinuxFileStore java 91 at sun nio fs UnixFileStore init UnixFileStore java 65 at sun nio fs LinuxFileStore init LinuxFileStore java 44 at sun nio fs LinuxFileSystemProvider getFileStore LinuxFileSystemProvider java 51 at sun nio fs LinuxFileSystemProvider getFileStore LinuxFileSystemProvider java 39 at sun nio fs UnixFileSystemProvider getFileStore UnixFileSystemProvider java 368 at java nio file Files getFileStore Files java 1461 at com google devtools build android ScopedTemporaryDirectory makeWritable ScopedTemporaryDirectory java 59 at com google devtools build android ScopedTemporaryDirectory visitFile ScopedTemporaryDirectory java 83 at com google devtools build android ScopedTemporaryDirectory visitFile ScopedTemporaryDirectory java 36 at java nio file Files walkFileTree Files java 2670 at java nio file Files walkFileTree Files java 2742 at com google devtools build android ScopedTemporaryDirectory close ScopedTemporaryDirectory java 96 at com google devtools build android AndroidResourceMergingAction main AndroidResourceMergingAction java 289 at com google devtools build android ResourceProcessorBusyBox Tool 7 call ResourceProcessorBusyBox java 91 at com google devtools build android ResourceProcessorBusyBox main ResourceProcessorBusyBox java 172 Exception in thread main java io IOException Mount point not found at sun nio fs LinuxFileStore findMountEntry LinuxFileStore java 91 at sun nio fs UnixFileStore init UnixFileStore java 65 at sun nio fs LinuxFileStore init LinuxFileStore java 44 at sun nio fs LinuxFileSystemProvider getFileStore LinuxFileSystemProvider java 51 at sun nio fs LinuxFileSystemProvider getFileStore LinuxFileSystemProvider java 39 at sun nio fs UnixFileSystemProvider getFileStore UnixFileSystemProvider java 368 at java nio file Files getFileStore Files java 1461 at com google devtools build android ScopedTemporaryDirectory makeWritable ScopedTemporaryDirectory java 59 at com google devtools build android ScopedTemporaryDirectory visitFile ScopedTemporaryDirectory java 83 at com google devtools build android ScopedTemporaryDirectory visitFile ScopedTemporaryDirectory java 36 at java nio file Files walkFileTree Files java 2670 at java nio file Files walkFileTree Files java 2742 at com google devtools build android ScopedTemporaryDirectory close ScopedTemporaryDirectory java 96 at com google devtools build android AndroidResourceMergingAction main AndroidResourceMergingAction java 289 at com google devtools build android ResourceProcessorBusyBox Tool 7 call ResourceProcessorBusyBox java 91 at com google devtools build android ResourceProcessorBusyBox main ResourceProcessorBusyBox java 172 Target tensorflow contrib lite java demo app src main TfLiteCameraDemo failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 16 750s Critical Path 3 39s FAILED Build did NOT complete successfully can anyone help me,,"angersson,angersson,angersson",2017-11-20 03:27:00,2017-11-29 01:26:20
IS,TensorFlow Lite Android example does not compile with Bazel,TensorFlow Lite Android example does not compile with Bazel as explained in its README System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 TensorFlow installed from source or binary source TensorFlow version use command below master c0662f1620c2b97abb79b8ae6a8a30f7c7719475 Python version 2 7 14 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 7 2 0 CUDA cuDNN version not using cuda GPU model and memory not using GPU Exact command to reproduce bazel build cxxopt ' std c 11' tensorflow contrib lite java demo app src main TfLiteCameraDemo Describe the problem When trying to compile the TF Lite Android demo with Bazel it does not work yielding,,"bryant1410,angersson,angersson,angersson,angersson,bryant1410",2017-11-17 19:24:00,2017-11-29 02:27:20
IS,Missing gradient for tf argmax,LookupError No gradient defined for operation 'Argmax' op type Argmax,,"tatatodd,boeddeker,tatatodd",2017-11-28 07:42:36,2017-11-29 04:46:45
IS,AttributeError module 'tensorflow' has no attribute isession',Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64bit TensorFlow installed from source or binary TensorFlow version use command below 1 4 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Why in tensorflow 1 4 when running validating command in sess tf session Line gives this error is Session attribute changed in 1 4 version of tensorflow compare to previous versions Like 0 12 Source code logs import tensorflow as tf hello tf constant 'hello tensorflow ' sess tf session Traceback most recent call last File stdin line 1 in module AttributeError module 'tensorflow' has no attribute isession',,mrry,2017-11-29 09:25:19,2017-11-29 14:51:59
PR,Add layer scope to tf contrib layers spatial softmax,tensorflow contrib layers spatial softmax is lacking a layer level scope before after before after,,"martinwicke,martinwicke,sguada,martinwicke,martinwicke",2017-11-06 10:45:18,2017-11-29 15:51:19
PR,Lazily configure TensorFlow logger,Fixes 10498,,"taion,taion,taion,mrry,taion,drpngx,dave-andersen,vrv,taion,dave-andersen,taion,rmlarsen,vrv,jhseu,vrv,craigcitro,taion,drpngx,taion,dave-andersen,sb2nov,taion,martinwicke,taion,martinwicke,martinwicke",2017-06-12 17:31:11,2017-11-29 15:51:46
PR,golang 2x speedup for encodeTensor,This is duplicate of but now it can be merged safely because is merged CC before go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 200 6792809 ns op PASS ok github com tensorflow tensorflow tensorflow go 2 116s after go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 500 3269740 ns op PASS ok github com tensorflow tensorflow tensorflow go 2 021s,,"anight,asimshankar,anight,asimshankar,asimshankar,asimshankar,asimshankar",2017-11-10 01:03:57,2017-11-29 15:56:53
PR,golang 15x speedup for decodeTensor,Make decodeTensor faster by running binary Read for the whole slice in last dimension Similar to before go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 200 7459717 ns op BenchmarkDecodeTensor 150528 8 100 11205557 ns op PASS ok github com tensorflow tensorflow tensorflow go 3 447s after go test bench goos linux goarch amd64 pkg github com tensorflow tensorflow tensorflow go BenchmarkNewTensor 150528 8 200 7009254 ns op BenchmarkDecodeTensor 150528 8 2000 747224 ns op PASS ok github com tensorflow tensorflow tensorflow go 3 793s,,"anight,asimshankar",2017-11-27 16:12:41,2017-11-29 16:02:57
PR,Fix absl flag initialization in cloud tpu profiler,This fixes a regression caused by 2652704b576adc16b4d735f651cea1024e88b72e where the command would not run See also tensorflow tensorboard 716 This is caused by the PIP generated program wrapper not invoking the tf app run that normally goes in the if main clause of a script That runner basically initializes flags But as far as I can tell this is the only pip console script in TensorFlow that still uses flags The other two appear to have migrated to argparse So this change should be sufficient CC,,"jart,jhseu,yifeif",2017-11-10 00:00:55,2017-11-29 16:08:44
IS,tf contrib metrics streaming mean,It works well But when I use weights tf constant 0 3 3 1 1 3 1 2 instead of weights above It can not work mean value 0 0 what is wrong,,"ispirmustafa,ispirmustafa",2017-11-12 09:06:59,2017-11-29 16:44:38
IS,remplace npy weight file from a checkpoint,Hi I went modify this line of code loading weights from pretrained mode weights dict np load self WEIGHTS PATH encoding 'bytes' item where WEIGHTS PATH is a an npy file WEIGHTS PATH 'bvlc alexnet npy' by my own weights saved in checkpoint Thanks a lot,,,2017-11-29 08:59:08,2017-11-29 16:51:17
IS,traceback error,Traceback most recent call last File usr lib python2 7 runpy py line 174 in run module as main main fname loader pkg name File usr lib python2 7 runpy py line 72 in run code exec cod in run globals File usr lib python2 7 py compile py line 181 in module sys exit main File usr lib python2 7 py compile py line 173 in main compile filename doraise True File usr lib python2 7 py compile py line 106 in compile with open file 'U' as f IOError Errno 2 No such file or directory '' Finished in 0 7s with exit code 1 shell cmd python m py compile dir opt sublime text path usr local sbin usr local bin usr sbin usr bin sbin bin usr games usr local games snap bin usr lib jvm java 8 oracle bin usr lib jvm java 8 oracle db bin usr lib jvm java 8 oracle jre bin c,,aselle,2017-11-28 23:09:04,2017-11-29 17:06:45
IS,Method of stabilizing prediction box,I found that when I used other methods to detect objects the prediction box was not stable However in the demo you provided I found that the detection box is very stable Why can you give me the code to stabilize the detection box,,aselle,2017-11-29 03:12:18,2017-11-29 17:07:03
IS,Tensorflow Conv model crashes on GPU with zero size batch,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes I have created two CNN models OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary I installed tensorflow via pip install Python 3 TensorFlow version use command below 1 4 0 Python version 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 GPU model and memory NVIDIA Tesla k80 totalMemory 11 17GiB freeMemory 11 09GiB Exact command to reproduce See below Below is the log keep dims is deprecated use keepdims instead Layer type Output Shape Param input 1 InputLayer None 7 264 0 reshape 1 Reshape None 7 264 1 0 conv2d 1 Conv2D None 7 264 64 16960 max pooling2d 1 MaxPooling2 None 7 132 64 0 flatten 1 Flatten None 59136 0 dense 1 Dense None 1024 60556288 dropout 1 Dropout None 1024 0 dense 2 Dense None 512 524800 dropout 2 Dropout None 512 0 dense 3 Dense None 88 45144 Total params 61 143 192 Trainable params 61 143 192 Non trainable params 0 home hpnhxxwn miniconda3 envs carnd term1 lib python3 5 site packages keras engine training py 2057 UserWarning Using a generator with use multiprocessing True and multiple worker s may duplicate your data Please consider using the keras utils Sequence class UserWarning 'Using a generator with use multiprocessing True ' ld learning rate is now 0 01 2017 11 29 04 58 20 964015 I tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX A VX2 FMA 2017 11 29 04 58 21 094051 I tensorflow stream executor cuda cuda gpu executor cc 900 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUM A node so returning NUMA node zero 2017 11 29 04 58 21 094719 I tensorflow core common runtime gpu gpu device cc 1062 Found device 0 with properties name Tesla K80 major 3 minor 7 memoryClockRate GHz 0 8235 pciBusID 0000 00 04 0 totalMemory 11 17GiB freeMemory 11 09GiB 2017 11 29 04 58 21 094744 I tensorflow core common runtime gpu gpu device cc 1152 Creating TensorFlow device device GPU 0 device 0 name Tesla K80 pci bus id 0000 00 04 0 compute capability 3 7 Epoch 1 1000 5180 6944 ETA 3 43 loss 0 1382 acc 0 9637 mean absolute error 0 0715 sparse categorical accuracy 7 1640e 05switching to 'AkPnStgb' 5212 6944 ETA 3 39 loss 0 1384 acc 0 9636 mean absolute error 0 0715 sparse categorical accuracy 7 1200e 052017 11 29 05 09 22 210897 F tensorflow stream executor cuda cuda dnn cc 444 could not convert BatchDescriptor count 0 feature map count 64 spatial 7 264 value min 0 000000 value max 0 000000 layout Batc hDepthYX to cudnn tensor descriptor CUDNN STATUS BAD PARAM Below is the model I have found other github issue created for the same issue not so far seems like there is no fix yet I heard the workaround is to use tf cond can someone show me how to use it in such case,,"ppwwyyxx,aselle",2017-11-29 06:05:40,2017-11-29 17:08:55
IS,why the size of filter is 3 3 in inceptionv1 py,L103 according to the paper the size of filter in the scope of InceptionV1 Mixed 3b Branch 2 should be 5 5 why is 3 3 in the script,,aselle,2017-11-29 07:57:48,2017-11-29 17:09:33
IS,Question about tf contrib image rotate,Good Morning is it possible to parse the result from tf contrib image rotate to a tensor to use it in t cast,,aselle,2017-11-29 08:52:56,2017-11-29 17:09:53
IS,enable get the 'mathematical' gradient of output w r t neural network parameters,In some situation it is necessary to get the 'mathematical' gradient of output w r t neural network parameters For example suppose I have a neural network out f s where s is a batch of input with shape None dim s while out is a scaler f is simply a MLP With tf gradient out tf trainable variables I can get gradient of out w r t neural network parameters of f which is a list of gradient Now I have two different batch of s s1 and s2 then we can get two different the above gradients G1 and G2 It seems that it is impossible to compute cosine between G1 and G2 using current tensorflow Do I need to flatten both gradients first Do G1 and G2 are the usual gradient in math,,"aselle,facaiy,aselle,aselle",2017-11-28 20:44:24,2017-11-29 17:16:54
PR,Fix Wrong Rendering of Code Example,Code example was being rendered as plain text This commit fixes it,,sb2nov,2017-11-29 09:34:03,2017-11-29 17:53:57
IS,and or etc should be overloaded if possible,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 OS X 10 13 1 TensorFlow installed from source or binary Binary anaconda TensorFlow version use command below 1 1 0 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory Intel HD Graphics 630 1536 MB not used Exact command to reproduce N A Describe the problem It would make code much cleaner if more of Python is binary boolean operations were overloaded for TF I understand this can not be done for because of hashmap key problems but and or not really as many operations as possible would be great Source code logs Currently,,"alextp,alextp,facaiy",2017-11-27 16:49:40,2017-11-29 18:29:47
IS,'No gradients provided for any variable check your graph for ops that do not support gradients',I write the code like following I could not figure it out for days please help,,"aselle,aselle",2017-11-27 01:06:56,2017-11-29 18:49:20
PR,Adding connectivity check compilation fix and some code refactoring to verbs,1 Connectivity check checking the correctness of the RDMA configuration parameters by pinging on each channel 2 Compilation with verbs and without CUDA fix contrib verbs only works on GPU 13466 3 Code refactoring Call done in case of not OK status fix Replace hardcoded 100 with RDMA QP QUEUE DEPTH,,"dariavel,dariavel,dariavel,dariavel,dariavel,jhseu,tatatodd,tatatodd",2017-11-06 12:50:46,2017-11-29 19:57:12
IS,TF Lite C standalone Interpreter,Feature request System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 4 Python version 2 7 12 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version None GPU model and memory None Exact command to reproduce None I deploy TensorFlow models to environments with very limited memory and was very excited to see how tiny the TF Lite kernel is several hundred kilobytes I know the project is young but I was wondering if there are any plans to support a standalone C build for the Lite architecture for deployment to Linux environments that do not have a TensorFlow runtime For my purposes this package should support the following Loading a model configuration Loading input tensors Invoking the model with input tensors Storing the result in output tensors Some serialization method for the input and output tensors I would like to know Is this a possible feature for TF Lite What would the scope be of implementing this Are there any plans to do so,,"aselle,aselle",2017-11-15 15:46:08,2017-11-29 20:37:52
PR,Update datasets md,Specifically I changed Iterator into tf data Iterator for people who read programming guide of Tensorflow,,mrry,2017-11-28 13:58:26,2017-11-29 20:42:44
PR,Half Normal Distribution and inverse error function,Inverse Error Function Added erfinv as a simple function of ndtri the api mirrors the approach taken in scipy special Mainly to prevent distributions with methods in terms of the inverse error function reimplementing their own wrappers around ndtri Half Normal Distribution Added the Half Normal distribution to contrib distributions Main things to look at is how I'm dealing with the pdf discontinuity A discontinuity in the pdf that sends values to 0 0 is easy to represent in prob by multiplying my a tensor with 0 0s at the relevant positions than log prob which requires masking inf wherever x 0 I would be interested if anyone has any suggestions for correct ways to implement the latter as I think this is a case where log prob is more numerically stable along the support of the distribution that is,,"ebrevdo,gunan,ebrevdo,ebrevdo,ebrevdo,ebrevdo",2017-10-28 12:08:47,2017-11-29 21:15:39
PR,Update datasets md,There is omission of tf data in front of Iterator from structure I found it When I read and tested So For some other people who read this article I ask for pull request,,sb2nov,2017-11-23 13:04:32,2017-11-29 21:45:15
PR,Typo fix,Typo fix uniqified uniquified,,sb2nov,2017-11-23 15:09:54,2017-11-29 21:49:41
PR,Typo fixing,typo fixed libaries libraries,,sb2nov,2017-11-23 14:45:39,2017-11-29 21:50:00
PR,Introduce tf http archive,This new repository rule consolidates patched http archive temp workaround http archive http archive and new http archive The following behaviors have been introduced A delete attribute that can rm rf certain repo content after extraction Helpful error messages when mirroring requirements are not followed cc,,"jart,gunan,damienmg,jart,gunan,case540",2017-11-23 00:16:15,2017-11-29 22:37:17
IS,Freezing Model drops Output Accuracy,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary Binary TensorFlow version use command below v1 2 and v1 3 Same Problem repeats on both Python version 3 5 CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 44 cuDNN Version 5 1 10 GPU model and memory GeForce GTX 1060 6GB I have a image segmentation network designed to classify roads and obstacles I want to freeze the model and serve it as a API So I used the default TensorFlow tool for freezing the model After freezing the output given by the network are completely off and inaccurate Here is one sample The Input Image 00016 Output when tested using ckpt files 16 actual Output after Freezing the Model 16 I have tried to freeze using different versions of tensorflow but that has not helped Since the network is performing as excepted when tested against checkpoint the issue I think is in the Freeze Models Script The network uses Batch normalisation Could this be the reason for this drop because I saw a couple of issues linked to that of similar nature How can I avoid that,,"aselle,aselle",2017-08-21 12:04:07,2017-11-29 23:29:51
IS,protobuf crashes at runtime when loading tensor lib,hardware Huawei P7 Android 4 4 2 i tried ndk r12b r10e and api 9 api 14 all run into this error 09 04 19 10 47 640 21660 21660 com zhuxin ecg jijian A libc Fatal signal 6 SIGABRT at 0x0000549c code 6 thread 21660 uxin ecg jijian 09 04 19 10 47 740 162 162 I DEBUG 09 04 19 10 47 740 162 162 I DEBUG Build fingerprint 'Huawei P7 L00 hwp7 4 4 2 HuaweiP7 L00 C17B620 user ota rel keys release keys' 09 04 19 10 47 740 162 162 I DEBUG Revision '0' 09 04 19 10 47 740 162 162 I DEBUG pid 21660 tid 21660 name uxin ecg jijian com zhuxin ecg jijian 09 04 19 10 47 740 162 162 I DEBUG signal 6 SIGABRT code 6 SI TKILL fault addr 09 04 19 10 47 880 754 754 W View requestLayout improperly called by com android systemui statusbar phone IconMerger 434090b0 V E I 0 0 270 72 7f0a0069 app id notificationIcons during layout running second layout pass 09 04 19 10 48 360 162 162 I DEBUG 06 pc 0000274d system bin linker 09 04 19 10 48 360 162 162 I DEBUG 07 pc 00002823 system bin linker 09 04 19 10 48 360 162 162 I DEBUG 08 pc 00002975 system bin linker 09 04 19 10 48 360 162 162 I DEBUG 09 pc 000029e9 system bin linker 09 04 19 10 48 360 162 162 I DEBUG 10 pc 00000f43 system bin linker 09 04 19 10 48 360 162 162 I DEBUG 11 pc 00050ee3 system lib libdvm so dvmLoadNativeCode char const Object char 182 09 04 19 10 48 360 162 162 I DEBUG 12 pc 00068885 system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 13 pc 00027ea0 system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 14 pc 0002eef0 system lib libdvm so dvmMterpStd Thread 76 09 04 19 10 48 360 162 162 I DEBUG 15 pc 0002c588 system lib libdvm so dvmInterpret Thread Method const JValue 184 09 04 19 10 48 360 162 162 I DEBUG 16 pc 00061595 system lib libdvm so dvmCallMethodV Thread Method const Object bool JValue std va list 336 09 04 19 10 48 360 162 162 I DEBUG 17 pc 000615b9 system lib libdvm so dvmCallMethod Thread Method const Object JValue 20 09 04 19 10 48 360 162 162 I DEBUG 18 pc 0006cd7d system lib libdvm so dvmInitClass 1020 09 04 19 10 48 360 162 162 I DEBUG 19 pc 0006da87 system lib libdvm so dvmResolveMethod 198 09 04 19 10 48 360 162 162 I DEBUG 20 pc 000234f4 system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 21 pc 0002eef0 system lib libdvm so dvmMterpStd Thread 76 09 04 19 10 48 360 162 162 I DEBUG 22 pc 0002c588 system lib libdvm so dvmInterpret Thread Method const JValue 184 09 04 19 10 48 360 162 162 I DEBUG 23 pc 00061879 system lib libdvm so dvmInvokeMethod Object Method const ArrayObject ArrayObject ClassObject bool 392 09 04 19 10 48 360 162 162 I DEBUG 24 pc 00069963 system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 25 pc 00027ea0 system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 26 pc 0002eef0 system lib libdvm so dvmMterpStd Thread 76 09 04 19 10 48 360 162 162 I DEBUG 27 pc 0002c588 system lib libdvm so dvmInterpret Thread Method const JValue 184 09 04 19 10 48 360 162 162 I DEBUG 28 pc 00061595 system lib libdvm so dvmCallMethodV Thread Method const Object bool JValue std va list 336 09 04 19 10 48 360 162 162 I DEBUG 29 pc 0004ac6b system lib libdvm so 09 04 19 10 48 360 162 162 I DEBUG 30 pc 0004ed47 system lib libandroid runtime so 09 04 19 10 48 360 162 162 I DEBUG 31 pc 0004faef system lib libandroid runtime so android AndroidRuntime start char const char const 354 09 04 19 10 48 360 162 162 I DEBUG stack 09 04 19 10 48 360 162 162 I DEBUG beed50e0 0006be74 09 04 19 10 48 360 162 162 I DEBUG beed50e4 81cfa290 09 04 19 10 48 360 162 162 I DEBUG beed50e8 beed5104 stack 09 04 19 10 48 360 162 162 I DEBUG beed50ec 812a0da8 data app lib com zhuxin ecg jijian 1 libecg sdk so std unordered map std string google protobuf FieldDescriptorProto Type google protobuf hash std string std equal to std string std allocator std pair std string const google protobuf FieldDescriptorProto Type operator std string 48 09 04 19 10 48 360 162 162 I DEBUG beed50f0 beed51a0 stack 09 04 19 10 48 360 162 162 I DEBUG beed50f4 81cfa290 09 04 19 10 48 360 162 162 I DEBUG beed50f8 81cfa290 09 04 19 10 48 360 162 162 I DEBUG beed50fc 20492111 09 04 19 10 48 360 162 162 I DEBUG beed5100 81cfa290 09 04 19 10 48 360 162 162 I DEBUG beed5104 00000001 09 04 19 10 48 360 162 162 I DEBUG beed5108 00000015 09 04 19 10 48 370 162 162 I DEBUG beed510c 71a0b990 09 04 19 10 48 370 162 162 I DEBUG beed5110 00000001 09 04 19 10 48 370 162 162 I DEBUG beed5114 4007d9b5 system lib libc so write 12 09 04 19 10 48 370 162 162 I DEBUG beed5118 4008e1d8 system lib libc so 09 04 19 10 48 370 162 162 I DEBUG beed511c 71a0b990 09 04 19 10 48 370 162 162 I DEBUG 00 beed5120 00000006 09 04 19 10 48 370 162 162 I DEBUG beed5124 00000016 09 04 19 10 48 370 162 162 I DEBUG beed5128 0000549c 09 04 19 10 48 370 162 162 I DEBUG beed512c 400b1f0f system bin linker 09 04 19 10 48 370 162 162 I DEBUG beed5130 400b1f0f system bin linker 09 04 19 10 48 370 162 162 I DEBUG beed5134 4005628d system lib libc so pthread kill 52 09 04 19 10 48 370 162 162 I DEBUG 01 beed5138 00000006 09 04 19 10 48 370 162 162 I DEBUG beed513c 00000000 09 04 19 10 48 370 162 162 I DEBUG beed5140 74a2f24c 09 04 19 10 48 370 162 162 I DEBUG beed5144 400564a1 system lib libc so raise 14 09 04 19 10 48 370 162 162 I DEBUG 02 beed5148 beed5154 stack 09 04 19 10 48 370 162 162 I DEBUG beed514c 400551d7 system lib libc so 09 04 19 10 48 390 162 162 I DEBUG memory near r1 09 04 19 10 49 350 754 754 W View requestLayout improperly called by com android systemui statusbar phone IconMerger 434090b0 V E 0 0 270 72 7f0a0069 app id notificationIcons during second layout pass posting in next frame 09 04 19 10 49 600 658 694 W InputDispatcher channel '43db7980 com zhuxin ecg jijian com ikinloop ecgapplication ui activity MainActivity server ' Consumer closed input channel or an error occurred events 0x9 09 04 19 10 49 600 658 694 E InputDispatcher channel '43db7980 com zhuxin ecg jijian com ikinloop ecgapplication ui activity MainActivity server ' Channel is unrecoverably broken and will be disposed 09 04 19 10 49 710 362 466 I logserver Object Path data system dropbox mask 0x00000080 09 04 19 10 49 710 362 466 I logserver event len 48 name data app native crash 1504523449716 txt gz 09 04 19 10 49 710 362 466 I logserver process one event can not find this event data app native crash 1504523449716 txt gz 09 04 19 10 49 710 362 466 I logserver clean cur cache 962 system rm r data log logcache 3577632 dev null 2 1 09 04 19 10 49 710 658 1213 W InputDispatcher Attempted to unregister already unregistered input channel '43db7980 com zhuxin ecg jijian com ikinloop ecgapplication ui activity MainActivity server ' 09 04 19 10 49 720 1095 1095 I HwLauncher DynamicIcon onWindowVisibilityChanged 4 com android calendar,,,2017-09-04 11:36:00,2017-11-29 23:30:44
PR,Format AUTHORS file,,,Androbin,2017-11-25 15:13:05,2017-11-30 00:02:06
PR,Clarifying checkpoint is not a file,I would like to clarify checkpoint is not a file I also changed some wording which may lead readers to use a physical file name in their code,,"tedhtchang,sb2nov,tedhtchang",2017-11-29 03:26:27,2017-11-30 00:02:25
PR,Speed up safe strtod and safe strtof functions by using double conversion library,11713,,"drpngx,drpngx,rmlarsen,rmlarsen,rmlarsen,drpngx,rmlarsen,drpngx,martinwicke,sb2nov,rmlarsen,sb2nov,sb2nov,drpngx,martinwicke,martinwicke,martinwicke,mrry,drpngx,drpngx,martinwicke,drpngx,martinwicke,sb2nov,martinwicke,caisq",2017-08-08 08:39:53,2017-11-30 00:02:50
PR,improved estimator export savedmodel exception,,,boeddeker,2017-11-29 18:41:02,2017-11-30 00:03:38
IS,Feature Request C gradient for LRN Local Response Normalization,Implement the gradient for LRN in c so that it is available for TF AddGradients This is the python code that I think would need to be ported L516 I'm using this issue to call dibs on this gradient port per is suggestion I was also advised to mention,,"drpngx,bpiel,suharshs,bpiel",2017-10-17 19:07:35,2017-11-30 00:04:24
PR,Feature Request C gradient for LRN,this resolves 13789 Registers the LRNGrad op as the gradient for LRN by implementing LRNGradHelper Single test case proves that everything was wired up correctly since I assume the LRNGrad code was thoroughly tested This is my first PR to TensorFlow When giving feedback please assume that I barely know what I'm doing,,"suharshs,suharshs,bpiel,skye,skye,skye,skye,skye",2017-10-26 03:12:35,2017-11-30 00:04:24
IS,On the way to latest CMake VS2017 CUDA 9 cudNN 7 Win10,As many of us 14126 14691 12052 I am trying to get TF1 4 build successfully on windows using the latest version of everything As far as I can judge I could do it but with some hacks As it is too long for me to complete I would like to share what I did for help finalizing It is too early for a PR I am using CMake 3 9 6 though 3 10 came out I have low cmake skill level I am not trying the python bindings VS2017 is the community edition Without GPU it is easy The only issue is the heap overflow C1002 or C1006 11096 The trick is to reduce parallel build by msbuild m 4 p CL MPCount 2 such that 4 2 is approximately the number of core you really have at least it worked for me Using Zm2000 did not work for me despite a lot of available memory 32G With GPU it is more tricky the tf core gpu kernels vcxproj does not compile at all AFAIU the CMake strategy changed from v3 6 to allow parallel computing CUDA is now treated as another language Without modifications nvcc simply returns with code error 1 or nothing happen I am not sure Here are my modifications from v1 4 From tensorflow tensorflow contrib cmake 1 adapt cmakelists txt a little Change CUDA 8 0 to CUDA 9 0 l 223 Add enable language CUDA l 224 The set CUDA NVCC FLAGS directives do not work anymore See below Add capabilities 6 0 and 6 1 in l 232 as well l 246 Might not be needed it is only for performance Change 64 80 to 64 90 and 64 6 to 64 7 l 247 and 248 similarly in l 272 276 2 in tf core kernels cmake Add set source files properties tf core gpu kernels srcs PROPERTIES LANGUAGE CUDA to recognize ' cu cc' extensions as cuda files in l 209 Rename cuda add library as add library l 210 3 edit this is the trick tf core gpu kernels vcxproj in the release section Encompass cl exe flags ie bigobj nologo Ob2 with the Xcompiler bigobj Ob2 directive l 147 These former flags are for the c compiler not for nvcc and result in the crash Add just before expt relaxed constexpr still in the AdditionalOptions Switch PerformDeviceLink from false to true l 164 Then everything compile msbuild on tf tutorials example trainer vcxproj and this tuto works The remaining point before PR is to avoid third step i e give the right directives to nvcc by understanding how the CUDA NVCC FLAGS works and add the linking Hope this solution will work without missing symbols 6396 Otherwise it is a nightmare both CUDA 8 and CMake 3 6 are not aware of VS2017 CMake compilation is not incremental 14194 and takes about 4 5H could use precompiled headers especially in tf core kernels,,"tatatodd,gunan,gunan",2017-11-22 16:30:20,2017-11-30 00:49:50
PR,Add operator for IndicesRowIterator,This fix adds the operator for IndicesRowIterator to address C2678 error in VS Debug mode as was specified in 12000 This fix fixes 12000,,"yongtang,martinwicke,caisq,yongtang,gunan,yongtang",2017-10-07 15:46:02,2017-11-30 00:53:39
IS,Tensorflow cannot be installed with default Windows Python 3 5 stack,After installing Python 3 5 0 using the Windows 64 bit installer which includes pip in the install pip3 install upgrade tensorflow Collecting tensorflow Could not find a version that satisfies the requirement tensorflow from versions No matching distribution found for tensorflow You are using pip version 7 1 2 however version 9 0 1 is available You should consider upgrading via the 'python m pip install upgrade pip' command I tried on a different machine that worked and found the only difference to be the pip version Updating to pip 9 0 1 solved the issue It is not explicitly stated anywhere that you need a newer version of pip When an old version of something is required to run something people tend to ignore the messages indicating there is a newer version of it because that is exactly what they are expecting yeah I know there is a newer version I meant to do this If this cannot be resolved for older version of pip specifically versions included with the required Python versions could you please state this in the documentation,,angersson,2017-11-10 15:53:55,2017-11-30 01:12:59
IS,Tensorflow Lite demo app with inception v3 Mobilenet v1 float model crashes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 14 04 Python version 3 4 3 Bazel version if compiling from source 0 5 4 Describe the problem Device Galaxy S8 I downloaded the Inception V3 Slim 2016 from I pushed the imagenet 2015 label strings txt and the inceptionv3 non slim 2015 tflite to the asset folder I edited the ImageClassifier java of tflite demo app The changes are the followings private static final String MODEL PATH inceptionv3 non slim 2015 tflite static final int DIM IMG SIZE X 299 static final int DIM IMG SIZE Y 299 The app hangs when it starts I could run the app with the default mobilenet quantized graph Similar is the case with mobilenet v1 224 Float graph as well the app hangs or crashes I assume the float model graph is not yet supported by TF Lite However in the documentation its written that it does support float for most operations I am thinking the error is due to image pre processing output and input size of float model grpah The error log is stated below The Error log 11 21 14 31 43 034 2111 2416 android example com tflitecamerademo E AndroidRuntime FATAL EXCEPTION CameraBackground Process android example com tflitecamerademo PID 2111 java lang IllegalArgumentException Failed to get input dimensions 0 th input should have 1072812 bytes but found 268203 bytes at org tensorflow lite NativeInterpreterWrapper getInputDims Native Method at org tensorflow lite NativeInterpreterWrapper run NativeInterpreterWrapper java 82 at org tensorflow lite Interpreter runForMultipleInputsOutputs Interpreter java 112 at org tensorflow lite Interpreter run Interpreter java 93 at com example android tflitecamerademo ImageClassifier classifyFrame ImageClassifier java 112 at com example android tflitecamerademo Camera2BasicFragment classifyFrame Camera2BasicFragment java 663 at com example android tflitecamerademo Camera2BasicFragment wrap0 Camera2BasicFragment java at com example android tflitecamerademo Camera2BasicFragment 4 run Camera2BasicFragment java 558 at android os Handler handleCallback Handler java 751 at android os Handler dispatchMessage Handler java 95 at android os Looper loop Looper java 154 at android os HandlerThread run HandlerThread java 61 Additional Questions 1 On the app the the tensorflow lite graph format is tflite However on the documentation the format is written as lite,,"aselle,Johnson145,freedomtan,Johnson145",2017-11-20 12:23:26,2017-11-30 01:16:43
IS,Possible sparse gradients bug in 1 4,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Slackware 14 2 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 Problem I get the following warning when I run my code and I no longer get the warning in TF 1 4 As far as I can tell one of the operations in the original code cannot handle sparse gradients,,"tatatodd,tatatodd",2017-11-27 19:41:18,2017-11-30 02:00:13
IS,Tensor as index to other tensor not supported,I have 2 tensors one is constant and one is placeholder lets say A 0 1 0 2 0 3 0 4 0 5 0 6 0 7 B 1 2 4 5 0 3 I want to build a tensor C like this C 0 2 0 3 0 5 0 6 0 1 0 4 which is a tensor in the same size of B and every element in C is equal to element in A indexed by B elements is there any way to do that Thanks,,tatatodd,2017-11-29 11:22:18,2017-11-30 02:13:50
IS,master branch compilation of llvm gpu backend failed,System information OS Platform and Distribution slackware64 current Python version 3 6 3 Bazel version 0 8 0 GCC Compiler version 5 4 0 CUDA cuDNN version 9 7 build environment export PYTHON BIN PATH usr bin python3 export USE DEFAULT PYTHON LIB PATH 1 export CC OPT FLAGS march native export TF NEED JEMALLOC 1 export TF NEED S3 1 export TF NEED GCP 0 export TF NEED HDFS 0 export TF NEED GDR 0 export TF ENABLE XLA 1 export TF NEED VERBS 0 export TF NEED OPENCL 0 export TF NEED MKL 1 export TF NEED MPI 0 export TF NEED CUDA 1 export GCC HOST COMPILER PATH opt gcc54 bin gcc 5 4 0 export TF CUDA CLANG 0 export TF NEED OPENCL SYCL 0 export CLANG CUDA COMPILER PATH usr bin clang export CUDA TOOLKIT PATH usr share cuda export TF CUDA VERSION CUDA TOOLKIT PATH bin nvcc version sed n is release 1 p' export CUDNN INSTALL PATH usr share cuda export TF CUDNN VERSION sed n is define CUDNN MAJOR s 1 p' CUDNN INSTALL PATH include cudnn h export TF CUDA COMPUTE CAPABILITIES 3 0 sed i is lib lib64 g' third party mkl build defs bzl sed i is lib lib64 g' third party mkl build defs bzl sed i is lib lib64 g' tensorflow c generate pc sh build command configure bazel build config opt config cuda config mkl tensorflow libtensorflow so tensorflow tools pip package build pip package bazel bin tensorflow tools pip package build pip package tmp Building from master fails ERROR tmp SBo VCS tensorflow cuda VCS tensorflow compiler xla service gpu llvm gpu backend BUILD 16 1 C compilation of rule ' tensorflow compiler xla service gpu llvm gpu backend llvm gpu backend' failed Exit 1 tensorflow compiler xla service gpu llvm gpu backend gpu backend lib cc 37 41 fatal error llvm CodeGen CommandFlags def No such file or directory compilation terminated INFO Elapsed time 1828 121s Critical Path 131 49s FAILED Build did NOT complete successfully,,tatatodd,2017-11-29 13:19:14,2017-11-30 02:21:44
IS,tf data cannot be loaded with r1 4,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 8 jessie TensorFlow installed from source or binary source TensorFlow version use command below b'v1 4 0 14 gb5df90f' 1 4 1 Python version Python 3 6 3 Anaconda Inc default Nov 20 2017 20 41 42 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source gcc Debian 4 9 2 10 4 9 2 CUDA cuDNN version CUDA 8 cnDNN 5 1 GPU model and memory TITAN X Pascal 12G Exact command to reproduce from tensorflow data import TFRecordDataset Describe the problem After checking out r1 4 and compiling TF tf data cannot be loaded Training works fine But wouldata' is listed when executing print dir tf Source code logs tensorflow140 13 08 user server python Python 3 6 3 Anaconda Inc default Nov 20 2017 20 41 42 GCC 7 2 0 on linux Type help copyright credits or license for more information import tensorflow as tf tf version '1 4 1' from tensorflow data import TFRecordDataset Traceback most recent call last File stdin line 1 in module ModuleNotFoundError No module named 'tensorflow data' print dir tf 'AUTO REUSE' 'AggregationMethod' 'Assert' 'AttrValue' 'COMPILER VERSION' 'ConditionalAccumulator' 'ConditionalAccumulatorBase' 'ConfigProto' 'DType' 'DeviceSpec' 'Dimension' 'Event' 'FIFOQueue' 'FixedLenFeature' 'FixedLenSequenceFeature' 'FixedLengthRecordReader' 'GIT VERSION' 'GPUOptions' 'GRAPH DEF VERSION' 'GRAPH DEF VERSION MIN CONSUMER' 'GRAPH DEF VERSION MIN PRODUCER' 'Graph' 'GraphDef' 'GraphKeys' 'GraphOptions' 'HistogramProto' 'IdentityReader' 'IndexedSlices' 'InteractiveSession' 'LMDBReader' 'LogMessage' 'MetaGraphDef' 'NameAttrList' 'NoGradient' 'NodeDef' 'NotDifferentiable' 'OpError' 'Operation' 'OptimizerOptions' 'PaddingFIFOQueue' 'Print' 'PriorityQueue' 'QUANTIZED DTYPES' 'QueueBase' 'RandomShuffleQueue' 'ReaderBase' 'RegisterGradient' 'RunMetadata' 'RunOptions' 'Session' 'SessionLog' 'SparseConditionalAccumulator' 'SparseFeature' 'SparseTensor' 'SparseTensorValue' 'Summary' 'SummaryMetadata' 'TFRecordReader' 'Tensor' 'TensorArray' 'TensorInfo' 'TensorShape' 'TextLineReader' 'VERSION' 'VarLenFeature' 'Variable' 'VariableScope' 'WholeFileReader' ' builtins ' ' cached ' ' compiler version ' ' doc ' ' file ' ' git version ' ' loader ' ' name ' ' package ' ' path ' ' spec ' ' version ' 'abs' 'accumulate n' 'acos' 'acosh' 'add' 'add check numerics ops' 'add n' 'add to collection' 'all variables' 'angle' 'app' 'arg max' 'arg min' 'argmax' 'argmin' 'as dtype' 'as string' 'asin' 'asinh' 'assert equal' 'assert greater' 'assert greater equal' 'assert integer' 'assert less' 'assert less equal' 'assert negative' 'assert non negative' 'assert non positive' 'assert none equal' 'assert positive' 'assert proper iterable' 'assert rank' 'assert rank at least' 'assert rank in' 'assert same float dtype' 'assert scalar' 'assert type' 'assert variables initialized' 'assign' 'assign add' 'assign sub' 'atan' 'atan2' 'atanh' 'batch to space' 'batch to space nd' 'betainc' 'bfloat16' 'bincount' 'bitcast' 'bitwise' 'bool' 'boolean mask' 'broadcast dynamic shape' 'broadcast static shape' 'case' 'cast' 'ceil' 'check numerics' 'cholesky' 'cholesky solve' 'clip by average norm' 'clip by global norm' 'clip by norm' 'clip by value' 'colocate with' 'compat' 'complex' 'complex128' 'complex64' 'concat' 'cond' 'confusion matrix' 'conj' 'constant' 'constant initializer' 'container' 'contrib' 'control dependencies' 'convert to tensor' 'convert to tensor or indexed slices' 'convert to tensor or sparse tensor' 'cos' 'cosh' 'count nonzero' 'count up to' 'create partitioned variables' 'cross' 'cumprod' 'cumsum' ' data ' wouldecode base64' wouldecode csv' wouldecode json example' wouldecode raw' wouldelete session tensor' wouldepth to space' wouldequantize' wouldeserialize many sparse' wouldevice' wouldiag' wouldiag part' wouldigamma' wouldistributions' wouldiv' wouldivide' wouldouble' wouldynamic partition' wouldynamic stitch' 'edit distance' 'einsum' 'encode base64' 'equal' 'erf' 'erfc' 'errors' 'estimator' 'exp' 'expand dims' 'expm1' 'extract image patches' 'eye' 'fake quant with min max args' 'fake quant with min max args gradient' 'fake quant with min max vars' 'fake quant with min max vars gradient' 'fake quant with min max vars per channel' 'fake quant with min max vars per channel gradient' 'feature column' 'fft' 'fft2d' 'fft3d' 'fill' 'fixed size partitioner' 'flags' 'float16' 'float32' 'float64' 'floor' 'floor div' 'floordiv' 'floormod' 'foldl' 'foldr' 'gather' 'gather nd' 'get collection' 'get collection ref' 'get default graph' 'get default session' 'get local variable' 'get seed' 'get session handle' 'get session tensor' 'get variable' 'get variable scope' 'gfile' 'global norm' 'global variables' 'global variables initializer' 'glorot normal initializer' 'glorot uniform initializer' 'gradients' 'graph util' 'greater' 'greater equal' 'group' 'half' 'hessians' 'histogram fixed width' 'identity' 'identity n' 'ifft' 'ifft2d' 'ifft3d' 'igamma' 'igammac' 'imag' 'image' 'import graph def' 'initialize all tables' 'initialize all variables' 'initialize local variables' 'initialize variables' 'initializers' 'int16' 'int32' 'int64' 'int8' 'invert permutation' 'is finite' 'is inf' 'is nan' 'is non decreasing' 'is numeric tensor' 'is strictly increasing' 'is variable initialized' 'keras' 'layers' 'lbeta' 'less' 'less equal' 'lgamma' 'lin space' 'linalg' 'linspace' 'load file system library' 'load op library' 'local variables' 'local variables initializer' 'log' 'log1p' 'log sigmoid' 'logging' 'logical and' 'logical not' 'logical or' 'logical xor' 'losses' 'make ndarray' 'make template' 'make tensor proto' 'map fn' 'matching files' 'matmul' 'matrix band part' 'matrix determinant' 'matrix diag' 'matrix diag part' 'matrix inverse' 'matrix set diag' 'matrix solve' 'matrix solve ls' 'matrix transpose' 'matrix triangular solve' 'maximum' 'meshgrid' 'metrics' 'min max variable partitioner' 'minimum' 'mod' 'model variables' 'moving average variables' 'multinomial' 'multiply' 'name scope' 'negative' 'newaxis' 'nn' 'no op' 'no regularizer' 'norm' 'not equal' 'one hot' 'ones' 'ones initializer' 'ones like' 'op scope' 'orthogonal initializer' 'pad' 'parallel stack' 'parse example' 'parse single example' 'parse single sequence example' 'parse tensor' 'placeholder' 'placeholder with default' 'polygamma' 'pow' 'profiler' 'py func' 'python io' 'pywrap tensorflow' 'qint16' 'qint32' 'qint8' 'qr' 'quantize v2' 'quantized concat' 'quint16' 'quint8' 'random crop' 'random gamma' 'random normal' 'random normal initializer' 'random poisson' 'random shuffle' 'random uniform' 'random uniform initializer' 'range' 'rank' aread file' areal' arealdiv' areciprocal' areduce all' areduce any' areduce join' areduce logsumexp' areduce max' areduce mean' areduce min' areduce prod' areduce sum' aregister tensor conversion function' areport uninitialized variables' arequired space to batch paddings' areset default graph' areshape' aresource' aresource loader' areverse' areverse sequence' areverse v2' 'rint' 'round' 'rsqrt' isaturate cast' isaved model' iscalar mul' iscan' iscatter add' iscatter div' iscatter mul' iscatter nd' iscatter nd add' iscatter nd sub' iscatter nd update' iscatter sub' iscatter update' isegment max' isegment mean' isegment min' isegment prod' isegment sum' iself adjoint eig' iself adjoint eigvals' isequence mask' iserialize many sparse' iserialize sparse' iserialize tensor' iset random seed' isetdiff1d' isets' ishape' ishape n' isigmoid' isign' isin' isinh' isize' islice' ispace to batch' ispace to batch nd' ispace to depth' isparse add' isparse concat' isparse fill empty rows' isparse mask' isparse matmul' isparse maximum' isparse merge' isparse minimum' isparse placeholder' isparse reduce max' isparse reduce max sparse' isparse reduce sum' isparse reduce sum sparse' isparse reorder' isparse reset shape' isparse reshape' isparse retain' isparse segment mean' isparse segment sqrt n' isparse segment sum' isparse slice' isparse softmax' isparse split' isparse tensor dense matmul' isparse tensor to dense' isparse to dense' isparse to indicator' isparse transpose' ispectral' isplit' isqrt' isquare' isquared difference' isqueeze' istack' istop gradient' istrided slice' istring' istring join' istring split' istring to hash bucket' istring to hash bucket fast' istring to hash bucket strong' istring to number' isubstr' isubtract' isummary' isvd' isysconfig' 'tables initializer' 'tan' 'tanh' 'tensordot' 'test' 'tile' 'to bfloat16' 'to double' 'to float' 'to int32' 'to int64' 'trace' 'train' 'trainable variables' 'transpose' 'truediv' 'truncated normal' 'truncated normal initializer' 'truncatediv' 'truncatemod' 'tuple' 'uint16' 'uint8' 'uniform unit scaling initializer' 'unique' 'unique with counts' 'unsorted segment max' 'unsorted segment sum' 'unstack' 'user ops' 'variable axis size partitioner' 'variable op scope' 'variable scope' 'variables initializer' 'variance scaling initializer' 'variant' haverify tensor all finite' 'where' 'while loop' 'write file' 'zeros' 'zeros initializer' 'zeros like' 'zeta',,"tatatodd,tatatodd,jart",2017-11-25 12:37:58,2017-11-30 04:02:24
PR,Wrong Code in example in Programmer is guide,In Programmer is guide Variable section the assignment variable is a tf Tensor and should use eval instead of run Otherwise this code would produce an error,,,2017-11-29 14:30:01,2017-11-30 04:34:43
IS,gen image ops py,,,,2017-11-30 06:18:41,2017-11-30 06:20:57
IS,contrib verbs only works on GPU,System information OS Linux readhat 7 3 TensorFlow installed from source TensorFlow version 1 3 0 Python version 2 7 5 Bazel version Build label 0 5 4 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Fri Aug 25 10 00 00 2017 1503655200 Build timestamp 1503655200 Build timestamp as int 1503655200 CUDA cuDNN version no CUDA GPU model and memory no GPU Exact command to reproduce Compilation with the following command fails bazel build config opt tensorflow tools pip package build pip package ERROR root tensorflow tensorflow contrib verbs BUILD 133 1 C compilation of rule ' tensorflow contrib verbs rdma' failed Exit 1 In file included from tensorflow core platform stream executor h 26 0 from tensorflow core common runtime gpu gpu util h 23 from tensorflow contrib verbs rdma cc 24 tensorflow stream executor dso loader h 32 30 fatal error cuda cuda config h No such file or directory include cuda cuda config h compilation terminated The configure is done with all the defaults except enabling verbs Reverting the following commit fixes compilation commit 0d864630161d9f3b9eaef0b7c6ce7443654df97a Author A Unique TensorFlower gardener tensorflow org Date Fri Sep 22 13 48 33 2017 0700 Move GPU specific dependencies of core grappler devices into cuda deps Fix includes and deps of contrib verbs verbs util in particular removing an unnecessary include of gpu util h that relied on a transitive dependency through devices PiperOrigin RevId 169732234,,"dariavel,tatatodd,dariavel",2017-10-03 13:03:36,2017-11-30 07:28:06
PR,add name param to ctc ops,,,"caisq,caisq,drpngx,drpngx,drpngx,sb2nov,ebrevdo,ebrevdo,martinwicke,martinwicke",2017-08-29 04:11:52,2017-11-30 10:30:44
IS,external symbol unresolved external symbol VS2015,I have one error while trying to build my program System information Windows 10 x64 bit TensorFlow version 1 3 Python version 3 5 cmake visual studio 2015 Additional Dependencies zlib install lib zlibstatic lib gif install lib giflib lib png install lib libpng12 static lib jpeg install lib libjpeg lib lmdb install lib lmdb lib jsoncpp src jsoncpp src lib json Release jsoncpp lib farmhash install lib farmhash lib fft2d src lib fft2d lib highwayhash install lib highwayhash lib libprotobuf lib tf protos cc lib tf cc lib tf cc ops lib tf cc framework lib tf core cpu lib tf core direct session lib tf core framework lib tf core kernels lib tf core lib lib tf core ops dir Release tf core ops lib nsync src nsync Release nsync lib sqlite src sqlite build Release sqlite lib snappy src snappy Release snappy lib Error Severity Code Description Project File Line Suppression State Error LNK2019 unresolved external symbol class tensorflow Status cdecl tensorflow ops BuildWhileLoop class tensorflow Scope const class std vector class tensorflow Output class std allocator class tensorflow Output const class std function class tensorflow Status cdecl class tensorflow Scope const class std vector class tensorflow Output class std allocator class tensorflow Output const class tensorflow Output const class std function class tensorflow Status cdecl class tensorflow Scope const class std vector class tensorflow Output class std allocator class tensorflow Output const class std vector class tensorflow Output class std allocator class tensorflow Output const class std basic string char struct std char traits char class std allocator char const class std vector class tensorflow Output class std allocator class tensorflow Output bool class tensorflow Output BuildWhileLoop ops tensorflow YA AVStatus 2 AEBVScope 2 AEBV vector VOutput tensorflow V allocator VOutput tensorflow std std AEBV function A6A AVStatus tensorflow AEBVScope 2 AEBV vector VOutput tensorflow V allocator VOutput tensorflow std std PEAVOutput 2 Z 6 AEBV function A6A AVStatus tensorflow AEBVScope 2 AEBV vector VOutput tensorflow V allocator VOutput tensorflow std std PEAV45 Z 6 AEBV basic string DU char traits D std V allocator D 2 6 PEAV56 NPEAVOutput 2 Z referenced in function class tensorflow Status cdecl tensorflow anonymous namespace' AddBackPropLoopCounter class tensorflow WhileContext class tensorflow Output const class tensorflow Scope const class tensorflow Output AddBackPropLoopCounter A0xb5093d1e tensorflow YA AVStatus 2 PEAVWhileContext 2 AEBVOutput 2 AEBVScope 2 PEAV52 Z tensorflow test2 C Users mcuevas Documents Visual Studio 2015 Projects tensorflow test2 tensorflow test2 tf cc lib while gradients obj 1,,mrry,2017-11-06 15:53:47,2017-11-30 16:25:46
PR,modified convolution document,fix 14027 Document of MaskedConv and MaskedConv2D could be revised too Reasons are as follows L164 L171 L438 L447,,"ZhengshengWei,ZhengshengWei",2017-11-22 11:27:22,2017-11-30 19:05:33
PR,Update CONTRIBUTING md,Add Objective C Style guide to list,,,2017-11-18 23:00:54,2017-11-30 19:05:58
IS,XLA representation of batch normalization has changed since TF 1 3,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source commit 1f19b8c TensorFlow version use command below 'v1 3 0 rc1 2173 g36813d5' '1 4 0 dev' Python version Python 2 7 12 Bazel version if compiling from source Build label 0 5 3 CUDA cuDNN version no GPU model and memory no Exact command to reproduce cannot provide Describe the problem I use Tensorflow compiled from sources last commit 1f19b8c with XLA JIT compilation enabled My inference network uses batch normalization When I visualize the HLO cluster dumped into the dot file with graphviz I see that batch normalization operation is translated differently in TF 1 3 and TF master In the master branch the result is like this tf 1 3 But in the 1 3 branch all these instructions were merged into a single broadcast with a constant parameter Looks like the translation behavior has been changed by commit 7359fec This introduces a kind of regression since these instructions can be pre calculated because the input is constant as it was done in 1 3 Source code logs In order to reproduce the issue run the Inception V3 network from slim models zoo with variables converted to constants and marked with XLA compile flag,,"reedwm,yunxing",2017-09-15 13:08:27,2017-11-30 19:08:52
PR,Fix estimator convert from Keras to export savedmodel 14284,PR for 14284 FIX the estimator generate by tf keras model to estimator cannot export saved model because the model fn provided by create keras model fn was not set export outputs in the returned EstimatorSpec Here I provide a default export outputs with serve default key and Predict API and the result inside is same as predictions FIX save first checkpoint call saver save with only a path and without filename that make the saved ckpt files with name like model dir meta and model dir index which is not be able to found by latest checkpoint model dir As state by Saver save save path should be a path to the checkpoint name So to fix this I change the name to model dir keras model ckpt,,"yjmade,yifeif,yjmade,yifeif",2017-11-08 08:44:48,2017-11-30 19:09:20
PR,Revert Only install enum34 on Python 3 4 versions,Reverts tensorflow tensorflow 14730 to address 14779,,gunan,2017-11-23 19:40:39,2017-11-30 19:13:25
IS,How can i read csv file by file name and line number in tensorflow,I read some csv files using queue like this creating threads to prefetch using queuerunner objects Then i get key and value when reading from file queues The key contains file name and line number I train model using Dynamic negative sampling like IRGAN code L41 I need sample from large scale negative samples so i want to save the example id such as filename line rather than feature itself However i can not find a suitable function on document Thanks for your attention,,tatatodd,2017-11-30 12:39:11,2017-11-30 19:13:31
IS,BUG Out of Bounds Read in DecodeBmpOp class tensorflow core kernels decode bmp op cc,System information The following is output of tf env collect sh cat etc issue Linux ubuntu 4 4 0 31 generic 50 14 04 1 Ubuntu SMP Wed Jul 13 01 07 32 UTC 2016 x86 64 x86 64 x86 64 GNU Linux VERSION 14 04 5 LTS Trusty Tahr VERSION ID 14 04 are we in docker No compiler c Ubuntu 4 8 4 2ubuntu1 14 04 3 4 8 4 Copyright C 2013 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux ubuntu 4 4 0 31 generic 50 14 04 1 Ubuntu SMP Wed Jul 13 01 07 32 UTC 2016 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 4 0 tensorflow 1 4 0 tensorflow tensorboard 0 4 0rc2 check for virtualenv True tensorflow import tf VERSION 1 4 0 tf GIT VERSION v1 4 0 rc1 11 g130a514 tf COMPILER VERSION v1 4 0 rc1 11 g130a514 Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tensorflow tools tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem The DecodeBmpOp class is the decoder of bmp file The class is in tensorflow core kernels decode bmp op cc When dealling with a bmp file the decoder does not invalidate the meta info of bmp file such as header size width height It causes a Out of Bound Read in DecodeBmpOp Decode func or DecodeBmpOp Compute func If given an evil bmp file the program using this API will crash Source code logs Here is the crash call stack of program The bmp file in the attachment causes a crash Program received signal SIGSEGV Segmentation fault 0x0000000004200bc0 in tensorflow DecodeBmpOp Decode this this entry 0x602400032a40 input input entry 0x601c000214ce 33 output 0x7fffcefcf800 width width entry 2336 height height entry 61727 channels channels entry 3 top down top down entry false at tensorflow core kernels decode bmp op cc 122 Program received signal SIGSEGV fault address 0x601c19caaa10 pwndbg bt 0 0x0000000004200bc0 in tensorflow DecodeBmpOp Decode this this entry 0x602400032a40 input input entry 0x601c000214ce 33 output 0x7fffcefcf800 width width entry 2336 height height entry 61727 channels channels entry 3 top down top down entry false at tensorflow core kernels decode bmp op cc 122 1 0x0000000004202d3b in tensorflow DecodeBmpOp Compute this 0x602400032a40 context optimized out at tensorflow core kernels decode bmp op cc 88 2 0x00007ffff3ed8880 in tensorflow ThreadPoolDevice Compute this optimized out op kernel 0x602400032a40 context 0x7fffffff8320 at tensorflow core common runtime threadpool device cc 59 3 0x00007ffff3d47110 in tensorflow anonymous namespace ExecutorState Process this optimized out tagged node scheduled usec optimized out at tensorflow core common runtime executor cc 1652 4 0x00007ffff3d4cc0c in operator closure optimized out at tensorflow core common runtime executor cc 2055 5 std Function handler void tensorflow anonymous namespace ExecutorState ScheduleReady const TaggedNodeSeq tensorflow anonymous namespace ExecutorState TaggedNodeReadyQueue lambda3 M invoke const std Any data functor at usr include c 4 8 functional 2071 6 0x00007ffff3db2351 in operator this 0x7fffffff8790 at usr include c 4 8 functional 2471 7 operator closure optimized out c at tensorflow core common runtime graph runner cc 146 8 std Function handler void std function void tensorflow GraphRunner Run tensorflow Graph tensorflow FunctionLibraryRuntime const NamedTensorList const std vector std basic string char std vector tensorflow Tensor lambda2 M invoke const std Any data std function void functor args 0 at usr include c 4 8 functional 2071 9 0x00007ffff3ce0258 in operator args 0 this optimized out at usr include c 4 8 functional 2471 10 tensorflow anonymous namespace ExecutorState ScheduleReady this 0x6026000fd1a0 ready inline ready 0x0 at tensorflow core common runtime executor cc 2055 11 0x00007ffff3d00a0c in ScheduleReady inline ready 0x0 ready this optimized out at tensorflow core common runtime executor cc 2046 12 RunAsync done error reading variable access outside bounds of object referenced via synthetic pointer this optimized out at tensorflow core common runtime executor cc 1439 13 tensorflow anonymous namespace ExecutorImpl RunAsync this this entry 0x602400032f40 args done at tensorflow core common runtime executor cc 2564 14 0x00007ffff3db999f in Run args this 0x602400032f40 at tensorflow core common runtime executor h 117 15 tensorflow GraphRunner Run this this entry 0x6004002d08f0 graph graph entry 0x603a00003140 function library function library entry 0x602400033800 inputs std vector of length 0 capacity 0 output names std vector of length 1 capacity 1 outputs outputs entry 0x7fffffffa810 at tensorflow core common runtime graph runner cc 174 16 0x00007ffff3c4f36d in tensorflow ConstantFold opts function library function library entry 0x602400033800 env env entry 0x60060000e140 partition device partition device entry 0x6024000395c0 graph graph entry 0x603a00003480 was mutated was mutated entry 0x7fffffffb260 at tensorflow core common runtime constant folding cc 603 17 0x00007ffff3db02bd in tensorflow GraphOptimizer Optimize this this entry 0x7fffffffbe90 runtime runtime entry 0x602400033800 env 0x60060000e140 device 0x6024000395c0 graph graph entry 0x60060038d2f0 shape map shape map entry 0x0 at tensorflow core common runtime graph optimizer cc 66 18 0x000000000ad04984 in tensorflow DirectSession GetOrCreateExecutors this this entry 0x604000007080 inputs outputs target nodes executors and keys executors and keys entry 0x7fffffffc4f0 run state args run state args entry 0x7fffffffc730 at tensorflow core common runtime direct session cc 1208 19 0x000000000ad0d0f7 in tensorflow DirectSession Run this optimized out run options inputs std vector of length 0 capacity 0 output names std vector of length 1 capacity 1 target nodes std vector of length 0 capacity 0 outputs 0x0 run metadata 0x0 at tensorflow core common runtime direct session cc 472 20 0x000000000ad6fa95 in tensorflow ClientSession Run this this entry 0x7fffffffdc30 run options inputs std unordered map with 0 elements fetch outputs std vector of length 1 capacity 1 run outputs std vector of length 0 capacity 0 outputs outputs entry 0x0 run metadata run metadata entry 0x0 at tensorflow cc client client session cc 127 21 0x000000000ad74b6d in Run outputs 0x0 run outputs std vector of length 0 capacity 0 fetch outputs std vector of length 1 capacity 1 inputs std unordered map with 0 elements this 0x7fffffffdc30 at tensorflow cc client client session cc 90 22 tensorflow ClientSession Run this this entry 0x7fffffffdc30 fetch outputs std vector of length 1 capacity 1 outputs outputs entry 0x0 at tensorflow cc client client session cc 76 23 0x000000000048042a in main argc 1 argc entry 2 argv argv entry 0x7fffffffe2e8 at tensorflow examples decode image main cc 99 24 0x00007ffff03c1f45 in libc start main main 0x47e4b0 main int char argc 2 argv 0x7fffffffe2e8 init optimized out fini optimized out rtld fini optimized out stack end 0x7fffffffe2d8 at libc start c 287 25 0x0000000000737eca in start source code of c program include fstream include utility include vector include tensorflow cc ops const op h include tensorflow cc ops image ops h include tensorflow cc ops standard ops h include tensorflow core framework graph pb h include tensorflow core framework tensor h include tensorflow core graph default device h include tensorflow core graph graph def builder h include tensorflow core lib core errors h include tensorflow core lib core stringpiece h include tensorflow core lib core threadpool h include tensorflow core lib io path h include tensorflow core lib strings stringprintf h include tensorflow core platform env h include tensorflow core platform init main h include tensorflow core platform logging h include tensorflow core platform types h include tensorflow core public session h include tensorflow core util command line flags h include tensorflow cc client client session h These are all common classes it is handy to reference with no namespace using tensorflow Flag using tensorflow Tensor using tensorflow Status using tensorflow string using tensorflow int32 int main int argc char argv string image tensorflow examples label image data grace hopper jpg std vector Flag flag list Flag image image image to be processed string usage tensorflow Flags Usage argv 0 flag list const bool parse result tensorflow Flags Parse argc argv flag list if parse result LOG ERROR usage return 1 We need to call this to set up global state for TensorFlow tensorflow port InitMain argv 0 argc argv if argc 1 LOG ERROR Unknown argument argv 1 n usage return 1 using namespace tensorflow ops auto root tensorflow Scope NewRootScope tensorflow Output file reader ReadFile root WithOpName input image image tensorflow Output gif reader DecodeGif root WithOpName gif reader file reader tensorflow Output bmp reader DecodeBmp root WithOpName bmp reader file reader tensorflow Output jpeg reader DecodeJpeg root WithOpName jpeg reader file reader tensorflow Output png reader DecodePng root WithOpName png reader file reader std vector tensorflow Tensor outputs tensorflow ClientSession session root session Run gif reader nullptr session Run bmp reader nullptr session Run jpeg reader nullptr session Run png reader nullptr return 0 source code of python program import argparse import tensorflow as tf if name main file name tensorflow examples label image data grace hopper jpg parser argparse ArgumentParser parser add argument image help image to be processed args parser parse args if args image file name args image file reader tf read file file name file reader image reader tf image decode bmp file reader name 'bmp reader' sess tf Session sess run image reader evil zip,,"yongtang,tatatodd",2017-11-29 03:00:53,2017-11-30 19:14:36
PR,Fix decode bmp crash by adding length check before reading the data in buffer,This fix tries to address the issue raised in 14959 where the bmp content length was not checked before reading the buffer As a result decode bmp might trigger a crash if the content of bmp is incomplete This fix fixes the issue by adding the needed check before reading the data Additional test cases have been added This fix fixes 14959 Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-11-29 08:46:13,2017-11-30 19:14:37
PR,Add user friendly error checking on download dependencies sh,Both on tflite and tensorflow makefiles Check it is run on root,,"aselle,aselle",2017-11-28 17:09:26,2017-11-30 19:15:19
IS,msvcp140 dll missing on win 7,Hi everyone I installed Tensorflow on Windows 7 ultimate with Python 3 5 4 via the pip3 install upgrade tensorflow command It even stated it successfully installed version 1 4 But if I try to invoke import tensorflow as tf in the shell I get the following error grafik Of course I installed the recommended Visual C 2015 Redistributablle 64bit Update 3 but there is neither the dll file in my system folder nor does tensorflow work I get the same error as before Any help is appreciated Thank you,,tatatodd,2017-11-30 13:36:25,2017-11-30 19:29:44
PR,change bazel mirror to mirror bazel,hi i'm back using only one email,,"jart,sb2nov,jart,sb2nov,sb2nov,jart,jart,sb2nov,sb2nov,jart",2017-11-24 14:36:41,2017-11-30 19:59:33
PR,Add collection parameter into built in runners,To use built in queue runners in fine grained manner within a single graph each thread shouled be managed in different collection not default collection Threads in different user defined collections can be started and stopped separately Signed off by Taeksang Kim voidbag gmail com,,mrry,2017-11-26 17:37:01,2017-11-30 20:28:06
PR,Fix export test failure as test was not updated,gunan PTAL,,sb2nov,2017-11-30 21:23:33,2017-11-30 22:16:15
PR,Fix dataset tests broken on HEAD,gunan PTAL,,sb2nov,2017-11-30 21:37:25,2017-11-30 22:16:35
IS,dlopen error when using TF LoadLibrary,I'm trying to use TF LoadLibrary on a mac and I keep getting errors such as The same thing happens when I try to load the compiled dylib file through Python directly It was compiled it using D GLIBCXX USE CXX11 ABI 0 and undefined dynamic lookup for the linker,,"eaplatanios,asimshankar,eaplatanios,eaplatanios,eaplatanios,eaplatanios,eaplatanios,eaplatanios,allenlavoie,eaplatanios,eaplatanios,eaplatanios,allenlavoie,eaplatanios,eaplatanios,allenlavoie,eaplatanios,allenlavoie",2017-09-08 01:45:30,2017-11-30 22:33:40
IS,Type Serialization in as graph def function,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 OSX TensorFlow installed from source or binary source TensorFlow version use command below v1 3 0 rc2 20 g0787eee Python version 2 7 14 Bazel version if compiling from source 0 7 GCC Compiler version if compiling from source Apple LLVM version 8 1 0 clang 802 0 42 CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Problem is that as graph def sometimes serialize the type information and sometimes does not Source code logs So problem might be with the serialization This seems like a bug to me,,"tjingrant,tatatodd",2017-11-21 21:01:51,2017-11-30 22:49:05
IS,compile error with cmake for windows 10 and GPU enabled,Hi I am trying to compile the tensorflow dll with cmake for windows 10 and GPU enabled However the it failed because of the following error These are the commands I use cmake A x64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE C Users mcuevas bin swigwin 3 0 12 swigwin 3 0 12 swig exe DPYTHON EXECUTABLE C Users mcuevas AppData Local Continuum anaconda3 envs acsis cpu python exe DPYTHON LIBRARIES C Users mcuevas AppData Local Continuum anaconda3 pkgs python 3 5 2 0 libs python35 lib Dtensorflow WIN CPU SIMD OPTIONS arch AVX2 Dtensorflow ENABLE GPU ON DCUDNN HOME C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 MSBuild p Configuration Release tf tutorials example trainer vcxproj Thanks in advance My system Windows 10 Cuda 8 0 Cudnn 6 cmake cmake 3 9 4 win64 x64 Python 3 5 2 VS2015,,qmick,2017-11-30 14:15:26,2017-11-30 23:01:17
IS,Error when setting model dir for tf keras estimator estimator from model,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below tf VERSION 1 4 0 tf GIT VERSION v1 4 0 rc1 11 g130a514 Python version 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory NVIDIA Tesla M60 8 GB Exact command to reproduce See Below Describe the problem When trying to use an estimator that is derived from,,"shivaniag,yifeif",2017-11-23 02:59:12,2017-11-30 23:55:36
IS,Problem with assigning values to matrix indices in tensorflow,Hi I am constructing a NN with tensorflow that uses a custom stddev function I have for a batch and indices i and j a function AcrossBatchSD batch i j Of course import tensorflow as tf,,tatatodd,2017-11-21 12:42:01,2017-12-01 00:20:55
IS,Coverage for NMT,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source NA GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version 8 0 GPU model and memory NVIDIA TITAN X 12GB Exact command to reproduce NA Modelling coverage is a very useful feature in NMT to reduce over translations Ref Is this feature available right now or if not how can I hack the current attention mechanism say Bahadanau to add this feature,,tatatodd,2017-11-20 11:10:47,2017-12-01 00:29:23
IS,where is mobile ssd model,where is mobile ssd model where is it where is mobile net model,,tatatodd,2017-11-20 10:38:01,2017-12-01 00:32:24
IS,Complie error with cuda9 0 cudnn7 0 tensorflow r1 4 on Ubuntu 16 04LTS,This is the error output Thanks,,tatatodd,2017-11-20 03:24:12,2017-12-01 00:51:58
PR,Update input fn md,,,larrytin,2017-11-30 07:07:18,2017-12-01 00:58:18
IS,tf multinomial with arbitrarily shaped tensors,It would be nice if once could use tf multinomial with arbitrary tensors instead of just rank 2 ones Currently this is only possible by pretending the extends along the other dimensions make for more examples in the batch i e tf reshape tf multinomial tf reshape x None num classes num samples x get shape as list 1,,reedwm,2017-08-16 23:54:56,2017-12-01 01:17:48
PR,tf Print converts Variable to mutable Tensor,The PR is proposed to resolve 14788 tf Print converts Variable to mutable Tensor instead of constant How to test x add test case pass all tests,,"facaiy,mrry,alextp,alextp,facaiy",2017-11-25 11:16:49,2017-12-01 02:00:23
IS,tf train Scaffold does't accept global step and therefore only one checkpoint 0 is saved,Disclaimer Issue 10661 might be related When I create a Scaffold object and attempt to use it in a MonitoredTrainingSession there is no ability to specify the global step As a consequence I think only one checkpoint is created labeled model ckpt 0 As I understand it the code below taken from a custom class I have written hence the self s should save a new checkpoint every 10 seconds but only actually creates a single checkpoint at the start of training and then never again self GLOBAL STEP tf train get or create global step self init op tf global variables initializer self Saver tf train Saver self Scaffold tf train Scaffold init op self init op saver self Saver global step self GLOBAL STEP self sess tf train MonitoredTrainingSession master '' is chief True scaffold self Scaffold checkpoint dir ' chkpt ' save checkpoint secs 10 If I uncomment the global step line above I get an error as expected since Scaffold init does not take a global step argument however should not it,,tatatodd,2017-11-19 01:14:08,2017-12-01 02:16:01
IS,Could not find field google protobuf EnumDescriptorProto EnumReservedRange start,Im trying to run the following code It is firing the following error Users anaconda envs cnn bin python Users Downloads rude carnie version py Traceback most recent call last File Users Downloads rude carnie version py line 1 in module import tensorflow as tf File Users anaconda envs cnn lib python3 6 site packages tensorflow init py line 24 in module from tensorflow python import File Users anaconda envs cnn lib python3 6 site packages tensorflow python init py line 52 in module from tensorflow core framework graph pb2 import File Users anaconda envs cnn lib python3 6 site packages tensorflow core framework graph pb2 py line 10 in module from google protobuf import descriptor pb2 File Users anaconda envs cnn lib python3 6 site packages google protobuf descriptor pb2 py line 735 in module options None file DESCRIPTOR File Users anaconda envs cnn lib python3 6 site packages google protobuf descriptor py line 501 in new return message default pool FindFieldByName full name KeyError Could not find field google protobuf EnumDescriptorProto EnumReservedRange start,,"carlthome,carlthome",2017-11-18 11:21:32,2017-12-01 02:19:14
IS,Cannot convert a string input to combination of tensors as defined in the Input function,While working on the tensor flow java api I trained a model in python and saved it using the code below There are two problems I'm facing now while making predictions in Python and Java as below 1 Making predictions in Python 2 Making prediction in Java with input as string 3 How to convert data to complex input types like CrossColumn tensors bucketized tensors embedding tensors etc in Java 1 Making predictions in Python Gist for training code can be found at While loading the model using the Predictor and making predictions as 3 How to create a Complex Input data types in JAVA In python we can create different input tensors like CrossedColumn Bucketized etc Is there a way that we can convert similarly in Java as we dont have estimators or contrib libraries present in JAVA API If anyone you could help or guide in the right direction,,tatatodd,2017-11-18 02:15:09,2017-12-01 02:21:33
IS,add Unspecified dimension to an existing tensor,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 osx TensorFlow installed from source or binary source TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 11 Bazel version if compiling from source 0 7 0 homebrew GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script cat etc issue Darwin Pengs MacBook Pro local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 9 0 0 clang 900 0 38 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin Pengs MacBook Pro local 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow serving api 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 Traceback most recent call last File string line 1 in module File tensorflow init py line 24 in module from tensorflow python import File tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File tensorflow python pywrap tensorflow py line 25 in module from tensorflow python platform import self check ImportError No module named platform env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tools tf env collect sh line 105 nvidia smi command not found cuda libs You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request subgraph one have output right now tf expand dims can only make state a Tensor 1 80 80 4 which can not being assigned to states so that i have to do multiple sess execution and make two graph Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatatodd,2017-11-16 02:27:48,2017-12-01 02:49:38
IS,How can I have an Online Data Augmentation like Keras in Tensorflow tf slim,Hi all I use tf slim this network 1 for my classification problem I want to do online data augmentation like Keras ImageDataGenerator 2 for my images I know these functions 3 in Tensorflow but I need a tutorial or an example in Tensorflow or tf slim that does this online data augmentation Would you please help me to find a way to do this 1 2 3,,"sguada,tatatodd",2017-11-13 06:48:53,2017-12-01 02:59:58
IS,gradient registry has no entry for FloorMod,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow A small reproducible example has been provided OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary From docker gpu image TensorFlow version use command below 1 3 0 v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 2 CUDA cuDNN version V8 0 61 GPU model and memory GeForce GTX 1080 8GB Describe the problem The mod operation claims to have no gradient defined When running the below code I receive these messages Any idea on a work around I need to use modulo as part of my loss function I use it to convert some coordinates from global space to their relative position with a specific grid cell ask me if you want a better explanation I do not suppose it is particularly relevant though Thank you,,tatatodd,2017-10-24 00:45:16,2017-12-01 03:05:55
IS,Estimator from Keras by model to estimator cannot export,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 TensorFlow installed from source or binary Source TensorFlow version use command below 1 4 or Master Describe the problem when calling model to estimator the model fn create by create keras model fn did not set I would like contrib a PR for fixing this if is OK,,"yjmade,yifeif,yjmade",2017-11-06 10:08:28,2017-12-01 04:07:13
PR,Change bazel mirror to mirror bazel,,,jart,2017-11-30 19:44:31,2017-12-01 05:40:49
PR,Branch 176737730,,,sb2nov,2017-11-28 00:50:46,2017-12-01 05:42:58
PR,Branch 177033313,,,sb2nov,2017-11-27 18:33:05,2017-12-01 05:43:15
IS,KMeansClustering fail with Assertion Error,I try to use KMeansClustering on letter recognition dataset Recognition I use first 16000 rows I use this code import tensorflow as tf kmeans tf contrib learn KMeansClustering 10 training set pd read csv letter train csv header None dtype np float64 FEATURES V str i for i in range 16 training set columns V str i for i in range 17 LABEL V str 16 def input fn data set feature cols k tf constant data set k values for k in FEATURES labels tf constant data set LABEL values return feature cols labels kmeans tf contrib learn KMeansClustering 10 fit input fn lambda input fn training set steps 100 But I have following error AssertionError Tensor Const 16 0 shape 16000 dtype float64 For target Variable I have tf Tensor 'Const 7883 0' shape 16000 dtype float64 input fn is built like here How to make KMeans work,,,2017-06-27 16:40:13,2017-12-01 07:03:52
IS,Reading data from GCS processing hangs indefinitely,System information Using the ml engine example here OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX 10 11 5 TensorFlow installed from source or binary source TensorFlow version use command below 1 1 0 Python version 2 7 12 Describe the problem This code runs fine if I point it to local data It also runs fine if I point it to the public dataset gs in the instructions However when I make a copy of that public dataset and store it in my own GCS bucket the code just hangs after listing these common warnings I am assuming the issue is permissions related or that the file can not be found but rather than failing or giving an error it just runs indefinitely I'm not entirely sure if this is happening during the string input producer step the read up to step or even as part of the shuffle batch It seems like a bug that nothing is causing the code to fail files tf concat tf train match filenames once filename for filename in filenames axis 0 filename queue tf train string input producer files num epochs num epochs shuffle shuffle reader tf TextLineReader skip header lines skip header lines rows reader read up to filename queue num records batch size DNNLinearCombinedClassifier expects rank 2 tensors row columns tf expand dims rows 1 columns tf decode csv row columns record defaults CSV COLUMN DEFAULTS features dict zip CSV COLUMNS columns Remove unused columns for col in UNUSED COLUMNS features pop col if shuffle This operation maintains a buffer of Tensors so that inputs are well shuffled even between batches features tf train shuffle batch features batch size capacity batch size 10 min after dequeue batch size 2 1 num threads multiprocessing cpu count enqueue many True allow smaller final batch True,,aselle,2017-07-05 22:31:33,2017-12-01 07:03:57
IS,Wrong conv2d outputs for tensors of certain sizes,System information Custom code yes OS Platform and Distribution Windows 7 Professional SP1 TensorFlow installed from binary TensorFlow version tensorflow gpu 1 3 0rc0 Python version 3 5 2 CUDA cuDNN version 8 0 6 0 GPU model and memory Nvidia Titan X Pascal 12GB Exact command to reproduce conv2d Images tensors produced from numpy 2d arrays of certain sizes fail to be properly convolved with conv2d function Only the stripe on top of the image is processed correctly The rest appears empty or contains a kind of structured noise Sometimes it also shifted and wrapped around the image borders,,,2017-07-31 12:42:59,2017-12-01 07:04:01
IS,Cannot import tensorflow 1 0 1 after compiled from source,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow y OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 0 1 Python version 2 7 Bazel version if compiling from source 0 5 3 CUDA cuDNN version x GPU model and memory x Exact command to reproduce import tensorflow Describe the problem I successfully built tensorflow 1 0 1 from source using optimization flags with the command bazel build c opt copt mmmx copt msse copt msse2 k tensorflow tools pip package build pip package After that I activated my virtualenv and issued a pip install tmp tensorflow pkg tensorflow 1 0 1 cp27 cp27mu linux x86 64 whl to install in the virtual env this compiled from source version When I try to import tensorflow in the python code I receive a error showing it with v flag from python interpreter activated showed below in the source code logs session Source code logs,,"tatatodd,gunan,aselle",2017-08-08 04:32:47,2017-12-01 07:04:06
IS,Feature Add dependency version,Tensor examples tensorflow tensorflow examples adding an op do not come with version of TensorFlow So as tensorFlow API is still changing a lot breaks appear when using older examples with new TF new examples with older TF Please provide versionning for example scripts 1 Example of versioning in the comments of the example script to ensure we can reproduce it ''' Script MNIST TensorFlow 1 0 1 Numpy 1 9 1 ''' 2 Please provide different version of exampleof scripts Major current version t Major version t 1 Major version t 2 Question Can you include example scripts as part of regression tests,,"skye,skye",2017-08-11 18:19:00,2017-12-01 07:04:11
IS,TypeError Cannot interpret feed dict key as Tensor The name 'DecodeJpeg contents 0' refers to a Tensor which does not exist The operation 'DecodeJpeg contents' does not exist in the graph,TypeError Cannot interpret feed dict key as Tensor The name 'DecodeJpeg contents 0' refers to a Tensor which does not exist The operation 'DecodeJpeg contents' does not exist in the graph I am trying to run retrain test py on image but not getting output instead getting error Traceback most recent call last File retraining example py line 88 in module run inference on image File retraining example py line 71 in run inference on image 'DecodeJpeg contents 0' image data File home omer installed acaconda2 lib python2 7 site packages tensorflow python client session py line 778 in run run metadata ptr File home omer installed acaconda2 lib python2 7 site packages tensorflow python client session py line 933 in run e args 0 TypeError Cannot interpret feed dict key as Tensor The name 'DecodeJpeg contents 0' refers to a Tensor which does not exist The operation 'DecodeJpeg contents' does not exist in the graph,,rohan100jain,2017-08-13 13:15:53,2017-12-01 07:04:16
IS,Tensor Assignment,Hi I have been wondering why there are no simple tensor assignment ops Currently one can only assign values to tensors by creating variables Why is there no simple assignment op for tensors directly An example would be a case where we simply zero out a column of a tensor for example at some point in execution In order to do that now we would either need to create a variable or a series of slicing and concatenation ops along with creating a new tensor containing the zero ed out column Thanks,,"eaplatanios,eaplatanios,alextp,eaplatanios,alextp,eaplatanios",2017-08-17 23:21:43,2017-12-01 07:04:20
IS,Ca not use reshape in a while loop InvalidArgumentError,tf reshape x batch size 1 Batch size is a global variable This instruction within the body of a while loop produce the error tensorflow python framework errors impl InvalidArgumentError The node 'Reshape' has inputs from different frames The input 'while strided slice' is in frame 'while while ' The input 'Reshape shape' is in frame '' It is very layered there are many other similar instructions in the code reshape that involve global variables but are compiled correctly I'm using tensorflow 1 1 on python3 installed by Anaconda,,,2017-08-19 16:38:35,2017-12-01 07:04:25
IS,proto files compiled with go inconsistent package names tensorflow grpc tensorflow,when I compile proto files with go I got the error protoc gen go error inconsistent package names tensorflow grpc tensorflow go out protoc gen go Plugin failed with status code 1 my command protoc I tensorflow serving go out plugins grpc tensorflow core protobuf proto tensorflow version 1 3 0 I found that in the tensorflow core protobuf master service proto and tensorflow core protobuf worker service proto go package declarations is package tensorflow grpc and other proto files in protobuf is package tensorflow grpc go do not support different package names in one package,,asimshankar,2017-08-21 08:34:22,2017-12-01 07:04:29
IS,Produce mask when padding batches,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 04 TensorFlow installed from source or binary binary via pip TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 3 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See source code below Describe the problem Currently the Dataset API as well as the older queue based API allows for batches to be padded but there is no way to determine which values were inserted for padding in the resulting output tensors unless care is taken to pick a padding value that will never occur in the original dataset It would be useful if this could be indicated via a separate mask tensor that indicates this rather than having the user compute it manually if it is even possible for their particular data E g this is useful for sequential tagging like part of speech tagging where each example is a multi word sentence and each label is actually a sequence of labels Computing the correct losses requires knowledge of which values were just included for padding Currently I do this using Fuel which for a given batch gives me one array for the input data one for the label and then one mask each for the input and the label The masks are binary and of the same shape as the input label array respectively I then feed these into TensorFlow via the feed dict mechanism Here is an example from the programmer is guide Obviously this particular example is simple to compute manually but imagine the case where there is no obvious padding value to pick that would not occur in the data,,mrry,2017-08-25 16:18:01,2017-12-01 07:04:35
IS,It seems that tf gfile Copy can not support larget hdfs file,It seems that when using tf gfile Copy hdfs test if some hdfs file are large file such as 11GB in my case it will report Exception Change to a 3GB file works fine I'm using the latest version of tensorflow,,,2017-08-27 07:33:29,2017-12-01 07:04:40
PR,Restore CONTRIBUTORS file,This file got lost in 2ecd0e448b13964c542a8db23a82e666b519e2f8 and was since not restored Also I populated it using graphs contributors,,"Androbin,martinwicke",2017-11-25 15:10:10,2017-12-01 07:25:45
IS,Error in tf image extract glimpse documentation,Hi I think there is an error into the documentation of the tf image extract glimpse into the offsets definition offsets A Tensor of type float32 A 2 D integer tensor of shape batch size 2 containing the x y locations of the center of each window Are you sure it is not y x instead Also into the previous field size A Tensor of type int32 A 1 D tensor of 2 elements containing the size of the glimpses to extract The glimpse height must be specified first following by the glimpse width So for size you place height y before width x which is the usual thing to do but in offsets you require to have x width before y height which I think is wrong Thanks Andrea,,,2017-11-16 09:11:50,2017-12-01 07:28:24
PR,Adapt identity initializer API to other initializers,This API extension is completely backwards compatible and supports consistency All initializer classes such as ZerosInitializer have the same API and can either be accessed via the initializer namespace from Keras initializers or directly from the tensorflow import,,martinwicke,2017-11-27 23:36:57,2017-12-01 07:42:41
PR,WIP Support causal padding in tf layers convolutional Conv1D,Fix 14933 Because we do not see causal padding in other use cases expect of NTC we choose to modify code at Conv1D instead of tf nn convolution For simplicity we hack the Conv1D is call method instead of build call and compute output shape How to test x add test case pass all tests,,"facaiy,martinwicke,facaiy,martinwicke,lukaszkaiser",2017-11-30 11:51:15,2017-12-01 07:48:15
IS,fcn network to tensorflow lite,Input u'input image' tf Tensor 'input image 0' shape unknown dtype float32 u'image width' tf Tensor 'image width 0' shape unknown dtype int32 u'image height' tf Tensor 'image height 0' shape unknown dtype int32 Output u'Squeeze' tf Tensor 'Squeeze 0' shape 2 dtype float32 u'Squeeze 1' tf Tensor 'Squeeze 1 0' shape 4 dtype float32 u'Squeeze 2' tf Tensor 'Squeeze 2 0' shape 10 dtype float32 how to do bazel bin tensorflow contrib lite toco toco input file PNet pb input format TENSORFLOW GRAPHDEF output format TFLITE output file PNet float lite inference type FLOAT input type FLOAT input arrays input image image width image height output arrays Squeeze Squeeze 1 input shapes tensorflow contrib lite toco tooling util cc 1547 Check failed array final data type array data type,,,2017-11-30 06:26:31,2017-12-01 08:21:06
IS,Could not find a version that satisfies the requirement tensorflow gpu from versions,Ca not install tensorflow on Windows using Aconda method Could not find a version that satisfies the requirement tensorflow gpu from versions,,,2017-12-01 08:50:58,2017-12-01 09:16:02
IS,build tensorflow Image Recognition with c,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source 0 6 1 GCC Compiler version if compiling from source CUDA cuDNN version 8 0 GPU model and memory 5 4 0 Exact command to reproduce I follow this tutorial usage with the c api try to build a a c tensorflow program Here is the steps 1 build tensorflow from source I am sure this step is right because I can install python tensorflow with the whl file built by this step 2 in the tensorflow source code directory I run this command bazel build tensorflow examples label image the build failed with following logs partial because whole log is too big WARNING home scott github tensorflow tensorflow tensorflow core BUILD 1781 1 in includes attribute of cc library rule tensorflow core framework headers lib ' external nsync public' resolves to 'external nsync public' not below the relative path of its package 'tensorflow core' This will be an error in the future Since this rule was created by the macro 'cc header only library' the error might have been caused by the macro implementation in home scott github tensorflow tensorflow tensorflow tensorflow bzl 1044 30 INFO Analysed 2 targets 0 packages loaded INFO Found 2 targets INFO From ProtoCompile tensorflow core example example pb cc bazel out local linux py3 opt genfiles external protobuf archive src warning directory does not exist INFO From ProtoCompile tensorflow core grappler costs op performance data pb cc bazel out local linux py3 opt genfiles external protobuf archive src warning directory does not exist bazel out local linux py3 opt genfiles external protobuf archive src warning directory does not exist INFO From ProtoCompile tensorflow contrib cloud kernels bigquery table partition pb cc bazel out local linux py3 opt genfiles external protobuf archive src warning directory does not exist INFO From Executing genrule tensorflow cc array ops genrule 2017 12 01 15 02 52 546440 W tensorflow core framework op gen lib cc 372 Squeeze can not find input squeeze dims to rename ERROR home scott github tensorflow tensorflow tensorflow examples label image BUILD 14 1 Linking of rule ' tensorflow examples label image label image' failed Exit 1 usr bin ld warning libcudnn so 6 needed by bazel out local linux py3 opt bin solib local U S Stensorflow Sexamples Slabel Uimage Clabel Uimage Utensorflow libtensorflow framework so not found try using rpath or rpath link bazel out local linux py3 opt bin solib local U S Stensorflow Sexamples Slabel Uimage Clabel Uimage Utensorflow libtensorflow framework so undefined reference to cudnnGetConvolutionBackwardDataAlgorithm',,,2017-12-01 08:17:23,2017-12-01 10:00:30
IS,Why tensorflow do not support tf float64 on some ops,Reproducing experiment of some paper using tensorflow may do not have good performance I have tried my best to keep the structure and hyper parameters unchanged Does anyone encounter similar problem Is it the code wrong I wonder that caffe can use float64 but tensorflow only can use float32 so there are more inaccuracy on gradients why tf do not support tf float64,,,2017-12-01 12:11:04,2017-12-01 12:12:59
IS,Make a copy of a model,Hi is there a canonical method in Tensorflow for this For example in Keras we can use keras models clone model for this purpose I though that model is copy would be such a nice feature since copy deepcopy does not work for me in Tensorflow I want to copy weights from this model to another model of identical structure and I do not want to save a model then restore it to another instance for this situation Specifically the situation at every iteration we train model1 then make model2 as a copy of current model1 adding noise to model1 parameters and sample from model2 and then use these samples to update model1,,,2017-11-20 15:30:29,2017-12-01 13:58:19
IS,error while importing,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Traceback most recent call last File line 1 in File usr local lib python2 7 dist packages tensorflow init py line 24 in from tensorflow python import File usr local lib python2 7 dist packages tensorflow python init py line 51 in from tensorflow python import pywrap tensorflow File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 52 in raise ImportError msg ImportError Traceback most recent call last File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow py line 41 in from tensorflow python pywrap tensorflow internal import File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 28 in pywrap tensorflow internal swig import helper File usr local lib python2 7 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError libcudnn so 5 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-01 11:16:50,2017-12-01 14:16:27
IS,startup time make train function very slow on Tesla V100 SXM2 16GB GPU compared to less powerful GPU,cross posted on keras Running mnist cnn py slightly modified mainly adding logging from tensorflow 1 4 running was done using a prebuilt docker image tensorflow tensorflow 1 4 0 gpu py3 on a p2 xlarge aws machine that has a Tesla K80 GPU performance is good the 1st batch which is dominated by the call to make train function takes about 2 seconds see time stamp for begin batch and end batch,,"tatatodd,tfboyd",2017-11-19 09:02:52,2017-12-01 15:49:52
IS,a,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-01 16:22:41,2017-12-01 17:40:08
IS,off by one bug in graph editor get forward walk ops,This line L414 converts Tensor to its corresponding op by replacing it with its consuming op seed ops util get consuming ops ts Instead it should replace it with its producing op seed ops t op for t in ts This would makes get forward walk ops tensor give same result as get forward walk ops tensor op which was probably the intention of this function I know contrib is not really supported but wanted to file this bug in order to reference it in work arounds in my code,,"yaroslavvb,yaroslavvb,purpledog,yaroslavvb,yaroslavvb,yaroslavvb,purpledog,yaroslavvb",2017-11-24 09:38:31,2017-12-01 17:51:48
IS,Try compile for raspbery pi and got graph pb h missing,tensorflow core framework graph pb h No such file or directory include tensorflow core framework graph pb h,,,2017-08-29 19:38:37,2017-12-01 18:56:59
IS,tf train Scaffold missing global step attribute,According to the docstring of tf train Scaffold there is a global step attribute with the following description global step A tensor containing the global step counter Picked from and stored into the GLOBAL STEP collection in the graph by default see L84 The problem is that no such attribute actually exists,,"aselle,tatatodd,ispirmustafa",2017-06-12 20:11:16,2017-12-01 19:14:32
PR,Fix deprecated function,tf contrib framework get or create global step tf train get or create global step,,PW486,2017-12-01 02:17:04,2017-12-01 19:20:20
PR,Only install enum34 on Python 3 4 versions Take 2,Python 3 6 sometimes has issues with enum34 because the standard library relies on enum features not in enum34 see for more details We will avoid the new versioning syntax in setuptools to allow old versions of setuptools to still work see 14779 Do you mind taking a look,,"alanhdu,yifeif",2017-12-01 16:21:39,2017-12-01 19:20:53
IS,Tutorial wrong code cifar10 multi gpu train py,when I run python cifar10 multi gpu train py num gpus 2 reported a error So what is use fp16 USE FP16 it didn a appear at anywhere in this code file,,qmick,2017-12-01 07:23:04,2017-12-01 19:21:03
PR,PeriodicResample Op Fixes 9369 clean history,This is the same PR as 9376 with no CLA issues,,"mrry,martinwicke,martinwicke,mrry,martinwicke,martinwicke,mrry,mrry,martinwicke,jhseu,martinwicke,sb2nov,sb2nov,sb2nov",2017-11-08 00:39:20,2017-12-01 19:21:22
IS,no such package 'tensorflow examples image retraining' BUILD file not found on package path for Virtual Environment on mac,Template ignored,,aselle,2017-11-30 23:53:32,2017-12-01 19:30:46
IS,tf image crop and resize,Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 14 04LTS TensorFlow installed from source or binary yes TensorFlow version use command below 1 3 0 Python version 2 7 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Anyone know how the tf image crop and resize images boxes batch inds pooled height pooled width method 'bilinear' name 'Crop' work i cannot find the tf image crop and resize in tensorflow python ops gen image ops py Thank you,,aselle,2017-11-30 05:52:26,2017-12-01 19:35:01
IS,GPU visual studio dependecies,I build tensorflow 1 4 0 for windows with GPU usage But when I run my program in visual studio 2015 I get these error My system Windows 10 Cuda 8 0 Cudnn 6 cmake cmake 3 9 4 win64 x64 Python 3 5 2 VS2015,,tatatodd,2017-11-30 23:08:54,2017-12-01 19:49:37
PR,Revert Arbitrary dim for slice 11140,This reverts commit 8011eda4b70faac6025c6b0553c3d95474adb5fe Check if tests pass,,"sb2nov,jhseu",2017-12-01 05:31:04,2017-12-01 20:22:17
PR,Add additional linkopts argument to tf custom op library,This will help a repository that uses tensorflow as a submoudle to use existing tensorflow bazel rules in tensorflow bzl,,,2017-11-30 23:10:51,2017-12-01 22:46:23
IS,Model trained on GPU does not restore properly when ran on CPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Describe the problem I have trained the official mnist model on GPU channels first NCHW but when I test it on CPU channels last NHWC I get different results On GPU I get an accuracy of 0 99309999 but the same model when tested on CPU gives 0 096199997 I believe when the model is restored from the checkpoint the kernel weights are not restored properly to accommodate for the new channel format The problem I have shown here is using the official mnist model but in reality I have a model that I have already trained using the channels first format on GPU which took several days to train But now I cannot evaluate this model on CPU,,"skye,martinwicke,nealwu,nealwu",2017-10-26 15:14:11,2017-12-01 23:42:03
PR,Introduce tf http archive,I decided to give another try,,"jart,gunan,jart,jart,gunan,gunan,jart,gunan,jart,jart,gunan",2017-12-01 00:14:13,2017-12-02 00:02:58
PR,Branch 177236996,,,sb2nov,2017-12-01 23:25:18,2017-12-02 01:35:47
PR,DO NOT SUBMIT TEST,,,sb2nov,2017-12-01 21:23:36,2017-12-02 07:20:20
PR,Increase test size to prevent timeout,,,sb2nov,2017-12-02 01:20:16,2017-12-02 07:20:28
PR,Branch 177545934,,,"sb2nov,sb2nov",2017-12-01 05:18:22,2017-12-02 09:38:23
IS,Eager Warn with invalid policy,If a user accidentally writes tfe enable eager execution tfe DEVICE PLACEMENT WARN instead of the correct tfe enable eager execution device policy tfe DEVICE PLACEMENT WARN they wo not get an error until later in their program For example tfe num gpus after the incorrect enable call produces I would think it makes more sense to throw an error immediately after the incorrect enable eager execution This is on master ab00df9,,"shivaniag,asimshankar",2017-11-21 02:31:54,2017-12-02 09:39:46
IS,Go TensorFlow 1 4 0 DataType 21 is not supported,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch linux TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 0 Python version NA using go Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 9 0 176 4 7 0 3 1 GPU model and memory GTX 1060 6GB Exact command to reproduce Describe the problem Calling the Value method on the evaluated output tensor of dataset related operations from the go package fails with the error DataType 21 is not supported It looks like op TextLineDataset produces a tensor of type tf Half can not be converted to a go type I may be using the datasets wrong If so the error and or documentation should be improved Source code logs,,"shivaniag,mrry,asimshankar,asimshankar",2017-11-22 19:42:17,2017-12-02 09:39:46
IS,panic runtime error cgo argument has Go pointer to Go pointer when using FIFOQueueV2 with non scalar shapes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 0 Python version NA using go bindings Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory NA using CPU Exact command to reproduce Describe the problem When using op FIFOQueueV2 from the go bindings and passing it only scalar shapes in op FIFOQueueV2Shapes the OP works as expected However when using multi dimensional shapes it panics with panic runtime error cgo argument has Go pointer to Go pointer Source code logs For a working example with scalar shapes replace the dataShapes and data lines with the commented versions below them,,"tatatodd,asimshankar",2017-11-26 23:18:56,2017-12-02 09:39:46
PR,Document iOS demo app in TF Lite Readme,See the rendered markdown here ios demo app I think the demo app is already well explained for the Android so it just require a few lines to describe how to build the iOS version,,"miaout17,gargn,miaout17,miaout17",2017-11-30 20:18:51,2017-12-02 09:39:56
PR,Update estimator py,Replace contrib metrics with core metrics,,"alanyee,martinwicke,alanyee,martinwicke,martinwicke",2017-11-05 09:26:37,2017-12-02 15:44:24
PR,Fix typo,Fix typo,,"ManHyuk,jhseu",2017-11-06 04:36:00,2017-12-02 15:44:45
IS,Tensorflow installation for python version 3 6,I am trying to install tensorflow framework on my Windows 10 system and the framework is showing me the similar error of image I have checked my system architecture which is 32 bit I have tried it installing using the conda 3 5 python version fix but then again same error arises Please help me resolve this issue as I am on a fix for last few days,,"aselle,aselle",2017-11-26 18:23:25,2017-12-02 17:52:03
IS,,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-02 09:09:03,2017-12-02 19:26:08
IS,Go bindings Two variables interfere unless op VarHandleOpSharedName is used,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch linux TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version NA GPU model and memory Describe the problem When creating and assigning values to two variables in the Go bindings they conflict one value gets assigned to both variables The variables assign OPs race so it is somewhat non deterministic which gets assigned to both Reproduce Use op VarHandleOp to create two variable handles and then use op AssignVariableOp to create OPs to assign the constant 1 to the first variable and 2 to the second Pull on the two assign OPs Evaluate the variable reader outputs for the two variables Expected result First variable has a value of 1 and second variable has a value of 2 Observed result Both variables have the same value usually 2 but occasionally 1 Is this behavior correct If I use the optional parameter op VarHandleOpSharedName in op VarHandleOp giving the two variables different names it works as expected so this is easy to work around Source code logs,,asimshankar,2017-12-02 17:34:38,2017-12-03 01:13:01
IS,segfaults in Saver restore with missing files,System information OS Platform and Distribution e g Linux Ubuntu 16 04 centos 7 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc1 2456 g7abd587 1 4 0 dev20170922 Python version 3 6 The above code segfaults in today is nightly build I expect an exception,,"ppwwyyxx,ppwwyyxx",2017-09-23 00:51:01,2017-12-03 01:23:16
IS,when execute bash tensorflow contrib lite build ios universal lib sh it has the following error tensorflow tensorflow contrib lite ios makefile inc 2 missing separator Stop,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-03 08:12:30,2017-12-03 08:14:46
PR,CMake Extract list of python modules,Progressing 10296 FYI,,"Androbin,mrry,Androbin,mrry,Androbin,mrry,Androbin,mrry,Androbin,mrry,mrry,mrry,Androbin,mrry,Androbin,Androbin,mrry,mrry,mrry,sb2nov,sb2nov,Androbin",2017-11-25 14:06:50,2017-12-03 14:30:15
PR,Add uint32 and uint64 support for bitwise and or xor,In tensorflow core ops bitwise ops cc uint32 and uint64 have been enabled for bitwise operations and or xor left shift right shift However the kernels of and or xor have no support of uint32 and uint64 This is in comparision to left shift right shift which have the uint32 uint64 support and is tested in bitwise ops test py This fix adds uint32 and uint64 to bitwise and or xor kernels This fix also adds relevant test cases in bitwise ops test py to bring and or xor as left shift right shift Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-11-26 01:41:43,2017-12-03 14:30:40
IS,Feature Request Resize netwoks on the fly,Hi Do you plan to change the present paradigm about tensorflow neural network that make the networks size to be static after using run Is it plan to be able to resize on the fly the network shape number of kernels type of activation function type of down sampling during the training for instance Thanks,,jart,2017-09-01 20:53:32,2017-12-03 18:57:08
IS,Running tensorflow gpu in virtual env in remote Ubuntu system,I was attempting to install tensorflow gpu version for my gpu system I do not have sudo access in the computer Cuda version 7 5 V7 5 17 is installed After following all the steps and finding a suitable version of tensorflow suitable to cuda 7 5 I have installed everything But after installing when I am trying to import tensorflow these errors are coming image I do not know how to resolve it Also does this error affect the running of my code in gpu or can I ignore it and start coding The solutions I found on forum is related to reinstalling cuda but I cannot do that as I do not have sudo access Can anyone please provide me some other solution to resolve this issue I really want to setup my environment soon for the project Thank you Additional info OS Platform and Distribution Ubuntu v 16 04 TensorFlow installed via creating virtualenv TensorFlow version 0 12 0rc0 Bazel version Not used CUDA cuDNN version 7 5 GPU model and memory NA Exact command to reproduce NA,,,2017-12-02 17:50:25,2017-12-03 20:39:38
PR,Add S3 to the list of implemented file systems in doc,This fix adds S3 to the list of implemented file systems in doc Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx",2017-12-03 15:34:59,2017-12-04 02:36:39
IS,Failing to retrieve AWS credentials running in ECS with the s3 provider,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below master Python version 3 6 0 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version None GPU model and memory None Exact command to reproduce None Describe the problem When using the S3 file system provider within an ECS container I am finding that even though my task has been assigned a task role that provides access to my S3 bucket it is unable to access it successfully Everything works fine if I supply the credentials manually using the AWS ACCESS KEY ID and AWS SECRET ACCESS KEY environment variables After some extensive head desking I have found that the version of aws sdk cpp that is used 1 0 90 appears to have been released before the ECS support was added to the sdk at a minimum I think we would want 1 0 97 so that everything works as expected I had originally tried to bump the version but it appears that the bazel mirror has nothing but 1 0 90 available,,yongtang,2017-12-03 00:58:17,2017-12-04 02:38:19
PR,Update AWS C SDK to 1 3 15,This fix tries to address the issue raised in 15066 where AWS C SDK version was not high enough to support ECS This fix updates AWS C SDK to 1 3 15 This fix fixes 15066 Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-12-03 02:13:04,2017-12-04 02:38:19
PR,Bump the GRPC version TF depends on,To help fix 14039,,"gunan,jhseu,gunan,yifeif,drpngx,gunan",2017-11-29 21:27:52,2017-12-04 06:20:57
PR,Fix a BUILD file bug in tensorflow contrib cloud BUILD,In tensorflow contrib cloud invoking bigquery reader ops test will fail The error is caused by the the fact that bigquery reader ops test depends on bigquery reader ops op lib and bigquery reader ops However bigquery reader ops test is in python bigquery reader ops op lib and bigquery reader ops are cc libraries So they should not be the dependencies of bigquery reader ops test This fix removes the above two dependencies so that bigquery reader ops test could run successfully Below is the full error message before this PR Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,gunan,drpngx",2017-12-01 04:22:32,2017-12-04 06:25:41
PR,DONOTMERGE Debug windows GPU build,,,"gunan,drpngx",2017-11-23 04:44:58,2017-12-04 06:26:33
PR,Edit mnist data read in to match tutorial,The accompanying tutorial and this file did not match The proposed code change was copied from the tutorial and confirmed to run correctly Note that this removes the ability to pass a custom data directory as an argument However since this is aimed at absolute beginners I believe clarity is more important than flexibility,,"nealwu,nealwu",2017-11-20 16:11:34,2017-12-04 06:52:19
PR,min quantize lib and command line,a quantize obfuscate lib 1 without Quantize DeQuantize ops 2 could obfuscate node names 3 use KMeans instead of simple average slice,,,2017-11-24 10:43:14,2017-12-04 10:29:03
IS,XLA Failure in the OS X xla service tests duplicate symbol,I am getting the following error when running the XLA service unit tests This is OS X head of the master branch using bazel 0 5 4 homebrew Is this a known issue at the moment,,"DavidNorman,hawkinsp",2017-09-28 08:57:53,2017-12-04 10:49:45
PR,DOC Fix documentation for dataset md,The code image tf decode jpeg parsed image data in 738 lines is incorrect It should be tf image decode jpeg instead of tf decode jpeg,,"caisq,caisq",2017-12-04 01:33:32,2017-12-04 14:35:49
IS,Compatibility with Bazel 0 8,Starting from Bazel 0 8 support for set constructors will be removed completely Currently one of the dependencies grpc is not compatible with this tensorflow uses an old version of it grpc has already been fixed please update your dependencies to use grpc with the following commit included grpc is loaded as a patched http archive you can also update the file third party grpc grpc patch to include the one line patch from the commit above if it is more convenient Just updating grpc to head or to to the commit that has the fix is not trivial because third party grpc grpc patch then has to be updated as well and as I do not know why those changes were necessary I do not know if I should keep update or delete them when I update grpc,,"reedwm,gunan,jhseu,gunan",2017-10-13 15:52:51,2017-12-04 15:22:27
PR,Fixing activate the Virtualenv,in Installing TensorFlow on macOS Probably needs to be fixed for Linux as well,,caisq,2017-12-04 13:23:40,2017-12-04 16:02:20
PR,tf Print supports Variable,CF 14788 14874 I agree that it might be not a good idea to pass Variable as input for tf Print and the implementation might be incomplete incorrect or even potentially dangerous So feel free to close the pr As we knwon tf Print is consistent with tf identity which always return a Tensor with the same type However the pr changes tf Print is behavior as return Tensor for Tensor return mutable Tensor for mutable Tensor return Variable for Variable The pr is opposed to 15069,,facaiy,2017-12-03 02:43:03,2017-12-04 16:14:28
IS,Tensorflow build fails with mavx512f,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Fedora 25 TensorFlow installed from source or binary source TensorFlow version use command below latest commit f58e6ce happens with older versions as well 23caaa5 f48673b 9a15e0a 3c4cb08 to only name a few Bazel version if compiling from source 0 4 5 CUDA cuDNN version none CPU model and memory XEON PHI 7250 96GiB ram Exact command to reproduce configure specify optimization flags mavx512f bazel build config opt verbose failures tensorflow tools pip package build pip package Describe the problem Building Tensorflow from source fails when avx512 instructions are activated After managing to compile most of the source the build fails somewhere in the eigen part of the code builderror txt Do not let yourself get thrown off by the MKL in some path names its just the name of the virtualenv for this report MKL was turned off in the configure See also similar Issue 9849,,aselle,2017-06-13 21:13:57,2017-12-04 19:06:42
PR,Fix typo,,,"ManHyuk,caisq",2017-12-04 12:20:38,2017-12-04 19:15:00
PR,fix overpadding in MixtureSameFamily,This fixes pad mix dims when mixture distribution does not have scalar batch size previous version would add too many dimensions,,"jvdillon,drpngx",2017-11-24 20:34:39,2017-12-04 19:26:54
PR,Branch 177809511,,,"caisq,caisq,caisq",2017-12-04 15:51:49,2017-12-04 19:34:23
PR,Update docs for tf contrib losses tf losses,This fix updates the docs in extend estimators md and changes the reference from tf contrib losses to tf losses as the former has been deprecated Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-12-04 16:20:51,2017-12-04 20:21:51
PR,Add an argument for additional linkopts to py wrappers rule,This will help a repository that uses tensorflow as a submoudle to use existing tensorflow bazel rules in tensorflow bzl,,,2017-12-04 04:26:19,2017-12-04 21:32:56
IS,The sequence of session run and control dependencies,See three examples The op is printed before y but q 2 0 why If op is executed before y y will be assigned by x which means y 1 0 and q should be 1 0,,"ppwwyyxx,ppwwyyxx,alextp,reedwm,alextp,ppwwyyxx",2017-12-03 13:57:34,2017-12-05 00:27:29
IS,ValueError graph def is invalid at node u'a Assign' Input tensor 'a 0' Cannot convert a tensor of type string to an input of type string ref,I want to change the input directory for validation using input map in tf train import meta graph Here is the demo code For training However I encounter the following errors ValueError graph def is invalid at node u'a Assign' Input tensor 'a 0' Cannot convert a tensor of type string to an input of type string ref I use tensorflow 1 2 It seems to be a bug,,"alextp,alextp",2017-08-25 09:46:31,2017-12-05 02:01:44
IS,tf gather with int32 indices yields wrong result on gpu,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 cat etc issue Ubuntu 16 04 2 LTS TensorFlow installed from source or binary Source head TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source bazel release 0 4 5 CUDA cuDNN version 8 0 7 0 GPU model and memory GeForce GTX 980 Exact command to reproduce,,"drpngx,drpngx,drpngx,reedwm",2017-09-08 14:07:20,2017-12-05 02:15:55
IS,Deallocation messages broken,The only way to calculate peak memory in OSS TensorFlow is to make memory timeline by parsing allocation deallocation messages possibly using helpers like this github com yaroslavvb memory util Sometime between TF 1 0 1 and TF 1 1 the deallocation messages stopped including allocation id so you can not track when each tensor got deallocated In TF 1 0 1 you see this 2017 09 16 13 24 28 I tensorflow core framework log memory cc 35 LOG MEMORY MemoryLogTensorDeallocation allocation id 1 allocator name cpu In latest TF you see this 2017 09 16 13 25 04 422108 I tensorflow core framework log memory cc 35 LOG MEMORY MemoryLogTensorDeallocation allocator name cpu Note that deallocation id is missing in later version cc who mentioned ongoing work for tracking memory deallocation,,"yaroslavvb,yaroslavvb,reedwm",2017-09-16 20:30:44,2017-12-05 02:51:16
IS,compiling CPU version under windows X86,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-05 03:30:06,2017-12-05 03:30:46
PR,add a new operator sparse tile like interface,Hi we are doing some research on graph networks which is very necessary for us to use sparse operators we think there might be someone else who has the same demands will join us Here we would continue to update those operators Thanks,,,2017-12-05 02:10:16,2017-12-05 04:00:49
IS,Why tensorflow do not support tf float64 on some ops,Reproducing experiment of some paper using tensorflow may do not have good performance I have tried my best to keep the structure and hyper parameters unchanged Does anyone encounter similar problem Is it the code wrong I wonder that caffe can use float64 but tensorflow only can use float32 so there are more inaccuracy on gradients why tf do not support tf float64,,"aselle,drpngx",2017-12-01 12:10:48,2017-12-05 04:35:31
IS,Feature Request Please make Estimator export savedmodel support input types other than tf Example,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 3 5 3 CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem I have a model I want to export it into SavedModel format by using tf estimator API because I'm using this API for training Unfortunately tf estimator export build raw serving input receiver fn and tf saved model signature def utils classification signature def require the input features must be encoded in tf Example format In order to use the export savedmodel function for exporting when writing a custom model fn for Estimator I must populate the export outputs element of the tf estimator EstimatorSpec return value Each output value must be an ExportOutput object such as tf estimator export ClassificationOutput tf estimator export RegressionOutput or tf estimator export PredictOutput Those three output types only support tf Example as the input,,"snnn,snnn",2017-12-05 09:03:56,2017-12-05 10:37:47
IS,a small problem in the word2vec,In the web url In the code line 123 buffer data span when I run the wiki data using 1000 examples 1000 rows the program says sequence index must be integer not slice so I changed buffer data span to buffer clear and buffer extend data span and it works well,,,2017-12-05 08:52:30,2017-12-05 11:56:08
PR,XLA Use the specific float list rather than a hard coded list,This change makes the test use the list of supported types for the backend under test rather than a hard coded list,,"DavidNorman,drpngx,DavidNorman,DavidNorman,DavidNorman",2017-11-21 09:06:15,2017-12-05 12:56:12
IS,Building tensorflow from the sourcefile,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Redhat TensorFlow installed from source or binary source TensorFlow version use command below 1 0 Python version 2 7 14 Bazel version if compiling from source GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version 8 5 GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Getting the following error Note Tried other plateforms but could get any reply I am not sure its a bug or else I apologize if I am using the wrong forum I am trying to install tensorflow from source so I can use MPI Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"snnn,snnn,drpngx",2017-12-04 19:57:22,2017-12-05 13:00:06
PR,Fix typo,fix typo,,,2017-12-05 11:57:25,2017-12-05 14:33:58
PR,Merge pull request 1 from tensorflow master,Fetch from upstream,,,2017-12-05 01:44:30,2017-12-05 14:50:48
IS,Using Sparse tensors to apply gradients in BackPropogation,Hi All I am trying to use sparse tensors while applying gradients and i see below error Tensor conversion requested dtype int64 for Tensor with dtype float32 'Tensor Adam 1 update conv1 1 weights sub 2 0 shape dtype float32 ' I am assuming this to be a bug as the dtype int64 must have been hardcoded for sparse tensors Is there any workaround for this issue Here is what I am trying to do this function multiplies gradients with prune weights so that gradient updation happens on pruned gradients,,"facaiy,facaiy,drpngx",2017-09-02 20:55:37,2017-12-05 17:18:07
IS,Add data dynamically to pre exisiting contrib data dataset,As far as I'm aware this is not possible so I think this is a feature request It would be great to be able to add data to a pre exisiting dataset object which already has an iterator attached For example in reinforcement learning one often collects data while exploring and needs to add this data to the training dataset I can not see how using the concatenate function is sufficient as this returns a new dataset object and would require a new iterator etc Thanks,,"aselle,mrry,aselle,mrry",2017-09-19 09:07:45,2017-12-05 17:20:48
IS,tf cc binary makes opencv unable to load an image,I try to load an image with opencv and work further on it with the tensorflow framework Unfortunately I get a really weird behaviour The image is loaded without problems using cc binary in Bazel Changing it to tf cc binary does not stop the code from compilation or running but opencv can not load any images any more Source code logs This is my BUILD file load tensorflow tensorflow bzl tf cc binary tf cc binary using this no image could be loaded anymore cc binary name main srcs main cpp linkopts lopencv core lopencv highgui lopencv imgcodecs lopencv imgproc visibility visibility public I use the standard example code from the opencv website Again it is working and the image gets loaded using cc binary include opencv2 core core hpp include opencv2 highgui highgui hpp include iostream using namespace cv using namespace std int main int argc char argv Mat image image imread tensorflow test imageHolder data example jpg CV LOAD IMAGE COLOR Read the file if image data Check for invalid input cout Could not open or find the image std endl return 1 namedWindow Display window WINDOW AUTOSIZE Create a window for display imshow Display window image Show our image inside it waitKey 0 Wait for a keystroke in the window return 0 This is my file structure in case it matters data example jpg src BUILD main cpp,,"aselle,allenlavoie,skye,skye",2017-09-24 20:09:05,2017-12-05 17:21:41
IS,cudnn PoolBackward launch failed when using tf nn max pool on Tensorflow GPU Windows 10,When using max pool the error below shows and stops the code I used the code available here Specifically I used the lib model bidirectional lstm py and the error occurs at the tdnn function when tf nn max pool is ran What does this error mean Thanks What related GitHub issues or StackOverflow threads have you found by searching the web for your problem I have searched through all websites including GitHub and StackOverflow and it seems like this error has not been reported anywhere else Environment info Tensorflow 1 3 0 Python 3 5 3 CUDA 8 0 cuDNN 6 0 OS Windows 10 GPU GeForce GTX 1080ti,,drpngx,2017-09-25 14:01:49,2017-12-05 17:22:36
IS,Feature request classifier deallocation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 6 TensorFlow installed from source or binary Binary pip TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' tensorflow Python version 2 7 8 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem DNNClassifier does not appear to have any methods for freeing its resources and that does not seem to occur automatically if I let the classifier go out of scope In the gist linked above I train evaluate and throw away DNNClassifiers as part of a genetic algorithm for feature selection but after training a little more than a hundred models it fails InvalidArgumentError see above for traceback Unsuccessful TensorSliceReader constructor Failed to get matching files on model 2017 10 18 21 41 26 125 model ckpt 4000 Resource exhausted model 2017 10 18 21 41 26 125 Source code logs,,"drpngx,drpngx,yaroslavvb,drpngx",2017-10-18 22:13:16,2017-12-05 17:26:10
IS,gfile random access file seek implementation inappropriate,the call stack for tensorflow python platform gfile GFile seek function is as follows L118 L153 L126 L27 L27 The implementation of SkipNBytes for random access file is read out N bytes It is not efficient if we seek through one huge file I think we should override the implementation for random access file I tried seek API for one large hdfs file it took more than one hour to finish,,yongtang,2017-11-13 06:58:29,2017-12-05 17:35:18
IS,Loading TF 1 1 model in TF 1 4,There is a model which has been trained in TF 1 1 it is a seq2seq model with bahdanau attention It uses DynamicAttentionWrapper which has been renamed to AttentionWrapper After updating TF to version 1 4 and switching to renamed AttentionWrapper the model can not be loaded I get multiple errors like the following Setting name to dynamic attention wrapper in AttentionWrapper constructor parameters does not resolve the issue Am I missing something Taking into account that production models take a lot of resources to be trained it would be good for them to be compatible between TF versions Thank you,,drpngx,2017-11-15 17:53:36,2017-12-05 17:50:12
IS,ImportError libcublas so 8 0 cannot open shared object file No such file or directory,I'm trying to run Tensorflow gpu through virtualenv via pip3 in Ubuntu 16 04 I have installed Cuda 9 0 and cuDNN v7 0 3 then tested both and they are working fine However when attempting to import Tensorflow in Python I get the following error Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory I located libcublas so in usr local cuda lib64 However I see that it references a new version of the library 9 0 176 My question is whether something simple can be done like creating a symbolic link to the library with the name of libcublas so 8 0 or I have to wait for an update in TF that can run with Cuda9 cuDNN 7 Cheers,,"drpngx,gunan,gunan",2017-11-16 14:07:07,2017-12-05 18:06:54
IS,Bug using regularizer for shared variables in tf cond branches,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 13 1 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem Setting the regularizer of a shared variable in tf cond branches gives an unexpected behaviour only one copy of the regularization op is added to tf GraphKeys REGULARIZATION LOSSES This is different from adding operations to a collection explicitly And optimizing the regularization loss does not raise an error Source code,,drpngx,2017-11-16 16:05:16,2017-12-05 18:07:27
PR,Fix link to BUILD file in android readme,Simple syntax error,,caisq,2017-12-04 22:02:09,2017-12-05 18:25:35
IS,Does Tensorflow support Graphic for AMD GPU also like NVIDIA GPU,Dear All I have laptop lenovo G50 80 I7 5500 with AMD RADEON R5 M230 2GB for graphic it is also gpu based on this link Radeon R5 M230 review does tensorflow support this amd for computing the same like what tensorflow did with GPU from NVIDIA if it has to be configured from the source what is the setting of tensorflow that when i compile it it will run the gpu Thx,,drpngx,2017-11-20 23:57:15,2017-12-05 18:27:25
IS,Wrong result when computing accuracy using tf metrics accuracy,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 1709 TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 0 Python version Python 3 5 2 Anaconda custom 64 bit Describe the problem I found the result tf metrics accuracy returns is incorrect when I trained my model To verify this I wrote a simple program You can see that acc and my acc is different and acc is wrong I double checked the doc and still confused Is there anything I missed Thank you,,"reedwm,reedwm",2017-12-05 04:18:37,2017-12-05 18:54:56
IS,build error undefined reference to clock gettime',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS 6 9 TensorFlow installed from source or binary source TensorFlow version use command below master branch the latest version Python version 2 7 Bazel version if compiling from source 0 8 0 GCC Compiler version if compiling from source 4 8 2 CUDA cuDNN version No GPU model and memory No Exact command to reproduce bazel build linkopt lrt c opt verbose failures tensorflow libtensorflow cc so Describe the problem I tried to build the tensor flow c lib from the source code but it failed Source code logs ERROR home baigang Projects xylib thirdparty tenserflow package tensorflow tensorflow cc BUILD 422 1 Linking of rule ' tensorflow cc ops random ops gen cc' failed Exit 1 gcc failed error executing command cd home baigang cache bazel bazel baigang d3e5550086b82aa173767408d0f485e7 execroot org tensorflow exec env PATH usr local bin bin usr bin usr local sbin usr sbin sbin home baigang bin PWD proc self cwd usr bin gcc o bazel out host bin tensorflow cc ops random ops gen cc ' Wl rpath ORIGIN solib k8 U S Stensorflow Scc Cops Srandom Uops Ugen Ucc Utensorflow' Lbazel out host bin solib k8 U S Stensorflow Scc Cops Srandom Uops Ugen Ucc Utensorflow ' Wl rpath ORIGIN rpath ORIGIN rpath ORIGIN ' pthread Wl no as needed Wl z relro z now B usr bin B usr bin pass exit codes Wl gc sections Wl S Wl bazel out host bin tensorflow cc ops random ops gen cc 2 params bazel out host bin solib k8 U S Stensorflow Scc Cops Srandom Uops Ugen Ucc Utensorflow libtensorflow framework so undefined reference to clock gettime' collect2 error ld returned 1 exit status Target tensorflow libtensorflow cc so failed to build INFO Elapsed time 418 738s Critical Path 35 11s FAILED Build did NOT complete successfully,,"reedwm,gunan,gunan",2017-12-05 14:19:20,2017-12-05 19:15:18
PR,Revert Speed up safe strtod and safe strtof functions by using doubl,e conversion library 12102 This reverts commit 495bb7b9f6b55b0e431fc604ad9dbf5415016d90,,"caisq,caisq,caisq,caisq",2017-12-05 15:06:55,2017-12-05 19:38:26
IS,Tensorflow current master build failure due to cuda cudnn,I would like to try out tf contrib framework sort which available on current master only Tried to build master but failed due to cuda cudnn library cannot found by bazel However I verified these library are exist at usr local cuda lib64,,,2017-12-05 23:45:31,2017-12-06 01:20:20
IS,MemoryError from tensorflow contrib learning datasets in Python3,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 5 3 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce python c import tensorflow as tf tf contrib learn datasets load dataset wouldbpedia' size 'full' Describe the problem The command results in an MemoryError even though the dataset easily fits into my memory 64GB and also works with Python 2 Source code logs Here is the traceback Traceback most recent call last File string line 1 in module File home james python3 5 ve lib python3 5 site packages tensorflow contrib learn python learn datasets init py line 71 in load dataset return DATASETS name size test with fake data File home james python3 5 ve lib python3 5 site packages tensorflow contrib learn python learn datasets text datasets py line 65 in load dbpedia train path target dtype np int32 features dtype np str target column 0 File home james python3 5 ve lib python3 5 site packages tensorflow contrib learn python learn datasets base py line 72 in load csv without header data np array data MemoryError,,"drpngx,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke",2017-11-19 03:24:39,2017-12-06 02:09:33
IS,ctc loss value problem,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 64bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 6 0 Bazel version if compiling from source None GCC Compiler version if compiling from source None CUDA cuDNN version None GPU model and memory None Exact command to reproduce None Describe the problem I used the source code below to calculate ctc loss The logit and target should extremely have no loss between them But the tf nn ctc loss return 1 91309595 What is the meaning of the tf ctc loss result But I use my custom ctc loss function which shows the loss is nearly zero Source code logs import numpy as np import tensorflow as tf logit np array 0 00001 0 9999 0 00001 0 00001 0 9999 0 00001 0 00001 0 00001 0 00001 0 00001 0 9999 0 00001 logit tf constant logit dtype 'float32' target tf SparseTensor indices 0 0 0 2 values 1 2 dense shape 1 3 seq tf constant np array 3 loss tf tf nn ctc loss target logit seq time major False ctc merge repeated True sess tf InteractiveSession tf global variables initializer run print loss tf eval,,,2017-12-04 05:48:55,2017-12-06 02:16:10
IS,tensorflow python framework errors impl NotFoundError u tensorflow master bazel bin tensorflow python tools freeze graph runfiles org tensorflow tensorflow contrib data python ops prefetching ops so undefined symbol ZN6google8protobuf8internal26fixed address empty stringB5cxx11E,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-06 03:38:25,2017-12-06 04:12:36
IS,TensorFLow build Error,when iam trying to retrain as per sample given in tensorflow org tutorials given below command bazel build tensorflow examples image retraining retrain after that gaving below errors any clue on this Error tensorflow third party py numpy BUILD 11 1 no such package ' local config python ' BUILD file not found on package path and referenced by ' third party py numpy headers' Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2017-12-06 04:46:39,2017-12-06 07:57:50
IS,Compiling CPU version on windows X86,System Information WIN 10 Visual studio 2015 Swigwin 3 0 12 Python 3 5 3 Cmake 3 10 0 Question description I am a new one about tensorflow I used cmake command in cmd just like this cmake A x64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE D swigwin 3 0 12 swig exe DPYTHON EXECUTABLE D Programs Python Python35 python exe DPYTHON LIBRARIES D Programs Python Python35 libs python35 lib Dtensorflow ENABLE GPU OFF and got the x64 vs project but when I wanted to generate x86 version with similar commnd like cmake A x86 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE D swigwin 3 0 12 swig exe DPYTHON EXECUTABLE D Programs Python Python35 python exe DPYTHON LIBRARIES D Programs Python Python35 libs python35 lib Dtensorflow ENABLE GPU OFF then I got a error cmake A x86 DCMAKE BUILD TYPE Debug DSWIG EXECUTABLE D swigwin 3 0 12 swig exe DPYTHON EXECUTABLE D Programs Python Python35 python exe DPYTHON LIBRARIES D Programs Python Python35 libs python35 lib Dtensorflow ENABLE GPU OFF CMake Error at CMakeLists txt 5 project Failed to run MSBuild command C Program Files x86 MSBuild 14 0 bin MSBuild exe to get the value of VCTargetsPath Now I want to ask does tensorflow support x86 windows Did anyone build the x86 version once before,,,2017-12-05 03:45:10,2017-12-06 08:33:50
PR,Document tf coreml converter in lite README md,,,"miaout17,miaout17",2017-12-05 20:14:29,2017-12-06 14:27:55
IS,stop gradients for weights in tf losses,In the case that the weights given to tf losses depend in some way on the model parameters the derivative of that loss also calculated with respect to the weights Stupid minimal example I would expect the weights to be considered constant for the calculation of a loss In case you agree with me I can make a PR that adds stop gradient around the weights parameter System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"facaiy,facaiy,facaiy,drpngx,drpngx",2017-12-01 19:25:12,2017-12-06 16:56:41
IS,Feature MonitoredSession should have run method with 'hooks to trigger' argument run hooks to trigger hooks 1 hooks 3,At the moment the session run hooks are passed to the constructor of MonitoredSession hooks and then they get executed for EVERY session run call within the MonitoredSession block This is inefficient and problematic E g if I define a LoggingTensorHook I want the logging output to be evaluated and printed at most ONCE per global step and not after some auxiliary session run calls that only evaluate the size of some queue or whatever else If you use feedable iterators the current MonitoredSession implementation actually crashes the program see issuecomment 348290076 The best solution in my opinion would be to be able to specify which run calls should actually trigger the before run and after run methods of the hooks e g via some flag argument in MonitoredSession run execute hooks True or alternatively pass a list of specific hooks whose before run and after run methods should be triggered by a run call via MonitoredSession run hooks to trigger,,"ispirmustafa,isaprykin,isaprykin",2017-12-06 14:50:46,2017-12-06 17:05:57
IS,Installing Tensorflow from source,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Redhat TensorFlow installed from source or binary source TensorFlow version use command below 1 4 1 Python version 2 7 14 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc 4 8 5 CUDA cuDNN version 8 6 GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am trying to install TF Its the last part of building TF from source pip install tmp tensorflow pkg tensorflow 1 4 1 cp27 cp27mu linux x86 64 whl Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem amalik node05 tensorflow pip install tmp tensorflow pkg tensorflow 1 4 1 cp27 cp27mu linux x86 64 whl Processing tmp tensorflow pkg tensorflow 1 4 1 cp27 cp27mu linux x86 64 whl Requirement already satisfied enum34 1 1 6 in lfs1 software7 anaconda2 lib python2 7 site packages from tensorflow 1 4 1 Requirement already satisfied backports weakref 1 0rc1 in lfs1 software7 anaconda2 lib python2 7 site packages from tensorflow 1 4 1 Requirement already satisfied wheel in lfs1 software7 anaconda2 lib python2 7 site packages from tensorflow 1 4 1 Requirement already satisfied mock 2 0 0 in lfs1 software7 anaconda2 lib python2 7 site packages from tensorflow 1 4 1 Collecting tensorflow tensorboard 0 5 0 0 4 0rc1 from tensorflow 1 4 1 Retrying Retry total 4 connect None read None redirect None after connection broken by 'NewConnectionError ' pip vendor requests packages urllib3 connection VerifiedHTTPSConnection object at 0x7f384a2261d0 Failed to establish a new connection Errno 101 Network is unreachable' ' simple tensorflow tensorboard Retrying Retry total 3 connect None read None redirect None after connection broken by 'NewConnectionError ' pip vendor requests packages urllib3 connection VerifiedHTTPSConnection object at 0x7f384a226350 Failed to establish a new connection Errno 101 Network is unreachable' ' simple tensorflow tensorboard Retrying Retry total 2 connect None read None redirect None after connection broken by 'NewConnectionError ' pip vendor requests packages urllib3 connection VerifiedHTTPSConnection object at 0x7f384a2264d0 Failed to establish a new connection Errno 101 Network is unreachable' ' simple tensorflow tensorboard Retrying Retry total 1 connect None read None redirect None after connection broken by 'NewConnectionError ' pip vendor requests packages urllib3 connection VerifiedHTTPSConnection object at 0x7f384a226650 Failed to establish a new connection Errno 101 Network is unreachable' ' simple tensorflow tensorboard Retrying Retry total 0 connect None read None redirect None after connection broken by 'NewConnectionError ' pip vendor requests packages urllib3 connection VerifiedHTTPSConnection object at 0x7f384a2267d0 Failed to establish a new connection Errno 101 Network is unreachable' ' simple tensorflow tensorboard Could not find a version that satisfies the requirement tensorflow tensorboard 0 5 0 0 4 0rc1 from tensorflow 1 4 1 from versions No matching distribution found for tensorflow tensorboard 0 5 0 0 4 0rc1 from tensorflow 1 4 1,,drpngx,2017-12-06 15:54:22,2017-12-06 17:08:40
IS,Multil model restore in tensorflow,I have two model without scope name but they have same variable name I want load them simultaneously but it will crash and throw error which is Variable XXX already exists I notice the issue url but the problem is solved by re training the model again and save them under different scope However I do not want to re train them again So how can I load existing models and save them into two different scope Any advise or help will be appreciated,,drpngx,2017-12-03 04:42:47,2017-12-06 17:12:29
IS,Input too short to compute filterbank,Hi I am new to tensorflow and i am trying to train model with my own data but i am getting below error 2017 12 06 18 56 38 030081 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030095 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030105 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030162 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030203 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030243 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030256 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030267 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030305 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030347 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030359 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030370 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030408 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030446 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030458 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030469 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030481 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030492 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030534 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030547 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030558 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030569 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030632 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030645 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030656 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030668 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030679 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030720 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030732 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030743 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030754 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030790 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030851 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030865 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030877 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030937 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030954 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 030967 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031028 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031043 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031054 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031066 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031078 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031118 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031132 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031144 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031155 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031211 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031227 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031238 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031249 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031309 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031325 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031338 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031349 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031408 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031425 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031437 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031474 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031512 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031525 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031537 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031573 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031608 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031620 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031631 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031643 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031687 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031699 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031710 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031769 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031799 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031812 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031823 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031834 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 031965 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032014 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032024 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032036 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032046 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032057 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032069 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032081 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032128 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032141 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032153 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032165 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032176 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032236 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032248 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032260 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032272 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032313 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032326 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032336 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032347 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032360 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank 2017 12 06 18 56 38 032399 E tensorflow core kernels mfcc mel filterbank cc 181 Input too short to compute filterbank and i am using below command to train bazel run tensorflow examples speech commands train data dir sound wanted words yes no data url,,reedwm,2017-12-06 13:31:40,2017-12-06 18:05:33
PR,summary image op test fixed on ppc64le,Hi As we discussed here I have created this PR to fix summary image op test on ppc64le Thanks,,"sandipmgiri,gunan,sandipmgiri",2017-12-06 08:34:16,2017-12-06 18:45:48
PR,Improve the Windows Bazel build,In this PR we are making following improvements 1 Remove unnecessary environment variables BAZEL VS Bazel can detect Visual C installation BAZEL PYTHON Not needed anymore since we do not use wrapper scripts NO MSVC WRAPPER Already using wrapper free CROSSTOOL by default USE DYNAMIC CRT Bazel already links to dynamic msvcrt by default 2 Remove the BUILD OPT variable in bazel test lib sh Add these options in configure py this way our users do not have to remember them every time 3 Remove bazel clean expunge With Bazel 0 8 0 I'm quite confident to remove this so that we can benefit from cache 4 When define no tensorflow py deps true we let py test depend on a marker file for all dependencies of the pip package By doing this even without bazel clean py test also gets to rerun as long as the pip package changes 5 Filter out external org tensorflow directory when creating the pip package,,"meteorcloudy,mrry,meteorcloudy",2017-12-05 12:13:31,2017-12-06 18:51:56
IS,tf data Dataset from generator creates too many threads throwing thread constructor failed,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Adapted an example from documentation OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS Siera 10 12 6 TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below tensorflow 1 4 0 cp27 cp27m macosx 10 11 x86 64 whl Python version 2 7 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version CPU GPU model and memory NA Exact command to reproduce Describe the problem If you run the code above which is adapted from tf data Dataset from generator docstring the program will crash with an error libc abi dylib terminating with uncaught exception of type std 1 system error thread constructor failed Resource temporarily unavailable I see the number of threads increasing in the activity monitor of the mac OS and when it reaches 3K threads the program crashes It takes several seconds Please let me know if this is not intended use of this API it is OS releated issue or there is a bug involved,,mrry,2017-12-06 18:50:12,2017-12-06 19:09:56
PR,MKL Adding MKL DNN Reshape op,,,"mahmoud-abuzaina,yifeif,claynerobison,gunan",2017-11-18 01:40:08,2017-12-06 19:27:54
PR,MKL Adding Relu implementation using the open source MKL DNN,,,"mahmoud-abuzaina,claynerobison,gunan",2017-11-10 17:08:20,2017-12-06 20:10:06
PR,MKL Adding MKL DNN graph pass implementation,,,"mahmoud-abuzaina,sb2nov,drpngx,gunan",2017-11-21 17:05:28,2017-12-06 20:11:06
PR,MKL Adding MKL DNN AddN op,,,"mahmoud-abuzaina,claynerobison,claynerobison,gunan",2017-11-18 01:38:48,2017-12-06 20:30:45
PR,MKL Adding MKL DNN Identity op,,,"mahmoud-abuzaina,claynerobison,gunan,claynerobison,gunan",2017-11-18 01:38:05,2017-12-06 20:31:13
PR,MKL Adding Batch Normalization implementation using the open source MKL DNN Lib,,,"mahmoud-abuzaina,claynerobison,gunan",2017-11-10 17:21:35,2017-12-06 20:37:04
PR,MKL Adding Convolution implementation using the open source MKL DNN Lib,,,"mahmoud-abuzaina,claynerobison",2017-11-10 22:56:06,2017-12-06 21:07:01
PR,MKL Adding Concat op implementation using the open source MKL DNN,,,"mahmoud-abuzaina,claynerobison,claynerobison,gunan",2017-11-10 17:16:00,2017-12-06 21:07:50
PR,Solved for MNIST file downloading problem,A lot of folks 6742 8126 8134 8116 were having trouble regarding this issue Even I faced it today while writing the MNIST code as the mnist py was unable to connect with the source url I downloaded the files and pasted it in the folder containing the code and made some changes in the code which solves the need for connecting it to the website Hope so this works out,,"caisq,caisq",2017-12-05 16:53:17,2017-12-06 21:52:35
IS,Is their any java spark api available for using Tensor,,,av8ramit,2017-12-05 13:36:02,2017-12-06 21:56:32
PR,MKL Adding MKL DNN pooling ops,,,"mahmoud-abuzaina,yifeif,claynerobison,gunan",2017-11-18 01:36:07,2017-12-06 22:28:04
PR,Update Eigen hash for fix of fp16 predux bug,Attention and xq For Maxwell and earlier GPUs Eigen was incorrectly casting fp16 values to unsigned int during some reductions This causes incorrect results in Tensorflow is xent and sparse xent ops when applied to fp16 data,,"nluehr,gunan,nluehr,gunan,nluehr,yifeif,gunan,gunan",2017-11-21 21:35:01,2017-12-06 22:28:41
IS,Feature request nightly build for python 3 6,The tf nightly pip packages are great Would it be possible to add support for python 3 6 and or provide a wheel for python 3 6 as part of the standard nightly build installation In particular the following succeeds,,"tillahoffmann,reedwm,gunan,av8ramit,tillahoffmann,tillahoffmann,av8ramit,tillahoffmann,av8ramit,tillahoffmann,av8ramit,tillahoffmann,av8ramit,gunan,gunan,av8ramit",2017-09-09 15:11:39,2017-12-06 22:31:23
PR,DO NOT SUBMIT Temporarily disable go test,context b 70154286,,"caisq,caisq,caisq,asimshankar",2017-12-06 22:03:36,2017-12-06 23:47:52
PR,Add batch support for various image ops,Working on 8926 I used 7369 as a guide for my work here I have added batch support for flip left right flip up down random flip left right random flip up down transpose image rot90 I have corrected existing tests in image ops test py and introduced a number of new tests based on existing tests for 3D inputs This is my first contribution to this repository and I have tried to follow the contributing guidelines However running pylint on image ops impl py and image ops test py revealed a number of pre existing style violations I have tried to fix the ones relevant to my work but may have missed some,,"JoshVarty,drpngx,drpngx,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,JoshVarty,JoshVarty,martinwicke,martinwicke,JoshVarty,JoshVarty,JoshVarty,jhseu,JoshVarty,jhseu,JoshVarty,jhseu,jhseu",2017-11-24 05:11:51,2017-12-07 00:22:12
PR,Go Do not require std c99 for the cgo code,This should fix the error github com tensorflow tensorflow tensorflow go graph go 31 3 error 'for' loop initial declarations are only allowed in C99 mode for int i 0 i num shapes i in some continuous builds like Alternative to 15169,,"asimshankar,asimshankar,asimshankar,caisq",2017-12-06 22:30:54,2017-12-07 01:52:21
IS,Got Attempting to use uninitialized value error after variable initalization,I am working on windows 10 Python 3 6 and tensorflow 1 4 0 I tested the code on two laptops one with gpu and another without both of them had this problem This is my code def network self net input dense1 tf layers dense net input 64 norm1 tf contrib layers batch norm dense1 relu1 tf nn relu norm1 dense2 tf layers dense relu1 32 norm2 tf contrib layers batch norm dense2 relu2 tf nn relu norm2 out tf layers dense relu2 1 return out def train self init global tf global variables initializer init local tf local variables initializer sess tf InteractiveSession sess tf Session sess run init global sess run init local data tf placeholder tf float32 self batch size 53 label tf placeholder tf float32 self batch size 1 prediction self network data loss tf reduce mean tf reduce sum tf square label prediction reduction indices 1 train step tf train GradientDescentOptimizer 1e 3 minimize loss for i in range self epoch for j in range 20000 self batch size batch data batch label self next batch self train data self train label batch label self next batch self train label sess run train step feed dict data batch data label batch label if j 50 0 start time time loss sess run loss feed dict data batch data label batch label print 'Epoch 2d 2d Iter 4d 4d Loss 8f Time cost 8f' i self epoch j 20000 self batch size loss time time start and this is the error message Traceback most recent call last File ipython input 17 6e018316c758 line 1 in module runfile 'C Users System Error Downloads report1 regression tf py' wdir 'C Users System Error Downloads report1' File C ProgramData Anaconda3 lib site packages spyder utils site sitecustomize py line 880 in runfile execfile filename namespace File C ProgramData Anaconda3 lib site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File C Users System Error Downloads report1 regression tf py line 99 in module main File C Users System Error Downloads report1 regression tf py line 92 in main regression train File C Users System Error Downloads report1 regression tf py line 76 in train sess run train step feed dict data batch data label batch label File C ProgramData Anaconda3 lib site packages tensorflow python client session py line 889 in run run metadata ptr File C ProgramData Anaconda3 lib site packages tensorflow python client session py line 1120 in run feed dict tensor options run metadata File C ProgramData Anaconda3 lib site packages tensorflow python client session py line 1317 in do run options run metadata File C ProgramData Anaconda3 lib site packages tensorflow python client session py line 1336 in do call raise type e node def op message FailedPreconditionError Attempting to use uninitialized value dense 18 bias Node dense 18 bias read Identity T DT FLOAT class loc dense 18 bias device job localhost replica 0 task 0 device CPU 0 dense 18 bias Caused by op wouldense 18 bias read' defined at File C ProgramData Anaconda3 lib site packages spyder utils ipython start kernel py line 231 in module main File C ProgramData Anaconda3 lib site packages spyder utils ipython start kernel py line 227 in main kernel start File C ProgramData Anaconda3 lib site packages ipykernel kernelapp py line 477 in start ioloop IOLoop instance start File C ProgramData Anaconda3 lib site packages zmq eventloop ioloop py line 177 in start super ZMQIOLoop self start File C ProgramData Anaconda3 lib site packages tornado ioloop py line 888 in start handler func fd obj events File C ProgramData Anaconda3 lib site packages tornado stack context py line 277 in null wrapper return fn args kwargs File C ProgramData Anaconda3 lib site packages zmq eventloop zmqstream py line 440 in handle events self handle recv File C ProgramData Anaconda3 lib site packages zmq eventloop zmqstream py line 472 in handle recv self run callback callback msg File C ProgramData Anaconda3 lib site packages zmq eventloop zmqstream py line 414 in run callback callback args kwargs File C ProgramData Anaconda3 lib site packages tornado stack context py line 277 in null wrapper return fn args kwargs File C ProgramData Anaconda3 lib site packages ipykernel kernelbase py line 283 in dispatcher return self dispatch shell stream msg File C ProgramData Anaconda3 lib site packages ipykernel kernelbase py line 235 in dispatch shell handler stream idents msg File C ProgramData Anaconda3 lib site packages ipykernel kernelbase py line 399 in execute request user expressions allow stdin File C ProgramData Anaconda3 lib site packages ipykernel ipkernel py line 196 in do execute res shell run cell code store history store history silent silent File C ProgramData Anaconda3 lib site packages ipykernel zmqshell py line 533 in run cell return super ZMQInteractiveShell self run cell args kwargs File C ProgramData Anaconda3 lib site packages IPython core interactiveshell py line 2717 in run cell interactivity interactivity compiler compiler result result File C ProgramData Anaconda3 lib site packages IPython core interactiveshell py line 2827 in run ast nodes if self run code code result File C ProgramData Anaconda3 lib site packages IPython core interactiveshell py line 2881 in run code exec code obj self user global ns self user ns File ipython input 17 6e018316c758 line 1 in module runfile 'C Users System Error Downloads report1 regression tf py' wdir 'C Users System Error Downloads report1' File C ProgramData Anaconda3 lib site packages spyder utils site sitecustomize py line 880 in runfile execfile filename namespace File C ProgramData Anaconda3 lib site packages spyder utils site sitecustomize py line 102 in execfile exec compile f read filename 'exec' namespace File C Users System Error Downloads report1 regression tf py line 99 in module main File C Users System Error Downloads report1 regression tf py line 92 in main regression train File C Users System Error Downloads report1 regression tf py line 67 in train prediction self network data File C Users System Error Downloads report1 regression tf py line 26 in network dense1 tf layers dense net input 64 File C ProgramData Anaconda3 lib site packages tensorflow python layers core py line 250 in dense return layer apply inputs File C ProgramData Anaconda3 lib site packages tensorflow python layers base py line 671 in apply return self call inputs args kwargs File C ProgramData Anaconda3 lib site packages tensorflow python layers base py line 559 in call self build input shapes 0 File C ProgramData Anaconda3 lib site packages tensorflow python layers core py line 145 in build trainable True File C ProgramData Anaconda3 lib site packages tensorflow python layers base py line 458 in add variable trainable trainable and self trainable File C ProgramData Anaconda3 lib site packages tensorflow python ops variable scope py line 1203 in get variable constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variable scope py line 1092 in get variable constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variable scope py line 425 in get variable constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variable scope py line 394 in true getter use resource use resource constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variable scope py line 805 in get single variable constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variables py line 213 in init constraint constraint File C ProgramData Anaconda3 lib site packages tensorflow python ops variables py line 356 in init from args self snapshot array ops identity self variable name read File C ProgramData Anaconda3 lib site packages tensorflow python ops array ops py line 125 in identity return gen array ops identity input name name File C ProgramData Anaconda3 lib site packages tensorflow python ops gen array ops py line 2070 in identity Identity input input name name File C ProgramData Anaconda3 lib site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File C ProgramData Anaconda3 lib site packages tensorflow python framework ops py line 2956 in create op op def op def File C ProgramData Anaconda3 lib site packages tensorflow python framework ops py line 1470 in init self traceback self graph extract stack pylint disable protected access FailedPreconditionError see above for traceback Attempting to use uninitialized value dense 18 bias Node dense 18 bias read Identity T DT FLOAT class loc dense 18 bias device job localhost replica 0 task 0 device CPU 0 dense 18 bias I searched stack overflow most of the answers told me to add an global variables initializer and I tried tf Session and tf InteractiveSession global and local variables initializer but still got this error,,mrry,2017-12-07 04:04:51,2017-12-07 04:10:34
PR,Branch 178185697,,,"caisq,caisq,caisq,ppwwyyxx,gunan",2017-12-07 03:47:41,2017-12-07 05:12:02
IS,Passing clear devices True to SavedModelBuilder add meta graph and variables loses function definitions,The SavedModelBuilder inadvertently strips all function definitions from the MetaGraphDef when clear devices True See this gist for a repro thanks for finding it The bug appears to stem from export meta graph which builds a GraphDef by selective field copying when certain options such as clear devices True are passed Passing clear devices False enables the code to succeed However it breaks compatibility between tf data and potentially other code and SavedModel so we should find a sustainable fix Can you please take a look Thanks,,mrry,2017-11-01 00:14:12,2017-12-07 05:13:24
IS,Strange Dataset API behaviour,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version sys version info major 3 minor 4 micro 3 releaselevel 'final' serial 0 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version Cuda 8 0 GPU model and memory Titan XP 12Gb Exact command to reproduce Describe the problem I get very strange behaviour of image read function See attached screenshot from tensorboard This is NOT a tensorboard problem as I get images as they are from Dataset object kodak messed Source images are fine I have attached a zip archive with source images Kodak zip Any current image with portrait orientation seems to be read incorrectly Source code logs There are no logs that could help,,mrry,2017-12-06 11:38:01,2017-12-07 05:13:24
IS,Tensorflow 1 3 with Python 3 6 2 under Windows 10 64 Bit OS has issue when run tensorflow tensorflow examples image retraining label image py,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 X64 Enterprise Edition TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version Anaconda 4 4 0 Python 3 6 2 Bazel version if compiling from source no CUDA cuDNN version No GPU model and memory No Exact command to reproduce tensorflow13 C Users James Tensorflow model retrain tensorflow for poets 2 scripts python label image py image c Users James Tensorflow sample img Panda001 jpg graph c Users James Tensorflow model retrain tensorflow for poets 2 scripts retrained graph pb labels C Users James Tensorflow model retrain tensorflow for poets 2 scripts retrained labels txt You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Error Log 2017 09 01 09 27 46 902115 I C tf jenkins home workspace nightly win M windows PY 36 tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use AVX AVX2 Traceback most recent call last File label image py line 120 in module input operation graph get operation by name input name File C Users James AppData Local conda conda envs tensorflow13 lib site packages tensorflow python framework ops py line 3225 in get operation by name return self as graph element name allow tensor False allow operation True File C Users James AppData Local conda conda envs tensorflow13 lib site packages tensorflow python framework ops py line 3097 in as graph element return self as graph element locked obj allow tensor allow operation File C Users James AppData Local conda conda envs tensorflow13 lib site packages tensorflow python framework ops py line 3157 in as graph element locked graph repr name KeyError The name 'import input' refers to an Operation not in the graph,,"drpngx,MarkDaoust,MarkDaoust,gunan",2017-09-01 01:41:43,2017-12-07 05:13:24
IS,Tensorflow how to save restore tf data Dataset,I made a model with tf data Dataset as a data IO function then i exported the graph and tried to restore it with meta graph file But it failed and following error messages occurred I think that tf data Dataset made a C object instead of python queue used before And the graph def only has a C object handler reference so the graph def alone without real C object can not load complete graph How can I load a executable graph with tf data Dataset Or is it impossible for now But the graphs with tf data Dataset make a error message above,,"mrry,mrry",2017-12-01 01:40:47,2017-12-07 05:13:24
IS,tensorflow python session list devices test fails on X86,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Installed from source TensorFlow version use command below TF 1 3 1 Python version Python 2 7 12 Bazel version if compiling from source Bazel 0 5 4 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel test config opt tensorflow python session list devices test Describe the problem Following 3 sub tests are failing on Ubuntu 16 04 x86 with the assertion errors 1 FAIL testListDevices main SessionListDevicesWithCApiTest L39 self assertGreaterEqual 1 len devices devices Getting AssertionError due to 1 unexpectedly not greater than or equal to 3 2 FAIL testListDevicesGrpcSession main SessionListDevicesWithCApiTest L47 self assertGreaterEqual 1 len devices devices Getting AssertionError due to 1 unexpectedly not greater than or equal to 3 3 FAIL testListDevicesClusterSpecPropagation main SessionListDevicesWithCApiTest L66 self assertGreaterEqual 2 len devices devices Getting AssertionError due to 2 unexpectedly not greater than or equal to 6 Is this is a known failure can we ignore or I am missing something here Please provide your comments on this Thanks Source code logs,,"sandipmgiri,tatatodd,sandipmgiri",2017-11-20 08:59:18,2017-12-07 05:13:24
PR,variables get global step is deprecated,variables get global step is deprecated use training util get global step instead WARNING message,,caisq,2017-12-05 03:15:41,2017-12-07 05:17:22
PR,Fix some Bash issues,Argument mixes string and array Use or separate argument Do not use on the left side of assignments,,"Androbin,caisq",2017-12-06 20:35:47,2017-12-07 05:17:50
IS,GPU memory increases in multiples of batch size 64 with allow growth True,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 4 0 14 gb5df90f' '1 4 1' Python version 2 7 12 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 6 CUDA cuDNN version V9 0 176 GPU model and memory V100 AWS P3 8X large instance Exact command to reproduce Inception V3 training as mentioned in models research slim python train image classifier py Describe the problem GPU memory is increasing in multiples of batch size of 64 Using 8 9 GB of GPU memory for batch size 16 or batch size 32 or batch size 64 And using 15 6 GB of GPU memory for batch size 96 and batch size 128 I would like to use batch size 96 so allocator wo not throw warnings during global step as it will have 2 3 GB unused Is this a feature Can we change its functioning,,"drpngx,vrv",2017-12-05 14:08:47,2017-12-07 05:18:41
IS,summary image op test failure on ppc64le,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 SLES RHEL ppc64le TensorFlow installed from source or binary source TensorFlow version use command below master Python version 2 7 4 Bazel version if compiling from source 0 4 5 CUDA cuDNN version GPU model and memory Exact command to reproduce bazel test c opt local resources 4096 4 0 1 0 j 1 test output errors tensorflow python kernel tests summary image op test You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request This test fails when run with c opt it passes with dbg fastbuild Recently there was a commit link below adjusting the tolerance value to pass this test it however fails for 'opt' build even after the change Issue Commit fixing this Is it okay to ignore the 'opt' build failure or should this issue be root caused further thanks Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Not equal to tolerance rtol 2e 05 atol 2e 05 None mismatch 2 85714285714 x array 221 102 129 y array 221 102 129 Ran 3 tests in 0 052s FAILED failures 1 not close where array 3 array 6 array 0 not close lhs 0 not close rhs 1 not close dif 1 not close tol 3 99999990e 05 dtype uint8 shape 5 7 1 Target tensorflow python kernel tests summary image op test up to date bazel bin tensorflow python kernel tests summary image op test INFO Elapsed time 9 223s Critical Path 1 12s tensorflow python kernel tests summary image op test FAILED root cache bazel bazel root 55751bac5fd009d8cf4f164f81814728 execroot tenso Executed 1 out of 1 test 1 fails locally,,"skye,gunan,sandipmgiri,gunan,sandipmgiri,gunan,sandipmgiri,sandipmgiri",2017-08-16 11:54:16,2017-12-07 05:59:37
PR,typo fixed,thats that is,,,2017-11-10 03:33:02,2017-12-07 07:57:16
PR,Change path,change path,,sb2nov,2017-11-23 15:19:01,2017-12-07 08:03:24
IS,Adding a variable of learning rate for each layer,I am wondering that is it easy to add a variable in tf get variable function which allows us to initialize the learning rate for each layer easily Since I found out that it is not easy to do in tensorflow but easy to do in other toolboxes,,"drpngx,facaiy,drpngx",2017-10-18 10:14:53,2017-12-07 10:26:55
IS,Not found Op type not registered 'CountExtremelyRandomStats',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS sierra 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version 3 5 2 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel bin tensorflow serving model servers tensorflow model server port 9000 model name rf quora model base path serving rf model rf log You can collect some of this information using our environment capture script cat etc issue Darwin xxxxxxxxxx 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 Mac OS X 10 12 6 are we in docker No compiler Apple LLVM version 9 0 0 clang 900 0 38 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Library Developer CommandLineTools usr bin uname a Darwin xxxxxxxxxx 16 7 0 Darwin Kernel Version 16 7 0 Thu Jun 15 17 36 27 PDT 2017 root xnu 3789 70 16 2 RELEASE X86 64 x86 64 check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi abc sh line 105 nvidia smi command not found cuda libs Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am getting the following error while running bazel command in the docker container command ran bazel bin tensorflow serving model servers tensorflow model server port 9000 model name rf quora model base path serving rf model rf log error Not found Op type not registered 'CountExtremelyRandomStats' in binary running on 864822af1c6c Make sure the Op and Kernel are registered in the binary running in this process I tried my search with the following link but in vain I am trying to do inference using tensorflow tensorserving but I am getting blocked by the above error Using Tensorflow 1 3 and using tensor forest api present in tf contrib tensor forest python Can anyone help me with this error as it is blocking my testing Note I have successfully ran tensorserving inference for mnist and inception examples models Source code logs 2017 11 08 07 27 45 038637 I tensorflow serving model servers main cc 147 Building single TensorFlow model file config model name rf quora model base path serving rf model 2017 11 08 07 27 45 038846 I tensorflow serving model servers server core cc 441 Adding updating models 2017 11 08 07 27 45 038879 I tensorflow serving model servers server core cc 492 Re adding model rf quora 2017 11 08 07 27 45 140519 I tensorflow serving core basic manager cc 705 Successfully reserved resources to load servable name rf quora version 1 2017 11 08 07 27 45 140575 I tensorflow serving core loader harness cc 66 Approving load for servable version name rf quora version 1 2017 11 08 07 27 45 140608 I tensorflow serving core loader harness cc 74 Loading servable version name rf quora version 1 2017 11 08 07 27 45 140647 I external org tensorflow tensorflow contrib session bundle bundle shim cc 360 Attempting to load native SavedModelBundle in bundle shim from serving rf model 1 2017 11 08 07 27 45 140685 I external org tensorflow tensorflow cc saved model loader cc 236 Loading SavedModel from serving rf model 1 2017 11 08 07 27 45 159712 I external org tensorflow tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that this TensorFlow binary was not compiled to use SSE4 1 SSE4 2 AVX AVX2 FMA 2017 11 08 07 27 45 192628 I external org tensorflow tensorflow cc saved model loader cc 284 Loading SavedModel fail Took 51931 microseconds 2017 11 08 07 27 45 192711 E tensorflow serving util retrier cc 38 Loading servable name rf quora version 1 failed Not found Op type not registered 'CountExtremelyRandomStats' in binary running on 864822af1c6c Make sure the Op and Kernel are registered in the binary running in this process,,drpngx,2017-11-08 10:49:04,2017-12-07 14:14:07
PR,DOC underline that tf Print behaves like tf identity,As suggested in 14788 fix the docstring print should have the same behavior as identity and it does The pr is opposed to 15068,,"facaiy,alextp",2017-12-03 02:54:23,2017-12-07 15:19:17
PR,DOC Fix documentation for inverse time decay,Fix the example in the documentation of inverse time decay and correct the pseudo code formula,,,2017-12-03 14:19:36,2017-12-07 15:20:34
IS,tf print makes a variable a constant,,,"facaiy,carlthome,facaiy,facaiy,carlthome,alextp,facaiy,alextp,facaiy,alextp",2017-11-22 09:14:17,2017-12-07 15:29:39
PR,Fix assert called error on Python3,by replacing it with assertTrue called,,"caisq,caisq",2017-12-07 15:17:07,2017-12-07 15:34:59
PR,Use argmax output type argument instead of cast op,argmax supports int32 output type since e3d99f4d8c0fb5479a0e7abb8623eb9ccab7c0ba so use it instead of cast op inside those helpers,,resec,2017-12-07 07:37:03,2017-12-07 16:25:21
IS,Error while implementing the feature requested in 10767,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 RHEL 6 8 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc1 5326 gcae852a' '1 4 0' Python version 2 7 14 Bazel version if compiling from source Build label 0 5 4 non git GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version Not installed GPU model and memory Using tensorflow for CPU Exact command to reproduce I want to implement in top k operation with options to specify what to do when a tie occurs for CIFAR 10 data set I came across this feature request in 10767 modified the 6 files as shown here and rebuilt from source When I run eval CIFAR10 py which contains the in top k op I get the following error File eval CIFAR10 py line 146 in module tf app run File usr local lib python2 7 site packages tensorflow python platform app py line 129 in run sys exit main argv File eval CIFAR10 py line 141 in main evaluate File eval CIFAR10 py line 130 in evaluate eval once saver summary writer top k op summary op File eval CIFAR10 py line 63 in eval once saver restore sess ckpt model checkpoint path File usr local lib python2 7 site packages tensorflow python training saver py line 1686 in restore self saver def filename tensor name save path File usr local lib python2 7 site packages tensorflow python client session py line 889 in run run metadata ptr File usr local lib python2 7 site packages tensorflow python client session py line 1120 in run feed dict tensor options run metadata File usr local lib python2 7 site packages tensorflow python client session py line 1317 in do run options run metadata File usr local lib python2 7 site packages tensorflow python client session py line 1336 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Multiple OpKernel registrations match NodeDef 'in top k InTopKV2 InTopKV2 T DT INT32 handle ties SAMPLE softmax linear softmax linear Reshape 2 in top k InTopKV2 k ' 'op InTopKV2 device type CPU constraint name T allowed values list type DT INT32 host memory arg predictions host memory arg targets host memory arg k host memory arg precision ' and 'op InTopKV2 device type CPU constraint name T allowed values list type DT INT32 host memory arg predictions host memory arg targets host memory arg k host memory arg precision ' Node in top k InTopKV2 InTopKV2 T DT INT32 handle ties SAMPLE softmax linear softmax linear Reshape 2 in top k InTopKV2 k Caused by op u'in top k InTopKV2' defined at File eval CIFAR10 py line 146 in module tf app run File usr local lib python2 7 site packages tensorflow python platform app py line 129 in run sys exit main argv File eval CIFAR10 py line 141 in main evaluate File eval CIFAR10 py line 116 in evaluate top k op tf nn in top k logits labels 1 handle ties SAMPLE File usr local lib python2 7 site packages tensorflow python ops nn ops py line 2523 in in top k return gen nn ops in top kv2 predictions targets k handle ties name name File usr local lib python2 7 site packages tensorflow python ops gen nn ops py line 2536 in in top kv2 handle ties handle ties name name File usr local lib python2 7 site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File usr local lib python2 7 site packages tensorflow python framework ops py line 3101 in create op op def op def File usr local lib python2 7 site packages tensorflow python framework ops py line 1583 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback Multiple OpKernel registrations match NodeDef 'in top k InTopKV2 InTopKV2 T DT INT32 handle ties SAMPLE softmax linear softmax linear Reshape 2 in top k InTopKV2 k ' 'op InTopKV2 device type CPU constraint name T allowed values list type DT INT32 host memory arg predictions host memory arg targets host memory arg k host memory arg precision ' and 'op InTopKV2 device type CPU constraint name T allowed values list type DT INT32 host memory arg predictions host memory arg targets host memory arg k host memory arg precision ' Node in top k InTopKV2 InTopKV2 T DT INT32 handle ties SAMPLE softmax linear softmax linear Reshape 2 in top k InTopKV2 k If you can kindly look into the matter I shall be much helped Thank you,,"drpngx,drpngx,drpngx",2017-12-01 09:34:33,2017-12-07 17:35:10
IS,Understanding LSTM cell Kernel values,Hi all I want to understand better those values in LSTM cell Kernel values extracted from tf Variable 'rnn multi rnn cell cell 0 lstm cell kernel 0' shape 97 280 dtype float32 ref from tf trainable variables My model is very simple input is a 27 element vector at each time step where the sequence length can be variable The model is one layer LSTM model with 70 hidden states So that is probably why the LSTM kernel is a matrix of 97 rows 27 input features and 70 hidden states As to the columns I can clearly see four groups by the pattern of values I guess each group is consist of 70 columns so totally 4 groups So my guess is that this LSTM kernel extracted from tf trainable variables maps input and previous hidden states to current hidden states in order of forget input update cell states and output However it is hard time for me to figure out the correspondence of these gates and their matrices with the Kernel matrix extracted from tf trainable variables Could somebody help Thanks Update Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary from pip TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 1 GPU model and memory k2200,,reedwm,2017-12-04 05:57:32,2017-12-07 18:48:10
PR,Add un fed placeholder warning to negative dimension error,Sometimes a user runs a tensor and forgets to initialize one of its placeholders in feed dict If that placeholder has a shape that includes None the None gets converted to 1 and rejected at the C level resulting in confusing error messages each word a separate link This problem also appears in 11371 This PR is a two line change that briefly mentions this issue in the exception string The hope is that it will help developers find the problem more quickly,,caisq,2017-12-07 11:33:57,2017-12-07 19:09:47
PR,MKL Revving mkl dnn to include all changes before 2017 11 20,This commit will pull the latest changes from the mkl dnn tree the mirror bazel build URL does not exist can you create it,,"claynerobison,caisq,caisq",2017-12-05 22:30:35,2017-12-07 19:36:08
PR,CMake Re Enable include,Issue 3996 and referenced tickets are already fixed,,"Androbin,mrry,Androbin,caisq,Androbin,Androbin",2017-12-04 15:14:13,2017-12-07 19:57:52
PR,Cherrypicks for 1 4 1,,,"av8ramit,av8ramit",2017-12-07 18:03:50,2017-12-07 20:04:34
PR,Training test fix,,,av8ramit,2017-12-07 21:14:45,2017-12-07 21:59:57
IS,Add sparse tensor support to tf data Dataset,The tf data Dataset class does not currently recognize a tf SparseTensor object as a component of a dataset element This makes it difficult to use the full capabilities of SparseTensor producing ops such as tf parse single example in Dataset map transformations and then manipulating those elements using operations like Dataset batch The existing tf train batch and related functions for queue based pipelines support tf SparseTensor and we should add support to Dataset for parity This Stack Overflow answer suggests some possible workarounds in the meantime,,"mrry,mrry,ebrevdo,mrry,mrry,jsimsa,mrry",2017-10-17 01:11:01,2017-12-07 23:51:42
IS,BatchNorm gamma not found in checkpoint,I trained a model with tensorflow1 4 and want to finetune in tensorflow 1 3 following is part of my code 1 train code with tf1 4 with slim arg scope inception v3 inception v3 arg scope y endpoints inception v3 inception v3 x CLASSES True 2 test code with master with slim arg scope inception v3 inception v3 arg scope y end points inception v3 inception v3 x label dim False with tf name scope 'train' loss custom function loss function y y train op custom function train function loss learn rate accuracy op custom function accuracy function y y output result custom function output result y init op tf group tf global variables initializer tf local variables initializer saver tf train Saver sess config tf ConfigProto allow soft placement True log device placement False sess config gpu options allow growth True sess tf Session config sess config merged summary tf summary merge all train writer tf summary FileWriter log dir sess graph saver tf train import meta graph 'model meishi inception v3 graph 1205 190241 meta' clear devices True sess run init op coord tf train Coordinator threads tf train start queue runners sess sess coord coord saver restore sess model meishi model 6690 saver restore sess model meishi inception v3 model 12042 error is NotFoundError see above for traceback Key InceptionV3 Mixed 7b Branch 2 Conv2d 0a 1x1 BatchNorm gamma not found in checkpoint at first i think the reason is slim argscope is not the same in these two version tensorflow and I tried to replace the slim of tf1 4 with the slim of master but the error still exist what is the problem of my code thx,,reedwm,2017-12-06 09:43:25,2017-12-07 23:55:17
PR,fix 15188 replaced isnan with std isnan to avoid build error,,,"gunan,yongtang,hawkinsp,gunan,gunan,gunan,hawkinsp",2017-12-07 18:13:22,2017-12-08 01:07:34
IS,error 'isnan' was not declared in this scope,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below Master branch commit 4ad12049 Python version N A Bazel version if compiling from source GCC Compiler version if compiling from source g 5 4 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build tensorflow libtensorflow so Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I'm trying to compile using bazel build tensorflow libtensorflow so I'm getting this error,,,2017-12-07 18:08:14,2017-12-08 01:08:11
IS,model fit crash keras example mnist TensorFlow1 4,I run example but it crashed when train namely model fit The error is An error ocurred while starting the kernel tensorflow core platform cpu feature guard cc 137 Your CPU supports instructions that thisTensorFlow binary was not compiled to use AVX AVX2 tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 04 00 0 compute capability 6 1 tensorflow stream executor cuda cuda dnn cc 385 could not create cudnn handle CUDNN STATUS INTERNAL ERROR tensorflow stream executor cuda cuda dnn cc 352 could not destroy cudnn handle CUDNN STATUS BAD PARAM tensorflow core kernels conv ops cc 667 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo algorithms And I run another example it crashed too when run at model fit but the error is not the same An error ocurred while starting the kernel tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name GeForce GTX 1080 Ti pci bus id 0000 04 00 0 compute capability 6 1 tensorflow stream executor cuda cuda dnn cc 385 could not create cudnn handle CUDNN STATUS INTERNAL ERROR tensorflow stream executor cuda cuda dnn cc 352 could not destroy cudnn handle CUDNN STATUS BAD PARAM tensorflow core kernels conv ops cc 667 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo algorithms My environment win7 tensorflow gpu 1 4 cuda 8 0 cudnn6 0 GeForce GTX 1080 Ti I really appreciate your help,,"reedwm,mrry",2017-12-06 11:21:26,2017-12-08 01:40:37
PR,Branch 178260923,,,"ankurtaly,ankurtaly,caisq,caisq,caisq",2017-12-07 19:16:28,2017-12-08 02:05:43
PR,Fix a typo in estimators md,A small typo similarily similarly,,yongtang,2017-12-07 22:42:41,2017-12-08 02:14:43
PR,Fix ios makefile inc for TFLite iOS demo app,It seems broken when merging change in b2db981a6731e978453862a73dab892bc674db68 The file was formatted with an invalid way I'm simply reverting the change I do not know why it happened Is it due to the inc file extension name,,miaout17,2017-12-07 19:09:35,2017-12-08 02:15:06
PR,Fix the iOS makefile on tensorflow lite,Just make it right Ref,,caisq,2017-12-05 08:08:41,2017-12-08 03:06:07
PR,Fix tag in source remote test no mac nomac,,,"caisq,caisq",2017-12-08 02:19:29,2017-12-08 03:14:19
PR,1 4 1 Release Updates,,,av8ramit,2017-12-08 04:08:25,2017-12-08 04:12:19
PR,Create test txt,,,,2017-12-08 05:45:51,2017-12-08 05:46:52
PR,Upgrade cuda to 9 and cudnn version to 7,,,"gunan,yifeif,gunan,gunan,gunan,gunan,gunan,zheng-xq,gunan,flx42,gunan,snnn,gunan,flx42,gunan",2017-11-21 22:44:58,2017-12-08 07:19:46
IS,Failure in LMDBReaderTest while reading testdata,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 s390x Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 4 0 Python version 2 7 12 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc 5 4 0 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce bazel test c opt tensorflow python kernel tests reader ops test Describe the problem While executing reader ops test came across failure in LMDBReaderTest Since I am running it on a big endian system the failure could be because the testdata data mdb is platform specific and hence gets interpreted wrongly Is my understanding correct How can I generate the above testdata for s390x big endian Source code logs,,"namrata-ibm,reedwm,bowang,namrata-ibm,namrata-ibm",2017-12-07 08:44:16,2017-12-08 12:06:02
PR,Delete Dockerfile devel gpu cuda9 cudnn7,our default dockerfiles now use cuda9 cudnn7 No need for this file anymore CC,,"gunan,flx42,gunan,flx42,gunan",2017-12-08 07:28:47,2017-12-08 14:11:29
PR,add link to decode bmp,add link to decode bmp to image api guide,,"freedomtan,drpngx",2017-12-01 02:43:37,2017-12-08 15:04:13
PR,MSVC Add tensorflow ops prefix for Read Write File,ReadFile and WriteFile collide with the functions in windows h Tell MSVC we want Tensorflow is ones,,"rongjiecomputer,caisq",2017-12-08 00:46:53,2017-12-08 15:56:57
IS,Feature GANEstimator allow passing of namedtuples,In the current GANEstimator implementation in train py gan model both real data as well as generator inputs is converted to tensors with either convert tensor or l or d or ops convert to tensor This prevents the user from using own data structures like namedtuples to pass information between the generator and discriminator In the current implementation when passing a namedtuple the result will be a list with all name information being lost I propose to either extend the tensor conversion to exclude namedtuples from them or to remove them entirely shor Do you think that is a good idea I am currently passing logits as well as sample id from a dynamic decoding around and I would like to keep the meaning of these across loss fn and discriminator fn 1 I could remove the conversions entirely This would introduce breaking changes 2 I could exclude namedtuples from the conversion 3 Idk yet I would create a PR for any of them if we find a suitable solution,,"facaiy,joel-shor",2017-12-06 14:44:17,2017-12-08 18:15:24
IS,Unhelpful exceptions from tf truncated normal with dtype tf int32,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 LTS TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version Python 2 7 6 Bazel version if compiling from source N A CUDA cuDNN version N A CPU GPU model and memory N A Exact command to reproduce python c import tensorflow as tf tf truncated normal 1 dtype tf int32 Describe the problem When attempting to initialize a tf Variable of type tf int32 using Source code logs See above,,drpngx,2017-09-06 23:30:16,2017-12-08 18:59:02
IS,Subclasses of Estimator cannot override members of Estimator,Any reason for not allowing subclasses of Estimator to override members other than ' call input fn' ' create global step',,rohan100jain,2017-09-08 13:04:08,2017-12-08 18:59:06
IS,Dataset from generator does not support strings,I have hit the same problem described in I think it is a missing feature instead of a bug,,mrry,2017-12-08 19:10:31,2017-12-08 19:26:17
IS,stdin,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,reedwm,2017-12-08 19:24:08,2017-12-08 19:44:30
IS,tfcompile error no matching function for call to 'transform',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No This is on a clean checkout of tensorflow OS Platform and Distribution e g Linux Ubuntu 16 04 OSX Sierra TensorFlow installed from source or binary source TensorFlow version use command below building from master command outputs 1 3 0 Python version 2 7 Bazel version if compiling from source 0 6 0 GCC Compiler version if compiling from source Configured with prefix Applications Xcode app Contents Developer usr with gxx include dir usr include c 4 2 1 Apple LLVM version 9 0 0 clang 900 0 38 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin CUDA cuDNN version N A ran configure without CUDA GPU model and memory N A no GPU Exact command to reproduce 1 Check out tensorflow 2 Run configure enable XLA support 3 cd tensorflow compiler aot 4 bazel build tfcompile Describe the problem This happens across multiple OSes as well we tried to compile on a unix distro with the same error Source code logs This seems to stem from a recent change in kernel support library cc specifically diff 877daea43ebeb1cd4756f960400ee922,,powderluv,2017-12-08 19:23:08,2017-12-08 20:23:06
IS,GatherNd InvalidArgumentError flat indices 8 8 1 does not index into param,System information OS Platform and Distribution Ubuntu 17 10 Linux 4 13 0 17 generic x86 64 with debian stretch sid TensorFlow installed from binary TensorFlow version v1 3 0 rc2 20 g0787eee 1 3 0 same on 1 4 0 Python version 3 6 3 GPU model and memory N A CPU only Numpy version 1 13 3 Bazel version N A CUDA cuDNN version N A C compiler version Ubuntu 7 2 0 8ubuntu3 7 2 0 Have I written custom code Yes Exact command to reproduce There is no single command The error arises when trying to fetch a TensorFlow tensor Please see the description below Describe the problem I am training a recurrent neural network RNN whereby I give it variable length sequences of random steps in two dimensions and train it to recognize the quadrant in which the random walker ended up This RNN works fine on a Windows machine with GPU all other specs are otherwise the same as above However on a Linux machine with CPU only I get an error which mysteriously traces back to a dimensionality hiccup with GatherNd The code for the full RNN is too convoluted to post but as you can see from below I am printing out the fetches to two tensors tf weights and tf last at each iteration of the batching In this case the training data is consumed one batch at a time for a total of 28 batches The batches are very basic loops so you would think that if a fetch works in one iteration of the loop it should also work for the next This is indeed the case for tf weights but not for tf last which for no apparent reason fails to evaluate at batch 7 28 tf last can be traced to a GatherNd operation I thoroughly inspected the data and it looks fine Please keep in mind that my code does work under Windows with GPU with all other specs remaining the same so it is hard to conceive of a bug from within the code itself Source code,,"reedwm,ebrevdo,ebrevdo,ebrevdo,reedwm,ebrevdo",2017-12-04 09:45:44,2017-12-08 20:47:35
IS,Tensorflow broken by new Bazel versions,Simplest way to reproduce the issue run bazel build config opt incompatible load argument is label nobuild tensorflow tools pip package build pip package Suggested fix to tensorflow third party sycl sycl BUILD tpl This should address the immediate need There are other issues to fix although not as pressing You can see them by building using all incompatible changes Let me know if you need any help Thanks,,"reedwm,gunan,angersson,angersson",2017-12-05 18:46:47,2017-12-08 22:42:29
PR,Also install libssl dev to make pip py3 6 work properly,,,gunan,2017-12-08 23:40:37,2017-12-09 00:14:40
IS,upgraded tensorflow to use GPU she is a no worky anymore,Script was running fine if a bit slow Decided it was time to upgrade to the gpu version of tensorflow From what I can tell for some reason it is looking for libcublas so 8 0 Since I just upgraded to the latest cuda libs I'm running libcublas so 9 0 176 found in usr local cuda 9 0 lib64 and yes that is in my path first item by the way Using TensorFlow backend Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-12-01 21:53:25,2017-12-09 01:40:31
IS,Build Tensorflow Lite C API into a dynamic library for Android,Is there any way of building the Tensorflow Lite C API into a dynamic library for Android I have tried to build with bazel for armv7a but this only gives the corresponding static libraries bazel build c opt tensorflow contrib lite crosstool top external android crosstool cpu armeabi v7a host crosstool top bazel tools tools cpp toolchain cxxopt std c 11 verbose failures,,"aselle,drpngx",2017-11-21 12:59:30,2017-12-09 01:41:23
IS,XLA Reshape test failing for 3rd party platforms,I have opened a discussion on the XLA dev mailing list but I think that this counts as an issue since if it is not fixed then potentially all XLA tests will migrate to being unusable for 3rd party devices topic xla dev 9cY21Hi0s s The issue is that the code in reshape test cc assumes that any devices which are not CPU CPU PARALLEL GPU will use the bfloat16 format This is not true for the Graphcore device,,"DavidNorman,DavidNorman,ukoxyz,drpngx",2017-12-05 12:03:28,2017-12-09 01:45:52
IS,Documentation required for SetIsStateful method in OP registration,There are some examples with custom ops that use SetIsStateful method during registration e g But there is no documentation about that method,,"aselle,drpngx",2017-12-04 17:05:47,2017-12-09 01:48:32
IS,XLA OSX tfcompile compile failure in llvm ir kernel support library cc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 OSX 10 13 2 TensorFlow installed from source or binary Source TensorFlow version use command below Top of Master 34bcd09c5fd4f6435517a499987b7e5044c8f2c0 Python version Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source Apple LLVM version 9 0 0 clang 900 0 39 2 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build tensorflow compiler aot tfcompile Describe the problem Compiler error when compiling tfcompile on OSX This was introduced by Commit You will need this PR to be able to fix other compile issues on OSX ERROR Users tfninja github tensorflow tensorflow compiler xla service llvm ir BUILD 171 1 C compilation of rule ' tensorflow compiler xla service llvm ir kernel support library' failed Exit 1 tensorflow compiler xla service llvm ir kernel support library cc 99 5 error no matching function for call to 'transform' std transform function arg begin function arg end Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr include c v1 algorithm 1922 1 note candidate template ignored could not infer template argument ' UnaryOperation' transform InputIterator first InputIterator last OutputIterator result UnaryOperation op Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr include c v1 algorithm 1932 1 note candidate function template not viable requires 5 arguments but 4 were provided transform InputIterator1 first1 InputIterator1 last1 InputIterator2 first2 1 error generated Target tensorflow compiler aot tfcompile failed to build Source code logs The issue seems to be with this line of code in which works on Linux but fails on OSX Clang tensorflow compiler xla service llvm ir kernel support library cc,,"powderluv,sanjoy,powderluv,powderluv",2017-12-08 01:14:47,2017-12-09 01:56:57
PR,Enable GCS filesystem for Windows,,,"snnn,mrry,snnn,mrry,snnn,mrry,snnn,drpngx,snnn,drpngx,snnn,mrry,snnn,mrry,drpngx",2017-11-24 06:45:14,2017-12-09 02:03:44
IS,tf contrib data Dataset filter documentation broken,With the old input pipeline functions in tf train batch you could specify the allow smaller final batch parameter which would allow or disallow a smaller final batch With the new input pipeline functions in tf contrib data the batch function allows a smaller final batch by default and to the best of my knowledge there is no way to skip this last half batch to ensure all batch sizes are equal Is there a possibility that a allow smaller final batch flag could be added to the new batch function,,"vrv,vrv",2017-07-26 01:36:39,2017-12-09 02:24:27
PR,Update gitignore,,,"Androbin,caisq,caisq",2017-12-08 21:58:57,2017-12-09 05:19:57
IS,tensorboard does not show my graph,In the morning I can use the following command to open my graph tensorboard logdir graph file dir However in the evening I use another PC I can not see my graph any more Error Information is image Then I tried to use the following command to inspect the content image I know there is only one top node in my graph called import Could any one help me to diagnose what could be the issue Thanks in advance,,,2017-12-09 07:34:06,2017-12-09 07:47:31
IS,tensorflow gpu on mac,I can use the following to install tensorflow on mac Python 2 pip install upgrade Python 3 pip3 install upgrade But I do not find the correponding files for tensorflow gpu Can it be generated and posted over there Thanks,,asimshankar,2017-12-09 04:55:15,2017-12-09 08:37:32
IS,ResidualWrapper and HighwayWrapper require rnn inputs' last dimension to be equal to num units,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce python from tensorflow contrib import rnn as rnn cell from tensorflow python ops import rnn import tensorflow as tf rnn inputs tf random uniform 10 10 10 cell rnn cell LSTMCell 128 cell rnn cell HighwayWrapper cell rnn cell ResidualWrapper cell rnn dynamic rnn cell rnn inputs dtype tf float32 Problem rnn cell ResidualWrapper and rnn cell HighwayWrapper throw an exception when rnn inputs' last dimension is not equal to num units Without wrappers the input tensor can be different from num units What is the reason for the different behaviour Is it intended Full Traceback,,ebrevdo,2017-12-08 18:49:46,2017-12-09 16:49:54
IS,When execute bash tensorflow contrib lite build ios universal lib sh it gives the error tensorflow tensorflow contrib lite ios makefile inc 2 missing separator Stop,System information Install problem Darwin MacBook Pro 2 local 16 7 0 Darwin Kernel Version 16 7 0 xnu 3789 71 6 1 RELEASE X86 64 x86 64 TensorFlow installed from source v1 0 0 rc2 15 g47bba63 dirty 1 0 0 Python 3 6 0 Anaconda custom x86 64 Bazel version None Apple LLVM version 9 0 0 clang 900 0 37 CUDA cuDNN version GPU model and memory Exact command to reproduce,,aselle,2017-12-03 08:23:51,2017-12-09 17:57:17
PR,fix typo,,,ManHyuk,2017-12-09 13:26:40,2017-12-09 20:20:45
IS,in minimize str v for v in grads and vars loss ValueError No gradients provided for any variable This error occurs while using minimize for an adam optimizer,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,drpngx,2017-12-09 20:19:06,2017-12-10 00:07:42
PR,pip sh unify the way virtualenv is invoked,between python3 6 and the other versions python m also seems to be a more robust way of calling virtualenv than relying on the virtualenv command on path,,"caisq,caisq",2017-12-08 16:49:10,2017-12-10 03:55:25
IS,Error while using cuda 9 0 libcublas so 8 0 cannot open shared object file No such file or directory,Hi I just installed cuda 9 0 and done all the requirements for cuda to run tensorflow like libcudnn7 7 0 5 15 1 cuda9 0 amd64 deb libcudnn7 dev 7 0 5 15 1 cuda9 0 amd64 deb The test example of libcudnn are working fine I installed tensorflow gpu it finished normally while using sudo pip3 install tensorflow gpu but at the time of import it gives me error ImportError libcublas so 8 0 cannot open shared object file No such file or directory Look like tensorflow does not support Cuda 9 0 Error is as follows ipython Python 3 5 2 default Nov 23 2017 16 37 01 Type 'copyright' 'credits' or 'license' for more information IPython 6 2 1 An enhanced Interactive Python Type ' ' for help In 1 import tensorflow as tf ImportError Traceback most recent call last usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py in module 57 58 from tensorflow python pywrap tensorflow internal import 59 from tensorflow python pywrap tensorflow internal import version usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py in module 27 return mod 28 pywrap tensorflow internal swig import helper 29 del swig import helper usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py in swig import helper 23 try 24 mod imp load module ' pywrap tensorflow internal' fp pathname description 25 finally usr lib python3 5 imp py in load module name file filename details 241 else 242 return load dynamic name filename file 243 elif type PKG DIRECTORY usr lib python3 5 imp py in load dynamic name path file 341 name name loader loader origin path 342 return load spec 343 ImportError libcublas so 8 0 cannot open shared object file No such file or directory During handling of the above exception another exception occurred ImportError Traceback most recent call last ipython input 1 64156d691fe5 in module 1 import tensorflow as tf usr local lib python3 5 dist packages tensorflow init py in module 22 23 pylint disable wildcard import 24 from tensorflow python import 25 pylint enable wildcard import 26 usr local lib python3 5 dist packages tensorflow python init py in module 47 import numpy as np 48 49 from tensorflow python import pywrap tensorflow 50 51 Protocol buffers usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py in module 70 for some common reasons and solutions Include the entire stack trace 71 above this error message when asking for help traceback format exc 72 raise ImportError msg 73 74 pylint enable wildcard import g import not at top unused import line too long ImportError Traceback most recent call last File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File usr lib python3 5 imp py line 242 in load module return load dynamic name filename file File usr lib python3 5 imp py line 342 in load dynamic return load spec ImportError libcublas so 8 0 cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary No use pip install tensorflow TensorFlow version use command below tensorflow gpu 1 4 1 cp35 cp35m manylinux1 x86 64 whl Python version Python 3 5 2 default Nov 23 2017 16 37 01 Bazel version if compiling from source No GCC Compiler version if compiling from source No CUDA cuDNN version cuda 9 0 GPU model and memory GeForce GT 750M Exact command to reproduce No just import tensorflow as tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"drpngx,drpngx,drpngx,drpngx,drpngx",2017-12-09 14:35:25,2017-12-10 12:36:45
IS,Install new TensorFlow via anaconda but failed,Hello When I tried to install TensorFlow via anaconda I ve searched the suitable cite to submit the issue but failed to find out it If this is not sorry for it and advice me The target os is 'windows 10' and via anaconda 5 0 1 For Windows Python 3 6 version 64bit After intall anaconda from my terminal 'cmd exe' conda create n tensorflow python 3 6 but received an error message But from 'Anaconda Prompt' below 'Anaconda3' of istart button' it works correctly Thus I recommend to include the following description start 'Anaconda Prompt' below 'Anaconda3' of istart button' between the steps,,,2017-12-09 08:04:49,2017-12-10 13:39:33
PR,fix typo,,,ManHyuk,2017-12-10 08:33:50,2017-12-10 15:04:33
PR,add support for quantized ops on windows,Quantized ops support on windows Added some simple python unit test to make sure it works Gotcha I need to use the latest version of gemmlowp in gemmlowp cmake which is not on mirror bazel build so I use github com directly for now This should provide the same functionality as tf on linux Performance could be better because msvc can not make use of the inline asm in gemmlowp compiling gemmlowp with clang would show much better results,,"guschmue,mrry,guschmue,mrry,gunan,caisq",2017-11-28 21:45:23,2017-12-10 18:39:03
PR,Go Adds Operations method to Graph,There is currently no way to list all of the operations in a graph from the go api This patch ads an Operations method to retrieve the list using the existing TF GraphNextOperation c api The graph test was modified to include testing this new method Signed off by Vishvananda Ishaya Abrams vishvananda gmail com,,"asimshankar,drpngx,caisq",2017-11-30 06:35:22,2017-12-10 18:52:57
PR,update Android libs,For android sample improve gitignore upgrade build tools to current most recent stable 3 0 1 add corresponding gradle,,"drpngx,drpngx,drpngx,drpngx,caisq",2017-12-02 11:18:26,2017-12-10 20:12:40
IS,Document S3 S3 REGION constant,This gave me a lot of grief recently as the AWS Region for S3 is controlled by an undocumented constant S3 REGION which defaults to us east 1 unless defined on the system level Extra frustrating as it departs from the common naming practice AWS REGION L52 If somebody could suggest where to document this I would be happy to contribute,,"aselle,jhseu,yongtang,yongtang",2017-11-28 19:16:21,2017-12-10 20:14:32
PR,Add AWS REGION env for S3 in TensorFlow,This fix tries to address the issue raised in 14951 where the region can only be specified with non common S3 REGION environment variables This fix adds the support of AWS REGION which takes precedence over S3 REGION This fix fixes 14951 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,caisq",2017-11-30 04:01:00,2017-12-10 20:14:32
PR,Fix typos,memory intialized memory initialized set memory intialized set memory initialized instrucion instruction elment element tensroflow tensorflow interpretted interpreted,,"ManHyuk,sb2nov,mrry,drpngx,drpngx,gunan",2017-11-27 08:41:27,2017-12-10 20:15:54
PR,Some PATH typo no train dir in tutorial,This file uses train dir But in code file there is no train dir anymore it should be replaced with log dir input data dir and checkpoint file respectively,,,2017-11-25 14:15:10,2017-12-10 20:17:01
PR,TFlite readme md add mobilenet frozen graph pb link,add mobilenet frozen graph pb link,,"drpngx,drpngx",2017-11-23 06:40:14,2017-12-10 20:24:21
PR,Wrong code in programmer is guide in Variable Section,In Programmer is guide Variable section the assignment variable is a tf Tensor and should use assignment op run instead of assignment run Otherwise this code would produce an error Or we can use sess run assignment to finish this assignment operation,,,2017-11-30 04:41:18,2017-12-10 20:31:28
PR,Update tf core framework cmake,To resolve this issue Replace gpu tracer cc with device tracer cc,,mrry,2017-11-27 04:03:49,2017-12-10 20:40:38
PR,Fix a typo in comment,its cached it is cached,,"mrry,drpngx",2017-11-28 01:01:44,2017-12-10 20:41:38
PR,Improve variance scaling initializer description,Added mention of the MRSA initialization alias This name has been mentioned in multiple publications initialization 22 btnG Mentioning it in the docs will make this initializer easier to find,,drpngx,2017-11-22 04:48:02,2017-12-10 20:56:13
PR,add extra document to parameter num epochs,Add extra documents to DatasetDataProvider I forget to call tf local variables initializer when I set num epochs to 1 I trace source code to find out that I need to do that I think put some extra documentation will help others to avoid this mistake,,caisq,2017-11-27 15:18:38,2017-12-10 21:04:48
PR,Remove non fused version of adjust saturation as GPU kernel already exists,In the existing implementation for adjust saturation the non fused version was still in place As the non fused is for non GPU support of adjust saturation and GPU kernel already exists now See commit 25c4f27 diff b53c223158b7c4fd248ef581da6566c2 it makes sense to remove the non fused version In addition with the removal of non fused implementation of adjust saturation now it is possible to provide batch support in 4 D instead of previous 3 D This resolves issue raised in 8926 This fix removed non fused version of adjust saturation and added additional test cases for batch support Note In PR 14187 non fused version of adjust hue has been removed so batch support for adjust hue has been enabled as well This PR also adds additional test cases for batch support of adjust hue Signed off by Yong Tang yong tang github outlook com,,"yongtang,alextp,yongtang,caisq",2017-11-22 12:48:44,2017-12-10 22:13:39
PR,update how tos reading data to use Dataset API,Since the Dataset API moved from contrib data into data core update the MNIST example to use Dataset over queues This was the first page I have found when searching how to best get data into TF and I thought it should reflect the current best practice Also if I understand correctly queues might be deprecated in favor of Datasets some time in the future,,"MarkDaoust,mrry,mrry,mrry,mrry,mrry,MarkDaoust,drpngx,drpngx,caisq",2017-11-21 11:43:50,2017-12-11 00:58:37
PR,Propagate DPCRE STATIC from pcre BUILD to swig BUILD,pcre internal h uses this macro to determine the content of PCRE EXP DECL So in order to keep consistent every file who includes pcre internal h directly or indirectly should also have this macro defined This pull request is for fix a build error on Windows hr ERROR C os t external swig BUILD bazel 5 1 Linking of rule ' swig swig' failed Exit 1120 link exe failed error executing command br misc o error LNK2019 unresolved external symbol imp pcre compile referenced in function Swig string regex br naming o error LNK2001 unresolved external symbol imp pcre compile misc o error LNK2019 unresolved external symbol imp pcre exec referenced in function Swig string regex br naming o error LNK2001 unresolved external symbol imp pcre exec br misc o error LNK2019 unresolved external symbol imp pcre version referenced in function Swig pcre version br misc o error LNK2001 unresolved external symbol imp pcre free br naming o error LNK2001 unresolved external symbol imp pcre free br bazel out host bin external swig swig exe fatal error LNK1120 4 unresolved externals br hr,,"snnn,vrv,snnn,jart,snnn,jart,snnn,jart,snnn,snnn,jart,gunan",2017-10-16 08:31:27,2017-12-11 01:24:26
IS,Potential memory leak from deleting array and closing file handler,Here are couple of minor memory leak for review 1 L569 L593 delete base looks missing 2 L164 L173 delete compressed length array looks missing when macro TF RETURN IF ERROR fails 3 L113 L123 Two potential problems a There is no fclose being called after fscanf fails b fclose could be called instead of pclose 4 L132 L137 When fwrite fails fclose could be called before return 1 PS I do not have handy working environment setup yet currently browsing code may be better fit for me,,"carlthome,carlthome,yongtang,yongtang,yongtang",2017-11-22 16:13:41,2017-12-11 01:44:54
PR,Fix several potential memory leaks,This fix fixes several potential memory leaks mostly caused by error return without proper deleting Note The original issue was raised by thanks This fix fixes 14800 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq",2017-11-23 02:28:25,2017-12-11 01:44:55
PR,improve int data type check in session,right now this would fail,,"mrry,mrry,mrry,mrry,martinwicke,mrry,martinwicke,martinwicke,caisq",2017-11-06 21:05:35,2017-12-11 02:11:52
IS,Keras Dropout support masking gets reset to False,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 6 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 1 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce see below You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request The Keras Dropout layer constructor tensorflow python keras impl keras layers core py sets support masking True and then calls its super constructor which sets it back to False Other layers defined in that module appear to set support masking True after the super constructor call Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"facaiy,fchollet,ZhengshengWei,facaiy,ZhengshengWei,ZhengshengWei",2017-11-23 04:24:01,2017-12-11 02:44:45
PR,fixed bug that Dropout support masking gets reset to False,fix 14819,,"ZhengshengWei,facaiy,ZhengshengWei,facaiy,drpngx,caisq",2017-11-23 10:18:50,2017-12-11 02:44:45
PR,Allow GANEstimator get hooks fn to be set manually,,,"joel-shor,joel-shor,joel-shor,caisq,joel-shor",2017-11-20 13:48:25,2017-12-11 03:40:05
PR,Instead of python use PYTHON BIN PATH in pip sh,,,"gunan,caisq,caisq,gunan,caisq,gunan,gunan,caisq,gunan,gunan",2017-12-10 08:22:47,2017-12-11 06:01:38
PR,Elastic Average optimizer,I have implemented a new distributed optimizer ElasticAverageOptimizer It is mentioned in the following issue 12472 EASGD is an async optimizer During the training Each worker will update the local variables and maintains its own local step which starts from 0 and is incremented by 1 after each update of local variables Whenever the communication period divides the local step the worker requests the current global center variables and then computed the elastic difference between global center variables and local variables The elastic difference then be used to update both local variables and global variables Reference,,"DjangoPeng,DjangoPeng,DjangoPeng,DjangoPeng,DjangoPeng,DjangoPeng,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,alextp,drpngx,yaroslavvb,sb2nov,sb2nov,DjangoPeng,drpngx,drpngx,DjangoPeng,yaroslavvb,alextp,DjangoPeng,alextp,alextp,alextp,alextp,caisq,caisq,caisq,caisq,drpngx,caisq,DjangoPeng",2017-09-13 11:46:22,2017-12-11 15:01:55
IS,Wrongly used dropout bug,Hi I guess it should use tf layers dropout instead of tf nn dropout here Because in the inference stage all the nodes should be used instead of dropout I guess this is a bug L92 Many thanks Best wishes Qiuqiang,,qmick,2017-12-11 12:00:13,2017-12-11 16:41:18
IS,tf estimator Estimator breaks when using python 3 5 type annotations,Minimal example System information OS Platform and Distribution Linux Mint 17 2 TensorFlow version v1 2 0 0 g12f033d 1 2 0 Python version 3 5,,"skye,martinwicke,yongtang",2017-08-13 12:49:10,2017-12-11 18:00:03
PR,Add annotations support for tf estimator Estimator,This fix adds annotations support for tf estimator Estimator so that the following works in python 3 This fix fixes 12249 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,martinwicke,martinwicke,yongtang,yongtang,yongtang,drpngx,sb2nov,martinwicke,yongtang,yongtang,martinwicke,martinwicke,yongtang,martinwicke,caisq,martinwicke",2017-08-14 19:07:55,2017-12-11 18:00:03
IS,Provide a list of supported XLA operations like TensorFlow Lite,TensorFlow Lite provides a list of currently supported ops here and I wonder if XLA could also have such a list It is rough to develop and train a model with the full TensorFlow Python API only to get stuck during AOT compilation because of missing ops kernels in the tf2xla bridge,,"carlthome,tatatodd,carlthome",2017-11-22 14:54:06,2017-12-11 18:33:14
IS,Feature request automatically pick all defaults in configure,Everytime a new configuration option is added my CI halts on the configure step as it is prompted for input Instead of setting each flag could we have some USE DEFAULTS 1 configure flag instead I assume the intention is to slowly move away from the shell script to something better hence configure py I wager but for now when testing projects with the master release it would be very useful to be able to just pick all default options for the WORKSPACE without knowing about them,,"carlthome,facaiy,carlthome,reedwm,yifeif",2017-12-08 11:02:05,2017-12-11 18:38:05
IS,TensorFlow import,Tensor flow report issue I am getting the following error when importing tensorflow import tensorflow as tf Traceback most recent call last File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Deena Awny AppData Local Programs Python Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Deena Awny AppData Local Programs Python Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow py line 52 in module raise ImportError msg ImportError Traceback most recent call last File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 18 in swig import helper return importlib import module mname File C Users Deena Awny AppData Local Programs Python Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level File frozen importlib bootstrap line 978 in gcd import File frozen importlib bootstrap line 961 in find and load File frozen importlib bootstrap line 950 in find and load unlocked File frozen importlib bootstrap line 648 in load unlocked File frozen importlib bootstrap line 560 in module from spec File frozen importlib bootstrap external line 922 in create module File frozen importlib bootstrap line 205 in call with frames removed ImportError DLL load failed The specified module could not be found During handling of the above exception another exception occurred Traceback most recent call last File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow py line 41 in module from tensorflow python pywrap tensorflow internal import File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 21 in module pywrap tensorflow internal swig import helper File C Users Deena Awny AppData Local Programs Python Python36 lib site packages tensorflow python pywrap tensorflow internal py line 20 in swig import helper return importlib import module ' pywrap tensorflow internal' File C Users Deena Awny AppData Local Programs Python Python36 lib importlib init py line 126 in import module return bootstrap gcd import name level package level ModuleNotFoundError No module named ' pywrap tensorflow internal' Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help,,,2017-09-05 14:48:27,2017-12-11 19:02:36
IS,getting no attribute key error in ubuntu virtual box,bazel bin tensorflow examples image retraining retrain image dir ' dataset dosa ' ERROR tensorflow Image directory ' dataset dosa ' not found Traceback most recent call last File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow examples image retraining retrain py line 1326 in module tf app run main main argv sys argv 0 unparsed File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File home dile tensorflow bazel bin tensorflow examples image retraining retrain runfiles org tensorflow tensorflow examples image retraining retrain py line 989 in main class count len image lists keys AttributeError 'NoneType' object has no attribute 'keys' Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,reedwm,2017-09-09 05:54:11,2017-12-11 19:02:41
IS,Cannot parse tensor from proto dtype DT INT32 when using tf extract image patches and tf reshape,Hi I'm experiencing a problem when using TensorFlow to extract image patches and then reshape the output I'm using TensorFlow 1 3 0 what am i doing wrong That is my code,,"facaiy,angersson",2017-12-11 08:16:17,2017-12-11 19:09:39
IS,ValueError Variable Model LSTMenc rnn basic lstm cell weights does not exist or was not created with tf get variable Did you mean to set reuse None in VarScope,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 1 0 rc0 61 g1ec6ed5' '1 1 0' Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem If I put reuse None while creating BasicLSTMCell in the following code I get this error,,angersson,2017-12-11 06:59:55,2017-12-11 19:11:20
IS,Using tensorflow to compute gradients w r t spectral decomposition error,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra 10 13 1 TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below v1 2 0 5 g435cdfc 1 2 1 Python version 3 5 2 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce see code You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Hi I'm having issues with evaluating the gradients of eigenvalues eigenvectors with respect to the underlying matrix Tensorflow evaluates the gradients however when compared against analytical derivations the gradients are generally inconsistent I understand numerical can be unstable I would like to understand is there is a bug in the gradients or if a different methodology was employed to the one cited below We are using tf self adjoint eig to evaluate the spectral decomposition for the tensorflow variable input We have initialised this with a symmetric matrix to satisfy the self adjoint operator property We wish to take the derivative of individual eigenvalues or eigenvector with respect to the original matrix note for eigenvectors we take one element from one eigenvector e g element 2 in eigenvector 1 to avoid the issue of gradient aggregation for now The methodology for evaluating analytical gradients of eigenvalues and vectors of a symmetric real matrix can be found in the paper On differentiating Eigenvalues and Eigenvectors by Magnus 1985 Theorem 1 eqn 6 7 We evaluated using our input matrix the gradients under this paper and compared it to tensorflow evaluated gradients and the gradients from finite difference approximation For the eigenvalues the gradients are similar identical on diagonal entries off by a factor of 2 on off diagonal elements however the eigenvectors are off by quite a bit outside the diagonal entries To start define a matrix A as excuse the matrix output formatting from Python A 3 2 4 2 1 1 4 1 5 using np linalg eig and tf self adjoint eig on A I simply initialised a variable with A and computed the gradient for the tf implementation Tensorflow eigenvalues 5 43071561 1 76904987 6 66166575 Python eigenvalues 5 43071561 6 66166575 1 76904987 I now wish to evaluate the gradient of eigenvalue 1 5 43071561 w r t A Analytical gradient 0 75896178 0 28555906 0 31842553 0 28555906 0 10744148 0 11980748 0 31842553 0 11980748 0 13359674 Tensorflow gradient 0 75896178 0 0 0 57111812 0 10744148 0 0 63685107 0 23961495 0 13359674 The diagonal entries are the same but the off diagonal entries are clearly off by a factor of 2 Now we try and evaluate gradients for the eigenvectors Tensorflow eigenvectors 0 87118413 0 31452619 0 37697678 0 32778267 0 94426587 0 0303395 0 36550888 0 09713517 0 92572567 Python eigenvectors 0 87118413 0 37697678 0 31452619 0 32778267 0 0303395 0 94426587 0 36550888 0 92572567 0 09713517 We try and find the gradient of the eigenvector 1 element 2 0 32778267 We expect the tensorflow gradient to the equivalent to the analytical gradient after taking into account the sign difference Analytical gradient 0 03511309 0 10795607 0 01312188 0 01321128 0 04061843 0 0049371 0 01473184 0 04529341 0 00550534 Tensorflow gradient 0 03511309 0 0 0 09474478 0 04061843 0 0 02785372 0 04035631 0 00550534 Besides the entries being different on the off diagonal one issue is that tensorflow only returns the lower triangle of the gradient Despite A being symmetric the contribution to the gradient is not symmetric as shown in the analytical evaluation above Thank you for reading TL DR I would like to understand where the gradient computations are coming from and why they differ substantially to the results we have been using in our research Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Here is a script that reproduces the above eigen decomp examplev2 py zip,,angersson,2017-12-11 05:32:08,2017-12-11 19:15:56
IS,Dataset Iterator is not an iterator,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 confidential TensorFlow installed from source or binary Pypi TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 5 3 CUDA cuDNN version sensitive information replaced by xxx Describe the problem The returned iterator is not an iterator because it does not provide a next or next method It does provide a get next method but that is not what Python expects,,"snnn,mrry",2017-12-11 12:49:31,2017-12-11 19:41:51
PR,Switched optimization mode for Pi builds to avoid internal compiler error,The nightly Pi3 builds have been failing with It appears to be the same problem that Chrome hit with gcc here Their solution was to change the optimization flags to avoid this so I have followed their lead and switched to O3 I hope this wo notl make a big latency or size difference but it does solve the compiler crash at least,,"petewarden,petewarden",2017-12-10 06:40:23,2017-12-11 20:55:16
IS,different output size for avg pool and max pool,Hello I have the same bug as this user My version is uo to date Have I written custom code Yes OS Platform and Distribution Linux Mint 18 3 codename Sylvia TensorFlow installed from Tensorflow Website TensorFlow version 14 1 0 Bazel version N A CUDA cuDNN version N A GPU model and memory GeForce 940MX Exact command to reproduce see link,,"facaiy,angersson",2017-12-10 16:34:43,2017-12-11 21:02:26
IS,Loss should change depending on the number of epochs chosen even if I set the seed,Hi colleagues I am using Keras to train different NNs I would like to know why if I increment the epochs the result until the same number of epochs is not the same for the evolution of loss I am using shuffle False and np random seed 2017 tf set random seed 2017 and I have check that if I repeat with the same number of epochs the result is the same so the random initialization is working After the epochs training I am deleting the ANN so the training begins at 0 again Here I attach the picture of the resulting training with 10 epochs img width 676 alt captura de pantalla 2017 12 09 a las 15 02 25 src And here I attach the picture of the resulting training with 8 epochs img width 679 alt captura de pantalla 2017 12 09 a las 15 02 34 src Also I would like to know why the training time is not exactly 8 10 the 10 epochs attempt and how is it possible that some of them have less accuracy with 2 more epochs Here is the link to open code Jupyter Notebook GitHub Jupyter Notebook ANN Comparison Thanks a lot,,angersson,2017-12-09 14:03:15,2017-12-11 21:07:40
PR,Allow keras applications to load weights from arbitrary path,This PR allows tensorflow python keras applications to load pretrained weights from an arbitrary filepath rather than only keras models It is the parallel PR to which was merged by on November 30 This change allows useres to load models in environments with limited access to keras models Kaggle notebooks are an example of this environment and this PR will help us support Keras in TensorFlow I have locally tested that I get the same predictions when loading a model with weights 'imagenet' and with weights pointing to another location with the same pretrained model file,,"dansbecker,caisq",2017-12-06 07:41:19,2017-12-11 21:11:42
IS,Tensorflow Unable to import frozen graph with batchnorm uninitialized value batch normalization moving mean,I am trying to freeze in a pbtxt file a checkpoint containing batchnorm layers ubuntu python 2 7 tf 1 1 0 context Have I written custom code Yes see below OS Platform and Distribution Docker with Ubuntu 14 04 TensorFlow installed from pip installer TensorFlow version tensorflow and tensorflow gpu 1 1 0 Bazel version N A CUDA cuDNN version Cuda 8 CUDNN 5 1 GPU model and memory Nvidia titan x 2 12Go Ram each Exact command to reproduce For this following these posts and issues I use this function freeze and prune graph model path and name output file None freezes a model trained and saved by the trainer by extracting the trainable variables between input node and output node turning them to constants changing the 1rst dim of input node to None saving the resulting graph as a single pb file param model path and name must finish by ckpt and the checkpoint must be composed of 3 files ckpt index ckpt meta and ckpt data 0000X of 0000Y param model path and name path to the trained model param output file file to save to If None model path and name ckpt pb return None config proto tf ConfigProto allow soft placement True with tf Session config config proto as sess new saver tf train import meta graph model path and name ' meta' clear devices True tf get default session run tf global variables initializer tf get default session run tf local variables initializer new saver restore sess model path and name get graph definition gd sess graph as graph def fix batch norm nodes for node in gd node if node op 'RefSwitch' node op 'Switch' for index in xrange len node input if 'moving ' in node input index node input index node input index ' read' elif node op 'AssignSub' node op 'Sub' if 'use locking' in node attr del node attr 'use locking' elif node op 'AssignAdd' node op 'Add' if 'use locking' in node attr del node attr 'use locking' tf get collection returns a list In this example we only want the input node sess graph get tensor by name 'input node 0' new shape None input node get shape as list 1 trainables tf get collection tf GraphKeys TRAINABLE VARIABLES new graph def tf graph util convert variables to constants sess gd output node variable names whitelist t name 2 for t in trainables 'output node' for node in new graph def node if node name 'input node' node attr ishape' CopyFrom attr value pb2 AttrValue shape tf TensorShape new shape as proto break with tf gfile GFile output file wb as f f write new graph def SerializeToString print 0 1 ops in the final graph format len new graph def node len sess graph as graph def node This goes well and creates the pbtxt file with the following output Converted 201 variables to const ops 5287 41028 ops in the final graph I then try to load the pbtxt model using this function def load frozen graph frozen graph file loads a graph frozen via freeze and prune graph and returns the graph its input placeholder and output tensor param frozen graph file pb file to load return tf graph tf placeholder tf tensor We load the protobuf file from the disk and parse it to retrieve the unserialized graph def with tf gfile GFile frozen graph file rb as f graph def tf GraphDef graph def ParseFromString f read Then we can use again a convenient built in function to import a graph def into the current default Graph with tf Graph as default as graph tf import graph def graph def input map None return elements None name prefix op dict None producer op list None input images placeholder graph get tensor by name 'prefix input node 0' input phase placeholder None try input phase placeholder graph get tensor by name 'prefix phase 0' except KeyError pass output graph get tensor by name 'prefix output node 0' return graph input images placeholder input phase placeholder output using the following snippet graph input images placeholder is training placeholder output load frozen graph model pbtxt sess tf Session config tf config graph graph feed dict input images placeholder prepared input if is training placeholder is not None feed dict is training placeholder False ret sess run output feed dict feed dict This however leads to the following error FailedPreconditionError see above for traceback Attempting to use uninitialized value prefix conv0 BatchNorm batch normalization moving mean Node prefix conv0 BatchNorm batch normalization moving mean read Identity T DT FLOAT class loc prefix conv0 BatchNorm batch normalization moving mean device job localhost replica 0 task 0 gpu 0 prefix conv0 BatchNorm batch normalization moving mean Node prefix output node 381 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 2447 prefix output node tensor type DT FLOAT device job localhost replica 0 task 0 cpu 0 Following the question I tried initializing variables graph input images placeholder is training placeholder output load frozen graph model pbtxt sess tf Session config tf config graph graph init tf global variables initializer tf local variables initializer sess run init feed dict input images placeholder prepared input if is training placeholder is not None feed dict is training placeholder False ret sess run self output feed dict feed dict This however changes the error to ValueError Fetch argument tf Operation 'init' type NoOp cannot be interpreted as a Tensor Operation name init op NoOp is not an element of this graph which seems to show that there is no variable that needs to be initialized What am I missing How to I freeze and reload the relevant values of a batch normalization layer PS I do realize that this might better be on stackoverflow but I posted there first and got no answer in 2 weeks,,angersson,2017-12-08 15:19:04,2017-12-11 21:15:08
IS,using ExponentialMovingAverage differs in CPU GPU,I use BN in cnn here is the code when i print variables in CPU GPU it differs In CPU it shows bn 1 bn 1 moments Squeeze ExponentialMovingAverage DT FLOAT 32 bn 1 bn 1 moments Squeeze 1 ExponentialMovingAverage DT FLOAT 32 bn 2 bn 2 moments Squeeze ExponentialMovingAverage DT FLOAT 64 bn 2 bn 2 moments Squeeze 1 ExponentialMovingAverage DT FLOAT 64 bn 3 bn 3 moments Squeeze ExponentialMovingAverage DT FLOAT 64 bn 3 bn 3 moments Squeeze 1 ExponentialMovingAverage DT FLOAT 64 bn 4 bn 4 moments Squeeze ExponentialMovingAverage DT FLOAT 64 bn 4 bn 4 moments Squeeze 1 ExponentialMovingAverage DT FLOAT 64 while in GPU it shows bn 1 bn 1 moments moments 1 mean ExponentialMovingAverage DT FLOAT 32 bn 1 bn 1 moments moments 1 variance ExponentialMovingAverage DT FLOAT 32 bn 2 bn 2 moments moments 1 mean ExponentialMovingAverage DT FLOAT 64 bn 2 bn 2 moments moments 1 variance ExponentialMovingAverage DT FLOAT 64 bn 3 bn 3 moments moments 1 mean ExponentialMovingAverage DT FLOAT 64 bn 3 bn 3 moments moments 1 variance ExponentialMovingAverage DT FLOAT 64 bn 4 bn 4 moments moments 1 mean ExponentialMovingAverage DT FLOAT 64 bn 4 bn 4 moments moments 1 variance ExponentialMovingAverage DT FLOAT 64 therefore when i load a CPU trainned ckeckpoint in GPU it turns out some errors like variables not found in file etc Can someone solve this problem thanks a lot,,"asimshankar,asimshankar,angersson",2017-10-03 08:38:20,2017-12-11 21:23:32
IS,tensorflow python framework errors impl InvalidArgumentError indices 49 60000 is not in 0 60000,I try to run the Sequence to Sequence Models with tensorflow but when I run the training set I have the problem like this Traceback most recent call last File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 1022 in do call return fn args File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 1004 in run fn status run metadata File Users loohaze anaconda envs python3 lib python3 6 contextlib py line 89 in exit next self gen File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python framework errors impl py line 469 in raise exception on not ok status pywrap tensorflow TF GetCode status tensorflow python framework errors impl InvalidArgumentError indices 49 60000 is not in 0 60000 Node model with buckets embedding attention seq2seq 2 embedding attention decoder embedding lookup 15 Gather Tindices DT INT32 Tparams DT FLOAT class loc embedding attention seq2seq embedding attention decoder embedding validate indices true device job localhost replica 0 task 0 cpu 0 embedding attention seq2seq embedding attention decoder embedding read recv decoder15 0 During handling of the above exception another exception occurred Traceback most recent call last File translate py line 322 in module tf app run File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File translate py line 319 in main train File translate py line 210 in train target weights bucket id False File Users loohaze Documents models tutorials rnn translate seq2seq model py line 251 in step outputs session run output feed input feed File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 767 in run run metadata ptr File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 965 in run feed dict string options run metadata File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 1015 in do run target list options run metadata File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python client session py line 1035 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError indices 49 60000 is not in 0 60000 Node model with buckets embedding attention seq2seq 2 embedding attention decoder embedding lookup 15 Gather Tindices DT INT32 Tparams DT FLOAT class loc embedding attention seq2seq embedding attention decoder embedding validate indices true device job localhost replica 0 task 0 cpu 0 embedding attention seq2seq embedding attention decoder embedding read recv decoder15 0 Caused by op 'model with buckets embedding attention seq2seq 2 embedding attention decoder embedding lookup 15' defined at File translate py line 322 in module tf app run File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python platform app py line 44 in run sys exit main sys argv 1 flags passthrough File translate py line 319 in main train File translate py line 178 in train model create model sess False File translate py line 136 in create model dtype dtype File Users loohaze Documents models tutorials rnn translate seq2seq model py line 179 in init softmax loss function softmax loss function File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 1180 in model with buckets decoder inputs bucket 1 File Users loohaze Documents models tutorials rnn translate seq2seq model py line 178 in lambda lambda x y seq2seq f x y False File Users loohaze Documents models tutorials rnn translate seq2seq model py line 142 in seq2seq f dtype dtype File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 876 in embedding attention seq2seq initial state attention initial state attention File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 772 in embedding attention decoder embedding ops embedding lookup embedding i for i in decoder inputs File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow contrib legacy seq2seq python ops seq2seq py line 772 in listcomp embedding ops embedding lookup embedding i for i in decoder inputs File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python ops embedding ops py line 111 in embedding lookup validate indices validate indices File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python ops gen array ops py line 1359 in gather validate indices validate indices name name File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python framework op def library py line 763 in apply op op def op def File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python framework ops py line 2395 in create op original op self default original op op def op def File Users loohaze anaconda envs python3 lib python3 6 site packages tensorflow python framework ops py line 1264 in init self traceback extract stack InvalidArgumentError see above for traceback indices 49 60000 is not in 0 60000 Node model with buckets embedding attention seq2seq 2 embedding attention decoder embedding lookup 15 Gather Tindices DT INT32 Tparams DT FLOAT class loc embedding attention seq2seq embedding attention decoder embedding validate indices true device job localhost replica 0 task 0 cpu 0 embedding attention seq2seq embedding attention decoder embedding read recv decoder15 0 It seems the problem happens randomly when running training set It means when I have this problem I can continue and this may not happen in next steps I checked this problem on previous issues but I am sure that I have set the parameter of vocabulary size Here are my input commands python translate py data dir private tmp ch en train dir private tmp ch en train result size 256 num layers 2 steps per checkpoint 200 from vocab size 60000 to vocab size 60000 So how to solve this problem,,"drpngx,drpngx,drpngx,angersson",2017-07-18 17:22:30,2017-12-11 21:40:27
IS,mismatch between the reported values of tt nn zero fraction,Has anyone run into this issue before tt nn zero fraction defined in nn imply py reports my convs layers in MobileNet v1 slim net have around 0 5 sparsity conv1 conv13 However when I freeze the model is weights and look at them there is none zero values Looking at the histogram there are many weights' values close to zero Does that function do approximation Can anyone verify this,,"facaiy,angersson",2017-09-16 17:06:35,2017-12-11 21:44:38
IS,libtensorflow cc so linker issues with r 1 3 on Mac OS X Undefined symbols for architecture,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes but this appears to be a linker issue OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 6 TensorFlow installed from source or binary Source TensorFlow version use command below Git tagged at 1 3 and master at 593dc8e5d65f4db93e8f5fced772abb3531a9752 Python version 2 7 OS Default Bazel version if compiling from source 0 5 3 homebrew CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel clean configure stating N to every option for CPU only build bazel build tensorflow libtensorflow cc so with no optimizations testing deployment Describe the problem The above commands builds a libtensorflow cc so from for TF 1 3 Linking my built libtensorflow cc so to a C Obj C App which has successfully linked against a TF 1 2 build of libtensorflow cc so results in the following linker errors in the log section of this bug report No code changes were made on my end between a working 1 2 libtensorflow cc so and a new 1 3 libtensorflow cc so Just replacing the binary so file building clean and re compiling Thank you Source code logs,,"gunan,asimshankar,asimshankar,allenlavoie,asimshankar,asimshankar,angersson",2017-08-23 20:55:30,2017-12-11 21:47:52
IS,Multiple infiniband cards support in tensorflow with RDMA,It seems that tensorflow with RDMA does not support multiple infiniband cards now It only uses the first device in the infiniband device list source rdma cc What do you think about this,,"byronyi,angersson,angersson",2017-09-21 03:06:53,2017-12-12 01:26:47
PR,Replace variables get global step use training util get global step,,,"caisq,caisq,caisq,caisq",2017-12-10 08:16:57,2017-12-12 02:54:11
PR,Branch 178689056,,,"dandelionmane,dandelionmane",2017-12-12 01:02:50,2017-12-12 03:11:58
IS,Using tfdbg with Monitored Session,System information I am using a modified version of CIFAR10 tutorial TensorFlow CentOS Linux release 7 3 1611 TensrFlow from Source TensorFlow v1 3 Python 2 7 Describe the problem Hello I see that I can not use tfdbg with Monitored session That is if I try to wrap mon sess tf debug LocalCLIDebugWrapperSession mon sess where mon sess is tf train MonitoredTrainingSession I get the following error TypeError Expected type class 'tensorflow python client session BaseSession' got type class 'tensorflow python training monitored session MonitoredSession' Can there be a support from Debugger with Monitored Sessions,,"reedwm,reedwm,caisq",2017-12-04 21:08:37,2017-12-12 03:12:38
PR,Documentation Fixing 'if' spelling,Fixing 'if' spelling,,"rajendraarora16,rajendraarora16",2017-12-12 07:30:03,2017-12-12 10:50:09
IS,no,,,,2017-12-12 15:16:30,2017-12-12 15:19:44
PR,Add TensorFlow support for tf repeat equivalent to np repeat,This fix tries to address the feature request proposed in 8246 where there was no equivalent of numpy repeat in TensorFlow This fix adds the support for tf repeat that is equivalent to np repeat NOTE in order to allow optional axis parameter this fix adds Repeat and RepeatFlat ops where one takes axis and another does not take axis This fix fixes 8246 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,ozabluda",2017-12-08 21:28:59,2017-12-12 16:08:18
IS,tf train batch and shuffle batch undetermined for multi queue input with multiple threads,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code see below OS Platform and Distribution e g Linux Ubuntu 16 04 OSX TensorFlow installed from source or binary pip install tensorflow 1 2 TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Python version Python 2 7 10 Bazel version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce Output Exception in training queues derailed 11 26 25 27 28 29 25 26 27 28 29 Describe the problem Both queues should be dequeued synchronously as it does when num threads 1 in the batch statement With num threads 1 the two input queue is will derail as shown in the example above Same issue appears also in train shuffle batch Source code logs See code above,,"drpngx,drpngx,mrry,mrry,mrry",2017-10-20 06:18:06,2017-12-12 16:40:20
PR,Exclude tests from contrib py,gunan Do not you think,,"Androbin,mrry",2017-12-12 14:05:53,2017-12-12 18:04:46
PR,In TensorArrayPackOrGatherOp handle num indices 0 better,Namely also consider the shape stored in the TensorArray object since TensorArrayGatherV3 ops created as part of gradient computation wo not have the element shape attr set Fixes 12743,,"ebrevdo,drpngx,sb2nov,martinwicke,martinwicke",2017-09-01 05:00:12,2017-12-12 18:36:59
PR,Update seq2seq py To avoid error thread lock,Issue Ca not pickle thread lock object,,"frankchn,martinwicke,martinwicke",2017-10-02 13:07:52,2017-12-12 18:47:45
PR,MonitoredTrainingSession supports partial restore from checkpoint,As mentioned in 6604 MonitoredTrainingSession is preferred to Supervisor I think it is useful to support partial restoration from checkpoint files in MonitoredTrainingSession The main idea is bypassing checkpoint restoration of SessionManager and adding a new CheckpointRestorerHook to restore data from checkpoint after tf Session is created and init op is run A new ctor parameter restore var list None added to explicitly specify which part of variables to be restored If not set all variables are restored by default behavior of Saver This way the user can train a model save checkpoint file change the model a bit and fine tune the new model by specifying restore var list when he she continues training,,"ispirmustafa,sb2nov,ispirmustafa,ispirmustafa,sb2nov,martinwicke,martinwicke",2017-09-25 03:39:36,2017-12-12 18:49:45
PR,Getting rid from unnecessary call 'inspect stack',Getting rid from unnecessary call 'inspect stack' in making of decorator in 'tf contrib framework add arg scope' P S On my laptop this call gives big overhead for initialization of tensorflow,,"drpngx,drpngx,drpngx,charlesnicholson,martinwicke,martinwicke",2017-09-22 11:23:39,2017-12-12 18:50:10
PR,find worker session by handle for worker,extract common template method to find worker session by handle and remove duplicated implements,,"horance-liu,mrry,mrry,horance-liu,horance-liu,mrry,gunan,drpngx,sb2nov,martinwicke,mrry,martinwicke",2017-08-22 07:37:58,2017-12-12 19:49:02
PR,Parameterize tensorflow CUDA and cudnn versions in cmake build,Also upgrade the defaults to cuda9 and cudnn 7,,"gunan,gunan",2017-12-12 07:09:57,2017-12-12 20:26:16
IS,FEATURE REQUEST Report uninitialized data iterators,At we found that iterators are not variables therefore report uninitalized variables fails with Frankly it must be very easy to adapt report unitialized variables to report data is unitialized iterators This would be helpful to avoid re initializing datasets each time when we call session run in GPflow Right now it provides initializing by demand feature Best Artem Artemev,,"mrry,mrry",2017-11-16 19:20:00,2017-12-12 21:35:16
IS,Cannot import tensorflow after installing tensorflow gpu Windows,I am running windows 10 64bit Tensorflow gpu version 1 4 0 CUDA version 8 0 cuDNN v6 0 I installed it using the cmd command pip install tensorflow gpu and do not have any other version of tensorflow installed now when I try to execute I get the error ModuleNotFoundError No module named 'tensorflow' I am hoping getting this working will solve my bigger issue of tensorflow not recognizing my gpu for gpu processing,,Carmezim,2017-12-12 18:58:42,2017-12-12 22:12:56
IS,Support python3 6 Linux,Python3 6 support Linux,,"facaiy,angersson",2017-12-12 13:02:00,2017-12-12 23:09:45
PR,Fix bugs of rounding in converting image from float to int,,,"martinwicke,martinwicke,martinwicke,drpngx,sb2nov,drpngx,drpngx,drpngx,drpngx,yifeif,jart,yifeif,drpngx,drpngx,drpngx,gunan,martinwicke,martinwicke",2017-08-10 22:27:48,2017-12-13 00:37:16
PR,sampled version of sparse softmax cross entropy with logits,Following from the already implemented sampled softmax loss this is a very similar implementation that performs sampling for sparse softmax cross entropy with logits,,"TTrapper,ebrevdo,ebrevdo,ebrevdo,TTrapper,TTrapper,TTrapper,ebrevdo,TTrapper,TTrapper,frankchn,drpngx,TTrapper,TTrapper,frankchn,frankchn,asimshankar,drpngx,ebrevdo,TTrapper,TTrapper,drpngx,TTrapper,drpngx",2017-10-02 20:59:30,2017-12-13 00:40:32
IS,tensorflow multigpu with dataset api is not converging,I am trying to train a resNet50 on multi gpus I have used url and I have added tensorflow Dataset input pipeline to the link code But after some steps loss is some value and does not changes any more value 0 693147 always I have tested this network with dataset API on single gpu and worked fine Im sure something is wrong with my data feeding because when I feed a simple random nd array it converges I have tested my tfrecord file it was OK but I dont know the problem I use ubuntu 16 04 tensorflow 1 4 python 2 7 12 gtx 1080 Gpus this is all my train code github txt,,,2017-12-12 15:23:58,2017-12-13 01:25:07
IS,S3 reads eventually fail with tensorflow is dataset API,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 Python version Python 2 7 12 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CPU GPU model and memory N A Exact command to reproduce Describe the problem The given script reads the MNIST data from S3 repeatedly from a public bucket on an EC2 machine in the same region as the S3 bucket Running this script eventually leads to python crashing after a few hours and the following error Source code logs It is hard to say what is happening without debugging symbols From the very generic error I suspect this is an issue with the S3 SDK As a workaround it would be nice for tensorflow is S3 plugin to retry or be more resilient to networking issues It is currently an annoying issue when running large distributed training jobs because they crash after a few hours of reading data Is anyone having a similar experience with S3,,"mrry,mrry,yongtang,drpngx,yongtang,yongtang,yongtang",2017-12-07 19:07:40,2017-12-13 01:32:46
IS,BUG ImportError No module named 'tensorflow contrib eager',System information I tried to import tensorflow contrib eager as tfe after installation and it throws No module error OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from python pip in virtualenv TensorFlow version 1 1 0 Python version 3 5 GPU model and memory GeForce GTX 1080 CUDA 8 0 cuDNN 6 0 Describe the problem After I install the eager i e pip install tf nightly gpu in my virtualenv activated I run,,"asimshankar,asimshankar,asimshankar",2017-11-04 15:54:38,2017-12-13 03:16:46
PR,Explicitly specify CUDA and CUDNN versions,A workaround to the base problem causing,,angersson,2017-12-13 01:49:42,2017-12-13 05:24:11
IS,Graph building and optimization is really slow,I'm using tensorflow 1 4 and tflearn 0 3 2 The os of my machine is Win 8 1 Apparently the graph building and cost optimization in my code is real slow which I think is a bug in Tensorflow either that or my machine is just real slow Here is the code Can anyone help me address this issue To reproduce it you can run main train py in this repository,,"selcouthlyBlue,selcouthlyBlue",2017-12-13 05:26:31,2017-12-13 06:50:06
PR,Removing unused variable b in EventsWriter from events writer test py,There was no use of b I have found so far in codebase However foo was a proper tag,,rajendraarora16,2017-12-12 09:41:52,2017-12-13 07:50:04
IS,opencv cannot read frame from video with tensorflow,I am using tensorflow r1 4 and opencv3 1 in ubuntu14 04 When I include include tensorflow core public session h or include tensorflow cc ops standard ops h I cannot read images from cv VideoCapture adn I got empty mat When I did not include these tensorflow headers I can read frame successfully Anyone could help me Thanks a lot I noticed other issues like 1924 6496 but got no idea Here is my cpp file include tensorflow core platform env h include tensorflow core public session h include tensorflow cc ops standard ops h include opencv2 opencv hpp include iostream using namespace std using namespace tensorflow int main cv VideoCapture cap if cap open home kx project RM dataset 01 avi std cout cannot open video std endl cv Mat frame while 1 cap frame if frame empty std cout no frame std endl continue cv imshow frame frame cv waitKey 0 return 0 my cmake file cmake minimum required VERSION 2 8 project tf example set CMAKE CXX FLAGS CMAKE CXX FLAGS g std c 11 W find package OpenCV 3 1 0 REQUIRED include directories home kx something tensorflow r1 4 home kx something tensorflow r1 4 tensorflow bazel genfiles home kx something tensorflow r1 4 tensorflow contrib makefile gen protobuf include home kx something tensorflow r1 4 tensorflow contrib makefile gen host obj home kx something tensorflow r1 4 tensorflow contrib makefile gen proto home kx something tensorflow r1 4 tensorflow contrib makefile downloads nsync public home kx something tensorflow r1 4 tensorflow contrib makefile downloads eigen home kx something tensorflow r1 4 bazel out local py3 opt genfiles OPENCV INCLUDE DIRS add executable tf test tf test cpp target link libraries tf test home kx something tensorflow r1 4 bazel bin tensorflow libtensorflow cc so home kx something tensorflow r1 4 bazel bin tensorflow libtensorflow framework so OpenCV LIBS The results no frame,,angersson,2017-12-13 13:15:26,2017-12-13 19:18:09
IS,Feature Request Easy way to predict after training model with Estimator and Dataset API,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 0 Python version Python 3 5 2 Anaconda custom 64 bit Bazel version if compiling from source None GCC Compiler version if compiling from source None Describe the problem I have beed trained a image classification cnn model with the Estimator and Dataset tf data TFRecordsDataset API The relative model files have bee saved in model dir The last few days I try very hard to figure out how to predict one or more images label using the saved model files However I failed and do not know what to do I can not find relative contents in the official doc So adding an easy method to do this may be a good idea Or is there another solution I missed FYI my training code is here,,angersson,2017-12-13 01:45:45,2017-12-13 19:29:21
PR,Update location for x86 64 android build,See,,angersson,2017-12-13 19:14:30,2017-12-13 20:41:39
PR,Fix problem with camera on Android TV,For a scenario of using a usb external camera we should use Camera API 2 according to the definition Camera1 API is framework API that had been created to support HALv1 x Camera2 API is a new API that is meant for HALv3 x However CameraCharacteristics INFO SUPPORTED HARDWARE LEVEL FULL should return false as USB camera doesn' support all the necessary capabilities INFO SUPPORTED HARDWARE LEVEL FULL This is a work around to use facing CameraCharacteristics LENS FACING EXTERNAL to detect usb external camera and use Camera2 API instead,,"lihanchen,andrewharp,andrewharp",2017-12-06 19:03:15,2017-12-13 21:34:33
IS,Using wrong location for x86 64 android build,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow A Yes OS Platform and Distribution e g Linux Ubuntu 16 04 A OSX 10 13 1 TensorFlow installed from source or binary A Source TensorFlow version use command below A 1 4 1 Python version A 2 7 Bazel version if compiling from source A 0 8 GCC Compiler version if compiling from source A CUDA cuDNN version GPU model and memory Exact command to reproduce make f tensorflow contrib makefile Makefile TARGET ANDROID ANDROID ARCH x86 64 Describe the problem Android x86 64 build fails with Makefile using make f tensorflow contrib makefile Makefile TARGET ANDROID ANDROID ARCH x86 64 because it cannot find the binary x86 64 linux android g It can be fixed by changing the tensorflow contrib makefile Makefile at line 303 from BIN PREFIX x86 64 linux android to BIN PREFIX x86 64 linux android,,"angersson,angersson",2017-12-13 18:38:09,2017-12-13 22:58:31
IS,Dockerfile devel gpu infinite prompt loop,Is it because the 1 4 branch does not support CUDA 9 0 L74 L76,,"flx42,gunan,flx42,angersson,angersson,flx42,flx42,angersson",2017-12-12 02:16:44,2017-12-13 23:55:58
IS,Object Detection frozen graph issue,Training environment System information MAC OSX 10 13 2 Tensorflow 1 4 rc1 GPU support Installation through source Python 3 6 Anaconda Bazel 0 8 CUDA 9 cuDNN7 GPU 1080Ti I have trained my own model for object detection Extracted graph from checkpoint as well This graph is working with the Mac GPU and CPU It is also working with Raspberry PI but when I am trying to run it on AWS EC2 Deep Learning AMI Amazon Linux and Deep Learning AMI Ubuntu both instance Built tensorflow 1 4 rc1 from source as well as installed using pip but it keep giving me following error When I am extracting frozen graph on EC2 instance from the same previous checkpoint it gives me much lower accuracy than my MAC and raspberryPI,,angersson,2017-12-13 19:45:53,2017-12-13 23:58:35
IS,questions about shared variables between CPU and GPU,Dear developers I looked at cifar10 multi gpu train py the idea about sharing model params among CPU and GPUs is inspiring However I have a few questions that I want to understand well before I can apply to my own problem As far as I can tell the model params are stored in CPU by looking into the tower loss function since cifar10 py explicitly pinned down all variables at cpu 0 Then function train wraps up tower loss with gpu device like this for i in xrange FLAGS num gpus with tf device ' gpu d' i loss tower loss scope tf get variable scope reuse variables Using this way I bet model params are stored in CPU and there is no extra copy anywhere because it is set to just reuse the same variables in the scope while GPU stored gradient operations written in tower loss In the way I believe the model params have to transfer from CPU to GPU whenever GPU calls for these params to operate upon It would be inefficient if doing multiple transfer to GPU I believe I notice identity operation in the end of tower loss Is tf identity total loss doing the trick so CPU transfers model params to the GPU only once then GPU just holds the local copy from then on,,angersson,2017-12-13 23:50:48,2017-12-13 23:58:58
IS,Could not find a version that satisfies the requirement tensorflow from versions,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Centos7 You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request when i use pip install python i got the follower errors root compute1 Object Detector App pip install tensorflow Collecting tensorflow Could not find a version that satisfies the requirement tensorflow from versions No matching distribution found for tensorflow root compute1 Object Detector App root compute1 Object Detector App root compute1 Object Detector App python V Python 2 7 14 root compute1 Object Detector App Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2017-12-14 07:19:47,2017-12-14 08:03:55
IS,stupid question but please help me to answer this,I have a problem with parallel computing I know that CUDA or pyCUDA can do such thing like 3D convolution in parallel I think about using tensorflow GPU by calling tf nn conv3d input filter does it uses build in functions in CUDA to operate 3D convolution with parallel computing or there are somethings else I am not familiar with C or even with pyCuda I am not sure how to implement 3D convolution with it Same question with all type of other implement with tensorflow GPU Bests,,Carmezim,2017-12-08 17:27:13,2017-12-14 08:08:04
IS,Tensorflow build fails with config sycl,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 17 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version 2 7 Bazel version if compiling from source 0 5 1 GCC Compiler version if compiling from source 6 0 3 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build c opt config sycl tensorflow libtensorflow cc so Logs ERROR home ashok Ashok tensorflow c tensorflow core kernels BUILD 3355 1 C compilation of rule ' tensorflow core kernels sendrecv ops' failed computecpp failed error executing command external local config sycl crosstool computecpp fPIE fno omit frame pointer Wall msse3 g0 O2 DNDEBUG ffunction sections fdata sections ' std c 11' MD MF remaining 119 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 In file included from tensorflow core kernels sendrecv ops cc 16 In file included from tensorflow core kernels sendrecv ops h 19 In file included from tensorflow core framework op kernel h 19 In file included from usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 functional 55 usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 1404 14 error no matching constructor for initialization of 'tuple const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool ' return tuple Elements std forward Elements args usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 functional 992 13 note in instantiation of function template specialization istd forward as tuple const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool ' requested here std forward as tuple std forward Args args usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 functional 1731 2 note in instantiation of function template specialization istd Bind lambda at tensorflow core kernels sendrecv ops cc 155 7 std function void std Placeholder 1 std Placeholder 2 std Placeholder 3 std Placeholder 4 std Placeholder 5 operator const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool void ' requested here Base M get pointer functor usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 functional 2115 33 note in instantiation of member function istd Function handler void const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool std Bind lambda at tensorflow core kernels sendrecv ops cc 155 7 std function void std Placeholder 1 std Placeholder 2 std Placeholder 3 std Placeholder 4 std Placeholder 5 M invoke' requested here M invoker My handler M invoke tensorflow core kernels sendrecv ops cc 154 38 note in instantiation of function template specialization istd function void const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool function std Bind lambda at tensorflow core kernels sendrecv ops cc 155 7 std function void std Placeholder 1 std Placeholder 2 std Placeholder 3 std Placeholder 4 std Placeholder 5 void void ' requested here Rendezvous DoneCallback done cb std bind usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 600 18 note candidate template ignored disabled by 'enable if' with Dummy void TCC Dummy template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 611 18 note candidate template ignored disabled by 'enable if' with Dummy void TCC Dummy template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 628 5 note candidate template ignored disabled by 'enable if' with UElements const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool TC sizeof UElements 1 Elements template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 641 5 note candidate template ignored disabled by 'enable if' with UElements const tensorflow Status const tensorflow Rendezvous Args const tensorflow Rendezvous Args const tensorflow Tensor bool TC sizeof UElements 1 Elements template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 737 19 note candidate template ignored disabled by 'enable if' with Alloc tensorflow Rendezvous Args UElements const tensorflow Rendezvous Args const tensorflow Tensor bool enable if TMC UElements template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 748 19 note candidate template ignored disabled by 'enable if' with Alloc tensorflow Rendezvous Args UElements const tensorflow Rendezvous Args const tensorflow Tensor bool enable if TMC UElements template usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 579 17 note candidate constructor template not viable requires 0 arguments but 5 were provided constexpr tuple usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 589 26 note candidate constructor template not viable requires 0 arguments but 5 were provided explicit constexpr tuple usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 670 19 note candidate constructor template not viable requires single argument ' in' but 5 arguments were provided constexpr tuple const tuple UElements in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 682 28 note candidate constructor template not viable requires single argument ' in' but 5 arguments were provided explicit constexpr tuple const tuple UElements in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 694 19 note candidate constructor template not viable requires single argument ' in' but 5 arguments were provided constexpr tuple tuple UElements in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 705 28 note candidate constructor template not viable requires single argument ' in' but 5 arguments were provided explicit constexpr tuple tuple UElements in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 721 2 note candidate constructor template not viable requires 7 arguments but 5 were provided tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 732 11 note candidate constructor template not viable requires 7 arguments but 5 were provided explicit tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 711 2 note candidate constructor template not viable requires 2 arguments but 5 were provided tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 759 2 note candidate constructor template not viable requires 3 arguments but 5 were provided tuple allocator arg t tag const Alloc a const tuple in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 763 2 note candidate constructor template not viable requires 3 arguments but 5 were provided tuple allocator arg t tag const Alloc a tuple in usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 772 2 note candidate constructor template not viable requires 3 arguments but 5 were provided tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 784 11 note candidate constructor template not viable requires 3 arguments but 5 were provided explicit tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 796 2 note candidate constructor template not viable requires 3 arguments but 5 were provided tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 808 11 note candidate constructor template not viable requires 3 arguments but 5 were provided explicit tuple allocator arg t tag const Alloc a usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 654 17 note candidate constructor not viable requires 1 argument but 5 were provided constexpr tuple tuple default usr lib gcc x86 64 linux gnu 6 3 0 include c 6 3 0 tuple 652 17 note candidate constructor not viable requires 1 argument but 5 were provided constexpr tuple const tuple default 1 error generated Target tensorflow libtensorflow cc so failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 1003 058s Critical Path 53 74s FAILED Build did NOT complete successfully,,"reedwm,gunan",2017-12-03 06:13:06,2017-12-14 08:16:45
IS,Bazel cmake compilations for Windows are completely broken,Ca not compile tensorflow revision 1 3 using Bazel revision of the last successful nightly build using cmake Error is the following I will be glad to help to fix the issues But I absolutely has no idea what is going on here Can anybody help to fix Windows compilation please Currently here is no build for Windows with AVX AVX2 support in the whole world,,"andrewharp,snnn,snnn,snnn,snnn,snnn,snnn,aselle,gunan,snnn,gunan,meteorcloudy,snnn,gunan,snnn,meteorcloudy,gunan",2017-09-11 19:43:18,2017-12-14 08:18:36
IS,how can I see the graphs in tensorboard,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,gunan,2017-12-14 08:14:57,2017-12-14 08:22:32
IS,the source code to compile about tensorflow1 1 0,I am very distressed I need some help I refer to TensorFlow Bindings for H2O ai I execute gradlew clean tensorflowCompile but always has error likes ERROR error loading package '' Encountered error while reading extension file 'closure defs bzl' no such package ' io bazel rules closure closure' Error downloading to root cache bazel bazel root c0282f68c3c9fe7828209fa3ece89ea6 external io bazel rules closure 5ca1dab6df9ad02050f7ba4e816407f88690cf7d tar gz Checksum was 5afc2087ab53b160fb58fde30339a2c2826c1a171404b7b8ff7227d5ebc8225c but wanted 60fc6977908f999b23ca65698c2bb70213403824a84f7904310b6000d78be9ce deepwater tensorflow tensorflowCompile FAILED errors with checksum how can I do fix this problem how can I checksum disabled please thanks,,gunan,2017-12-03 11:52:33,2017-12-14 08:28:08
IS,how to feed a placeholder with the return values of tf train batch,Code images raw images labels tf train batch image raw image label batch size batch size num threads 1 capacity 4 batch size allow smaller final batch True return images raw images labels images labels load batch dataset batch size batch size sess run train op feed dict x x img y true label Errors sess run train op feed dict x images y true labels File usr local lib python2 7 site packages tensorflow python client session py line 895 in run run metadata ptr File usr local lib python2 7 site packages tensorflow python client session py line 1074 in run raise TypeError 'The value of a feed cannot be a tf Tensor object ' TypeError The value of a feed cannot be a tf Tensor object Acceptable feed values include Python scalars strings lists numpy ndarrays or TensorHandles,,,2017-12-14 11:46:56,2017-12-14 12:07:45
IS,tensorflow python bfloat16 test and tensorflow python framework dtypes test failing on Windows,,,"meteorcloudy,facaiy,meteorcloudy",2017-12-14 09:50:57,2017-12-14 13:01:40
IS,Header mismatch when running 'Simple Audio Recognition',tensorflow 1 4 ubuntu 17 10 python3 6 anaconda cuda 8 0 cudnn 6 0 Going with Simple Audio Recognition I met an error when running,,"aselle,aselle",2017-11-29 14:59:15,2017-12-14 16:39:50
PR,XLA Add fast path cases for common scatter and gather operations,This change checks if the indices vector passed to a scatter or gather operation is a constant and does a fast path operation when it is filled with a zero based incrementing set This is quite a common case because of tensor array stack and unstack,,"DavidNorman,hawkinsp,hawkinsp,hawkinsp,hawkinsp,hawkinsp,DavidNorman,DavidNorman,DavidNorman,DavidNorman,caisq",2017-12-07 15:12:51,2017-12-14 18:08:06
IS,code is jammed when evaluate,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary pip3 TensorFlow version use command below 1 4 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 46 GPU model and memory 2GB Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION the code is jammed when run eval results pc classifier evaluate input fn pcd test input fn np I built model under the guidance of cnn mnist py the differences are that I change the network architecture and using my input functioin Everything is normal during the training process but it jammed during the evaluate process the call stack is default and it jammed at the code for hook in self hooks hook after run run context session run hook SessionRunValues results outputs hook if hook in outputs else None options options run metadata run metadata what is the problem Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,angersson,2017-12-14 08:22:43,2017-12-14 18:59:35
IS,Error when following official installation instructions,INFO Found 1 target ERROR opt tensorflow tensorflow stream executor BUILD 39 1 C compilation of rule ' tensorflow stream executor cuda platform' failed Exit 1 crosstool wrapper driver is not gcc failed error executing command cd home cjliux cache bazel bazel root fbc06f9baef46cade6e35d9e4137e37c execroot org tensorflow exec env CUDA TOOLKIT PATH usr local cuda CUDNN INSTALL PATH usr local cuda 8 0 GCC HOST COMPILER PATH usr bin gcc PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 6 1 TF CUDA VERSION 8 0 TF CUDNN VERSION 7 TF NEED CUDA 1 TF NEED OPENCL 0 external local config cuda crosstool clang bin crosstool wrapper driver is not gcc U FORTIFY SOURCE ' D FORTIFY SOURCE 1' fstack protector fPIE Wall Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 DNDEBUG ffunction sections fdata sections ' march native' ' std c 11' ' march native' MD MF bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic d ' frandom seed bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic o' fPIC DEIGEN MPL2 ONLY DTENSORFLOW USE JEMALLOC DSNAPPY iquote iquote bazel out local linux opt genfiles iquote external nsync iquote bazel out local linux opt genfiles external nsync iquote external bazel tools iquote bazel out local linux opt genfiles external bazel tools iquote external jemalloc iquote bazel out local linux opt genfiles external jemalloc iquote external protobuf archive iquote bazel out local linux opt genfiles external protobuf archive iquote external eigen archive iquote bazel out local linux opt genfiles external eigen archive iquote external local config sycl iquote bazel out local linux opt genfiles external local config sycl iquote external gif archive iquote bazel out local linux opt genfiles external gif archive iquote external jpeg iquote bazel out local linux opt genfiles external jpeg iquote external com googlesource code re2 iquote bazel out local linux opt genfiles external com googlesource code re2 iquote external farmhash archive iquote bazel out local linux opt genfiles external farmhash archive iquote external fft2d iquote bazel out local linux opt genfiles external fft2d iquote external highwayhash iquote bazel out local linux opt genfiles external highwayhash iquote external png archive iquote bazel out local linux opt genfiles external png archive iquote external zlib archive iquote bazel out local linux opt genfiles external zlib archive iquote external snappy iquote bazel out local linux opt genfiles external snappy iquote external local config cuda iquote bazel out local linux opt genfiles external local config cuda isystem external nsync public isystem bazel out local linux opt genfiles external nsync public isystem external bazel tools tools cpp gcc3 isystem external jemalloc include isystem bazel out local linux opt genfiles external jemalloc include isystem external protobuf archive src isystem bazel out local linux opt genfiles external protobuf archive src isystem external eigen archive isystem bazel out local linux opt genfiles external eigen archive isystem external gif archive lib isystem bazel out local linux opt genfiles external gif archive lib isystem external farmhash archive src isystem bazel out local linux opt genfiles external farmhash archive src isystem external png archive isystem bazel out local linux opt genfiles external png archive isystem external zlib archive isystem bazel out local linux opt genfiles external zlib archive isystem external local config cuda cuda isystem bazel out local linux opt genfiles external local config cuda cuda isystem external local config cuda cuda cuda include isystem bazel out local linux opt genfiles external local config cuda cuda cuda include no canonical prefixes Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' fno canonical system headers c tensorflow stream executor cuda cuda dnn cc o bazel out local linux opt bin tensorflow stream executor objs cuda platform tensorflow stream executor cuda cuda dnn pic o tensorflow stream executor cuda cuda dnn cc In instantiation of 'cudnnStatus t perftools gputools cuda wrap WrapperShim cudnnSetRNNDescriptor operator perftools gputools cuda CUDAExecutor Args with Args cudnnRNNStruct int int cudnnDropoutStruct cudnnRNNInputMode t cudnnDirectionMode t cudnnRNNMode t cudnnDataType t ' tensorflow stream executor cuda cuda dnn cc 1017 50 required from here tensorflow stream executor cuda cuda dnn cc 139 38 error cannot convert 'cudnnRNNStruct ' to 'cudnnHandle t aka cudnnContext ' for argument '1' to 'cudnnStatus t cudnnSetRNNDescriptor cudnnHandle t cudnnRNNDescriptor t int int cudnnDropoutDescriptor t cudnnRNNInputMode t cudnnDirectionMode t cudnnRNNMode t cudnnRNNAlgo t cudnnDataType t ' cudnnStatus t retval name args tensorflow stream executor cuda cuda dnn cc 233 3 note in expansion of macro 'PERFTOOLS GPUTOOLS CUDNN WRAP' macro cudnnSetRNNDescriptor tensorflow stream executor cuda cuda dnn cc 238 1 note in expansion of macro 'CUDNN DNN ROUTINE EACH R5' CUDNN DNN ROUTINE EACH R5 PERFTOOLS GPUTOOLS CUDNN WRAP In file included from tensorflow stream executor cuda cuda dnn cc 42 0 bazel out local linux opt genfiles external local config cuda cuda cuda include cudnn h 1553 8 note class type 'cudnnRNNStruct' is incomplete struct cudnnRNNStruct tensorflow stream executor cuda cuda dnn cc In function 'int perftools gputools cuda anonymous CudnnDataTypeToByteSize cudnnDataType t ' tensorflow stream executor cuda cuda dnn cc 858 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In member function 'int perftools gputools cuda CudnnRnnParamsDescriptor GetRegionCountPerLayer const' tensorflow stream executor cuda cuda dnn cc 1200 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnRNNInputMode t perftools gputools cuda anonymous ToCudnnRnnInputMode perftools gputools dnn RnnInputMode ' tensorflow stream executor cuda cuda dnn cc 821 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnDirectionMode t perftools gputools cuda anonymous ToCudnnRnnDirectionMode perftools gputools dnn RnnDirectionMode ' tensorflow stream executor cuda cuda dnn cc 833 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnRNNMode t perftools gputools cuda anonymous ToCudnnRnnMode perftools gputools dnn RnnMode ' tensorflow stream executor cuda cuda dnn cc 845 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnDataType t perftools gputools cuda anonymous ToCudnnDataType perftools gputools dnn DataType perftools gputools dnn DataLayout ' tensorflow stream executor cuda cuda dnn cc 809 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionFwdAlgo t perftools gputools cuda anonymous ToConvForwardAlgo perftools gputools dnn AlgorithmType ' tensorflow stream executor cuda cuda dnn cc 283 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionBwdDataAlgo t perftools gputools cuda anonymous ToConvBackwardDataAlgo perftools gputools dnn AlgorithmType ' tensorflow stream executor cuda cuda dnn cc 305 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc In function 'cudnnConvolutionBwdFilterAlgo t perftools gputools cuda anonymous ToConvBackwardFilterAlgo perftools gputools dnn AlgorithmType ' tensorflow stream executor cuda cuda dnn cc 327 1 warning control reaches end of non void function Wreturn type tensorflow stream executor cuda cuda dnn cc At global scope tensorflow stream executor cuda cuda dnn cc 128 26 warning 'tensorflow thread ThreadPool perftools gputools cuda wrap GetCudaThreadpool ' defined but not used Wunused function static port ThreadPool GetCudaThreadpool Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 22 367s Critical Path 10 38s FAILED Build did NOT complete successfully I have configure nvcc to be the cuda compiler so I have no idea why the aforementioned message means Can any one help,,,2017-09-11 14:53:06,2017-12-14 19:00:52
PR,Branch 178996911,Improvement over last PR in that we rolled back a break in the CPU tests Fixed the same merge conflicts in tensorflow core platform cloud gcs dns cache cc Fixed a lot of trivial merge conflicts in keras,,dandelionmane,2017-12-14 06:05:13,2017-12-14 19:10:32
PR,Remove redundant dependencies,Looks like they got added back during merge 15136,,"yifeif,yifeif",2017-12-11 19:42:16,2017-12-14 19:11:51
PR,Branch 178965261,Fixed a minor merge conflict in tensorflow core platform cloud gcs dns cache cc,,"dandelionmane,yifeif,gunan",2017-12-13 23:29:02,2017-12-14 19:12:39
PR,Fix for 12537,I have built the fix on x86 linux no gpu and it is working There are some android specific code in logging that I ignored L35 L75,,"vrv,vrv,vrv,asimshankar,asimshankar",2017-12-07 02:17:27,2017-12-14 19:16:32
PR,Revert Add batch support for various image ops 14854,This reverts commit 20aa9e0a9f129ed929cea1fb45ec12b7be3ac68e fyi,,"jhseu,jhseu,martinwicke,jhseu,jhseu",2017-12-13 23:25:46,2017-12-14 19:33:22
PR,Benchmarks for flipping and random flipping,martinwicke fyi,,"jhseu,jhseu",2017-12-13 23:18:04,2017-12-14 19:33:35
IS,Iterator on cached tf data Dataset cannot be reinitialized,Found a likely bug when trying to use a reinitializable iterator to read from two cached datasets one for validation and one for training The iterator can however only be initialized once per cached dataset Seems to me like the iterator should remove the lock file when being reinitialized it is not in my case and that is why I get this issue Here is a minimal example with only one cached dataset basic system information below Example AlreadyExistsError see above for traceback There appears to be a concurrent caching iterator running cache lockfile already exists ' home ubuntu ai notebooks notebooks projects deep purple cache dir cache lockfile' If you are sure no other running TF computations are using this cache prefix delete the lockfile and re initialize the iterator Lockfile contents Created at 1513187725 Node IteratorGetNext IteratorGetNext output shapes 5 3 output types DT FLOAT device job localhost replica 0 task 0 device CPU 0 Iterator Sytem information Tensorflow version v1 4 0 rc1 11 g130a514 1 4 0 installed from pip Python version 3 5 2 OS Linux Ubuntu 16 04 3 CUDA 8 0 61 cuDNN 6,,"mrry,saeta,saeta,saeta",2017-12-13 18:15:07,2017-12-14 19:52:24
PR,Dockerfile devel gpu optimize the size of the generated image,Use nvidia cuda 9 0 base ubuntu16 04 as the base image to select just the CUDA libraries we need Remove the installed static libraries Remove the dependency on openjdk 8 since Bazel ships with a local copy Perform a shallow clone of the repository The image is 2 94GB down from 4 87GB Signed off by Felix Abecassis fabecassis nvidia com See initial discussion here,,"flx42,gunan,flx42,flx42,gunan,flx42,gunan,yongtang,martinwicke,angersson",2017-12-14 05:39:52,2017-12-14 20:38:56
PR,Fix issue in the Defun docs,This fix fixes a couple of typos in the Defun docs tf Constant tf constant Signed off by Yong Tang yong tang github outlook com,,"yongtang,jhseu",2017-11-07 15:06:43,2017-12-14 20:53:16
PR,Add float64 support for conv1d and conv2d,This fix tries to address the issue raised in 12941 where float64 for conv1d and conv2d is incomplete This fix adds float64 support for conv1d float64 support for conv2d float16 support for conv3d updated docs for float16 support of conv1d already supported This fix fixes 12941 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,drpngx,yongtang,drpngx,sb2nov,sb2nov,yongtang,sb2nov,drpngx,yongtang,yongtang,gunan,martinwicke,yongtang,drpngx,martinwicke,martinwicke",2017-09-10 09:45:24,2017-12-14 21:39:33
IS,Automatic node placement allocating graph nodes to multiple devices feature in distributed tensorflow,I read tensorflow white papaer and found node placement which allocates graph nodes to devices without manual configuration This post says this feature was removed because it did not perform well However it was posted a year ago and I think you are still developing this feature Is it included in the current version of tensorflow If so what code do i need to see If inot do you plan to add this feature,,,2017-12-14 13:58:56,2017-12-14 22:17:10
PR,Changed ffmpeg verbosity semantics,The tf contrib ffmpeg decode and tf contrib ffmpeg encode functions are extremely verbose and make it nearly impossible to see other printed messages Corresponding methods for image such as tf image decode png produce no output under normal conditions and it would be nice for audio video methods to align with this FFmpeg on valid MP3 file with loglevel info and without hide banner old semantics,,yongtang,2017-11-15 10:34:08,2017-12-14 23:10:03
PR,Fixed typo in tfprof,intialized initialized,,"PW486,martinwicke",2017-11-10 05:17:15,2017-12-15 01:32:36
IS,CMake Default values of some options are not properly set,by default However because cmake options is default values are either OFF or ON this does not work as supposed I will post a Pull Request addressing this issue in a few minutes,,myungjoo,2017-11-09 10:21:37,2017-12-15 01:33:17
PR,CMake configure default string values of options properly,Because cmake configures defaults values as ON or OFF only string values as default does not work Thus when it is set OFF we need to re set the values Fixes 14400 Signed off by MyungJoo Ham myungjoo ham samsung com,,"myungjoo,mrry",2017-11-09 10:25:34,2017-12-15 01:33:17
IS,GPU memory usage changed from TF 1 3 0 to 1 4 0 runs out of memory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Custom code included below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary From pip TensorFlow version use command below 1 3 0 and 1 4 0 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version cuda 8 0 cudnn 6 0 GPU model and memory GTX 1080 8GB Exact command to reproduce python example script py Describe the problem Bug TensorFlow runs out of GPU memory ResourceExhaustedError when using version 1 4 0 when running code that runs fine on version 1 3 0 Please see the following script to reproduce Source code logs,,angersson,2017-12-14 22:55:32,2017-12-15 01:54:55
IS,Performance problem TF VS Keras,Hello I just got huge difference in results using Keras Back end TensorFlow and TensorFlow I want to know if the difference in performances is normal The keras model produces a loss of 0 2 model k models Sequential model add k layers convolutional Conv2D 64 kernel size 3 3 input shape 75 75 3 model add Activation arelu' model add BatchNormalization model add k layers convolutional MaxPooling2D pool size 3 3 strides 2 2 model add k layers Dropout 0 2 model add k layers convolutional Conv2D 128 kernel size 3 3 model add Activation arelu' model add BatchNormalization model add k layers convolutional MaxPooling2D pool size 2 2 strides 2 2 model add k layers Dropout 0 2 model add k layers convolutional Conv2D 128 kernel size 3 3 model add Activation arelu' model add BatchNormalization model add k layers convolutional MaxPooling2D pool size 2 2 strides 2 2 model add k layers Dropout 0 3 model add k layers convolutional Conv2D 64 kernel size 3 3 model add Activation arelu' model add BatchNormalization model add k layers convolutional MaxPooling2D pool size 2 2 strides 2 2 model add k layers Dropout 0 3 model add k layers Flatten model add k layers Dense 512 model add Activation arelu' model add BatchNormalization model add k layers Dropout 0 2 model add k layers Dense 256 model add Activation arelu' model add BatchNormalization model add k layers Dropout 0 2 model add k layers Dense 1 model add Activation isigmoid' mypotim Adam lr 0 01 decay 0 0 model compile loss 'binary crossentropy' optimizer mypotim metrics 'accuracy' The TensorFlow normal model produces 0 7 x tf placeholder tf float32 None 75 75 3 name DNN Input learningRateIn tf placeholder tf float32 keep prob tf placeholder tf float32 isTrainPlace tf placeholder tf bool with tf name scope 'conv 1' conv 1 tf layers conv2d x 64 3 3 activation tf nn relu batch n1 tf contrib layers batch norm conv 1 center True scale True is training isTrainPlace scope 'bn1' mpool 1 tf layers max pooling2d batch n1 pool size 2 2 strides 2 2 dropout 1 tf layers dropout mpool 1 rate 0 8 training isTrainPlace with tf name scope 'conv 2' conv 2 tf layers conv2d dropout 1 128 3 3 activation tf nn relu batch n2 tf contrib layers batch norm conv 2 center True scale True is training isTrainPlace scope 'bn2' mpool 2 tf layers max pooling2d batch n2 pool size 2 2 strides 2 2 dropout 2 tf layers dropout mpool 2 rate 0 8 training isTrainPlace with tf name scope 'conv 3' conv 3 tf layers conv2d dropout 2 128 3 3 activation tf nn relu batch n3 tf contrib layers batch norm conv 3 center True scale True is training isTrainPlace scope 'bn3' mpool 3 tf layers max pooling2d batch n3 pool size 2 2 strides 2 2 dropout 3 tf layers dropout mpool 3 rate 0 7 training isTrainPlace with tf name scope 'conv 4' conv 4 tf layers conv2d dropout 3 64 3 3 activation tf nn relu batch n4 tf contrib layers batch norm conv 4 center True scale True is training isTrainPlace scope 'bn4' mpool 4 tf layers max pooling2d batch n4 pool size 2 2 strides 2 2 dropout 4 tf layers dropout mpool 4 rate 0 7 training isTrainPlace h4 tf contrib layers flatten dropout 4 with tf name scope wouldense 1' y dense 1 tf layers dense h4 512 activation tf nn relu batch dense 1 tf contrib layers batch norm y dense 1 center True scale True is training isTrainPlace scope 'bn5' dropout dense 1 tf layers dropout batch dense 1 rate 0 8 training isTrainPlace with tf name scope wouldense 2' y dense 2 tf layers dense dropout dense 1 256 activation tf nn relu batch dense 2 tf contrib layers batch norm y dense 2 center True scale True is training isTrainPlace scope 'bn6' dropout dense 2 tf layers dropout batch dense 2 rate 0 8 training isTrainPlace y estimated tf layers dense dropout dense 2 2 PS the code above is inspired from url Can anybody help me please to undersand if it is normal or not does Keras uses different tensorflow parameters than the default parameters of tensorflow Thanks in advance Toetoe,,angersson,2017-12-14 23:54:03,2017-12-15 01:55:29
PR,Fixed typos in comments,,,"PW486,betterenvi,betterenvi,PW486,betterenvi,jhseu",2017-11-09 10:14:44,2017-12-15 01:57:14
PR,Forward declare condition variable fix for 14388,Necessary to enable friendship with mutex on msvc,,,2017-11-09 01:35:26,2017-12-15 01:57:45
IS,opencv cannot read any image with tensorflow,It is the same issue as 1924 since the bug is closed I open a new one because this bug have not been solved yet From subashp I am using the TF 1 4 and linking against C code Below code always says it failed to read the file I have incorporated above suggestions and it doesnt make any difference Thoughts suggestions,,"allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie,gunan,allenlavoie",2017-11-06 02:14:50,2017-12-15 05:04:56
PR,Instead of option use set to define non bool cmake build args,,,"gunan,gunan",2017-12-14 21:20:27,2017-12-15 06:02:41
IS,InvalidArgumentError in tensorflow reduce sum gradient when compiling from sources,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0rc2 Python version 3 5 3 Bazel version if compiling from source cmake 3 9 0 CUDA cuDNN version cpu only GPU model and memory cpu only Exact command to reproduce I compiled tensorflow from source according to the instructions given here I activated support for AVX that is the reason I want to compile from source All steps work without problems I then install the whl with pip in my python environment Now if I run my code with that version of tf it crashes but it works if I use a pre compiled version Describe the problem A script that runs without problems when I use a pre built version of tensorflow throws an error when I use the compiled version see below for trace I also compiled r1 2 and saw the same problem Since the code works with the pre built tf version 1 1 I suspect the problem is related to compiling from source Source code logs Error when running with the compiled tf The code causing the error is w tf exp tf reduce sum tf multiply node labels enc state axis 2 keep dims True Both node labels and enc state are 40x5x30 dim tensors And as I already said there are no issues at all running this code if I do not compile from source,,"skye,skye,aselle,angersson,mrry",2017-08-10 12:51:14,2017-12-15 09:41:26
IS,Windows Environment and TF 1 4 1 Unavailable through PyPI,Hello dear Tensorflowers When running the following code pip install tensorflow 1 4 1 I obtain the following error This error seem logical because the wheel file does not exist for the windows distribution TF 1 4 1 No Windows Compiled Library TF 1 4 0 Windows Compiled Library is present Is the support for the windows platform dropped Or maybe some compilation pipeline broke somewhere Thanks for your help Jonathan,,"gunan,gunan",2017-12-13 16:09:02,2017-12-15 09:51:53
PR,Use base dtype for self dtype in tf layers,This avoids mismatch dtype ref vs no ref when using variables as inputs to a layer See 15262,,"ppwwyyxx,ppwwyyxx,alextp",2017-12-12 01:23:28,2017-12-15 09:52:50
IS,import scoped meta graph use wrong name scope and fails to restore the collections,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 3 6 3 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem This is a tiny code occurs the problem In this code import scoped meta graph def create the different variables s v and s 1 v but returns only s v This problem occurs when the name scope created by import graph def inside import scoped meta graph def does not match the argument import scope L658 L663,,,2017-12-13 00:46:03,2017-12-15 12:05:05
IS,Standardize arguments in SessionRunHook APIs,Some hooks inheriting from SessionRunHook use different input argument keywords while implementing the exact same functionality This should be ironed out I wanted to make a PR for this but I realised this will be backwards incompatible Still I think we should standardise this E g every secs by SecondOrStepTimer every n secs by LoggingTensorHook this seems like most descriptive one to me save secs by CheckpointSaverHook,,ispirmustafa,2017-12-14 21:10:30,2017-12-15 16:43:57
PR,Support config monolithic in tf sysconfig get link flags,Currently tf sysconfig get link flags always adds ltensorflow framework With this change it would check whether TensorFlow was built with config monolithic,,"alsrgv,alsrgv,alsrgv,alsrgv,drpngx,drpngx,ekelsen,alsrgv,drpngx,alsrgv,ekelsen,ekelsen,alsrgv",2017-12-05 20:22:48,2017-12-15 16:59:54
IS,index to string table from file cannot use tf string as vocabulary file,Running stock tensorflow on macOS I get Due to None check at L1126 This is an issue because I can not seem to be able to make index to string table from file read the vocabulary file from a GraphKeys ASSET FILEPATHS collection when storing the graph as a saved model,,,2017-11-12 22:37:22,2017-12-15 18:20:53
PR,index to string table from file can use tf string as vocabulary file,Fix 14505 How to test x add test case pass all tests,,"facaiy,martinwicke,facaiy,martinwicke",2017-11-13 05:42:37,2017-12-15 18:20:53
PR,Add description for new PR workflow,,,"yifeif,martinwicke,yifeif",2017-12-15 01:16:51,2017-12-15 18:37:35
IS,Distributed Training Randomly Stops During the Training Process,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 2 CUDA cuDNN version 6 0 GPU model and memory Tesla K80 12G Describe the problem In my distributed training program there are one server and two workers which all run in separately nvidia docker container At the beginning the cluster works just fine but running normally after several hours the two workers just stop My training process 1 I create three nvidia docker containers one for parameter server two for workers 2 In every container I run the train replica function below after defining all necessary parts such as cluster spec inference function data batch and so on 3 It works correctly at the beginning 4 It stops several hours later Source code logs My trainer function,,"jart,aselle,mrry,mrry,angersson,mrry",2017-08-29 02:32:00,2017-12-15 18:38:30
PR,Replace loop iteration with chip,In unique op cc the ouput tensor was generated through loop iteration It seems that this could be improved through Eigen is chip The fix addresses this improvement Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-12-12 02:04:15,2017-12-15 19:02:55
IS,No GPU OpKernel for tf exp operation for Complex64,I am running tensorflow 1 4 0 from nightly build 'v1 3 0 rc1 5297 g4b7d79b6ea' on ubuntu 16 04 I have had success working in eager mode great job with this guys however I think I found a small bug It seems that there is no OpKernel on device 'GPU' for the tf exp operation applied to complex numbers in eager mode This can be reproduced with the below code Keeping operations on CPU works just fine but I figured this would be easy to implement for GPU as well Thanks,,"reedwm,asimshankar,rryan,rryan,rryan",2017-12-04 19:43:46,2017-12-15 19:54:38
PR,GPU Add Complex kernel for tf exp,Fix 15103 Because it is my first contribution for GPU kernel the PR might be not good Welcome to feedback and any help will be appreciated Thanks How to test x add test case pass all test,,"facaiy,rmlarsen,rmlarsen,rmlarsen",2017-12-07 11:58:42,2017-12-15 19:54:38
IS,Computing gradients of loop variables return None,Problem description I got None when computing gradient of the two loop variables that are supposed to have gradient Minimum code to reproduce the error System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Debian GNU Linux 7 11 wheezy TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 4 g9283868 1 4 0 Python version 3 5 4 Bazel version if compiling from source CUDA cuDNN version NA GPU model and memory NA,,"angersson,angersson",2017-12-15 18:27:24,2017-12-15 21:00:37
IS,Tensorflow c memory leak Valgrind,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 17 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source 0 5 1 GCC Compiler version if compiling from source 6 0 3 CUDA cuDNN version N A GPU model and memory N A Describe the problem I am executing simple tensorflow code to create graph def as shown below These type of errors are also generated when I do session run Due to the above issues the memory needed to run the program keeps increasing as time passes and the application crashes due to insufficient memory after a certain point of time I have also posted the issue in stack overflow,,angersson,2017-12-15 14:14:46,2017-12-15 21:08:24
PR,Go Make op wrapper generation more robust,Since Go 1 8 GOPATH has a default value so handle that gopath generate sh expected bash for the string substitution syntax while ish' may point to another shell So explicitly require bash,,"asimshankar,asimshankar",2017-12-14 02:09:33,2017-12-15 21:51:04
PR,Fix tflite models md title,,,,2017-12-15 22:13:05,2017-12-15 22:20:33
IS,module 'tensorflow contrib' has no attribute 'lite',Hello folks Everytime I try to run the example fo TOCO I get the error module 'tensorflow contrib' has no attribute 'lite' OS Platform and Distribution Mac OS High Sierra Tensorflow installed from pip version 1 4 1 Python version 2 7 14 and 3 6 3 Anaconda custom 64 bit The informations about my system are those cat etc issue Darwin Leandros MacBook Pro local 17 3 0 Darwin Kernel Version 17 3 0 Thu Nov 9 18 09 22 PST 2017 root xnu 4570 31 3 1 RELEASE X86 64 x86 64 Mac OS X 10 13 2 are we in docker No compiler Apple LLVM version 9 0 0 clang 900 0 37 Target x86 64 apple darwin17 3 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin uname a Darwin Leandros MacBook Pro local 17 3 0 Darwin Kernel Version 17 3 0 Thu Nov 9 18 09 22 PST 2017 root xnu 4570 31 3 1 RELEASE X86 64 x86 64 check pips numpy 1 13 3 numpydoc 0 7 0 protobuf 3 5 0 post1 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found Seams like tensorflow lite is not available for reason Sorry if this is not a bug and I am just being dumb about how to make TOCO works,,"aselle,angersson",2017-12-15 18:02:55,2017-12-15 22:28:51
IS,Feature request tf info to show docstrings in jupyter notebook,When working with jupyter notebooks it is really helpful to see the documentation within the notebook Numpy has a function called np info which takes a numpy function as argument and prints its docstring For example np info np mean prints the docstring for np mean It would be really helpful to have an equivalent tf info for those of us who work with jupyter notebooks and who does not,,ppwwyyxx,2017-12-15 14:36:36,2017-12-15 22:52:40
IS,Upgrade to CuDNN 7 and CUDA 9,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Server 2012 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 rc1 Python version 3 5 2 Bazel version if compiling from source N A CUDA cuDNN version CUDA V8 0 44 CuDNN 6 0 GPU model and memory Nvidia GeForce GTX 1080 Ti 11 GB Exact command to reproduce N A Describe the problem Please upgrade TensorFlow to support CUDA 9 and CuDNN 7 Nvidia claims this will provide a 2x performance boost on Pascal GPUs,,"shivaniag,tfboyd,tfboyd,tfboyd,theflofly,tfboyd,ppwwyyxx,tfboyd,tfboyd,4F2E4A2E,tfboyd,4F2E4A2E,cancan101,tfboyd,tfboyd,theflofly,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd,yaroslavvb,tfboyd,tfboyd,tfboyd,yaroslavvb,tfboyd,gunan,gunan,gunan,yaroslavvb,gunan,gunan,4F2E4A2E,gunan,gunan,4F2E4A2E,tfboyd,tfboyd",2017-08-04 22:57:53,2017-12-15 23:02:03
PR,Bump the eigen dependency version,Fixes 12052,,gunan,2017-12-15 19:56:18,2017-12-15 23:02:03
PR,Load boundaries array into shared memory before hand for bucketize,This fix is a follow up to 13922 This fix loads boundaries array into shared memory before each thread in order to improve performance for bucketize op The fix is based on feedback discussion r150058312 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,sb2nov,yongtang,drpngx,rmlarsen,drpngx",2017-11-21 23:30:52,2017-12-16 00:06:14
IS,cannot install with virtualenv python3 6,Have I written custom code No OS Platform and Distribution MacOS 10 13 2 TensorFlow installed from conda URL of the TensorFlow Python package TensorFlow version 1 4 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce I just follow Install with conda My python was installed with conda I think maybe that is the problem virtualenv system site packages p python3 tensorflow Running virtualenv with interpreter usr local bin python3 Using base prefix ' usr local Cellar python3 3 6 3 Frameworks Python framework Versions 3 6' New python executable in Users xinhai tensorflow bin python3 6 Also creating executable in Users xinhai tensorflow bin python Installing setuptools pip wheel Complete output from command Users xinhai tensorflow bin python3 6 setuptools pip wheel stringstringstringstringstringstringstringstring Traceback most recent call last File stdin line 7 in module File usr local lib python2 7 site packages virtualenv support pip 9 0 1 py2 py3 none any whl pip init py line 5 in module File usr local Cellar python3 3 6 3 Frameworks Python framework Versions 3 6 lib python3 6 logging init py line 28 in module from string import Template ImportError cannot import name 'Template' Installing setuptools pip wheel done Traceback most recent call last File usr local lib python2 7 site packages virtualenv py line 2328 in module main File usr local lib python2 7 site packages virtualenv py line 713 in main symlink options symlink File usr local lib python2 7 site packages virtualenv py line 945 in create environment download download File usr local lib python2 7 site packages virtualenv py line 901 in install wheel call subprocess cmd show stdout False extra env env stdin SCRIPT File usr local lib python2 7 site packages virtualenv py line 797 in call subprocess cmd desc proc returncode OSError Command Users xinhai tensorflow bin python3 6 setuptools pip wheel failed with error code 1,,,2017-12-15 08:54:21,2017-12-16 10:10:21
IS,official MNIST example should avoid huge constants,Right now MNIST model loads dataset as a huge MNIST constant L65 This makes graphdef 1 GB in size That causes slowness when trying to visualize graph dump graphdef It should instead avoid constant IE you can load dataset into tf Variable,,yaroslavvb,2017-12-16 21:23:00,2017-12-16 21:23:26
PR,Add customerized kernel implementation for clip by value,This fix tries to address the issue raised in 7225 where tf clip by value does not have a custom kernel and reused tf maximum and tf mimimum In case scalar values are passed to tf clip by value unnecessary memory usage might incur This fix adds the customerized kernel implementation for tf clip by value This fix fixes 7225 Signed off by Yong Tang yong tang github outlook com,,"yongtang,benoitsteiner,benoitsteiner,yongtang,yongtang,benoitsteiner,yongtang,yongtang,martinwicke,benoitsteiner,benoitsteiner,yongtang,gunan",2017-10-26 13:38:07,2017-12-16 23:02:59
IS,IteratorGetNext should have a None gradient defined,Currently IteratorGetNext has no gradient defined This can cause failures like below in tf gradients The solution is to define None gradient like the tf stop gradient op A work around when this failure occurs is to wrap dataset ops inside tf stop gradient,,"yaroslavvb,yaroslavvb",2017-12-16 23:17:24,2017-12-17 00:03:35
PR,Initial SRU Implementation,Hi as per I'm submitting an initial PR for SRU implementation I have checked the results with implementation here I intend to implement SRUBlock as well but I have been distracted away by other high priority things until recently So I will incrementally add the SRUBlock here as well In addition it occurs to me that SRU only allows num units equal to input size Can someone verify my interpretation Otherwise we cannot perform equaiton 7 in the paper because of last dimension size mismatch,,"tjingrant,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,tjingrant,tjingrant,tjingrant,tjingrant,tjingrant,ebrevdo,tjingrant,benoitsteiner,ebrevdo,gunan,asimshankar,tjingrant,ebrevdo",2017-10-25 18:35:51,2017-12-17 01:00:28
PR,Fix issues in doc tf Placeholder should be tf placeholder,This fix fixes issues in the doc data feeder py where tf Placeholder should be tf placeholder,,"yongtang,mrry",2017-12-13 03:47:59,2017-12-17 01:05:00
PR,Fix typos,This PR fixes some typos transfered betweeen forwared occuring occured varibale succesfully and depedency,,taehoonlee,2017-12-13 08:00:25,2017-12-17 01:37:36
PR,Fixing typo,,,rajendraarora16,2017-12-12 13:40:32,2017-12-17 05:12:20
IS,Not a valid TensorFlow Graph serialization at org tensorflow contrib android TensorFlowInferenceInterface loadGraph loadGraph,Hi I build libtensorflow inference so libandroid tensorflow inference java jar from source then use them in an android studio project But when I run TensorFlowInferenceInterface tflite new TensorFlowInferenceInterface assetManager MODEL PATH the program always crashes and prints Caused by java io IOException Not a valid TensorFlow Graph serialization Invalid GraphDef at org tensorflow contrib android TensorFlowInferenceInterface loadGraph TensorFlowInferenceInterface java 551 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 105 The tflite file in MODEL PATH is generated successfully by bazel toco from a model graph and the tflite file is successfully read into byte array Are there any special restrictions on the graph What are the possible reasons why function TensorFlowInferenceInterface loadGraph throws an Exception Thanks a lot,,,2017-12-17 09:45:49,2017-12-18 01:35:20
PR,Revert Initial SRU Implementation 13978,This reverts commit e3e2ac9181c42eb82548726d8a250944b56180fd,,"gunan,tjingrant,gunan",2017-12-18 05:30:45,2017-12-18 06:00:35
PR,Fix PEP8,This PR fixes pep8 related issues,,taehoonlee,2017-12-15 02:11:27,2017-12-18 06:03:46
PR,Fix 15297 bfloat16 is unsigned on Windows,15297 BYTE ORDER is not a builtin macro in VC Need to include tensorflow core platform cpu info h before using it,,"snnn,snnn,snnn,guschmue,dandelionmane,snnn,meteorcloudy,snnn",2017-12-12 08:05:53,2017-12-18 06:05:29
IS,feature request Switch to nvidia docker v2,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 3 5 4 Bazel version if compiling from source None GCC Compiler version if compiling from source None CUDA cuDNN version None GPU model and memory None Exact command to reproduce None Describe the problem Now we are using nvidia docker v1 for CI build We should switch to v2 because v1 is now being deprecated Source code logs,,"snnn,gunan,snnn,gunan",2017-12-18 02:57:44,2017-12-18 07:14:27
PR,R0 7,,,,2017-12-18 07:46:29,2017-12-18 07:51:34
IS,iOS build all ios ssd sh wouldouble conversion double conversion h' file not found,iOS build all ios ssd sh wouldouble conversion double conversion h' file not found but script downloaded double conversion in downloads folder located at tensorflow contrib makefile,,,2017-12-12 13:33:18,2017-12-18 12:53:45
PR,Fix the CODEOWNERS file syntax,Note even though this file is currently disabled it still seems worth fixing the syntax in case it is enabled again in the future See for details on CODEOWNERS syntax In particular we should change from this pattern,,"nealwu,gunan,nealwu",2017-12-16 02:12:14,2017-12-18 17:28:59
IS,Build break on locale Windows,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 1703 TensorFlow installed from source or binary source TensorFlow version use command below d752244 1 4 0 Python version 3 6 Bazel version if compiling from source cmake 3 9 6 GCC Compiler version if compiling from source msvc 1900 CUDA cuDNN version cuda 8 0 61 cudnn 6 0 GPU model and memory 1080ti 11GiB Exact command to reproduce cmake A x64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE C Users User swigwin 3 0 10 swig exe DPYTHON EXECUTABLE C Users User Anaconda3 python exe DPYTHON LIBRARIES C Users User Anaconda3 python36 lib Dtensorflow ENABLE GPU ON DCUDNN HOME C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 Dtensorflow WIN CPU SIMD OPTIONS arch AVX2 You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Because msvc use locale code page to open source file build fail on re2 is test if use locale Windows Already create a PR on upstream Please help Thanks Source code logs C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1281 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1282 error C2064 1 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1284 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1285 error C2064 1 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1287 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1288 error C2064 1 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1296 error C2059 ' ' C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1298 error C2070 are2 ErrorTest ' sizeof C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1365 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1366 error C2146 ' ' istring' C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1375 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1376 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1377 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1378 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1379 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1380 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1382 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1383 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1384 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1385 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1386 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1387 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1389 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1390 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1391 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1392 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1393 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1394 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1416 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1417 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1418 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1630 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1631 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing re2 test cc 1375 fatal error C1057 C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 244 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 245 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 246 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 247 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 248 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 249 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 250 error C2001 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 252 error C2064 1 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 311 error C2064 1 C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 311 error C2059 ' ' C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj C Users User tensorflow tensorflow contrib cmake build re2 src re2 re2 testing search test cc 315 error C2070 are2 RegexpTest ' sizeof C Users User tensorflow tensorflow contrib cmake build re2 src re2 search test vcxproj C Users User tensorflow tensorflow contrib cmake build re2 vcxproj,,"fo40225,mrry",2017-12-18 16:47:24,2017-12-18 17:53:44
PR,Fix failing test tensorflow python function test,benoitsteiner It seems tensorflow python function test is failing with my last commit from 13998 sorry about that It looks like the function test created a graph with python through a helper class and invoked tests through c api I am not familiar with the function test though as ClipByValue is actually hidden and is exposed through python only with the gradient defined in python as well I think replacing it will fix the issue Please take a look Again really sorry for the caused inconvenience Signed off by Yong Tang yong tang github outlook com,,"yongtang,gunan,yongtang,yongtang,tjingrant,caisq,yongtang",2017-12-17 18:21:03,2017-12-18 18:20:54
IS,Feature request RecordInput to support gzipped tfrecord files,Currently RecordInput does not support gzipped tfrecord files would be great to have this supported,,yongtang,2017-08-17 01:55:56,2017-12-18 18:37:26
PR,Add compression support to RecordInput,This fix tries to fix the request raised in 12344 so that it is possible to process RecordInput with compressions An attr of compression type has been added Additional tests have been created to cover the changes This fix fixes 12344 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,drpngx,martinwicke,yongtang,yongtang,martinwicke,drpngx,drpngx,yongtang,yongtang,drpngx,yongtang,drpngx,drpngx,martinwicke",2017-08-17 19:53:41,2017-12-18 18:37:26
IS,Minor documentation mistake,Under the Getting a tf Tensor object is rank subheading r tf rank my3d should be r tf rank my image,,angersson,2017-12-12 23:22:56,2017-12-18 19:56:11
IS,Feature Request API Design review tf get shape tf get size tf Tensor size tf Tensor get size etc,Below everything with get in the name refers to dynamic symbolic everything without to static integer 1 Introduce tf get shape x Then tf get shape x tf shape x will be analogous to existing tf Tensor get shape tf Tensor shape 2 Introduce tf set shape x matching tf get shape x 3 Introduce tf get size x Then tf get size x tf size x will be analogous to tf get shape x tf shape x 4 Ditto for tf get shape n x see tf shape n x 5 Introduce tf Tensor size for compatibility with np ndarray size tf size x x size will be analogous to tf shape x x shape 6 Ditto for tf Tensor get size 7 Should there also be tf size n x and tf get size n x,,"ozabluda,asimshankar,ozabluda,reedwm,martinwicke",2017-10-27 21:44:04,2017-12-18 20:51:43
PR,add recovery wait secs option for MonitoredTrainingSession,In order to reduce the sleep time by worker to wait for a model to be initialized or restored we add recovery wait secs option for MonitoredTrainingSession and we are able to start distributed training faster,,"horance-liu,ispirmustafa,horance-liu,martinwicke,horance-liu,frankchn,jhseu,rmlarsen,rmlarsen,rmlarsen,rmlarsen,martinwicke,horance-liu,jhseu,jhseu,jhseu,horance-liu,martinwicke,gunan,martinwicke,drpngx,sb2nov,horance-liu,gunan,martinwicke,martinwicke",2017-07-16 10:01:20,2017-12-18 20:55:23
PR,Update core py,Corrected the documentation of the Dense layer regarding the computation performed by the layer,,AndreiCostinescu,2017-12-18 17:14:13,2017-12-18 21:47:29
PR,Fix api usage in examples of GAN,,,betterenvi,2017-12-15 07:45:17,2017-12-18 21:50:55
PR,Fix typo of tf abs docstring,Change ' which causes incorrect highlight to And by the way this is a typo I found when checking whether 9827 was resolved The answer seems to be yes and we can close 9827 now,,qmick,2017-12-15 12:13:19,2017-12-18 21:52:45
IS,Dataset API does not pass dimensionality information when constructing graph using official ResNet,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OSX 10 12 6 TensorFlow installed from source or binary TensorFlow version use command below 1 3 0 Python version 3 6 1 Describe the problem When I try to combine the dataset API with the resnet architecture provided at tensorflow models official resnet the graph cannot be constructed because the dimension of the input data is not passed to the model constructing function Source code logs Skeleton code The last line throws an error on compiling ValueError The last dimension of the inputs to Dense should be defined Found None this makes reference back to the resent v2 definition where the final layer is a dense layer It appears that the dataset API is not passing dimension information hence the final dense layer does not know how to construct itself,,"drpngx,mrry,mrry,mrry,mrry,mrry",2017-09-27 18:32:37,2017-12-18 22:03:36
PR,Enable api compatibility test to also run on macos,Looks like it also passes on macos when we use python 2,,gunan,2017-12-18 21:10:30,2017-12-18 22:09:52
PR,Add an is external arg to tf copts,It is for support build custom ops on Windows This is what we talked last week,,"snnn,snnn,meteorcloudy,snnn,gunan,yifeif",2017-12-18 09:04:41,2017-12-18 22:10:21
PR,Fix lib strings str util test on Windows,,,"snnn,mrry,yifeif",2017-12-18 11:41:24,2017-12-18 22:27:34
PR,Fix broken link in tensorflow lite readme,,,,2017-12-13 18:21:36,2017-12-19 00:27:41
PR,variable scope use auxiliary name scope to control whether to create new name scope,Now variable scope always create a new name scope side effect when invoked The behavior will result in name scope collision mentioned in 13429 Hence we proposed to add a parameter auxiliary name scope to control whether to create new name scope or not If accepted we can reenter variable scope and its original name scope without side effect How to test x add unit tests pass all tests,,"facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,lukaszkaiser,facaiy,facaiy,facaiy,lukaszkaiser,facaiy,martinwicke,facaiy,facaiy,facaiy,facaiy,martinwicke,martinwicke,facaiy",2017-11-09 03:07:44,2017-12-19 00:52:10
PR,Disable failing testcases on windows,,,gunan,2017-12-19 00:21:01,2017-12-19 00:56:33
PR,Include solib local for MKL DNN libs,solib local libmklml intel so is not getting included in the package build pip package sh has been updated to copy solib instead of just solib k8 so just update setup py to include it See for details,,"gunan,yifeif",2017-11-20 07:13:14,2017-12-19 01:09:38
PR,Branch 179464468,Push,,"ekelsen,yifeif,yifeif",2017-12-18 22:44:38,2017-12-19 01:33:34
IS,Bug with tf layers Dense,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 GPU model and memory GTX 1080 ti Exact command to reproduce with tf variable scope 'hello' as var scope var tf get variable 'var' 3 4 5 dense tf layers Dense 5 name wouldense layer' b dense a And the error was RuntimeError Conversion function function TensorConversionFunction at 0x7f5bed522b90 for type class 'tensorflow python ops variables Variable' returned incompatible dtype requested float32 ref actual float32,,"facaiy,facaiy,facaiy,ppwwyyxx,facaiy,fchollet,alextp",2017-12-11 07:51:25,2017-12-19 01:34:15
PR,Compute test accuracy in batches to avoid OOM on GPUs,Reported here Alternative to this for mnist deep py Note that some reports in claim that BFC solves the problem and that it would be included in the next binary release but as this writing is two years after those comments it stands to reason that the example still does not work out of the box for low memory GPUs,,,2017-12-19 03:52:09,2017-12-19 04:11:10
IS,Feature request Use placeholders to specify the inputs of TFGAN model,,,"betterenvi,betterenvi",2017-12-15 06:02:16,2017-12-19 06:13:54
IS,feature request custom GraphKeys QUEUE RUNNERS for input pipeline,i find no perfect answer about using input pipeline to train and eval in same Session switch input pipeline at stackoverflow eg if we define different input pipeline for train and eval the following code will start both train and eval input pipeline that is not we want if we can custom GraphKeys QUEUE RUNNERS collection for different input pipeline i think we can start input pipeline through parameter of collection tf train add queue runner qr collection tf GraphKeys QUEUE RUNNERS eg tf train add queue runner qr collection tf GraphKeys TRAIN QUEUE RUNNERS eg tf train add queue runner qr collection tf GraphKeys EVAL QUEUE RUNNERS is it right thanks,,"tatatodd,mrry",2017-11-22 11:55:21,2017-12-19 08:09:40
IS,error bazel building quantize graph with cuda,this is for tf 1 3 and bazel 0 53 with cuda 8 and cudnn 6 on windows 10 64 and python 3 6 bazel build tensorflow tools quantization quantize graph verbose failures Loading complete Analyzing Found 1 target Building 0 10 Linking tensorflow python gen state ops py wrappers cc exe for host From Linking tensorflow python gen state ops py wrappers cc exe for host LINK warning LNK4044 unrecognized option ' Wl rpath local config cuda cuda lib64' ignored LINK warning LNK4044 unrecognized option ' Wl rpath local config cuda cuda extras CUPTI lib64' ignored LINK warning LNK4044 unrecognized option ' pthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' ldl' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' ldl' ignored LINK warning LNK4044 unrecognized option ' lpthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lpthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored LINK warning LNK4044 unrecognized option ' lpthread' ignored LINK warning LNK4044 unrecognized option ' lm' ignored Creating library bazel out host bin tensorflow python gen state ops py wrappers cc lib and object bazel out host bin tensorflow python gen state ops py wrappers cc exp From Compiling tensorflow core kernels batch norm op gpu cu cc cl Command line warning D9002 ignoring unknown option ' x' cl Command line warning D9002 ignoring unknown option ' nvcc options relaxed constexpr' cl Command line warning D9002 ignoring unknown option ' nvcc options ftz true' cl Command line warning D9002 ignoring unknown option ' msse3' cl Command line warning D9024 unrecognized source file type 'cuda' object file assumed cl Command line warning D9027 source file 'cuda' ignored ERROR C users user downloads tensorflow tensorflow core kernels BUILD 2703 1 C compilation of rule ' tensorflow core kernels depthwise conv op gpu' failed Exit 2 cl exe failed error executing command SET CUDA COMPUTE CAPABILITIES 6 1 SET CUDA PATH C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 SET CUDA TOOLKIT PATH C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 SET CUDNN INSTALL PATH C Program Files NVIDIA GPU Computing Toolkit CUDA v8 0 SET INCLUDE C Program Files x86 Microsoft Visual Studio 14 0 VC INCLUDE C Program Files x86 Microsoft Visual Studio 14 0 VC ATLMFC INCLUDE C Program Files x86 Windows Kits 10 include 10 0 14393 0 ucrt C Program Files x86 Windows Kits NETFXSDK 4 6 1 include um C Program Files x86 Windows Kits 10 include 10 0 14393 0 shared C Program Files x86 Windows Kits 10 include 10 0 14393 0 um C Program Files x86 Windows Kits 10 include 10 0 14393 0 winrt SET LIB C Program Files x86 Microsoft Visual Studio 14 0 VC LIB amd64 C Program Files x86 Microsoft Visual Studio 14 0 VC ATLMFC LIB amd64 C Program Files x86 Windows Kits 10 lib 10 0 14393 0 ucrt x64 C Program Files x86 Windows Kits NETFXSDK 4 6 1 lib um x64 C Program Files x86 Windows Kits 10 lib 10 0 14393 0 um x64 SET NO WHOLE ARCHIVE OPTION 1 SET PATH C Program Files x86 Microsoft Visual Studio 14 0 Common7 IDE CommonExtensions Microsoft TestWindow C Program Files x86 Microsoft Visual Studio 14 0 VC BIN amd64 C Windows Microsoft NET Framework64 v4 0 30319 C Program Files x86 Microsoft Visual Studio 14 0 VC VCPackages C Program Files x86 Microsoft Visual Studio 14 0 Common7 IDE C Program Files x86 Microsoft Visual Studio 14 0 Common7 Tools C Program Files x86 Microsoft Visual Studio 14 0 Team Tools Performance Tools x64 C Program Files x86 Microsoft Visual Studio 14 0 Team Tools Performance Tools C Program Files x86 Windows Kits 10 bin x64 C Program Files x86 Windows Kits 10 bin x86 C Program Files x86 Microsoft SDKs Windows v10 0A bin NETFX 4 6 1 Tools x64 C Anaconda3 C users user downloads C tools msys64 usr local bin C tools msys64 usr bin C tools msys64 usr bin C tools msys64 opt bin C Windows System32 C Windows C Windows System32 Wbem C Windows System32 WindowsPowerShell v1 0 C tools msys64 usr bin site perl C tools msys64 usr bin vendor perl C tools msys64 usr bin core perl C WINDOWS system32 SET PWD proc self cwd SET PYTHON BIN PATH C Anaconda3 python exe SET PYTHON LIB PATH C Anaconda3 lib site packages SET TEMP C Users user AppData Local Temp SET TF CUDA CLANG 0 SET TF CUDA COMPUTE CAPABILITIES 6 1 SET TF CUDA VERSION 8 0 SET TF CUDNN VERSION 6 SET TF NEED CUDA 1 SET TF NEED OPENCL 0 SET TMP C Users user AppData Local Temp C Program Files x86 Microsoft Visual Studio 14 0 VC bin amd64 cl exe DCOMPILER MSVC DNOMINMAX D WIN32 WINNT 0x0600 D CRT SECURE NO DEPRECATE D CRT SECURE NO WARNINGS D SILENCE STDEXT HASH DEPRECATION WARNINGS bigobj Zm500 J Gy GF EHsc wd4351 wd4291 wd4250 wd4996 nologo I Ibazel out msvc x64 py3 opt genfiles Iexternal bazel tools Ibazel out msvc x64 py3 opt genfiles external bazel tools Iexternal eigen archive Ibazel out msvc x64 py3 opt genfiles external eigen archive Iexternal local config sycl Ibazel out msvc x64 py3 opt genfiles external local config sycl Iexternal protobuf Ibazel out msvc x64 py3 opt genfiles external protobuf Iexternal gif archive Ibazel out msvc x64 py3 opt genfiles external gif archive Iexternal jpeg Ibazel out msvc x64 py3 opt genfiles external jpeg Iexternal com googlesource code re2 Ibazel out msvc x64 py3 opt genfiles external com googlesource code re2 Iexternal farmhash archive Ibazel out msvc x64 py3 opt genfiles external farmhash archive Iexternal fft2d Ibazel out msvc x64 py3 opt genfiles external fft2d Iexternal highwayhash Ibazel out msvc x64 py3 opt genfiles external highwayhash Iexternal png archive Ibazel out msvc x64 py3 opt genfiles external png archive Iexternal zlib archive Ibazel out msvc x64 py3 opt genfiles external zlib archive Iexternal snappy Ibazel out msvc x64 py3 opt genfiles external snappy Iexternal local config cuda Ibazel out msvc x64 py3 opt genfiles external local config cuda Iexternal bazel tools tools cpp gcc3 Iexternal eigen archive Ibazel out msvc x64 py3 opt genfiles external eigen archive Iexternal protobuf src Ibazel out msvc x64 py3 opt genfiles external protobuf src Iexternal gif archive lib Ibazel out msvc x64 py3 opt genfiles external gif archive lib Iexternal gif archive windows Ibazel out msvc x64 py3 opt genfiles external gif archive windows Iexternal farmhash archive src Ibazel out msvc x64 py3 opt genfiles external farmhash archive src Iexternal png archive Ibazel out msvc x64 py3 opt genfiles external png archive Iexternal zlib archive Ibazel out msvc x64 py3 opt genfiles external zlib archive Iexternal local config cuda cuda Ibazel out msvc x64 py3 opt genfiles external local config cuda cuda Iexternal local config cuda cuda cuda include Ibazel out msvc x64 py3 opt genfiles external local config cuda cuda cuda include showIncludes MT O2 c tensorflow core kernels depthwise conv op gpu cu cc Fobazel out msvc x64 py3 opt bin tensorflow core kernels objs depthwise conv op gpu tensorflow core kernels depthwise conv op gpu cu o x cuda DGOOGLE CUDA 1 nvcc options relaxed constexpr nvcc options ftz true DGOOGLE CUDA 1 msse3 DLANG CXX11 D VERSION MSVC DPLATFORM WINDOWS DTF COMPILE LIBRARY DEIGEN HAS C99 MATH DTENSORFLOW USE EIGEN THREADPOOL DEIGEN AVOID STL ARRAY Iexternal gemmlowp wd4018 U HAS EXCEPTIONS D HAS EXCEPTIONS 1 EHsc tensorflow core util cuda kernel helper h 359 error C3861 'atomicAdd' identifier not found tensorflow core util cuda kernel helper h 360 error C3861 'atomicAdd' identifier not found tensorflow core util cuda kernel helper h 361 error C3861 'atomicAdd' identifier not found tensorflow core util cuda kernel helper h 362 error C3861 'atomicAdd' identifier not found tensorflow core util cuda kernel helper h 365 error C3861 'atomicMax' identifier not found tensorflow core util cuda kernel helper h 366 error C3861 'atomicMax' identifier not found tensorflow core util cuda kernel helper h 378 error C3861 'max' identifier not found tensorflow core util cuda kernel helper h 378 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 394 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 394 error C3861 ' double as longlong' identifier not found tensorflow core util cuda kernel helper h 393 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 399 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 445 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 462 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 498 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 507 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 516 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 527 error C3861 ' int as float' identifier not found tensorflow core util cuda kernel helper h 527 error C3861 ' float as int' identifier not found tensorflow core util cuda kernel helper h 526 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 529 error C3861 ' int as float' identifier not found tensorflow core util cuda kernel helper h 538 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 538 error C3861 ' double as longlong' identifier not found tensorflow core util cuda kernel helper h 537 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 540 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 548 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 557 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 566 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 577 error C3861 ' int as float' identifier not found tensorflow core util cuda kernel helper h 577 error C3861 ' float as int' identifier not found tensorflow core util cuda kernel helper h 576 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 579 error C3861 ' int as float' identifier not found tensorflow core util cuda kernel helper h 588 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 588 error C3861 ' double as longlong' identifier not found tensorflow core util cuda kernel helper h 587 error C3861 'atomicCAS' identifier not found tensorflow core util cuda kernel helper h 590 error C3861 ' longlong as double' identifier not found tensorflow core util cuda kernel helper h 617 error C2065 'warpSize' undeclared identifier tensorflow core util cuda kernel helper h 619 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 620 error C3861 ' shfl' identifier not found tensorflow core util cuda kernel helper h 621 error C3861 ' shfl' identifier not found tensorflow core util cuda kernel helper h 622 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 637 error C2065 'warpSize' undeclared identifier tensorflow core util cuda kernel helper h 639 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 640 error C3861 ' shfl up' identifier not found tensorflow core util cuda kernel helper h 641 error C3861 ' shfl up' identifier not found tensorflow core util cuda kernel helper h 642 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 657 error C2065 'warpSize' undeclared identifier tensorflow core util cuda kernel helper h 659 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 660 error C3861 ' shfl down' identifier not found tensorflow core util cuda kernel helper h 661 error C3861 ' shfl down' identifier not found tensorflow core util cuda kernel helper h 662 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 677 error C2065 'warpSize' undeclared identifier tensorflow core util cuda kernel helper h 679 error C2059 syntax error 'volatile' tensorflow core util cuda kernel helper h 680 error C3861 ' shfl xor' identifier not found tensorflow core util cuda kernel helper h 681 error C3861 ' shfl xor' identifier not found tensorflow core util cuda kernel helper h 682 error C2059 syntax error 'volatile' tensorflow core kernels depthwise conv op gpu cu cc 70 error C2182 ' launch bounds ' illegal use of type 'void' tensorflow core kernels depthwise conv op gpu cu cc 71 error C2061 syntax error identifier 'DepthwiseConv2dGPUKernelNHWC' tensorflow core kernels depthwise conv op gpu cu cc 161 error C2143 syntax error missing ' ' before ' ' tensorflow core kernels depthwise conv op gpu cu cc 161 error C2447 ' ' missing function header old style formal list tensorflow core kernels depthwise conv op gpu cu cc 295 error C2182 ' launch bounds ' illegal use of type 'void' tensorflow core kernels depthwise conv op gpu cu cc 295 error C2374 'tensorflow launch bounds ' redefinition multiple initialization tensorflow core kernels depthwise conv op gpu cu cc 70 note see declaration of 'tensorflow launch bounds ' tensorflow core kernels depthwise conv op gpu cu cc 296 error C2061 syntax error identifier 'DepthwiseConv2dGPUKernelNCHW' tensorflow core kernels depthwise conv op gpu cu cc 431 error C2143 syntax error missing ' ' before ' ' tensorflow core kernels depthwise conv op gpu cu cc 431 error C2447 ' ' missing function header old style formal list tensorflow core kernels depthwise conv op gpu cu cc 759 warning C4068 unknown pragma tensorflow core kernels depthwise conv op gpu cu cc 711 error C2182 ' launch bounds ' illegal use of type 'void' tensorflow core kernels depthwise conv op gpu cu cc 711 error C2374 'tensorflow launch bounds ' redefinition multiple initialization tensorflow core kernels depthwise conv op gpu cu cc 70 note see declaration of 'tensorflow launch bounds ' tensorflow core kernels depthwise conv op gpu cu cc 712 error C2061 syntax error identifier 'DepthwiseConv2dBackpropInputGPUKernelNHWC' tensorflow core kernels depthwise conv op gpu cu cc 779 error C2143 syntax error missing ' ' before ' ' tensorflow core kernels depthwise conv op gpu cu cc 779 error C2447 ' ' missing function header old style formal list tensorflow core kernels depthwise conv op gpu cu cc 916 error C2182 ' launch bounds ' illegal use of type 'void' tensorflow core kernels depthwise conv op gpu cu cc 916 error C2374 'tensorflow launch bounds ' redefinition multiple initialization tensorflow core kernels depthwise conv op gpu cu cc 70 note see declaration of 'tensorflow launch bounds ' tensorflow core kernels depthwise conv op gpu cu cc 917 error C2061 syntax error identifier 'DepthwiseConv2dBackpropFilterGPUKernelNHWC' tensorflow core kernels depthwise conv op gpu cu cc 1024 error C2143 syntax error missing ' ' before ' ' tensorflow core kernels depthwise conv op gpu cu cc 1024 error C2447 ' ' missing function header old style formal list tensorflow core kernels depthwise conv op gpu cu cc 1170 error C2182 ' launch bounds ' illegal use of type 'void' tensorflow core kernels depthwise conv op gpu cu cc 1170 error C2374 'tensorflow launch bounds ' redefinition multiple initialization tensorflow core kernels depthwise conv op gpu cu cc 70 note see declaration of 'tensorflow launch bounds ' tensorflow core kernels depthwise conv op gpu cu cc 1171 error C2061 syntax error identifier 'DepthwiseConv2dBackpropFilterGPUKernelNCHW' tensorflow core kernels depthwise conv op gpu cu cc 1284 error C2143 syntax error missing ' ' before ' ' tensorflow core kernels depthwise conv op gpu cu cc 1284 error C2447 ' ' missing function header old style formal list cl Command line warning D9002 ignoring unknown option ' x' cl Command line warning D9002 ignoring unknown option ' nvcc options relaxed constexpr' cl Command line warning D9002 ignoring unknown option ' nvcc options ftz true' cl Command line warning D9002 ignoring unknown option ' msse3' cl Command line warning D9024 unrecognized source file type 'cuda' object file assumed cl Command line warning D9027 source file 'cuda' ignored Target tensorflow tools quantization quantize graph failed to build Elapsed time 8 033s Critical Path 4 14s,,"gunan,meteorcloudy,snnn",2017-08-31 09:45:16,2017-12-19 11:06:12
IS,sparse multiclass hinge loss error,Hello I'm getting the error below using sparse multiclass hinge loss Any hints would be highly appreciated make tensor proto values dtype shape verify shape 369 else 370 if values is None 371 raise ValueError None values not supported 372 if dtype is provided forces numpy array to be the type 373 provided if possible ValueError None values not supported,,,2017-12-16 12:10:12,2017-12-19 11:53:22
IS,What is the best practice for running training and evaluation on the same machine,I ask the question at stackoverflow No answer so far maybe I can find people have similar needs Here is the question What I want to do 1 I only have 1 machine 2 I want to evaluate the mode periodically What I have now 1 use a placeholder Say I run 1000 step of training by feeding the training data then I feed in validation dataset for evaluation put it in a loop But as google suggested placeholder is not a good way for long run training 2 So I use slim dataset to feed in data Now the model is bonded with training dataset like this net slim conv2d inputs 64 11 11 4 padding 'VALID' scope 'conv1' I have to construct another model in another graph which is bonded with validation dataset Is there a better way of doing that I know that google is focusing on distribution training on large scale but I think as tensorflow is a low level and flexible framwork There must be a way can do what I want,,mrry,2017-12-19 15:00:54,2017-12-19 17:40:18
PR,Use Eigen version of the scalar fmod op for fmod ops,It seems that scalar fmod op is supported in Eigen so this fix changes scalar fmod2 op to use Eigen version of the scalar fmod op Signed off by Yong Tang yong tang github outlook com,,yongtang,2017-12-18 19:21:28,2017-12-19 18:01:41
PR,fix typos,fix typos,,ManHyuk,2017-12-19 10:33:38,2017-12-19 18:09:35
IS,error,I get error when I make placeholder,,shivaniag,2017-09-19 14:13:35,2017-12-19 19:05:26
IS,TensorFlow binary was not compiled to use AVX AVX2 from Java 1 8,image image System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform from Windows 10 TensorFlow installed from source or binary TensorFlow version 1 4 0 Java version 1 8 0 144 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory GTX 1060 6G and Memory 8G Exact command to reproduce javac You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs C Program Files Java jdk1 8 0 144 bin java agentlib jdwp transport dt socket address 127 0 0 1 56173 suspend y server n javaagent C Users Administrator IntelliJIdea2017 3 system captureAgent debugger agent jar C Users Administrator AppData Local Temp capture props Dfile encoding UTF 8 classpath C Program Files Java jdk1 8 0 144 jre lib charsets jar C Program Files Java jdk1 8 0 144 jre lib deploy jar C Program Files Java jdk1 8 0 144 jre lib ext access bridge 64 jar C Program Files Java jdk1 8 0 144 jre lib ext cldrdata jar C Program Files Java jdk1 8 0 144 jre lib ext dnsns jar C Program Files Java jdk1 8 0 144 jre lib ext jaccess jar C Program Files Java jdk1 8 0 144 jre lib ext jfxrt jar C Program Files Java jdk1 8 0 144 jre lib ext localedata jar C Program Files Java jdk1 8 0 144 jre lib ext nashorn jar C Program Files Java jdk1 8 0 144 jre lib ext sunec jar C Program Files Java jdk1 8 0 144 jre lib ext sunjce provider jar C Program Files Java jdk1 8 0 144 jre lib ext sunmscapi jar C Program Files Java jdk1 8 0 144 jre lib ext sunpkcs11 jar C Program Files Java jdk1 8 0 144 jre lib ext zipfs jar C Program Files Java jdk1 8 0 144 jre lib javaws jar C Program Files Java jdk1 8 0 144 jre lib jce jar C Program Files Java jdk1 8 0 144 jre lib jfr jar C Program Files Java jdk1 8 0 144 jre lib jfxswt jar C Program Files Java jdk1 8 0 144 jre lib jsse jar C Program Files Java jdk1 8 0 144 jre lib management agent jar C Program Files Java jdk1 8 0 144 jre lib plugin jar C Program Files Java jdk1 8 0 144 jre lib resources jar C Program Files Java jdk1 8 0 144 jre lib rt jar C gitspase zczdemo target classes E maven Jars org tensorflow tensorflow 1 4 0 tensorflow 1 4 0 jar E maven Jars org tensorflow libtensorflow 1 4 0 libtensorflow 1 4 0 jar E maven Jars org tensorflow libtensorflow jni 1 4 0 libtensorflow jni 1 4 0 jar E maven Jars org projectlombok lombok 1 16 18 lombok 1 16 18 jar C Program Files JetBrains IntelliJ IDEA 2017 3 1 lib idea rt jar com zcz tensorflow zczdemo HelloTF Connected to the target VM address '127 0 0 1 56173' transport isocket' Hello from 1 4 0 Disconnected from the target VM address '127 0 0 1 56173' transport isocket',,"snnn,snnn",2017-12-18 14:59:54,2017-12-19 20:51:40
IS,tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 and 14 04and windows TensorFlow installed from source or binary Anaconda TensorFlow version use command below 1 30 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version CUDA 8 0 GPU model and memory GeForce GTX TITAN Exact command to reproduce python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 669140 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 803520 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 803612 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 804101 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 804146 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 804578 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 804622 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 921353 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 921412 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 921736 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 921769 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 18 922064 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 18 922096 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 056649 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 056716 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 057046 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 057079 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 057369 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 057399 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 192128 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 192198 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 192519 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 192551 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 192829 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 192858 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 581540 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 581599 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 581928 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 581961 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 582241 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 582271 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 712218 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 712290 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 712602 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 712634 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 19 712909 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 19 712937 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 20 109602 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 109676 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 110017 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 110051 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 110337 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 110368 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 258401 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 258473 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 258812 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 258845 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 259145 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 259175 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast x 2017 12 18 14 27 20 409659 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 409726 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 20 410061 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 410096 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x 2017 12 18 14 27 20 410375 W tensorflow core framework op kernel cc 1182 Unimplemented Cast float to string is not supported 2017 12 18 14 27 20 410406 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Unimplemented Cast float to string is not supported Node Cast 6 Cast DstT DT STRING SrcT DT FLOAT device job localhost replica 0 task 0 cpu 0 Cast 6 x Source code logs import os import numpy as np import tensorflow as tf import matplotlib pyplot as plt import random img weight 224 img hight 224 VOC NUM CLASS 15 img channels 3 def getfile datapath labelpath class train label train for root dirs files in os walk datapath for pic in files class train append os path join root pic with open labelpath as filee i 0 for l in filee readlines if i 0 t for j in l split ' ' t append j strip ' n' label train append t 0 15 else i 1 temp for i in label train array1 np array i dtype int tostring temp append array1 label train temp return class train label train def get batch image label image W image H batch size capacity ''' Args image list type label list type image W image width image H image height batch size batch size capacity the maximum elements in queue Returns image batch 4D tensor batch size width height 3 dtype tf float32 label batch 1D tensor batch size dtype tf int32 ''' image tf cast image tf string label tf cast label tf string make an input queue input queue tf train slice input producer image label shuffle True label input queue 1 image contents tf read file input queue 0 image tf image decode png image contents channels 3 image tf image flip left right image image set shape image H image W 3 image tf image per image standardization image label tf decode raw label tf int64 float32 label tf cast label tf float32 label tf reshape label VOC NUM CLASS image batch label batch tf train batch image label batch size batch size num threads 64 capacity capacity image batch tf cast image batch tf float32 return image batch label batch def shulffedata image label a int i for i in range len image random shuffle a temp image temp label for i in a temp image append image i temp label append label i image temp image label temp label return image label def dataprovider train dir ' media thomas images ' train dircsv ' media thomas cxr8 Binarylabels csv' save dir ' home thomas Densenet vision networks master chexray ' BATCH SIZE 1 name test wouldatatest' images labels getfile train dir train dircsv images labels shulffedata images labels train images images int len images 0 8 train label labels int len images 0 8 test images images int len images 0 8 test label labels int len images 0 8 train image batch train label batch get batch train images train label img weight img hight BATCH SIZE 2000 test image batch test label batch get batch test images test label img weight img hight BATCH SIZE 2000 with tf Session as sess i 0 coord tf train Coordinator threads tf train start queue runners sess sess coord coord when exeute this sentence it report error try while not coord should stop and i 1 image label sess run test image batch test label batch image label sess run train image batch train label batch image label sess run image batch label batch for j in np arange BATCH SIZE print label print label j plt imshow image j plt show i 1 except tf errors OutOfRangeError print done finally coord request stop coord join threads,,"facaiy,facaiy",2017-12-19 07:05:31,2017-12-19 20:54:49
PR,Branch 179578952,Push,,"ekelsen,ekelsen,yifeif,yifeif",2017-12-19 19:28:03,2017-12-19 21:55:15
PR,Updating MKL to the latest release,,,"gunan,yifeif,yifeif,yifeif",2017-12-19 00:17:48,2017-12-19 22:00:06
PR,Fix minor typo in CUDNN VERSION check,Effectively enables CUDNN CONVOLUTION BWD FILTER ALGO WINOGRAD NONFUSED in CudnnSupport GetConvolveBackwardFilterAlgorithms for cuDNN v5 1,,"nluehr,gunan,yifeif",2017-12-11 23:10:06,2017-12-19 22:00:32
PR,FreeBSD compatibility,After 1 2 0 tensorflow broke on FreeBSD provided changes makes it build again Also when nsync has merged this PR The nsync dependency needs to be bumped,,"blodan,gunan,gunan,blodan,blodan,gunan,gunan,gunan,blodan,blodan,blodan,gunan,yifeif",2017-11-28 14:37:02,2017-12-19 22:00:49
PR,Fix broken image link in TensorFlow Lite is docs,I fixed the link of image in the same way as other documents in tensorflow tensorflow docs src,,yifeif,2017-12-14 10:51:25,2017-12-19 22:01:54
PR,Removing extra d after close method in SessionTest java,,,"rajendraarora16,asimshankar,rajendraarora16,rajendraarora16,rajendraarora16,rajendraarora16,yifeif",2017-12-12 07:57:21,2017-12-19 22:03:18
PR,Add common error documentation,See,,yifeif,2017-12-17 01:12:28,2017-12-19 22:14:23
PR,fix Pooling1D data format bug,When data format is channels last input is NWC so we have to expand dim 1 to make it become NHWC Then we apply pooling on W which is the 3rd dimention When data format is channels first input is NCW so we have to expand dim 2 to make it become NCHW Then we apply pooling on W which is the 4th dimention,,yifeif,2017-12-19 17:48:08,2017-12-19 22:33:58
PR,Fixed memory stats ops test,Added explicit dependency to avoid matrix free prior to stats op execution,,"nluehr,yifeif",2017-12-11 21:04:22,2017-12-19 22:36:24
PR,Update math ops py,Corrected documentation of tf reduce mean,,"AndreiCostinescu,yifeif",2017-12-18 17:11:05,2017-12-19 22:37:34
PR,update create train op to use get global step,Fixes this warning,,"cancan101,ispirmustafa,yifeif",2017-11-08 03:05:56,2017-12-19 23:20:56
IS,Feature request add tf decode libsvm op,Hi since libsvm format is used widespreadly to store sparse data and is supported by many main stream frameworks spark LibSVMDataSource sklearn load svmlight file xgboost LibSVM format Could tensorflow support to parse libsvm format like tf decode csv,,"facaiy,yongtang,angersson,facaiy",2017-11-07 07:49:12,2017-12-19 23:21:30
PR,Add decode libsvm for libsvm format support,This fix is an effort to add libsvm format support with the implementation of decode libsvm as was proposed in 14313 The implementation is done in contrib with e g where the input is a string tensor and the output is a tuple of label and feature The label tensor is the same shape as input The feature tensor is of the shape input shape num features This fix fixes 14313 Signed off by Yong Tang yong tang github outlook com,,"yongtang,facaiy,facaiy,facaiy,mrry,mrry,mrry,mrry,mrry,mrry,mrry,facaiy,facaiy,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,mrry,yongtang,snnn,mrry,yongtang,mrry,yongtang,facaiy,yongtang,yongtang,yongtang,mrry,yongtang,yongtang,mrry,yifeif,yongtang,mrry,facaiy",2017-11-07 19:23:05,2017-12-19 23:21:30
PR,Fix a compile error in file block cache test cc,tensorflow core platform cloud file block cache test cc 461 error C3493 'block size' cannot be implicitly captured because no default capture mode has been specified Compiler Visual Studio 2017 v15 4 4,,"snnn,yifeif",2017-12-19 12:52:38,2017-12-19 23:23:01
IS,Name variable scopes of tensorflow python layers base Layer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem This is a tiny code that creates layers and connects them in series Results Other than case 3 an unexpected graph is generated Is this a bug Case 1 img alt result height 450 src Case 2 img alt result height 450 src Case 3 img alt result height 450 src,,"facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,reedwm,lukaszkaiser,facaiy,lukaszkaiser,facaiy,facaiy,lukaszkaiser,facaiy,facaiy,lukaszkaiser,facaiy,facaiy",2017-10-01 11:34:37,2017-12-19 23:31:50
PR,BUG fix name scope collision in tf layers,Fix 13429 Since 14390 has been merged into master branch we can easily solve the problem with auxiliary name scope False How to test x add test case x pass all tests,,"facaiy,lukaszkaiser,yifeif,facaiy,yifeif",2017-12-19 05:41:42,2017-12-19 23:31:50
IS,feature request decode compressed,It will be great if you could add tf decode compressed to be used in situations that tfrecords cannot be used Currently only tf decode raw can be used in such situations which becomes a big issue with massive amount size of files,,"tatatodd,mrry,mrry,yongtang,yongtang,drpngx,martinwicke",2017-11-26 13:31:12,2017-12-20 00:00:50
PR,Add decode compressed support,This fix tries to address the issue raised in 14887 to add decode compressed support The API will take a string Tensor compressed with either ZLIB or GZIP and output a string Tensor of the same shape with content uncompressed This fix fixes 14887 Signed off by Yong Tang yong tang github outlook com,,"yongtang,asimshankar,yongtang,yongtang,martinwicke,martinwicke,yongtang,yongtang,martinwicke,yongtang,yongtang,martinwicke,yongtang",2017-12-05 15:04:15,2017-12-20 00:00:50
PR,Add missing tf copts calls,To eliminate warnings like libarithmetic optimizer a arithmetic optimizer o warning LNK4049 locally defined symbol DEVICE CPU tensorflow 3QEBDEB char const const tensorflow DEVICE CPU imported This PR depends on 15439 Please merge that first,,"snnn,snnn,jhseu,snnn,snnn,snnn,snnn,snnn",2017-11-14 07:05:17,2017-12-20 00:04:05
IS,BUG Undeclared error in tensorflow contrib memory stats kernels memory stats ops cc,System information Linux Ubuntu 17 10 TensorFlow installed from source TensorFlow version 1 4 1 Python version 3 6 Bazel version 0 8 1 GCC Compiler version 7 2 Describe the problem undeclared error raised in tensorflow contrib memory stats kernels memory stats ops cc when build v1 4 1 with jemalloc OpenCL Source code logs ERROR tensorflow tensorflow contrib memory stats BUILD 17 1 C compilation of rule ' tensorflow contrib memory stats python ops memory stats ops so' failed Exit 1 tensorflow contrib memory stats kernels memory stats ops cc 64 5 error unknown type name ' MaxBytesInUseOp ' did you mean 'BytesInUseOp' MaxBytesInUseOp BytesInUseOp tensorflow core framework op kernel h 1209 68 note expanded from macro 'REGISTER KERNEL BUILDER' REGISTER KERNEL BUILDER UNIQ HELPER COUNTER kernel builder VA ARGS tensorflow core framework op kernel h 1212 53 note expanded from macro 'REGISTER KERNEL BUILDER UNIQ HELPER' REGISTER KERNEL BUILDER UNIQ ctr kernel builder VA ARGS tensorflow core framework op kernel h 1225 24 note expanded from macro 'REGISTER KERNEL BUILDER UNIQ' return new VA ARGS context tensorflow contrib memory stats kernels memory stats ops cc 44 7 note 'BytesInUseOp' declared here class BytesInUseOp public MemoryStatsOp 1 error generated,,qmick,2017-12-19 10:34:05,2017-12-20 00:05:50
PR,Fix issue building memory stats with opencl,This PR fixes 15477 This bug exists in at least 1 4 1 5 and master branch should I send PR for every branch,,"qmick,yifeif",2017-12-19 11:51:55,2017-12-20 00:05:50
PR,Revert changes in TrainingHelper that cause no gradient error,Change occured in Discussed in,,"yifeif,yifeif,Androbin,Androbin",2017-12-19 09:32:21,2017-12-20 00:07:46
PR,Change NHWC NCHW to NWC NCW for conv1d,While working on 13105 I noticed that in the current code base conv1d uses NHWC NCHW which should really be NWC NCW This fix addresses this issue and keep NHWC NCHW compatible internally so that users will not be impacted Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,yongtang,jhseu,yongtang,martinwicke,asimshankar,yongtang,martinwicke",2017-11-08 16:47:43,2017-12-20 00:35:51
PR,R1 4,,,yifeif,2017-11-26 23:41:45,2017-12-20 00:39:16
PR,Add compression support for TextLineReader,This fix tries to address the issue raised in 14593 where it was not possible to process compressed TextLineReader This fix add compression support for TextLineReader similar to TFRecordReader Additional tests have been added This fix fixes 14593 Signed off by Yong Tang yong tang github outlook com,,"yongtang,martinwicke,asimshankar,yongtang,yifeif,yongtang",2017-11-16 00:14:46,2017-12-20 00:41:33
IS,no protobuf package for macos Python 3 6,Following instructions on pip install upgrade This does not work for Python 3 6 with error protobuf 3 1 0 cp35 none macosx 10 11 x86 64 whl is not a supported wheel on this platform If I just change URL cp36 there is no such file,,"yaroslavvb,gunan,jhseu,yaroslavvb,jhseu,jhseu",2017-12-16 20:33:16,2017-12-20 00:50:18
PR,Unstack int64 tensors on GPU,Registered unstack GPU kernel op for int64 tensors Extended tests to check unstack op on different types of tensors for CPU and GPU,,"dantkz,frankchn,dantkz,yifeif",2017-10-05 13:56:00,2017-12-20 00:52:34
IS,C API Functions Support,Hi I was wondering what the status is for supporting the creation of functions in the C API Could not this be done in a similar manner to how while loops are currently constructed Thanks Anthony P S This could also be useful for defining gradient functions for ops not supported by the C API gradients,,"eaplatanios,skye,skye,iganichev,eaplatanios,iganichev,eaplatanios,iganichev,eaplatanios,eaplatanios,eaplatanios,iganichev,eaplatanios,iganichev,eaplatanios,eaplatanios,eaplatanios,iganichev",2017-08-08 20:49:42,2017-12-20 01:21:16
IS,Problem about tf data Dataset from sparse tensor slices,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 3 52 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 46 GPU model and memory 2GB Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I used the tf data Dataset from sparse tensor slices to built a dataset But the website has no enought information Here is my code point cloud feature dataset tf data Dataset from sparse tensor slices sparse feature point cloud feature dataset point cloud feature dataset shuffle buffer size 100000 point cloud feature dataset point cloud feature dataset batch batch size BATCH SIZE point cloud feature dataset point cloud feature dataset repeat iterator feature point cloud feature dataset make one shot iterator when I called the iterator feature get nest It return 3 Tensors of shape none none 1 Instead of a SparseTensor The input Sparse Tensor of dataset has a shape of 1000000 300000 Each row is a example I hope talents can replenish the Doc Thanks Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"drpngx,mrry,mrry,mrry,mrry,av8ramit,av8ramit",2017-12-11 02:12:45,2017-12-20 01:21:28
IS,Cannot assign a device for operation isave ShardedFilename 1' when exporting custom Estimator,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux ubuntu254 4 2 0 42 generic 49 14 04 1 Ubuntu SMP Wed Jun 29 20 22 11 UTC 2016 x86 64 x86 64 x86 64 GNU Linux TensorFlow installed from source or binary pip TensorFlow version use command below tf VERSION 1 3 0 Python version 2 7 6 Bazel version if compiling from source CUDA cuDNN version release 8 0 V8 0 44 6 0 GPU model and memory GTX Titan Black 6 GB GTX 1060 6 GB Exact command to reproduce run estimator CNN py Describe the problem Continued from this discussion searchin discuss export discuss XHABHQG5l2I jZBvc0 NBgAJ I want to export a custom Estimator multiple CNN layer CTC loss in multi GPU setting derived from cifar 10 multi GPU example using export savemodel But i encountered this error InvalidArgumentError see above for traceback Cannot assign a device for operation isave ShardedFilename 1' Could not satisfy explicit device specification ' device GPU 0' because no supported kernel for GPU devices is available this should not occured in 1 3 0 please see discussion Source code logs environment tf env txt full error trace error txt source code TF bug zip,,"martinwicke,isaprykin,isaprykin,martinwicke,martinwicke,nfiedel,nfiedel",2017-09-27 07:30:22,2017-12-20 01:23:13
IS,tf device is allocating all available GPU memory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 1 LTS TensorFlow installed from source or binary source git repo TensorFlow version use command below 'unknown' '1 3 0 rc2' using commit 3686ef0d51047d2806df3e2ff6c1aac727456c1d Python version Python 2 7 12 default Nov 19 2016 06 48 10 Bazel version if compiling from source Build label 0 5 1 Build target bazel out local fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Tue Jun 6 10 34 11 2017 1496745251 Build timestamp 1496745251 Build timestamp as int 1496745251 CUDA cuDNN version CUDA 8 0 cuDNN 5 0 5 GPU model and memory GTX 1080 Ti 11172MiB Exact command to reproduce At this point tensorflow is allocating all of the available GPU memory This can be checked using nvidia smi Expected behavior is nothing is done with GPU I have used tensorflow 1 2 1 which will allocate nothing on GPU until a tf Session is created tf Session also allows setting config gpu options per process gpu memory fraction to limit the usage of GPU memory,,"mrry,mrry",2017-08-16 10:23:26,2017-12-20 01:32:02
IS,Feature Any plan to add Dynamic Graph support in TF,We know that TF follows the define and run paradigm while some other DL frameworks support define by run paradigm such as pyTorch and Chainer define and run actually reduce the mind set overhead for DL modeling guys due to that it can help reduce the try and feedback loop MxNet another originally define and run DL framework already adds support for dynamic graph through Gluon As far as I know there are TensorFlow Fold project which provides dynamic batching support but it does not provides the define by run support Is there any plan for TFer to add the dynamic graph support in the near future If not my team is going to work on this stuff before jumping in I just want to make sure our energies are invested on unique features rather than duplicated ones Thanks,,"carlthome,skye,asimshankar,asimshankar",2017-08-16 09:17:10,2017-12-20 01:39:03
IS,TextLineReader is missing compression option see TFRecordReader,tf TextLineReader does not currently provide a way to read GZIP encoded files This option exists in TFRecordReader Which would seem to require implementing compression here,,"yongtang,yongtang",2017-11-15 18:33:39,2017-12-20 01:40:01
IS,GPU Allocation and Results Unexpected for Simple Test codes,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory two of Nvidia Quadro M4000 Exact command to reproduce Describe the problem I have two Nvidia Quadro M4000 GPUs each has a 8G Memory My regular memory has 64G space I tested a simple GPU memory allocation for tensorflow and found that the allocation seems larger than the GPU memory My test codes are as below GPU MEMORY BYTES 8 2 30 Assuming your GPU has 8GB of memory adjust accordingly Number of float32 elements 4 bytes that consume 7 8 of GPU memory NUM ELEMS int 7 GPU MEMORY BYTES 8 4 def Test1 with tf device gpu 0 t tf ones 2 NUM ELEMS s tf reduce sum t config tf ConfigProto gpu options tf GPUOptions visible device list '0' allow soft placement False with tf Session config config as sess print sess run s This should fail since it consumes more memory than exists in the GPU def Test2 with tf device gpu 0 t0 tf ones NUM ELEMS Tensor that consumes 80 of GPU0 is memory s0 tf reduce sum t0 with tf device gpu 1 t1 tf ones NUM ELEMS Tensor that consumes 80 of GPU1 is memory s1 tf reduce sum t1 s tf add s0 s1 config tf ConfigProto gpu options tf GPUOptions visible device list '0 1' allow soft placement False with tf Session config config as sess print sess run s I expect the Test2 should work well but Test1 should fail as one GPU only has 8G memory However both test functions succeeded but the results are incorrect NUM ELEMS is about 1 879 e 9 and I expected that it should be half of the output of Test2 Test1 should fail However I got Test1 is output as 1 07374e 09 and Test2 is output as 2 14748e 09 It seems that Both Test1 and Test2 clip the number of elements to 2 30 As NUM ELEMS is int32 even clipping should be clipped to 2 31 but not 2 30 In Test1 if I change the first dimension in tf ones 2 NUM ELEMS from 2 to 15 the outputs are always 1 07374e 09 if the first dimension is no less than 16 it starts to crash showing out of GPU memory My questions are 1 Why the GPU allocation did not crash for larger than 8G for single GPU 2 Why the output results are clipped to 2 30 for single GPU and 2 31 for two GPUs 3 How could I get the correct outputs,,"reedwm,ekelsen,reedwm,reedwm,reedwm,reedwm,reedwm,reedwm",2017-10-09 17:17:45,2017-12-20 01:41:21
IS,tensorflow lite error when convert frozen model to lite format,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 4 8 4 2ubuntu1 14 04 3 4 8 4 CUDA cuDNN version cuda8 0 cudnn6 0 I tried to convert squeezenet frozen model to lite format with the following command bazel run config opt tensorflow contrib lite toco toco input file home xxx caffe tensorflow npy2ckpt squeezenet frozen model pb input format TENSORFLOW GRAPHDEF output format TFLITE output file home xxx caffe tensorflow npy2ckpt squeezenet squeezenet lite inference type FLOAT input type FLOAT input arrays input output arrays prob input shapes 1 227 227 3 the output is shown below 2017 11 21 18 35 29 977505 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 170 operators 231 arrays 0 quantized 2017 11 21 18 35 29 981856 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 40 operators 93 arrays 0 quantized 2017 11 21 18 35 29 982061 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before dequantization graph transformations 40 operators 93 arrays 0 quantized 2017 11 21 18 35 29 982201 I tensorflow contrib lite toco allocate transient arrays cc 312 Total transient array allocated size 4071680 bytes theoretical optimal value 4071680 bytes 2017 11 21 18 35 29 982317 I tensorflow contrib lite toco toco tooling cc 255 Estimated count of arithmetic ops 0 781679 billion note that a multiply add is counted as 2 ops 2017 11 21 18 35 29 982482 F tensorflow contrib lite toco tflite export cc 192 Unsupported operator Squeeze Then I tried to convert mobilenet v1 1 0 224 pb to lite format the same error as above bazel run config opt tensorflow contrib lite toco toco input file home xxx Downloads freeze mobilenet MobileNet img224 mobilenet v1 1 0 224 pb input format TENSORFLOW GRAPHDEF output format TFLITE output file home xxx Downloads freeze mobilenet MobileNet img224 mobilenet lite inference type FLOAT input type FLOAT input arrays input output arrays output input shapes 1 224 224 3 output 2017 11 21 22 07 39 747095 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 418 operators 584 arrays 0 quantized 2017 11 21 22 07 39 766175 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 31 operators 88 arrays 0 quantized 2017 11 21 22 07 39 766390 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before dequantization graph transformations 31 operators 88 arrays 0 quantized 2017 11 21 22 07 39 766592 I tensorflow contrib lite toco allocate transient arrays cc 312 Total transient array allocated size 6422528 bytes theoretical optimal value 4816896 bytes 2017 11 21 22 07 39 766751 I tensorflow contrib lite toco toco tooling cc 255 Estimated count of arithmetic ops 1 14264 billion note that a multiply add is counted as 2 ops 2017 11 21 22 07 39 766952 F tensorflow contrib lite toco tflite export cc 192 Unsupported operator Squeeze Although I installed tensorflow with pip install tensorflow gpu in order to convert model to lite format I git clone the tensorflow files and configure bazel to compile the files I do not know whether this affect the converting of models but the error is really strange,,"miaout17,gargn,aselle",2017-11-21 14:41:33,2017-12-20 01:41:25
IS,labels produced by Dataset API can not be well operated when use tf reduce sum or tf split on labels it returnss the wrong result,my system cuda 8 0 tensorflow gpu 1 3 0 tensorflow tensorboard 0 1 7 python 2 7 ubuntu 14 04 description I use Dataset and Estimator to train my model When I test the return value of Dataset the return value images and labels of input fn is right But when I use tf reduce sum or tf split to the labels all results got wrong I can not undenstand what had happend key code def dataset parser value is training return signal imagel and label def input fn is training num epochs 1 return batch imagel and label FLAGS batch size 5 sess tf InteractiveSession images labels input fn True 1 sess run labels the labels of one batch array 0 1 2 75984216 5 86036015 1 0 3 82080388 4 23745823 1 0 7 59959507 4 93859673 0 1 3 29546738 5 50357151 0 1 2 0612247 6 73015881 dtype float32 label weight score tf split value labels num or size splits 2 1 1 axis 1 i 1 print labels print sess run label i print sess run weight i print sess run score i we expected to get the split value of 1 0 3 82080388 4 23745823 but the result is following Tensor IteratorGetNext 1 shape 4 dtype float32 0 1 2 85865355 5 57142878 a tf reduce sum labels 0 print sess run a we expected to get the values of 2 3 19 53693319 27 27014543 but we get the following result 4 1 25 82047653 24 87050629 code detail,,"mrry,mrry",2017-11-17 08:25:38,2017-12-20 02:04:23
PR,Add LICENSES to gitignore for iOS example,Update gitignore file for ios to cover the license files that get installed following the install instructions,,yifeif,2017-11-16 23:07:19,2017-12-20 02:16:29
PR,XLA FIX XLA tfcompile on OSX if Guard AVX SSE and NEON instructions,This fixes XLA tfcompile on OSX On OSX you currently run into linker errors because unsupported instructions are registered Add ifdefs to register only the supported instructions Also include PR 14137 changes for missing sincos sincosf in XLA on macOS since it was closed without a merge TEST Build tensorflow compiler aot tests tfcompile builds successfully on OSX 10 13 2,,"powderluv,sanjoy,sanjoy,powderluv,powderluv,powderluv,sanjoy,sanjoy,sanjoy,sanjoy,powderluv,powderluv,sanjoy,powderluv,sanjoy,powderluv,powderluv,hawkinsp,powderluv,powderluv,hawkinsp,hawkinsp,powderluv,rongjiecomputer,yifeif",2017-11-27 00:06:18,2017-12-20 02:17:23
IS,Tensorflow stops training on random epoch,When I run the following code on GPU it trains well for some epoches and then just hangs While hanged processes are still alive but the GPU usages become 0 In the below code I am using Dataset API from tf contrib data Dataset But I also tried using placeholder and feed dictionary approach which hangs as well on random epoch during training I am struggling with the problem for last 2 3 weeks and cannot find a way out I am running the code on a remote GPU cluster Here are some information about cluster node Using tensorflow gpu version 1 4 Here are some screen shot of different hangs Hanged on an epoch hanged epc GPU usage that time hanged GPU usage while running not hanged running gpuusage Hanged on another eopch hanged2 This type of random hanging behavior keeps repeating on each run Each time it hangs on a random epoch That is why I cannot figure out what is going wrong By looking at code or other set up can anybody please give me any idea about what is going wrong or how can I debug this out Thanks,,"drpngx,drpngx",2017-11-11 10:56:32,2017-12-20 02:27:48
IS,gpu 0 stream not showing up on timeline,I am generating timeline with TensorFlow r1 3 I can only see job localhost replica 0 task 0 cpu 0 and job localhost replica 0 task 0 gpu 0 But I can not find gpu 0 stream Any idea image My code to regenerate the timeline,,"bowang,reedwm,bowang",2017-08-12 13:12:10,2017-12-20 02:30:42
IS,session t Create Failed using tensorflow exported model on IOS,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 Generating Tensorflow model Ubuntu 16 04 LTS GNU Linux 4 4 0 91 generic x86 64 Load Tensorflow model macOS 10 12 Sierra TensorFlow installed from source or binary TensorFlow is installed from source TensorFlow version use command below TensorFlow version 1 2 0 Python version Python version 3 5 Bazel version if compiling from source Bazel version 0 5 3 CUDA cuDNN version None GPU model and memory NA Exact command to reproduce Describe the problem Error happen when call status session t Create graph error message 2017 08 16 13 22 27 692781 0800 CameraExample 6322 2753781 Error adding graph to session No OpKernel was registered to support Op 'RandomUniform' with these attrs Registered devices CPU Registered kernels no registered kernels Source code logs Export models as pb file In python self saver save self sess self my path to model model ckpt global step i output graph def tf graph util convert variables to constants self sess self sess graph def output node names 'models simple y conv' with tf gfile FastGFile self my path to model 'graph pb' mode 'wb' as f f write output graph def SerializeToString IOS use the following operations to process exported model Call freeze graph synthesize graph pb and CKPT generate frozen pb bazel bin tensorflow python tools freeze graph input graph XXXX graph pb input checkpoint XXXX model ckpt 0 output node names models simple Placeholder models simple y conv input binary output graph XXXX frozen pb Call optimize for inference reduce the operation replace the calculation can not run in the iOS version generate inference pb bazel bin tensorflow python tools optimize for inference input XXXX frozen pb output XXXX inference pb input names models simple Placeholder output names models simple y conv frozen graph True Call quantize graph to further optimize the graph generate rounded graph pb bazel bin tensorflow tools quantization quantize graph input XXXX inference pb output XXXX rounded graph pb output node names models simple y conv mode weights rounded Then execute the following code BOOL loadGraphFromPath executed successfully but error raised at status session t Create graph BOOL loadGraphFromPath NSString path auto status ReadBinaryProto tensorflow Env Default path fileSystemRepresentation graph if status ok NSLog Error reading graph s status error message c str return NO This prints out the names of the nodes in the graph auto nodeCount graph node size NSLog Node count d nodeCount for auto i 0 i nodeCount i auto node graph node i NSLog Node d s ' s' i node op c str node name c str return YES create tf session BOOL createSession tensorflow SessionOptions options auto status tensorflow NewSession options session t if status ok NSLog Error creating session s status error message c str return NO status session t Create graph if status ok error NSLog Error adding graph to session s status error message c str return NO return YES error message 2017 08 16 13 22 27 692781 0800 CameraExample 6322 2753781 Error adding graph to session No OpKernel was registered to support Op 'RandomUniform' with these attrs Registered devices CPU Registered kernels no registered kernels Node dropout random uniform RandomUniform RandomUniform T DT INT32 dtype DT FLOAT seed 87654321 seed2 24 dropout Shape It seems that RandomUniform was not supported on iOS but when I called freeze graph those which are not supported on iOS should be deleted What can I do for this problem,,"skye,petewarden",2017-08-16 08:44:15,2017-12-20 02:38:38
IS,Unable to build C example by bazel on windows 10,System information Have I written custom code No OS Platform and Distribution Windows 10 64Bit TensorFlow installed from binary TensorFlow version master Python version 3 6 1 Bazel version if compiling from source 0 5 4 binary in windows powershell,,,2017-09-09 05:09:56,2017-12-20 02:42:09
IS,AttentionWrapperZeroState Input to reshape is a tensor with 32768 values but the requested shape has 65536,I am building an encoder decoder model with attention and BeamSearchDecoder using tensor flow documentation I am getting following error InvalidArgumentError Traceback most recent call last ipython input 160 ac947b28f4dd in module 29 summary length generagte summary length summary length np random randint 5 8 30 text length len text batch size 31 keep prob 1 0 0 32 Remove the padding from the summaries 33 pad vocab to int PAD Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python client session pyc in run self fetches feed dict options run metadata 893 try 894 result self run None fetches feed dict options ptr 895 run metadata ptr 896 if run metadata 897 proto data tf session TF GetBuffer run metadata ptr Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python client session pyc in run self handle fetches feed dict options run metadata 1122 if final fetches or final targets or handle and feed dict tensor 1123 results self do run handle final targets final fetches 1124 feed dict tensor options run metadata 1125 else 1126 results Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python client session pyc in do run self handle target list fetch list feed dict options run metadata 1319 if handle is None 1320 return self do call run fn self session feeds fetches targets 1321 options run metadata 1322 else 1323 return self do call prun fn self session handle feeds fetches Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python client session pyc in do call self fn args 1338 except KeyError 1339 pass 1340 raise type e node def op message 1341 1342 def extend graph self InvalidArgumentError Input to reshape is a tensor with 32768 values but the requested shape has 65536 Node decode 1 Reshape 2 Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 tile batch 2 Reshape 2 decode 1 concat 2 Caused by op u wouldecode 1 Reshape 2' defined at File Users tusharagarwal anaconda2 lib python2 7 runpy py line 174 in run module as main main fname loader pkg name File Users tusharagarwal anaconda2 lib python2 7 runpy py line 72 in run code exec code in run globals File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel main py line 3 in module app launch new instance File Users tusharagarwal anaconda2 lib python2 7 site packages traitlets config application py line 658 in launch instance app start File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel kernelapp py line 474 in start ioloop IOLoop instance start File Users tusharagarwal anaconda2 lib python2 7 site packages zmq eventloop ioloop py line 177 in start super ZMQIOLoop self start File Users tusharagarwal anaconda2 lib python2 7 site packages tornado ioloop py line 887 in start handler func fd obj events File Users tusharagarwal anaconda2 lib python2 7 site packages tornado stack context py line 275 in null wrapper return fn args kwargs File Users tusharagarwal anaconda2 lib python2 7 site packages zmq eventloop zmqstream py line 440 in handle events self handle recv File Users tusharagarwal anaconda2 lib python2 7 site packages zmq eventloop zmqstream py line 472 in handle recv self run callback callback msg File Users tusharagarwal anaconda2 lib python2 7 site packages zmq eventloop zmqstream py line 414 in run callback callback args kwargs File Users tusharagarwal anaconda2 lib python2 7 site packages tornado stack context py line 275 in null wrapper return fn args kwargs File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel kernelbase py line 276 in dispatcher return self dispatch shell stream msg File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel kernelbase py line 228 in dispatch shell handler stream idents msg File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel kernelbase py line 390 in execute request user expressions allow stdin File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel ipkernel py line 196 in do execute res shell run cell code store history store history silent silent File Users tusharagarwal anaconda2 lib python2 7 site packages ipykernel zmqshell py line 501 in run cell return super ZMQInteractiveShell self run cell args kwargs File Users tusharagarwal anaconda2 lib python2 7 site packages IPython core interactiveshell py line 2717 in run cell interactivity interactivity compiler compiler result result File Users tusharagarwal anaconda2 lib python2 7 site packages IPython core interactiveshell py line 2821 in run ast nodes if self run code code result File Users tusharagarwal anaconda2 lib python2 7 site packages IPython core interactiveshell py line 2881 in run code exec code obj self user global ns self user ns File ipython input 160 ac947b28f4dd line 18 in module loader tf train import meta graph checkpoint ' meta' File Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python training saver py line 1698 in import meta graph kwargs File Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python framework meta graph py line 656 in import scoped meta graph producer op list producer op list File Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python framework importer py line 313 in import graph def op def op def File Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File Users tusharagarwal anaconda2 lib python2 7 site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback Input to reshape is a tensor with 32768 values but the requested shape has 65536 Node decode 1 Reshape 2 Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 cpu 0 tile batch 2 Reshape 2 decode 1 concat 2 The error occurs when trying to Make predictions Test the Model Section Training runs fine The error occurs when I set beam size 2 The error shown is for beam size 2 However it runs fine for beam size 1 I am not able to figure out what is going wrong I know the code is long Any help will be highly appreciated as I am unable to debug it and stuck on it for days My code is My code is here Model Inputs def model inputs input data tf placeholder tf int32 None None name 'input' targets tf placeholder tf int32 None None name 'targets' lr tf placeholder tf float32 name 'learning rate' keep prob tf placeholder tf float32 name 'keep prob' summary length tf placeholder tf int32 None name isummary length' max summary length tf reduce max summary length name 'max dec len' text length tf placeholder tf int32 None name 'text length' return input data targets lr keep prob summary length max summary length text length def process encoding input target data vocab to int batch size ending tf strided slice target data 0 0 batch size 1 1 1 slice it to target data 0 batch size 0 1 dec input tf concat tf fill batch size 1 vocab to int ' GO ' ending 1 return dec input Encoding layer def encoding layer rnn size sequence length num layers rnn inputs keep prob for layer in range num layers with tf variable scope 'encoder ' format layer cell fw tf contrib rnn LSTMCell rnn size initializer tf random uniform initializer 0 1 0 1 seed 2 cell fw tf contrib rnn DropoutWrapper cell fw input keep prob keep prob cell bw tf contrib rnn LSTMCell rnn size initializer tf random uniform initializer 0 1 0 1 seed 2 cell bw tf contrib rnn DropoutWrapper cell bw input keep prob keep prob enc output enc state tf nn bidirectional dynamic rnn cell fw cell bw rnn inputs sequence length dtype tf float32 enc output tf concat enc output 2 original code is missing this line below that is how we connect layers by feeding the current layer is output to next layer is input rnn inputs enc output return enc output enc state Training Decoding layer def training decoding layer dec embed input summary length dec cell output layer vocab size max summary length batch size enc state training helper tf contrib seq2seq TrainingHelper inputs dec embed input sequence length summary length time major False training decoder tf contrib seq2seq BasicDecoder cell dec cell helper training helper initial state dec cell zero state dtype tf float32 batch size batch size clone cell state enc state output layer output layer training logits tf contrib seq2seq dynamic decode training decoder impute finished True maximum iterations max summary length return training logits Inference Decoding layer def inference decoding layer embeddings start token end token dec cell output layer max summary length batch size lengths enc state beam width '''Create the inference logits''' start tokens tf ones like lengths start token inference decoder tf contrib seq2seq BeamSearchDecoder cell dec cell embedding embeddings start tokens start tokens end token end token initial state dec cell zero state dtype tf float32 batch size batch size beam width 2 clone cell state enc state beam width beam width output layer output layer inference logits tf contrib seq2seq dynamic decode inference decoder impute finished False maximum iterations max summary length return inference logits def lstm cell lstm size keep prob cell tf contrib rnn BasicLSTMCell lstm size return tf contrib rnn DropoutWrapper cell input keep prob keep prob Decoding layer def decoding layer dec embed input embeddings enc output enc state vocab size text length summary length max summary length rnn size vocab to int keep prob batch size num layers '''Create the decoding cell and attention for the training and inference decoding layers''' output layer Dense vocab size kernel initializer tf truncated normal initializer mean 0 0 stddev 0 1 with tf variable scope decode dec cell tf contrib rnn MultiRNNCell lstm cell rnn size keep prob for in range num layers attn mech tf contrib seq2seq BahdanauAttention rnn size enc output text length normalize False dec cell tf contrib seq2seq AttentionWrapper cell dec cell attention mechanism attn mech attention layer size rnn size training logits training decoding layer dec embed input summary length dec cell output layer vocab size max summary length batch size enc state beam width 2 enc output tf contrib seq2seq tile batch enc output multiplier beam width lengths tf contrib seq2seq tile batch text length multiplier beam width enc state tf contrib seq2seq tile batch enc state multiplier beam width with tf variable scope decode reuse True dec cell tf contrib rnn MultiRNNCell lstm cell rnn size keep prob for in range num layers attn mech tf contrib seq2seq BahdanauAttention rnn size enc output lengths normalize False dec cell tf contrib seq2seq AttentionWrapper cell dec cell attention mechanism attn mech attention layer size rnn size inference logits inference decoding layer embeddings vocab to int ' GO ' vocab to int ' EOS ' dec cell output layer max summary length batch size lengths enc state beam width return training logits inference logits def seq2seq model input data target data keep prob text length summary length max summary length vocab size rnn size num layers vocab to int batch size '''Use the previous functions to create the training and inference logits''' Use Numberbatch is embeddings and the newly created ones as our embeddings embeddings word embedding matrix embeddings s tf get variable word embeddings vocab size 300 embeddings t tf get variable word embeddings2 vocab size 300 enc embed input tf nn embedding lookup embeddings s input data enc output enc state encoding layer rnn size text length num layers enc embed input keep prob dec input process encoding input target data vocab to int batch size shape batch size senquence length each seq start with index of GO dec embed input tf nn embedding lookup embeddings t dec input training logits inference logits decoding layer dec embed input embeddings t enc output enc state vocab size text length summary length max summary length rnn size vocab to int keep prob batch size num layers return training logits inference logits Set the Hyperparameters epochs 100 batch size 64 rnn size 256 num layers 2 learning rate 0 005 keep probability 0 95 Build the graph train graph tf Graph Set the graph to default to ensure that it is ready for training with train graph as default Load the model inputs input data targets lr keep prob summary length max summary length text length model inputs Create the training and inference logits training logits inference logits seq2seq model tf reverse input data 1 targets keep prob text length summary length max summary length len vocab to int 1 rnn size num layers vocab to int batch size Create tensors for the training logits and inference logits training logits tf identity training logits rnn output 'logits' inference logits inference logits predicted ids 0 inference logits tf identity inference logits predicted ids name 'predictions' Create the weights for sequence loss the sould be all True across since each batch is padded masks tf sequence mask summary length max summary length dtype tf float32 name 'masks' with tf name scope optimization Loss function cost tf contrib seq2seq sequence loss training logits targets masks Optimizer optimizer tf train AdamOptimizer learning rate Gradient Clipping gradients optimizer compute gradients cost capped gradients tf clip by value grad 5 5 var for grad var in gradients if grad is not None train op optimizer apply gradients capped gradients print Graph is built graph location graph print graph location train writer tf summary FileWriter graph location train writer add graph train graph Train the Model learning rate decay 0 95 min learning rate 0 0005 display step 20 Check training loss after every 20 batches stop early 0 stop 3 If the update loss does not decrease in 3 consecutive update checks stop training per epoch 3 Make 3 update checks per epoch update check len sorted texts short batch size per epoch 1 update check 2 update loss 0 batch loss 0 summary update loss Record the update losses for saving improvements in the model checkpoint best model ckpt with tf Session graph train graph as sess sess run tf global variables initializer If we want to continue training a previous session loader tf train import meta graph checkpoint ' meta' loader restore sess checkpoint for epoch i in range 1 epochs 1 update loss 0 batch loss 0 for batch i summaries batch texts batch summaries lengths texts lengths in enumerate get batches sorted summaries short sorted texts short batch size start time time time loss sess run train op cost input data texts batch targets summaries batch lr learning rate summary length summaries lengths text length texts lengths keep prob keep probability batch loss loss update loss loss end time time time batch time end time start time if batch i display step 0 and batch i 0 print 'Epoch 3 Batch 4 Loss 6 3f Seconds 4 2f ' format epoch i epochs batch i len sorted texts short batch size batch loss display step batch time display step batch loss 0 if batch i update check 0 and batch i 0 print Average loss for this update round update loss update check 3 summary update loss append update loss If the update loss is at a new minimum save the model if update loss min summary update loss print 'New Record ' stop early 0 saver tf train Saver saver save sess checkpoint else print No Improvement stop early 1 if stop early stop break update loss 0 Reduce learning rate but not below its minimum value learning rate learning rate decay if learning rate min learning rate learning rate min learning rate if stop early stop print Stopping Training break def text to seq text '''Prepare the text for the model''' text clean text text return vocab to int get word vocab to int ' UNK ' for word in text split Test The Model input sentences The coffee tasted great and was at such a good price I highly recommend this to everyone love individual oatmeal cups found years ago sam quit selling sound big lots quit selling found target expensive buy individually trilled get entire case time go anywhere need water microwave spoon know quaker flavor packets generagte summary length 3 2 input sentences test text 0 10 generagte summary length summary l 0 10 texts text to seq input sentence for input sentence in input sentences checkpoint best model ckpt if type generagte summary length is list if len input sentences len generagte summary length raise Exception Error makeSummaries parameter generagte summary length must be same length as input sentences or an integer generagte summary length list generagte summary length else generagte summary length list generagte summary length len texts loaded graph tf Graph with tf Session graph loaded graph as sess Load saved model loader tf train import meta graph checkpoint ' meta' loader restore sess checkpoint input data loaded graph get tensor by name 'input 0' logits loaded graph get tensor by name 'predictions 0' text length loaded graph get tensor by name 'text length 0' summary length loaded graph get tensor by name isummary length 0' keep prob loaded graph get tensor by name 'keep prob 0' Multiply by batch size to match the model is input parameters for i text in enumerate texts generagte summary length generagte summary length list i answer logits sess run logits input data text batch size summary length generagte summary length summary length np random randint 5 8 text length len text batch size keep prob 1 0 0 Remove the padding from the summaries pad vocab to int PAD print ' Review n r ' format input sentences i print ' Summary n r n r n r' format join int to vocab i 0 for i in answer logits if i 0 pad tensorflow,,,2017-12-02 19:01:51,2017-12-20 03:01:52
IS,After quantized ssd mobilenet v1 coco model loaded error on Android,System information OS Platform and Distribution Linux Ubuntu 14 04 5 LTS TensorFlow installed from binary TensorFlow version 1 2 1 Python version 2 7 Bazel version 0 70 GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version 8 0 GPU model and memory Tesla P100 PCIE Exact command to reproduce Describe the problem Load a quantized ssd mobilenet v1 model on Android meet error Caused by java io IOException Not a valid TensorFlow Graph serialization NodeDef mentions attr 'T' not in Op name Where signature input bool index int64 I quantize the ssd mobilenet v1 model o ubuntu 14 using the below command,,tatatodd,2017-11-22 03:19:33,2017-12-20 03:28:02
IS,gradients 1 generated in graph but not connected with AdamOptimizer,System information OS platform Linux Unbuntu 16 04 Tensorflow install from pip install Tensorflow version 1 4 0 Python version py2 7 Problem I want to write a CNN classification network for MNIST dataset And I write a class named MNIST classification then define ' build model ' and ' train phase ' in this class In main function I define a object of MNIST classification class and callback the ' train phase ' to start a training process But I found in Graph there are two gradients generated at each computation node i e gradients and gradients 1 I use tf gradients loss train vars to print all gradients' names and get ' gradients 1 ' but within the Graph gradients 1 are not connected with a AdamOptimizer which leads to no backward propagation update for each trainable variable image Source code import tensorflow as tf from utils import utils import numpy as np class mnist classification object def init self sess graph train param 'num of epoches' 1000 'num of classes' 10 'log dir' ' log' 'model dir' ' model' 'batch size' 128 'learn rate' 1e 4 'max iter' 5000 wouldim feat' 28 self num of epoches train param 'num of epoches' self log dir train param 'log dir' self model dir train param 'model dir' self batch size train param 'batch size' self learn rate train param 'learn rate' self max iter train param 'max iter' self dim feat train param wouldim feat' self num of classes train param 'num of classes' self sess sess self graph graph Build up MNIST classification model assert self sess graph is self graph self build model def convolution block self inp feat kernel size num of kernel channels conv strides conv padding var scope ''' Function convolution block i e convolution Maxpooling ReLU Input 1 tensor inp feat i e input feature dimension batch size height width channel 2 int32 kernel size 3 int32 num of kernel channels 4 int32 conv strides 5 string conv padding 5 string var scope Output tensor activ ''' try num of feat channels inp feat shape 3 value except num of feat channels 1 with tf variable scope var scope weights tf get variable name 'conv weights' shape kernel size kernel size num of feat channels num of kernel channels initializer tf random normal initializer stddev 0 1 biases tf get variable name 'conv biases' shape num of kernel channels initializer tf zeros initializer Convolution layer conv tf nn conv2d inp feat weights strides conv strides padding conv padding name 'conv' data format 'NHWC' biases Activation layer activ tf nn relu conv Pooling layer pool tf nn max pool activ ksize 1 2 2 1 strides 1 2 2 1 padding 'SAME' return pool def fc layer self inp feat num of outputs var scope ''' Function fc layer Input 1 inp feat dimension batch size dim feat 2 num of outputs 3 var scope reuse True Output fc ''' dim feat inp feat shape 1 value with tf variable scope var scope fc weights tf get variable name 'fc weights' dtype tf float32 shape dim feat num of outputs initializer tf random normal initializer stddev 0 1 fc bias tf get variable name 'fc bias' dtype tf float32 shape num of outputs initializer tf zeros initializer tf nn xw plus b x weights bias tf matmul x weights biases fc tf nn xw plus b x inp feat weights fc weights biases fc bias return fc def build model self self digit tf placeholder dtype tf float32 shape self batch size self dim feat self dim feat 1 self label tf placeholder dtype tf int64 shape self batch size self num of classes One hot encoding for label with tf name scope 'label trans' self new label utils array sparse to dense self label self num of classes conv1 self convolution block inp feat self digit conv strides 1 1 1 1 conv padding 'SAME' kernel size 5 num of kernel channels 32 var scope 'conv1' conv2 self convolution block inp feat conv1 conv strides 1 1 1 1 conv padding 'SAME' kernel size 5 num of kernel channels 64 var scope 'conv2' conv3 self convolution block inp feat conv2 conv strides 1 1 1 1 conv padding 'SAME' kernel size 7 num of kernel channels 64 var scope 'conv3' flatt tf layers flatten conv3 name 'flatten' fc1 self fc layer inp feat flatt num of outputs 1024 var scope 'fc1' fc1 tf nn relu fc1 fc2 self fc layer inp feat fc1 num of outputs 10 var scope 'fc2' self predict tf nn softmax logits fc2 dim 1 self loss tf reduce mean tf losses softmax cross entropy onehot labels self label logits fc2 Define MNIST classification accuracy correct tf equal tf argmax self predict 1 tf argmax self label 1 self accuracy tf reduce mean tf cast correct 'float' Define training operations self train op tf train AdamOptimizer self learn rate minimize self loss def train self img file lab file Load data into memory img n rows n cols utils read MNIST file img file fmt ' IIII' lab utils read MNIST file lab file fmt ' II' Intialize the global variables and local variables self sess run tf global variables initializer self sess run tf local variables initializer List all trainable variables train vars tf trainable variables for var in train vars print var name Add gradients into tensorboard summary gradients tf gradients self loss train vars for ii in range len gradients if gradients ii None tf summary histogram train vars ii name gradients ii Add loss into tensorboard summary tf summary scalar 'loss' self loss tf summary scalar 'accuracy' self accuracy tf summary image 'input image' self digit summary writer tf summary FileWriter log self sess graph merged tf summary merge all Start training process for ii epoch in range self num of epoches for ii iter in range self max iter img batch utils randomly sample img self batch size img batch np expand dims img batch axis 3 255 lab batch utils randomly sample lab self batch size lab batch utils array sparse to dense np int64 lab batch num of classes self num of classes pred los acc summary self sess run self train op self predict self loss self accuracy merged feed dict self digit img batch self label lab batch if ii epoch self max iter ii iter 100 0 summary writer add summary summary ii epoch self max iter ii iter print pred 0 print lab batch 0 print ' Loss at No d Epoch No d Iteration 5f' ii epoch ii iter los print ' Accuracy at No d Epoch No d Iteration 5f' ii epoch ii iter acc Main function from utils utils import array sparse to dense from utils utils import read MNIST file from matplotlib import pyplot import numpy as np import tensorflow as tf from model MNIST classification import mnist classification import os import sys Check if tensorflow version '1 4 0' API assert tf version '1 4 0' Set system default encoding method 'utf 8' reload sys sys setdefaultencoding 'utf 8' os environ CUDA DEVICE ORDER PCI BUS ID os environ CUDA VISIBLE DEVICES 1 with tf Graph as default as graph with tf Session as sess MNIST inst mnist classification sess sess graph graph MNIST inst train img file ' data train images idx3 ubyte' lab file ' data train labels idx1 ubyte',,,2017-12-20 03:31:05,2017-12-20 05:17:33
IS,The document of tf nn dynamic rnn needs to be re formatted,Hi Someone take a look at the document page of tf nn dynamic rnn I think there are some formatting bugs in the second half of the web page,,asimshankar,2017-10-08 03:11:15,2017-12-20 05:31:30
IS,Undefined op in speech commands example,I am using tensorflow 1 3 0 built from source I run the newly released speech commands example its in tensorflow examples speech commands following all the stuffs and all good However after I used the freeze py script and generated the pb graph I am unable to load it back The code I used to load pb graph is Error File usr local lib python2 7 dist packages tensorflow python framework importer py line 285 in import graph def raise ValueError 'No op named s in defined operations ' node op ValueError No op named DecodeWav in defined operations,,"jart,jart,jart",2017-08-28 20:33:42,2017-12-20 05:37:12
IS,Feature Request fold batch norm into convolution weights of graph transform tool,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 6 0 GPU model and memory GTX1080 Exact command to reproduce bazel build tensorflow tools graph transforms transform graph bazel bin tensorflow tools graph transforms transform graph in graph tensorflow inception graph pb out graph optimized inception graph pb inputs 'Mul' outputs isoftmax' transforms ' strip unused nodes type float shape 1 299 299 3 remove nodes op Identity op CheckNumerics fold constants ignore errors true fold batch norms fold old batch norms' After diving into the generated pb graph I found that the current fold batch norm ops seems to only fold batch norm into two ops mul and add which is not exactly as the readme demonstrated fold the batch norm into the weights of convolution If this is the case it would be better to further merge the mul and add into conv weights,,carlthome,2017-09-01 02:40:31,2017-12-20 05:38:30
IS,cuDNN on windows will speed up image retraining,If I will do 4 steps from installwindows it will speed up tensorflow image retraining screenshot 7,,,2017-12-01 10:01:46,2017-12-20 06:00:35
IS,raw video files to tfrecords code integration,Since I had to address the issue of converting large and many raw RGB video files e g avi mp4 etc into tfrecords for threaded QueueRunner training during a research project in the past I was wondering if my resulting code 1 could be of any help to the TensorFlow community If not I would make a feature request and possibly participate or support the implementaton When I had to address this at an early stage of my project I could not find any useful implementations This seems to have remained unchanged as of now 1 Thanks in advance System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 macOS Sierra 10 13 1 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version I use the CPU version GPU model and memory Exact command to reproduce,,"aselle,mrry,mrry,mrry",2017-12-01 13:48:34,2017-12-20 07:16:14
IS,Ubuntu installation instruction is too obsolete,For successful build on Ubuntu it is required to do much more than stated on the installation instructions My system It is required change the build command bazel build config opt config cuda cxxopt fabi version 0 tensorflow tools pip package build pip package verbose failures And it is still not enough I still can not make successful build,,"drpngx,drpngx,aselle,aselle",2017-09-13 13:07:45,2017-12-20 07:22:27
PR,XLA tfcompile Various fixes for MSVC Part 1,This is the initial work to solve 15213 More changes will come in other PRs tensorflow compiler aot tests make test graphs py Use os path for path manipulation tensorflow compiler xla array h Explicitly include numeric for std accumulate tensorflow compiler xla service cpu external constant pool cc h Use tensorflow port Aligned Malloc Free tensorflow compiler xla service cpu llvm ir runtime cc Fix std array initialization tensorflow compiler xla service cpu simple orc jit cc Remove unused dlfcn h and polyfill sincos f for MSVC tensorflow compiler xla service heap simulator h Add const to custom comparator tensorflow compiler xla status macros h Use simplified version of TF ASSIGN OR RETURN for MSVC The simplified version also works for GCC as well actually tensorflow compiler xla util h Hide the workaround for GCC 7 from MSVC is eyes tensorflow core lib gtl compactptrset h Define ssize t for MSVC tensorflow core platform macros h Define LANG CXX11 for VS 2015 In MSVC cplusplus 199711 even when std c latest is set because MSVC is still not fully C 11 compliant,,"rongjiecomputer,rongjiecomputer,rongjiecomputer",2017-12-12 12:39:35,2017-12-20 08:42:46
IS,maxpooling error while building tf label image example,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit TensorFlow installed from source or binary Using CMake and instructions present at tensorflow tensorflow contrib cmake Python version 3 6 1 CUDA cuDNN version CUDA 8 0 61 cuDNN 5 1 GPU model and memory NVIDIA GeForce GTX TITAN X 382 05 Exact command to reproduce MSBuild p Configuration Release tf label image example vcxproj Describe the problem i am facing this error while trying to build the project tf label image example I was able to build this project without GPU support but while building with GPU support i am facing the following error C Users alalwani tensorflow tensorflow contrib cmake build tf label image example vcxproj default target 1 Link target maxpooling op obj error LNK2001 unresolved external symbol public bool cdecl tensorflow functor MaxPoolForwardWithOptionalArgmax operator struct Eigen QInt8 const int int int int int int int int int int int int struct Eigen QInt8 int64 struct Eigen GpuDevice const R MaxPoolForwardWithOptionalArgmax UQInt8 Eigen functor tensorflow QEAA NPEBUQInt8 Eigen hhhhhhhhhhhhpeau34 PEA JAEBUGpuDevice 4 z C Users alalwa ni tensorflow tensorflow contrib cmake build tf label image example vcxproj C Users alalwani tensorflow tensorflow contrib cmake build Release tf label image example exe fatal error LNK1120 1 unresolved externals C Users alalwani tensorflow tensorflow contrib cmake build tf label image example vcxproj,,"reedwm,mrry",2017-09-15 14:28:55,2017-12-20 09:34:42
IS,ar,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-12-20 14:33:43,2017-12-20 14:33:56
IS,Distributed Tensorflow data feeding in the beginning,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux TensorFlow installed from source or binary binary TensorFlow version use command below 1 1 31 Python version 2 7 Bazel version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Describe the problem I am using distributed tensorflow I have a huge parameter matrix partitioned across multiple parameter servers In the beginning of training only some workers will have the following exception If the failed workers are restarted possibly need multiple restarts then the workers can go through and continue the training I have checked the hdfs paths and files They all look good It seems the problem is that the failed workers cannot get the parameters from some ps in the last line see embedding lookup DynamicPartition S751 Source code logs Exception thrown Caused by op u'ReaderReadV2' defined at File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 runpy py line 174 in run module as main main fname loader pkg name File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 runpy py line 72 in run code exec code in run globals File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyspark zip pyspark daemon py line 180 in module File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyspark zip pyspark daemon py line 157 in manager File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyspark zip pyspark daemon py line 61 in worker File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyspark zip pyspark worker py line 174 in main process File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyspark zip pyspark worker py line 169 in process serializer dunits processed is zero ump stream func split index iterator outfile File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 pyspark zip pyspark rdd py line 2408 in pipeline func File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 pyspark zip pyspark rdd py line 2408 in pipeline func File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 pyspark zip pyspark rdd py line 2408 in pipeline func File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 pyspark zip pyspark rdd py line 345 in func File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 pyspark zip pyspark rdd py line 793 in func File grid 4 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000002 tfspark zip tensorflowonspark TFSparkNode py line 240 in mapfn File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyfiles my distributed learning py line 105 in map fun x y units completed records prodcued sg key read csv examples skipgrams None batch size num epochs task index num workers File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 pyfiles my distributed learning py line 56 in read csv examples sg key sg csv sg reader read sg queue File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 site packages tensorflow python ops io ops py line 193 in read return gen io ops reader read v2 self reader ref queue ref name name File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 site packages tensorflow python ops gen io ops py line 422 in reader read v2 queue handle queue handle name name File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 site packages tensorflow python framework op def library py line 767 in apply op op def op def File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 site packages tensorflow python framework ops py line 2359 in create op original op self default original op op def op def File grid 5 tmp yarn local usercache myusername appcache application 1501873511061 2823832 container e06 1501873511061 2823832 01 000168 tf lib python2 7 site packages tensorflow python framework ops py line 1242 in init self traceback extract stack OutOfRangeError see above for traceback FIFOQueue ' 1 sg queue' is closed and has insufficient elements requested 1 current size 0 Node ReaderReadV2 ReaderReadV2 device job worker replica 0 task 1 cpu 0 sg reader sg queue Node embedding lookup DynamicPartition S751 Recv client terminated false recv device job ps replica 0 task 6 cpu 0 send device job worker replica 0 task 1 cpu 0 send device incarnation 6148508285306453080 tensor name edge 726 embedding lookup DynamicPartition tensor type DT INT32 device job ps replica 0 task 6 cpu 0,,"mrry,aselle,mrry",2017-08-19 07:57:34,2017-12-20 16:13:24
IS,compile tensorflow with the source code ERROR,when i compile tensorflow with the source code an ERROR appear If you know how to solve this problem please help me Thank you ERROR home hy003 tensorflow tensorflow python BUILD 4508 1 C compilation of rule ' tensorflow python framework fast tensor util so' failed Exit 1 bazel out local opt genfiles tensorflow python framework fast tensor util cpp In function 'PyObject pyx f 5numpy PyDataType SHAPE PyArray Descr ' bazel out local genfiles tensorflow python framework fastz tensor util cpp 5500 48 error 'PyDataType HASSUBARRAY' was not declared in this scope pyx t 1 PyDataType HASSUBARRAY pyx v d 0,,allenlavoie,2017-11-29 07:03:11,2017-12-20 17:12:50
IS,Eager gradients function can not compute the gradient for simple functions,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 dev20171215 Python version 3 6 3 Anaconda Inc default Nov 8 2017 15 10 56 MSC v 1900 64 bit AMD64 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce See description You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem First define a loss function Then compute the gradient when w 0 1 tfe gradients function loss 0 1 The output is as expected Next compute the gradient when w 50 tfe gradients function loss 50 The output is None I expected the output to be 360 because the gradient is 40 8 w,,"caisq,alextp",2017-12-16 20:55:58,2017-12-20 17:58:39
IS,Go bindings No shape inference function exists for op 'CreateSummaryFileWriter',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version NA using Go bindings Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version cuda 9 1 85 1 cudnn 7 0 5 1 GPU model and memory GTX 1060 6GB Exact command to reproduce See below Describe the problem Calling op CreateSummaryFileWriter panics with panic failed to add operation CreateSummaryFileWriter No shape inference function exists for op 'CreateSummaryFileWriter' did you forget to define it Source code logs,,asimshankar,2017-12-20 05:05:17,2017-12-20 18:17:34
IS,Visualizing Embeddings,projections n the visual for data exploration there are 2 options for distance One of them should be Euclidean as against Euclidian,,"facaiy,shivaniag,facaiy,facaiy,shivaniag,jart",2017-11-23 10:06:38,2017-12-20 19:10:14
IS,Document building tensorflow gpu from source,I have built Tensorflow 1 2 from source with GPU support However the Python package name is tensorflow and not tensorflow gpu as is common We also have machines that do not have GPUs in them so I would like to have them both However I could not find any documentation on how to do this when building from source,,"gunan,Mistobaan,gunan",2017-06-30 21:16:32,2017-12-20 19:11:01
IS,Environment Variable KERB TICKET CACHE PATH is unnecessary,have provided a commit to add kerberos ticket cache file In com sun security auth module Krb5LoginModule initialize it default set ticketCacheName from ticketCache of options ticketCache was set in org apache hadoop security HadoopConfiguration by System getenv KRB5CCNAME So according to set ticket cache by KRB5CCNAME instead of KERB TICKET CACHE PATH the program still working properly Therefore is unnecessary just remind users set KRB5CCNAME in,,"reedwm,jhseu,llhe,llhe",2017-08-15 08:34:19,2017-12-20 19:14:27
IS,HistogramSummary not support fp16,There is a issue when I train my model with adm optimizer tf train AdamOptimizer It seems HistogramSummary not support DT HALF 2017 11 24 09 19 36 954820 W tensorflow core framework op kernel cc 1192 Invalid argument Infinity in summary histogram for local4 BatchNorm beta 1 Node local4 BatchNorm beta 1 HistogramSummary T DT HALF device job localhost replica 0 task 0 device CPU 0 local4 BatchNorm beta 1 tag local4 BatchNorm beta read 171 But if i use the other optimizer such as GradientDescentOptimizer or RMSPropOptimizer there is no the issue above I do not know why Is there anyone meet this error,,"aselle,aselle",2017-11-24 02:08:32,2017-12-20 19:15:11
IS,Bug experiment py continuous train and eval leads to overfitting,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow YES OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 0 1 4 gbd6743e dirty 1 0 1 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Our team has found what we believe is a critical bug in experiment py continuous train and eval L506 that pretty much guarantees any model trained with this method will lead to overfitting The problem is that every time it alternates from evaluating to training again it calls self call train L569 which eventually makes it to estimator py train model L950 This function first creates a brand new graph L952 then sets up the input pipelines L956 This necessarily means that the input pipelines are reset from scratch on every training lap and since a training lap is typically much shorter than an epoch this means the model is only trained with a small portion of the whole dataset Originally we raised this as an issue in Google is tf seq2seq but as far as we can tell now the bug probably belongs into Tensorflow instead as we can not see a simple way to modify the tf seq2seq code to avoid this issue from arising Thank you for looking into this matter Source code logs N A,,"tatatodd,jhseu,xiejw,xiejw,xiejw",2017-06-23 14:26:06,2017-12-20 19:19:22
IS,Distributed training with synchronized SGD using 'grpc verbs' sometimes hangs indefinitely,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary Source TensorFlow version use command below v1 2 0 1755 gee4259a 1 2 1 Python version Python 3 5 2 Bazel version if compiling from source 0 5 1 CUDA cuDNN version 8 0 5 1 GPU model and memory GeForce GTX 1080 Ti Exact command to reproduce Sorry the command is not available since this is custom code RDMA driver version libibverbs dev 1 2 1mlnx1 OFED 4 0 1 5 3 40200 Describe the problem I am training a seq2seq model with synchronized SGD using tf train SyncReplicasOptimizer and tf train Supervisor over RDMA using grpc verbs protocol on 2 workers and 1 parameter server Each worker has 8 GPUs and the model on each GPU is the same I can train this model fine with the default grpc protocol using the same setting When I switched to grpc verbs the behavior becomes unpredictable Most of the times both workers hang for at least 12 hours so not because I did not wait long enough Sometimes the chief worker worker 0 starts training but worker 1 hangs This should not happen since I am programming with synchronized SGD Worker 0 should be blocked if worker 1 is not ready In rare case it can go through and start training I believe the RDMA driver is correctly installed When worker hangs the CPU utilization stays low but not zero and the GPU utilization is 0 Source code logs I attached below the log from worker 1 worker1 txt In this case worker 1 hangs and worker 0 starts training There are some custom logs printed In the log you can find that worker 1 sent a RDMA MESSAGE TENSOR REQUEST to the parameter server but never got an ACK and I have checked the log from the parameter server which showed that it never received a RDMA MESSAGE TENSOR REQUEST from worker 1 I also attached the full trace gdb worker1 txt collected on worker 1 in gdb with thread apply all bt during worker 1 hanging Thanks,,"byronyi,byronyi,suiyuan2009,suiyuan2009,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi,byronyi",2017-07-10 18:44:52,2017-12-20 19:29:20
IS,Feature request tfdbg support for Session partial run setup and Session partial run,Hello When I debug tensorflow codes written with partial run setup and partial run using tfdbg it output partial run setup is not implemented for debug wrapper sessions I want to know how to debug tensorflow codes with partial run setup and partial run Thank you,,caisq,2017-10-24 08:09:24,2017-12-20 19:30:54
IS,Feature request RMSProp without momentum variables,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra TensorFlow installed from source or binary Source TensorFlow version use command below v1 3 0 24 g658866597 1 3 0 Python version 3 6 3 Bazel version if compiling from source 0 6 1 CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem The current RMSPropOptimizer always allocates momentum variables even though the default and probably 99 of people never make use of it In fact if one wishes to combine momentum and adaptive gradient descent he she will most likely instantiate an AdamOptimizer instead The extra variables waste precious GPU CPU memory as well as disk space when saved as checkpoints while providing minimal utility Suggestion introduce a new version of ApplyRMSProp operations that does not use momentum variables at all and dynamically choose which implementation to use in RMSPropOptimizer constructor depending on whether the momentum argument is constant zero Alternative solution change the current ApplyRMSProp operations so that it does not use momentum variables and direct the minority users who currently need momentum with RMSProp to Adam instead,,"facaiy,tatatodd,jhseu,jhseu",2017-10-07 03:28:28,2017-12-20 19:34:20
IS,import error cudnnConvolutionBiasActivationForward because tensorflow cpu and tensorflow gpu both were installed,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below Tensorflow gpu 1 3 0 Python version on both 2 7 and 3 5 Bazel version if compiling from source CUDA cuDNN version CUDA 8 Cudnn 5 GPU model and memory Nvidia GeForce GTX 1080 Ti 11 GB Exact command to reproduce 1 pip install tensorflow 2 pip install tensorflow gpu 3 pin unistall tensorflow 4 pip uninstall tensorflow gpu 5 pip install tensorflow gpu You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I installed tensorflow cpu and tensorflow gpu by mistake I uninstalled both the versions after realising my mistake I then got afresh install with tensorflow gpu Then i get an import error as below ImportError usr local lib python3 5 dist packages tensorflow python pywrap tensorflow internal so undefined symbol cudnnConvolutionBiasActivationForward I tried restarting and force reinstall but both did not work I also tried with a virtual environment and failed When i downgraded to tensorflow gpu 1 2 1 it works However i need 1 3 Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"yifeif,yifeif,yifeif",2017-10-25 15:05:02,2017-12-20 19:34:57
IS,Possible memory leak with tf py func with distributed Tensorflow,When running Tensorflow as an distributed process to provide data with tf data it gradually consumes more and more memory and finally consumes all memory of the system Scripts to reproduce We use a dummy dataset which produce 128 28 28 1 tensors Case1 Without distribute which works fine it will only consume 429Mb memory no matter how many batches we run Codes in test1 py Tensorflow v1 4 0 rc1 11 g130a514 1 4 0 OS ubuntu mate 16 04 1 Python 3 6 1 conda 4 3 30,,"mrry,alextp,mrry",2017-12-20 09:47:28,2017-12-20 19:39:15
PR,Clear the decref cache after calls to py func to ensure no leaks,Fixes 15518,,alextp,2017-12-20 17:50:25,2017-12-20 19:39:15
IS,No gradient defined for op Select,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 x64 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version None CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem It seems there is no gradient defined for the Select operation in the C API I am actually getting this issue while using the C API through the C bindings provided by the TensorFlowSharp project and for this reason I did not fill the exact command to reproduce field above However seeing that op is indeed still missing from the C API Hope its not a false alarm given that I did not test libtensorflow dll directly,,"facaiy,tatatodd",2017-11-23 21:32:11,2017-12-20 19:40:05
PR,C gradient for Select,Fix 14845 migrate python implementation to c side source L919 How to test x add test case pass all tests,,"facaiy,suharshs,suharshs,facaiy,facaiy,drpngx,facaiy,facaiy,facaiy,suharshs,facaiy,yifeif,gunan",2017-11-24 11:24:50,2017-12-20 19:40:05
PR,Fix Golang readme installation instruction formatting,This looks like it got pasted in incorrectly,,,2017-12-20 18:19:37,2017-12-20 19:41:57
PR,fix typos,fix typos,,ManHyuk,2017-12-20 10:10:18,2017-12-20 19:42:29
PR,Fix typos,,,snnn,2017-12-20 07:39:44,2017-12-20 19:45:25
IS,XLA crash on Wasserstein GAN,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow installed from source TensorFlow version use command below v1 2 0 1382 g708cbaf 1 2 0 Python version Python 3 5 2 Bazel version if compiling from source CUDA cuDNN version CUDA 8 cudnn 6 GPU model and memory 2x1080 Ti 12 Gb Describe the problem When I'm running this code with XLA I get the following error message Without XLA it works OK,,"jart,hawkinsp,jlebar",2017-07-13 08:23:38,2017-12-20 19:46:21
IS,should tf contrib data FixedLengthRecordDataset work with GS,Trying to open a GS file gs with tf contrib data FixedLengthRecordDataset I get tensorflow core framework op kernel cc 1158 Out of range EOF reached 0 bytes were read out of 262144 bytes requested,,"aselle,tfboyd,tfboyd,jhseu",2017-07-25 23:34:30,2017-12-20 19:46:40
IS,TensorFlow lack of repeatability in tf estimator DNNClassifier,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce custom code no it is the one in system Apple OS Mac OsX 10 13 TensorFlow version 1 3 0 Python version 3 6 3 GPU model AMD FirePro D700 actually two such GPUs You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Dear all I wish to use TensorFlow to perform classification on medical datasets To do this I am using exactly the same code as that proposed in the only difference being that I face medical datasets rather than the Iris database So it is not custom code I do need help about the following problem if I run the same code on the same data with the same parameters for the network configuration number of layers number of neurons in each layer and so on the results are different I mean I run the same code ten times and I obtain ten different values for the accuracy These values are even largely different as they range from 73 up to 83 This means that the subjects considered suffering from a given disease vary from a run to another Differently said once set a network structure there are several subjects who are considered either healthy or sick depending on the run only As you can imagine this lack of repeatability makes that code useless from both scientific and medical viewpoints another user running the same configuration over the same data set would find a different model and different results so would cure different subjects I have noticed that for the Iris database the problem seems not to take place and accuracy is always 0 9666 This depends on the problem being very easy linearly separable for all but one items and very small data set I have carried out a search on the internet and I have found several other people who have noted the same problem As for the possible solutions I have read several as well I have implemented them all with no result Here I add a short list of some suggested remedies that failed in my case os environ 'PYTHONHASHSEED' '0' np random seed 0 tf set random seed 0 rn seed 0 tf reset default graph session conf tf ConfigProto intra op parallelism threads 1 inter op parallelism threads 1 sess tf Session graph tf get default graph config session conf Is there any chance to fix this problem It is a pity that such an excellent tool as TensorFlow is cannot guarantee repeatibility I am using TensorFlow 1 3 0 Python 3 6 3 and an Apple with Mac OsX 10 13 Thank you very much Best regards Ivanoe De Falco Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Source code is in,,"facaiy,facaiy,facaiy,ekelsen,skye,mrry,aselle,mrry",2017-10-16 10:57:30,2017-12-20 19:54:17
PR,Update mnist py,Comment modification,,"yifeif,snnn,yifeif",2017-12-20 02:29:12,2017-12-20 20:03:01
PR,XLA tfcompile Add Env CreateUniqueFileName and use it in SaveGraph,Split part of tensorflow Env LocalTempFilename into tensorflow Env CreateTempFilename so that it can be used in SaveGraph This PR is to replace 15335 I am terrible in creating descriptive function name better name suggestion for CreateTempFilename is welcomed cc 15213,,"rongjiecomputer,jlebar,jlebar,jlebar,rongjiecomputer,rongjiecomputer,rongjiecomputer,jlebar,jlebar,jlebar,jlebar,rongjiecomputer,rongjiecomputer,jlebar,jlebar,rongjiecomputer,rongjiecomputer,jlebar,rongjiecomputer,jlebar,rongjiecomputer,jlebar,rongjiecomputer,yifeif",2017-12-19 10:36:24,2017-12-20 20:05:09
IS,Softplus with parameters,Should I go on implementing the parametric version of Softplus Current implementation softplus impl py L35 Reference to parametric version PyTorch docs torch nn Softplus,,"shivaniag,jvdillon,jvdillon",2017-07-30 22:20:58,2017-12-20 20:51:56
IS,Why remove tolerate dup recv from LocaRendezvous,I did not find a PR for this patch Maybe this discussion belongs to that particular commit page If so I will move it there Can somebody explain the rationale behind this patch Current contrib verbs uses exactly this flag to transfer tensors Note it is set true here L34 Removing it totally breaks verbs I am asking if this patch is absolutely needed since there is no simple workaround for contrib verbs without this flag,,"reedwm,byronyi,yanivbl6",2017-07-27 19:45:15,2017-12-20 21:04:45
PR,XLA Fix another XLA tfcompile compile error on OSX,This fixes issue though that was accidentally closed kernel support library cc 99 5 error no matching function for call to 'transform' std transform function arg begin TEST build tfcompile on OSX also requires PR 14893,,"powderluv,sanjoy,powderluv,sanjoy,powderluv,powderluv,powderluv,yifeif,yifeif",2017-12-09 04:54:25,2017-12-20 21:12:00
IS,W tensorflow stream executor cuda cuda dnn cc 2223,The source code I try to compile has been changed and now it requires tf nightly build 1 4 version For that reason I created new conda environment which includes 1 4 version of tensorflow However I still use the same set up except the version of tensorflow I have read they anticipate releasing 1 4 version of tensorflow wih cuDNN 7 instead of cuDNN 6 Is this the reason that I get these warnings Should I upgrade the cuDNN version from 6 to 7 I'm also getting RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 although I loaded the 3 6 version of tf nightly build This is what I get System information OS Platform and Distribution Linux Ubuntu 16 04 LTS TensorFlow installed from source or binary tf nightly gpu 1 4 0 dev20171010 cp36 cp36m manylinux1 x86 64 whl TensorFlow version 1 4 0 dev20171010 Python version 3 6 1 Anaconda 64bit CUDA cuDNN version cuda ga2 8 0 amd64 cudnn 8 0 linux x64 v6 0 GPU model and memory Nvidia GeForce GT 710 1GB memory Exact command to reproduce python train xxx train batch size 16 val batch size 16,,"allenlavoie,av8ramit,allenlavoie,tatatodd,yzhwang,yzhwang",2017-10-11 12:58:10,2017-12-20 21:21:20
PR,XLA Use os path for path manipulation,Split from 15310 15213,,"rongjiecomputer,yifeif",2017-12-20 08:33:39,2017-12-20 21:50:35
PR,Fixed bug in code within programmer is guide markdown docs for Variabl,es Had a call to tensor run method but Tensor instances have no run method switched to eval instead,,yifeif,2017-11-17 22:15:23,2017-12-20 21:57:56
IS,stack bidirectional RNNs swap memory and time major args,Feature Request adding swap memory and time major arguments to stack bidirectional rnn and stack bidirectional dynamic rnn from the source i see that both stack bidirectional function just wraps bidirectional rnn so it use concatenated output as next bidirectional layer is input is it intentional that swap memory and time major argument not added,,"asimshankar,ebrevdo",2017-07-20 09:28:19,2017-12-20 22:00:42
IS,Op type not registered 'GatherTree' in binary running on,Hi I'm trying to use the GTT Graph Transform Tool on NMT model From the NMT sample project I get the following error bazel bin tensorflow tools graph transforms transform graph in graph tmp NMT frozenGraphPB pb out graph Quant NMT pb inputs '' outputs 'attention' transforms 'add default attributes quantize weights quantize nodes' Op type not registered 'GatherTree' in binary running on Make sure the Op and Kernel are registered in the binary running in this process Any idea how to solve this issue Thx System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No code change using GTT tool example OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary From Source TensorFlow version use command below Latest Python version 3 5 3 6 and 2 7 Bazel version if compiling from source CUDA cuDNN version None GPU model and memory Tried in several systems and installations Exact command to reproduce bazel bin tensorflow tools graph transforms transform graph in graph tmp NMT frozenGraphPB pb out graph Quant NMT pb inputs '' outputs 'attention' transforms 'add default attributes quantize weights quantize nodes',,allenlavoie,2017-10-22 13:39:33,2017-12-20 22:07:43
PR,Release notes and version string update,,,"gunan,asimshankar,asimshankar,asimshankar,av8ramit,gunan,av8ramit,av8ramit,gunan,gunan,gunan",2017-12-19 05:01:29,2017-12-20 22:15:15
PR,Update Android JCenter links,Looks like the bintray repo was reorganized and the previous references to tensorflow android now 404 This PR adds working links,,pvaneck,2017-11-07 20:39:16,2017-12-20 22:23:48
IS,Unexpected behavior in tf contrib distributions Categorical,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 3 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Python version 2 7 10 Bazel version if compiling from source CUDA cuDNN version CPU GPU model and memory CPU Exact command to reproduce Describe the problem I wonder if this is a bug or if this is a design choice to have tf contrib distributions Categorical output a number outside the support of the distribution if all of the probabilities are 0 In any case it would be helpful to throw an error when all probabilities are 0 rather than output a number that does not work Source code logs See above,,"aselle,ebrevdo,ebrevdo,ebrevdo,jvdillon",2017-07-25 18:23:05,2017-12-20 22:37:42
IS,Mac build problem with local config python,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No this repros on master r1 3 and r1 2 OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS Sierra 10 12 5 TensorFlow installed from source or binary Source repros on master r1 3 r1 2 TensorFlow version use command below See above Python version 2 7 10 Clean virtualenv Bazel version if compiling from source 0 5 1 homebrew CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce bazel build tensorflow tools pip package build pip package Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I'm trying to build the pip package generator so I can test changes to the pip package The same command works on Linux Source code logs bazel build tensorflow tools pip package build pip package ERROR private var tmp bazel dandelion bd129d2cd1c27b48980a1c74fec9319a external local config python BUILD 136 12 in outs attribute of genrule rule numpy include Genrules without outputs do not make sense ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted,,"dandelionmane,martinwicke,damienmg,av8ramit",2017-07-26 21:51:48,2017-12-20 22:42:58
IS,Op type not registered HashTableV2 error while deploying model in cloud ml,Problem while deploying model in Tensorflow 1 4 Code Screenshot But when I tried with tf1 2 with some changes in the code in model fn Basically not using tf keras but using tf contrib keras it was working is this bug,,jart,2017-12-20 18:22:04,2017-12-20 23:04:58
PR,Fix typo,,,ManHyuk,2017-12-11 06:09:43,2017-12-20 23:08:45
PR,Fix control input name for quantize node,Relate to 9792 strip x at the end of control input name Fix the problem that mentioned,,"martinwicke,yifeif",2017-11-14 03:46:41,2017-12-20 23:15:31
PR,Remove redundant code of slice op cc,In slice op cc line 252 when input dims is 4 it is handle as a special case So it is not necessary to handle the 4 case when input dims is not 4,,"qmick,qmick,yifeif",2017-11-11 04:40:56,2017-12-20 23:15:45
PR,XLA tfcompile Implement mkstemps for MSVC,mkstemps used in SaveGraph is not available on Windows Implementation adapted from L470,,"rongjiecomputer,snnn,rongjiecomputer,jlebar,rongjiecomputer,jlebar,rongjiecomputer,rongjiecomputer",2017-12-13 08:28:16,2017-12-20 23:27:48
PR,XLA Define LANG CXX11 for VS 2015,In MSVC cplusplus 199711 even when std c latest is set because MSVC is still not fully C 11 compliant Split from 15310 15213,,"rongjiecomputer,snnn,rongjiecomputer,snnn,tatatodd",2017-12-20 08:39:07,2017-12-20 23:48:55
IS,Keras TimeDistributed wrapper error 'NoneType' object has no attribute 'as list',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below built from master pulled on 10 26 Python version 3 6 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See below Describe the problem Issue arises when using TimeDistributed wrapper in release 1 4 See simple code example below which works fine in version 1 3 Source code logs,,"facaiy,jart,jart",2017-10-28 04:05:55,2017-12-20 23:54:12
PR,Fix indenting on cache check in Network layer class,Resolves 14054 The else and ensuing code on the cache check was indented one spot too far This resulted in the cache hit code not being executed when there was a cache hit and the cache miss code never being called because there was a cache hit,,"martinwicke,martinwicke,martinwicke,martinwicke,yifeif",2017-11-08 18:47:47,2017-12-20 23:54:12
PR,modified convolution document,fix 14027,,"ZhengshengWei,fchollet,ZhengshengWei,ZhengshengWei,fchollet,jhseu,ZhengshengWei,yifeif",2017-11-09 10:50:18,2017-12-20 23:55:29
PR,added patch needed for jetson tx2 1,arm64 does not support NUMA so TryToReadNumaNode in cuda gpu executor cc has to be modified accordingly to avoid a failure at runtime Currently everybody using a jetson board needs to apply this patch manually which is a pain if you forget because it fails at runtime and not at build This means that you compile for a couple of hours only to realize you should have done this first,,jhseu,2017-11-09 14:32:43,2017-12-20 23:56:20
PR,XLA Hide GCC 7 1 1 workaround from MSVC,Split from 15310 15213,,"rongjiecomputer,tatatodd,rongjiecomputer,tatatodd",2017-12-20 08:36:53,2017-12-20 23:58:26
PR,XLA Fix std array initialization,Split from 15310 15213,,"rongjiecomputer,tatatodd",2017-12-20 08:36:27,2017-12-21 00:00:15
PR,XLA Explicitly include numeric,std accumulate comes from numeric but numeric is not implicitly included by algorithm in MSVC Split from 15310 15213,,"rongjiecomputer,tatatodd",2017-12-20 08:35:35,2017-12-21 00:07:39
PR,XLA Add 'const' to custom comparator,Split from 15310 15213,,"rongjiecomputer,tatatodd",2017-12-20 08:34:14,2017-12-21 00:07:49
PR,Implement backpropagation for SVD when full matrices is False,This pull request implements backpropagation for the singular value decomposition operation when full matrices is False A request for this feature is in 13641 The algorithm I use is the same one as in the autograd implementation L127 L217 There is a very nice derivation of the formula written I think by towns at j towns I hope you do not mind that I include this link here I found it in the description of your autograd pull request that added this feature Thanks in advance for taking the time to review this,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,martinwicke,rmlarsen,rmlarsen,rmlarsen",2017-11-05 18:51:15,2017-12-21 00:32:45
IS,Documentation truncated normal does not match implementation,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Nope OS Platform and Distribution e g Linux Ubuntu 16 04 Linux CentOS 7 3 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 6 1 Bazel version if compiling from source N A CUDA cuDNN version 8 0 6 0 GPU model and memory Nvidia Tesla 12 GB Exact command to reproduce Describe the problem The documentation of tf truncated normal contains the following line for its parameter stddev The standard deviation of the truncated normal distribution However the example below shows that the truncated normal does not have the given standard deviation This means that the documentation would be correct if it said The standard deviation of the normal distribution before truncation or if the standard deviation of the samples would be indeed the given standard deviation Source code logs import numpy as np import tensorflow as tf standard deviation not 1 with tf Session print np std tf truncated normal 10000 stddev 1 eval compared to scipy from scipy stats import truncnorm print truncnorm 2 2 loc 0 scale 1 std,,,2017-10-13 11:58:32,2017-12-21 00:57:32
IS,Encountered a training error when using slim with multi GPU connect by PIX type,Hi all I encountered a training error when I training model in multi GPU The key condition is using slim to write model and training in multi GPU GTX TITAN X which connect by PIX type How to reproduce 1 checkout office code in here 2 copy code in below slim model code and replace it to cifar10 py file Because only slim code can reproduce this issue 3 start to training System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS Linux release 7 2 1511 TensorFlow installed from source or binary source TensorFlow version use command below Tensorflow 1 2 0 1 0 1 Python version 2 7 Bazel version if compiling from source 1 4 5 GCC Compiler version if compiling from source 4 8 5 CUDA cuDNN version CUDA 8 0 and cuDNN 5 0 GPU model and memory TITAN X with 12GB Exact command to reproduce,,,2017-11-09 10:35:58,2017-12-21 01:37:44
PR,Update debugger md,When working thru the examples I'm seeing just Softmax rather than softmax Softmax If this is indeed correct the output image also needs to be updated,,yifeif,2017-12-20 19:54:48,2017-12-21 02:19:45
IS,slow cifar10 multi gpu train py stock example and 'Ignoring device specification device GPU' warning,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no using stock example scripts from cifar10 OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS inside singularity container using docker image tensorflow latest gpu TensorFlow installed from source or binary docker latest gpu unmodified TensorFlow version use command below,,"nealwu,nealwu",2017-07-09 19:02:06,2017-12-21 02:33:34
PR,Use a trailing period to define floating point constant,In the example code for basic usage of tf estimator the array y eval uses the constant 7 when the rest of surrounding constants use trailing periods The corresponding code for a custom estimator has the trailing period compare line 378 to line 450,,,2017-12-21 03:04:21,2017-12-21 03:07:31
PR,Branch 179628764,Push,,"ekelsen,ekelsen,yifeif,yifeif,yifeif,caisq,yifeif,caisq,caisq",2017-12-20 19:03:55,2017-12-21 04:13:59
IS,Switching Session to MonitoredTrainingSession Produces Negative Dimension Tensors from Queues,I already posted on StackOverflow but received no response I have made some changes to my code since posting on StackOverflow but the problem is still the same the readers and queues I use without a problem with a vanilla tf Session work fine but if I try to switch to a tf train MonitoredTrainingSession I get the following error InvalidArgumentError see above for traceback Shape 15 1 4 has negative dimensions Node define inputs y Placeholder dtype DT FLOAT shape 15 4 device job local replica 0 task 0 cpu 0 I'm using TensorFlow v1 2 0 5 g435cdfc 1 2 1 Here is my code This works fix random seed to permit comparison between training runs tf set random seed seed 0 define graph model import model with tf Session as monitored sess monitored sess run tf global variables initializer create coordinator to handle threading coord tf train Coordinator start threads to enqueue input minibatches for training threads tf train start queue runners sess monitored sess coord coord data monitored sess run training data x y x lengths y lengths data 0 when done ask the threads to stop coord request stop wait for threads to finish coord join threads But then this code does not work tf set random seed seed 0 define graph model import model create a one process cluster with an in process server server tf train Server create local server define hooks for writing summaries and model variables to disk hooks construct training hooks model summary op model loss train log directory create monitored training session to write model variables and summaries to disk with tf train MonitoredTrainingSession master server target config tf ConfigProto allow soft placement True is chief True hooks hooks as monitored sess create coordinator to handle threading coord tf train Coordinator start threads to enqueue input minibatches for training threads tf train start queue runners sess monitored sess coord coord train data monitored sess run training data x y x lengths y lengths data 0 when done ask the threads to stop coord request stop wait for threads to finish coord join threads The function construct training hooks is pretty straightforward def construct training hooks summary op loss train log directory hooks tf train StopAtStepHook last step tf flags FLAGS max steps tf train CheckpointSaverHook checkpoint dir train log directory saver tf train Saver save steps 5 tf train SummarySaverHook output dir train log directory summary op summary op save steps 1 tf train NanTensorHook loss tensor loss return hooks,,"aselle,mrry,mrry",2017-07-11 21:07:37,2017-12-21 04:19:15
IS,Fails to optimize MultivariateNormalFullCovariance It breaks on Cholesky decomposition I have cherry picked the mentioned commit to update gradient issue in MultivariateNormalFullCovariance Still it fails in optimization,I am trying to optimize a distribution with Mu Nx4 and covariance matrix Nx4x4 using MultivariateNormalFullCovariance The optimization runs for few iterations loss seems to be reducing gradients are not exploding The code breaks with following InvalidArgumentError see above for traceback Got info 4 for batch index 0 expected info 0 Debug info potrf Node MultivariateNormalFullCovariance init Cholesky Cholesky T DT FLOAT device job localhost replica 0 task 0 gpu 0 Reshape 2 Node gradients AddN 30 49 Recv client terminated false recv device job localhost replica 0 task 0 cpu 0 send device job localhost replica 0 task 0 gpu 0 send device incarnation 1 tensor name edge 3080 gradients AddN 30 tensor type DT FL I have debugged analyzing the covarince pdf and gradients they all seem to be alright giving expecting values Suddenly at one iteration code breaks,,"ebrevdo,ebrevdo",2017-11-03 07:50:48,2017-12-21 06:07:13
IS,Kernel Bias created for only one LSTM when using BasicLSTMCell with MultiRNNCell,I am using the example code ptb word lm py that creates 2 layers of lstm is The code clearly creates 2 c h tuples each tuple corresponding to one LSTM Each c and h should depend on matrices i j f o input gate new input foget gate outpu gate that are found in BasicLSTMCell in rnn cell impl py With tf global variables you should be able to get these matrices In fact it returns a kernel matrix and a bias matrix The kernel matrix is of size 400x800 which corresponds to only one LSTM parameters the i j f o matrices are concatenated horizontally The matrices for the input and h t 1 are concatenated vertically However whether I am using 1 layer LSTM or 2 layer LSTM the number of parameters stays the same 400x800 when it should be 400x1600 or a tuple of some sort or an additional kernel and bias It seems that tf global variables does not expose all trainable parameters in this case Is that true or am I missing something EDIT I am now fairly certain that this is a problem because when I use the block option in the script multirnncell works correctly and generates 2 kernel matrices and 2 bias matrices with BasicLSTMCell it only generates one kernel matrix and 1 bias matrix,,"ebrevdo,ebrevdo",2017-10-18 16:36:02,2017-12-21 07:14:24
IS,mutex h private member is inaccessible,System information msvc v140 Problem mutex h Ln 145 condition variable cannot access private member mu in mutex when compiling a standalone c project on Windows Solution Forward declare condition variable in mutex h I have created a pull request,,,2017-11-09 01:33:12,2017-12-21 12:26:40
IS,Tensorflow installation error,Tensorflow installation error Method followed InstallingAnaconda Environment ubuntu 16 04 anaconda 4 3 29 Python 2 7 13 nvidia 1070 GPU Please help gopi gp source activate tensorflow tensorflow gopi gp pip install ignore installed upgrade Collecting tensorflow gpu 1 4 0 from Using cached Collecting enum34 1 1 6 from tensorflow gpu 1 4 0 Using cached enum34 1 1 6 py2 none any whl Collecting six 1 10 0 from tensorflow gpu 1 4 0 Using cached six 1 11 0 py2 py3 none any whl Collecting protobuf 3 3 0 from tensorflow gpu 1 4 0 Using cached protobuf 3 5 0 post1 cp27 cp27mu manylinux1 x86 64 whl Collecting numpy 1 12 1 from tensorflow gpu 1 4 0 Using cached numpy 1 13 3 cp27 cp27mu manylinux1 x86 64 whl Collecting wheel from tensorflow gpu 1 4 0 Using cached wheel 0 30 0 py2 py3 none any whl Collecting backports weakref 1 0rc1 from tensorflow gpu 1 4 0 Using cached backports weakref 1 0 post1 py2 py3 none any whl Collecting tensorflow tensorboard 0 5 0 0 4 0rc1 from tensorflow gpu 1 4 0 Using cached tensorflow tensorboard 0 4 0rc3 py2 none any whl Collecting mock 2 0 0 from tensorflow gpu 1 4 0 Using cached mock 2 0 0 py2 py3 none any whl Collecting setuptools from protobuf 3 3 0 tensorflow gpu 1 4 0 Downloading setuptools 38 2 4 py2 py3 none any whl 489kB 100 491kB 30kB s Collecting futures 3 1 1 python version 3 2 from tensorflow tensorboard 0 5 0 0 4 0rc1 tensorflow gpu 1 4 0 Downloading futures 3 2 0 py2 none any whl Collecting werkzeug 0 11 10 from tensorflow tensorboard 0 5 0 0 4 0rc1 tensorflow gpu 1 4 0 Downloading Werkzeug 0 13 py2 py3 none any whl 311kB 100 317kB 31kB s Collecting html5lib 0 9999999 from tensorflow tensorboard 0 5 0 0 4 0rc1 tensorflow gpu 1 4 0 Collecting markdown 2 6 8 from tensorflow tensorboard 0 5 0 0 4 0rc1 tensorflow gpu 1 4 0 Downloading Markdown 2 6 10 zip 414kB 100 419kB 43kB s Collecting bleach 1 5 0 from tensorflow tensorboard 0 5 0 0 4 0rc1 tensorflow gpu 1 4 0 Using cached bleach 1 5 0 py2 py3 none any whl Collecting funcsigs 1 python version 3 3 from mock 2 0 0 tensorflow gpu 1 4 0 Using cached funcsigs 1 0 2 py2 py3 none any whl Collecting pbr 0 11 from mock 2 0 0 tensorflow gpu 1 4 0 Using cached pbr 3 1 1 py2 py3 none any whl Building wheels for collected packages markdown Running setup py bdist wheel for markdown done Stored in directory home gopi cache pip wheels 1e 5a 55 a80b200d12e234d575ad68c1528593d1ce488720b65b24e48c Successfully built markdown Installing collected packages enum34 six setuptools protobuf numpy wheel backports weakref futures werkzeug html5lib markdown bleach tensorflow tensorboard funcsigs pbr mock tensorflow gpu Exception Traceback most recent call last File home gopi local lib python2 7 site packages pip basecommand py line 215 in main status self run options args File home gopi local lib python2 7 site packages pip commands install py line 342 in run prefix options prefix path File home gopi local lib python2 7 site packages pip req req set py line 784 in install kwargs File home gopi local lib python2 7 site packages pip req req install py line 851 in install self move wheel files self source dir root root prefix prefix File home gopi local lib python2 7 site packages pip req req install py line 1064 in move wheel files isolated self isolated File home gopi local lib python2 7 site packages pip wheel py line 345 in move wheel files clobber source lib dir True File home gopi local lib python2 7 site packages pip wheel py line 329 in clobber os utime destfile st st atime st st mtime OSError Errno 1 Operation not permitted ' home gopi anaconda2 lib python2 7 site packages enum README' tensorflow gopi gp,,"Carmezim,Carmezim,Carmezim",2017-12-18 10:26:46,2017-12-21 12:33:58
IS,error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions,bazel build c opt config cuda tensorflow tools pip package build pip package Linux Ubuntu 16 04 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 9 0 7 0 GPU model and memory GTX 965m ERROR home zhouzl tensorflow master tensorflow contrib seq2seq BUILD 51 1 error while parsing d file home zhouzl cache bazel bazel zhouzl 418dff85d676df3fe7a9d3de8f68c1df execroot org tensorflow bazel out local linux opt bin tensorflow contrib seq2seq objs python ops beam search ops gpu tensorflow contrib seq2seq kernels beam search ops gpu cu pic d No such file or directory In file included from usr local cuda 9 0 bin targets x86 64 linux include common functions h 50 0 from usr local cuda 9 0 bin targets x86 64 linux include cuda runtime h 115 from command line 0 usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead,,"npanpaliya,npanpaliya",2017-08-22 12:49:45,2017-12-21 14:32:36
IS,Docker image file generated by parameterized docker build sh fails 3,Issue Fixed previous docker install issue 13379 Executing parameterized docker build sh generates new docker file but image fails to turn into an docker image throws error message System information I have used a stock example script provided in TensorFlow Windows 10 professional TensorFlow install as docker image tensorflow tensorflow 1 3 0 devel py3 TensorFlow version 1 3 Python version 3 Bazel version 0 5 0 CUDA cuDNN version not relevant CPU install GPU model and memory not relevant CPU install Docker CE 17 09 0 ce which docker usr bin docker Command triggering issue tensorflow tensorflow tools docker parameterized docker build sh Error messages Required build parameters TF DOCKER BUILD TYPE cpu TF DOCKER BUILD IS DEVEL no TF DOCKER BUILD DEVEL BRANCH Optional build parameters TF DOCKER BUILD CENTRAL PIP TF DOCKER BUILD IMAGE NAME TF DOCKER BUILD VERSION TF DOCKER BUILD PORT TF DOCKER BUILD PUSH CMD FINAL IMAGE NAME tensorflow tensorflow FINAL TAG latest Original Dockerfile tensorflow tensorflow tools docker Dockerfile Docker build will occur in temporary directory tmp tmp nBIOwyaShf Downloading pip wheel from Modified Dockerfile at tmp tmp nBIOwyaShf Dockerfile Building docker image with image name and tag tensorflow latest invalid argument tensorflow latest for t invalid reference format See wouldocker build help' FAIL docker build of tensorflow latest with Dockerfile tmp tmp nBIOwyaShf Dockerfile failed Inspecting the resulting docker file for further introspection cat tmp tmp nBIOwyaShf Dockerfile FROM ubuntu 16 04 MAINTAINER Craig Citro craigcitro google com RUN apt get update apt get install y no install recommends build essential curl libfreetype6 dev libpng12 dev libzmq3 dev pkg config python python dev rsync software properties common unzip apt get clean rm rf var lib apt lists RUN curl O python get pip py rm get pip py RUN pip no cache dir install Pillow h5py ipykernel jupyter matplotlib numpy pandas scipy sklearn python m ipykernel kernelspec RUN pip no cache dir install COPY jupyter notebook config py root jupyter COPY notebooks notebooks COPY run jupyter sh EXPOSE 6006 EXPOSE 8888 WORKDIR notebooks CMD run jupyter sh allow root Additional introspection with docker image file Copied and pasted the parameterized docker build sh output docker file content and tried to execute on docker hub which fails Docker hub log reports yields the following additional error information Step 6 9 RUN pip no cache dir install Running in fd0d49a714e4 91mtensorflow 1 head cp35 cp35m manylinux1 x86 64 whl is not a supported wheel on this platform 0m Removing intermediate container fd0d49a714e4 The command ' bin sh c pip no cache dir install ' returned a non zero code 1,,,2017-10-17 13:49:28,2017-12-21 14:44:26
IS,Supervisor SummaryWriter and Saver stop after some time,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 anaconda3 python 3 6 TensorFlow installed from source or binary binary pip install tensorflow gpu TensorFlow version use command below 1 2 0 Bazel version if compiling from source CUDA cuDNN version 5 1 GPU model and memory 1080 Titan X K80 Exact command to reproduce System information tf env txt Describe the problem Hey guys I get the problem on 3 different machines all on ubuntu 16 04 and the tensorflow 1 2 All experiments were executed on a single machine with a single GPU To initialize a session I use a tf Supervisor and supervisor managed sessions with the default summary writer and saver It works all well for up to 30mins 1h30mis But after that time the summary writer stops to write events and the saver also stops to save the model parameters However the model still runs and produces valid outputs I also checked the python log for tensorflow with level DEBUG But all I got was some information logs until it suddenly stops see below Is there a way to track the SVSummaryThread SVTimerCheckpointThread Thanks in advance and keep up the good work Cheers Source code logs,,,2017-06-21 15:08:47,2017-12-21 15:11:31
IS,Little error in example how to read data,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 4 Exact command to reproduce Describe the problem Error when doing the above second command AttributeError module 'tensorflow' has no attribute wouldata' The data attribute is actually in the contrib module then you should change the line 108 of the file tensorflow tensorflow examples how tos reading data fully connected reader py dataset tf data TFRecordDataset filename to dataset tf contrib data TFRecordDataset filename Sorry I do not know if I should have submitted a pull request for such a little change,,"mrry,mrry",2017-12-21 14:31:56,2017-12-21 15:17:56
IS,Tensorflow 1 3 tf constant with dtype float32 float64 float16 may have inconsistent behavior,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 with docker running gcr io tensorflow tensorflow latest TensorFlow installed from source or binary NA TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Describe the problem A tensorflow constant with None in array with dtype float32 float64 seem to throw an error However if they are first wrapped by a numpy array none is accepted and turned into NaN This behavior seems inconsistent,,"drpngx,MarkDaoust,MarkDaoust",2017-10-19 03:47:14,2017-12-21 15:19:12
IS,tf reduce mean is not compatible with np mean,tf reduce mean emphasized that this function is compatible with numpy Equivalent to np mean But it does not in the output type Consider the following code for example System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 Python version 3 6,,"yongtang,drpngx,MarkDaoust,DjangoPeng,drpngx,MarkDaoust",2017-10-21 17:39:20,2017-12-21 15:27:25
PR,golang added Session ListDevices method,Implemented Session ListDevices method,,"anight,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,anight,anight,anight,anight,anight,anight,asimshankar,jhseu,caisq,yifeif,yifeif",2017-11-08 22:34:58,2017-12-21 16:04:47
IS,tf estimator RunConfig is incompatible with tf contrib learn Experiment train,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 2 0 rc2 21 g12f033d' '1 2 0' Bazel version if compiling from source CUDA cuDNN version CUDA 8 0 44 libcudnn so 5 1 10 GPU model and memory N A Exact command to reproduce See below You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request tf estimator RunConfig does not have an environment attribute which is incompatible with the current implementation of tf contrib learn Experiment train L248 A workaround for local training is simply to set rc environment None in general I do not know whether a PR should add the attribute to tf estimator RunConfig or amend the implementation of tf contrib learn Experiment train to check for its existence Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"xiejw,xiejw",2017-06-25 00:44:27,2017-12-21 17:58:10
PR,Remove quantized matmul op for hexagon test in Windows build scripts,,,"snnn,yifeif",2017-12-21 03:55:07,2017-12-21 18:04:39
PR,Update API Docs,Updated api dos for SampleDistortedBoundingBox v1 and v2 to update tf image summary to tf summary image,,"yifeif,yifeif,yifeif",2017-12-20 23:08:57,2017-12-21 18:11:23
PR,XLA Use simplified version of TF ASSIGN OR RETURN for MSVC,This simplified version also works for GCC as well actually Split from 15310 15213,,"rongjiecomputer,tatatodd,tatatodd,tatatodd,rongjiecomputer,tatatodd,rongjiecomputer,tatatodd,tatatodd",2017-12-20 08:38:46,2017-12-21 18:12:54
PR,XLA Use tensorflow port Aligned Malloc Free,Split from 15310 15213,,"rongjiecomputer,sanjoy,rongjiecomputer,tatatodd",2017-12-20 08:36:06,2017-12-21 18:13:24
PR,Simple Recurrent Unit,As per issuecomment 352343576,,"tjingrant,asimshankar,gunan,tjingrant,yifeif,ebrevdo,tjingrant,tjingrant,ebrevdo,tjingrant,yifeif",2017-12-18 07:27:09,2017-12-21 18:13:47
IS,All the graph have an operation Retval that makes the train loop slow,I have tried to train the model in tf cnn benchmarks py and cifar10 multi gpu train py All the timelines results like the image bellow There is an operation named ' Retval' in the end of training loop But as we see long idle time was leaved in the timeline How can I make the training faster by getting rid of the operation ' Retval' Is there other method to let the gpu be at full power 2017 06 15 19 57 31 2017 06 15 19 58 33 The images above were got by the script python tf cnn benchmarks py local parameter device cpu num gpus 2 batch size 64 model vgg16 variable update independent optimizer sgd trace file home zhaoerchao timeline benchmark json distortions,,"aselle,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,yzhwang,zheng-xq",2017-06-15 12:00:24,2017-12-21 18:29:33
IS,solved session Create graph def No OpKernel was registered to support Op 'RandomUniform',issue crashes when loading pb file in C program Session session GraphDef graph def SessionOptions opts TF CHECK OK ReadBinaryProto Env Default heartPrintPbPathFile graph def TF CHECK OK NewSession opts session TF CHECK OK session Create graph def os linux train python inference C interface runtime error on inference part Non OK status session Create graph def status Invalid argument No OpKernel was registered to support Op 'RandomUniform' with these attrs Registered devices CPU Registered kernels no registered kernels Node rnn net rnn dropout 63 random uniform RandomUniform RandomUniform T DT INT32 dtype DT FLOAT seed 0 seed2 0 rnn net rnn dropout 63 Shape python train code with tf variable scope rnn net as scope cell for i in range num layers cell append tf nn rnn cell LSTMCell hidden size state is tuple True cell tf nn rnn cell MultiRNNCell cell cell tf nn rnn cell DropoutWrapper cell output keep prob self keep prob initial state cell zero state batch size tf float32 input list tf unstack conv output axis 1 rnn output tf nn static rnn cell input list dtype tf float32 self rnn output rnn output 1 print rnn output shape print self rnn output get shape hint one i found that if i delete this line cell tf nn rnn cell DropoutWrapper cell output keep prob self keep prob then the trained pb file can be loaded normally hint two beside rnn part i also have cnn part in the network and the dropout in cnn works just fine with tf variable scope conv net as scope filters 15 11 7 5 kernel size 64 64 32 32 input layer tf reshape self x 1 seq len 1 conv1 1 tf layers conv1d inputs input layer filters filters 0 kernel size kernel size 0 padding same activation tf nn tanh name 'conv1 1' conv1 2 tf layers conv1d inputs conv1 1 filters filters 1 kernel size kernel size 1 padding same activation tf nn tanh pool1 tf layers max pooling1d inputs conv1 2 pool size 4 strides 4 bn1 batch norm pool1 self is train scope 'bn1' dropout1 tf layers dropout inputs bn1 rate 1 self keep prob conv2 1 tf layers conv1d inputs dropout1 filters filters 2 kernel size kernel size 2 padding same activation tf nn tanh name 'conv2 1' conv2 2 tf layers conv1d inputs conv2 1 filters filters 3 kernel size kernel size 3 padding same activation tf nn tanh pool2 tf layers max pooling1d inputs conv2 2 pool size 4 strides 4 bn2 batch norm pool2 self is train scope 'bn2' dropout2 tf layers dropout inputs bn2 rate 1 self keep prob conv3 1 tf layers conv1d inputs dropout2 filters filters 2 kernel size kernel size 2 padding same activation tf nn tanh conv3 2 tf layers conv1d inputs conv3 1 filters filters 3 kernel size kernel size 3 padding same activation tf nn tanh pool3 tf layers max pooling1d inputs conv2 2 pool size 2 strides 2 conv output pool3,,,2017-12-21 03:35:22,2017-12-21 18:43:29
PR,bugfix long is 32 bits on Windows,Please avoid to use 'long' as data type result 2147483648,,"snnn,yifeif",2017-12-20 08:25:56,2017-12-21 18:43:42
IS,No PyPi package for Tensorflow 1 4 on Windows,Running Windows 10 with Python 3 6 Just wondering when that is gonna come out,,"Carmezim,gunan",2017-12-21 03:58:55,2017-12-21 18:55:25
PR,fix random distributions test,iota is declared in numeric,,"snnn,yifeif",2017-12-21 08:28:01,2017-12-21 19:02:34
PR,XLA Define ssize t for Windows,Split from 15310 15213,,"rongjiecomputer,tatatodd,tatatodd,mrry,rongjiecomputer,tatatodd,rongjiecomputer,snnn,rongjiecomputer,snnn",2017-12-20 08:37:06,2017-12-21 19:12:36
IS,sparse multiclass hinge loss Error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N OS Platform and Distribution e g Linux Ubuntu 16 04 Windows MacOS TensorFlow installed from source or binary N TensorFlow version use command below 1 4 Python version 2 7 Bazel version if compiling from source N GCC Compiler version if compiling from source N CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce See below Describe the problem There seems to be a bug in sparse multiclass hinge loss as per the example below Source code logs make tensor proto values dtype shape verify shape 369 else 370 if values is None 371 raise ValueError None values not supported 372 if dtype is provided forces numpy array to be the type 373 provided if possible ValueError None values not supported,,"facaiy,petrosmol,facaiy,petrosmol",2017-12-19 11:52:38,2017-12-21 19:13:03
PR,support unknown shape for sparse multiclass hing loss,Fix 15480 How to test x add test case pass all tests,,"facaiy,yifeif",2017-12-21 06:29:42,2017-12-21 19:13:03
PR,Add the C gradient of the Prod operation,This PR adds the gradient of the Prod operation to the C API,,"theflofly,alextp,theflofly,drpngx,theflofly,alextp,yifeif,theflofly,yifeif,yifeif,theflofly",2017-11-09 22:05:52,2017-12-21 19:13:16
PR,Fix typos,fix typos,,ManHyuk,2017-12-21 19:46:04,2017-12-21 20:36:11
PR,Update Imageops Docs,Created using update api def sh and tested using api test all tests passed INFO Build completed successfully 2 total actions tensorflow core api test PASSED in 0 1s Executed 1 out of 1 test 1 test passes There were tests whose specified size is too big Use the test verbose timeout warnings command line option to see which ones these are,,,2017-12-21 06:33:12,2017-12-21 20:36:37
PR,Branch 179822007,,,"yifeif,yifeif,yifeif",2017-12-21 19:02:46,2017-12-21 20:37:30
PR,Update layers pull request,I have created a new pull request by updating the unit test cases with reference to my previous pull request I have already updated layers py initially by checking for beta in the if condition The initial pull request was raised in accordance with the issue Please verify and get back,,"shreyneil,shreyneil,vrv,shreyneil,yifeif,shreyneil,yifeif,shreyneil",2017-11-22 06:53:26,2017-12-21 22:44:22
IS,DIGITS tensorflow distributed problem Graph is finalized and cannot be modified,I am a DIGITS novice and I want to change the TensorFlow single machine from DIGITS to distributed The following is the code that I modified sv tf train Supervisor is chief FLAGS task index 0 logdir ' root digits digits jobs hello' saver saver init op init op with sv prepare or wait for session server target as sess inf model start queue runners sess val model start queue runners sess train model start queue runners sess try while not train model queue coord should stop summary str step sess run train model train train model summary train model global step feed dict feed dict options run options run metadata run metadata and run it but error 2017 12 19 06 56 23 696588 I tensorflow core distributed runtime master session cc 999 S tart master session ad6a96f02b5d215f with config INFO tensorflow Starting standard services 2017 12 19 06 56 23 INFO Starting standard services INFO tensorflow Starting queue runners INFO tensorflow Saving checkpoint to path root digits digits jobs xwk model ckpt 2017 12 19 06 56 23 INFO Starting queue runners 2017 12 19 06 56 23 INFO Saving checkpoint to path root digits digits jobs xwk model ck ptINFO tensorflow Errorreported to Coordinator exceptions KeyError 'pyfunc 1' Node val data data reader PyFuncTin DT STRING Tout DT STRING DT INT32 DT INT64 DT INT32 token pyfunc 1 device job ps replica 0 task 0 cpu 0 2017 12 19 06 56 23 INFO Error reported to Coordinator exceptions KeyError 'pyfunc 1' Node val data data reader PyFuncTin DT STRING Tout DT STRING DT INT32 DT INT64 DT INT32 token pyfunc 1 device job ps replica 0 task 0 cpu 0 INFO tensorflow root digits digits jobs xwk model ckpt is not in all model checkpoint pat hs Manually adding it 2017 12 19 06 56 24 INFO root digits digits jobs xwk model ckpt is not in all model che ckpoint paths Manually adding it 2017 12 19 06 56 24 INFO Starting queue runners val Traceback most recent call last File root digits digits tools tensorflow main py line 779 in tf app run File usr local lib python2 7 dist packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File root digits digits tools tensorflow main py line 629 in main val model start queue runners sess File root digits digits tools tensorflow model py line 208 in start queue runners tf add to collection digits GraphKeys QUEUE RUNNERS qr File usr local lib python2 7 dist packages tensorflow python framework ops py line 4 248 in add to collection get default graph add to collection name value File usr local lib python2 7 dist packages tensorflow python framework ops py line 2 792 in add to collection self check not finalized File usr local lib python2 7 dist packages tensorflow python framework ops py line 2 181 in check not finalized raise RuntimeError Graph is finalized and cannot be modified RuntimeError Graph is finalized and cannot be modified Do you know what is the cause of the final problem If you know please tell me thx,,snnn,2017-12-21 06:56:05,2017-12-21 23:32:25
IS,Has this issue been solved for all containers ImportError cannot import name audio ops,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I am running the tutorial audio recognition network OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 'v1 0 0 rc2 15 g47bba63 dirty' '1 0 0' Python version 2 7 6 Bazel version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce python tensorflow examples speech commands train py Describe the problem I pip installed tensorflow using virtualenv Then I run python tensorflow examples speech commands train py for which the following error message appears Traceback most recent call last File home cogknit tensorflow tensorflow examples speech commands train py line 79 in module import input data File home cogknit tensorflow tensorflow examples speech commands input data py line 35 in module from tensorflow contrib framework python ops import audio ops as contrib audio ImportError cannot import name audio ops In stack overflow I came across the same issue only with anaconda install in the following link There the answer indicated that the audio ops py file is missing from the framework and has not been released yet This indication seems to be validated by a developer in the following link and recently an update seems to have been made released per the same link My question in particular is does the release solve the error in virtualenv installation too Or has not it been solved at all Is it better to move to a docker installation Are there any alternatives commands that I can use to circumvent this error 12722 dealt with the same error but the solution seems to have worked only for tensorflow built from source Is there anything that I should check again Thank you,,"reedwm,reedwm",2017-09-14 09:20:02,2017-12-21 23:47:33
IS,Standalone graph trained using on NCHW data format giving errors on CPU when testing running forward pass,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Binary whl file TensorFlow version use command below 1 2 0 rc1 Python version 2 7 Bazel version if compiling from source N A CUDA cuDNN version CUDA 8 0 61 CuDNN 5 1 10 GPU model and memory GeForce GTX 1080 Exact command to reproduce Describe the problem I have a standalone graph create by freezing my model net which has a few slim conv2d slim max pool2d operations defined with NCHW data format I have used freeze graph py utility to create the stand alone graph using a trained checkpoint trained using NCHW format When I tested the graph ran forward pass on a Ubuntu machine with GPU it was running very well But when I ran the same code to test forward pass with the same stand alone graph a Ubuntu machine that has no GPU but CPU I got the following errors I believe the errors are related to Is it possible to modify the stand alone graph that is running well on GPU to make it run successfully on CPU machine Is it possible to avoid retraining the model using NHWC format and recreate the standalone model Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"aselle,petewarden,aselle,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit,zhangyaobit",2017-09-19 06:29:48,2017-12-22 00:09:51
IS,ONNX Model Support,Please add support for the ONNX open model standard or a conversion tool would be great,,,2017-12-21 16:51:24,2017-12-22 00:13:48
IS,How do I compile Tensorflow source with Altera FPGA library AOCLUtils OPENCL,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version 1 3 Python version v2 7 10 Bazel version 0 5 4 Exact command to reproduce set all as default value configure not use cuda Describe the problem I am studying posting matmul op calculation into Altera FPGA Arria 10 via OPENCL and combine source and OpenCL AOCLUtils library as python package However I encountered much problem about this and always build Bazel failed when compile The following share some experience in every stages and some problem over the past month AOCLUtils library package pre code AOCLUtils BUILD for bazel AOCLUtils aocl utils h AOCLUtils opencl h AOCLUtils options h AOCLUtils opencl cpp AOCLUtils options cpp AOCLUtils scoped ptrs h code pre OPENCL header library package in home mater intelFPGA pro 17 0 hld host include compiled library so in home mater intelFPGA pro 17 0 hld host linux64 lib home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib pre code CL cl d3d10 h CL cl ext h CL cl gl h CL cl hpp CL opencl h CL cl ext altera h CL cl gl ext h CL cl h CL cl platform h code pre 1 Study third party library SYCL Seems not support Altera FPGA Original tensorflow supports OpenCL via SYCL However it only seems support GPU CPU not Altera FPGA Besides I gave up this method 2 Success build a New external Op with AOCLUtils OPENCL via g but it is my purpose Refer I study example for a new op and build as library with AOCLUtils OPENCL The g command is as follow then built as zero out cl so Tensorflow can load this external library and run some calculation in FPGA zero out module tf load op library ' zero out all so' Although my purpose is tensorflow python installation with AOCLUtils OPENCL library it makes sure that tensorflow can support FPGA library pre code g std c 11 shared main cpp o zero out cl so fPIC I home mater tensorflowCPU 1 3 lib python2 7 site packages tensorflow include I home mater intelFPGA 17 0 hld host include home mater AI FPGA TF OPENCL ZeroOut common src AOCLUtils opencl cpp home mater AI FPGA TF OPENCL ZeroOut common src AOCLUtils options cpp L home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib L home mater intelFPGA pro 17 0 hld host linux64 lib Wl no as needed lalteracl laltera a10 ref mmd lelf I home mater AI FPGA TF OPENCL ZeroOut common inc O2 D GLIBCXX USE CXX11 ABI 0 code pre 3 Modify Tensorflow source code with AOCLUtils OPENCL and always bazel build failed step 1 git clone into home mater git test tensorflow opencl tensorflow root folder step 2 copy AOCLUtils package into tensorflow root folder step 3 Add cc library into WORKSPACE for external opencl library not sure correct method pre code new local repository name opencl headers path home mater intelFPGA pro 17 0 hld host include build file content cc library name CL hdrs glob CL h visibility visibility public linkopts shared new local repository name opencl libs path home mater intelFPGA pro 17 0 hld host linux64 lib build file content cc library name libopencl srcs glob so visibility visibility public linkopts shared new local repository name a10 lib path home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib build file content cc library name liba10 srcs libaltera a10 ref mmd so visibility visibility public linkopts shared code pre step 4 Add BUILD file into AOCLUtils folder pre code cc library name aocutils srcs glob cpp hdrs glob h deps opencl libs libopencl opencl headers CL a10 lib liba10 visibility visibility public code pre step 5 Add deps into tf kernel library in tensorflow root folder tensorflow core kernels BUILD I would like to run matmul op calculation in FPGA so try to include FPGA library pre code tf kernel library name matmul op deps MATH DEPS AOCLUtils aocutils code pre I tried 3 methods to build tensorflow source code as python installation package but always failed step 6A Original bazel build command Failed situation A Use original Bazel build command but failed to find CL library exception fatal error CL cl h No such file or directory command pre code bazel build config opt tensorflow tools pip package build pip package verbose failures cxxopt D GLIBCXX USE CXX11 ABI 0 code pre result pre code ERROR home mater git test tensorflow opencl AOCLUtils BUILD 1 1 C compilation of rule ' AOCLUtils aocutils' failed Exit 1 gcc failed error executing command cd home mater cache bazel bazel mater cf4207c477b73da1da7e3336942f640b execroot org tensorflow exec env PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF NEED CUDA 0 TF NEED OPENCL 0 usr bin gcc U FORTIFY SOURCE fstack protector Wall B usr bin B usr bin Wunused but set parameter Wno free nonheap object fno omit frame pointer g0 O2 ' D FORTIFY SOURCE 1' DNDEBUG ffunction sections fdata sections ' march native' ' std c 0x' ' march native' ' D GLIBCXX USE CXX11 ABI 0' MD MF bazel out local opt bin AOCLUtils objs aocutils AOCLUtils options pic d ' frandom seed bazel out local opt bin AOCLUtils objs aocutils AOCLUtils options pic o' fPIC iquote iquote bazel out local opt genfiles iquote external opencl libs iquote bazel out local opt genfiles external opencl libs iquote external bazel tools iquote bazel out local opt genfiles external bazel tools iquote external opencl headers iquote bazel out local opt genfiles external opencl headers iquote external a10 lib iquote bazel out local opt genfiles external a10 lib isystem external bazel tools tools cpp gcc3 fno canonical system headers Wno builtin macro redefined ' D DATE redacted ' ' D TIMESTAMP redacted ' ' D TIME redacted ' c AOCLUtils options cpp o bazel out local opt bin AOCLUtils objs aocutils AOCLUtils options pic o In file included from AOCLUtils opencl h 32 0 from AOCLUtils aocl utils h 27 from AOCLUtils options cpp 22 external opencl headers CL opencl h 42 19 fatal error CL cl h No such file or directory compilation terminated Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 12 957s Critical Path 5 11s FAILED Build did NOT complete successfully code pre step 6B Add link path in command Failed situation B Use original Bazel build command with CL external path included but failed to missing dependency declarations exception missing dependency declarations for the following files included by 'AOCLUtils options cpp' I think this method should be ok and bazel can find CL library location but I can not understand what happen for this I study some information about 'missing dependency declarations' and found 'CROSSTOOL' for GPU for this title It did not help me to solve it because I do not use GPU configuration command like building a New external Op method pre code bazel build config opt tensorflow tools pip package build pip package copt I home mater intelFPGA 17 0 hld host include verbose failures copt L home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib copt L home mater intelFPGA pro 17 0 hld host linux64 lib cxxopt D GLIBCXX USE CXX11 ABI 0 code pre result pre code ERROR home mater git test tensorflow opencl AOCLUtils BUILD 1 1 undeclared inclusion s in rule ' AOCLUtils aocutils' this rule is missing dependency declarations for the following files included by 'AOCLUtils options cpp' ' home mater intelFPGA 17 0 hld host include CL cl h' ' home mater intelFPGA 17 0 hld host include CL cl platform h' ' home mater intelFPGA 17 0 hld host include CL cl gl h' ' home mater intelFPGA 17 0 hld host include CL cl gl ext h' ' home mater intelFPGA 17 0 hld host include CL cl ext h' ' home mater intelFPGA 17 0 hld host include CL cl ext altera h' In file included from home mater intelFPGA 17 0 hld host include CL cl ext h 42 0 from external opencl headers CL opencl h 45 from AOCLUtils opencl h 32 from AOCLUtils aocl utils h 27 from AOCLUtils options cpp 22 home mater intelFPGA 17 0 hld host include CL cl ext altera h 442 0 warning ignoring pragma warning Wunknown pragmas pragma warning push home mater intelFPGA 17 0 hld host include CL cl ext altera h 443 0 warning ignoring pragma warning Wunknown pragmas pragma warning disable 4201 home mater intelFPGA 17 0 hld host include CL cl ext altera h 459 0 warning ignoring pragma warning Wunknown pragmas pragma warning pop Target tensorflow tools pip package build pip package failed to build code pre step 6C Build AOCLUtils as library AOCUtils so at first then build tensorflow with this library Failed situation C Due to the below two situation I tried to build AOCUtils package as library Maybe it can skip some exception for CL library missing Although it passed c code compiled and continue to build about 10 minutes below two situation show failed message immediately it still be failed at packaging python due to not find AOCLUtils First command for AOCUtils so pre code g std c 11 shared AOCLUtils opencl cpp AOCLUtils options cpp o AOCLUtils AOCUtils so fPIC I home mater tensorflowCPU 1 3 lib python2 7 site packages tensorflow include I home mater intelFPGA 17 0 hld host include L home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib L home mater intelFPGA pro 17 0 hld host linux64 lib Wl no as needed lalteracl laltera a10 ref mmd lelf I home mater git test tensorflow opencl O2 D GLIBCXX USE CXX11 ABI 0 code pre Modify AOCLUtils BUILD pre code cc library name aocutils srcs AOCLUtils so hdrs glob h visibility visibility public code pre Second command for build pre code bazel build config opt tensorflow tools pip package build pip package copt I home mater intelFPGA 17 0 hld host include verbose failures copt L home mater intelFPGA pro 17 0 hld board a10 ref linux64 lib copt L home mater intelFPGA pro 17 0 hld host linux64 lib cxxopt D GLIBCXX USE CXX11 ABI 0 code pre result pre code ERROR home mater git test tensorflow opencl tensorflow python BUILD 2908 1 Linking of rule ' tensorflow python pywrap tensorflow internal so' failed Exit 1 gcc failed error executing command cd home mater cache bazel bazel mater cf4207c477b73da1da7e3336942f640b execroot org tensorflow exec env PWD proc self cwd PYTHON BIN PATH usr bin python PYTHON LIB PATH usr local lib python2 7 dist packages TF NEED CUDA 0 TF NEED OPENCL 0 usr bin gcc shared o bazel out local opt bin tensorflow python pywrap tensorflow internal so ' Wl rpath ORIGIN solib k8 U S SAOCLUtils Caocutils UAOCLUtils' Lbazel out local opt bin solib k8 U S SAOCLUtils Caocutils UAOCLUtils Wl version script tensorflow tf version script lds pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread pthread ' fuse ld gold' Wl no as needed Wl z relro z now B usr bin B usr bin pass exit codes Wl gc sections Wl bazel out local opt bin tensorflow python pywrap tensorflow internal so 2 params usr bin ld gold error cannot find lAOCLUtils collect2 error ld returned 1 exit status Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 817 337s Critical Path 40 20s FAILED Build did NOT complete successfully code pre Could someone help me find some suggestion or share information about this Thanks,,"shivaniag,martinwicke,martinwicke",2017-09-19 07:21:14,2017-12-22 02:45:19
IS,TensorFlow automatically modify variable scope name,check the following code I dont know why TF just modify the variable scope name while i try to add a new placeholder into the existed scope Is it a BUG,,facaiy,2017-12-22 07:08:33,2017-12-22 07:39:35
PR,Make GANEstimator global step inc dependent on gen and dis losses,This solves a non deterministic problem that prevents to use global step in tf cond during training See also issuecomment 351212183,,"joel-shor,joel-shor,joel-shor",2017-12-12 22:40:46,2017-12-22 09:51:06
IS,Dataset shuffle operation is not deterministic,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 elementary OS 0 4 1 Loki TensorFlow installed from source or binary binary TensorFlow version v1 4 0 19 ga52c8d9 1 4 1 Python version 3 5 2 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version Not related GPU model and memory Not related Exact command to reproduce mentioned below Describe the problem Dataset Shuffle operation is not determenastic Source code logs test code sample taken from,,mrry,2017-12-22 01:07:43,2017-12-22 15:12:54
IS,Tensorflow 1 4 C API considerably slower than Python,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source with all optimizations TensorFlow version use command below 1 4 Python version 3 5 2 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 8 0 6 0 GPU model and memory GTX960M Describe the problem I was trying to run several models and evaluate the performance with different batch sizes in python and c and noticed that the c API version is considerably slower than the python one Both were compiled with the same optimizations and with cuda support When I try to predict the output of a single 256x256 image in python it takes me 0 5 seconds and when i do it in tensorflow c api it takes me 1 7 seconds Notice that in python I was using a non deployed model without freezing and transforming graph whereas in C I did those transformations Does anyone knows why this is happening Is it because of the frozen and transformed graph I always thought the C API would be at least as fast as the Python version,,,2017-12-21 11:13:17,2017-12-22 16:20:14
PR,Refactor methods for path calculation,This allows other scripts to access this logic This is what I meant,,"Androbin,Androbin,gunan,Androbin,gunan,Androbin,Androbin,martinwicke,Androbin,martinwicke,martinwicke,martinwicke,Androbin,Androbin,Androbin,Androbin,yifeif,Androbin,martinwicke,Androbin,Androbin,Androbin,Androbin,gunan,Androbin,gunan,Androbin,Androbin,Androbin,Androbin,Androbin,jart,Androbin,jart,Androbin,jart,jart",2017-12-12 13:56:10,2017-12-22 18:25:07
IS,why keras run slower and slower,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,jart,2017-12-22 03:35:22,2017-12-22 18:58:36
IS,tf profiler reports 0B memory usage,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0 dev20171103 Python version 3 5 Exact command to reproduce total bytes is what the profiler reports as requested bytes above It seems like that data is not being updated in the run metadata The correct value is in memory stats host persistent memory size but that value is not available in the profiler output And according to the profiler proto that value is supposed to represent the bytes allocated to persistent objects like Variables even though none of the values in the example are persistent So I'm not sure if this is an issue with tf profiler or with how memory information is stored in RunMetadata,,"drasmuss,tatatodd,drasmuss,drasmuss,yaroslavvb",2017-11-28 23:25:49,2017-12-22 19:04:56
PR,Refactor methods for path calculation,jart I really appreciate your advice I have rewritten 15315 to be more boring get grandparent path degree a files grandparent of the given degree get abs data path path depth frame 0 path relative to a file upwards the callstack get data files path frame 0 no change in behavior but now shared with other methods They should be about boring enough to be useful and to be shared This should resolve the issues with get data files path by making it less brittle And I think get abs data path is how get path to datafile should really look like Further thoughts on this are appreciated,,"Androbin,jart,Androbin,Androbin",2017-12-22 19:48:27,2017-12-22 20:00:32
IS,'tensorflow contrib reduce slice ops objs python ops reduce slice ops gpu tensorflow contrib reduce slice ops kernels reduce slice ops gpu cu pic o' was not created,Hi i'm running the tensorflow from the source and after building the tensorflow using bazel using below command bazel build config opt config cuda tensorflow tools pip package build pip package The error message pasted below 10 errors detected in the compilation of home lb cache bazel bazel lb 144f5944ef8ff562c57e67fdaa41565f execroot org tensorflow tmpae8 5f0170552fd082f4 tmpxft 0000245c 00000000 6 reduce slice ops gpu cu cpp1 ii ERROR home lb WorkSpace AI WORK tensorflow tensorflow contrib reduce slice ops BUILD 14 1 output 'tensorflow contrib reduce slice ops objs python ops reduce slice ops gpu tensorflow contrib reduce slice ops kernels reduce slice ops gpu cu pic o' was not created ERROR home lb WorkSpace AI WORK tensorflow tensorflow contrib reduce slice ops BUILD 14 1 not all outputs were created or valid Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 74 030s Critical Path 8 38s FAILED Build did NOT complete successfully,,jart,2017-12-22 06:40:28,2017-12-22 20:05:30
IS,decode image resize images workflow does not work,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Performing resize images with output of decode image Describe the problem This problem was addressed in but was closed and are also relevant The basic problem is that the output of tf image decode image cannot be passed to tf image resize images It raises ValueError 'images' contains no shape in the call to resize images Possible workarounds to this include using decode jpeg decode png or adding decoded image set shape None None None before calling tf image resize images However as pointed out in 1029 nothing about the underlying op requires knowing a static shape Source code logs decoded image tf image decode jpeg tf read file image filename tf image resize images decoded image 100 100,,"yongtang,andreas-eberle,yongtang,jart,jart,andreas-eberle",2017-11-03 18:27:06,2017-12-22 20:12:36
IS,Linux GPU build failing CUDACC VER is no longer supported,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 10 kernel 4 14 8 TensorFlow installed from source or binary Source failed build TensorFlow version use command below master Python version 3 6 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 4 9 CUDA cuDNN version 9 0 7 0 4 GPU model and memory Two 1080 Ti 11Gb each Exact command to reproduce bazel build c opt copt mavx copt mavx2 copt mfma copt mfpmath both copt msse4 2 config cuda tensorflow tools pip package build pip package Describe the problem I note the build bot is failing too for Linux GPU since the latest merge in the past 1 hour Source code logs ERROR home daniel build tensorflow tensorflow contrib image BUILD 106 1 error while parsing d file home daniel cache bazel bazel daniel a40ff47569db15fec953d4e5b5812083 execroot org tensorflow bazel out k8 py3 opt bin tensorflow contrib image objs python ops distort image ops gpu tensorflow contrib image kernels adjust hsv in yiq op gpu cu pic d No such file or directory In file included from usr local cuda 9 0 bin targets x86 64 linux include common functions h 50 0 from usr local cuda 9 0 bin targets x86 64 linux include cuda runtime h 115 from command line 0 usr local cuda 9 0 bin targets x86 64 linux include crt common functions h 64 24 error token CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead is not valid in preprocessor expressions define CUDACC VER CUDACC VER is no longer supported Use CUDACC VER MAJOR CUDACC VER MINOR and CUDACC VER BUILD instead tensorflow core util cuda device functions h 37 7 note in expansion of macro ' CUDACC VER ' elif CUDACC VER 7050 Target tensorflow tools pip package build pip package failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 237 382s Critical Path 22 79s,,"reedwm,jart",2017-12-21 21:53:54,2017-12-22 20:58:44
IS,tf contrib learn KMeansClustering squeeze problem when using predict,This is a problem with every version of tensorflow I have tried 1 1 1 2 1 3 After using the fit method train a KMeansClustering model if the predict method is used to predict a single data point is cluster then there is an internal error predicting two data points works fine In tensorflow contrib learn python learn estimators estimator py in predict generator the batch length is rightly determined by asking for the first dimension of the shape but the problem is at least for KMeansClustering tensorflow contrib factorization python ops clustering ops py infer graph uses tf squeeze to remove all dimensions with size of 1 for the distances and indices An error occurs when computing batch size because the value will have rank 0 after the squeeze This appears to have been there since gardener originally imported that code for computing kmeans A This certainly does not need to squeeze the first dimension as in my case if predict is called for a single value then the distances and indices are both just one element B I cannot really see why a squeeze should be done there in the first place Perhaps flatten that does not make sense either I have a pull request ready which just removes the squeeze But I wanted to file an issue to which the original developer might be able to comment Or I can try to make it squeeze all but the first dimension though the shape of those tensors are unknown when the graph is built I will have to figure out how to do that I would prefer to just not squeeze if it is not necessary Here is a script that demonstrates the problem Removing the squeeze in clustering ops py fixes this script is problem or give it two data points to predict,,reedwm,2017-07-24 02:17:40,2017-12-22 22:27:10
PR,Apply rc0 cherry picks,Excludes,,angersson,2017-12-22 19:10:54,2017-12-22 22:29:05
IS,lite model file size,how to reduce my model size my own trained tensorflow model i want to use tensorflow lite converter get a smaller tflite file but the tflite file has the same size with my trained model bazel bin tensorflow contrib lite toco toco allow custom ops input file data log frozen model pb input format TENSORFLOW GRAPHDEF output format TFLITE output file data log mobilenet tflite inference type FLOAT input data types FLOAT input arrays input output arrays output input shapes 1 224 224 3,,jart,2017-12-22 13:22:38,2017-12-22 22:30:39
IS,how to build tensorflow lite so for linux ubuntu thanks,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,jart,2017-12-21 07:29:59,2017-12-22 22:46:30
PR,Branch 179953488,push,,"ekelsen,ekelsen,yifeif,martinwicke,yifeif",2017-12-22 21:05:48,2017-12-22 23:55:38
PR,Fix allow smaller final batches for bucket by sequence length,Fixes 8182,,"ebrevdo,jhseu,ebrevdo,ebrevdo",2017-11-09 20:59:56,2017-12-22 23:56:19
IS,Possible Bug with GPU matmul op cc,Hello I am trying to run a matrix multiplication on GPU This is the code i am running on python Is it a possible bug or i am doing something wrong,,"ppwwyyxx,jart",2017-12-19 17:00:18,2017-12-23 00:20:22
IS,Image Input for GridLSTM,I would like to use GridLSTM for a handwriting recognition task Unfortunately the documentation is lacking info on how to input images into GridLSTMs,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,jart",2017-12-20 03:23:17,2017-12-23 00:27:25
IS,Tensorflow Website XSRF Token missing or incorrect,The error occurs when I read current TF API documentation My default lang is set to Russian but it does not matter and has influence only on the bottom menu But when I'm trying to change the language to English or Chinese I get the following error message XSRF Token missing or incorrect Is it ok or this is the TF Website bug Windows 10 Firefox 56 0 2 x64 1setlang 2xsrf,,"MarkDaoust,jart",2017-11-14 07:19:58,2017-12-23 02:18:04
IS,Using function defun and while loops,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below 1 4 0 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 6 GPU model and memory Tesla x Pascal 12gb Exact command to reproduce run defun while py You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Function defun when used alongside a while loop is throwing shape errors More explicitly when using a concatenation operation of sliced tensors with the loop variable the newly defined op throws no errors However when the slices are added to the loop variable it throws shape errors related to the while loop It might be an issue with the fetch argument that fails to work in this case The code along with a more detailed explanation can be found on Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"drpngx,alextp",2017-12-06 08:38:54,2017-12-23 03:31:03
IS,Tensorflow gpu 1 4 1 windows binaries could not be found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 1709 TensorFlow installed from source or binary looking for the binary TensorFlow version use command below 1 4 1 Python version 3 6 3 64 bit Exact command to reproduce pip3 install upgrade tensorflow gpu Describe the problem Ca not find the binaries for the 1 4 1 windows version,,snnn,2017-12-18 14:56:40,2017-12-23 04:25:35
IS,Tensorflow Installation Problem in Anaconda3 5 0 1Environment,After installing the Anaconda3 5 0 1 on Ubuntu 17 10 I have followed the following steps to install the Tesnorflow conda create n tensorflow python 3 6 source activate tensorflow tensorflow pip install ignore installed upgrade After installing the above pakages I have verified the above installation in Anaconda environment following issues are faced we6aisol we6aisol H170 Gaming 3 source activate tensorflow tensorflow we6aisol we6aisol H170 Gaming 3 python Python 3 6 3 Anaconda Inc default Nov 20 2017 20 41 42 GCC 7 2 0 on linux Type help copyright credits or license for more information import tensorflow as tf home we6aisol anaconda3 envs tensorflow lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds Please help me to resolve this issue Thanks Regards Manoj Bansal,,jart,2017-12-18 15:06:40,2017-12-23 04:44:57
PR,Relex restrictions on tf foldr and tf foldl,This fix tries to address the issue raised in 12019 where tf foldr and tf foldl only accpet first shape dimensions be identical for all list elements The issue comes from the implementation of tf foldr and tf foldl where the input elems is converted to tensor then converted to tensor array L100 L106 It is possible to bypass the conversion to tensor and go directly to tensor array as long as the input elems is Iterable and pass infer shape False This fix is an proposal to relex the restriction on tf foldr and tf foldl so that a list of elements with different shapes could be passed This fix fixes 12019 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,mrry,ebrevdo,facaiy,yongtang,yongtang,yongtang,ebrevdo,martinwicke,martinwicke,yongtang",2017-09-24 22:52:35,2017-12-23 07:34:48
IS,upgrade tensorflow 1 4 from 1 2 get undefined symbol error,I import c api of concat op and add tensorflow core kernels concat lib hdrs to the deps my code work ok based on tf1 2 when I upgrade tf to 1 4 compile and install is ok when I run my model I got the error as Traceback most recent call last File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow contrib own concat python ops own concat ops test py line 5 in module from tensorflow contrib import own concat File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow contrib own concat init py line 19 in module from tensorflow contrib own concat python ops own concat ops import File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow contrib own concat python ops own concat ops py line 11 in module resource loader get path to datafile ' own concat ops so' File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow contrib util loader py line 55 in load op library ret load library load op library path File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow python framework load library py line 56 in load op library lib handle py tf TF LoadLibrary library filename status File home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow python framework errors impl py line 473 in exit c api TF GetCode self status status tensorflow python framework errors impl NotFoundError home my work cache bazel bazel my work ce8941cb5767b65fdf1825ce866fc372 execroot org tensorflow bazel out local opt bin tensorflow contrib own concat own concat ops test runfiles org tensorflow tensorflow contrib own concat python ops own concat ops so undefined symbol ZN10tensorflow9ConcatCPUIfEEvPNS 10DeviceBaseERKSt6vectorISt10unique ptrINS 6TTypesIT Li2ElE11ConstMatrixESt14default deleteIS8 EESaISB EEPNS7 6MatrixE,,"allenlavoie,allenlavoie,allenlavoie",2017-12-22 09:50:52,2017-12-23 17:53:47
IS,error namespace Eigen half impl has no member half raw when building latest TensorFlow CUDA 9 0,When trying to build latest TensorFlow for CUDA 9 0 CuDNN 7 0 from today is head Complete instructions to reproduce are here but basically I followed steps in in Dockerfile devel gpu to install dependencies and then did bazel build c opt config cuda Here are the errors,,"yaroslavvb,gunan,yaroslavvb,gunan,caisq,caisq,gunan,samikama,gunan,reedwm,gunan,gunan",2017-12-04 23:24:06,2017-12-23 21:20:44
IS,error C2678 binary ' ' no operator found which takes a left hand operand of type IndicesRowIterator,If you build a debug version of the current tensorflow version 1 3 0 on Windows with CMAKE following error is occurred ClCompile target C Program Files x86 Microsoft Visual Studio 2017 Professional VC Tools MSVC 14 10 25017 include xutility 978 error C2678 binary ' ' no operator found which takes a left hand operand of type 'tensorflow boosted trees utils anonymous namespace' IndicesRowIterator' or there is no acceptable conversion compiling sou rce file C Development dev test projects deeplearning tensorflow tensorflow tensorflow contrib boosted trees lib utils sparse column iterable cc C Development de v test projects deeplearning tensorflow build64 tf core kernels vcxproj The reason is IndicesRowIterator operator is missing Adding these lines bool operator const IndicesRowIterator other const QCHECK LT iter other iter return row idx other row idx solves the problem System information tensorflow 1 3 0 Windows 10 VisualStudio 2017 CMake 3 8 1,,"shivaniag,gunan,yongtang,yongtang,gunan",2017-08-03 11:05:12,2017-12-23 21:30:47
PR,Update tf learn reference to TF Estimators,,,"terrytangyuan,caisq",2017-12-22 21:57:47,2017-12-23 22:47:10
PR,MKL Adding MKL DNN support for LRN op,,,claynerobison,2017-12-22 21:06:09,2017-12-24 01:12:06
IS,AttentionWrapper is not compatible with dynamic rnn,System information TensorFlow version v1 2 0 rc2 21 g12f033d 1 2 0 Python 3 Describe the problem The return of zero state function of tensorflow contrib seq2seq AttentionWrapper is not compatible with tensorflow nn dynamic rnn function It seems that if output shape ndims 0 in copy one through function does not work Once those scalar elements in return tuple are modified to have the shape like batch size the error disappears Code to reproduce the bug,,"shivaniag,lukaszkaiser,ebrevdo",2017-08-03 04:11:15,2017-12-24 12:16:55
IS,Cannot statically link against Tensorflow library in Golang,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below 1 4 0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce go build a v o hellotf ldflags ' linkmode external extldflags static L usr local lib ' x GITHUB PROJ NAME hellotf Describe the problem I'm trying to compile a statically linked binary of the hello world app against the TF 1 4 0 binary per the golang install hello world instructions and am not able to successfully link against the TF library as it reports that ltensorflow cannot be found by usr bin ld in the go build The command used is go build a v o hellotf ldflags ' linkmode external extldflags static L usr local lib ' x GITHUB PROJ NAME hellotf I have tried linking against usr local lib where libtensorflow lives using extldflags CGO LDFLAGS LDFLAGS etc done sudo ldconfig and the env setup with LD LIBRARY PATH and LIBRARY PATH but cannot move past this step and always get the error status The only related issue I have encountered for this is but that did not help much either That being said I can dynamically link and build the helloworld go code e g go build hello tf go and go test github com tensorflow tensorflow tensorflow go all work successfully the issue arises when I try to statically link and cannot link to libtensorflow after it compiles no matter what settings I try using Any help or advice would be greatly appreciated Thanks,,asimshankar,2017-12-21 20:35:00,2017-12-24 18:10:46
PR,R1 4,,,drpngx,2017-12-23 07:29:24,2017-12-25 02:18:33
PR,Branch 180008567,,,caisq,2017-12-24 16:46:22,2017-12-25 02:42:53
IS,I cannot use Binomial sample could you please help me,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2017-12-25 07:28:37,2017-12-25 18:11:25
IS,Cannot compute output tensor of tf keras layers Lambda tf unstack,System information Have I written custom code Yes OS Platform and Distribution Ubuntu 16 04 TensorFlow installed from binary TensorFlow version tf nightly 1 5 0 dev20171224 Python version 3 5 4 Source code This is a tiny code that creates a model which stacks and unpacks input tensors,,,2017-12-25 15:34:14,2017-12-25 19:50:58
PR,MKL Reverting PR 14478 which breaks Inception v3 with MKL,PR 14478 based on commit e7b69e4 removed line 276 from ifdef INTEL MKL section and breaks Inception v3 with MKL Perhaps someone meant to remove line 202,,claynerobison,2017-12-21 23:12:36,2017-12-26 00:11:05
PR,Clean bazel all files targets,Broken out of 15166,,"Androbin,Androbin,Androbin,yifeif,martinwicke,jart,martinwicke,jart,martinwicke,drpngx,Androbin,drpngx,Androbin,martinwicke,gunan,martinwicke,gunan,yifeif,drpngx",2017-12-14 16:58:32,2017-12-26 02:06:23
PR,Add missing stdio h include,Add missing stdio h include in tensorflow contrib lite kernels op macros h Otherwise it fails to find stderr To reproduce it,,"bryant1410,drpngx",2017-11-29 13:57:54,2017-12-26 02:37:46
IS,No gradient defined for op Pow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 x64 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Bazel version N A Python version None CUDA cuDNN version None GPU model and memory None Exact command to reproduce Describe the problem It seems there is no gradient defined for the Pow operation in the C API I am actually transferring this issue from Similar to the case of Select 14845 it seems there is also no gradient for the Pow operation in the C API,,facaiy,2017-12-09 20:09:30,2017-12-26 04:48:52
PR,add c gradient for op Pow,Fix 15239 How to test x add test case pass all tests,,"facaiy,suharshs,suharshs,caisq,facaiy,facaiy,drpngx,facaiy,caisq,drpngx,gunan",2017-12-10 06:48:33,2017-12-26 04:48:52
PR,Branch 180053468,,,"drpngx,drpngx",2017-12-26 01:09:22,2017-12-26 04:53:52
IS,ImportError libmklml intel so cannot open shared object file No such file or directory,GPU 1080 Ti cuda 9 0 cuddn 7 0 v7 centos 7 installed Intel MKL DNN but the error is still present here is the output,,,2017-12-25 21:05:09,2017-12-26 06:45:20
IS,vm compiled tensorflow libmklml intel so ImportError,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 VM TensorFlow installed from source or binary Source TensorFlow version use command below Branch r1 4 and branch master Python version 3 6 3 Bazel version if compiling from source Build label 0 8 1 Install using apt repository GCC Compiler version if compiling from source gcc 6 Ubuntu 6 4 0 10ubuntu1 16 04 york0 6 4 0 20171112 Exact command to reproduce python c import tensorflow as tf Describe the problem After compiling Tensorflow from source with tutorial and install the compiled pip package I import tensorflow on python console and get those errors python c import tensorflow as tf Traceback most recent call last File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home potatoman anaconda3 lib python3 6 imp py line 243 in load module return load dynamic name filename file File home potatoman anaconda3 lib python3 6 imp py line 343 in load dynamic return load spec ImportError libmklml intel so cannot open shared object file No such file or directory During handling of the above exception another exception occurred Traceback most recent call last File string line 1 in module File home potatoman anaconda3 lib python3 6 site packages tensorflow init py line 24 in module from tensorflow python import File home potatoman anaconda3 lib python3 6 site packages tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow py line 73 in module raise ImportError msg ImportError Traceback most recent call last File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File home potatoman anaconda3 lib python3 6 site packages tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description File home potatoman anaconda3 lib python3 6 imp py line 243 in load module return load dynamic name filename file File home potatoman anaconda3 lib python3 6 imp py line 343 in load dynamic return load spec ImportError libmklml intel so cannot open shared object file No such file or directory Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace above this error message when asking for help My machine is a headless KVM virtual machine running on a ubuntu 17 10 btw I figure out where the problem is somehow which is the pip packaging script do not include those mkl so files and in my case replace solib k8 in script tensorflow tools pip package setup py at line 185 with solib local solves the issue,,"drpngx,drpngx",2017-12-10 16:43:46,2017-12-26 12:10:34
PR,Update HTTP HTTPS,URLs updated to use HTTPS protocol where appropriate to improve security and privacy,,,2017-12-25 18:13:07,2017-12-26 15:13:35
IS,tf name scope does not work with tf layers,When I define a layer with and try to get its variables with tf global variables scope MY SCOPE it returns nothing because name scope did not apply to the layers from tf layers Should not their name be tf Variable 'MY SCOPE layer1 kernel 0' shape 784 100 dtype float32 ref tf Variable 'MY SCOPE layer1 bias 0' shape 100 dtype float32 ref instead of tf Variable 'layer1 kernel 0' shape 784 100 dtype float32 ref tf Variable 'layer1 bias 0' shape 100 dtype float32 ref so that I can use my scope to reach my layers This works with everything but tf layers module,,"facaiy,asimshankar,facaiy",2017-12-25 18:39:45,2017-12-26 18:06:27
PR,Add support for CUBLAS TENSOR OP MATH in fp16 GEMM,Applies to matrix multiplications with fp16 input output Computations will fall back to pseudo fp16 if tensor op math is disabled or not supported Enabled by default but can be disabled by setting the environment variable TF DISABLE TENSOR OP MATH 1,,"nluehr,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,zheng-xq,yzhwang,yzhwang,nluehr,nluehr,nluehr,nluehr,nluehr,nluehr,yzhwang,yzhwang,yzhwang,yzhwang,yzhwang,nluehr,nluehr,yzhwang,yzhwang,nluehr,nluehr,yzhwang,zheng-xq,zheng-xq,zheng-xq,zheng-xq,nluehr,nluehr,nluehr,nluehr,nluehr,frankchn,martinwicke,nluehr,nluehr,sb2nov,nluehr,zheng-xq,zheng-xq,drpngx",2017-10-02 19:48:01,2017-12-26 19:11:35
PR,Remove unneeded branch check,,,"yaroslavvb,yaroslavvb,frankchn,yaroslavvb,yaroslavvb,martinwicke,aselle,yifeif,drpngx,drpngx",2017-10-04 23:17:49,2017-12-26 19:13:51
PR,MKL Fixing MKL DNN convolution filter propagation to backprop,Added code to propagate the 2D convolution filter to the backward pass,,claynerobison,2017-12-09 00:28:55,2017-12-26 19:20:28
PR,Update C API test data comparison for s390x,Base64 encode decode is not endian dependent The hash passed to Base64 will generate different string on big endian platform Correcting the test data comparison for s390x architecture,,"iganichev,iganichev,drpngx",2017-12-15 09:55:10,2017-12-26 19:20:55
PR,MKL Adding missing reorders in ReLU and AddN,Commit to add missing reorder primitive in ReLU and AddN operators,,"nhasabni,drpngx",2017-12-15 21:33:25,2017-12-26 19:21:07
IS,RuntimeError No C shape function registered for standard op SingleImageRandomDotStereograms,single image random dot stereograms windows bug the function works fine on ubuntu 16 04 tf 1 4 0 CPU I know that the support for unsupported libraries in tf contrib on Windows is incomplete and left up to the individual contributors I found some sketchy solutions by editing gen single image random dot stereograms ops py but i could not figure it out correctly Source code Windows 10 Pro 1709 conda version 4 3 30 python version 3 5 4 tensorflow 1 3 0 tensorflow 1 2 0 AttributeError 'NoneType' object has no attribute isingle image random dot stereograms,,yongtang,2017-12-17 19:44:34,2017-12-26 19:21:21
PR,Add shape function SingleImageRandomDotStereograms,This fix tries to address the issue raised in 15429 where there is no shape function for SingleImageRandomDotStereograms This fix adds the shape function for SingleImageRandomDotStereograms NOTE SingleImageRandomDotStereograms takes an attribute of output image shape which is in the format of X Y C ImageX ImageY Channel However the actual data output is in the format of ImageY ImageX Channel h w c So by default the output image shape has the value of 1024 768 1 but the output data will be 768 1024 1 And if 1200 800 1 is used explicitly then the output data shape will be 800 1200 1 This fix does not change the behavior for now This fix fixes 15429 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,drpngx",2017-12-18 01:26:47,2017-12-26 19:21:21
PR,call within the loop,optimize call within the loop,,drpngx,2017-12-18 12:55:23,2017-12-26 19:21:45
PR,Add ws2 32 lib to gcs dns cache test is linkopts,Needed for Windows,,"snnn,drpngx",2017-12-20 03:20:14,2017-12-26 19:22:06
PR,XLA Remove unused dlfcn h and implement sincos f for MSVC,Split from 15310 15213,,"rongjiecomputer,tatatodd,rongjiecomputer,sanjoy,rongjiecomputer,sanjoy,rongjiecomputer,sanjoy,sanjoy,sanjoy,rongjiecomputer,rongjiecomputer,sanjoy,rongjiecomputer,drpngx",2017-12-20 08:37:31,2017-12-26 19:22:44
PR,added note about weights gradient in compute weighted loss,Added a note concerning the gradient computation w r t weights in losses compute weighted loss see 15046 I have only added it to this function and not the other losses like mean squared error because it is a rare cornercase that should be documented somewhere but is of no relevance to most users,,drpngx,2017-12-21 00:20:07,2017-12-26 19:23:06
PR,Bug fix for example parsing ops test,Delay tensor allocation Static variables' initialization order is not determined in C In one static variable is constructor you can not access other static variables unless they are constexpr which is not true for tensor is allocators Replacing it with std call once static init order,,"snnn,snnn,drpngx",2017-12-21 07:45:12,2017-12-26 19:23:25
PR,Fix adding elements to collections deque,In some cases word2vec basic py L123 will fail at L123 and throw the following error and this is consistent with L114,,drpngx,2017-12-22 07:07:18,2017-12-26 19:23:54
PR,Bazel MSVC Fix build error since aae439c,15213,,"rongjiecomputer,drpngx,rongjiecomputer,drpngx,snnn,rongjiecomputer,snnn,drpngx",2017-12-22 09:29:53,2017-12-26 19:24:16
PR,Fix missing sincos in XLA on macOS,Building XLA on macOS failed due to missing sincos and sincosf tried to fix the issue but still needs too,,"Lewuathe,drpngx,sanjoy,drpngx",2017-11-23 14:44:56,2017-12-26 19:39:29
PR,fix InvalidArgumentError when using cv2 with tf py func,If we use cv2 imread filename cv2 IMREAD GRAYSCALE here we will get an InvalidArgumentError TypeError bad argument type for built in operation using cv2 imread filename decode cv2 IMREAD GRAYSCALE instead solves this issue,,"jhseu,drpngx",2017-11-06 10:42:44,2017-12-26 19:55:43
PR,Fix an lib error while building with CUDA9 1,Some header files in CUDA9 1 was moved into dir cuda include crt causing when building with CUDA9 1 headers like math functions hpp could no long be loaded Adding the directory into BUILD file fixs the issue,,"drpngx,gunan,gunan",2017-12-26 07:48:16,2017-12-26 20:03:26
PR,fix clip weights tests,using learning rate 1 variable value after the first update becomes zero resulting in failed tests,,"caisq,drpngx",2017-11-30 10:43:59,2017-12-26 20:36:15
PR,Branch 180147476,,,"drpngx,drpngx",2017-12-26 20:02:43,2017-12-27 01:26:58
PR,Allowing a single Tensor in a StagingArea,This brings the code in line with the documentation so that both of the following are valid import tensorflow as tf from tensorflow contrib import staging staging StagingArea dtypes tf int32 put tf constant 1 staging StagingArea dtypes tf int32 put tf constant 2 tf constant 2 Fixes 13288,,"frankchn,martinwicke,martinwicke,martinwicke,drpngx",2017-10-05 06:33:15,2017-12-27 02:04:14
PR,Adding verify images to example image retrainer,Adding verify images to allow soft checking of image files before bottleneck creation When enabled invalid images are ignored with a warning instead of throwing an exception,,"caisq,martinwicke,drpngx",2017-10-08 18:08:36,2017-12-27 02:05:12
PR,support DepthwiseConv2dNative op when use python tools optimize for i,support DepthwiseConv2dNative op when use python tools optimize for inference py,,"martinwicke,martinwicke,drpngx",2017-10-27 07:54:35,2017-12-27 02:09:56
PR,Batch normalization for LSTM,A recurrent batch normalization is implemented based on The new functionality allows for setting normalization for each of the inputs the actual input or the state and the cell prior to the activation function To avoid a double implementation tensorflow python layers normalization BatchNormalization is called to perform the normalization and it can be controlled fully but if no extra configuration is provided a good default configuraiton is used By default no normalization is done The only aspect mentioned in the paper that was not implemented was that it was recommended there that the statistics be taken on a time step basis rather than having all time steps share the same statistics This would have necessitated a lot of tinkering in BatchNormalization to the point that it would be more economical if that behaviour was desired to simply port the parts needed into LSTM and adjust them as necessary but that should not be part of the main branch,,"martinwicke,martinwicke,drpngx",2017-10-30 19:26:22,2017-12-27 02:12:00
PR,Documentation fix clarifying sum in softmax function,This notational fix makes it more clear that you are summing over the classes in the denominator of the softmax function,,"martinwicke,drpngx",2017-11-02 00:57:17,2017-12-27 02:14:29
PR,consistency in function name,,,"martinwicke,drpngx",2017-11-05 19:52:11,2017-12-27 02:39:25
PR,Add templated functions for safe strto f d i32 i64 u32 u64,While working on 14330 I noticed that there is no templated functions for safe strto f d i32 i64 u32 u64 As a result an additional wrapper has to be created in different places to apply the typename in a templated class or function Examples of the wrappers include the existing implementations in tensorflow core kernels string to number op cc Convert tensorflow core lib strings proto text util h ProtoParseNumeric and in 14330 It might make sense to add a templated function for safe strto f d i32 i64 u32 u64 to avoid existing and future code duplications This fix adds to address the above mentioned issue Note If this PR is merged then 14330 will needs to be updated accordingly Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry,mrry,drpngx",2017-11-22 09:38:30,2017-12-27 02:46:18
PR,Add int64 support for BroadcastArgs and BroadcastGradientArgs,In array ops cc both int32 and int64 are expected to be supported for BroadcastArgs and BroadcastGradientArgs However this was not the case as only int32 kernel are registered even though T is part of the TypeConstraint This fix adds the int64 kernel support for BroadcastArgs and BroadcastGradientArgs and adds related test cases Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,drpngx",2017-12-11 01:40:34,2017-12-27 02:47:15
PR,XLA Make the client test able to be disabled using a manifest file,This change allows these 3 tests in the XLA ClientTest to be selectively disabled using the manifest mechanism,,"DavidNorman,drpngx",2017-12-11 15:32:39,2017-12-27 02:47:54
PR,Fix discrepancy between doc and impl for tf reverse,This fix tries to address the discrepancy between doc and implementations for tf reverse In the documentation both int32 and int64 could be used for axis However the actual implementation of the tf reverse does not support int64 and caused missing kernel error This fix addresses this issue and added the int64 support for axis in tf reverse Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,martinwicke",2017-10-12 21:37:45,2017-12-27 02:49:56
IS,Add kappa coefficient as a new metric,Currently tensorflow supports using accuracy as a metric for model is performance However for unbalanced datasets kappa coefficient is a commonly used metric Would it be possible to add this one in the model metrics,,"angersson,facaiy",2017-12-12 00:42:48,2017-12-27 02:50:50
PR,New metric Cohen is kappa,resolve 15285 Add new metric cohen kappa which is equivalent to sklearn metrics cohen kappa score 0 19 but the implementation does not support weighted matrix yet Ref Cohen is kappa Wiki is kappa Cohen is kappa Index of Inter rater Reliability sklearn metrics cohen kappa score How to test x add test cases pass all tests,,"facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,facaiy,drpngx,drpngx,drpngx,caisq",2017-12-18 11:23:25,2017-12-27 02:50:50
PR,mpi collectives Refactor to fix build issues,After TF commit 5c7f9e3 the mpi collectives package would no longer build ops and kernels This build issue caused mpi collectives import to fail in Python with the following error NameError Could not find operator MPISize in dynamic library mpi collectives so ref issue 13875 To fix this issue add build targets to ensure both ops and kernels are built Note also refactored the build targets and directory structure to more closely match other contrib packages,,"jthestness,jthestness,jthestness,allenlavoie,allenlavoie,allenlavoie,jthestness,jthestness,jthestness,drpngx,gunan",2017-12-21 00:35:51,2017-12-27 02:51:41
IS,Channel number of convolution output is unspecified when atrous rate 1,Python 2 7 Tensorflow v1 2 0 rc2 21 g12f033d and v1 3 0 rc1 2361 gd1286ab Easily reproduced by the following code I believe this is related to the reshaping operation in the atrous convolution The issue happens only when the spatial shape is unknown and with NCHW format Not sure if this happens to the latest version,,"facaiy,facaiy,drpngx,ebrevdo,facaiy,ebrevdo,facaiy,facaiy",2017-10-20 18:25:39,2017-12-27 03:35:25
PR,Recover the lost output channel number of atrous convolution for NC format,Fix 13861 How to test x add new test case pass all tests,,"facaiy,facaiy,drpngx,facaiy,drpngx,facaiy,facaiy,jhseu,facaiy,martinwicke,facaiy,yifeif,facaiy,drpngx,drpngx,drpngx,facaiy,drpngx",2017-10-31 05:59:40,2017-12-27 03:35:25
PR,session clusterspec prop test and common runtime direct session with tracking alloc test fixed for GPU,As I discussed here and I made the changes in code to pass session clusterspec prop test and common runtime direct session with tracking alloc test tests for GPU Thanks,,"sandipmgiri,sandipmgiri,sandipmgiri,saeta,sandipmgiri,drpngx,drpngx",2017-11-14 06:43:33,2017-12-27 03:35:54
IS,Tensorflow lite 0 1 1 causing Build to fail,I am trying to use tensrflow lite in Android When I add compile 'org tensorflow tensorflow lite 0 1 1' I get I am using multidex and AGP 2 3 3 When I take tensorflow lite off the app builds correctly When I put it back the build fails I believe this is a bug in the library,,,2017-12-26 18:48:54,2017-12-27 08:57:05
IS,BUG variables outside wo not update in DNNLinearCombinedRegressor,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 11 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 5 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Variables outside wo not update for DNNLinearCombinedRegressor while everything is OK for DNNRegressor The bug stems from that only variables in dnn linear scope will be updated in the code below L214 L227 Source code logs This is a tiny code to see whether w is updated or not Results For DNNRegressor w variables are updated img width 688 alt dnn src For DNNLinearCombinedRegressor w keeps constant img width 690 alt deep and wide src,,"facaiy,facaiy,ispirmustafa",2017-09-30 11:14:24,2017-12-27 17:58:27
PR,update README md,Added whl file downloading links of Python 3 6 for Linux with CPU only and GPU both,,"av8ramit,av8ramit,av8ramit,av8ramit,av8ramit",2017-12-22 08:13:44,2017-12-27 21:03:56
PR,XLA Replace GCC vector extension with portable Intel SIMD,MSVC does not support GCC vector extension so replace it with Intel SIMD library Eigen also uses Intel SIMD library to implement vector functions MSVC does not have SSE4 1 macro although it does define AVX when building with arch AVX Since Eigen enables SSE4 1 when AVX is defined Eigen Core Core 156 we just follow Eigen 15213,,"rongjiecomputer,rongjiecomputer,rongjiecomputer,sanjoy,sanjoy,rongjiecomputer,yifeif,drpngx,drpngx,rongjiecomputer,drpngx",2017-12-21 12:14:31,2017-12-27 22:25:52
PR,Revert Fix a bug bfloat16 is unsigned on Windows 15302,This reverts commit fdf34a88bec9645473f10ba2d52df4cfcb80d582,,av8ramit,2017-12-27 17:33:27,2017-12-27 22:43:46
IS,tf bitwise bitwise and and friends have bad shape functions,The bitwise ops are componentwise and do normal broadcasting at the kernel level However they claim unchanged shape during op registration define BINARY BITWISE Input x T Input y T Output z T SetIsCommutative Attr T int8 int16 int32 int64 uint8 uint16 uint32 uint64 SetShapeFn shape inference UnchangedShape To reproduce do import tensorflow as tf tf bitwise bitwise and tf zeros 3 1 dtype tf int32 tf zeros 1 3 dtype tf int32 tf Tensor 'BitwiseAnd 0' shape 3 1 dtype int32 The result shape should be 3 3 not 3 1,,"girving,yongtang",2017-11-17 07:36:31,2017-12-27 22:44:18
PR,Fix shape inference for bitwise ops with broadcasting,This fix tries to address the issue raised in 14646 where shape inference for bitwise ops is incorrect with broadcasting As was specified in 14646 in the following the result shape should be 3 3 not 3 1 This fix fixes the issue by changing SetShapeFn shape inference UnchangedShape to SetShapeFn shape inference BroadcastBinaryOpShapeFn Additional test cases have been added This fix fixes 14646 Signed off by Yong Tang yong tang github outlook com,,"yongtang,facaiy,yongtang,facaiy,drpngx,yongtang,facaiy",2017-11-18 01:06:32,2017-12-27 22:44:18
PR,updated Readme md,tf nightly whl files download links added for Linux of python 3 6 version,,av8ramit,2017-12-27 19:53:55,2017-12-27 22:49:18
PR,Removed misplaced quote char,,,drpngx,2017-12-27 15:35:48,2017-12-27 23:46:24
PR,Replace sys maxint with sys maxsize in learning py,use sys maxsize because sys maxint does not exist in Python 3,,"sb2nov,drpngx",2017-11-27 14:53:44,2017-12-28 00:00:45
PR,Fix typo 'updaye' in audio recognition md,Fix typo 'updaye' to 'update' in audio recognition md,,"drpngx,drpngx",2017-12-27 16:47:29,2017-12-28 00:07:17
PR,Fix small typo in docstring which causes the API doc to render incorr,ectly See screen shot 2017 12 27 at 19 53 06 on,,drpngx,2017-12-27 18:54:06,2017-12-28 00:07:37
PR,Predictor fixes for core estimators,Creating a predictor from a core estimator was broken due to a wrong instance check wrong initialization of the ChiefSessionCreator This PR fixes both,,"drpngx,drpngx,drpngx",2017-12-26 21:56:54,2017-12-28 01:05:38
PR,minor wording fix in slim readme,we want to restore a model from a checkpoint whose variables have different names to those in the current graph add the to in the line,,"drpngx,drpngx",2017-12-27 20:09:58,2017-12-28 01:06:03
PR,fix the distributed training problem for the estimator api,Current version will fail as I tried to use the tf estimator train and evaluate api for distributed training on the same machine All the gpus will be occupied even when I set session config gpu options allow growth True for tf estimator RunConfig,,"martinwicke,martinwicke,yifeif,yifeif,drpngx,drpngx",2017-11-10 09:32:07,2017-12-28 01:16:46
PR,Exclude tf stream executor cmake for CPU only,Bug introduced in 15099 Fixes 3996,,"Androbin,Androbin,drpngx",2017-12-23 12:46:56,2017-12-28 01:58:24
PR,CMake Add bazel tests for python file lists,Progressing 10296,,"Androbin,gunan,gunan,gunan,gunan,gunan,Androbin,Androbin,Androbin,Androbin,Androbin,gunan,gunan,gunan,Androbin,Androbin,Androbin,gunan,Androbin,gunan,Androbin,Androbin,mrry,Androbin,mrry,Androbin,Androbin,Androbin,gunan,Androbin,Androbin,jart,Androbin,Androbin,Androbin,Androbin,Androbin,Androbin,Androbin,drpngx,Androbin,drpngx,jart,Androbin,Androbin",2017-12-06 20:15:04,2017-12-28 02:10:34
PR,Branch 180224227,Need a push for the release,,"av8ramit,yifeif",2017-12-28 00:11:27,2017-12-28 03:04:20
IS,My validate loss is unchanged when training what is the reason may it be,Dears Lately I train a Inception v3 model in RAP dataset BUT entropy loss on Validate data is always unchanged when training The loss shows as follows sorry I do not find the port attaching images And yesterday I add tf control dependencies tf get collection tf GraphKeys UPDATE OPS in code it still not work What reasons may it be Sincerely hope your replies and BEST WISHES TO YOU,,,2017-12-28 01:51:39,2017-12-28 05:44:29
IS,tf losses mean squared error is actually sum of squares,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc1 5211 gab0fcac 1 5 0 dev20171124 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce To truly get mean squared error one has to explictly use reduction Reduction MEAN This indicates bad naming Maybe squared error is a better name also similar to other names in tf losses,,"ppwwyyxx,ppwwyyxx",2017-12-02 12:43:06,2017-12-28 05:47:20
IS,tf image decode image does not support png grayscale 16bit,Code to reproduce System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary pip3 install tensorflow TensorFlow version use command below 1 4 1 Python version Python 3 5 2 Bazel version if compiling from source nope GCC Compiler version if compiling from source nope CUDA cuDNN version no gpu GPU model and memory no gpu Exact command to reproduce see abve python c import tensorflow as tf print tf GIT VERSION tf VERSION v1 4 0 19 ga52c8d9 1 4 1 Describe the problem It should return uint16 but returns uint8 Source code logs see above,,,2017-12-28 05:41:20,2017-12-28 08:16:42
PR,XLA Fix OS X compile error with std transform and std addressof,I do not know if this has been flagged up elsewhere on my platform OS X XLA I receive the following error when trying to compile tensorflow compiler xla service llvm ir kernel support library cc It is possible that std addressof cannot be matched with the unary function template This code change replaces addressof with an function which does match std function ok,,"DavidNorman,yifeif,DavidNorman,DavidNorman,sanjoy,DavidNorman,DavidNorman",2017-12-11 15:30:36,2017-12-28 08:43:10
IS,Very slow tf transpose on CPU compared to numpy,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Tested on Linux Ubuntu 16 04 and Mac OS TensorFlow installed from source or binary Both affected TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Tensorflow transpose is 10000 slower than numpy transpose on my example Source code logs,,shoyer,2017-12-28 15:33:56,2017-12-28 16:39:46
PR,R1 4,,,av8ramit,2017-12-28 06:45:36,2017-12-28 17:51:27
PR,Enabling tests to pass with python3 6 Updating dependencies for dock,er tests,,"av8ramit,av8ramit",2017-12-28 00:16:36,2017-12-28 17:53:59
PR,mean relative error supports complex label,Fix 14658 How to test x add test case pass all tests,,"facaiy,drpngx,drpngx,facaiy,facaiy,drpngx,facaiy,drpngx",2017-11-17 20:41:03,2017-12-28 18:53:33
PR,Cherrypicks,Fixes for release tests,,av8ramit,2017-12-28 18:03:21,2017-12-28 18:54:30
PR,Add name scope to tf image,This PR fixes 1560 I searched through the tf image API list and found the following APIs need to add name scope crop to bounding box pad to bounding box flip left right random flip left right flip up down random flip up down per image standardization central crop resize images resize image with crop or pad transpose image Thanks for quick reply before and could you please take a look x Add name scope to above functions x Add test case s RELNOTES Add name scopes to tf image functions,,"qmick,qmick,martinwicke,drpngx,drpngx,qmick",2017-12-12 05:32:02,2017-12-28 18:55:40
PR,Freeze pb model will not remove is training flag of bn attr and it is moreover still set as true,Using tensorflow python framework graph util impl py convert variables to constants to freeze graph to pb model will not remove is training flag of batch normalization as well as fused batch normalization ops tf layers batch normalziation in the inference graph Moreover the is training flag is still set as true This issue will not cause any errors to use the pb model on Android However it will cause converting errors to tflite model by toco Is it possible to optimize this conversion tool to resolve the problem in further versions Following is the node output of the pb model during loading name convolution layer block layer1 batch normalization FusedBatchNorm op FusedBatchNorm input convolution layer block layer1 conv2d Conv2D input batch normalization gamma read input batch normalization beta read input convolution layer block layer1 batch normalization Const input convolution layer block layer1 batch normalization Const 1 attr key T value type DT FLOAT attr key data format value s NHWC attr key epsilon value f 0 0010000000475 attr key is training value b true,,"drpngx,drpngx,drpngx",2017-12-23 08:54:29,2017-12-28 19:06:42
IS,The relationship between neural network depth and accuracy,Hi I am learning to design a simple neural network and try to identify 28x28 pixel greyscale images in the MNIST dataset I find that the neural network depth is not directly proportional to the recognition rate one layer neural network recognition rate 92 two layer neural network recognition rate 94 four layer neural network recognition rate 91 8 Can someone help me analyze it 6 Please click on the picture to see the complete picture information thank you very much,,,2017-12-24 08:15:10,2017-12-28 19:08:04
PR,CMake Remove invalid python modules,Split from 15368 Friendly ping,,"Androbin,drpngx,Androbin,drpngx,Androbin,drpngx,drpngx,Androbin,drpngx,Androbin,drpngx,drpngx",2017-12-23 13:43:51,2017-12-28 19:15:24
PR,fix variable name,,,"drpngx,drpngx",2017-12-27 06:34:10,2017-12-28 19:19:02
PR,Improve doc of TFRecordDataset shuffle ahead of map,In the origin document the code to demonstrate TFRecordDataset do dataset map parser then do dataset shuffle 10000 This code use a high number of buffer size 10000 and since map do ahead of shuffle means when the first time this dataset yield one result it will need to run map over 10000 items and this can take a lot of time So instead we can do shuffle ahead of map since the item of TFRecordDataset is one Example raw data shuffle ahead will not compromise the randomness and then the map parser only need to process one batch of items at a time Which results much faster startup,,"yjmade,mrry",2017-12-28 03:56:00,2017-12-28 19:34:39
PR,README Link to build history,Completes 15666,,Androbin,2017-12-27 23:45:23,2017-12-28 19:40:55
IS,MNIST dataset gzip train images idx3 ubyte gz not in gzip format,initiated from tensorflow discuss From greina eng ucsd edu I'm trying to use from tensorflow examples tutorials mnist import input data mnist data input data read data sets 'MNIST data' one hot True but I am getting the error that the downloaded file is not in GZip format There are several bug reports on this but none of them seem to solve the issue I found train images idx3 ubyte gz in the local directory MNIST data but even trying gunzip fails,,"aselle,aselle,aselle",2017-12-27 20:59:09,2017-12-28 20:23:19
IS,upgrades to boosted trees an example with feature importance tuning savedmodel,System information N A Describe the problem Feature Request I hate to make a trite request but is there any plan to add more documentation or examples to the tensorflow contrib boosted trees submodule Now that there is a GB classifier available I am hoping to replace my production XGBoost code with boosted trees as soon as I can prove it out Perhaps it is my newness to tf contrib learn is Estimator s and Experiment s but I found the examples a bit opaque and repetitive For example would it be possible to have an example script demonstrating these properties some feature importance metrics I see the Hooks but do not know how to use them some type of hyperparameter tuning max depth examples per layer etc the implementation of an ExportStrategy in the Experiment or better yet throw away the experiment and directly operate on a trained Estimator I'm struggling to write a proper serving input function a perhaps commented out example of using each input in the GradientBoostedTreeClassifier constructor Sorry to ask for hand holding here It is just taking me longer than usual to figure these things out from the source code Also to the extent that I have figured out some of these are you welcoming PRs for more thorough examples,,,2017-11-13 17:27:23,2017-12-28 20:51:59
IS,tools compatibility module is missing or not installed properly through pip,Running tf upgrade py gets ImportError System information Ubuntu 16 04 Tensorflow 1 2 1 upgraded 'natively' via pip from a pre 1 0 version sudo H pip install upgrade tensorflow gpu Python version 2 7 12,,,2017-07-02 08:03:46,2017-12-28 23:39:14
PR,Make tf upgrade py dependency free,Nothing else references the ast edits so it will make tf upgrade py much easier to use if it is just absorbed This change fixes 11217 where a whole bunch of folks encountered difficulties for this very reason,,"jart,caisq,caisq,drpngx,jart,drpngx,drpngx,jart,drpngx",2017-11-28 23:27:52,2017-12-28 23:39:14
PR,CMake Include example compile script,mrry Friendly ping,,"Androbin,drpngx,Androbin,drpngx,drpngx,Androbin,drpngx,drpngx,drpngx,drpngx,drpngx",2017-12-24 17:30:07,2017-12-28 23:45:44
PR,correct the misspell of Quantize,,,drpngx,2017-12-11 11:04:02,2017-12-29 00:18:38
PR,Update 4 convolutions ipynb,,,,2017-12-03 00:13:05,2017-12-29 00:19:01
PR,Update 4 convolutions ipynb,,,,2017-12-03 00:17:52,2017-12-29 00:19:08
PR,Update 4 convolutions ipynb,,,"sb2nov,drpngx",2017-12-03 00:28:17,2017-12-29 00:19:40
IS,FusedBatchNorm Conv2D backwards does not support zero batch size,Most ops in TF work well with tensors with zero elements However del convolution del fusedbatchnorm with cudnn gives the following error I would expect it checks and returns a 4D tensor with zero batch size Currently I have to work around it by tf cond,,"ppwwyyxx,facaiy,ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx,ppwwyyxx,yzhwang",2017-11-17 16:25:50,2017-12-29 00:38:36
PR,Support empty input tensor for some ops fix 14657,Cudnn kernels does not work for empty input tensors This PR adds support for empty input tensor for FusedBatchNorm FusedBatchNormGrad Conv2DBackpropFilter and cudnn pooling fix 14657,,"ppwwyyxx,yzhwang,ppwwyyxx,yzhwang,ppwwyyxx,yzhwang,yzhwang,ppwwyyxx,yzhwang,zhangyaobit,ppwwyyxx,zhangyaobit,ppwwyyxx,zhangyaobit,ppwwyyxx,ppwwyyxx,drpngx,ppwwyyxx,drpngx,drpngx,yifeif,drpngx,drpngx,ppwwyyxx,drpngx,drpngx,ppwwyyxx,drpngx,yifeif,drpngx",2017-12-11 08:20:04,2017-12-29 00:38:36
PR,Added mode to input fn argument,And modified existing tests to include the mode argument deleted previous PR because I accidentally pulled a bunch of other commits into the branch,,"k-w-w,yifeif,drpngx,drpngx,drpngx,yifeif,drpngx,drpngx,drpngx",2017-11-17 21:34:05,2017-12-29 00:45:00
PR,Add a mutex in cuda solvers GetrfImpl,This should solve issue 13558 Because NVIDIA does not publish the code it is not possible to prove the bug is in the cuSolver function However I have removed commented code from matrix inverse op cpp until essentially only the call to solver Getrf remained and from' project mostly everything except the regularized inverse calls and the segmentation fault still occurred It did not appear when there was a single thread calling regularized inverse The segmentation fault always occurs without my change and never after introducing the lock although that in itself does not mean the bug is solved Note that GetrsImpl is already protected with a lock so apparently this issue was known Finally has a second stacktrace which does not involve the Getrf function I could not reproduce this error but it may be a different bug,,"codrut3,yaroslavvb,codrut3,codrut3,rmlarsen,rmlarsen,drpngx,codrut3,drpngx,drpngx",2017-11-12 09:35:16,2017-12-29 01:38:28
PR,WIP Add tf copts to XLA libraries,Split from 14531 Required by 15213 Depends on 15466 To fix a build error in tensorflow compiler xla util There is a name conflict in xla data pb h So DNOGDI compiler flag is a must for who includes this file,,"snnn,jhseu,gunan,snnn,snnn,jhseu,rongjiecomputer,snnn,snnn,snnn,jhseu,snnn,snnn",2017-12-18 09:48:49,2017-12-29 01:50:29
PR,Portability fix for StrAppend,15557,,"snnn,drpngx,snnn,drpngx,snnn,snnn",2017-12-22 08:22:38,2017-12-29 01:52:18
PR,Add a wrapper for cc library tf cc library,I will replace every cc library under tensorflow with tf cc library,,"snnn,jhseu,jhseu,snnn,snnn,jhseu,snnn,snnn,gunan,snnn,meteorcloudy,gunan,meteorcloudy,gunan,meteorcloudy,gunan,snnn,rongjiecomputer",2017-12-19 03:01:16,2017-12-29 01:56:57
IS,ImportError libmklml intel so cannot open shared object file No such file or directory with python 2 7,Ubuntu 16 04 GPU 1080 Ti Cuda 9 0 CuDDN 7 0 v7 Using my PC not a VM Installed Intel MKL DNN by this guilde mkl but looks like something wrong because when trying to make a test for tensorflow got error Recently someone created same problem and it was closed with reason PR 12975 but it was for a VM Can anyone explain please what i can be and how to fix it Dont have any build pip package scrips at the TF folder Its doesnt looks like same problem as PR 12975,,asimshankar,2017-12-26 07:02:56,2017-12-29 02:19:56
IS,TensorFlowInferenceInterface readNodeFloat error,This is part of my Tensorflow frozen graph I have named the input and output nodes g ParseFromString open 'frozen graph pb' 'rb' read g node name input op Placeholder attr key dtype value type DT FLOAT attr key shape value shape dim size 1 dim size 68 node name output op Softmax input add attr key T value type DT FLOAT I ran this model by the following code CELL is name of directory where my file is located final String MODEL FILE file CELL optimized graph pb final String INPUT NODE input final String OUTPUT NODE output final int INPUT SIZE 1 68 float RESULT new float 8 inferenceInterface new TensorFlowInferenceInterface inferenceInterface initializeTensorFlow getAssets MODEL FILE inferenceInterface fillNodeFloat INPUT NODE INPUT SIZE input and finally inferenceInterface readNodeFloat OUTPUT NODE RESULT But I get this error in Log 12 28 16 42 48 622 9890 12178 com getfocus signalsimilarity I native tensorflow inference jni cc 151 Initialization done in 52 275ms 12 28 16 42 51 048 9890 12178 com getfocus signalsimilarity E native tensorflow inference jni cc 170 Output output not found aborting I have searched a lot for the solution but nothing seems to solve this Thanks in advance,,asimshankar,2017-12-28 12:08:09,2017-12-29 02:56:55
PR,updated the latest mkldnn,This commit will pull the latest changes from the mkl dnn tree the mirror bazel build URL does not exist can you create it,,"jinghuangintel,jinghuangintel",2017-12-29 03:22:37,2017-12-29 03:37:43
PR,Removing extra space preventing double declared if statement and from http to https,,,rajendraarora16,2017-12-29 09:16:00,2017-12-29 09:29:08
PR,getting latest pull,,,rajendraarora16,2017-12-29 09:29:57,2017-12-29 09:30:12
IS,ImportError No module named contracts,,,,2017-12-29 10:01:41,2017-12-29 10:02:35
IS,ValueError Batch length of predictions should be same,Hi I'm trying to visualize the output of a convolutional autoencoder using TensorFlow Estimator API I use 64 64 images stored in a Numpy array as input and use tf estimator inputs numpy input fn to feed this input to my estimator Everything works perfectly fine during training but as soon as I try to do predictions it seems that I have an issue with my input fn Please forgive me in advance I am not 100 sure this is a bug but I think I have tried everything I had in mind Can anybody see what is wrong Thanks in advance,,,2017-12-29 09:53:08,2017-12-29 15:56:21
PR,updated the latest mkldnn,This commit will pull the latest changes from the mkl dnn tree the mirror bazel build URL does not exist can you create it,,"jinghuangintel,jinghuangintel,drpngx,gunan,jinghuangintel",2017-12-29 03:44:35,2017-12-29 18:34:11
IS,Eager tfe implicit value and gradients uses functions operating on raw tf variables,System information Tensorflow version 1 5 0 dev20171126 Python version Python 3 5 0 v3 5 0 374f501f4567 Sep 12 2015 11 00 19 Problem Forgive me if I'm re iterating something that is discussed before Even though I do not think the issue described here is a bug I nevertheless believe it is worthy to point out The specific issue is that when we pass a loss function e g,,asimshankar,2017-12-28 05:50:28,2017-12-29 22:05:16
IS,ImportError libcublas so 9 0 cannot open shared object file No such file or directory,I installed tf nightly build and I get the following error on import of tensorflow ImportError libcublas so 9 0 cannot open shared object file No such file or directory If I check for cuda 9 I get the following I that due to a name mismatch libcublas so 9 0 libcublas so 9 1 And if so how can we overcome this,,"asimshankar,gunan,asimshankar",2017-12-23 13:58:25,2017-12-29 22:12:20
IS,Unable to compile from source on High Sierra 10 13 2 with bazel 0 9 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS High Sierra 10 13 2 TensorFlow installed from source or binary source TensorFlow version use command below tf 1 4 Python version 3 6 3 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source Apple LLVM version 9 0 0 clang 900 0 39 2 Exact command to reproduce bazel build c opt copt mavx copt mavx2 copt mfma copt msse4 1 copt msse4 2 config opt k tensorflow tools pip package build pip package Describe the problem I'm unable to compile tensorflow from source I get too many errors as shown below in the logs Source code logs,,"Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,Carmezim,asimshankar",2017-12-25 06:42:27,2017-12-29 22:14:03
IS,Is it possible to have labels for outputs I found it on the documentation,For example currently if I want to run a graph with multiple output which return a dictionary maps labels to results so I can get specific result based on the output label,,,2017-12-29 22:36:27,2017-12-29 22:38:05
IS,BUG argparse Argument Parser is not working in nightly build,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip install tf nightly gpu TensorFlow version use command below v1 3 0 rc1 5211 gab0fcac 1 5 0 dev20171125 Python version 3 5 3 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version 9 0 7 0 GPU model and memory Titan Xp 12Gb Exact command to reproduce python test py myarg buzz Describe the problem Nightly build is not handing correctly arguments passed to the script The arguments are parsed correctly in the official 1 4 version,,"dantkz,mrry,martinwicke,yilei,dantkz,yilei,dantkz,yilei,yilei,dantkz,mrry,yilei",2017-11-27 16:32:09,2017-12-29 22:45:26
IS,Inconsistent losses for Keras,TF 1 2 0 Python 3 5 TF Official Keras There are many sparse softmax cross entropy but they all have different APIs Some are compatible with tf contrib keras models Model compile and the others are not because of sentinel and different order of output and target Interestingly both the original TF and Keras use target output and only tf contrib keras backend version uses output target tf keras needs to use output target otherwise the model is not trained Can we unify the interface and document when to use each version,,"martinwicke,fchollet,martinwicke,fchollet,martinwicke",2017-06-30 15:24:56,2017-12-29 22:46:16
IS,undocumented change in variable scope from tf 1 0 1 to tf 1 1 0,System Information Custom code a minimal reproducible example provided below Linux Fedora 24 and Fedora 25 TensorFlow installed from binary using pip TensorFlow version 1 0 1 and 1 1 0 CUDA 8 0 cuDNN 5 1 GeForce GTX 1080 Problem I'm trying to run some code that I wrote for tensorflow 1 0 1 on tensorflow 1 1 0 It seems like tf contrib layers fully connected is showing different behaviour for 1 1 0 compared to 1 0 1 See below for a minimal reproducible example showing the difference Source code and logs Tensorflow 1 0 1 Fedora 24 Looking at the release notes for Tensorflow 1 1 there is no mention of change in behaviour of variable scope for tf contrib layers fully connected But it seems like in 1 1 we have to create variables manually using tf get variable before using tf contrib layers fully connected Am I missing something,,"aselle,lukaszkaiser,aselle,lukaszkaiser,lukaszkaiser",2017-06-14 14:32:25,2017-12-30 00:15:40
PR,Clarify batch norm documentation to highlight that the dimensions for,normalization depend on the shape of the tensor,,"drpngx,drpngx,drpngx",2017-12-27 10:49:05,2017-12-30 07:53:32
IS,using tf layers batch normalization gives erratic validation loss though implementation seems correct,I am trying to use Batch Normalization using tf layers batch normalization 1 and I have followed the documentation closely My code looks like this language python def create conv exp model fingerprint input model settings is training Dropout placeholder if is training dropout prob tf placeholder tf float32 name wouldropout prob' Mode placeholder mode placeholder tf placeholder tf bool name mode placeholder he init tf contrib layers variance scaling initializer mode FAN AVG Input Layer input frequency size model settings 'bins' input time size model settings ispectrogram length' net tf reshape fingerprint input 1 input time size input frequency size 1 name reshape net tf layers batch normalization net training mode placeholder name 'bn 0' for i in range 1 6 net tf layers conv2d inputs net filters 8 2 i kernel size 5 5 padding isame' kernel initializer he init name conv d i net tf layers batch normalization net training mode placeholder name 'bn d' i with tf name scope relu d i net tf nn relu net net tf layers max pooling2d net 2 2 2 2 'SAME' name maxpool d i net shape net get shape as list net height net shape 1 net width net shape 2 net tf layers conv2d inputs net filters 1024 kernel size net height net width strides net height net width padding isame' kernel initializer he init name conv f net tf layers batch normalization net training mode placeholder name 'bn f' with tf name scope relu f net tf nn relu net net tf layers conv2d inputs net filters model settings 'label count' kernel size 1 1 padding isame' kernel initializer he init name conv l Squeeze squeezed tf squeeze net axis 1 2 name squeezed if is training return squeezed dropout prob mode placeholder else return squeezed mode placeholder And my train step looks like this language python update ops tf get collection tf GraphKeys UPDATE OPS with tf control dependencies update ops optimizer tf train AdamOptimizer learning rate learning rate input gvs optimizer compute gradients cross entropy mean capped gvs tf clip by value grad 2 2 var for grad var in gvs train step optimizer apply gradients gvs During training I am feeding the graph with language python train summary train accuracy cross entropy value sess run merged summaries evaluation step cross entropy mean train step increment global step feed dict fingerprint input train fingerprints ground truth input train ground truth learning rate input learning rate value dropout prob 0 5 mode placeholder True During validation language python validation summary validation accuracy conf matrix sess run merged summaries evaluation step confusion matrix feed dict fingerprint input validation fingerprints ground truth input validation ground truth dropout prob 1 0 mode placeholder False My loss and accuracy curves orange is training blue is validation Plot of loss vs number of iterations 2 Plot of accuracy vs number of iterations 3 The validation loss and accuracy seem very erratic Is my implementation of Batch Normalization wrong Or is this normal with Batch Normalization and I should wait for more iterations Or maybe moving statistics are not being saved and hence poor performance I tried StackOverflow and found many people have the same problem and there is no definitive guide on how to resolve this 1 2 3,,asimshankar,2017-12-30 07:00:14,2017-12-30 09:12:21
IS,Cannot load pretrained models in Android via jcenter provided library,It is a great step to support importing Android lib via jcenter However I'm having trouble in loading pretrained models into TensorFlowInferenceInterface which says NodeDef mentions attr wouldilations' not in Op I think it is a compatibility issue meaning that the model graph is not consistent with the graph interpreter The models directly downloaded from slim and frozen by myself Anyone can help me,,asimshankar,2017-12-24 08:35:28,2017-12-30 10:06:50
IS,matmul back propagation quadratic memory consumption,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 3 CUDA cuDNN version using CPU only Describe the problem tf matmul in back propagation has memory consumption quadratic in the number of records of data Test case and discussion here One answer at time of writing suggests a workaround using mini batches appears to confirm quadratic memory consumption is not expected I have also tried using tf tensordot a b 1 which seems to be a synonym of tf matmul a b and does not use as much memory This despite the existence of another discussion indicating tf matmul should be more efficient,,,2017-12-27 23:10:47,2017-12-30 16:51:40
PR,fix typo,fix typo,,"ManHyuk,caisq",2017-12-30 14:58:24,2017-12-30 17:08:37
PR,Fixed a typo for CreateBody,,,drpngx,2017-12-29 19:44:28,2017-12-30 21:54:57
IS,wrong output extra symbol b,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows Home TensorFlow installed from source or binary binary pip TensorFlow version use command below 1 4 0 GPU Python version 3 6 GPU GTX1050 Ti M disabled Intel visualization Basically any output I try to write in console is with extra symbol b for example with cmmand I downloaded GPU verison form guide from official webiste with Anaconda installing with anaconda url i have tried the validation example and same problem extra symbol b,,"facaiy,asimshankar",2017-12-30 18:37:28,2017-12-31 05:03:02
IS,CUDA 9 1 and TensorFlow,I am using NVIDIA GeForce GTX 1050 and installed NVIDIA 387 26 I installed cuDNN 7 0 5 and CUDA 9 1 As of my understanding I know that tensorflow is not supported in CUDA 9 1 My question is when I can expect the next build release of TF to support CUDA 9 1 For the time being shall I make a link from CUDA 9 0 to CUDA 9 1 and expect to work Or is there any better way to solve the problem,,"asimshankar,gunan,av8ramit,av8ramit,av8ramit,gunan,gunan,av8ramit,gunan,gunan",2017-12-27 14:10:43,2017-12-31 05:44:23
PR,Utility classes for writing Java source code from a C process,This PR sets up a few tools for writing Java source files from the op generator or any future generator of Java code written in C They are handling most of the tricky cases known to be encountered when we will generate the ops including generics wildcards optional inner classes etc Note that they focus on simplicity rather than performance or memory optimitizations since they will only be used at compile time As stated in a previous PR java writer and source writer are being kept separate since the later might be a good candidate to be move to the core io layer if required some day,,"karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,karllessard,karllessard,sb2nov,karllessard,drpngx,karllessard,karllessard,drpngx,karllessard,drpngx,asimshankar,asimshankar,drpngx,asimshankar",2017-10-30 14:29:29,2017-12-31 05:44:49
PR,Utility classes for writing Java source code from a C process,This PR sets up a few tools for writing Java source files from the op generator or any future generator of Java code written in C They are handling most of the tricky cases known to be encountered when we will generate the ops including generics wildcards optional inner classes etc Note that they focus on simplicity rather than performance or memory optimitizations since they will only be used at compile time As stated in a previous PR java writer and source writer are being kept separate since the later might be a good candidate to be move to the core io layer if required some day,,"karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,asimshankar,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,karllessard,asimshankar,asimshankar,karllessard,karllessard,sb2nov,karllessard,drpngx,karllessard,karllessard,drpngx,karllessard,drpngx,asimshankar,asimshankar,drpngx,asimshankar",2017-10-30 14:29:29,2017-12-31 05:44:49
PR,Branch 180304271,,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,caisq,gunan,gunan,drpngx,drpngx",2017-12-29 01:11:30,2017-12-31 06:33:08
IS,isaved model cli py' bug fix,In file python tools saved model cli py at function def print tensor info tensor info The first line should be print ' dtype ' value key for key value in types pb2 DataType items tensor info dtype Not be print ' dtype ' types pb2 DataType keyss tensor info dtype because tensor info dtype is an Integer which is the value of types not the index of type values,,"qmick,qmick,qmick,drpngx,yifeif",2017-12-24 09:33:59,2017-12-31 06:33:44
PR,Optimize batch matrix transposition for narrow matrices,This is an improved version of matrix transposition that specializes in the case when the matrices to be transposed are narrow This is a preliminary implementation and I hope to get some feedback before further optimizing this implementation as it would likely entail great deal of efforts and patience This implementation modifies the general matrix transposition kernel in a minimal way Essentially this implementation enables the rectangular tile shapes to be used for transposition Before only square tiles are allowed This implementation has a couple of specialized tile sizes and a very simple cost function is used to select among them during runtime The logic behind this cost function is simple and will likely to be effective on a variety of platforms We tested this implementation on problem sizes of 32 64 128 256 512 1024 X range 16 2048 32 X range 2 16 as well as 32 64 128 256 512 1024 X range 2 16 X range 16 2048 32 where these problem size dimensions can be interpreted as batch size matrix height matrix width correspondingly The average speedup is 16 7 This experiment includes 10752 data points and is plotted using excel to indicate for what sub space of all problem size space do we see speedups over baseline existing implementation See picture In the picture problem sizes where we do see speedups are colored red and otherwise white The three dimensional problem size space is collapsed to two by serializing the batch size dimension and matrix height dimension As you can see from the current performance results existing implementation is very good at dealing with large batches of tiny matrices This is due to the fact that the baseline implementation uses a brute force and nonetheless effective way of dividing up workloads evenly which outperforms this commits I may consider modify the cost function to use the baseline in these cases in the future Again this is only a preliminary implementation I'm happy to make significant changes,,"tjingrant,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,tjingrant,tjingrant,tjingrant,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,tjingrant,tjingrant,tjingrant,tjingrant,tjingrant,tjingrant,jlebar,jlebar,jlebar,tjingrant,tjingrant,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,tjingrant,tjingrant,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,jlebar,tjingrant,jlebar,tjingrant,jlebar,tjingrant,tjingrant,tjingrant,jlebar,tjingrant,tjingrant,tjingrant,tjingrant,jlebar,yzhwang,tjingrant,yzhwang,yzhwang,tjingrant,yzhwang,tjingrant,tjingrant,yzhwang,martinwicke,tjingrant,yzhwang,drpngx,tjingrant,drpngx,tjingrant,drpngx,drpngx,drpngx,drpngx",2017-09-14 21:44:18,2017-12-31 06:39:34
PR,Update deprecated get global step in example,WARNING tensorflow From usr local lib python2 7 dist packages tensorflow contrib tensor forest client random forest py 193 get global step from tensorflow contrib framework python ops variables is deprecated and will be removed in a future version Instructions for updating Please switch to tf train get global step thrown when running random forest mnist py updated to training util get global step used elsewhere in the same file,,"drpngx,drpngx",2017-12-03 18:28:48,2017-12-31 06:40:51
IS,Error while building from source on Ubuntu,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 3 6 3 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 5 4 0 20160609 CUDA cuDNN version 9 1 GPU model and memory GTX 950 2GB Exact command to reproduce bazel build config opt config cuda incompatible load argument is label false tensorflow tools pip package build pip package Describe the problem The following error occurring while building tensorflow from source I'm not able to understand what the error is Source code logs,,,2017-12-30 13:16:51,2017-12-31 09:01:53
PR,Simplify the dense to one hot method,Simplified the dense to one hot method The updated method behaves exactly like the old one but is more concise,,drpngx,2017-12-30 21:01:09,2017-12-31 12:23:35
PR,Fixes 15736,This will allow users to import keras submodules without typing from tensorflow python keras but just directly from tensorflow keras This change also does not create a duplicate of the module object but just assign it two names one with tensorflow python keras keeping current functionality and tensorflow keras allowing a much more consistent API use With this change the user is able to import keras objects directly for example,,,2017-12-31 13:54:04,2017-12-31 14:01:04
PR,MKL update mkldnn to the latest release,This commit will pull the latest changes from the mkl dnn tree the mirror bazel build URL does not exist can you create it,,"jinghuangintel,jinghuangintel,drpngx",2017-12-29 18:43:38,2017-12-31 19:52:17
PR,Fix error message of WhereOpCPU,,,"ppwwyyxx,drpngx,drpngx,drpngx",2017-12-01 08:52:25,2017-12-31 22:21:05
PR,Fix initialization of tf contrib layers spatial softmax temperature,It is now possible to initialize a trainable temperature with values other than 1,,"drpngx,drpngx",2017-12-12 09:07:58,2017-12-31 22:21:58
PR,fix description of HASHTABLE LOOKUP in smartreply doc,HASHTABLE LOOKUP is a builtin op rather than a custom one,,"freedomtan,drpngx,drpngx",2017-12-28 09:30:22,2017-12-31 22:24:32
PR,Fix out of memory issue on Tegra devices,TF used to allocate available memory 300MB or available memory 225MB for TF to use This is fine for graphic cards but will cause out of memory issue on Tegra Modify to allocate available memory 1GB for Tegra 1GB should be enough for OS and other apps available memory 1GB should be 0 8 1 5GB which is enough for most graph for TF,,"lihanchen,drpngx,drpngx,lihanchen,drpngx",2017-12-28 20:18:32,2017-12-31 22:24:43
PR,Update estimator md,,,"larrytin,drpngx,drpngx",2017-12-29 04:46:32,2017-12-31 22:25:15
PR,Update graphs md,,,"larrytin,drpngx,drpngx",2017-12-29 04:52:40,2017-12-31 22:25:34
PR,Update estimator md,The anchor fit dnnclassifier can not locate to a valid position You can try the following two links fit dnnclassifier fit dnnclassifier,,"larrytin,drpngx,drpngx",2017-12-29 07:21:34,2017-12-31 22:26:01
PR,Fix the headers error due to recent CUDA9 1 change,Some headers in CUDA 9 1 has been move to cuda include crt directory,,"drpngx,drpngx,gunan,drpngx,drpngx,nluehr,gunan",2017-12-30 19:41:04,2017-12-31 22:26:25
PR,Fixes 15736,This will allow users to import keras submodules without typing from tensorflow python keras but just directly from tensorflow keras This change also does not create a duplicate of the module object but just assign it two names one with tensorflow python keras keeping current functionality and tensorflow keras allowing a much more consistent API use With this change the user is able to import keras objects directly for example,,drpngx,2017-12-31 14:05:33,2017-12-31 22:34:57
IS,Importing submodules from tensorflow keras fails with No module named 'tensorflow keras',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary pip TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 6 Exact command to reproduce from tensorflow keras import datasets fails but should work import tensorflow as tf succeeds tf keras datasets succeeds from tensorflow python keras import datasetst succeeds Describe the problem Importing submodules from tensorflow keras fails with error ModuleNotFoundError No module named 'tensorflow keras' but import tensorflow as tf and then doing tf keras datasets works This is a big inconsistency also it means that every time an element from within the tensforlow keras module you need to write the complete path which is very annoying this removes the simplicity and readability of the keras API A work around is to import submodules from tensorflow python keras which again is inconsistent In my opinion since the documentation states that keras is availabe at tf keras that should be the access path to the submodules and not tensorflow python keras I will try to make a pull request for this Source code logs,,"drpngx,drpngx,fchollet,drpngx",2017-12-30 16:44:49,2017-12-31 22:36:00
PR,include solib in pip package,See issue 15252 for detail also should fixes issue 13711 The problem is that when compile tensorflow with config mkl on virtual machines mkl libraries wo not be included because they locate under solib local however setup py only includes solib k8,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-12-10 16:46:09,2017-12-31 23:19:55
PR,Sgdr fix,Proposed fix for SGDR implementation Developed together with the author,,"taion,vrv,vrv,vrv,vrv,asimshankar,vrv,drpngx,drpngx,drpngx,drpngx,drpngx,vrv,drpngx,drpngx,drpngx,drpngx",2017-11-12 15:52:15,2018-01-01 00:01:41
PR,improve compute high rank hessians,fix possible compute high rank hessians,,"tillahoffmann,tillahoffmann,tillahoffmann,tillahoffmann,vrv,vrv,vrv,vrv,vrv,vrv,drpngx,vrv,drpngx,drpngx",2017-12-12 12:03:42,2018-01-01 00:02:51
PR,CMake Test existence of python entries,Split from 15166 Friendly ping,,"Androbin,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-12-23 13:34:36,2018-01-01 00:04:12
PR,Used template version of SafeStringToNumeric to reduce code duplication,This fix uses template version of SafeStringToNumeric to avoid customerized ConvertHelper for the purpose of reduce code duplication Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry,drpngx,drpngx",2017-12-29 01:33:00,2018-01-01 00:05:43
PR,XLA Add missing win header deps to framework lite,Continue from 15579 Most Tensorflow components depend on framework rather than framework lite so I did not notice this until I try to build XLA tfcompile locally again 15213,,"rongjiecomputer,drpngx",2017-12-31 09:14:28,2018-01-01 00:06:43
PR,XLA Define TF COMPILE LIBRARY for two libraries,Both index ops kernel argmax float 1d cc L48 and index ops kernel argmax float 2d cc L50 use TF EXPORT macro We need to define TF COMPILE LIBRARY comes from tf copts L170 to make sure TF EXPORT is expanded into declspec dllexport 15213,,"rongjiecomputer,drpngx",2017-12-31 09:20:20,2018-01-01 00:06:53
PR,fix doc tf data contrib map and batch to tf contrib data map and batch,change from unexist tf data contrib map and batch to tf contrib data map and batch,,"yjmade,drpngx,drpngx,drpngx,drpngx",2017-12-29 05:18:09,2018-01-01 00:40:47
PR,XLA Fix std array initialization take 2,15511 did not fix the issue on MSVC The actual root cause is due to the presence of and around const C array For std array int 2 a 1 2 3 MSVC seems to see 1 2 3 as a pointer which triggers C2100 compile error Removing and fixes the issue 15213,,"rongjiecomputer,drpngx",2017-12-31 09:29:10,2018-01-01 00:40:59
PR,Add S3 logging to TensorFlow is logging system,This fix is an attempt to help the issue raised in 15159 where there is no logging in S3 file system and it is not easy to debug to diagnose This fix adds S3 logging to TensFlow is logging with This fix is related to 15159 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,drpngx,yongtang,yongtang,yongtang,yongtang,yongtang,yongtang,drpngx,yongtang,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,yongtang,gunan,drpngx,drpngx,drpngx",2017-12-19 20:15:18,2018-01-01 01:03:21
PR,Update license year,TO DO x Wait to the next year 100 done depends on timezone Merge octocat,,"drpngx,drpngx,drpngx",2017-12-31 20:26:04,2018-01-01 01:46:02
PR,Revert add c gradient for op Pow 15245,This reverts commit e1ded7fa7cfacaeea43a903e738dd3fe2baabc57 CC,,"gunan,drpngx,gunan,facaiy",2017-12-31 23:20:10,2018-01-01 05:37:03
PR,Upgrade all TF base images to ubuntu 16,,,"gunan,yifeif,angersson,yifeif,gunan,gunan,drpngx,gunan,drpngx,gunan",2017-12-18 21:06:34,2018-01-01 06:35:57
PR,Revert C gradient for Select 14862,This reverts commit dc355dc491836f1202a2c3fcef0a9da6902fd7da,,"gunan,gunan",2018-01-01 05:41:02,2018-01-01 07:11:32
PR,Branch 180441903,,,"drpngx,drpngx",2018-01-01 00:05:18,2018-01-01 07:18:16
PR,Optimizing code and adding from http to https,,,"rajendraarora16,asimshankar,asimshankar,rajendraarora16,asimshankar,rajendraarora16,rajendraarora16,drpngx",2017-12-29 09:35:10,2018-01-01 07:26:27
PR,Trivial python syntax fixes,,,,2018-01-01 07:57:38,2018-01-01 08:15:45
IS,FeatureRequest Decorator for estimator input fn,In the documentation for Passing input fn Data to Your Model passing input fn data to your model there are a few methods provided for using a function to construct input data and then wrapping that to get a function object The documentation suggests functools partial or lambda Would it be possible to provide a python decorator maybe under the tf estimator module Looking at suggested decorator and usage below I think it makes the code cleaner when making these reusable input functions Proposed decorator n b name to be improved aligned with TF If this is favourable I would be happy to provide a contribution towards such an addition System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS TensorFlow installed from source or binary pip TensorFlow version use command below v1 4 0 8 gbca50da6eb 1 4 0 Python version 3 6 3 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A,,"facaiy,reedwm,martinwicke,ispirmustafa,martinwicke,martinwicke",2017-12-07 01:45:44,2018-01-01 10:25:54
PR,remove trailing semicolon at the end of line,removed trailing semicolon in the statement according to Google Python Style Guide Semicolons Do not terminate your lines with semi colons and do not use semi colons to put two commands on the same line,,drpngx,2018-01-01 16:17:46,2018-01-01 19:03:28
PR,Fix invalid Markdown in docstring,There is currently invalid markdown in the docstring which is causing the docs site to render incorrectly img width 902 alt screen shot 2018 01 01 at 10 17 59 am src This patch fixes the indentation on the MD code block which should fix the issue,,drpngx,2018-01-01 18:19:03,2018-01-01 21:20:03
PR,R1 2,,,drpngx,2018-01-01 18:44:44,2018-01-02 01:20:34
IS,Error when bazel building after pull down newest master branch,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 12 Bazel version if compiling from source 0 5 4 CUDA cuDNN version 8 0 61 GPU model and memory NVIDIA Corporation Device 1b06 Exact command to reproduce,,aselle,2017-11-16 04:04:57,2018-01-02 05:43:34
PR,order quantized table by value for ease of reading,,,caisq,2018-01-02 15:18:42,2018-01-02 17:40:27
PR,order quantized table by value for ease of reading,,,caisq,2018-01-02 15:18:10,2018-01-02 17:40:42
IS,How to run the inceptionv3 on the Knights Landing Intel Xeon Phi,I have built tensorflow from scratch for the Knights Landing and it seems to give only 4 5images sec Can someone give a procedure to run these standard benchmarks,,"reedwm,reedwm,tfboyd,tfboyd,tfboyd,tfboyd,tfboyd",2017-08-10 18:39:25,2018-01-02 17:55:02
IS,weighted cross entropy with logits produces wrong result,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 CUDA cuDNN version 8 0 6 0 GPU model and memory Geforce GTX 1080 Ti 12G Describe the problem I am trying to use tf nn weighted cross entropy with logits API but I found I just can not get the right result when the weight is not 1 0 1 0 means no weight Source code logs running result loss1 1 02193164517 loss1 1 96332399324 loss2 1 02193164517 loss2 4 80529539791,,,2018-01-02 17:11:06,2018-01-02 18:23:20
IS,Feature Dataset API Reinitializable Iterator resets to first dataset element,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow slightly altered stock example see below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary 1 4 0 from source Python version 3 6 3 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version 8 0 GPU model and memory Nvidia 1060 Describe the problem Currently the re initializable iterator API using from structure and Iterator make initializer always resets the get next op of the iterator to fetch the first element of its Dataset instance again after running sess run training init op or sess run validation init op respectively Is this really the intended behavior This means that if you want to switch between training and validation Datasets within one epoch i e in a shorter rhythm than the full dataset length you will always only iterate over the first batch size number of training steps before validation step elements of the training set during training Source code logs I guess the code example will make it clearer,,"mrry,mrry,mrry",2017-12-18 14:49:11,2018-01-02 18:44:01
IS,Feature Request Add payload only compression support for TFRecord files,This feature request is a follow up to PR 12369 and issue 12344 Issue 12344 raised the feature request of supporting gzipped TFRecord files However the compression means the TFRecord file is gzipped as a whole and the header is compressed as well In certain situations it might be desirable to expose the header and only compress the payload for better visibility and lookup performance This issue is a feature request to support payload only compression for TFRecord files,,"yongtang,yongtang,asimshankar",2017-11-08 02:18:40,2018-01-02 19:00:38
PR,order quantized table by value for ease of reading,,,caisq,2018-01-02 15:11:26,2018-01-02 19:29:58
PR,Fix kmeans gpu and upgrading TF base images to 16,,,av8ramit,2018-01-02 21:50:19,2018-01-02 22:43:09
PR,Fix docs to recommend cuDNN 6 0 rather than the old 5 1 or non exist,ent 6 1 Also see 14805 PiperOrigin RevId 177097162,,av8ramit,2018-01-02 23:43:18,2018-01-02 23:48:54
PR,Fixing the item test failure,Implementing fix for the item test Push CP will take quite a long time,,av8ramit,2018-01-02 23:59:00,2018-01-03 00:00:44
PR,configure eagerly determine the truthfulness of environment variables,Eagerly determine the truthfulness of environment variables in get var function This way we can skip checking e g Android workspace setup if the user sets TF SET ANDROID WORKSPACE 0 Tested manually,,"caisq,caisq,caisq,caisq,caisq,caisq,caisq",2018-01-02 05:59:18,2018-01-03 01:13:02
IS,contrib all reduce not update to latest nccl,send op dst tensors nccl broadcast level 2 output w dst devices this line is out of date hope update to latest,,skye,2017-12-26 13:39:35,2018-01-03 01:41:42
IS,How to register all kernels to Android lib,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary binary TensorFlow version use command below 1 0 1 Python version 3 4 Bazel version if compiling from source 0 4 You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I am trying to compile a Android lib which can load a MetaGraph into a session as this link 43639305 specifies I first extracts a GraphDef from this MetaGraph and uses this GraphDef to generate ops to register h Then I compile the lib as bazel build my model test test lib copt DSELECTIVE REGISTRATION crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a However when I trying to run the test lib it complains some kernels are not registered Then I brutally adds all kernels to be registered as define SHOULD REGISTER OP KERNEL clz true However it still complains How can I solve this by adding this Const kernel or simply registering all kernels,,skye,2017-12-30 03:16:38,2018-01-03 01:57:02
IS,Tensorflow Python3,i recently installed tensorflow in my linux machine with pip when i try to import tensorflow it show me this i installed tensorflow cpu version with this command pip install tensorflow this warning do not affect the script but its annoying can anyone explain to me what is this OS Linux ubuntu Python Version 3 6 4,,,2017-12-30 12:58:04,2018-01-03 01:57:30
IS,BUG REPORT how to set TF CONFIG bug,System information python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 4 0 19 ga52c8d9' '1 4 1' Describe the problem NORMAL CODE but can not set TF CONFIG by os environ with json dumps correctly Need your help Thanks,,,2018-01-02 08:56:17,2018-01-03 02:05:57
IS,Summary op crashes when run multiple times,System information Windows 10 16299 pip install tensorflow gpu b'unknown' 1 4 0 3 5 CUDA V9 1 85 cuDNN version 6 Geforce 930 MX 2GB Describe the problem Opening a session for the second time and trying to run a summary op causes crash for some reason The error message is misleading as a placeholder is provided Source code logs,,"skye,skye",2017-12-31 04:19:35,2018-01-03 02:06:26
IS,Protobuf Compilation object detection protos anchor generator pb2 py Permission denied issue,I need to implement object detection using Tensorflow but Im getting Protobuf Compilation object detection protos anchor generator pb2 py Permission denied issue when executing protoc object detection protos proto python out in Protobuf Compilation this is the issue i already having error Here is my link for Tensorflow model url and i used Protocol Buffers v3 4 0 So can anyone knows how to solve and execute that command,,skye,2017-12-31 12:07:01,2018-01-03 02:10:18
IS,Training broke with ResourceExausted error,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 5 CUDA cuDNN version 8 GPU model and memory TITAN X 12207MiB Most Probably everyone will be asking about this is a question for StackOverflow Here is the link to the StackOverflow question But please take a look at the problem There could be some bug in tensorflow as the error occurs after 32 epoch Here is the code of the model A short description of the model would be Character level Embedding Vector Embedding lookup LSTM1 Word level Embedding Vector Embedding lookup LSTM2 LSTM1 LSTM2 single layer MLP softmax layer CRF layer LSTM1 LSTM2 Single layer MLP WGAN discriminator While running the code it produces the following error output at the epoch 32 ResourceExhaustedError see above for traceback OOM when allocating tensor with shape 24760 100 Node chars bidirectional rnn bw bw while bw lstm cell split Split T DT FLOAT num split 4 device job localhost replica 0 task 0 device GPU 0 gradients 2 Add 3 y chars bidirectional rnn bw bw while bw lstm cell BiasAdd Node bi lstm bidirectional rnn bw bw stack 167 Recvclient terminated false recv device job localhost replica 0 task 0 device CPU 0 send device job localhost replica 0 task 0 device GPU 0 send device incarnation 1 tensor name edge 636 bi lstm bidirectional rnn bw bw stack tensor type DT INT32 device job localhost replica 0 task 0 device CPU 0 My question is if there is any error then it should occur in the first epoch why at 32 epoch I am using embedding lookup in following way Where embeddings is a 61698 100 sized vector which is only 24 MB However in the error message it showed the error with 24760 100 sized vector which is only 10MB It also produces warning while declaring optimizers for the model it was suggested as below gradients impl py 96 UserWarning Converting sparse IndexedSlices to a dense Tensor of unknown shape This may consume a large amount of memory,,skye,2018-01-01 11:31:01,2018-01-03 02:13:59
IS,Rank calculated incorrectly using 'gen array ops rank ',System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 2 1 0 gb4957ff' '1 2 1' Python version 2 7 12 Bazel version if compiling from source 0 4 5 CUDA cuDNN version No GPU GPU model and memory No GPU Exact command to reproduce tensorflow python kernel tests transpose op test The problem While running TensorFlow tests such as tensorflow python kernel tests transpose op test or tensorflow contrib distributions mixture test on a big endian system they fail with error ValueError Dimension must be 2 but is 0 for 'Mixture 1 sample Categorical sample transpose' op 'Transpose' with input shapes 1 4 0 After debugging a little realized that while calculating rank of a tensor in transpose method L1276 the rank is calculated incorrectly via gen array ops rank a I tried replacing rank gen array ops rank a to use the array ops rank a method instead and it works perfectly fine I tried the same change on an x86 machine and it does not break anything there I am unable to understand the difference between the two methods though Also is there some major impact of above change which is not very obvious,,"namrata-ibm,mrry,namrata-ibm,frreiss,namrata-ibm,frreiss,namrata-ibm,namrata-ibm,mrry,namrata-ibm,mrry,namrata-ibm",2017-07-11 12:24:13,2018-01-03 04:33:17
IS,Custom gradient aggregation methods,I would like a way to apply some custom gradient aggregation ops Probably the simplest thing to do is just allow tf gradients and Optimizer compute gradients to return un aggregated gradients so I could work with those Anyway seems like an easy fix I will do this myself in a month or so cant now as on holiday but if someone else wants to do it has some thoughts I am interested,,"yaroslavvb,yaroslavvb,yaroslavvb",2017-12-31 20:41:42,2018-01-03 05:13:03
IS,Missing Feature Input Pipeline for Models with Multi step Optimization,Describe the problem After some searching and reading e g 7951 I found the current input pipeline framework is generally lack of support for models with multi step optimization In most of the models before GAN General Adversarial Networks a model almost has one optimization function that is we optimize over a mini batch of input data once in a step While starting from GAN many models have two or more optimization functions in other words they sequentially optimize on several functions using the same batch of data Adversarial Autoencoders The current input pipeline works fine with a unique optimization operation per step where the tf Session will pull a batch of data from the input queue once For multi step optimization models if you link all steps with a unique input queue then the queue will be pulled several times if you link all sequential optimization steps with that queue Apparently this is completely wrong From my point of view I think we should add a peek op in tf QueueBase for supporting multistep sequential optimization So for example for GAN we can link optimization over discriminator with a peek many op and link optimization over generator with a dequeue many op In general for multiple steps we can do peek many peek many dequeue many For the new tf data Dataset API when we called session run we advance the iterator So in the new data importing API we still lack of this feature I think currently a workaround of this would be building a buffer with tf Variable and make all subsequent optimization step depends on the snapshot of the buffer Like In this case we have to copy the entire batch of data for each step,,mrry,2017-09-26 02:16:55,2018-01-03 06:01:11
IS,Feature request non blocking enqueue operations,As for version 1 2 queue operations involving enqueuing can block if a queue is full or empty This is very useful for designing input threads feeding the queue from static datasets as it suspends the thread until it can proceed doing its work However this behavior might not be desirable or acceptable if instead the data being fed comes from an asynchronous and continuously changing live source at a best effort basis because blocking the thread implies missing the continuity of the source For example let is say we have a distributed reinforcement learning environment where an external game plays asynchronously and a thread tries its best to read the most recent state of the game and input the actions to take As a result this thread keeps producing training batches that are enqueued in a PaddingFIFOQueue which are consumed by a separate trainer In this case if for any reason the trainer takes too long or has an un expected peak in the number of training batches it receives the queue will fill and the producer thread s will block Since the source of data the external game keeps playing this means that the next time the producer threads unblock they will probably have lost temporal coherency on the game In this case dropping a training batch would be more desirable than blocking the thread until such batch can be enqueued For this reason I would like to propose the following feature a new optional argument to the enqueuing methods enqueue and enqueue many that allows to immediately return when the queue is full instead of blocking the thread This argument would default to the existing behavior e g 'non blocking False' so no code updates are required Signaling if how many elements were successfully enqueued or failed to do so is likely a desirable output of a non blocking enqueue operation However implementing it might not be trivial without altering the function return signature If we find this is something we should provide it might be better to instead of adding a new argument simply add new non blocking versions of the enqueue ops that return a op num elements discarded tuple Any comments or suggestions are most welcome,,"yaroslavvb,yaroslavvb,yaroslavvb,mrry",2017-08-05 08:02:31,2018-01-03 06:03:20
IS,Dataset API fromGenerator Functionality,mrry I was looking at the code for the fromGenerator function and I notice that you do iter generator to create multiple parallel iterators over the same generator Maybe I'm not too familiar with the semantics of a Python generator but my impression was that it represents a continuation and it is not necessarily repeatable meaning that you would have to cache all the elements you get in order to reproduce them For example let is say a generator is querying an online service and yielding a different tensor at each time point dependent on the answer it gets from that service This would not be repeatable without caching those tensors So in that case how would your implementation behave And in more general what does the iter function applied in this setting mean Regarding the caching of elements I think that if there is a problem with the current implementation then the right way to do this would be something along the lines of 1 Create a dataset from a generator as it is currently done but also store a flag in it specifying it is a GeneratorDataset could also be subclassing dataset to make things simpler 2 When repeat is called on such a dataset convert the generator to something like a Scala stream which simply memoizes elements as you obtain them but lazily evaluates the tail of your sequence sort of like an iterator but with memoization and then return a dataset that uses that stream as its source It may be totally unnecessary depending on the semantics of the iter function but based on a quick search I did I could not find enough information for this setting,,"eaplatanios,ppwwyyxx,mrry",2017-09-11 17:07:28,2018-01-03 06:06:38
IS,tf stack eats memory over time,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 3 5 CUDA cuDNN version 8 GPU model and memory 1060 6GB Describe the problem I use tf stack to stack 2 images But the memory used by this program increase over time I use memory profiler check it it is caused by tf stack here is the minimal re produce code First I profile it line by line here is the result you can see it very clearly that line 26 take a lot of memory My image is 800 600 and I only stack 2 image each time so 1 3G memory consumption is not normal Line Mem usage Increment Line Contents 11 190 0 MiB 190 0 MiB 12 def stack images 13 190 0 MiB 0 0 MiB image file list glob glob car images jpg 14 421 6 MiB 231 7 MiB sess tf Session 15 16 1998 4 MiB 0 0 MiB for in range 300 17 read image 18 1992 5 MiB 1 5 MiB image1 tf gfile FastGFile image file list 0 'rb' read 19 1992 5 MiB 0 0 MiB image2 tf gfile FastGFile image file list 1 'rb' read 20 decode image 21 1992 8 MiB 77 6 MiB image1 decode tf image decode image image1 channels 3 22 1993 3 MiB 108 6 MiB image2 decode tf image decode image image2 channels 3 23 stack image 24 1993 3 MiB 0 7 MiB image stack tf stack image1 decode image2 decode 25 run session 26 1998 4 MiB 1350 4 MiB r image stack sess run image stack 27 mark function so I can check the memory usage of every loop 28 1998 4 MiB 29 0 MiB function mark 29 force garbage collection so all the un reference variable will be freed 30 1998 4 MiB 0 0 MiB del r image stack 31 1998 4 MiB 8 9 MiB gc collect Then I profile it over time I use function function mark to distinguish each loop So we can see it very clearly that the memory usage of this program is increase over time figure 1 My question is How should I avoid this problem because it cause a serious performance regression,,mrry,2018-01-03 02:15:52,2018-01-03 06:27:07
IS,GPU Isolated docker containers fail in a distributed training with more than one worker,System information Have I written custom code Yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary No TensorFlow version v1 2 0 rc2 21 g12f033d 1 2 0 Python version Python 3 5 2 Bazel version CUDA cuDNN version 'CUDA VERSION' '8 0 61' 'CUDNN VERSION' '5 1 10' GPU model and memory 8x GCE K80 Tesla Context 1 I have created a Cloud Compute Engine instance with 8 GPUs 2 I have started a couple of GPU isolated containers with intention to run each as a separate worker sudo NV GPU 0 nvidia docker run it name tf worker 0 p 8000 8000 v pwd repo notebooks repo gcr io tensorflow tensorflow latest gpu py3 bin bash 3 To create a loopback to the host I run following echo netstat nr grep ' 0 0 0 0' awk ' print 2 ' dockerhost etc hosts Through dockerhost it properly detects and pings all the open ports on the host including processes running in other containers that are exposed with p hostport containerport Problem Case 1 Normal When I run a distributed TensorFlow script using dockerhost with only one worker and any number of ps servers e g ps hosts dockerhost 7000 dockerhost 7001 worker hosts dockerhost 8000 everything works as intended local grcp servers are launched worker and ps communicate well Case 2 Issue When I increase the number of worker jobs e g worker hosts dockerhost 8000 dockerhost 8001 i get Master init Unavailable and Master init Internal Errors Case 3 Normal BTW everything works smoothly when I run all the workers inside a single container isolating GPUs with CUDA VISIBLE DEVICES Case 4 Issue Also it is worth mentioning here that using queues solution to shutdown ps proposed in fails in both Case 1 and Case 2 This results in immediate tensorflow python framework errors impl UnavailableError when starting ps Statement Is this an intended behaviour Or does such setting is insufficient for a distributed training and a special master server or a cluster manager is needed It just seems interesting that it would work for one worker but not for more Reproducible Toy Example repr txt Log worker log txt,,"mrry,mrry,mrry,mrry",2017-07-12 13:07:13,2018-01-03 06:40:38
IS,Tensorflow Dataset from generator blocks input,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 both win7 and CentOS 7 2 1511 TensorFlow installed from source or binary pip3 TensorFlow version use command below 'v1 4 0 rc1 11 g130a514 1 4 0' and '1 5 0 dev20180102' Python version 3 5 3 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA Describe the problem I submitted a problem on stackoverflow but nobody solved it So I open it here Does anybody can help to solve it Here is the problem I installed tensorflow 1 4 0 via pip without gpu support My python version is 3 5 3,,"mrry,mrry,mrry",2017-12-31 12:14:53,2018-01-03 06:41:38
IS,Feature Request Support for None values in tf contrib data Dataset,It would be very handy if the Dataset API supports None types The idea is to be able to use the same Iterator object for the training and the test datasets As the training dataset contains labels and the test dataset does not the only workaround I know at the moment is to use some dummy labels in order to make the two datasets compatible with the same Iterator This can waste a lot of memory though and is not a clean solution Instead maybe it can be possible to create a Dataset from None that behaves in a way such that its output types and output shapes are compatible with any other type and shape but does not consume so much memory Here is a quick example,,"drpngx,mrry,mrry",2017-10-20 19:59:50,2018-01-03 06:42:47
IS,Unable to find source java class ' Users vinay garg AndroidStudioProjects tensorflow tensorflow java src main java org tensorflow op core Constant java',I follow the instructions on the tensorflow official website on how to import android samples I did exactly as they said but when I try to run the app it shows the following error Error Execution failed for task ' compileDebugJavaWithJavac' Unable to find source java class ' Users vinay garg AndroidStudioProjects tensorflow tensorflow java src main java org tensorflow op core Constant java' because it does not belong to any of the source dirs ' Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android src main java Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android src Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android build types debug java Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android gradleBuild generated source r debug Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android gradleBuild generated source buildConfig debug Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android gradleBuild generated source aidl debug Users vinay garg AndroidStudioProjects tensorflow tensorflow examples android gradleBuild generated source rs debug ' The problem is Constants java file is in the parent directory and not in the sample project directory I tried to find the usage of the Constants java file but can not find its use anywhere in the sample project What am I missing here,,,2018-01-02 13:19:39,2018-01-03 07:17:55
IS,GO Tests Fail for Tensorflow 1 4 0 but example code works on amd64 and arm64,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 on amd64 and arm64 TensorFlow installed from source or binary amd64 binary arch64 source d752244f tensorflow libtensorflow so TensorFlow version use command below 1 4 0 Python version python3 5 Bazel version if compiling from source arm64 0 7 0 GCC Compiler version if compiling from source arm64 5 4 0 6ubuntu1 16 04 5 CUDA cuDNN version amd64 cuda 8 0 libcudnn so 6 GPU model and memory amd64 GeForce GTX 1060 6071MiB Exact command to reproduce go test github com tensorflow tensorflow tensorflow go Describe the problem Test fail but example code example package work on both platforms Source code logs amd64,,"asimshankar,asimshankar",2017-12-12 10:41:30,2018-01-03 08:12:37
IS,compile error with config sycl,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 the latest version I git from tensorflow Python version 3 6 3 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version no GPU model and memory no Exact command to reproduce bazel build c opt config sycl tensorflow tools pip package build pip package something else OpenCl version 1 2 computecpp path usr local computecpp version 0 5 0 computecpp info Device Info Discovered 1 devices matching platform any device type any Device 0 Device is supported UNTESTED Vendor not tested on this OS CL DEVICE NAME Hainan CL DEVICE VENDOR Advanced Micro Devices Inc CL DRIVER VERSION 2482 3 CL DEVICE TYPE CL DEVICE TYPE GPU clinfo Number of platforms 1 Platform Name AMD Accelerated Parallel Processing Platform Vendor Advanced Micro Devices Inc Platform Version OpenCL 2 0 AMD APP 2482 3 Platform Profile FULL PROFILE Platform Extensions cl khr icd cl amd event callback cl amd offline devices Platform Extensions function suffix AMD Platform Name AMD Accelerated Parallel Processing Number of devices 1 Device Name Hainan Device Vendor Advanced Micro Devices Inc Device Vendor ID 0x1002 Device Version OpenCL 1 2 AMD APP 2482 3 Driver Version 2482 3 Device OpenCL C Version OpenCL C 1 2 Device Type GPU Device Profile FULL PROFILE Device Board Name AMD AMD Radeon HD 8500M Device Topology AMD PCI E 04 00 0 Max compute units 4 SIMD per compute unit AMD 4 SIMD width AMD 16 SIMD instruction width AMD 1 Max clock frequency 850MHz Graphics IP AMD 6 0 Device Partition core Max number of sub devices 4 Supported partition types none specified Max work item dimensions 3 Max work item sizes 256x256x256 Max work group size 256 Preferred work group size multiple 64 Wavefront width AMD 64 Preferred native vector sizes char 4 4 short 2 2 int 1 1 long 1 1 half 1 1 n a float 1 1 double 1 1 cl khr fp64 Half precision Floating point support n a Single precision Floating point support core Denormals No Infinity and NANs Yes Round to nearest Yes Round to zero Yes Round to infinity Yes IEEE754 2008 fused multiply add Yes Support is emulated in software No Correctly rounded divide and sqrt operations Yes Double precision Floating point support cl khr fp64 Denormals Yes Infinity and NANs Yes Round to nearest Yes Round to zero Yes Round to infinity Yes IEEE754 2008 fused multiply add Yes Support is emulated in software No Correctly rounded divide and sqrt operations No Address bits 32 Little Endian Global memory size 2140311552 1 993GiB Global free memory AMD printDeviceInfo 68 get number of CL DEVICE GLOBAL FREE MEMORY AMD error 33 Global memory channels AMD 2 Global memory banks per channel AMD 8 Global memory bank width AMD 256 bytes Error Correction support No Max memory allocation 1591773593 1 482GiB Unified memory for Host and Device No Minimum alignment for any data type 128 bytes Alignment of base address 2048 bits 256 bytes Global Memory cache type Read Write Global Memory cache size 16384 Global Memory cache line 64 bytes Image support Yes Max number of samplers per kernel 16 Max size for 1D images from buffer 134217728 pixels Max 1D or 2D image array size 2048 images Base address alignment for 2D image buffers 256 bytes Pitch alignment for 2D image buffers 256 bytes Max 2D image size 16384x16384 pixels Max 3D image size 2048x2048x2048 pixels Max number of read image args 128 Max number of write image args 8 Local memory type Local Local memory size 32768 32KiB Local memory syze per CU AMD 65536 64KiB Local memory banks AMD 32 Max constant buffer size 65536 64KiB Max number of constant args 8 Max size of kernel argument 1024 Queue properties Out of order execution No Profiling Yes Prefer user sync for interop Yes Profiling timer resolution 1ns Profiling timer offset since Epoch AMD 1512650783761772748ns Thu Dec 7 20 46 23 2017 Execution capabilities Run OpenCL kernels Yes Run native kernels No Thread trace supported AMD No SPIR versions 1 2 printf buffer size 1048576 1024KiB Built in kernels Device Available Yes Compiler Available Yes Linker Available Yes Device Extensions cl khr fp64 cl amd fp64 cl khr global int32 base atomics cl khr global int32 extended atomics cl khr local int32 base atomics cl khr local int32 extended atomics cl khr int64 base atomics cl khr int64 extended atomics cl khr 3d image writes cl khr byte addressable store cl khr gl sharing cl amd device attribute query cl amd vec3 cl amd printf cl amd media ops cl amd media ops2 cl amd popcnt cl khr image2d from buffer cl khr spir cl khr gl event NULL platform behavior clGetPlatformInfo NULL CL PLATFORM NAME AMD Accelerated Parallel Processing clGetDeviceIDs NULL CL DEVICE TYPE ALL Success AMD clCreateContext NULL default Success AMD clCreateContextFromType NULL CL DEVICE TYPE CPU No devices found in platform clCreateContextFromType NULL CL DEVICE TYPE GPU Success 1 Platform Name AMD Accelerated Parallel Processing Device Name Hainan clCreateContextFromType NULL CL DEVICE TYPE ACCELERATOR No devices found in platform clCreateContextFromType NULL CL DEVICE TYPE CUSTOM No devices found in platform clCreateContextFromType NULL CL DEVICE TYPE ALL Success 1 Platform Name AMD Accelerated Parallel Processing Device Name Hainan ICD loader properties ICD loader Name OpenCL ICD Loader ICD loader Vendor OCL Icd free software ICD loader Version 2 2 8 ICD loader Profile OpenCL 1 2 NOTE your OpenCL library declares to support OpenCL 1 2 but it seems to support up to OpenCL 2 1 too Describe the problem I want Compile With sycl config with the command bazel build c opt config sycl tensorflow tools pip package build pip package but unfortunately get the error Illegal ambiguous match on configurable attribute deps in sycl sycl sycl using sycl ccpp sycl using sycl trisycl Multiple matches are not allowed unless one is unambiguously more specialized I did not know what casue this compile error Please Help,,drpngx,2017-12-08 06:34:19,2018-01-03 08:12:39
IS,Tensorflow Java Api Graph support any other than InceptionV3,I'm fairly new to tensorflow but I have got a general idea of it I have retrained Faster RCNN coco model on my own images in ubuntu and exported the frozen graph Now I'm busy writing an Java app in windows that will use the model for object detection I need bounding boxes etc to can not just use the normal classifier In my java app when I try to load importGraphDef the frozen graph converted to bytes I get the following error Op type not registered 'NonMaxSuppressionV2' Any and all examples I find online of implementing the tensorflow java api uses inceptionv3 So my guess is that the java API does not yet support other types faster rcnn in my case models Is that correct or are there something else I should be looking at if it is then I have to rewrite my java app in python And if so does anyone know when support will be implemented Thank you,,"asimshankar,asimshankar",2017-11-14 13:20:26,2018-01-03 08:14:12
IS,Batch Norm variance output mismatches with tf 1 4 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from binary binary TensorFlow version use command below 1 4 0 Python version 2 7 0 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 5 0 GPU model and memory GTX1080 and 8 GB Exact command to reproduce python test google bn py Describe the problem Batch normalization test failed with tensorflow version 1 4 0 but the same test passed with tensorflow version 1 3 0 Source code logs assert array almost equal variance expected var decimal 4 AssertionError Arrays are not almost equal to 4 decimals mismatch 100 0 x array 0 08 0 0908 0 0773 dtype float32 y array 0 0792 0 0898 0 0764,,"drpngx,drpngx,ppwwyyxx",2017-12-10 09:58:04,2018-01-03 10:22:17
IS,Any other official way not public in github issues to report security bug of tensorflow,Hi I have found a security issue in Tensorflow An attacker can easily execute arbitary code on victim machine through this issue I think it has severe secure impact on tensorflow users So it is not proper to disclosure this issue on github issues publicly before it is fixed Is there any other official way to report security issue I will explain the details Thanks,,,2017-12-05 06:48:56,2018-01-03 12:04:34
IS,Ca not build with basel Python Configuration Error define PYTHON BIN PATH,Ca not get what im doing wrong Win7 python 3 6 tensorflow from master cuda 9 0 cudnn 7 0 5 for cuda 9 0 basel and swig loaded today C Users Andrey Desktop tensorflow bazel clean INFO Starting clean this may take a while Consider using async if the clea n takes more than several minutes C Users Andrey Desktop tensorflow python configure py WARNING Running Bazel server needs to be killed because the startup options ar e different You have bazel 0 8 1 installed Please specify the location of python Default is C Users Andrey Anaconda3 pyt hon exe Found possible Python library paths C Users Andrey Anaconda3 lib site packages Please input the desired Python library path to use Default is C Users Andre y Anaconda3 lib site packages Do you wish to build TensorFlow with XLA JIT support y N y XLA JIT support will be enabled for TensorFlow Do you wish to build TensorFlow with GDR support y N y GDR support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N y VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N y CUDA support will be enabled for TensorFlow Please specify the CUDA SDK version you want to use e g 7 0 Leave empty to d efault to CUDA 9 0 Please specify the location where CUDA 9 0 toolkit is installed Refer to README md for more details Default is C Program Files NVIDIA GPU Computing Toolkit CUDA v9 0 Please specify the cuDNN version you want to use Leave empty to default to cuD NN 7 0 Please specify the location where cuDNN 7 library is installed Refer to README md for more details Default is C Program Files NVIDIA GPU Computing Toolkit C UDA v9 0 Please specify a list of comma separated Cuda compute capabilities you want to b uild with You can find the compute capability of your device at com cuda gpus Please note that each additional compute capability significantly increases your build time and binary size Default is 3 5 5 2 Do you wish to build TensorFlow with MPI support y N n No MPI support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Add config mkl to your bazel command to build with MKL support Please note that MKL on MacOS or windows is still not supported If you would like to use a local MKL instead of downloading please set the envi ronment variable TF MKL ROOT every time before build Would you like to interactively configure WORKSPACE for Android builds y N n Not configuring the WORKSPACE for Android builds C Users Andrey Desktop tensorflow bazel build config opt config win cuda tensorflow tools pip package build pip package Loading Loading 0 packages loaded Analyzing target tensorflow tools pip package build pip package 3 packages l oaded Analyzing target tensorflow tools pip package build pip package 24 packages loaded Analyzing target tensorflow tools pip package build pip package 34 packages loaded Analyzing target tensorflow tools pip package build pip package 72 packages loaded ERROR C users andrey desktop tensorflow third party py numpy BUILD 11 1 no su ch package ' local config python ' Traceback most recent call last File C users andrey desktop tensorflow third party py python configure bzl line 291 create local python repository repository ctx File C users andrey desktop tensorflow third party py python configure bzl line 251 in create local python repository check python bin repository ctx python bin File C users andrey desktop tensorflow third party py python configure bzl line 204 in check python bin fail define s ' s' is not execut File C users andrey desktop tensorflow third party py python configure bzl line 27 in fail fail sPython Configuration Error Python Configuration Error define PYTHON BIN PATH 'C Users Andrey Anaconda3 python exe' is not executable Is it the python binary and referenced by ' third party py numpy headers' Analyzing target tensorflow tools pip package build pip package 72 packages loaded ERROR Analysis of target ' tensorflow tools pip package build pip package' fai led build aborted Loading failed INFO Elapsed time 6 710s FAILED Build did NOT complete successfully 72 packages loaded,,gunan,2017-12-17 02:51:21,2018-01-03 12:28:49
PR,WIP Add bazel runfiles manifest support for Windows,To implement the ideas in msg bazel discuss Po8xN8dhWkI sWPUYV9YBAAJ Now tensorflow core example example parser configuration test is disabled on Windows because it cannot find the data files testing RunFileRelocator GetInstance Relocate is the replacement of testing TensorFlowSrcRoot We should mark TensorFlowSrcRoot as deprecated or completely remove it Places need to change c c api test cc cc saved model loader test cc compiler aot codegen test cc compiler xla service gpu llvm gpu backend utils test cc compiler xla tests sample file test cc contrib ffmpeg default ffmpeg lib test cc contrib lite models test utils h contrib lite testing generated examples zip test cc contrib session bundle bundle shim test cc contrib session bundle test util cc core distributed runtime rpc grpc testlib cc core grappler costs graph properties test cc core grappler utils scc test cc core kernels hexagon graph transferer test cc core kernels spectrogram test cc core platform cloud google auth provider test cc core profiler internal tfprof show test cc core profiler internal tfprof stats test cc core profiler internal tfprof tensor test cc core profiler internal tfprof timeline test cc core example example parser configuration test cc core platform cloud oauth client test cc Ref TODO 1 deal with folders 2 do not translate abs path,,"snnn,snnn,laszlocsomor,snnn,laszlocsomor,laszlocsomor,snnn,snnn,laszlocsomor,snnn,laszlocsomor,snnn,laszlocsomor,snnn",2017-12-19 09:55:24,2018-01-03 13:02:48
PR,Use BSD fnmatch on Windows,15501 It has a BSD 3 Clause copyright,,"snnn,snnn",2017-12-20 06:54:56,2018-01-03 13:05:01
IS,ImportError libcublas so 9 0 cannot open shared object file,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-03 13:24:29,2018-01-03 13:28:23
IS,CPU usage drops after several steps,I am running a tensorflow computation graph The same graph was running fine before but all of a sudden I noticed that after several steps and checkpoint the CPU usage drops from more than 600 to 100 for the rest of the session It seems like all executors are dying when saving maybe and the computation keeps running on only 1 Core shooting up and down from 100 to 200 I also posted the issue on stack overflow,,drpngx,2017-12-09 16:46:23,2018-01-03 14:56:14
IS,no such file or directory 'x86 64' when building the library in TensorFlow Lite for iOS,Hi all I encountered with an issur when trying to setting up the environment to build TensorFlow Lite for iOS building But when I was trying to build the library for all five supported architectures on iOS using tensorflow contrib lite build ios universal lib sh I have the follwing issue xcrun error SDK iphonesimulator cannot be located xcrun error SDK iphonesimulator cannot be located xcrun error unable to lookup item 'PlatformPath' in SDK 'iphonesimulator' xcrun error SDK iphonesimulator cannot be located xcrun error SDK iphonesimulator cannot be located xcrun error unable to lookup item 'Path' in SDK 'iphonesimulator' xcrun error SDK iphoneos cannot be located xcrun error SDK iphoneos cannot be located xcrun error unable to lookup item 'SDKVersion' in SDK 'iphoneos' gcc std c 11 O3 DNDEBUG miphoneos version min 9 0 DGEMMLOWP ALLOW SLOW SCALAR FALLBACK fembed bitcode Wno c 11 narrowing mno thumb fno exceptions isysroot arch x86 64 O3 I I Users zhangjiawei tensorflow tensorflow contrib lite I Users zhangjiawei tensorflow tensorflow contrib lite downloads I Users zhangjiawei tensorflow tensorflow contrib lite downloads eigen I Users zhangjiawei tensorflow tensorflow contrib lite downloads gemmlowp I Users zhangjiawei tensorflow tensorflow contrib lite downloads neon 2 sse I Users zhangjiawei tensorflow tensorflow contrib lite downloads farmhash src I Users zhangjiawei tensorflow tensorflow contrib lite downloads flatbuffers include I Users zhangjiawei tensorflow tensorflow contrib lite gen obj I usr local include c tensorflow contrib lite allocation cc o Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite allocation o gcc miphoneos version min 9 0 fembed bitcode mno thumb isysroot arch x86 64 O3 I I Users zhangjiawei tensorflow tensorflow contrib lite I Users zhangjiawei tensorflow tensorflow contrib lite downloads I Users zhangjiawei tensorflow tensorflow contrib lite downloads eigen I Users zhangjiawei tensorflow tensorflow contrib lite downloads gemmlowp I Users zhangjiawei tensorflow tensorflow contrib lite downloads neon 2 sse I Users zhangjiawei tensorflow tensorflow contrib lite downloads farmhash src I Users zhangjiawei tensorflow tensorflow contrib lite downloads flatbuffers include I Users zhangjiawei tensorflow tensorflow contrib lite gen obj I usr local include c tensorflow contrib lite context c o Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite context o gcc std c 11 O3 DNDEBUG miphoneos version min 9 0 DGEMMLOWP ALLOW SLOW SCALAR FALLBACK fembed bitcode Wno c 11 narrowing mno thumb fno exceptions isysroot arch x86 64 O3 I I Users zhangjiawei tensorflow tensorflow contrib lite I Users zhangjiawei tensorflow tensorflow contrib lite downloads I Users zhangjiawei tensorflow tensorflow contrib lite downloads eigen I Users zhangjiawei tensorflow tensorflow contrib lite downloads gemmlowp I Users zhangjiawei tensorflow tensorflow contrib lite downloads neon 2 sse I Users zhangjiawei tensorflow tensorflow contrib lite downloads farmhash src I Users zhangjiawei tensorflow tensorflow contrib lite downloads flatbuffers include I Users zhangjiawei tensorflow tensorflow contrib lite gen obj I usr local include c tensorflow contrib lite downloads farmhash src farmhash cc o Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite downloads farmhash src farmhash o gcc std c 11 O3 DNDEBUG miphoneos version min 9 0 DGEMMLOWP ALLOW SLOW SCALAR FALLBACK fembed bitcode Wno c 11 narrowing mno thumb fno exceptions isysroot arch x86 64 O3 I I Users zhangjiawei tensorflow tensorflow contrib lite I Users zhangjiawei tensorflow tensorflow contrib lite downloads I Users zhangjiawei tensorflow tensorflow contrib lite downloads eigen I Users zhangjiawei tensorflow tensorflow contrib lite downloads gemmlowp I Users zhangjiawei tensorflow tensorflow contrib lite downloads neon 2 sse I Users zhangjiawei tensorflow tensorflow contrib lite downloads farmhash src I Users zhangjiawei tensorflow tensorflow contrib lite downloads flatbuffers include I Users zhangjiawei tensorflow tensorflow contrib lite gen obj I usr local include c tensorflow contrib lite error reporter cc o Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite error reporter o gcc std c 11 O3 DNDEBUG miphoneos version min 9 0 DGEMMLOWP ALLOW SLOW SCALAR FALLBACK fembed bitcode Wno c 11 narrowing mno thumb fno exceptions isysroot arch x86 64 O3 I I Users zhangjiawei tensorflow tensorflow contrib lite I Users zhangjiawei tensorflow tensorflow contrib lite downloads I Users zhangjiawei tensorflow tensorflow contrib lite downloads eigen I Users zhangjiawei tensorflow tensorflow contrib lite downloads gemmlowp I Users zhangjiawei tensorflow tensorflow contrib lite downloads neon 2 sse I Users zhangjiawei tensorflow tensorflow contrib lite downloads farmhash src I Users zhangjiawei tensorflow tensorflow contrib lite downloads flatbuffers include I Users zhangjiawei tensorflow tensorflow contrib lite gen obj I usr local include c tensorflow contrib lite interpreter cc o Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite interpreter o clang error no such file or directory 'x86 64' clang warning no such sysroot directory ' arch' Wmissing sysroot make Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite allocation o Error 1 make Waiting for unfinished jobs clang error no such file or directory 'x86 64' clang warning no such sysroot directory ' arch' Wmissing sysroot clang error no such file or directory 'x86 64' clang warning no such sysroot directory ' arch' Wmissing sysroot make Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite context o Error 1 make Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite downloads farmhash src farmhash o Error 1 clang error no such file or directory 'x86 64' clang warning no such sysroot directory ' arch' Wmissing sysroot make Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite error reporter o Error 1 clang error no such file or directory 'x86 64' clang warning no such sysroot directory ' arch' Wmissing sysroot make Users zhangjiawei tensorflow tensorflow contrib lite gen obj ios x86 64 tensorflow contrib lite interpreter o Error 1 System information OS Platform and Distribution macOS High Sierra 10 13 2 17C88 TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 6 1 GCC Compiler version if compiling from source GCC 4 2 1 Compatible Apple LLVM 6 0 clang 600 0 57 Exact command to reproduce bash tensorflow contrib lite build ios universal lib sh Have I written custom code no TensorFlow installed from source Bazel version N A CUDA cuDNN version N A GPU model and memory N A Has anyone else had the same problem,,,2017-12-11 04:34:36,2018-01-03 15:26:54
IS,bug tf estimator DNNClassifier setting n classes has no effect,Describe the problem I was following the examples for a tensorflow estimator I am setting n classes but the label check in check labels tensorflow python estimator canned head py line 222 keeps kicking back the following error ValueError Mismatched label shape Classifier configured with n classes 1 Received 4 Suggested Fix check your n classes argument to the estimator and or the shape of your label Source code logs System information Mac OSX 10 12 6 Python 2 7 Tensorflow 'v1 4 0 19 ga52c8d9b01' '1 4 1',,facaiy,2018-01-03 00:18:44,2018-01-03 15:52:39
PR,Fix typo in UserInputError,The phrase The followings are lines 336 337 should be changed to The following are,,,2018-01-03 12:07:34,2018-01-03 15:57:02
PR,Fix typo in LinearModel docstring,adn and,,,2018-01-03 11:05:01,2018-01-03 15:57:59
PR,Fix git configuration on Windows,Running python script on Windows require explicitly invoke python binary,,meteorcloudy,2018-01-03 12:36:23,2018-01-03 16:01:21
IS,configure py environment variables,Have I written custom code No OS Platform and Distribution Linux Any TensorFlow installed from Source TensorFlow version 1 4 Master Branch Bazel version 0 6 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A System information Building from source Branch Master currently d87a9fbbc5f49ec5ae8eb52c62628f0b1a0bf67f Describe the problem Line 1353 of configure py needs to have int wrapped around the function get var otherwise the string that is returned always flags positive and setting TF SET ANDROID WORKSPACE 0 environment variable to avoid user interaction in building from source will never work,,,2018-01-02 21:50:40,2018-01-03 16:35:40
PR,Revert Remove unneeded branch check 13495,This reverts commit 3aee5f1df97f44d9c14995505895f1877d7de8ae Fix build with Python3,,"meteorcloudy,yaroslavvb",2018-01-03 15:36:42,2018-01-03 16:36:32
IS,Dataset from generator does not play nice with feature column categorical column with vocabulary list,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux 4 4 0 98 generic 121 14 04 1 Ubuntu SMP Wed Oct 11 11 54 55 UTC 2017 x86 64 x86 64 x86 64 GNU Linux TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 4 0 rc1 11 g130a514' '1 4 0' Python version Python 2 7 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce curl L o predict not working py '' python predict not working py Describe the problem I have the same code in two versions one using Dataset from generator and one using Dataset from tensor slices To me it looks like the created Datasets have the exact same content but feature column categorical column with vocabulary list does not work with the from generator one which ought to be a bug right Source code logs Sources are in links above,,"mrry,drpngx,ispirmustafa",2017-12-07 08:23:46,2018-01-03 16:59:38
IS,Bug tf data Dataset map computes unrequested graph parts,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow See code example at the bottom OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 rc1 11 g130a514 1 4 0 Python version Python 3 6 1 Anaconda custom 64 bit Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Short tf Session run does not compute unnecessary things that are not requested except for the case the tensorflow code in inside a tf data Dataset map So is it possible to add this feature to tf data Dataset map Maybe the problem is in tensorflow python framework function Defun Long I want to build a fully featured input pipeline that provides everything Than should tensorflow determine what is necessary to compute When I tried to figure out if this is possible I found that the dataset has some code for parallel execution So preprocessing should be inside the Dataset pipeline When I looked at the source code I think the reason may be connected to tensorflow python framework function Defun but I can not find the motivation to use Defun and the initial commit 2017 05 17 under contrib had already Defun used With my knowledge as a tensorflow beginner I can only fix this when I ignore parallel execution i e remove all Defun s but then I can also do the transform after Iterator get next Maybe knows more about this Source code logs Here a small example that demonstrates this behavior Node the tf sleep idx 0 1 is a open end in the graph and the print should never be executed,,"boeddeker,drpngx,mrry,boeddeker,mrry,mrry",2017-11-15 20:58:35,2018-01-03 18:05:04
IS,Make a State ful LSTM with data input from TF Dataset,14906 This is to reference a closed issue Thanks for suggestion on using Dataset flat map to slice the input signal sequence However how could we know the beginning and ending of the original sequence after sliced And how could we reset the LSTM state so that we can make a state ful LSTM Thanks,,"mrry,mrry",2017-12-04 06:00:43,2018-01-03 18:07:41
IS,Missing MPI collectives op symbols in TF build,Running into a build issue when trying to use MPI collectives We are able to build a recent version of TF using NVIDIA is changes for CUDA 9 cuDNN 7 However it appears that the build strips the MPI collectives library ops It seems like the issue might be caused by commit 5c7f9e3 which changes linking behavior but we are unable to bisect due to commit order dependencies Anyone have an idea how to fix the issue We are willing to update the MPI collectives code and submit a PR fix System information Have I written custom code as opposed to using a stock example script provided in TensorFlow We have applied NVIDIA is CUDA 9 cuDNN 7 patches for mixed precision per this page training tensorflow OS Platform and Distribution e g Linux Ubuntu 16 04 14 04 TensorFlow version use command below ea94bbe9fa9f9b3d01fb057c02ef7873d76bf09c Python version 3 6 Bazel version 0 5 4 CUDA cuDNN version CUDA 9 0 103 rc cuDNN 7 0 rc Exact command to reproduce python c 'import tensorflow contrib mpi collectives as mpi',,"jthestness,allenlavoie,jthestness,allenlavoie,jthestness,allenlavoie,jthestness,jthestness,jthestness",2017-10-21 00:53:02,2018-01-03 18:10:28
PR,MKL Fixes for concat and elementwise ops,Fixes concat for Svd test cases and disable 4 elementwise ops to get SSG VGG 16 model to work with MKL DNN Disabled tanh due to differences between Tensorflow and DNN primitives,,"agramesh1,yifeif,yifeif,drpngx,agramesh1,drpngx,agramesh1,agramesh1,agramesh1,drpngx",2017-12-15 23:37:18,2018-01-03 18:17:54
IS,Exception trying to import a retrained model in android classifier demo app,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 3 0 rc1 5733 gb43d0f3' '1 4 0' Python version 2 7 12 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version GPU model and memory Exact command to reproduce I have retrained a mobilenet v1 1 0 224 frozen graph pb model with the following script export PYTHONPATH usr local lib python2 7 dist packages usr lib python2 7 dist packages export IMAGE SIZE 224 export WIDTH MUL 1 0 0 75 0 50 0 25 export ARCHITECTURE mobilenet WIDTH MUL IMAGE SIZE export BASE DIR cd dirname BASH SOURCE 0 pwd export TF FILES DIR tf files python m scripts retrain bottleneck dir TF FILES DIR bottlenecks how many training steps 4000 model dir TF FILES DIR models summaries dir TF FILES DIR training summaries ARCHITECTURE output graph TF FILES DIR retrained graph pb output labels TF FILES DIR retrained labels txt architecture ARCHITECTURE image dir TF FILES DIR flower photos I copied retrained graph pb and retrained labels txt in the assets directory of the android demo app in tensorflow examples android and modified the source code in ClassifierActivity java as follows Original code private static final String INPUT NAME input private static final String OUTPUT NAME output private static final String MODEL FILE file private static final String LABEL FILE file Replaced by private static final String INPUT NAME input private static final String OUTPUT NAME final result private static final String MODEL FILE file private static final String LABEL FILE file End I cleaned and rebuilt the whole project in Android Studio successfully The app was then loaded on a Huawei P8 Lite Android 7 0 and starting TF Classify the following error occurs E tensorflow CameraActivity Exception java lang RuntimeException Failed to load model from 'file' at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 113 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 118 at org tensorflow demo CameraActivity onPreviewFrame CameraActivity java 120 at android hardware Camera EventHandler handleMessage Camera java 1204 at android os Handler dispatchMessage Handler java 105 at android os Looper loop Looper java 156 at android app ActivityThread main ActivityThread java 6523 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 942 at com android internal os ZygoteInit main ZygoteInit java 832 Caused by java io IOException Not a valid TensorFlow Graph serialization NodeDef mentions attr wouldilations' not in Op name Conv2D signature input T filter T output T attr T type allowed DT HALF DT FLOAT attr strides list int attr use cudnn on gpu bool default true attr padding string allowed SAME VALID attr data format string default NHWC allowed NHWC NCHW NodeDef MobilenetV1 MobilenetV1 Conv2d 0 convolution Conv2D T DT FLOAT data format NHWC dilations 1 1 1 1 padding SAME strides 1 2 2 1 use cudnn on gpu true input MobilenetV1 Conv2d 0 weights read Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary at org tensorflow contrib android TensorFlowInferenceInterface loadGraph TensorFlowInferenceInterface java 535 at org tensorflow contrib android TensorFlowInferenceInterface init TensorFlowInferenceInterface java 105 at org tensorflow demo TensorFlowImageClassifier create TensorFlowImageClassifier java 103 at org tensorflow demo ClassifierActivity onPreviewSizeChosen ClassifierActivity java 118 at org tensorflow demo CameraActivity onPreviewFrame CameraActivity java 120 at android hardware Camera EventHandler handleMessage Camera java 1204 at android os Handler dispatchMessage Handler java 105 at android os Looper loop Looper java 156 at android app ActivityThread main ActivityThread java 6523 at java lang reflect Method invoke Native Method at com android internal os ZygoteInit MethodAndArgsCaller run ZygoteInit java 942 at com android internal os ZygoteInit main ZygoteInit java 832 Application terminated How to fix this error,,"asimshankar,asimshankar",2017-12-28 16:13:06,2018-01-03 18:28:29
PR,Revert Fix a bug bfloat16 is unsigned on Windows 15302,This reverts commit fdf34a88bec9645473f10ba2d52df4cfcb80d582 Since the fix for 15302 is not getting merged soon I will revert it to fix the Windows build FYI,,meteorcloudy,2018-01-03 15:32:41,2018-01-03 18:42:59
IS,RMSProp fails with InteractiveSession and embed sequence on GPU,Note This works fine if any of the following without GPU if use normal Session instead of the interactive one if do not do embed sequence user other optimiser not RMSProp This is the snippet to get the error System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 3 LTS TensorFlow installed from source or binary docker TensorFlow version use command below 1 3 0 Python version 3 5 CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 61 GPU model and memory Tesla K80,,"skye,skye,skye,skye,skye,skye",2017-10-21 15:29:33,2018-01-03 19:13:40
IS,tf biderectional dynamic rnn get stuck when running the graph,I built a 1 layer bidirectional RNN with 128 hidden nodes using the output tf nn bidirectional dynamic rnn forward cell backward cell inputs seqlens tf float32 is tuple True time major True interface I run the network with input data size of 57x285x4608 time step x batch size x num feature but get stuck in the outputs sess run outputs feeds The system does not indicate any resource exhausted When I reduce the time step to 31 the network runs successfully When I only reduce the number of 3rd dimension to 512 it still fails to work It seems there is some constraints on the input sequence length Any idea on this problem I run this program on Nvidia DGX Server with 4 Tesla P100 GPUs The OS is ubuntu 14 04,,"reedwm,reedwm,ebrevdo,ebrevdo,ebrevdo,ebrevdo,mrry",2017-10-02 09:27:09,2018-01-03 19:14:31
IS,DataLossError Checksum does not match when using multiple TFRecordDataset via tf case,See below Please let me know what I can do to provide more information for you I am working on pulling out the offending code into a standalone py file to replicate the bug elsewhere but it might take a few days System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 arch linux LTS kernel 4 9 44 1 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 master branch as of commit 566d167c Python version 3 6 2 Bazel version if compiling from source 0 5 2 2 CUDA cuDNN version 8 0 61 2 6 0 21 2 GPU model and memory 1080 GTX Ti Exact command to reproduce I do not have exact source for you yet of a trimmed down example I will see if I can put one together Generally the steps are Generate a few TFRecord files Instantiate a few TFRecordDataset from the files Perform necessary pre processing on TFRecordDataset entries for each dataset then on the dataset itself cache repeat shuffle batch etc For example we might have datasets train dataset validate dataset and test dataset Initialize each dataset make initializable iterator Train a model using an input tensor x of,,"mrry,mrry,mrry",2017-08-18 19:30:57,2018-01-03 19:27:28
IS,How to control the thread number on Tensorflow,Hi all Do we have any options to control the number of threads in TF Slim both in training and evaluation processes Specifically I use this network for my classification problem I changed the evaluation part in a way that runs train and evaluation in parallel like this code I can run it on my own CPU without any problem But I can not execute them on a supercomputer It seems that it is related to the very large number of threads which are being created by Tensorflow If the number of threads exceeds the maximum number of threads pre set in SLURM 28 then the job will fail Since it is unable to create new threads it will end up with error resource temporarily unavailable This error provided when the code tries to restore parameters from checkpoints If there is no limitation on the number of threads like on my pc it works fine I tried to limit the number of CPU threads used by Tensorflow to 1 by creating config like FLAGS num preprocessing threads 1 config tf ConfigProto config intra op parallelism threads FLAGS num preprocessing threads config inter op parallelism threads FLAGS num preprocessing threads slim evaluation evaluation loop master FLAGS master checkpoint path each ckpt logdir FLAGS eval dir num evals num batches eval op list names to updates values print ops variables to restore variables to restore session config config But unfortunately that did not help In my opinion the main problem we are having here is the fact that we are not able to control the number of threads here Although we set it to 1 with various TF options you can actually see that this job is creating many more threads on the node slurm script python 128 python python 8 python Training script is creating 128 threads and evaluation script is creating 8 both numbers vary over time Any idea on the way to control the thread numbers will be highly appreciated because I do need to fix this issue urgently Ellie P S I'm using Python 2 7 13 and Tensorflow 1 3 0,,"aselle,mrry,mrry,mrry",2017-11-27 04:53:57,2018-01-03 19:28:34
IS,Unable access S3 using the S3 filesystem,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 docker container based on centos7 TensorFlow installed from source or binary binary from pip TensorFlow version use command below 'v1 4 0 rc1 11 g130a514' '1 4 0' Python version 2 7 5 Bazel version if compiling from source n a GCC Compiler version if compiling from source n a CUDA cuDNN version n a GPU model and memory n a Exact command to reproduce,,"reedwm,reedwm,drpngx,drpngx,drpngx,yongtang,yongtang,drpngx",2017-12-06 15:37:22,2018-01-03 19:29:17
IS,XLA feature fix INVALID ARGUMENTS Unsupported type in DataTypeToPrimitiveType complex64,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS Sierra 10 12 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source 0 4 5 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce tfcompile Currently the XLA compiler seems to not support complex dtypes I ran into this when trying to use the spectral ops ff2d in an AOT compilation Is it possible to fix this Alternatively is there a workaround that succeeds now I thought I could maybe bitcast a float64 to a complex64 but it seems bitcast is also not implemented for XLA,,"tatatodd,carlthome,brianwa84,brianwa84",2017-08-08 18:25:33,2018-01-03 19:30:09
IS,segfaults in GPU tf matrix inverse,I'm running into segfaults in tf matrix inverse I'm adding identity 0 001 so matrices should be invertible and same procedure works fine in numpy and in TensorFlow CPU version python inverse segfault py This non deterministically crashes after 1 2 seconds with various backtraces IE TensorFlow commit NVIDIA SMI 381 09 libcudart so 8 0 44 libcudnn so 6 0 21 Nvidia GTX 1080,,"yaroslavvb,asimshankar,drpngx",2017-10-07 23:40:22,2018-01-03 19:31:07
IS,About Deterministic Behaviour of GPU implementation of tensorflow,OS Platform and Distribution e g Linux Ubuntu 16 04 Debian TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' CUDA cuDNN version 8 0 GPU model and memory GeForce GTX 950 Dear experts I have just written a python code that implements a CNN with tensorflow Despite using tf set random seed 0 throughout my code I get different results for each different run using a GPU while this is not happening when switching to CPU I read different threads about stochastic behaviour of GPUs and I could find that the stochastic behaviour is happening when using AdamOptimizer My code now uses a CPU just for the optimizer and a GPU for all the others operations so now the time performance of the GPU is 25 better than CPU despite the 700 of the full GPU implementation My question is is this avoidable Should I really give up in having a deterministic code when using GPUs How can I tune my hyperparameters and use a full GPU code some forums say to make an average of different runs but this kills the time advantage of using GPUs Thanks in advance for all your kind support and for the wonderful job,,"drpngx,reedwm,ekelsen,ekelsen,ekelsen,drpngx,drpngx,protoget",2017-09-07 08:07:09,2018-01-03 19:34:45
IS,Internal failed initializing StreamExecutor for CUDA device ordinal 0 Internal failed call to cuDevicePrimaryCtxRetain,SYSTEM Infomation ubuntu16 04 cuda7 5 cudnn5 gtx1060 tensorflow1 0 1 python3 5 memory 15 6G used 5 3GB nvidia smi I will be grateful to anyone for helping me Thanks everyone,,"drpngx,drpngx",2017-11-11 03:21:54,2018-01-03 19:36:30
IS,Gradients with TensorArray fail after scatter of 0 size,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce see below Describe the problem The following fails The above code works if ta ta scatter tf range 0 0 ta gather tf range 0 0 which gathers a 0x3 tensor and then scatters it into zero indices in ta is removed This seems to happen because TensorArrayScatterGrad does not and cannot copy over the element size from the Python TensorArray object that scatter was called on I submitted 12742 as a fix which works for the above snippet,,"jart,ebrevdo",2017-09-01 05:16:17,2018-01-03 19:56:00
PR,Memory allocation improvement for decode libsvm,This fix is an improvement to 14330 Previously string split was handled through str util Split which may incur unnecessary memory allocations This fix uses StringPiece instead See comment pullrequestreview 79877956 for reference Signed off by Yong Tang yong tang github outlook com,,"yongtang,mrry,yongtang,caisq",2018-01-03 02:34:18,2018-01-03 20:26:52
IS,Distributed tensorflow Stuck at CreateSession still waiting for response from worker,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 0 1 3 Python version 2 7 CUDA cuDNN version no Describe the problem Run the code on k8s with the spec 1 ps 20 workers there are some workers print the log all the time,,"nolanliou,nolanliou,mrry,nolanliou,mrry,nolanliou,mrry",2017-09-01 07:07:56,2018-01-03 20:36:55
PR,Remove noop python command in pyx library rule,It looks to me like the command produced should be shutil copyfile src split 0 cpp src split 0 cpp based on how cpp outs is constructed a few lines above Allen could you take a look and comment This file and the direct call to the python binary is one of the root causes of 15618,,gunan,2018-01-03 06:51:53,2018-01-03 20:54:39
IS,Can we install tensorflow with a package manager in Linux distro,As we all know Tensorflow is a major opensource deeplearning framework to the developers BTW How can we install tensorflow with a package manager such as apt get for deb yum zypper dnf for rpm in Linux distro Reference I could not find related scripts from the above web address Does tensorflow support 1 manual compilation with tools ci build build sh and 2 pre built docker based compilation only System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 0 and Ubuntu 16 04 3 TensorFlow installed from source or binary Latest version of Tensorflow form github TensorFlow version use command below Latest version of Tensorflow form github Python version 2 7 Bazel version if compiling from source with Cmake w o Bazel GCC Compiler version if compiling from source GCC 5 0 CUDA cuDNN version None w CPU only GPU model and memory None DRAM 16GB Exact command to reproduce Nonthing Describe the problem No support Source code logs Omission,,tfboyd,2018-01-03 06:03:26,2018-01-03 20:55:34
IS,More simpler examples of using dataflow ops StagingArea,Describe the problem Getting the below error when using StagingArea ValueError Fetch argument tf Operation 'group deps' type NoOp cannot be interpreted as a Tensor Operation name group deps op NoOp The error happens only after completing a few 100 steps It would be a great help if someone can place simpler examples of proper usage of StagingArea Source code logs compute stage put op compute stage put iterator get next if compute stage put op type 'Stage' compute stage ops append compute stage put op,,"drpngx,mrry,drpngx,drpngx",2017-12-07 09:29:46,2018-01-03 20:59:14
IS,lookup index table from tensor emits an error in eager mode when invoked more than once,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS TensorFlow installed from source or binary tf nightly TensorFlow version use command below 1 5 0 dev20171206 Python version 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce python from tensorflow python ops import lookup ops import tensorflow contrib eager as tfe tfe enable eager execution inpt '1611' '1612' '1613' '1615' '1616' '1617' '1618' '1619' '1621' a lookup ops index table from tensor inpt name 'a' b lookup ops index table from tensor inpt name 'b' Problem When the eager execution is enabled the following error occurs console FailedPreconditionError Table already initialized Op InitializeTableV2 name string to index hash table string to index hash table string to index hash table table init Source code logs Full trace Question Is there a way to specify more than one lookup table a shared name or a special scope,,"drpngx,alextp,alextp,drpngx",2017-12-08 13:14:40,2018-01-03 20:59:46
IS,MonitoredSession close does not stop a thread when using SyncReplicasOptimizer hook,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 Python version 3 5 2 Describe the problem If using SyncReplicasOptimizer the MonitoredSession is not able to stop a thread when calling session close It will wait the whole stop grace period secs and then close reporting that a thread could not be stopped INFO tensorflow Coordinator stopped with threads still running Thread 5 the thread number may vary Here you can find the piece of code reduced as much as possible to reproduce it Source code After several runs of this same script I also got a segmentation fault but only once,,"drpngx,ispirmustafa,isaprykin,isaprykin,isaprykin,isaprykin,drpngx",2017-10-17 10:59:12,2018-01-03 21:05:13
IS,How to build a full C API libtensorflow cc so for Android,Describe the problem When I use,,"jart,drpngx,drpngx",2017-09-01 08:43:25,2018-01-03 21:07:14
PR,Make frame positions configurable,This also fixes a bug in get root dir with all resources The value of sys getframe 1 is caller sensitive This leads to unexpected bugs where it gives the path of the wrong file For example get root dir with all resources is supposed to find the runfiles directoy But because of the extra call to get data files path everything shifts by one and now it resolves all paths on the location of the resource loader py file loaded repository or PIP but not a runfiles path In the places it is used currently it does not break anything tho This PR fixes the behavior of get root dir with all resources and makes the frame positions configurable on all methods with a default for compatibility Friendly ping,,"Androbin,Androbin,Androbin,asimshankar",2017-12-23 15:55:25,2018-01-03 21:29:00
IS,ImportError libcublas so 9 0 cannot open shared object file No such file or directory,I met the same problem as ImportError libcublas so 9 0 cannot open shared object file No such file or directory but non of their methods work,,gunan,2018-01-03 13:26:58,2018-01-03 21:38:28
IS,compile failed for tf gpu 1 4 cuda 9 cudnn 7 vc 2017 windows 10,I would greatly appreciate if anyone could help me out with compiling I followed 5600 and 13962 in compiling the wheel however when building i got into 6 types of in total 90 errors Respectively c2070 c2059 c2064 c2001 c1057 c2146 My build command was cmake A x64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE C swigwin 3 0 12 swig exe DPYTHON EXECUTABLE python exe DPYTHON LIBRARIES C ProgramData Anaconda3 libs python36 lib DPYTHON INCLUDE DIR C ProgramData Anaconda3 Include DNUMPY INCLUDE DIR C ProgramData Anaconda3 lib site packages numpy core include Dtensorflow ENABLE GPU ON DCUDNN HOME C Program Files NVIDIA GPU Computing Toolkit CUDA v9 0 Dtensorflow WIN CPU SIMD OPTIONS arch AVX Everything looks good until the compiler arch native support failed It manage to configure the build so I continue with MSBuild p Configuration Release tf python build pip package vcxproj The last 9999 line of the failed log is here tf compile build error log txt Warmest Regards Colman,,"mrry,mrry,gunan,angersson,gunan,gunan,gunan,gunan",2017-11-18 16:13:31,2018-01-03 21:43:21
PR,iOS Add optional Selective Registration of Ops,The current iOS library is huge Add the ability to selectively register for the ops the tensorflow library will support This greatly reduces resultant binary based on the network A full arm64 build was 122MB on my machine vs one selectively registered for SSD Mobilenet was only 93MB Also fixes a minor bug where the selected arch was not being passed to the compile ios protobuf sh script TEST build all ios sh a arm64 generates a fat binary for arm64 build all ios sh a arm64 g Downloads op inference graph pb generates a binary that is much smaller,,"powderluv,powderluv,powderluv,powderluv,powderluv,jhseu,powderluv,powderluv,drpngx,drpngx,powderluv,drpngx,powderluv,powderluv",2017-11-09 21:15:43,2018-01-03 22:04:32
IS,Support layer wise batch normalization parameter in tensorflow contrib estimators,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution Linux Ubuntu 14 04 TensorFlow installed from source or binary installed from source TensorFlow version use command below 1 2 0 Python version Python 2 7 6 Bazel version if compiling from source 0 5 2 CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem Tensorflow is current DNN classifier regressor do not provide support to plugin in layer wise normalization function This issue is fired to provide support to add a layer wise norm func parameter in their constructors Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Following is a snippet of my proposed update in DNNClassifier In case this change passes your review I will submit the full code change including updates to all other related estimators diff git a tensorflow contrib learn python learn estimators dnn py b tensorflow contrib learn python learn estimators dnn py index cb15ef2 a3d9c01 100644 a tensorflow contrib learn python learn estimators dnn py b tensorflow contrib learn python learn estimators dnn py 127 6 127 10 def dnn model fn features labels mode params config None params get input layer min slice size or 64 20 num ps replicas config num ps replicas if config else 0 embedding lr multipliers params get embedding lr multipliers layer norm func params get layer norm func layer norm params params get layer norm params layer norm params mode mode features get feature dict features parent scope dnn 168 6 172 8 def dnn model fn features labels mode params config None net num hidden units activation fn activation fn normalizer fn layer norm func normalizer params layer norm params variables collections parent scope scope hidden layer scope if dropout is not None and mode model fn ModeKeys TRAIN 297 6 303 8 class DNNClassifier estimator Estimator weight column name None optimizer None activation fn nn relu layer norm func None layer norm params None dropout None gradient clip norm None enable centered bias False 372 6 380 8 class DNNClassifier estimator Estimator optimizer optimizer activation fn activation fn dropout dropout layer norm func layer norm func layer norm params layer norm params gradient clip norm gradient clip norm embedding lr multipliers embedding lr multipliers input layer min slice size input layer min slice size,,ispirmustafa,2017-08-23 02:17:51,2018-01-03 22:29:09
IS,tf train SyncReplicasOptimizer training does not start,System information Have I written custom code Yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from binary TensorFlow version use command below tensorflow gpu 1 3 0 Python version Python 3 6 2 Bazel version if compiling from source not installed CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 61 GPU model and memory NVIDIA Quadro P5000 16GB Exact command to reproduce write actual IP addresses instead of ip address1 and ip address2 on machine 1 python trainer py replicas num 1 ps hosts ip address1 2222 worker hosts ip address2 2223 job name ps task index 0 on machine 2 python trainer py replicas num 1 ps hosts ip address1 2222 worker hosts ip address2 2223 job name worker task index 0 Describe the problem I'm trying to train an below model with distributed synchronized training I tried 1 ps and 1 worker 1 ps and 2 workers 1 ps and 3 workers It is a sample code similar to putting it all together example trainer program If I comment out line 71 shown below training became asynchronized trainig and there is no problem opt tf train SyncReplicasOptimizer opt replicas to aggregate FLAGS replicas num total num replicas FLAGS replicas num But if I run it with line 71 not commented out training will not start I followed usage to make it synchronized There is no error But trainig will not continue sess run line 96 never ends Is there any suggestions what might be the problem Source code logs Source code,,drpngx,2017-10-20 09:20:04,2018-01-04 00:02:34
IS,Batch Normalization layer is unusable,Despite the numerous submitted issues tf layers batch normalization still feels completely unusable The major problems are 1 It does not allow for input tensors with varying shapes It is complete nonsense to have a fixed batch size It should be allowed for the batch dimension to be vary 2 One needs to manually update the running mean and variance This is very uncomfortable and a very common pitfall for many beginners while it would take just a couple of lines to do the update internally based on the value of the training parameter I have recently seen too many custom implementations of a batch normalization layer because of the above problems and it will definitely be very useful if these problems are fixed ASAP I am using tensorflow gpu version 1 4,,"ppwwyyxx,facaiy,ppwwyyxx,facaiy,ppwwyyxx",2017-11-22 20:21:21,2018-01-04 00:51:46
PR,add a function to add extra logging handler,I want to separate different level of logs So error message will not be buried by info debug logs In r1 4 I use following code to do the job but when I change to r1 5 it do not work any more because tensorflow rewrite tf logging py and logger is not exposed So I think add a function to add extra handler should be useful,,"asimshankar,yilei",2017-12-27 15:40:57,2018-01-04 00:55:42
PR,Update advise md,,,,2018-01-03 21:42:09,2018-01-04 01:35:51
IS,Doubt in the implementation of gan is training critera,I read the code of gan implementation in tf contrib gan but I'm not quite sure whether the generator train op and discriminator train op use the same batch of data Here is the code in url Can we guarantee that both hooks run the optimizer on the same batch along with that each hook run the respective optimizer several times on the same batch I think that is needed for gan training and consistent with relative papers,,rohan100jain,2017-11-14 03:27:20,2018-01-04 01:56:52
IS,BUG Memory leak in tf string split,profile 9734 0066 txt profile 9734 0100 txt profile 9734 0150 txt Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Centos Linux version 3 10 0 229 4 2 el7 x86 64 gcc version 4 8 2 20140120 Red Hat 4 8 2 16 GCC TensorFlow installed from source or binary pip install tensorflow TensorFlow version use command below tensorflow 1 3 0 Python version Python 2 7 5 Bazel version if compiling from source N A CUDA cuDNN version N A CPU only GPU model and memory N A Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am seeing noticeably large memory usage when I use tf string split within the map function of a dataset API I have attached a sample code below I tried to do a heap analysis and I see std basic string Rep S create constantly growing in size and not freeing up its memory If i remove the tf string split and just return the line as is there is no memory held over This issue is a blocker for us to scale up the tensorflow pipeline to large datasets I have attached three output files of pprof over time 6447 1 96 8 96 8 6447 1 96 8 std basic string Rep S create 9765 5 96 5 96 5 9765 5 96 5 std basic string Rep S create 14704 7 95 5 95 5 14704 7 95 5 std basic string Rep S create Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem import tensorflow as tf def mapper line line tf identity line tokens tf string split line delimiter ' t' return tokens indices def run filenames sample txt Cluster spec cluster tf train ClusterSpec worker localhost 2223 server tf train Server cluster job name worker task index 0 dataset tf contrib data TextLineDataset filenames dataset dataset batch 1000 dataset dataset map mapper 8 repeat iterator dataset make one shot iterator next element iterator get next with tf Session target server target as session while True try session run next element except tf errors OutOfRangeError break run You can run this script by LD PRELOAD usr lib64 libtcmalloc so 4 HEAPPROFILE tmp profile nohup python u bug py output log,,"aselle,mrry,mrry",2017-09-22 19:30:17,2018-01-04 01:59:19
PR,Fix unstable test case for Select op,Fix 14862 CF 15764 In the test case for Select op the condition might switch to another value when x1 is close to x2 The PR is opened to resolve the unstable condition Test passed for 100 times cc,,"facaiy,drpngx,facaiy,drpngx",2018-01-03 06:12:08,2018-01-04 02:13:18
IS,tensorboard failed on win 10,I tried to use tensorboard win10 python3 5 2 tensorflow gpu 1 1 0 but failed with the error image module 'tensorflow' has no attribute 'make tensor proto' but I tried on win 7 with the same events and succeed win7 python3 5 2 tensorflow gpu 1 0 1 image Is there a bug,,,2017-09-21 12:01:17,2018-01-04 02:50:23
IS,BUG same feature column creates duplicate tensors for DNNLinearCombinedRegressor,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 11 6 TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 5 2 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem It seems that the same feature column creates two tensors for DNNLinearCombinedRegressor see voc embed in graph below Is this the right behavior we expected The behavior stems from that feature column is processed by DNN and Linear independently see code dnn L154 and linear L196 Source code logs graph large attrs key too large attrs limit attr size 1024 run 1,,"facaiy,ispirmustafa,facaiy,facaiy,facaiy,ispirmustafa,facaiy,facaiy",2017-09-20 07:44:43,2018-01-04 04:10:00
IS,variable scopes count miscalculates when reentering variable scope again,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 mac 10 11 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 3 5 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem The unexpected results are fund when I investigates 14703 see code here L1621 L1623 variable scope always restores its old variable scopes count after exit unfortunately it seems that we forget reentering case I am not sure whether the behavior is a bug Source code logs,,"facaiy,lukaszkaiser,facaiy",2017-12-12 06:49:54,2018-01-04 05:07:58
IS,Error when run label image graph tmp quantized graph pb after quantized model,tensorflow 1 4 0 I followed the command line from tensorflow tensorflow docs src performance quantization md ran the following command is ok and produce a new model quantized graph pb bazel build tensorflow tools graph transforms transform graph bazel bin tensorflow tools graph transforms transform graph in graph tensorflow examples label image data inception v3 2016 08 28 frozen pb out graph tmp quantized graph pb inputs input outputs InceptionV3 Predictions Reshape 1 transforms 'add default attributes strip unused nodes type float shape 1 299 299 3 remove nodes op Identity op CheckNumerics fold constants ignore errors true fold batch norms fold old batch norms quantize weights quantize nodes strip unused nodes sort by execution order' But there is a problem when I was running with command bazel build tensorflow examples label image label image bazel bin tensorflow examples label image label image graph tmp quantized graph pb Else it worked if I replace quantized graph pb with inception v3 2016 08 28 frozen pb here The error info is 2017 12 04 08 27 02 891427 E tensorflow core framework op kernel cc 1142 OpKernel 'op DenseToSparseBatchDataset device type CPU ' for unknown op DenseToSparseBatchDataset 2017 12 04 08 27 02 891520 E tensorflow core framework op kernel cc 1142 OpKernel 'op GroupByWindowDataset device type CPU ' for unknown op GroupByWindowDataset 2017 12 04 08 27 02 891562 E tensorflow core framework op kernel cc 1142 OpKernel 'op IgnoreErrorsDataset device type CPU ' for unknown op IgnoreErrorsDataset 2017 12 04 08 27 02 891636 E tensorflow core framework op kernel cc 1142 OpKernel 'op DatasetToSingleElement device type CPU ' for unknown op DatasetToSingleElement 2017 12 04 08 27 02 891686 E tensorflow core framework op kernel cc 1142 OpKernel 'op SerializeIterator device type CPU ' for unknown op SerializeIterator 2017 12 04 08 27 02 891712 E tensorflow core framework op kernel cc 1142 OpKernel 'op DeserializeIterator device type CPU ' for unknown op DeserializeIterator 2017 12 04 08 27 02 891733 E tensorflow core framework op kernel cc 1142 OpKernel 'op MapAndBatchDataset device type CPU ' for unknown op MapAndBatchDataset 2017 12 04 08 27 02 891777 E tensorflow core framework op kernel cc 1142 OpKernel 'op ParallelInterleaveDataset device type CPU ' for unknown op ParallelInterleaveDataset 2017 12 04 08 27 02 891805 E tensorflow core framework op kernel cc 1142 OpKernel 'op ScanDataset device type CPU ' for unknown op ScanDataset 2017 12 04 08 27 02 891825 E tensorflow core framework op kernel cc 1142 OpKernel 'op SqlDataset device type CPU ' for unknown op SqlDataset 2017 12 04 08 27 02 901109 E tensorflow examples label image main cc 327 Invalid argument Node 'InceptionV3 InceptionV3 Conv2d 1a 3x3 BatchNorm batchnorm mul eightbit input port 0 reduction dims' Unknown input node ' input 0' how should I fix it,,reedwm,2017-12-04 08:35:51,2018-01-04 06:41:09
IS,Can google publish checkpoint file for some common network VGG AlexNet,In tensorflow models repository developer maintains some pre built model and checkpoint files from some famous network it is very convenient for some developer do not have too much computation resources train a network from scratch can take a very long time The author of these networks do publish weights file but It is not for tensorflow mostly for caffe,,,2017-11-17 03:06:14,2018-01-04 07:07:48
IS,Bazel Build Fails with undeclared inclusion s in rule ' nccl archive nccl',System information The environment used is tf env txt The branch downloaded is tensorflow master branch When I run the configure script the configuration is tf configure bazelrc Describe the problem When I run There appears to be a problem with bazel build with MKL enabled I have been able to compile this with MKL disabled MKL for Ubuntu should be supported yes,,"tfboyd,tfboyd,gunan,gunan,gunan,gunan,gunan,gunan,gunan,ilya-biryukov,gunan,ilya-biryukov,gunan",2017-11-08 19:53:04,2018-01-04 07:18:49
IS,Build TF 1 2 error no such package ' nccl archive ' OR undeclared inclusion s in rule ' nccl archive nccl' this rule is missing dependency declarations for the following files included by 'external nccl archive src libwrap cu cc',Hi I compiled tensorflow r1 0 successfully with Centos 7 0 cuda 8 0 and CUDNN 6 5 gcc 4 8 5 Recently We want follow the latest version of Tensorflow error below are always occur ERROR home jiangbo tensorflow tensorflow tools pip package BUILD 76 1 no such package ' nccl archive ' home jiangbo cache bazel bazel jiangbo 0c80707bb0528f07a36b6bc1e1bf9b14 external nccl archive build Operation not permitted and referenced by ' tensorflow tools pip package licenses' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted My bazel version have tried 0 4 5 and 0 5 2 but compile error Some method to solve this problem I have tried but no one helps any body knows this problem please tell me or let me know you thought After I compiled TF r1 2 error I have checkout to r1 0 it is weird the same error info again,,"martinwicke,martinwicke,av8ramit,gunan",2017-07-10 07:17:36,2018-01-04 07:20:59
IS,ci tensorflow org lacks a security certificate,The Problem now lacks a security certificate or it expired To repro visit Chrome will note that the connection is not private This is breaking TensorBoard is tests that run on travis The tests pip install nightly versions of TensorFlow from these URLs TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label cpu slave lastSuccessfulBuild artifact pip test whl tensorflow 1 head cp27 none linux x86 64 whl TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON3 label cpu slave lastSuccessfulBuild artifact pip test whl tensorflow 1 head cp34 cp34m linux x86 64 whl Error Logs from a Failed Test Run Collecting tensorflow 1 head from TF BUILD IS PIP PIP TF BUILD PYTHON VERSION PYTHON2 label cpu slave lastSuccessfulBuild artifact pip test whl tensorflow 1 head cp27 none linux x86 64 whl Exception Traceback most recent call last File home travis virtualenv python2 7 14 lib python2 7 site packages pip basecommand py line 215 in main status self run options args File home travis virtualenv python2 7 14 lib python2 7 site packages pip commands install py line 335 in run wb build autobuilding True File home travis virtualenv python2 7 14 lib python2 7 site packages pip wheel py line 749 in build self requirement set prepare files self finder File home travis virtualenv python2 7 14 lib python2 7 site packages pip req req set py line 380 in prepare files ignore dependencies self ignore dependencies File home travis virtualenv python2 7 14 lib python2 7 site packages pip req req set py line 620 in prepare file session self session hashes hashes File home travis virtualenv python2 7 14 lib python2 7 site packages pip download py line 821 in unpack url hashes hashes File home travis virtualenv python2 7 14 lib python2 7 site packages pip download py line 659 in unpack http url hashes File home travis virtualenv python2 7 14 lib python2 7 site packages pip download py line 853 in download http url stream True File home travis virtualenv python2 7 14 lib python2 7 site packages pip vendor requests sessions py line 488 in get return self request 'GET' url kwargs File home travis virtualenv python2 7 14 lib python2 7 site packages pip download py line 386 in request return super PipSession self request method url args kwargs File home travis virtualenv python2 7 14 lib python2 7 site packages pip vendor requests sessions py line 475 in request resp self send prep send kwargs File home travis virtualenv python2 7 14 lib python2 7 site packages pip vendor requests sessions py line 596 in send r adapter send request kwargs File home travis virtualenv python2 7 14 lib python2 7 site packages pip vendor cachecontrol adapter py line 47 in send resp super CacheControlAdapter self send request kw File home travis virtualenv python2 7 14 lib python2 7 site packages pip vendor requests adapters py line 497 in send raise SSLError e request request SSLError SSL CERTIFICATE VERIFY FAILED certificate verify failed ssl c 661,,"chihuahua,chihuahua,chihuahua,gunan,chihuahua,gunan,chihuahua",2018-01-04 00:12:28,2018-01-04 08:37:37
IS,build link tensorflow lite c library,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 2 7 12 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source g 5 4 0 CUDA cuDNN version none GPU model and memory none Exact command to reproduce g std c 11 I tensorflow L lframework demo cpp Describe the problem I run 'bazel build tensorflow contrib lite framework' and get libframework so Then I use libframework so in my own code but get undefined reference error when compile with g temp ccYTZw2h o In function 'main' demo cpp text 0x46 undefined reference to 'tflite DefaultErrorReporter ' demo cpp text 0x6a undefined reference ro 'tflite FlatBufferModel BuildFromFile char const tflite ErrorReporter ' I get following lines by 'nm libframework so grep 'DefaultErrorReporter'' 000000000001b1b0 b ZGVZN6tflite20DefaultErrorReporterEvE14error reporter 0000000000007990 T ZN6tflite20DefaultErrorReporterEv 000000000001b1a8 b ZZN6tflite20DefaultErrorReporterEvE14error reporter I'm not familiar with how to use tensorflow lite Where is the problem could be Source code logs,,,2018-01-02 07:00:33,2018-01-04 08:58:37
IS,Feature Request saver save mkdir if directory not exist,Describe the problem saver save sess 'my model' returns error if directory not exist It would be nice if saver can automatically create the missing directory Traceback most recent call last File tf voice recognition py line 783 in module saver save sess 'my model' File usr local lib python2 7 dist packages tensorflow python training saver py line 1594 in save raise exc ValueError Parent directory of my model does not exist can not save,,,2018-01-04 04:06:02,2018-01-04 09:01:05
PR,Remove 0 in final result argument,Small change to line 393 in my recent testing of retrain and the label image workflow as of today TF master 136697e I had to remove 0 from the label image output layer argument Thank you,,caisq,2018-01-04 00:00:28,2018-01-04 15:17:07
IS,Android Dex cannot parse version 52 byte code,When including compile 'org tensorflow tensorflow lite 0 1 1' I get the error Android Dex cannot parse version 52 byte code If I use AGP 3 0 0 the problem goes away since it has support for Java 8 but the problem exists if I try to use 2 3 3,,asimshankar,2017-12-28 16:25:40,2018-01-04 15:32:51
IS,Using grid rnn cell Grid1LSTMCell makes stack bidirectional dynamic rnn Throw different shape errors,I encountered a problem using grid rnn cell Grid1LSTMCell I have no problems using it on contrib static rnn and contrib static bidirectional rnn I encounter these shape errors 1 When the input layer is unstacked Shape 1 1 must have rank at least 3 2 When the input layer is not unstacked Shape 1 2 8 must have rank 2 Which are apparently conflicting with each other,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,ebrevdo,phvu,selcouthlyBlue",2017-12-22 03:34:15,2018-01-04 16:28:23
PR,Merging 1 5 0 rc0 back to master,,,av8ramit,2018-01-04 03:08:43,2018-01-04 18:14:52
PR,Fix build issues with cuda 9 1 through updating eigen,,,"gunan,gunan,av8ramit",2018-01-02 21:55:13,2018-01-04 18:32:04
IS,Error in InputQueueingStateSaver barrier,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Mint 18 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 2 0 rc2 21 g12f033d 1 2 0 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I encounter an error related to barriers when using tf contrib training batch sequences with states I use this function to batch sequences For now just batches of 4 I do not understand the error it but I tried empirically poking at it and it only occurs with some capacity values For example it does not occur within 15 minutes with a capacity value of 16 good for 4 batches and cycles through the input sequences as expected It does occur within a minute with capacity values of 32 and 64 I know this is incredibly vague but I can explore more if you can help me understand the underlying issue I do believe this question does not fit the StackOverflow format as this is buggy behaviour Source code logs Below the error log One thing I do not understand for example is that it always complains about components 0 8 I have verified that this occurs for multiple keys My best guess is that this has to do with save state trying to save over state that has already been saved,,"ebrevdo,ebrevdo,ebrevdo",2017-07-19 16:34:48,2018-01-04 18:39:05
PR,Enable tilde expansion in debug wrappers,This commit allows paths beginning with ' ' to be used when specifying where debug files should be dumped The tilde will now be expanded to the user is home directory,,"pvaneck,caisq,caisq",2018-01-04 17:50:11,2018-01-04 19:10:26
IS,Non determinism from tf data Dataset map with random ops,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes please see the minimal reproducible example script below OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 Linux CentOS 7 4 6 6 300 el7 centos x86 64 TensorFlow installed from source or binary pip3 install tf nightly also happens when built from source TensorFlow version use command below v1 3 0 rc1 3690 g9b9cbbe 1 5 0 dev20171023 Python version 3 6 3 Bazel version if compiling from source N A since nightly build reproduces the issue but when built from source I use 0 6 1 homebrew CUDA cuDNN version a GPU is not needed to reproduce the issue however it has also been tested with CUDA 8 0 61 cuDNN 7 0 1 GPU model and memory N A a GPU is not needed to reproduce the issue however it has also been tested with Tesla K80s Exact command to reproduce See minimal reproducible example below Describe the problem The new tf data Dataset API contains a map function with a num parallel calls parameter which allows elements to be processed in parallel by multiple threads Although not explicitly mentioned in the API docs prior discussions such as a comment from today issuecomment 338772693 have indicated that the map function should be deterministic w r t the graph seed even if num parallel calls 1 I have observed that if the function being mapped contains only non random ops then this determinism is observed see step 2 below However if the the function being mapped contains a random op the results become non deterministic for all values of num parallel calls 1 This is unexpected and prevents training experiments from being reproducible unless num parallel calls 1 Also please note that the example below serves as a minimal example to reproduce the issue The real scenario involves running data augmentation during training Source code logs 1 pip3 install tf nightly 2 Run the following code to observe that map functions with only non random ops are deterministic for all values of num parallel calls which is the expected behavior 4 Observe that swapping out the map line above with an entirely different random op such as dataset dataset map lambda x x tf random normal 64 64 3 seed 42 num parallel calls threads is also non deterministic for values of num parallel calls 1,,"skye,mrry",2017-10-24 00:26:33,2018-01-04 19:13:34
IS,Feature query How to load the graph model only once and then give series of inputs,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No Running the Simple Audio recognition network tutorial OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Source TensorFlow version use command below 1 3 Python version 3 6 Bazel version if compiling from source 0 6 0 Describe the problem I am a tensorflow and neural network novice I was able to run the Simple audio recognition network For a given input wavefile the model obtained gives the result in approx 5 seconds I want reduce this time to 100s of milliseconds From the issue there seems to be a way to do this using the graph I used the graph optimisation tool but there was not a considerable reduction in time I heard that loading the graph is what takes time and hence I need to figure out how to load the graph only once and then feed the inputs without feeding all the parameters every time a new input needs to be tested The command that is used for decoding is as follows python tensorflow examples speech commands label wav py graph tmp my frozen graph pb labels tmp speech commands train conv labels txt wav tmp speech dataset left a5d485dc nohash 0 wav Also does anyone know if there is official data on how long alexa google home take to respond to trigger words,,"drpngx,drpngx",2017-10-19 17:56:41,2018-01-04 19:27:18
IS,How periodicaly evaluate the Performance of Models in TF Slim,I am trying to use DensNet 1 for regression problem with TF Slim My data contains 60000 jpeg images with 37 float labels for each image I divided my data into three different tfrecords files of a train set 60 a validation set 20 and a test set 20 I need to evaluate validation set during training loop and make a plot like image 2 In TF Slim documentation they just explain train loop and evaluation loop separately I can just evaluate validation or test set after training loop finished While as I said I need to evaluate during training I tried to use slim evaluation evaluation loop function instead of slim evaluation evaluate once But it does not help slim evaluation evaluation loop master FLAGS master checkpoint dir checkpoint path logdir FLAGS eval dir num evals num batches eval op list names to updates values print ops variables to restore variables to restore summary op tf summary merge summary ops eval interval secs eval interval secs I tried evaluation evaluate repeatedly as well from tensorflow contrib training python training import evaluation evaluation evaluate repeatedly master FLAGS master checkpoint dir checkpoint path eval ops list names to updates values print ops eval interval secs eval interval secs In both of these functions they just read the latest available checkpoint from checkpoint dir and apparently waiting for the next one however when the new checkpoints are generated they do not perform at all I use Python 2 7 13 and Tensorflow 1 3 0 on CPU Any help will be highly appreciated 1 2,,"drpngx,drpngx",2017-10-17 03:04:48,2018-01-04 19:27:49
IS,ERROR tensorflow Exception in QueueRunner truncated record at 935047,so why this errors,,"drpngx,drpngx",2017-10-17 07:16:13,2018-01-04 19:28:52
IS,label image example does not work with Mobilenetv1 224,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 12 5 TensorFlow installed from source or binary Source TensorFlow version use command below Github tag 1 2 release Python version 2 7 Mac OS X System install Bazel version if compiling from source Homebrew 0 4 5 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce bazel bin tensorflow examples label image label image image Path to image jpg input layer input output layer MobilenetV1 Predictions Reshape 1 graph Path To my trained mobilenet pb labels Path To My labels txt input mean 0 input std 255 Describe the problem Ive retrained MobileNetV1 224 via the TF Slim readme md and have produced a graph pb trained against a data set with 5 labels to classify I am attempting to validate my training by running the exported graph on some validation and training data myself and have build label image and specified the above flags to run Its unclear if label image is expected able to run MobileNet but it does not it errors with E tensorflow examples label image main cc 312 Running model failed Invalid argument Tried to explicitly squeeze dimension 1 but dimension was not 1 2 Node MobilenetV1 Logits SpatialSqueeze Squeeze T DT FLOAT squeeze dims 1 2 device job localhost replica 0 task 0 cpu 0 MobilenetV1 Logits Conv2d 1c 1x1 BiasAdd Source code logs Full execution command and output Mayalls Object tensorflow vade bazel bin tensorflow examples label image label image image Volumes MediaArchive datasets SynopsisCinemaNet data Framing original photos Extreme Close Up images 12 copy jpg input layer input output layer MobilenetV1 Predictions Reshape 1 graph Volumes MediaArchive datasets SynopsisCinemaNet model FramingWeekend CinemaNetFraming pb labels Volumes MediaArchive datasets SynopsisCinemaNet datasets Framing labels txt input mean 0 input std 255 2017 07 03 14 44 05 971869 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 05 972224 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 05 972228 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 05 972231 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 06 123365 E tensorflow examples label image main cc 312 Running model failed Invalid argument Tried to explicitly squeeze dimension 1 but dimension was not 1 2 Node MobilenetV1 Logits SpatialSqueeze Squeeze T DT FLOAT squeeze dims 1 2 device job localhost replica 0 task 0 cpu 0 MobilenetV1 Logits Conv2d 1c 1x1 BiasAdd Mayalls Object tensorflow vade bazel bin tensorflow examples label image label image image Volumes MediaArchive datasets SynopsisCinemaNet data Framing converted photos Extreme Close Up images 12 copy jpg input layer input output layer MobilenetV1 Predictions Reshape 1 graph Volumes MediaArchive datasets SynopsisCinemaNet model FramingWeekend CinemaNetFraming pb labels Volumes MediaArchive datasets SynopsisCinemaNet datasets Framing labels txt input mean 0 input std 255 2017 07 03 14 44 47 201141 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 47 201530 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 47 201534 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 47 201538 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations 2017 07 03 14 44 47 365892 E tensorflow examples label image main cc 312 Running model failed Invalid argument Tried to explicitly squeeze dimension 1 but dimension was not 1 2 Node MobilenetV1 Logits SpatialSqueeze Squeeze T DT FLOAT squeeze dims 1 2 device job localhost replica 0 task 0 cpu 0 MobilenetV1 Logits Conv2d 1c 1x1 BiasAdd Mayalls Object tensorflow vade,,petewarden,2017-07-03 18:53:33,2018-01-04 19:32:32
IS,Centered batch padding with tf data Dataset API,Hi First of all kudos for the PaddedBatchDataset op and all the tf data Dataset API Right now all the examples in the batch are aligned at coordinate 0 0 I think it is very convenient in many applications e g image processing to have the examples centered in the batch I would like to know if you would accept a pull request in that direction If so I am willing to work on this I suggest to add a flag to the operator so that the user can decide whether she wants the data centered or aligned at 0 0 i e the current behavior This changes should not be difficult to make,,"mrry,ebrevdo,ebrevdo,mrry",2017-10-25 10:58:58,2018-01-04 19:35:31
IS,Want to build tensorflow for android but stuck at this problem,OS Platform and Distribution Windows 10 Bazel version 0 5 2 C Users dulam tensorflow bazel build c opt tensorflow contrib android libtensorflow inference so ERROR C users dulam tensorflow tensorflow core BUILD 1415 1 no such target ' tensorflow tools git gen spec json' target 'gen spec json' not declared in package 'tensorflow tools git' defined by C users dulam tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR C users dulam tensorflow tensorflow core BUILD 1415 1 no such target ' tensorflow tools git gen head' target 'gen head' not declared in package 'tensorflow tools git' defined by C users dulam tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR C users dulam tensorflow tensorflow core BUILD 1415 1 no such target ' tensorflow tools git gen branch ref' target 'gen branch ref' not declared in package 'tensorflow tools git' defined by C users dulam tensorflow tensorflow tools git BUILD and referenced by ' tensorflow core version info gen' ERROR Analysis of target ' tensorflow contrib android libtensorflow inference so' failed build aborted,,"drpngx,drpngx,drpngx,andrewharp,drpngx,drpngx,andrewharp",2017-07-04 19:46:43,2018-01-04 19:44:24
IS,Tensorflow org master version is not updated,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Not Relevant OS Platform and Distribution e g Linux Ubuntu 16 04 Not Relevant TensorFlow installed from source or binary Not Relevant TensorFlow version use command below Not Relevant Python version Not Relevant Bazel version if compiling from source Not Relevant GCC Compiler version if compiling from source Not Relevant CUDA cuDNN version Not Relevant GPU model and memory Not Relevant Exact command to reproduce Not Relevant Describe the problem tensorflow org master version should be updated to master however it seems that it has not been regenerated for a while For example the latest addition of the performance guide for tf data has not yet made it to the website Doc source Generated web page in tensorflow org master version Currently shows Last updated November 14 2017 in the bottom,,"gunan,MarkDaoust",2017-12-26 20:42:01,2018-01-04 19:56:55
IS,Compilation Flags,Can someone please explain the flags that can be enabled when compiling TensorFlow from source I do not seem to understand the functionality of most of them and they are not documented,,"drpngx,MarkDaoust",2017-11-17 22:03:01,2018-01-04 20:02:05
PR,Fixes and formatting to configure py,Fix a bug in error generation regarding true false string parsing Some minor style fixes,,"caisq,gunan,caisq",2018-01-04 16:05:37,2018-01-04 20:54:55
PR,Remove python boolean check from adjust gamma,The adjust gamma operation used a python boolean to check if gamma was positive This however removes any possibility of using a scalar tensor which means it can not be used to apply random augmentations during training It is fixed by using a tf assert positive statement,,"martinwicke,drpngx,drpngx,martinwicke,martinwicke,drpngx,drpngx,drpngx,drpngx,drpngx",2017-11-14 17:00:05,2018-01-04 21:52:30
IS,cudaCheckError failed on any gpu apart from gpu 0,I am experiencing a strange issue similar to 9489 on both a 4 GPUs and a 2 GPUs machine Basically I have a tensorflow model that trains and performs very well on one GPU I now want to distribute the training phase by using multiple GPUs at once I followed the CIFAR10 example to parallelize the model but keep getting errors a few iterations into the training process I get most times but I have also seen shape errors on reshape tensors while the graph is already running and segmentation errors I have been playing around with configurations and so far I have noticed that the crash only happens if gpu 1 is being called I tried using only gpu 1 and encountered the same problem On the other end the same script using with tf device 'gpu 0' and only this gpu works fine What I tried I reinstalled tensorflow from sources set up and tested another machine with more GPUs to no avail test out txt other errors that have occurred iter 1 70000 total loss 2 5591 2 5591 rpn loss cls 0 6961 rpn loss box 0 0025 loss cls 1 8603 loss box 0 0003 lr 0 001000 speed 4 586s iter iter 2 70000 total loss 1 3976 1 3976 rpn loss cls 0 6869 rpn loss box 0 0078 loss cls 0 7021 loss box 0 0007 lr 0 001000 speed 2 638s iter iter 3 70000 total loss 1 0764 1 0764 rpn loss cls 0 6849 rpn loss box 0 0251 loss cls 0 2764 loss box 0 0900 lr 0 001000 speed 1 999s iter iter 4 70000 total loss 0 9941 0 9941 rpn loss cls 0 6804 rpn loss box 0 0118 loss cls 0 2407 loss box 0 0611 lr 0 001000 speed 1 673s iter cudaCheckError failed invalid resource handle 2017 06 22 10 07 47 528133 F tensorflow stream executor cuda cuda driver cc 312 Check failed CUDA SUCCESS cuCtxSetCurrent cuda context context 0 vs 4 experiments scripts faster rcnn end2end sh line 58 30171 Aborted core dumped python tools train net py device DEV number of devices NUM DEVICES weights data pretrain model VGG imagenet npy imdb TRAIN IMDB iters ITERS cfg experiments cfgs faster rcnn end2end yml network VGGnet train EXTRA ARGS 2017 06 22 10 10 04 886367 W tensorflow core common runtime bfc allocator cc 217 Allocator GPU 1 bfc ran out of memory trying to allocate 3 51GiB The caller indicates that this is not a failure but may mean that there could be performance gains if more memory is available cudaCheckError failed invalid resource handle 2017 06 22 10 10 06 489802 E tensorflow stream executor cuda cuda event cc 49 Error polling for event status failed to query event CUDA ERROR DEINITIALIZED 2017 06 22 10 10 06 489835 F tensorflow core common runtime gpu gpu event mgr cc 203 Unexpected Event status 1 2017 06 22 10 10 58 935801 W tensorflow core common runtime bfc allocator cc 217 Allocator GPU 1 bfc ran out of memory trying to allocate 3 51GiB The caller indicates that this is not a failure but may mean that there could be performance gains if more memory is available iter 1 70000 total loss 2 8609 2 8609 rpn loss cls 0 6944 rpn loss box 0 0092 loss cls 2 1569 loss box 0 0004 lr 0 001000 speed 4 461s iter iter 2 70000 total loss 1 4497 1 4497 rpn loss cls 0 6778 rpn loss box 0 0152 loss cls 0 7555 loss box 0 0012 lr 0 001000 speed 2 556s iter iter 3 70000 total loss 1 5660 1 5660 rpn loss cls 0 7197 rpn loss box 0 0325 loss cls 0 6074 loss box 0 2063 lr 0 001000 speed 1 921s iter 2017 06 22 10 11 03 655654 W tensorflow core framework op kernel cc 1165 Invalid argument Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape 2017 06 22 10 11 03 655654 W tensorflow core framework op kernel cc 1165 Invalid argument Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape 2017 06 22 10 11 03 655687 W tensorflow core framework op kernel cc 1165 Invalid argument Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape 2017 06 22 10 11 03 655692 W tensorflow core framework op kernel cc 1165 Invalid argument Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape Traceback most recent call last File tools train net py line 100 in module max iters args max iters File home SERILOCAL a larreche Faster RCNN TF tools lib fast rcnn train py line 375 in train net sw train model sess max iters File home SERILOCAL a larreche Faster RCNN TF tools lib fast rcnn train py line 281 in train model run metadata run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 896 in run run metadata ptr File usr local lib python2 7 dist packages tensorflow python client session py line 1108 in run feed dict tensor options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1261 in do run options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1280 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape Caused by op u'tower 1 Reshape' defined at File tools train net py line 100 in module max iters args max iters File home SERILOCAL a larreche Faster RCNN TF tools lib fast rcnn train py line 375 in train net sw train model sess max iters File home SERILOCAL a larreche Faster RCNN TF tools lib fast rcnn train py line 208 in train model cross entropy t loss box t rpn cross entropy t rpn loss box t self tower loss i File home SERILOCAL a larreche Faster RCNN TF tools lib fast rcnn train py line 148 in tower loss outputs roi data outputs cls score outputs bbox pred self net inference gpu id File home SERILOCAL a larreche Faster RCNN TF tools lib networks VGGnet train py line 89 in inference reshape layer 2 name 'rpn cls score reshape' format i File home SERILOCAL a larreche Faster RCNN TF tools lib networks network py line 26 in layer decorated layer output op self layer input args kwargs File home SERILOCAL a larreche Faster RCNN TF tools lib networks network py line 217 in reshape layer int d tf cast tf cast input shape 1 tf float32 tf cast input shape 3 tf float32 tf cast d tf float32 tf int32 input shape 2 0 2 3 1 name name File usr local lib python2 7 dist packages tensorflow python ops gen array ops py line 2472 in reshape name name File usr local lib python2 7 dist packages tensorflow python framework op def library py line 767 in apply op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 2528 in create op original op self default original op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 1203 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback Input to reshape is a tensor with 178500 values but the requested shape has 365072219990 Node tower 1 Reshape Reshape T DT FLOAT Tshape DT INT32 device job localhost replica 0 task 0 gpu 1 tower 1 transpose tower 1 Reshape shape,,"tatatodd,tatatodd",2017-06-21 18:59:30,2018-01-04 21:59:50
IS,Make tf contrib seq2seq BaseAttentionMechanism public,Currently if users want to write their own attention mechanisms they have to do so from scratch by extending the tf contrib seq2seq AttentionMechanism class which has nothing or import the BaseAttentionMechanism from attention wrapper py with the following inconvenient import statement from tensorflow contrib seq2seq python ops attention wrapper import BaseAttentionMechanism It is worth including this class directly accessible from tf contrib seq2seq considering that it adds good defaults and that both forms of attention currently available Bahdanau and Luong inherit this class My proposal is to simply rename the class to BaseAttentionMechanism without an underscore or perhaps a more meaningful name such as BasicAttentionMechanism to differentiate it from the parent class AttentionMechanism and add the class to the all array in attention wrapper py,,"aselle,ebrevdo",2017-06-18 07:52:50,2018-01-04 22:24:19
IS,Feature request RNN BeamSearchDecoder with Mixture Density Networks For Continuous Truth Values,For continuous data there are 3 options to run a beam search when decoding 1 This is a workaround Quantize continuous truth values into into either one hot vector or embedding effectively transforming the regression into a classification problem 2 Use a mixture density model with N Gaussian mixtures When decoding sample top beam width mixtures 3 Use the SOTA method described in this paper Of course the preferred method is number 3 With a graph similar to how can such a decoder be implemented My suggestion is to create a separate decoder subclass that specifically handle this situtation to avoid confusion,,"rohan100jain,ebrevdo",2017-06-22 18:15:04,2018-01-04 22:25:48
PR,extract populate weight collection,,,,2018-01-04 22:21:04,2018-01-04 22:28:59
IS,Seq2Seq Documentation is Broken,A good third of the documentation on is written about a DynamicAttentionWrapper class The link posted for an API results in a 404 This class is not mentioned in init py at Can someone please either update the documentation or add the class to git so we can actually use it,,"tatatodd,tatatodd",2017-06-22 16:28:43,2018-01-04 22:37:55
PR,Closing input stream runner session in TensorFlowInferenceInterface java and fixing bit changes,,,"rajendraarora16,asimshankar,asimshankar,asimshankar,asimshankar,rajendraarora16,rajendraarora16,asimshankar,asimshankar,rajendraarora16,asimshankar,rajendraarora16,asimshankar,caisq,rajendraarora16",2018-01-03 11:19:08,2018-01-04 23:28:59
IS,C1002 error when building on Windows 10 64 bit with vs 2017,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit version 1511 TensorFlow installed from source or binary source TensorFlow version use command below master branch commit 90b2a38a1 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory CPU only Exact command to reproduce C cmake 3 9 0 rc4 win64 x64 bin cmake exe G Visual Studio 15 2017 Win64 DCMAKE BUILD TYPE Release DSWIG EXECUTABLE C swigwin 3 0 12 swig exe DPYTHON EXECUTABLE C Users x conda envs tensorflow python exe DPYTHON LIBRARIES C Users x conda envs tensorflow libs python35 lib Dtensorflow BUILD CC TESTS ON Dtensorflow WIN CPU SIMD OPTIONS arch AVX C cmake 3 9 0 rc4 win64 x64 bin cmake exe build You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Issued above build command and got the following error at last C Users X github tensorflow tensorflow contrib cmake build ALL BUILD vcxproj default target 1 C Users X github tensorflow tensorflow contrib cmake build beam search ops vcxproj default target 3 C Users X github tensorflow tensorflow contrib cmake build pywrap tensorflow internal vcxproj default target 4 C Users X github tensorflow tensorflow contrib cmake build pywrap tensorflow internal static vcxproj default t arget 5 C Users X github tensorflow tensorflow contrib cmake build tf core kernels vcxproj default target 108 ClCompile target c users x github tensorflow tensorflow contrib cmake build external eigen archive eigen src core products gener alblockpanelkernel h 2011 fatal error C1002 compiler is out of heap space in pass 2 C Users X github tensorfl ow tensorflow contrib cmake build tf core kernels vcxproj cl Command line error D8040 error creating or communicating with child process C Users X github tensorflow tensorflow contrib cmake build tf core kernels vcxproj 86 Warning s 2 Error s For the warnings there are two kinds C Users X github tensorflow tensorflow c c api cc 1938 warning C4190 'TF NewWhile' has C linkage specified but returns UDT 'TF WhileParams' which is incompatible with C C Users X github tensorflow tensorflow contrib cma ke build tf test lib vcxproj and c users X github tensorflow tensorflow core kernels eigen spatial convolutions h 724 warning C4789 buffer '' of size 8 bytes will be overrun 32 bytes will be written starting at offset 0 C Users X github tensorflow tens orflow contrib cmake build tf core kernels vcxproj I saw there are many complains about compiler is out of heap space in pass 2 error and some say adding Zm2000 to the compiler would solve the problem I applied this patch 78 6 78 8 if WIN32 set CMAKE CXX FLAGS RELEASE CMAKE CXX FLAGS RELEASE D ITERATOR DEBUG LEVEL 0 set CMAKE CXX FLAGS MINSIZEREL CMAKE CXX FLAGS MINSIZEREL D ITERATOR DEBUG LEVEL 0 set CMAKE CXX FLAGS RELWITHDEBINFO CMAKE CXX FLAGS RELWITHDEBINFO D ITERATOR DEBUG LEVEL 0 Increase heap size set CMAKE CXX FLAGS CMAKE CXX FLAGS Zm2000 But did not solve this problem Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2017-06-28 03:14:35,2018-01-05 00:48:56
PR,Branch 180746153,,,"raghuraman-k,raghuraman-k,jhseu,frankchn",2018-01-04 21:06:41,2018-01-05 01:03:06
PR,Bazel Windows Wrap rm rf in Bash for Windows and some refactoring,rm rf is not available in Windows command prompt Run it in Bash like patch pl Refactor the wrapping logic into a new macro wrap bash cmd,,"rongjiecomputer,caisq,rongjiecomputer",2018-01-04 03:10:47,2018-01-05 01:33:43
PR,Fix typo in eager value and gradients docstring,The function is computing gradients with respect to f so this is possessive of the function if I'm reading this properly,,,2018-01-04 22:22:19,2018-01-05 01:34:09
PR,Fix docs,,,"av8ramit,asimshankar,asimshankar,asimshankar,MarkDaoust,av8ramit,asimshankar",2018-01-04 22:24:25,2018-01-05 01:35:54
IS,Weird behavior of tf train Saver,System information Linux Ubuntu 14 04 TensorFlow installed from binary TensorFlow version v1 0 0 rc2 CUDA 8 0 CuDNN 5 1 Tesla K80 12GB Describe the problem I have a problem with the tf train Saver specifically with the 'max to keep' argument If I create a Saver with 'max to keep' set to let is say 3 and use the saver save function to save my model in the current directory it keeps all files and does not delete the old ones after 3 or more are created If I set the path where to save the model to a different location it works just fine See also my stackoverflow question Source code logs Creates for the numbers 1 to 10 each 3 files testfile 1 data 00000 of 00001 testfile 1 index testfile 1 meta,,"aselle,concretevitamin,rohan100jain",2017-06-16 07:40:02,2018-01-05 02:10:37
IS,How to read image data and fill image tensor by tensorflow c apis,I want to infer a image by a trained model first read a image as Mat by opencv then fill plane tensor with Mat Does it work Is there any better way to the following code waiting for some warming person thank you very much Mat img imread file name std vector Mat bgr split img bgr tensorflow Tensor four dim plane DT UINT8 tensorflow TensorShape 1 img rows img cols 3 auto plane tensor four dim plane tensor unsigned char 4 for int k 0 k 3 k for int i 0 i img rows i for int j 0 j img cols j plane tensor 0 i j k bgr k at unsigned char i j tensorflow Status status3 session Run image tensor plane tensor output node outputs System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 windows10 TensorFlow installed from source or binary source TensorFlow version use command below TF1 4 Python version python3 5 2 GCC Compiler version if compiling from source vs2015 CUDA cuDNN version cuda8 0 cudnn6 0 GPU model and memory TXT1080TI 11G Bazel version Exact command to reproduce,,,2017-11-30 09:25:56,2018-01-05 02:18:52
IS,Cmake TF1 4 GUP on windows 10,Who can give me some recent samples about Cmake TF1 4 GUP on windows 10 I have tried several times following some old links but failed System information OS Platform and Distribution win10 64 TensorFlow version use command below 1 4 0 Python version 3 5 2 CUDA cuDNN version 9 0 7 0 3 GPU model and memory GTX 1080Ti VS2015 Have I written custom code TensorFlow installed from Bazel version Exact command to reproduce,,Carmezim,2017-11-15 03:42:21,2018-01-05 02:19:18
IS,IOS camera example load map data from in pix is incorrect,for int y 0 y wanted input height y float out row out y wanted input width wanted input channels 0 height for int x 0 x wanted input width x const int in x y image width wanted input width const int in y x image height wanted input height tensorflow uint8 in pixel in in y image width image channels in x image channels float out pixel out row x wanted input channels for int c 0 c wanted input channels c out pixel c in pixel c input mean input std fixed code rotoate 90 and resized for int y 0 y wanted input width y float out row out y wanted input width wanted input channels for int x 0 x wanted input height x const int in x y image width wanted input width const int in y image height x image height wanted input height tensorflow uint8 in pixel in in y image width image channels in x image channels float out pixel out row x wanted input channels for int c 0 c wanted input channels c out pixel c in pixel c input mean input std,,,2017-11-11 03:42:14,2018-01-05 04:01:13
IS,Feature Request delete key in MutableHashTable,A wouldelete' method in contrib lookup MutableHashTable would be useful when there are too many key value pairs and we can only handle the recent ones Is there any possibility that the delete method will be implemented Thanks,,ysuematsu,2017-06-27 08:41:07,2018-01-05 04:26:01
IS,tf scatter add causes error in loop,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes it is below OS Platform and Distribution e g Linux Ubuntu 16 04 MacOSX TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 Bazel version if compiling from source CUDA cuDNN version no CUDA GPU model and memory no GPU Exact command to reproduce Describe the problem I found very strange behavior of tf scatter add I created a tf while loop that creates a Tensor wrapped inside a tf Variable If I do not add something to the Variable outside the loop tensorflow causes an error telling me that the Variable is not mutable I asked the on StackOverflow and was told to create a bug report comment80914069 46935216 Uncommenting the commented line removes the error But I do not think this is intended behavior Source code logs import tensorflow as tf m 25 batch num 32 num bus 50 C tf zeros m batch num num bus m tf float64 C tf Variable C c tf ones batch num num bus m tf float64 C tf scatter add C 0 c k tf constant 1 stop cond lambda k C k m def construct C k C upd c c 1 C tf scatter add C k upd c return k 1 C k C tf while loop stop cond construct C k C sess tf Session sess run tf global variables initializer C1 sess run C,,"jart,ebrevdo,ebrevdo",2017-10-30 18:44:32,2018-01-05 04:26:49
PR,Change dso loader to look for libcupti so instead of libcupti so 8 0,On Android it is hard to package libcupti so 8 0 with bazel to generate CUDA enabled apk The cc library macro in bazel only looks for so not so,,"lihanchen,andrewharp,gunan,lihanchen,gunan",2018-01-02 22:58:58,2018-01-05 06:20:35
IS,Failed to convert a pb file to a lite file where there is a custom lite op sin,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 5 LTS TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 2 7 6 Bazel version if compiling from source 0 8 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I followed How to use custom operators to create a pb file and sin cc in tensorflow contrib lite kernel Then I added TfLiteRegistration Register SIN and AddCustom Sin Register SIN in register cc But when I used the bazel command to covert the pb file the sin op can not be converted Here is the command I used bazel build tensorflow contrib lite toco toco bazel bin tensorflow contrib lite toco toco input file tftest sin pb input format TENSORFLOW GRAPHDEF output file tftest sin tflite output format TFLITE inference type FLOAT input array input input shape 1 output array output Here is the corresponding ERROE information Some of the operators in the model are not supported by the standard TensorFlow Lite runtime If you have a custom implementation for them you can disable this error with allow custom ops Here is a list of operators for which you will need custom implementations Sin I tried to use allow custom ops but it did not work Here is the ERROR information Converting unsupported operation Sin I think I have to modify more files but I do not know which files I should modify and how to modify Could you please give a detailed demo Thx,,,2017-12-16 08:04:56,2018-01-05 06:28:58
IS,fatal error C1083 Cannot open include file 'tensorflow core framework device attributes pb text h',I am new to tensorflow when I compile tensorfolw with VS2015 in Windows 7 I got the following error could anyone help on this thanks fatal error C1083 Cannot open include file 'tensorflow core framework device attributes pb text h',,"snnn,snnn,snnn",2017-12-20 09:15:06,2018-01-05 06:57:34
IS,Tensorflow predicts odd results with insufficient GPU memory,Hi all I am currently having a problem that when my code tries to initialize two or more predict instances in a GPU with insufficient memory instead of throwing an OOM exception the instances are initialized normally However when I try to predict an image with these instances they produce weird results like 1 0 0 0 0 0 Is this a bug when two or more sessions try to race for limited amount of GPU memory Please see below for my system information and the exact steps to reproduce the problem I would very much appreciate it if you could take a look Cheers Vincent System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution CentOS Linux release 7 2 1511 TensorFlow installed from source or binary official binaries TensorFlow version use command below 1 3 0 1 2 0 1 1 0 Python version 2 7 5 CUDA cuDNN version CUDA 8 0 61 CUDNN 6 0 GPU model and memory 1080 Ti 11172MB Exact steps to reproduce 1 Download and uncompress the file below with two scripts 2 Download the official inception v1 imagenet pretrained model from 3 Try to occupy most of the memory in the GPU to run on the exact amount of memory to occupy needs to be carefully tuned to reproduce the problem in my case I use pycuda to allocate 10720 out of the 11172MB of my 1080 Ti 4 Run test monitor py in two separate command prompts we should see weird results within a few minutes the scripts stop when encounter such results reproduce code zip,,"asimshankar,yzhwang,yzhwang",2017-11-02 02:49:38,2018-01-05 08:25:55
IS,Unable to compile tensorflow r1 4 from source with cuda 8 0 and cudnn 7 and after downgrading bazel,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below r1 4 Python version 2 7 12 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 8 0 7 0 4 GPU model and memory 1080 Ti Exact command to reproduce bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures cxxopt D GLIBCXX USE CXX11 ABI 0 action env LD LIBRARY PATH LD LIBRARY PATH Describe the problem I'm trying to compile TF r1 4 from source but did not manage to get this working although I tried several fixes 1 Downgrading bazel from 0 9 0 to 0 8 1 based on 15492 2 sudo sh c echo ' usr local cuda 8 0 lib64' etc ld so conf d nvidia conf and sudo ldconfig based on 13481 3 adding the action env argument based on 47295278 Note When installing cudnn I used both the runtime library and the tar file which i extracted and placed it in the usr local cuda library respective folders Source code logs,,"skye,reedwm,reedwm,gunan",2017-12-27 03:02:31,2018-01-05 13:50:41
PR,Branch 180856860,,,"raghuraman-k,raghuraman-k,jhseu,raghuraman-k,caisq,caisq,raghuraman-k",2018-01-05 00:24:19,2018-01-05 14:04:12
IS,Segmentation fault on get session handle after 1 4 1 upgrade,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 19 ga52c8d9 from 1 4 1 pip install Python version 2 7 6 Bazel version if compiling from source N a GCC Compiler version if compiling from source N a CUDA cuDNN version N a GPU model and memory N a Exact command to reproduce After upgrading from 1 3 to 1 4 1 running the following code produces a segmentation fault,,jart,2017-12-22 17:50:43,2018-01-05 14:05:19
IS,tf assert equal raises incorrect traceback in Eager mode,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 1 LTS TensorFlow installed from source or binary pip binary TensorFlow version use command below 1 5 0 dev20171227 Python version 3 5 0 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version None GPU model and memory None Exact command to reproduce python main py Describe the problem In eager mode tf assert equal only shows in traceback message when two inputs are different However in graph mode it does show different values in the message Source code logs,,"asimshankar,iganichev",2018-01-01 09:43:43,2018-01-05 14:05:19
IS,tf nn fractional max pool output have same batch size when feed with different input batch size,Describe the problem tf nn fractional max pool output have same batch size when feed with different input batch size Attached is test code I write 2 different input is feed in with different batch size outputs get same batch size pool test py txt code result shape of input a 3 32 32 3 shape of output a 3 21 21 3 shape of input b 4 32 32 3 shape of output b 3 21 21 3 System information cat etc issue Linux c 1080u 4 10 0 40 generic 44 16 04 1 Ubuntu SMP Thu Nov 9 15 37 44 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux c 1080u 4 10 0 40 generic 44 16 04 1 Ubuntu SMP Thu Nov 9 15 37 44 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 numpydoc 0 7 0 check for virtualenv False tensorflow import Traceback most recent call last File string line 1 in module ModuleNotFoundError No module named 'tensorflow' env LD LIBRARY PATH usr local cuda 8 0 lib64 DYLD LIBRARY PATH is unset nvidia smi Thu Nov 30 11 55 40 2017 NVIDIA SMI 384 90 Driver Version 384 90 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 108 Off 00000000 01 00 0 On N A 0 51C P8 21W 280W 860MiB 11169MiB 9 Default Processes GPU Memory GPU PID Type Process name Usage 0 1060 G usr lib xorg Xorg 542MiB 0 1540 G compiz 315MiB cuda libs usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61 cat etc issue Linux c 1080u 4 10 0 40 generic 44 16 04 1 Ubuntu SMP Thu Nov 9 15 37 44 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux c 1080u 4 10 0 40 generic 44 16 04 1 Ubuntu SMP Thu Nov 9 15 37 44 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 protobuf 3 5 0 post1 tensorflow gpu 1 4 0 tensorflow tensorboard 0 4 0rc3 check for virtualenv False tensorflow import tf VERSION 1 4 0 tf GIT VERSION v1 4 0 rc1 11 g130a514 tf COMPILER VERSION v1 4 0 rc1 11 g130a514 Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda 8 0 lib64 DYLD LIBRARY PATH is unset nvidia smi Thu Nov 30 11 56 18 2017 NVIDIA SMI 384 90 Driver Version 384 90 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 108 Off 00000000 01 00 0 On N A 0 51C P0 80W 280W 860MiB 11169MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 1060 G usr lib xorg Xorg 542MiB 0 1540 G compiz 315MiB cuda libs usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61,,tatatodd,2017-11-30 04:20:21,2018-01-05 14:05:19
IS,BUG no viable conversion ERROR raised in tensorflow core kernels eigen pooling h when build v1 4 1 for opencl,System information OS Platform and Distribution Linux Ubuntu 17 10 TensorFlow installed from source TensorFlow version 1 4 1 Python version 3 6 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source 7 2 Describe the problem no viable conversion ERROR raised when build v1 4 1 with opencl computecpp CE 0 5 0 Source code logs ERROR tensorflow tensorflow core kernels BUILD 3169 1 C compilation of rule ' tensorflow core kernels pooling ops' failed Exit 1 In file included from tensorflow core kernels pooling ops 3d cc 29 tensorflow core kernels eigen pooling h 338 12 error no viable conversion from ' m128' vector of 4 'float' values to 'cl sycl vec float 4 ' Packet skip mask tensorflow core kernels eigen pooling h 333 5 note in instantiation of function template specialization 'Eigen internal AvgPoolMeanReducer float reducePacketWithType cl sycl vec float 4 ' requested here reducePacketWithType static cast T 0 p accum external eigen archive unsupported Eigen CXX11 src Tensor TensorReduction h 186 15 note in instantiation of function template specialization 'Eigen internal AvgPoolMeanReducer float reducePacket cl sycl vec float 4 ' requested here reducer reducePacket self m impl template packet Unaligned firstIndex j p external eigen archive unsupported Eigen CXX11 src Tensor TensorReduction h 279 56 note in instantiation of member function 'Eigen internal InnerMostDimReducer Eigen TensorEvaluator const Eigen TensorReductionOp Eigen internal AvgPoolMeanReducer float const Eigen IndexList Eigen type2index 1 const Eigen TensorReshapingOp const Eigen DSizes long 3 const Eigen TensorVolumePatchOp 1 1 1 const Eigen TensorMap Eigen Tensor const float 5 1 long 16 MakePointer MakePointer Eigen ThreadPoolDevice Eigen internal AvgPoolMeanReducer float true reduce' requested here InnerMostDimReducer Self Op Vectorizable reduce self 0 num coeffs reducer external eigen archive unsupported Eigen CXX11 src Tensor TensorReduction h 523 48 note in instantiation of member function 'Eigen internal FullReducer Eigen TensorEvaluator const Eigen TensorReductionOp Eigen internal AvgPoolMeanReducer float const Eigen IndexList Eigen type2index 1 const Eigen TensorReshapingOp const Eigen DSizes long 3 const Eigen TensorVolumePatchOp 1 1 1 const Eigen TensorMap Eigen Tensor const float 5 1 long 16 MakePointer MakePointer Eigen ThreadPoolDevice Eigen internal AvgPoolMeanReducer float Eigen ThreadPoolDevice true run' requested here internal FullReducer Self Op Device run this reducer m device data external eigen archive unsupported Eigen CXX11 src Tensor TensorMorphing h 133 19 note in instantiation of member function 'Eigen TensorEvaluator const Eigen TensorReductionOp Eigen internal AvgPoolMeanReducer float const Eigen IndexList Eigen type2index 1 const Eigen TensorReshapingOp const Eigen DSizes long 3 const Eigen TensorVolumePatchOp 1 1 1 const Eigen TensorMap Eigen Tensor const float 5 1 long 16 MakePointer MakePointer Eigen ThreadPoolDevice evalSubExprsIfNeeded' requested here return m impl evalSubExprsIfNeeded data external eigen archive unsupported Eigen CXX11 src Tensor TensorAssign h 132 24 note skipping 2 contexts in backtrace use ftemplate backtrace limit 0 to see all return m rightImpl evalSubExprsIfNeeded m leftImpl data external eigen archive unsupported Eigen CXX11 src Tensor TensorDevice h 35 59 note in instantiation of member function 'Eigen internal TensorExecutor const Eigen TensorAssignOp Eigen TensorMap Eigen Tensor float 5 1 long 16 MakePointer const Eigen TensorReshapingOp const Eigen DSizes long 5 const Eigen TensorReductionOp Eigen internal AvgPoolMeanReducer float const Eigen IndexList Eigen type2index 1 const Eigen TensorReshapingOp const Eigen DSizes long 3 const Eigen TensorVolumePatchOp 1 1 1 const Eigen TensorMap Eigen Tensor const float 5 1 long 16 MakePointer MakePointer Eigen ThreadPoolDevice true run' requested here internal TensorExecutor const Assign DeviceType run assign m device tensorflow core kernels pooling ops 3d cc 108 71 note in instantiation of function template specialization 'Eigen TensorDevice Eigen TensorMap Eigen Tensor float 5 1 long 16 MakePointer Eigen ThreadPoolDevice operator Eigen TensorReshapingOp const Eigen DSizes long 5 const Eigen TensorReductionOp Eigen internal AvgPoolMeanReducer float const Eigen IndexList Eigen type2index 1 const Eigen TensorReshapingOp const Eigen DSizes long 3 const Eigen TensorVolumePatchOp 1 1 1 const Eigen TensorMap Eigen Tensor const float 5 1 long 16 MakePointer MakePointer ' requested here output tensor T 5 device context eigen device CPUDevice tensorflow core kernels pooling ops 3d cc 194 39 note in instantiation of member function 'tensorflow LaunchPoolingOp Eigen ThreadPoolDevice float tensorflow PoolingType AVG launch' requested here LaunchPoolingOp Device T Type launch context tensor in window stride tensorflow core kernels pooling ops 3d cc 133 12 note in instantiation of member function 'tensorflow Pooling3DOp Eigen ThreadPoolDevice float tensorflow PoolingType AVG Compute' requested here explicit Pooling3DOp OpKernelConstruction context UnaryOp T context tensorflow core kernels pooling ops 3d cc 738 15 note in instantiation of member function 'tensorflow Pooling3DOp Eigen ThreadPoolDevice float tensorflow PoolingType AVG Pooling3DOp' requested here TF CALL float REGISTER CPU KERNELS external local config sycl crosstool sycl include SYCL vec h 9461 3 note candidate constructor not viable no known conversion from ' m128' vector of 4 'float' values to 'const vec float 4 ' for 1st argument vec const vec dataT kElems rhs external local config sycl crosstool sycl include SYCL vec h 9437 3 note candidate template ignored could not match iswizzled vec float kElemsRhs kIndexRhsN ' against ' attribute vector size 4 sizeof float float' vector of 4 'float' values vec const swizzled vec dataT kElemsRhs kIndexRhsN rhs 1 error generated,,,2017-12-19 12:26:34,2018-01-05 15:37:13
IS,Feature request Add FFT to XLA bridge,As there are now CPU FFT implementations it seems like a small extra step to add the FFT ops to the XLA bridge Surely tf spectral is an immensely important suite of functions for a huge number of use cases,,"carlthome,reedwm,carlthome,carlthome,carlthome,carlthome,carlthome,brianwa84,brianwa84,brianwa84",2017-08-16 06:13:34,2018-01-05 16:09:51
IS,tf boolean mask does not check array bounds,OS Platform and Distribution e g Linux Ubuntu 16 04 archlinux TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 6 CUDA cuDNN version 8 0 6 0 The code runs while I expect an index out of bound error In fact even when mask is a 4x1 boolean I still expect an error since b is 1x4 But that is somewhat arguable,,"ppwwyyxx,reedwm,reedwm,rryan,rryan,ppwwyyxx",2017-08-18 21:25:48,2018-01-05 17:51:22
PR,Fix a few pip tests,In training test py avoid calling the assert called method which is not universally available Add tensorflow contrib data python kernel tests dataset serialization test as a pip package dependency to fix four failing contrib data pip tests,,caisq,2018-01-05 14:32:27,2018-01-05 17:54:57
IS,Dataset API batching is slow for numpy arrays,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4rc1 Python version 3 5 2 Bazel version if compiling from source Not sure think 0 7 GCC Compiler version if compiling from source 5 4 CUDA cuDNN version 8 6 GPU model and memory gtx980 Exact command to reproduce see attached Describe the problem The Prints the following on my machine Python single generator examples s 3779128 899140432 Python batch generator examples s 137113566 52500817 tf npy single examples s 2623 528591111384 tf npy batch examples s 10184 987886595052 tf npy single batch examples s 308841 62594729604 tf range single examples s 4673 512357184766 tf range batch examples s 352137 31184393575,,"mrry,jsimsa",2017-11-11 10:42:22,2018-01-05 18:01:38
IS,consuming Dataset becomes slower and slower if make one shot iterator each epoch,Problem I run make one shot iterator each epoch because I want re shuffle the dataset each epoch I Know that the dataset shuffle repeat batch pipeline can do almost the same thing but when data num can not be divided exactly by batch size the pipeline merges two epochs at their boundary to construct a complete batch which I HATE So I choose to run dataset shuffle batch and make one shot iterator before each epoch But I find that the speed of consuming dataset becomes slower and slower significantly I tried different settings to find out that it is make one shot iterator which makes consuming slow By the way I build tensorflow 1 4 from source on OS X with support of GPU some hacky workaround Code System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 OS X 10 12 5 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 2 7 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source clang 802 0 42 CUDA cuDNN version 9 0 7 GPU model and memory GTX1080 8G Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION,,"shivaniag,jsimsa",2017-11-24 19:27:25,2018-01-05 18:02:00
PR,Removing twice times declared same statement in Java org tensorflow Operation shape function,There is an already defined statement in shape method Java org tensorflow Operation shape However I found that after TF GraphGetTensorShape graph output cdims get static cast int num dims status the same statement was declared or we can probably add throwExceptionIfNotOK env status instead of that statement if it is necessarily required,,"rajendraarora16,asimshankar",2018-01-05 13:39:51,2018-01-05 18:49:27
PR,Add release note sparse tensors in tf data,,,mrry,2018-01-05 18:27:22,2018-01-05 18:55:50
PR,fix the comments which mistake x for y in gradient checker,Fix the comments which mistake x for y in gradient checker py,,"caisq,alextp",2018-01-05 10:12:34,2018-01-05 19:12:01
PR,Windows Disable bfloat16 test and framework dtypes test,Reenable after fixing,,"meteorcloudy,meteorcloudy,meteorcloudy,gunan",2018-01-04 11:01:19,2018-01-05 19:13:04
IS,Major performance hit when running two processes on same GPU,I have observed a major performance hit when running two identical models on the same GPU with allow growth set to True so that each process which only needs a small fraction of the GPU memory 1gb 11gb are used when allow growth is set to true When running a single model on a single process it consistently finished going through the data I have available in approximately 170 174 seconds and never exceeds 50 Volatile GPU Utilization according to nvidia smi However when running with two separate concurrent processes each identical to the first they both finish in approximately 320 340 seconds which is unexpected since GPU utilization was not even half in the first scenario and running two concurrently effectively slows them down to running them sequentially despite the seemingly available processing power and memory Is this intentional or is there a better way to do this Currently launching two workers via Celery each of which create their own TF session and load the model into it separately and run the data through it I would love to make maximal use of available hardware and this seems like a very counter intuitive outcome I can observe each process allocate roughly 1GiB GPU memory and each adds approximately 45 50 GPU utilization For testing purposes data and model used in both parallel runs is completely identical Any thoughts Am I misusing TF System information Using Keras to load model Ubuntu 16 04 CUDA CUDNN 8 0 5 1 TF version 1 0 1 GTX 1080 ti not being used to render screen second 1080 ti is doing that Running in nvidia docker with a single GPU available to worker process the one not rendering the screen Running two separate sessions initiated via Celery which both create their own session set allow growth True each load the model into memory separately and each run with data separately,,"ppwwyyxx,yzhwang,yzhwang",2017-06-23 22:35:57,2018-01-05 19:22:25
PR,Adding installation dependencies for python3 6 based on failures from,the release job,,"av8ramit,av8ramit,drpngx",2017-12-23 00:39:58,2018-01-05 20:39:06
PR,Deletes unnecessary lines of code,The rest of this function changed sufficiently that these lines of code are not doing anything and can cause bugs Fixes issue 15852,,"alextp,alextp",2018-01-05 18:41:14,2018-01-05 20:51:47
IS,gather nd bounds checking not working,When using gather nd sometimes out of bounds indices lead to errors bounds checking the expected behavior and sometimes it seems to just read zeros I expect it reading just other memory from the GPU but I have never observed anything other than zeros so I'm not sure When I run on the CPU the bounds seem to be appropriately checked i e I get the errors desired Here is some example code Version info Linux Mint 4 4 0 53 generic x86 64 Python version 3 5 2 CUDA version release 8 0 V8 0 61 cuDNN version 6 0 21 Tensorflow version v1 3 0 rc2 20 g0787eee 1 3 0 nvidia drivers version 375,,"ppwwyyxx,langmore,facaiy,yongtang",2017-08-26 00:19:52,2018-01-05 20:53:31
IS,scatter nd does not check indices for out of bounds on GPU when using float32,I noticed that the scatter nd command behaves inconsistently with respect to checking the given indices In most cases the command raises an error when trying to set an index that is out of bound for the given shape However on the GPU when updates is of dtype tf float32 this check is not performed and invalid indices are just ignored In the case of tf int32 or always when on the CPU and exception is raised See below for detailed information and a minimal example that has been adapted from the scatter nd documentation Additionally I noticed that the scatter nd documentation does not state whether a bound check is performed or not That might be worth adding System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary installed from binary via pip GPU version TensorFlow version use command below v1 3 0 rc2 20 g0787eee 1 3 0 Python version 3 5 2 CUDA cuDNN version cuda8 0 cuDNN6 via docker container nvidia cuda 8 0 cudnn6 devel GPU model and memory GeForce GTX 1080 8112 MB Exact command to reproduce,,"reedwm,ebrevdo,ebrevdo,yongtang",2017-10-13 12:12:27,2018-01-05 20:53:31
PR,Update documentation for gather nd gather to specify behaviors for out of bound indices,This fix updates documentation for gather nd gather scatter nd to specify behaviors for out of bound indices Basically on CPU an error will be returned and on GPU 0 value will be filled to the expected positions of the output This fix closes 13687 This fix closes 12608 Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang,ebrevdo",2018-01-04 20:02:37,2018-01-05 20:53:32
IS,MonitoredTrainingSession aborts without error or exeption,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 3 TensorFlow installed from source or binary binary pip install TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version Python 3 6 3 Anaconda Inc Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version cuda 8 0 61 2 libcudnn so 6 0 21 GPU model and memory Titan X 32GB Exact command to reproduce During some training runs this script just ends after few epochs with printing 'eval done' It does not print any error nor an exception In other runs with the same setup in runs through How could this happen that the for loop stops even the epochs is smaller than 100 Edit I tried it also without the try except block around the MonitoredTrainingSession but it was the same no exception no error epoch 15 and printing eval done tf env txt,,,2018-01-04 11:29:10,2018-01-05 21:07:25
IS,cuda cuda config h missing when compiling custom ops with nvcc,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes see below OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below v1 3 0 0 g9e76bf324 1 3 0 Python version 3 5 2 Bazel version if compiling from source 0 5 4 CUDA cuDNN version 8 0 44 5 1 5 GPU model and memory Any Exact command to reproduce See below Describe the problem When compiling a custom op using nvcc which includes tensorflow core util cuda kernel helper h I get the following error Copying cuda config h to site packages tensorflow include tensorflow stream executor cuda solves the problem The same issue has been observed by several other users in 6602 see the comments added after the issue was closed,,"aselle,allenlavoie,gunan",2017-09-07 00:12:05,2018-01-05 22:02:39
IS,TfLiteCameraDemo only contains 32 bit libtensorflowlite jni so,I strictly followed the steps on to build the TfLiteCameraDemo But I found only 32 bit libtensorflowlite jni so was contained in the final APK I modified the source code of libneuralnetworks so to test my employer is NN accelerator which needed the 64 bit libtensorflowlite jni so even I configed bazel with configure config android arm64 and built with bazel build cxxopt std c 11 cpu arm64 v8a tensorflow contrib lite java demo app src main TfLiteCameraDemo could not work Where was my mistake Or how can I pack the 64 bit libtensorflowlite jni so into the final APK,,"aselle,angersson,angersson,angersson",2017-12-22 09:47:47,2018-01-05 22:59:43
PR,Use https for www tensorflow org,This fix uses for www tensorflow org for the purpose of increased security and consistency with the rest of the documentations Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-05 23:04:04,2018-01-05 23:18:38
IS,Wrong syntax in bibtex DOCS,System information Irrelevant Describe the problem The bibtex entry for citing the Tensorflow white paper in bibtex format has incorrect syntax ' i should be ' i in the first author name Source code logs See also,,,2017-10-14 07:24:01,2018-01-06 02:27:20
PR,Branch 180993147,,,"raghuraman-k,raghuraman-k,raghuraman-k,caisq",2018-01-06 01:20:08,2018-01-06 03:46:31
IS,Maven Packaging for GPU backed Java Bindings,System information N A Describe the problem Currently the only libtensorflow jni artifact which is deployed to Maven Central is compiled with CPU only support This means that at least as far as my current understanding goes any machine which I would like to deploy to and run GPU backed code on has to build TensorFlow from source with GPU support As one can imagine this makes the logistics of such deployments much more difficult and time consuming It would be wonderful if the libtensorflow jni artifact either contained a GPU compiled TensorFlow libraries and could use them automatically when possible or if there was a separate artifact perhaps with a gpu artifact classifier that contained those libraries The former streamlines build processes at the cost of bloating the artifact a bit while the latter at least provides an easy means of enabling GPU support for users which desire it I'm guessing that something like this is somewhere on the timeline I know that the Java bindings are under active development but I have been unable to find any documentation on the topic Thank you Source code logs N A,,"drpngx,asimshankar,drpngx,asimshankar",2017-09-08 13:38:12,2018-01-06 03:47:34
IS,W c l tensorflow 1501918863922 work tensorflow 1 2 1 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX instructions but these are available on your machine and could speed up CPU computations 2018 01 06 09 50 33 745519 W c l tensorflow 1501918863922 work tensorflow 1 2 1 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use AVX2 instructions but these are available on your machine and could speed up CPU computations 2018 01 06 09 50 33 745553 W c l tensorflow 1501918863922 work tensorflow 1 2 1 tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use FMA instructions but these are available on your machine and could speed up CPU computations,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,asimshankar,2018-01-06 02:12:58,2018-01-06 05:39:30
IS,Eager bugs,After I use eager to debug code the default version of tf changed when I reusing ipython and tf can not placement mode to GPU but placed on CPU OS Platform and Distribution CentOS Linux 7 Core 4 4 77 1 el7 elrepo x86 64 TensorFlow installed from Instlled from Docker Hub TensorFlow version 1 4 0 Bazel version N A CUDA cuDNN version 8 0 GPU model and memory Titan XP Exact command to reproduce N A,,"asimshankar,asimshankar,asimshankar",2017-12-08 11:36:36,2018-01-06 05:50:36
IS,Eager error when restore tfe Network checkpoint by tfe restore network checkpoint,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 6 0dev20170105 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 0 7 0 GPU model and memory pascal Exact command to reproduce N A Describe the problem When I want to restore tfe Network by using tfe restore network checkpoint from a graph mode checkpoint such as pretrained slim resnet ckpt so need name map of tfe restore network checkpoint I get an error,,,2018-01-06 15:19:47,2018-01-06 15:31:16
IS,missing instruction for BahdanauAttention,This is just my opinion when call BahdanauAttention instance it create a variable scope with None name or scope variable While name or scope is None and get variable with the same name inside the variable scope repeatedly it will automatically add ' N' to the name of the scope And I think it is not compatible with some functions like stati rnn because there are explicit 'for loop' inside the function and every loop of 'for loop' will create different variables inside the variable scope but not creating once and sharing,,"angersson,angersson,lukaszkaiser",2017-12-08 02:55:28,2018-01-06 17:02:02
IS,Building Tensorflow 1 4 1 from source successful on MacOS but pip install to Python 2 7 14 of wheel file fails with not supported wheel on this platform,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOX Yosemite 10 10 5 TensorFlow installed from source or binary source binary loads fine no problem TensorFlow version use command below Tensorflow 1 4 1 Python version Python 2 7 14 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source Xcode7 2 1 CUDA cuDNN version N a GPU model and memory N a Exact command to reproduce See my notes for TensorFlow 1 4 1 install from source below Note Bazel build completed successfully only issue is the failure to pip install the wheel file Describe the problem see the tl dr at bottom of notes Ca not load generated wheel file of Tensorflow 1 4 1 into Python 2 7 14 despite having built everything local Tried with several Python versions MacOS orginal version Python 2 7 14 from binary upgrade and using a Python 2 7 14 that I built an installed locally Note Tensorflow 1 4 0 binary can be loaded and runs ok but operates differently than TensorFlow 1 4 0 that I have running on CentOS 7 4 box hence my interest in building from source and tracking down why this is the case Source code logs Bazel Build was ok built for CPU only 4044 actions successful completion Also the build pip package works fine Only issue is the failure to pip install the wheel file Here are notes of exactly what I did TensorFlow Build Notes using Bazel MCL Jan 5 2018 Done on Macbook Yosemite 10 10 5 using Xcode 7 2 1 You need to get Xcode7 2 1 from Apple and install it For TensorFlow build using Bazel you need to install JDK8 Java Development Kit 8 not 9 Bazel built from source see home Bazel Xcode7 2 1 which offers clang 700 xxx version First tried with Xcode6 3 x needed to put DOSbox on iPad as DOSpad Had to update Xcode After Xcode7 2 1 install copy dmg to Applications Xcode7 2 1 Note the directory had to be manually created first Run it all as root on the Macbook cd home TensorFlow tensorflow 1 4 1 Needed to do a make clean in Bazel Do this bazel clean expunge pitche le vache totemo eh Run this to build Note the configure is a Q A For initial build no special features were selected ie I selected n to all the build with this cool thing Y n configure Once configure is complete do this note it is all one line bazel build config opt incompatible load argument is label false tensorflow tools pip package build pip package The build runs for 66 minutes and reports Elapsed time 3985 215 s Critical Path 132 83 s Build completed successfully 4044 total actions This makes a build pip package sh file in the tensorflow tools pip package subdir You now need to make the whl the compressed package pip uses to install to python from this thing the Bazel build made You run the script bazel bin to do this On the Macbook and Linux you will need to enter bazel bin tensorflow for it to work Note pwd reports home TensorFlow tensorflow 1 4 1 Note The TensorFlow build instructions use top level directory tmp but I do not want it destroyed if it works tmp means temporary eh I created top level tftop Note bazel bin is a directory You are running the build pip package script that is down in there not the build pip package sh script in tensorflow tree bazel bin tensorflow tools pip package build pip package tftop tensorflow pkg I ran this to tftop which might be wrong since I got a bunch of warnings about dll lib h for Eigen for external for google and some other all not being found Tried to run it again using tmp and I got message bazel bin tensorflow tools pip package build pip package No such file or directory The build pip package destroys the build generated files this is no problem it turns out Just re run the bazel build as bazel remembers all the compiles and the build pip package thing completes in a few seconds The file that is created in tftop tensorflow pkg is tensorflow 1 4 1 cp27 cp27m macosx 10 4 x86 64 whl This TensorFlow install instructions say to use this sudo pip install tftop tensorflow pkg tensorflow 1 4 1 py2 none any whl But it of course does not work as there is no such file And when I try as root pip install tftop tensorflow pkg tensorflow 1 4 1 cp27 cp27m macosx 10 4 x86 64 whl I get the showstopper message tensorflow 1 4 1 cp27 cp27m macosx 10 4 x86 64 whl is not a supported wheel on this platform and for now I am completely stopped What I did Re ran Bazel it remembers everything was compiled Ran in a few seconds Ran bazel bin tensorflow tools pip package build pip package tmp tensorflow pkg exactly as indicated in the TensorFlow documentation here common installation problems Got exactly the same warning messages about a bunch of missing files Tried pip install tmp tensorflow pkg tensorflow 1 4 0 py2 none any whl of course did not work No such filename You have to use the wheel file that the build process generates which is in the tmp tensorflow pkg directory pip install tmp tensorflow pkg tensorflow 1 4 1 cp27 cp27m macosx 10 4 x86 64 whl this pip install is to a local built Python 2 7 14 which currently has the Tensorflow 1 4 0 binary successfully installed which successfully operates Error message same tensorflow 1 4 1 cp27 cp27m macosx 10 4 x86 64 whl is not a supported wheel on this platform Tried with different versions of Python tweaked the PATH in bash profile to get my custom built one and the framework system verison Same problem for both Result TensorFlow Build successful pip install to Python 2 7 14 on MacOSX fails with version mis match or a bug maybe Post Mortem Questions I was expecting the documentation to match this install process I probably need the py2 none any whl type of wheel to be generated right What I am getting is some very MacOSX version specific thing being built which is failing the pip install because of a version mismatch maybe TL DR How can I force the build process to build the py2 none any whl type of wheel which does not have fascist style version checking D and just builds the whl file as per what the TensorFlow build instructions describe or Is there some tweak I can make to the build process which all seems to be working quite fine to tell the process to really actually please code the built version of TensorFlow 1 4 1 to the actual machine the Yosemite 10 10 5 Macbook that I have run the build upon Mark Langdon Jan 5 2018,,,2018-01-05 19:30:12,2018-01-06 18:38:05
IS,Object detection works on Linux but not Mac,System information OS Platform and Distribution Linux 16 04 and Mac OS 10 12 6 TensorFlow installed from source or binary Mac Binary Linux Source TensorFlow version use command below Mac 'v1 3 0 rc2 20 g0787eee' '1 3 0' Linux 'v1 3 0 rc1 4003 g1f582aa' '1 4 0 rc0' Python version Mac 2 7 14 Linux 2 7 12 Bazel version if compiling from source Linux 0 7 0 GCC Compiler version if compiling from source Linux GCC 5 4 0 CUDA cuDNN version Linux CUDA 9 cuDNN 7 GPU model and memory Linux TitanXp Describe the problem I trained a model using the tensor flow object detection api with faster rcnn resnet101 I then exported the model using the provided export inference graph py The model works on Linux but does not work on Mac Both platforms are using tensor flow 1 3 0 I have provided the crash log Source code logs 2017 11 25 20 39 12 847344 E tensorflow core common runtime executor cc 644 Executor failed to create kernel Invalid argument NodeDef mentions attr 'T' not in Op name Where signature input bool index int64 NodeDef ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary Node ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater Traceback most recent call last File Documents detect py line 13 in module model detect image File Documents object detector py line 71 in detect feed dict self image tensor image np expanded File usr local lib python2 7 site packages tensorflow python client session py line 895 in run run metadata ptr File usr local lib python2 7 site packages tensorflow python client session py line 1124 in run feed dict tensor options run metadata File usr local lib python2 7 site packages tensorflow python client session py line 1321 in do run options run metadata File usr local lib python2 7 site packages tensorflow python client session py line 1340 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError NodeDef mentions attr 'T' not in Op name Where signature input bool index int64 NodeDef ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary Node ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater Caused by op u'ClipToWindow Where' defined at File Documents detect py line 7 in module limbs det object detector Documents graph pbtxt Documents graph pb 2 File Documents object detector py line 49 in init tf import graph def od graph def name '' File usr local lib python2 7 site packages tensorflow python framework importer py line 313 in import graph def op def op def File usr local lib python2 7 site packages tensorflow python framework ops py line 2630 in create op original op self default original op op def op def File usr local lib python2 7 site packages tensorflow python framework ops py line 1204 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback NodeDef mentions attr 'T' not in Op name Where signature input bool index int64 NodeDef ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater Check whether your GraphDef interpreting binary is up to date with your GraphDef generating binary Node ClipToWindow Where Where T DT BOOL device job localhost replica 0 task 0 cpu 0 ClipToWindow Greater,,"aselle,ebrevdo,josh11b",2017-11-26 01:47:11,2018-01-06 19:53:23
IS,tensorflow logging glog redefined warning,I just integrated a tensorflow module to my existing c project I was already using glog for logging in my existing project logging to files Now when I build the new project it throws warnings like usr local include google tensorflow tensorflow core platform default logging h 254 0 warning CHECK GT redefined define CHECK GT val1 val2 CHECK OP Check GT val1 val2 usr local include glog logging h 793 0 note this is the location of the previous definition define CHECK GT val1 val2 CHECK OP GT val1 val2 Is this behavior safe I am not concerned that much with the logs that tensorflow generates I need my existing modules to continue logging to files If this behavior is unsafe this could be a good feature request to have glog logging not affected by tensorflow logging,,,2017-12-22 11:19:13,2018-01-06 20:11:15
IS,How to know my loss function does not have numerical problems,I wrote the following loss function that I post below How do I know that I do not have any kind of numerical issues with it because something tells me that I do,,,2018-01-06 16:36:28,2018-01-07 01:05:33
PR,Assert3DImage that adds a control dependency for the shape check,I noticed that the Check3DImage was always used in exactly the same way and extracted this into its own convenience function The only remaining use of Check3DImage was an import in gen image ops py saying TODO drpng remove these once internal use has discontinued so maybe it could be removed entirely,,drpngx,2017-12-21 19:14:42,2018-01-07 12:33:12
IS,Documentation does not explain the utility of 1 as value for the axis parameter of the tf concat method,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X version 10 13 2 TensorFlow installed from source or binary Binary pip TensorFlow version use command below v1 3 0 rc1 5211 gab0fcac 1 5 0 dev20171126 Python version Python 3 5 0 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Just run a Python script with the code I am sharing with you Describe the problem It apparently concatenates along the last axis See the following example The following documention does not seem to explain this use case,,"yongtang,yongtang",2018-01-06 03:41:22,2018-01-07 14:57:16
PR,Update docs for concat in case axis 0,This fix tries to address the issue raised in 15905 where the documentation does not cover the case of axis 0 for tf concat This fix fixes 15905 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,yongtang,caisq",2018-01-06 19:37:24,2018-01-07 14:57:16
IS,Tensorflow Optimize for Inference KeyError,I got the following error when optimizing the graph for inference Traceback most recent call last File C Python35 lib runpy py line 193 in run module as main main mod spec File C Python35 lib runpy py line 85 in run code exec code run globals File C Python35 lib site packages tensorflow python tools optimize for inference py line 146 in module app run main main argv sys argv 0 unparsed File C Python35 lib site packages tensorflow python platform app py l ine 48 in run sys exit main sys argv 1 flags passthrough File C Python35 lib site packages tensorflow python tools optimize for inference py line 90 in main FLAGS output names split FLAGS placeholder type enum File C Python35 lib site packages tensorflow python tools optimize for inference lib py line 109 in optimize for inference placeholder type enum File C Python35 lib site packages tensorflow python tools strip unused lib py line 83 in strip unused raise KeyError The following input nodes were not found s n not f ound KeyError The following input nodes were not found 'input' n Please help me soon,,,2018-01-07 10:02:14,2018-01-08 05:09:43
IS,occurs error to convert from pb to tflite file format,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 4 0 Python version 3 4 Bazel version if compiling from source 0 5 4 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build c opt copt msse4 1 copt msse4 2 tensorflow contrib lite toco toco bazel bin tensorflow contrib lite toco toco input format TENSORFLOW GRAPHDEF output format TFLITE input file home yh tttt aaa pb output file home yh tttt aaa lite inference type FLOAT input type FLOAT input arrays input output arrays MobilenetV1 Predictions ArgMax 2 input shapes 1 64 64 3 Describe the problem current tensorflow lite could not support below operation If we use below operation how can I do something Here is the warning and error message I got Source code logs 2018 01 04 16 04 35 910769 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 910856 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 910902 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 910928 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 910971 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911011 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911035 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911066 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911089 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911129 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911165 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911188 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911226 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911260 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911283 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911320 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911355 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911377 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911415 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911450 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911473 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911513 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911547 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911571 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911601 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911624 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911654 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911677 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911707 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911730 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911759 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911781 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911811 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911834 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911873 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 911907 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 911931 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 911968 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 912003 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912026 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912063 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 912097 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912120 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912158 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 912192 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912215 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912252 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 912286 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912308 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912337 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912360 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912390 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912412 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912442 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912464 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912496 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912520 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912550 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912572 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912602 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912625 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912655 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912678 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912708 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912730 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912760 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912782 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912812 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912837 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912867 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912890 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912919 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912943 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 912973 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 912996 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913026 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913050 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913080 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913102 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913132 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913154 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913184 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913218 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913258 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913282 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913312 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913335 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913365 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913388 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913418 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913441 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913471 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913494 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913525 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913547 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913577 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913600 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913630 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913653 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913682 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913705 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913734 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913757 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913786 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913808 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913838 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913861 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913891 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913913 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913942 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 913965 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 913994 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914016 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914046 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914068 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914097 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914120 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914183 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914209 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914238 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914260 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914289 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914310 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914339 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914360 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914387 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914408 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914457 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Pow 2018 01 04 16 04 35 914500 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914523 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914557 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914580 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914695 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914721 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914754 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914778 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914812 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914835 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914864 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914885 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 914966 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 914993 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915026 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915049 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915078 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915099 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915127 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915149 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915219 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915245 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915274 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915297 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915326 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915347 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915376 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915397 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915472 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915498 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915528 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915549 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915578 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915599 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915627 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915649 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915718 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915745 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915774 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915795 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915823 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915845 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915873 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915895 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 915971 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 915998 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916027 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916049 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916077 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916098 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916126 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916147 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916217 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916243 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916271 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916292 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916320 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916342 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916370 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916391 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916468 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916495 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916524 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916545 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916573 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916594 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916622 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916644 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916713 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916739 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916768 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916790 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916817 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916839 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916866 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916888 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 916964 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 916991 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917019 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917041 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917068 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917089 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917117 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917138 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917208 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917234 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917263 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917288 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917317 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917338 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917366 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917387 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917463 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RandomUniform 2018 01 04 16 04 35 917497 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917519 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917547 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 917568 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917702 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation SoftmaxCrossEntropyWithLogits 2018 01 04 16 04 35 917801 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation SaveV2 2018 01 04 16 04 35 917850 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 917873 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917901 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 917922 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917949 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 917971 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 917998 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918019 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918046 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918067 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918094 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918115 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918152 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918175 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918216 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918239 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918269 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918286 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918308 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918325 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918346 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918362 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918384 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918399 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918421 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918438 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918459 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918477 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918514 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918535 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918562 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918583 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918610 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918630 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918657 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918678 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918705 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918725 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918752 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918774 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918801 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918821 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918848 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918867 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918895 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918916 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918943 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 918963 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 918990 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919010 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919037 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919057 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919084 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919104 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919131 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919151 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919178 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919199 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919226 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919246 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919273 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919294 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919321 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919341 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919368 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919388 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919415 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919435 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919461 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919480 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919506 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919527 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919553 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919574 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919600 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919620 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919647 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919669 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919696 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919717 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919743 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919763 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919789 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919809 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919835 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919855 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919882 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919901 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919928 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919948 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 919974 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 919996 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920022 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920042 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920068 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920088 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920114 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920135 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920161 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920181 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920208 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920228 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920256 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920278 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920305 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920326 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920353 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920373 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920400 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920420 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920447 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920468 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920494 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920516 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920542 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920563 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920589 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920610 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920636 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920656 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920682 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920702 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920729 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920749 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920775 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920796 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920823 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920843 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920870 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920891 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920918 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920938 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 920964 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 920984 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921011 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921031 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921057 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921077 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921104 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921125 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921152 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921172 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921199 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921219 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921246 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921268 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921294 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921314 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921341 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921362 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921389 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921410 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921437 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921459 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921486 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921507 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921533 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921553 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921580 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921599 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921626 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921647 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921674 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921694 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921720 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921740 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921767 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921787 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921814 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921834 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921862 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921882 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921908 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921929 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 921956 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 921976 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922002 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922022 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922049 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922068 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922095 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922115 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922154 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922187 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922210 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922226 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922247 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922264 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922285 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922301 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922322 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922339 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922361 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922377 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922398 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922430 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922458 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922478 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922505 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922526 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922553 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922573 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922600 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922621 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922648 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922668 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922695 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922715 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922742 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922763 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922790 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation RestoreV2 2018 01 04 16 04 35 922811 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922854 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation VariableV2 2018 01 04 16 04 35 922878 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Assign 2018 01 04 16 04 35 922918 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Equal 2018 01 04 16 04 35 922964 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation ScalarSummary 2018 01 04 16 04 35 922987 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation ScalarSummary 2018 01 04 16 04 35 923009 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation ScalarSummary 2018 01 04 16 04 35 923028 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation MergeSummary 2018 01 04 16 04 35 923082 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Prod 2018 01 04 16 04 35 923107 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation Prod 2018 01 04 16 04 35 923150 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation ZerosLike 2018 01 04 16 04 35 923209 I tensorflow contrib lite toco import tensorflow cc 1122 Converting unsupported operation BiasAddGrad 2018 01 04 16 04 35 923248 F tensorflow contrib lite toco import tensorflow cc 924 Check failed GetBoolAttr node transpose b false 1 vs 0 Aborted core dumped,,,2018-01-04 06:43:47,2018-01-08 07:41:15
IS,tensorflow contrib lite toco dump graphviz cc In function 'void toco DumpGraphviz const toco Model std cxx11 string ' tensorflow contrib lite toco dump graphviz cc 329 35 warning comparison between signed and unsigned integer expressions Wsign compare for int op index 0 op index ops to dump size op index Target tensorflow contrib lite toco toco failed to build,tensorflow contrib lite toco dump graphviz cc In function 'void toco DumpGraphviz const toco Model std cxx11 string ' tensorflow contrib lite toco dump graphviz cc 329 35 warning comparison between signed and unsigned integer expressions Wsign compare for int op index 0 op index ops to dump size op index Target tensorflow contrib lite toco toco failed to build,,,2018-01-08 08:05:20,2018-01-08 08:14:40
IS,bazel ubuntu 16 04 bazel build tensorflow python tools optimize for inference,tensorflow core platform macros h 78 30 note in definition of macro 'TF PREDICT FALSE' define TF PREDICT FALSE x x tensorflow core util tensor format h 340 3 note in expansion of macro 'CHECK' CHECK index 0 index dimension attributes size tensorflow core util tensor format h In instantiation of 'T tensorflow GetFilterDim tensorflow gtl ArraySlice T tensorflow FilterTensorFormat char with T long long int ' tensorflow core util tensor format h 381 54 required from here tensorflow core util tensor format h 355 29 warning comparison between signed and unsigned integer expressions Wsign compare CHECK index 0 index dimension attribute size tensorflow core platform macros h 78 30 note in definition of macro 'TF PREDICT FALSE' define TF PREDICT FALSE x x tensorflow core util tensor format h 355 3 note in expansion of macro 'CHECK' CHECK index 0 index dimension attribute size ERROR home zyx Desktop code tensorflow master tensorflow contrib lite toco BUILD 169 1 C compilation of rule ' tensorflow contrib lite toco graph transformations' failed Exit 1 In file included from external gemmlowp public internal dispatch gemm shape h 20 0 from external gemmlowp public gemmlowp h 19 from tensorflow contrib lite kernels internal common h 48 from tensorflow contrib lite toco runtime types h 18 from tensorflow contrib lite toco model h 25 from tensorflow contrib lite toco graph transformations graph transformations h 23 from tensorflow contrib lite toco graph transformations resolve tensorflow matmul cc 20 external gemmlowp public internal internal kernel default h 88 2 error error SIMD not enabled you would be getting a slow software fallback Consider enabling SIMD extensions for example usin g msse4 if you are on modern x86 If that is not an option and you would like to continue with the slow fallback define GEMMLOWP ALLOW SLOW SCALAR FALLBACK error Target tensorflow python tools optimize for inference failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 637 451s Critical Path 54 99s FAILED Build did NOT complete successfully,,,2018-01-08 07:50:21,2018-01-08 08:15:00
IS,MultiRNNCell and reuse variables,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 2 7 6 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version 8 0 6 0 GPU model and memory Geforce GTX TITAN X 12G Describe the problem tf nn dynamic rnn and tf nn rnn cell MultiRNNCell breaks down when add tf get variable scope reuse variables before defining a rnn architecture Correct Situation When there is no tf get variable scope reuse variables Conclusion It seems that tf get variable scope reuse variables and tf nn rnn cell MultiRNNCell are not compatiable,,,2018-01-02 15:12:14,2018-01-08 15:42:05
IS,I think some bug in tf contrib layers l2 regularizer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 win10 TensorFlow installed from source or binary install TensorFlow version use command below 1 5 Python version 3 5 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem when I call the tf contrib layers l2 regularizer 0 5 w I was toll that Expected int64 got 0 5 of type 'float' instead But the doc says that it need a float clearly and as a weight it can not be an integer Source code logs l2 0 for w in tf global variables l2 tf contrib layers l2 regularizer 0 5 w loss tf losses softmax cross entropy onehot labels one hot labels logits result vector l2,,ppwwyyxx,2018-01-04 05:41:11,2018-01-08 15:45:58
IS,How to see the implementation of softmax cross entropy,In tf nn ops file it imports the file tensorflow python ops import gen nn ops but I can not find the file gen nn ops in the directory,,,2018-01-06 08:00:56,2018-01-08 15:52:15
IS,An easy problem about tensorflow tf reduce mean op,I know there might not be a suitable palce to ask this question but I really hope someone cloud help me i want to use the tf reduce mean to obtain the mean of an array ignore the zeros element eg data 1 2 3 4 5 6 0 0 0 i want to obtain mean 2 5 3 5 4 5 but tf reduce mean op gets the mean 1 6 2 3 3 Thank you very much,,skye,2018-01-08 08:33:27,2018-01-08 15:55:30
PR,Update 1 notmnist ipynb,,,,2018-01-08 15:57:09,2018-01-08 16:01:57
PR,extract populate weight collection,,,"ispirmustafa,ispirmustafa",2018-01-04 22:34:06,2018-01-08 17:20:41
IS,With tf nightly gpu getting error ImportError lib x86 64 linux gnu libm so 6 version GLIBC 2 23' not found,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Binary TensorFlow version use command below tf nightly gpu I can not import TensorFlow to check the version Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version Cuda 9 0 cuDNN 7 0 4 GPU model and memory GTX 1080 8GB Exact command to reproduce This occurs if I pip install tf nightly gpu 1 5 0 dev20171212 which is the earliest version of tf nightly gpu it occurs on When I pip install the previous version with pip install tf nightly gpu 1 5 0 dev20171207 the issue does not occur This issue is similar to 53 and 3127 CC any ideas what the issue could be,,"reedwm,gunan,yongtang,jhseu,gunan,reedwm",2017-12-15 00:43:20,2018-01-08 18:06:53
IS,LSTM in eager is 15 slower than in tensorflow on CPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 3 0 rc1 6744 gf99275a 1 6 0 dev20180105 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version none GPU model and memory none Exact command to reproduce,,,2018-01-08 17:05:42,2018-01-08 18:52:53
PR,Fix tensorflow CurrentStackTrace when TF GENERATE BACKTRACE is not defined,Fix culprit,,"meteorcloudy,rongjiecomputer,meteorcloudy",2018-01-08 13:22:42,2018-01-08 19:14:15
IS,error in tensorflow setup command error when running building the TensorFlow pip package,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary Source TensorFlow version use command below TensorFlow commit 70ba44b46bb9e5f5e55b2357676ffa7196b9bda7 Python version 2 7 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version CUDA 8 0 cuDNN 6 0 GPU model and memory GTX 1080 8 GB Exact command to reproduce This does not occur on the commit before 70ba44b46bb9e5f5e55b2357676ffa7196b9bda7 When running configure I choose the default option for everything except that I choose to use CUDA Note I use config monolithic to get around 13243 CC any ideas what the issue could be,,"reedwm,gunan,gunan,gunan,alanhdu,gunan,yifeif",2017-11-22 03:47:05,2018-01-08 19:15:29
IS,High Performance Models documentation page unclear on StagingArea not being a FIFOQueue,I feel that it would be good to modify the High Performance Models page to make it clear that the StagingArea class does not guarantee ordered delivery This would mean changing the line StagingArea is a queue like operator similar to tf FIFOQueue The difference is that StagingArea offers simpler functionality and can be executed on both CPU and GPU in parallel with other stages to something like this StagingArea is a queue like operator similar to tf FIFOQueue The difference is that StagingArea does not guarantee FIFO ordering but offers simpler functionality and can be executed on both CPU and GPU in parallel with other stages I just spent longer than I would care to admit bug hunting when FIFO ordering was critical,,"yaroslavvb,yaroslavvb,yifeif",2017-09-05 02:16:13,2018-01-08 19:17:08
PR,MKL Dockerfile Locked to Broadwell AVX2 arch to work around Eigen Issues with AVX512,Eigen currently has issues when Tensorflow is compiled with march skylake or the container is build on a skylake system with march native The container is now compiled with march broadwell which adds AVX2 instructions which are supported on Skylake Haswell Broadwell KNL and KNM architectures,,"claynerobison,gunan,claynerobison,gunan,rmlarsen,yifeif,claynerobison",2017-12-04 21:52:45,2018-01-08 19:20:49
IS,Discontinuity at halfway point in graph output,I have written custom code as opposed to using a stock example script provided in TensorFlow to reproduce the error 1 convert HnH gate txt to HnH gate py 2 Edit mypath in out method at end of file for your system Save 3 in python run HnH gate py 4 run out to create csv files for the good and bad output i out 101 new probka good ii out 102 new probka bad 5 Plot data from hh 101 csv and hh 102 csv and verify the discontinuity at half way point in hh 102 csv 6 Two additional tests can be run i Edit parameter timepoints in main to show error remaps to half way point ii My temporary correction is to create 2x points and throw half away this is done in p update setting cut in half True 7 This same error was found running the code in Tensorflow 1 4 on MacOS Sierra My system info is cat etc issue Linux PAULP XPS15 4 4 0 43 Microsoft 1 Microsoft Wed Dec 31 14 42 53 PST 2014 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux PAULP XPS15 4 4 0 43 Microsoft 1 Microsoft Wed Dec 31 14 42 53 PST 2014 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 3 numpydoc 0 7 0 protobuf 3 4 1 tensorflow 1 3 0 tensorflow tensorboard 0 1 5 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION b'unknown' tf COMPILER VERSION b'unknown' Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found cuda libs Describe the problem I am running a RNN for a Hodgkin and Huxley type gating of an ion channel protein called HnH gate py The program takes a placeholder vmem and produces a timeseries output of the size timepoints At the halfway point in the timeseries there is a discontinuity in the results This only appears with some arrays fed to my tf placeholder Others produce normal results I can correct for the problem by doubling the number of timepoints requested and throwing half away The array vmem list good 100 0 90 0 80 0 70 0 60 0 50 0 41 0 30 0 20 0 10 0 0 0 10 0 20 0 30 0 40 0 50 0 100 0 90 0 80 0 70 0 60 0 50 0 41 0 30 0 20 0 10 0 0 0 10 0 20 0 30 0 40 0 50 0 appears to work perfectly The array vmem list bad 80 0 60 0 40 0 20 0 00 0 20 0 41 0 60 0 80 0 55 0 0 0 10 0 20 0 30 0 40 0 50 0 70 0 50 0 30 0 10 0 10 0 30 0 50 0 70 0 90 0 30 0 10 0 0 0 10 0 20 0 30 0 40 0 shows the error To see my temporary correction edit the parameter in the HH p update method to cut in half True I have written a short output routine to export the simulation to a csv file just edit the path and provide a string to make a unique filename out 101 new probka good out 102 new probka bad Source code logs program file is HnH gate py provided as HnH gate txt HnH gate txt convert to HnH gate py HnH gate txt System and Error Description HnH gate bug report txt HnH gate bug report txt Output example demonstrating problem Artifact plotting new probka bad py Artifact plotting new probka bad pdf Thanks for your help Paul,,,2018-01-07 18:17:27,2018-01-08 23:12:15
IS,Installation says to use cuDNN v6 1 but NVIDIA only offers 6 0 and 7 0 4,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem NVIDIA only offers the following from their website Download cuDNN v7 0 4 Nov 13 2017 for CUDA 9 0 Download cuDNN v7 0 4 Nov 13 2017 for CUDA 8 0 Download cuDNN v6 0 April 27 2017 for CUDA 8 0 Download cuDNN v6 0 April 27 2017 for CUDA 7 5 Download cuDNN v5 1 Jan 20 2017 for CUDA 8 0 Download cuDNN v5 1 Jan 20 2017 for CUDA 7 5 installation instructions say to use cuDNN v6 1 For details If you have a different version of one of the preceding packages please change to the specified versions In particular the cuDNN version must match exactly TensorFlow will not load if it cannot find cuDNN64 6 dll Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"tatatodd,tatatodd,mrry,tatatodd,tatatodd,tatatodd",2017-11-22 19:39:36,2018-01-08 23:12:59
PR,DO NOT MERGE YET Cuda config,,,av8ramit,2018-01-06 00:43:45,2018-01-08 23:39:24
PR,Branch 181174976,,,"frankchn,frankchn,frankchn,frankchn,frankchn",2018-01-08 18:28:33,2018-01-09 01:00:25
IS,Undefined Symbol gen parsing ops py wrappers cc when building pip package,System information greg salt code tensorflow more tf env txt cat etc issue Linux salt 4 13 0 21 generic 24 Ubuntu SMP Mon Dec 18 17 29 16 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 17 10 Artful Aardvark VERSION ID 17 10 VERSION CODENAME artful are we in docker No compiler configure set to gcc 6 c Ubuntu 7 2 0 8ubuntu3 7 2 0 Copyright C 2017 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux salt 4 13 0 21 generic 24 Ubuntu SMP Mon Dec 18 17 29 16 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 14 0 protobuf 3 5 1 s2clientprotocol 1 1 tensorflow gpu 1 4 0 tensorflow serving api 1 4 0 tensorflow tensorboard 0 4 0rc3 check for virtualenv False tensorflow import Traceback most recent call last File string line 1 in module File tensorflow init py line 24 in module from tensorflow python import File tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File tensorflow python pywrap tensorflow py line 25 in module from tensorflow python platform import self check ImportError No module named platform env LD LIBRARY PATH usr local cuda lib64 opt tensorlibs lib DYLD LIBRARY PATH usr local cuda lib64 opt tensorlibs lib nvidia smi Mon Jan 8 13 25 47 2018 NVIDIA SMI 387 26 Driver Version 387 26 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 GeForce GTX 1070 Off 00000000 01 00 0 On N A 24 34C P8 9W 151W 596MiB 8112MiB 3 Default Processes GPU Memory GPU PID Type Process name Usage 0 988 G usr lib xorg Xorg 373MiB 0 1384 G usr bin compiz 116MiB 0 8602 G token 09D12A9300046A211380F83BAD0A60C6 46MiB 0 15983 G token 29A09CA037A6A6610BD563090AA5B5DA 56MiB cuda libs usr local cuda 8 0 doc man man7 libcudart so 7 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 targets x86 64 linux lib libcudart static a usr local cuda 8 0 targets x86 64 linux lib libcudart so 8 0 61 usr local cuda 9 1 doc man man7 libcudart so 7 usr local cuda 9 1 doc man man7 libcudart 7 usr local cuda 9 1 targets x86 64 linux lib libcudart static a usr local cuda 9 1 targets x86 64 linux lib libcudart so 9 1 85 usr local cuda 9 0 doc man man7 libcudart so 7 usr local cuda 9 0 doc man man7 libcudart 7 usr local cuda 9 0 targets x86 64 linux lib libcudart static a usr local cuda 9 0 targets x86 64 linux lib libcudart so 9 0 103 Describe the problem Build command below fails w undefined symbol bazel build config opt config cuda tensorflow tools pip package build pip package verbose failures ERROR home greg code tensorflow tensorflow python BUILD 1398 1 Executing genrule tensorflow python parsing ops pygenrule failed Exit 127 bash failed error executing command cd home greg cache bazel bazel greg ca148a14f6c24000015970c3c0a435f7 execroot org tensorflow exec env CUDA TOOLKIT PATH usr local cuda CUDNN INSTALL PATH usr local cuda 9 1 GCC HOST COMPILER PATH usr bin gcc 6 LD LIBRARY PATH usr local cuda lib64 opt tensorlibs lib PATH opt ant bin usr local cuda bin usr local sbin usr local bin usr sbin usr bin sbin bin usr games usr local games snap bin usr lib jvm java 9 oracle bin usr lib jvm java 9 oracle db bin opt gephi bin opt eclipse opt gradle bin PYTHON BIN PATH usr bin python3 PYTHON LIB PATH usr lib python3 dist packages TF CUDA CLANG 0 TF CUDA COMPUTE CAPABILITIES 6 1 TF CUDA VERSION 9 1 TF CUDNN VERSION 7 TF NEED CUDA 1 TF NEED OPENCL SYCL 0 bin bash bazel out k8 py3 opt genfiles tensorflow python parsing ops pygenrule genrule script sh bazel out host bin tensorflow python gen parsing ops py wrappers cc symbol lookup error bazel out host bin tensorflow python gen parsing ops py wrappers cc undefined symbol ZN10tensorflow17ParseExampleAttrs10FinishInitEv Target tensorflow tools pip package build pip package failed to build INFO Elapsed time 63 574s Critical Path 19 07s FAILED Build did NOT complete successfully Source code logs greg salt code tensorflow dpkg l grep cuda ii cuda 9 1 85 1 amd64 CUDA meta package ii cuda 9 1 9 1 85 1 amd64 CUDA 9 1 meta package ii libcudnn7 7 0 5 15 1 cuda9 1 amd64 cuDNN runtime libraries ii libcudnn7 dev 7 0 5 15 1 cuda9 1 amd64 cuDNN development libraries and headers ii libcudnn7 doc 7 0 5 15 1 cuda9 1 amd64 cuDNN documents and samples,,,2018-01-08 21:28:54,2018-01-09 01:00:54
IS,Eager Incompatible rnn model shapes inferred when using more than one CudnnGRU LSTM,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0dev20171230 Python version 3 6 Describe the problem When I use more than one CudnnGRU in eager I got an error,,"skye,alextp,allenlavoie,allenlavoie,allenlavoie,allenlavoie,allenlavoie",2017-12-31 10:29:19,2018-01-09 01:01:22
PR,WIP LSTMBlockFusedCell supports Dropout,Fix 13649 The work has not been done yet However I'm not sure whether the solution is approved I mean using DropoutWrapper for inner implementation So I open the PR early to collect feedback cc I will add test case later,,"facaiy,ebrevdo,facaiy,ebrevdo,facaiy,facaiy",2018-01-04 11:08:15,2018-01-09 04:03:07
IS,NEON XLA CPU runtime is not compiling because of missing plog function in Eigen,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 3 0 0 g9e76bf324' '1 3 0' Python version 3 4 3 Bazel version if compiling from source 0 5 4 CUDA cuDNN version no GPU model and memory no Exact command to reproduce WORKSPACE correctly configure for Android NDK r12b and SDK latest bazel build c opt cxxopt ' std c 11' crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a tensorflow compiler xla service cpu cpu runtime neon Describe the problem I use Tensorflow compiled from source to use XLA aot binaries for Arm For XLA to work it needs to have runtime support for that architecture but with the above command it fails complaining for a missing function in Eigen I fixed the bug in Eigen and submitted a pull request for integration with the following patch the compilation completes successfully Once the pull request is accepted I will submit a pull request here to use the new Eigen version with the fix Source code logs For the record this is the error i get bazel build c opt cxxopt ' std c 11' crosstool top external android crosstool host crosstool top bazel tools tools cpp toolchain cpu armeabi v7a tensorflow compiler xla service cpu cpu runtime neon Extracting Bazel installation INFO Analysed target tensorflow compiler xla service cpu cpu runtime neon 17 packages loaded INFO Found 1 target ERROR home gmichel work tensorflow tensorflow compiler xla service cpu BUILD 333 1 C compilation of rule ' tensorflow compiler xla service cpu cpu runtime neon' failed Exit 1 In file included from external eigen archive Eigen Core 372 0 from third party eigen3 Eigen Core 1 from tensorflow compiler xla service cpu cpu runtime neon cc 20 external eigen archive Eigen src Core GenericPacketMath h In instantiation of 'Packet Eigen internal plog const Packet with Packet vector 4 builtin neon sf ' tensorflow compiler xla service cpu cpu runtime neon cc 32 33 required from here external eigen archive Eigen src Core GenericPacketMath h 411 60 error no matching function for call to 'log const vector 4 builtin neon sf ' Packet plog const Packet a using std log return log a external eigen archive Eigen src Core GenericPacketMath h 411 60 note candidates are In file included from external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 44 0 from external androidndk ndk sources cxx stl gnu libstdc 4 9 include complex 44 from external eigen archive Eigen Core 78 from third party eigen3 Eigen Core 1 from tensorflow compiler xla service cpu cpu runtime neon cc 20 external androidndk ndk platforms android 14 arch arm usr include math h 218 8 note double log double double log double NDK FPABI MATH external androidndk ndk platforms android 14 arch arm usr include math h 218 8 note no known conversion for argument 1 from 'const vector 4 builtin neon sf' to wouldouble' In file included from external androidndk ndk sources cxx stl gnu libstdc 4 9 include complex 44 0 from external eigen archive Eigen Core 78 from third party eigen3 Eigen Core 1 from tensorflow compiler xla service cpu cpu runtime neon cc 20 external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 357 3 note constexpr float std log float log float x external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 357 3 note no known conversion for argument 1 from 'const vector 4 builtin neon sf' to 'float' external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 361 3 note constexpr long double std log long double log long double x external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 361 3 note no known conversion for argument 1 from 'const vector 4 builtin neon sf' to 'long double' external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 369 5 note template class Tp constexpr typename gnu cxx enable if std is integer Tp value double type std log Tp log Tp x external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 369 5 note template argument deduction substitution failed external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath In substitution of 'template class Tp constexpr typename gnu cxx enable if std is integer Tp value double type std log Tp with Tp vector 4 builtin neon sf ' external eigen archive Eigen src Core GenericPacketMath h 411 60 required from 'Packet Eigen internal plog const Packet with Packet vector 4 builtin neon sf ' tensorflow compiler xla service cpu cpu runtime neon cc 32 33 required from here external androidndk ndk sources cxx stl gnu libstdc 4 9 include cmath 369 5 error no type named ' type' in istruct gnu cxx enable if false double ' In file included from external eigen archive Eigen Core 78 0 from third party eigen3 Eigen Core 1 from tensorflow compiler xla service cpu cpu runtime neon cc 20 external eigen archive Eigen src Core GenericPacketMath h In instantiation of 'Packet Eigen internal plog const Packet with Packet vector 4 builtin neon sf ' tensorflow compiler xla service cpu cpu runtime neon cc 32 33 required from here external androidndk ndk sources cxx stl gnu libstdc 4 9 include complex 790 5 note template class Tp std complex Tp std log const std complex Tp log const complex Tp z return complex log z external androidndk ndk sources cxx stl gnu libstdc 4 9 include complex 790 5 note template argument deduction substitution failed In file included from external eigen archive Eigen Core 372 0 from third party eigen3 Eigen Core 1 from tensorflow compiler xla service cpu cpu runtime neon cc 20 external eigen archive Eigen src Core GenericPacketMath h 411 60 note mismatched types 'const std complex Tp ' and 'const vector 4 builtin neon sf' Packet plog const Packet a using std log return log a Target tensorflow compiler xla service cpu cpu runtime neon failed to build Use verbose failures to see the command lines of failed build steps INFO Elapsed time 15 227s Critical Path 0 76s FAILED Build did NOT complete successfully,,aselle,2017-09-17 16:25:35,2018-01-09 07:52:45
PR,Fix local path for hexagon graph execution in sample script,,,,2018-01-09 08:59:39,2018-01-09 09:03:44
IS,Boringssl support for s390x,Creating this issue with reference System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below master Bazel version if compiling from source 0 6 1 CUDA cuDNN version Not used Exact command to reproduce bazel build c opt tensorflow tools pip package build pip package,,"Nayana-ibm,Nayana-ibm,gunan,gunan,Nayana-ibm,gunan,Nayana-ibm,case540,gunan,gunan,martinwicke,mrry,martinwicke,Nayana-ibm,gunan,Nayana-ibm,gunan,Nayana-ibm,gunan,Nayana-ibm,gunan,Nayana-ibm,gunan,Nayana-ibm",2017-10-27 18:25:10,2018-01-09 09:06:19
IS,beginner bug TensorFlow does not seem to be decomposing GradientDescent into XLA ops,System information Tensorflow compiled on a branch of a fork Contains extra LOG INFO and std cout statements to notify the names of the functions being called OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 'v1 2 0 1878 ga5066f6' '1 2 1' Python version 2 7 12 Bazel version if compiling from source release 0 5 2 CUDA cuDNN version CUDA 8 GPU model and memory NVIDIA Quadro K1200 4 GB Exact command to reproduce python tflow parent tensorflow tensorflow example tutorials mnist mnist mnist softmax xla py tf env txt Context My work involves securing Tensorflow is computations The approach I have planned to take is to add XLA ops during the conversion of TF ops to XLA ops which are lowered into functions calls in LLVM IR that send data to and receive data from a secure environment I'm currently verifying if both training and inference TF Ops are lowered to XLA ops The Problem I have made some changes to the code to highlight when some OpKernels and XlaOpKernels are being invoked lowered I have used the mnist softmax xla py example to observe tensorflow is behaviour I found that ApplyGradientDescentGPU was being called 2000 times 2 layer network and 1000 iterations clearly not JIT instead of ResourceApplyGradientDescent yet other Ops including MatMul and subtraction seem to have been optimized by XLA Why is gradient descent not optimized by XLA Source code logs The output text lost its structure when I pasted it So here are the screenshots github 1 github 2 github 3 github 4 Note that the first 2 kernels have been called a 100 times each Related Also it would be helpful if someone could answer Tensow XLA Passing tensors to external functions at runtime as it is the important assumption of my approach that Tensorflow can allow such XLA ops I appreciate any information on its feasibility as I could start on a different approach as soon as possible Thanks Sanjay,,,2017-07-18 21:23:51,2018-01-09 10:14:15
IS,error while bazel build,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below r1 5 Python version 3 6 3 Anaconda GCC Compiler version if compiling from source 5 4 CUDA cuDNN version 9 0 176 7 0 5 GPU model and memory NVIDIA GTX 1080 Driver 385 111 8G Bazel version if compiling from source 0 9 Exact command to reproduce bazel build config opt cxxopt D GLIBCXX USE CXX11 ABI 0 config cuda tensorflow tools pip package build pip package action env LD LIBRARY PATH LD LIBRARY PATH Describe the problem Use the commend line bazel build config opt cxxopt D GLIBCXX USE CXX11 ABI 0 config cuda tensorflow tools pip package build pip package action env LD LIBRARY PATH LD LIBRARY PATH And got the error When coppileing I got a lot of warning like this WARNING home xxh tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' No longer supported Switch to SavedModel immediately Cuda 9 0 test pass And copied the cudnn h and libcudnn to cuda file It is all fine,,,2018-01-05 20:05:06,2018-01-09 11:07:40
IS,C API SIGABRT abort Non OK status RegisterAlreadyLocked Invalid name,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Working with public C API OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS 10 13 2 17C88 TensorFlow installed from source or binary binary TensorFlow version use command below libtensorflow 1 4 1 from brew package Python version non Bazel version if compiling from source non GCC Compiler version if compiling from source Apple Swift version 4 0 3 swiftlang 900 0 74 1 clang 900 0 39 2 lldb 900 0 64 Swift 4 0 CUDA cuDNN version non GPU model and memory non Exact command to reproduce Using swift code as example Describe the problem Dear TensorFlow community It is really strange issue from time to time at the same code I have SIGABRT crash Sanitizer options can not help to resolve that issue List of libs loaded in attached file dyld log txt Source code logs Using C API I am alloc new Graph by TF NewGraph L26,,"asimshankar,asimshankar",2018-01-07 17:15:42,2018-01-09 16:06:20
IS,Building Error clang error no such file or directory 'x86 64',Hi all I met this problem when I was trying to build the Tensorflow Lite for iOS following this instruction Every thing went well until I tried the command tensorflow contrib lite build ios universal lib sh The error occured clang error no such file or directory 'x86 64' What could be the problem Thank you very much My environment Mac Sierra 10 12 6 XCode 9 2,,aselle,2017-12-19 15:38:54,2018-01-09 17:17:47
PR,Branch 181239691,,,"frankchn,frankchn,frankchn",2018-01-09 01:09:42,2018-01-09 19:10:06
PR,Remove third party prefixes,,,"Androbin,drpngx,Androbin,drpngx,yifeif",2017-12-27 23:54:21,2018-01-09 19:10:55
IS,Tensorflow Non deterministic behaviour with large model using while loop,Hello I believe to have found a bug in Tensorflow when running the code below I am currently trying to build a neural transducer and have stumbled across TF sometimes not returning any values for a function I have not had the chance yet to test this out on another machine no GPU TF 1 4 1 Ubuntu 17 10 I am not sure whether this is indeed a bug or not so I'm first posting it here The code is redacted a bit to highlight only the parts that fail I have also posted to StackOverflow considering it might be an error in my code but have not got any response yet Notes I believe the bug occurs around line 160 in the body of the while loop in the function run full transducer The session is returning encoder outputs transducer outputs I do not use random functions As far as I can tell if I remove the Print OP in line 164 the output is always 0 Example of a correct return value more or less Have I written custom code Yes OS Platform and Distribution Ubuntu 17 10 Artful Aardvark TensorFlow installed from binary TensorFlow version 1 4 1 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Execute the code block as a python file a few times Thanks Nikita,,,2018-01-04 15:20:55,2018-01-09 19:53:38
IS,iOS Camera Example not able to fit to iphone 6 screen,System information OS Platform and Distribution macOS High Sierra TensorFlow installed from source TensorFlow version 1 4 Describe the problem When I run the tensorflow camera example on xcode it runs fine but only in dimensions that fit an iphone 4 I changed the build settings have turned on autolayout and even tried messing around with the constraints It seems like no matter what I try the viewcontroller wo not get any larger,,,2018-01-09 15:17:12,2018-01-09 20:51:43
PR,Branch 181341793,,,"frankchn,frankchn,frankchn",2018-01-09 19:16:46,2018-01-09 21:47:59
IS,Python Configuration Error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source TensorFlow version use command below the latest master branch Python version 3 6 3 in anaconda python path is C Users huo y Anaconda3 python exe Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source msvc 14 CUDA cuDNN version no GPU model and memory no Exact command to reproduce bazel build config opt tensorflow tools pip package build pip package Describe the problem when I build tensorflow with bazel on windows by msys2 shell I got this error Python Configuration Error define PYTHON BIN PATH 'C Users huo y Anaconda3 python exe' is not executable Is it the python binary Source code logs ERROR C users huo y tensorflow master util python BUILD 5 1 no such package ' local config python ' Traceback most recent call last File C users huo y tensorflow master third party py python configure bzl line 291 create local python repository repository ctx File C users huo y tensorflow master third party py python configure bzl line 251 in create local python repository check python bin repository ctx python bin File C users huo y tensorflow master third party py python configure bzl line 204 in check python bin fail define s ' s' is not execut File C users huo y tensorflow master third party py python configure bzl line 27 in fail fail sPython Configuration Error Python Configuration Error define PYTHON BIN PATH 'C Users huo y Anaconda3 python exe' is not executable Is it the python binary and referenced by ' util python python headers' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted Loading failed INFO Elapsed time 16 677s FAILED Build did NOT complete successfully 63 packages loaded currently loading tensorflow core kernels Fetching 32 768b 4s It may cause by python configure bzl I think But I do not know how to correct it here is on function about the error in python config bzl I find that when I run configure the python path is windows format just like C Users huo y Anaconda3 python exe but in msys2 the path may show c Users huo y Anaconda3 python exe I guess that when using bash c it should need the path just like c Users huo y Anaconda3 python exe can get the correct return code but it seems that the python bin parameter is the windows path format can anyone help check it because I do not be farmiliar with bazel,,shivaniag,2018-01-06 10:50:49,2018-01-09 22:28:30
IS,Failed to synchronize the stop event,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below b'v1 4 0 0 gd752244' 1 4 0 Python version 3 5 2 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version 9 0 7 0 GPU model and memory Tesla V100 SXM2 16GB Exact command to reproduce,,"angersson,zheng-xq,zheng-xq,shivaniag",2017-11-08 13:17:00,2018-01-09 22:43:49
IS,a document bug,from in the section How do you get a model you can use on mobile the right path is,,shivaniag,2017-11-17 10:24:52,2018-01-09 23:23:49
PR,Add new internal release notes that were missed in the previous iteration,,,"angersson,angersson",2018-01-09 23:22:48,2018-01-09 23:23:49
IS,The API doc for tensorflow keras backend set learning phase is wrong,System information TensorFlow version use command below 1 4 0 Python version Python 2 7 13 Anaconda Inc Describe the problem When I implemented Custom Estimator API with tf keras I countered following error,,"shivaniag,shivaniag",2017-11-21 06:13:07,2018-01-09 23:25:01
IS,cant downlod tensorflow it shows could not find a versone,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"shivaniag,shivaniag",2017-11-23 02:16:11,2018-01-09 23:25:34
IS,How to define multiple loss function and train op in tf estimator EstimatorSpec,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 Python version 2 7 12 CUDA cuDNN version 6 0 GPU model and memory 1080 Ti 1080 Describe the problem I'm currently implementing a pose estimation system and I defined my network with 3 loss and train op in each of degree yaw pitch and roll And I'm current using your tf estimator API which I think is pretty convenient to monitor the system however I found that I may only be able to define one loss and train op using this set of API I would like to know if there is any solution to train and monitor the system with multiple loss and train op at the same time Thanks Source code logs,,"shivaniag,ispirmustafa,ispirmustafa,ispirmustafa",2018-01-01 18:14:02,2018-01-09 23:48:24
IS,Function categorical column with identity with big number as num buckets parameter causes training hang and crash,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 macOS 10 12 6 TensorFlow installed from source or binary binary TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 Bazel version if compiling from source CUDA cuDNN version not use GPU GPU model and memory no GPU Exact command to reproduce Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request When I try to use use id or item id as an feature and process it through function,,"ispirmustafa,ispirmustafa",2017-09-20 12:47:42,2018-01-10 00:08:47
IS,Estimator predict always loads model checkpoint preventing partially loading checkpoints,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 Python version 3 5 Describe the problem When using Tensorflow is Estimator to do predictions the Estimator always loads the checkpoint in the model dir As this is done after the model fn is called there is no way to partially load a checkpoint for predictions For training I partially load the initial checkpoint in the model fn which works fine I also tried not specifying the model dir for the Estimator As the documentation states init this results in the Estimator using a temporary folder However as the temporary folder does not contain a checkpoint I get the error Could not find trained model in model dir It looks like there is no way to only partially load a checkpoint for prediction If so please provide a way to do this For me this is important because I have a large model with several outputs For different datasets some of the outputs have different sizes However some of them are the same for all datasets That is why I want to load them with the same code and only partially because I do not need to load and run the whole network for this prediction,,"andreas-eberle,ispirmustafa",2018-01-09 12:56:34,2018-01-10 00:21:25
IS,Documentation for placeholder does not explain when shape is or None,System information Not necessary Describe the problem The documentation for placeholder does not explain the case when its shape is or None Possible solution Add the explanations in this SO answer to the documentation of placeholder including the example,,shivaniag,2018-01-09 23:28:05,2018-01-10 01:01:55
IS,Import Error No module named ' pywrap tensorflow',On running the following command import tensorflow I get an error C Users Neerav python Python 3 5 0 v3 5 0 374f501f4567 Sep 13 2015 02 27 37 MSC v 1900 64 bit AMD64 on win32 Type help copyright credits or license for more information import tensorflow Traceback most recent call last File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File C Users Neerav AppData Local Programs Python Python35 lib imp py line 296 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File stdin line 1 in module File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python init py line 60 in module raise ImportError msg ImportError Traceback most recent call last File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File C Users Neerav AppData Local Programs Python Python35 lib imp py line 296 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File C Users Neerav AppData Local Programs Python Python35 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ImportError No module named ' pywrap tensorflow' Error importing tensorflow Unless you are using bazel you should not try to import tensorflow from its source directory please exit the tensorflow source tree and relaunch your python interpreter from there I have the following system features windows 64 bit python 3 5 0 64 bit Nvidia computing toolkit CUDA v8 0 the cuDNN version 6 0 all of them are added to my path location also which is Python Python35 Scripts i have tensorflow in Python Python35 Lib site packages tensorflow I even have a pywrap tensorflow so file and pywrap tensorflow py,,shivaniag,2018-01-08 10:46:51,2018-01-10 01:16:38
PR,Recognize more environments as interactive,and log to stdout in those cases and show INFO messages by default Fixes 6438,,"martinwicke,drpngx,MarkDaoust",2017-12-21 23:15:02,2018-01-10 02:07:26
IS,Missing dlcose FreeLibrary after dlopen LoadLibrary,Have I written custom code N A OS Platform and Distribution N A TensorFlow installed from N A TensorFlow version N A Bazel version N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Problem description A Looking at code below there are couple of issues L34 L59 1 There is no dlcose call after dlopen and dysym in the code above 2 There can be two successful getLibraryHandle calls without dlclose in loadFunction B More generally the code below shows there is no interface to unload DLL either L254 L280,,,2017-12-11 19:28:27,2018-01-10 03:08:17
PR,update label image py,1 add build rule for label image py 2 remove extraneous semicolons,,"freedomtan,gunan,sb2nov,freedomtan,sb2nov,gunan,drpngx,drpngx,drpngx,drpngx,caisq,drpngx,drpngx,freedomtan,caisq",2017-12-01 04:19:25,2018-01-10 04:10:02
IS,Tensor Core support for NVIDIA Volta architecture,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 5386775e64aac0bb5020974122645da900bc312a Python version 3 5 Bazel version if compiling from source 0 8 1 GCC Compiler version if comp6iling from source 5 4 0 CUDA cuDNN version 9 1 7 0 5 GPU model and memory Titan V Exact command to reproduce Describe the problem It is widely reported that using float16 on Nvidia Volta architecture comes only with x2 improvement instead of the expected x4 x8 improvement using Tensor Cores I checked that Tensorflow master branch used cudnnGetConvolutionForwardAlgorithm to get the best possible algorithm for the given GPU However I think either cudnnGetConvolutionForwardAlgorithm v7 or cudnnFindConvolutionForwardAlgorithmEx should be used to fully utilize the Volta architecture Could you please check this issue with a Volta architecture GPU Source code logs,,"shivaniag,reedwm,zheng-xq,yzhwang,yzhwang,zheng-xq,yzhwang",2018-01-05 23:48:20,2018-01-10 05:24:52
PR,R1 5 verbs w 0 copies,Verbs implementation to use direct tensor writes 0 copies Motivation Following HKUST research on the use of GPU direct and their GDR implementation we wish to adopt the 0 copies approach and apply it to the current verbs implementation while keeping the current implementation advantages such as configurability and the use of RDMA for control messages Performance Compared with the current GRPC verbs and GDR implementation the result implementation gave the best performance for every model with any number of nodes For VGG16 on 8 nodes with 4 P100 GPUs each the prototype beat the second place by over 15 Implementation requirements 1 Tensor writes need to be done directly from the source Tensor to the destination Tensor with no memory copies in between This should be done for all DMAble tensors which are located either on CPU or on a RDMA compatible GPU device GPU direct 2 Non DMAble tensors CanMemCopy false will be serialized to proto on the sender side RDMA written to a registered buffer on the receiver side and then deserialized by the receiver 3 Tensors which are located on a non RDMA compatible GPU will be RDMA written to a registered CPU proxy buffer on the receiver side and then copied to GPU by the receiver Implementation constrains For best stability and proof of correctness we will divide the implementation to two stages 1 At first stage we will keep changes to the current implementation to the minimum possible The expense will be that we may have unused or unnecessary code leftovers which may also affect performance 2 At second stage we will re iterate over the code and remove irrelevant code parts The design of the solution aims that we will achieve both stages with relative ease Design guidelines 1 Since we do not want to do any unnecessary memory copying we will no longer allocate a fixed CPU buffer as the destination for the RDMA write Instead we will do the writing directly to the result tensor or if the result tensor is on a device which does not support RDMA we will do the writing to a proxy CPU tensor and then copy its content to the result tensor 2 The address of the destination Tensor needs to be sent to the sender side for writing meaning that the result proxy tensor should be pre allocated on the receiver side prior to sending the tensor request In order to do that we need to know its meta data i e shape and data type for DMAble tensors and proto size for serialized tensors Unfortunately this information is only available on the sender side which complicates manners In order to avoid sending extra messages for querying the meta data on each step we store a local meta data cache per tensor Based on the assumption that the meta data of a tensor rarely changes between steps we expect that on most times the cache will only be updated once When the sender receives a request for a tensor if it is the first time this tensor is requested or in the rare case that the meta data did change the sender will first send a meta data response on which the receiver will update the local cache and reallocate the result proxy tensors if required When the receiver sends the tensor request it will contain also the meta data currently stored in its local cache so the sender can compare it to see if there was a change 3 When the sender writes the tensor content to the result tensor no additional data is being written with it That means we need to reside on ibverbs immediate uint32 t to indicate which request we are responding to in order to trigger the receive callback The easiest and most elegant way is to key the recv callback with a unique request index uint32 t instead of the current key with step id string 4 Since the sender no longer writes the tensor from to fixed buffers we no longer need to schedule the writes using the local remote status In addition we no longer rely on the RmdaTensorBuffer members as the source destination addresses and rkey lkey Instead each RdmaTensorBuffer will hold multiple Response objects one per step id from which we derive destination address and rkey The source address and lkey are always the ones of the source Tensor 5 With the addition of tensor pre allocation we noticed there is a large code similarity between sending the first tensor request and re sending the request in case of meta data changes After implementing a common method for tensor pre allocation it turned out that implementation becomes much simpler by encapsulating the process of request sending re sending meta data response callback and content response callback all in a single Request class The request class holds all the relevant request information which reduces excessive parameter passing and lambda capturing This decision is purely for elegance and code simplicity and we decided to implement it in first stage because it makes the implementation much easier New types classes enum RdmaImmDataType Immediate types to distinguish between different RDMA writes on the remote side Ack writes and control message writes have a fixed immediate value The rest of the writes are tensor writes and the immediate value is the relevant request index enum RdmaWriteIDType Types to distinguish between different RDMA write complete events Ack control message tensor DMA write and tensor proto write class RdmaWriteID Context for RDMA write complete events Holds the RdmaWriteIDType and additional data class RemoteAddressContext Remote address information address mr Will be passed as write context for tensor proto writes class RdmaTensorMetaData Meta data for a tensor type shape is dead proto size class RdmaMemoryMgr Manages the meta data cache and the registered memory regions class RdmaTensorRequest Holds and manages information for a single tensor request throughout the entire receive cycle API Start Start the request RecvTensorMetaData Receive meta data from the remote side RecvTensorContent Receive tensor content from the remote side and invoke the done callback class RdmaTensorResponse Holds information for a single tensor response such as destination address and rkey Protocol changes The protocol messages themselves will remain mostly unchanged at the first stage but will be used differently as described below The current messages structures already have most of the required fields for the new implementation The only change is the buffer size field which is no longer used since we are no longer sending additional information with the tensor and thus it is now always equal to the tensor bytes field Instead we use that field to pass the request index Message structure type name size name step id request index remote addr rkey is dead data type tensor shape tensor bytes 1B 2B 512 8B 8B 8B 4B 1B XB XB 8B RDMA MESSAGE TENSOR REQUEST receiver sender The original tensor request type The message type name name size Name of the requested tensor step id Step ID request index Request index remote addr rkey Address rkey of the result proxy tensor Irrelevant for first time request is dead data type tensor shape tensor bytes The current meta data as stored in the receiver local cache The sender will use that information to know if the receiver is cache requires updating RDMA MESSAGE BUFFER REQUEST sender receiver The meta data update message in case meta data had changed or if it is the first time the tensor is requested type The message type request index Request index is dead data type tensor shape tensor bytes The up to date meta data RDMA MESSAGE BUFFER RESPONSE receiver sender Tensor re requset after meta data update and reallocation of result proxy tensors type The message type name name size Name of the requested tensor step id Step ID request index Request index remote addr rkey Address rkey of the reallocated result proxy tensor is dead data type tensor shape tensor bytes The new meta data Will be removed in the next phase RDMA MESSAGE TENSOR WRITE sender receiver No longer sent There is only a direct write of the tensor content to the result proxy tensor Request index passed as the immediate value of the write RDMA MESSAGE TENSOR IDLE receiver sender No longer sent alt text Phase 1 message protocol Second stage optimizations 1 Remove unused code leftovers 2 Remove the ACK buffer completely since we can rely completely on its immediate value Future optimizations 1 Map the tensor names to indexes to significantly reduce the request message size 2 Understand the purpose of empty tensors and if we can skip remote fetching for them 3 Consider concatenating multiple requests and or using multiple message buffers 4 Consider a no request architecture,,,2018-01-07 13:09:15,2018-01-10 12:18:57
PR,Add internal release notes that were previously missing,I was not sure about some of the Important Other changes so please double check that I have not missed anything actually critical,,"angersson,av8ramit,av8ramit,av8ramit,av8ramit,av8ramit,av8ramit,av8ramit,av8ramit,angersson,angersson",2018-01-09 23:45:17,2018-01-10 19:29:28
PR,Disabling the interleave op test for now,,,"av8ramit,gunan,mrry,av8ramit",2018-01-10 18:43:39,2018-01-10 20:11:17
PR,Adding an install sources line for 1 5 0 rc0 Earlier we only updated,this for official,,"av8ramit,av8ramit,gunan,av8ramit",2018-01-08 22:21:15,2018-01-10 20:15:12
PR,Disabling the warnings test for python3 5 as well,,,av8ramit,2018-01-10 19:19:30,2018-01-10 20:17:00
PR,Fix r1 5 tests,PiperOrigin RevId 181212111,,av8ramit,2018-01-09 23:08:07,2018-01-10 20:20:12
PR,Modify parse bazel version to return a tuple of ints,Bazel is updating its version to 0 10 0 and this will break the version check Applying suggested fix in,,"frankchn,frankchn",2018-01-10 19:17:41,2018-01-10 20:28:08
IS,unable to install from source with undefined external dependency target error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below r1 4 0 Python version 2 7 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version no GPU model and memory no Exact command to reproduce sudo bazel build config opt cxxopt D GLIBCXX USE CXX11 ABI 0 tensorflow tools pip package build pip package Describe the problem I'm trying to install r1 4 0 from source with CPU version and follow the install guidelines on the official website But some errors occur The errors are shown in Source code logs 1 It seems that the undefined external dependency target local config sycl is referred in some files eg tensorflow 1 4 0 third party eigen3 build 2 I am sure the openCL suppurt is disabled when configure 3 I tried to install version r1 0 1 from source but the same errors occur 4 I tried to install version r1 4 0 from binary and success Why this happens and how can I fix it Thank you Source code logs ERROR home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD 4 1 First argument of 'load' must be a label and start with either ' ' ' ' or ' ' Use incompatible load argument is label false to temporarily disable this check ERROR home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD 6 1 First argument of 'load' must be a label and start with either ' ' ' ' or ' ' Use incompatible load argument is label false to temporarily disable this check ERROR home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD 30 9 Traceback most recent call last File home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD line 27 cc library name syclrt srcs sycl libr 3 more arguments File home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD line 30 in cc library sycl library path name isycl library path' is not defined ERROR home tangdehong cache bazel bazel root 4bf03e1269a0e4905c62fa69a980acb4 external local config sycl sycl BUILD 39 1 Target ' local config sycl sycl using sycl' contains an error and its package is in error and referenced by ' local config sycl sycl sycl' ERROR home tangdehong OpenSourceCode tensorflow 1 4 0 third party eigen3 BUILD 20 1 Target ' local config sycl sycl sycl' contains an error and its package is in error and referenced by ' third party eigen3 eigen3' ERROR Analysis of target ' tensorflow tools pip package build pip package' failed build aborted Loading failed INFO Elapsed time 0 745s FAILED Build did NOT complete successfully 0 packages loaded currently loading tensorflow contrib losses 17 packages Thank you,,"skye,gunan,gunan",2018-01-04 15:16:57,2018-01-10 20:43:22
IS,Build Source build at HEAD generating XLA erros on Mac OS,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS High Sierra TensorFlow installed from source or binary Source TensorFlow version use command below HEAD a770968 Python version 3 6 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 9 0 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Build procedures on doc optimized for native arch and XLA enabled Describe the problem Building TensorFlow on Mac OS with XLA enabled and configuration given above optimized for native arch and CPU only yields the following errors,,"Carmezim,brianwa84,Carmezim",2018-01-08 17:04:44,2018-01-10 21:10:23
PR,Update version strings,,,"angersson,angersson",2018-01-10 22:01:39,2018-01-10 22:02:37
IS,tf r1 4 bazel build error nsync,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below r1 4 Python version Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source gcc Ubuntu 5 4 1 2ubuntu1 16 04 5 4 1 20160904 CUDA cuDNN version 8 0 6 Exact command to reproduce sudo bazel build c opt config cuda copt mtune native copt O3 tensorflow libtensorflow cc so tensorflow libtensorflow so genrule strategy standalone spawn strategy standalone Problem I use tensorflow c api to run some RL applications When I run my project I get this error It was okay with tensorflow r1 3 or older versions home joonho workspace rai deepLearning tensorflow tensorflow core platform default mutex h 25 22 fatal error nsync cv h No such file or directory include nsync cv h I think there is linking error I clearly have the headers in my environment How can I fix this is this bug in tf r1 4 or am I doing something wrong joonho joonho HP Z440 Workstation locate nsync cv h home joonho cache bazel bazel root 4eb2082608889a2b4334c89631226226 external nsync public nsync cv h home joonho virtualenvs tensorflow lib python3 5 site packages external nsync public nsync cv h home joonho virtualenvs tensorflow lib python3 5 site packages tensorflow include external nsync public nsync cv h,,"drpngx,drpngx,MarkDaoust,MarkDaoust",2017-11-16 11:44:46,2018-01-10 22:46:50
PR,Disable all failing tests to fix TF opensource tests,PiperOrigin RevId 181212111,,av8ramit,2018-01-10 20:25:52,2018-01-10 22:51:22
PR,TensorFlow for NVIDIA Tegra devices with CUDA support,,,"lihanchen,andrewharp,andrewharp,andrewharp,andrewharp,lihanchen,lihanchen,lihanchen,lihanchen,andrewharp,lihanchen,andrewharp,lihanchen,andrewharp,lihanchen,lihanchen,lihanchen,andrewharp,andrewharp,lihanchen,lihanchen,drpngx,lihanchen,drpngx,andrewharp,drpngx,drpngx,andrewharp,zheng-xq,andrewharp",2017-11-02 01:23:55,2018-01-10 23:01:07
PR,Branch 181499300,,,"frankchn,frankchn,frankchn,av8ramit,frankchn,av8ramit",2018-01-10 20:38:55,2018-01-11 00:11:47
PR,R1 4,,,av8ramit,2018-01-11 00:17:30,2018-01-11 00:18:57
IS,home hp cache bazel bazel hp a7dace51e7355e610cd60a2c24b75c6d external astor archive BUILD 8 1 Converting to Python 3 external astor archive astor source repr py failed Exit 1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below clone from git Python version 3 6 3 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 0 7 0 GPU model and memory GTX1070ti 8GB Exact command to reproduce Describe the problem build error when I finished configure and run bazel build config opt config cuda tensorflow tools pip package build pip package met an error Source code logsExtracting Bazel installation WARNING home hp Downloads tensorflow tensorflow core BUILD 1825 1 in includes attribute of cc library rule tensorflow core framework headers lib ' external nsync public' resolves to 'external nsync public' not below the relative path of its package 'tensorflow core' This will be an error in the future Since this rule was created by the macro 'cc header only library' the error might have been caused by the macro implementation in home hp Downloads tensorflow tensorflow tensorflow bzl 1152 30 WARNING home hp cache bazel bazel hp a7dace51e7355e610cd60a2c24b75c6d external grpc WORKSPACE 1 Workspace name in home hp cache bazel bazel hp a7dace51e7355e610cd60a2c24b75c6d external grpc WORKSPACE com github grpc grpc does not match the name given in the repository is definition grpc this will cause a build error in future versions WARNING home hp Downloads tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle exporter' No longer supported Switch to SavedModel immediately WARNING home hp Downloads tensorflow tensorflow contrib learn BUILD 15 1 in py library rule tensorflow contrib learn learn target ' tensorflow contrib learn learn' depends on deprecated target ' tensorflow contrib session bundle gc' No longer supported Switch to SavedModel immediately INFO Found 1 target ERROR home hp cache bazel bazel hp a7dace51e7355e610cd60a2c24b75c6d external astor archive BUILD 8 1 Converting to Python 3 external astor archive astor source repr py failed Exit 1,,shivaniag,2018-01-10 03:41:02,2018-01-11 00:22:57
IS,Some gpu tests are failing on Windows in Bazel build,They are marked as no windows gpu in but we need to investigate why they are now failing,,"meteorcloudy,shivaniag,gunan",2017-08-02 07:34:26,2018-01-11 01:22:56
IS,tf Estimator creates loss and loss 1 for eval train,OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 12 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 2 7 Describe the problem When using the tf Estimator the summary files save out summaries for the loss variable evaluated every checkpoint The summary for the training is saved as 'loss 1' I got this tensorboard by running the ciphar10 estimator code located This makes it difficult to compare the eval train loss on the same graph in tensorboard What causes this naming issue and what can be done to fix it Thanks screen shot 2018 01 09 at 12 02 53 pm,,"facaiy,facaiy,shivaniag",2018-01-09 20:04:17,2018-01-11 01:24:05
IS,Error While Importing Tensorflow 1 5 RC0 with CUDA 9 1,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64 bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 RC0 Python version 3 6 3 via Anaconda Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 1 7 0 5 GPU model and memory GTX 1050 4GB notebook version Exact command to reproduce import tensorflow from a Python shell Describe the problem The installation of the CUDA cuDNN and Tensorflow went smoothly When I import tensorflow I get the error pasted below CUDA and CUDA PATH V9 1 were automatically set by the installer to C Program Files NVIDIA GPU Computing Toolkit CUDA v9 1 Installation instructions used CUDA windows steps 7 to 10 ignored because it involved downloading nearly 6 GB for a test Is it required I have not installed TF in Windows before cuDNN step 5 ignored as I did not have a Visual Studio project is there a VS project in the context of Tensorflow Tensorflow pip install ignore installed upgrade tensorflow gpu 1 5 0rc inside a conda environment Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-10 19:06:12,2018-01-11 01:38:37
IS,tensorflow input output tensor reshape c,currently I am working on loading and testing a tensorflow model on android using c and the trained model is a full convolutional model so the input need to be dynamically reshaped according to input image size I can make this done easily using python but when turn to c I can hardly find much examples and experience on this the trained model is converted to pb file and the input and output tensor shape has been specified before conversion in python and now I want to reshape the input and output in c before using the model,,,2018-01-10 05:53:51,2018-01-11 02:22:41
IS,TFGAN ideas for pretraining training,With the PR 14723 enabling get hooks fn to be set manually instead of the default 1 step generator and 1 step discriminator there comes a set of new problems things to consider 1 The Estimator saves configured tensor summaries in the background This does not work when doing something like a 2 2 split for generator discriminator or a 2 3 Then Estimator will only save one step instead of the actual amounts of steps taken right This means that we have to consider an option to configure the FileWriter I believe that is possible for the vanilla Estimator with scaffolds but not for the GANEstimator currently This FileWriter has to be accessible by the RunTrainOpsHook We would also need a generator discriminator specific global step that will be used in the RunTrainOpsHook A quick idea would be to use the overall global step train steps of a RunTrainOpsHook or to use dummy global step generator and dummy global step discriminator 2 When pre training with a normal call to train and a modified sequential train hook 10 10 the generator for e g 10 steps and then the discriminator for 10 steps Does the discriminator loss fn receive 10 times new data from the generator through gan model discriminator real outputs or will it always be the same data For pre training I would assume I can feed in the same output data from the generator in batches multiple epochs I believe that is not possible in the current setup but correct me if I am wrong 3 I have different loss functions for both pre training and training There is not ModeKeys PRETRAIN to switch between them If I find more things I will add them here,,"joel-shor,joel-shor,joel-shor,joel-shor,joel-shor,joel-shor",2017-12-11 11:44:24,2018-01-11 02:52:58
PR,Fix typos,This PR fixes some typos refered ouptuts from from suport whithin posibility and then then,,"taehoonlee,caisq",2018-01-10 02:59:48,2018-01-11 03:07:31
PR,py2tf add py2tf internal BUILD rule to pip package,to make pip tests pass,,"caisq,caisq",2018-01-11 03:11:27,2018-01-11 04:56:14
IS,Clarify documentation of stacked cuDNN RNNs,Currently the documentation for cuDNN RNNs is unclear as to whether the RNNs LSTMs or GRUs when they are bidirectional and configured with multiple layers integrate the outputs from both directions at a given layer n before sending it to the next layer n 1 or whether each direction works independently of the other I e forward layers send information just to the forward layers above and similarly for the backward direction The difference in behavior is quite important and it would be great if the documentation is updated to state which behavior is being carried out,,"jart,jart,protoget,jart",2017-11-01 12:44:53,2018-01-11 05:01:45
IS,tensorflow tensorboard on cifs results in PermissionDeniedError,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Using stock example script mnist py from OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 TensorFlow installed from source or binary using standard tensorflow tensorflow 1 1 0 gpu image TensorFlow version use command below using standard tensorflow tensorflow 1 1 0 gpu image Python version using standard tensorflow tensorflow 1 1 0 gpu image Bazel version if compiling from source tensorflow tensorflow 1 1 0 gpu CUDA cuDNN version GPU model and memory Tesla K80 Exact command to reproduce Describe the problem I am running stock mnist py from on tensorflow tensorflow 1 1 0 gpu and running tensorboard in parallel on the same container Everything works well if logdir is located on local ssd If i am configuring logdir to be on samba directory and using tensorboard during job execution specifically if i am using Embeddings the job fails at writing temp checkpoint files see logs below If I am not using tensorboard embeddings during job is execution the job finishes successfully Source code logs 2017 10 24 17 39 31 165783 W tensorflow core framework op kernel cc 1152 Permission denied model ckpt 500 index tempstate18351127508205389812 Traceback most recent call last File mnt batch tasks shared LS root mounts external tb sample mnist py line 164 in module main File mnt batch tasks shared LS root mounts external tb sample mnist py line 156 in main mnist model learning rate use two fc use two conv hparam File mnt batch tasks shared LS root mounts external tb sample mnist py line 136 in mnist model saver save sess os path join LOGDIR model ckpt i File usr local lib python2 7 dist packages tensorflow python training saver py line 1391 in save self saver def filename tensor name checkpoint file File usr local lib python2 7 dist packages tensorflow python client session py line 778 in run run metadata ptr File usr local lib python2 7 dist packages tensorflow python client session py line 982 in run feed dict string options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1032 in do run target list options run metadata File usr local lib python2 7 dist packages tensorflow python client session py line 1052 in do call raise type e node def op message tensorflow python framework errors impl PermissionDeniedError model ckpt 500 index tempstate18351127508205389812 Node save SaveV2 SaveV2 dtypes DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT device job localhost replica 0 task 0 cpu 0 recv save Const 0 save SaveV2 tensor names save SaveV2 shape and slices conv1 B 41 conv1 B Adam 43 conv1 B Adam 1 45 conv1 W 47 conv1 W Adam 49 conv1 W Adam 1 51 conv2 B 53 conv2 B Adam 55 conv2 B Adam 1 57 conv2 W 59 conv2 W Adam 61 conv2 W Adam 1 63 fc1 B 65 fc1 B Adam 67 fc1 B Adam 1 69 fc1 W 71 fc1 W Adam 73 fc1 W Adam 1 75 fc2 B 77 fc2 B Adam 79 fc2 B Adam 1 81 fc2 W 83 fc2 W Adam 85 fc2 W Adam 1 87 test embedding 89 train beta1 power 91 train beta2 power 93 Caused by op u isave SaveV2' defined at File mnt batch tasks shared LS root mounts external tb sample mnist py line 164 in module main File mnt batch tasks shared LS root mounts external tb sample mnist py line 156 in main mnist model learning rate use two fc use two conv hparam File mnt batch tasks shared LS root mounts external tb sample mnist py line 114 in mnist model saver tf train Saver File usr local lib python2 7 dist packages tensorflow python training saver py line 1056 in init self build File usr local lib python2 7 dist packages tensorflow python training saver py line 1086 in build restore sequentially self restore sequentially File usr local lib python2 7 dist packages tensorflow python training saver py line 689 in build save tensor self AddSaveOps filename tensor saveables File usr local lib python2 7 dist packages tensorflow python training saver py line 276 in AddSaveOps save self save op filename tensor saveables File usr local lib python2 7 dist packages tensorflow python training saver py line 219 in save op tensors File usr local lib python2 7 dist packages tensorflow python ops gen io ops py line 780 in save v2 tensors tensors name name File usr local lib python2 7 dist packages tensorflow python framework op def library py line 768 in apply op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 2336 in create op original op self default original op op def op def File usr local lib python2 7 dist packages tensorflow python framework ops py line 1228 in init self traceback extract stack PermissionDeniedError see above for traceback model ckpt 500 index tempstate18351127508205389812 Node save SaveV2 SaveV2 dtypes DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT DT FLOAT device job localhost replica 0 task 0 cpu 0 recv save Const 0 save SaveV2 tensor names save SaveV2 shape and slices conv1 B 41 conv1 B Adam 43 conv1 B Adam 1 45 conv1 W 47 conv1 W Adam 49 conv1 W Adam 1 51 conv2 B 53 conv2 B Adam 55 conv2 B Adam 1 57 conv2 W 59 conv2 W Adam 61 conv2 W Adam 1 63 fc1 B 65 fc1 B Adam 67 fc1 B Adam 1 69 fc1 W 71 fc1 W Adam 73 fc1 W Adam 1 75 fc2 B 77 fc2 B Adam 79 fc2 B Adam 1 81 fc2 W 83 fc2 W Adam 85 fc2 W Adam 1 87 test embedding 89 train beta1 power 91 train beta2 power 93,,"skye,jart,jart",2017-10-24 18:33:11,2018-01-11 05:04:29
IS,tf1 2 1 can not build on Ubuntu 16 04 pyenv,I can not build tf1 2 1 from source on ubuntu 16 04 and pyenv tf1 0 tf1 1 are ok to be build normally System information Ubuntu 16 04 tf from git checkout r1 2 python 3 5 2 bazel 0 5 2 from deb CUDA 8 0 cudnn5 GTX 1080ti x2 python environment,,"aselle,aselle,jart",2017-07-25 05:21:01,2018-01-11 05:07:22
PR,fix a to allocator,Please review this PR ASAP,,zheng-xq,2018-01-10 07:55:45,2018-01-11 05:18:01
IS,Java JNI Object Detection Not big Difference with GPU or CPU Insignificant difference 300ms with and without GPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary by instructions Install on Linux Take the following steps to install TensorFlow for Java on Linux or macOS 1 Download libtensorflow jar which is the TensorFlow Java Archive JAR 2 Decide whether you will run TensorFlow for Java on CPU s only or with the help of GPU s To help you decide read the section entitled Determine which TensorFlow to install in one of the following guides Installing TensorFlow on Linux 3 Download and extract the appropriate Java Native Interface JNI file for your operating system and processor support by running the following shell commands TF TYPE gpu OS uname s tr ' upper ' ' lower ' mkdir p jni curl L TF TYPE OS x86 64 1 4 0 tar gz tar xz C jni TensorFlow version use command below 1 4 0 Python version n a not used here Java instead Bazel version if compiling from source n a not used here GCC Compiler version if compiling from source n a not used here CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 61 cuDNN 6 GPU model and memory GeForce 940MX Source code logs,,"asimshankar,asimshankar",2018-01-10 14:06:41,2018-01-11 06:11:54
PR,Adding cuda config h to the pip package,,,"av8ramit,av8ramit,av8ramit",2018-01-09 01:13:19,2018-01-11 07:14:13
IS,external eigen archive unsupported Eigen CXX11 Tensor 84 26 fatal error cuda runtime h No such file or directory,System information After run the tf env collect sh in my terminal i get this infomation cat etc issue Linux saners 4 10 0 32 generic 36 16 04 1 Ubuntu SMP Wed Aug 9 09 19 02 UTC 2017 x86 64 x86 64 x86 64 GNU Linux are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 4 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux saners 4 10 0 32 generic 36 16 04 1 Ubuntu SMP Wed Aug 9 09 19 02 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 13 1 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 4 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc1 1204 g084d29e tf COMPILER VERSION v1 3 0 rc1 1204 g084d29e Sanity check array 1 dtype int32 env LD LIBRARY PATH usr local cuda 8 0 lib64 usr local cuda 8 0 extras CUPTI include usr local cuda 8 0 include LD LIBRARY PATH DYLD LIBRARY PATH is unset nvidia smi Tue Aug 22 09 32 48 2017 NVIDIA SMI 375 82 Driver Version 375 82 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Quadro K620 Off 0000 01 00 0 On N A 34 40C P0 2W 30W 291MiB 1999MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage 0 1037 G usr lib xorg Xorg 142MiB 0 1867 G compiz 58MiB 0 2340 G el token 36B9BD8BE2E6AD02534077E8E73C38D9 89MiB cuda libs usr local cuda 8 0 lib64 libcudart static a usr local cuda 8 0 lib64 libcudart so 8 0 61 usr local cuda 8 0 doc man man7 libcudart 7 usr local cuda 8 0 doc man man7 libcudart so 7 Tensorflow version 'v1 3 0 rc1 1204 g084d29e' '1 3 0' Describe the problem when i use bazel build tensorflow examples android tensorflow demo in terminal i get the error ERROR home saners tensorflow tensorflow core kernels BUILD 4581 1 C compilation of rule ' tensorflow core kernels android tensorflow kernels' failed arm linux androideabi gcc failed error executing command external androidndk ndk toolchains arm linux androideabi 4 9 prebuilt linux x86 64 bin arm linux androideabi gcc fstack protector strong fpic ffunction sections funwind tables remaining 77 argument s skipped com google devtools build lib shell BadExitStatusException Process exited with status 1 In file included from third party eigen3 unsupported Eigen CXX11 Tensor 1 0 from tensorflow core kernels bias op gpu h 21 from tensorflow core kernels bias op cc 30 external eigen archive unsupported Eigen CXX11 Tensor 84 26 fatal error cuda runtime h No such file or directory include cuda runtime h compilation terminated Target tensorflow examples android tensorflow demo failed to build my tensorflow has installed normally but i do not know how to solve this problem Anyone can help me,,"gunan,gunan,gunan,gunan,gunan,gunan",2017-08-22 01:43:02,2018-01-11 07:44:01
IS,fail to convert resnet v1 50 to tflite,I downloaded resnet v1 50 model from when I tried to convert this model to tflite I got below error 2018 01 10 14 54 19 491608 F tensorflow contrib lite toco tflite export cc 303 Some of the operators in the model are not supported by the standard TensorFlow Lite runtime If you have a custom implementation for them you can disable this error with allow custom ops Here is a list of operators for which you will need custom implementations Mean Squeeze I use below command to convert bazel bin tensorflow contrib lite toco toco input file resnet v1 50 frozen pb input format TENSORFLOW GRAPHDEF output format TFLITE output file resnet v1 50 tflite inference type FLOAT input type FLOAT input arrays input output arrays resnet v1 50 predictions Reshape 1 input shapes 1 224 224 3 Does it means that tflite do not support op Mean and Squeeze,,,2018-01-10 07:43:17,2018-01-11 07:55:24
IS,getting attribute error,I executed the code and got this error File new1 py line 131 in main classifier tf estimator Estimator model fn model fn AttributeError 'module' object has no attribute 'estimator' pls help,,,2017-12-03 18:39:58,2018-01-11 09:36:46
IS,Bug in boolean input tensors for ops,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary pip3 install user tensorflow gpu TensorFlow version use command below 1 4 1 Python version 3 5 2 Bazel version if compiling from source NA GCC Compiler version if compiling from source gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 CUDA cuDNN version cuda 8 0 61 cudnn v6 GPU model and memory any Exact command to reproduce see description below You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Boolean tensors seem to have a bug In C I define an op with a boolean input tensor like so REGISTER OP SpatialAugmentationPossible Input input float32 Output output bool Input mirror bool Input angle float32 Input dx float32 Input dy float32 Input sx float32 Input sy float32 Attr crop width int Attr crop height int Note that mirror is a boolean tensor The op compiles fine When calling like this op ops spatial augmentation possible input test input mirror tf cast mirror dtype tf bool angle tf convert to tensor angle dtype tf float32 dx tf convert to tensor dx dtype tf float32 dy tf convert to tensor dy dtype tf float32 sx tf convert to tensor sx dtype tf float32 sy tf convert to tensor sy dtype tf float32 crop width 500 crop height 300 possible tensor sess run op I get 2018 01 11 14 57 45 722505 F tensorflow core framework tensor cc 586 Check failed dtype expected dtype 10 vs 1 I checked the proto 10 corresponds to boolean and 1 to float32 If I change the line with the mirror argument like this mirror tf cast mirror dtype tf float32 I get ValueError Tensor conversion requested dtype bool for Tensor with dtype float32 'Tensor Cast 0 shape 1 dtype float32 device device GPU 0 ' That means now it is complaining that I do not input a bool But the message above is saying that I should not input a bool For this reason there seems to be a bug Best Eddy,,,2018-01-11 14:02:20,2018-01-11 14:13:33
PR,Fix inline if else statement in CMAKE CACHE ARGS,An if else statement was given inline as an argument to CMAKE CACHE ARGS for some CMake external projects as discussed in 15209 This resulted in the following init cache entries on some systems This commit changes the inline if else arguments to DCMAKE POSITION INDEPENDENT CODE BOOL tensorflow ENABLE POSITION INDEPENDENT CODE which is functionality equivalent,,"yifeif,caisq",2018-01-10 13:05:09,2018-01-11 14:21:40
PR,Use https for,It looks like there are a couple of links in saved model md using http to point to serving and the rest are using https to point to serving This fix updates to https for consistency and security Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-11 05:41:24,2018-01-11 14:46:36
PR,Update embedding md,When I reference embedding projector I found the string of https was removed So I added it to help other people get a correct reference about How to Use t SNE Effectively from Embedding of Programmer is guides,,,2018-01-11 05:12:04,2018-01-11 14:47:53
PR,Add clean dep to a bazel macro,Currently copts macro has select statement with tensorflow This resulted in bazel error when any supermodule that uses tensorflow as a submoudle and uses copts macro,,"gunan,gunan,caisq",2018-01-07 04:36:44,2018-01-11 14:48:42
PR,Add clean dep to copts macro,Currently copts macro has select statement with tensorflow This resulted in bazel error when any supermodule that uses tensorflow as a submoudle and uses copts macro,,"gunan,gunan,caisq",2018-01-07 04:38:49,2018-01-11 14:50:41
PR,Utility classes for writing Java source code from a C process part 2,Part 2 of pull request 14094 that has been splitted into several commits This part features only a language agnostic writer that outputs generated source code into a file or in memory Note that this class is being kept apart from the Java specific code generators since it could be a good candidate to be moved in the core io library in the future ref 13748 cc,,"karllessard,asimshankar,asimshankar,karllessard,asimshankar,caisq",2018-01-07 16:51:22,2018-01-11 14:52:03
PR,Windows Release script for C library GPU builds on Windows,Fixed Can you also setup a job for GPU build using tensorflow tools ci build windows libtensorflow gpu sh like,,"meteorcloudy,asimshankar,asimshankar,asimshankar,meteorcloudy,meteorcloudy,meteorcloudy,av8ramit,meteorcloudy,angersson,meteorcloudy",2018-01-05 13:19:12,2018-01-11 15:03:42
IS,Crelu should have axis,Currently the tf nn crelu activation concatenates along the last axis This would work fine for dense layers and conv layers where the data fromat channels last but this would be incorrect if invoked on the widely used data format channels first for conv layers on the GPU,,yongtang,2017-12-25 02:06:17,2018-01-11 17:33:24
PR,Add axis support for tf nn crelu,This fix tries to address the issue raised in 15619 where it was not possible to specify an axis for tf nn crelu By default axis 1 was used for concatenation implicitly This fix adds the support of axis for tf nn crelu and adds test cases for it This fix fixes 15619 Signed off by Yong Tang yong tang github outlook com,,"yongtang,caisq,yongtang,caisq,yongtang,yongtang,asimshankar,caisq,yongtang,caisq",2018-01-04 06:21:58,2018-01-11 17:33:24
IS,Feature request Reduce learning rate on plateau,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes But applies to stock examples as well OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary Binary TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version Python 3 5 4 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version CUDA V8 0 61 cuDNN 6 0 21 GPU model and memory GTX 1080Ti 11GB running driver version 384 98 Exact command to reproduce N A However I am using the Experiment Estimator and Dataset APIs in order to do training Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I would like to reduce the learning rate during training However I do not want to treat this as another tunable hyperparameter so I would like this to be based on performance plateauing In Keras it is easy to implement learning rate reduction by monitoring the validation loss using the ReduceLROnPlateau callback function but in TensorFlow this does not seem to be the case easy I certainly have not found any implementation of this so I propose this as a feature request Feel free to close this if this is not the correct forum Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"shivaniag,martinwicke,martinwicke",2018-01-09 22:49:36,2018-01-11 17:51:34
IS,tf data Dataset padded batch does not work with dataset map using tf py func,System information Have I written custom code yes OS Platform and Distribution CentOS Linux release 7 2 1511 TensorFlow installed from pip TensorFlow version use command below 1 4 1 Python version 2 7 5 Describe the problem It is quite common for NLP tasks to read variable length sentences from text files to map them and to padd them But Dataset padded batch does not work with tf dataset which uses map tf py func Source code,,mrry,2018-01-11 05:44:19,2018-01-11 17:56:46
IS,TypeError Input isplit dim' of 'Split' Op has type float32,Hi I use Tensorflow 1 5 0rc0 on windows Python 3 5 2 and I have this issue TypeError Input isplit dim' of 'Split' Op has type float32 that does not match expected type of int32 I have seen some answers for older versions of tensor flow but is there any fix for the new version,,,2018-01-08 18:10:04,2018-01-11 18:37:16
IS,lib package does not bundle MKL DNN,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 1 Python version 2 7 12 Bazel version if compiling from source 0 8 1 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem I wa not to build the tensorflow C API from source with MKL DNN support in order to use it in another project The easiest solution if not the only convenient one I found for building the C API is using the lib package tool Is there a way to fix the Bazel build such that it outputs all necessary libs,,asimshankar,2018-01-10 14:47:46,2018-01-11 18:49:00
IS,Link gives 404,installation gives 404,,,2018-01-11 12:54:49,2018-01-11 19:19:48
PR,Hide MSVC workaround from Clang on Windows,15990,,"rongjiecomputer,caisq",2018-01-10 01:51:56,2018-01-11 20:58:23
IS,bug about tensorflow can not call opencv imread properly,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 Python version 2 7 but actually i am talking about c code Bazel version if compiling from source 0 5 4 0 7 0 all tried GCC Compiler version if compiling from source 4 8 4 CUDA cuDNN version N A GPU model and memory CPU mode Exact command to reproduce bazel run c opt tensorflow cc face face Describe the problem i add opencv as a third party lib to tensorflow and modify the workspace and BUILD file to include it to the project it works well when i use tensorflow 1 2 1 or version before it recently i update my tensorflow to the newest version it recommand i must update my bazel at least 0 5 4 i use 0 5 2 with jdk7 before and when i update bazel and move my own code to the new project compiling seems ok but when i run the binary it seems not right i can not load a jpeg file when i use cv imread it does not crash but return a cv Mat with size 0 in the new project i can load a bmp file properly so i guess it is because the project does not link the libjpeg but i never need to link the libjpeg manually because it is included in the opencv library so i guess there is a bug in the new version of tensorflow i have tried the linkopt with ljpeg but it does not work Source code logs WORKSPACE File new local repository name opencv path usr local build file opencv BUILD BUILD file of opencv cc library name opencv srcs glob lib so hdrs glob include hpp includes include visibility visibility public linkstatic 1 BUILD file of my code tf cc binary name face srcs face cc includes deps tensorflow cc cc ops tensorflow cc client session tensorflow core tensorflow opencv opencv copts fopenmp linkopts lgomp ljpeg my code cv Mat img cv imread pic jpg std cout line img channels img cols img rows endl the log will be pic jpg 1 0 0 but if i read a bmp file cv Mat img cv imread pic bmp std cout line img channels img cols img rows endl the log will be pic bmp 3 500 355,,"aselle,martinwicke,martinwicke",2017-11-23 08:16:13,2018-01-11 22:18:57
IS,tf keras backend set learning phase does not work during evaluating model,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip install tensorflow gpu TensorFlow version use command below 1 4 0 Python version 3 5 2 Exact command to reproduce Describe the problem When I run following script error InvalidArgumentError see above for traceback You must feed a value for placeholder tensor 'block1 conv1 bn keras learning phase' with dtype bool occured After searching in keras repository and stackoverflow I find it is caused by the design of learning phase parameter of BN layers which behave differently at training and testing time See here fchollet have added K set learning phase for tensorflow to solve this problem So when I use keras instead of tf keras no issue is reported I wonder if this part is still not integrated into tensorflow completely Source code logs,,"fchollet,fchollet,fchollet,fchollet",2017-12-14 15:15:40,2018-01-11 22:31:41
PR,Enable axis support for tf unique,The axis support for Unique has been Added in PR 12952 defined in UniqueV2 ops The support for axis in python version of the tf unique was not enabled yet due to the API workflow porcess 3 weeks This fix adds the support for axis with tf unique by adds Unique to hidden txt and adds a python wrapper of tf unique to pointing to UniqueV2 This fix addresses part of the issue 15644 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,yongtang,drpngx,yongtang,yongtang,drpngx,yongtang,drpngx,yongtang,drpngx,yongtang,drpngx,yongtang,drpngx,drpngx,vrv,yongtang,annarev,asimshankar,yongtang,yongtang,martinwicke,yongtang,martinwicke,yongtang,annarev,yongtang,drpngx,yongtang,martinwicke",2017-12-27 12:07:40,2018-01-11 22:40:30
IS,Bug Feature constant folding FP16,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 RHEL 7 TensorFlow installed from source or binary Source TensorFlow version use command below 'v1 3 0 rc1 6207 ge210cb1' '1 4 0' Python version python2 7 Bazel version if compiling from source bazel 0 9 0 GCC Compiler version if compiling from source gcc 4 8 Exact command to reproduce python tensorflow models tutorial images convolutional py use fp16 Describe the problem When using FP16 in e g the case listed above the following error occurs E tensorflow core grappler optimizers constant folding cc 1272 Unexpected type half E tensorflow core grappler optimizers constant folding cc 1242 Unexpected type half When looking into constant folding cc i found out FP16 support exists at given lines but is commented out Why is this not yet included in Tensorflow As far as I can see this is more of a feature request than a bug report since these code lines simply check if computational effort can be reduced if the matrix is zero or one Also when using above command the model trains until step 1100 then the learning rate drops to 0 a known FP16 problem Still it is annoying to encounter this in an official tutorial file,,"jart,rmlarsen,rmlarsen",2017-12-20 16:09:52,2018-01-11 23:03:48
PR,Apply 1 5 rc1 cherry picks,,,"angersson,angersson,angersson,gunan",2018-01-11 22:49:23,2018-01-12 00:38:14
IS,Building TensorFlow on Windows patch and rm,System information Have I written custom code Yes provided below OS Platform and Distribution Windows 10 1709 Build 16299 192 TensorFlow installed from source or binary Binary Attempting source build of master TensorFlow version 1 4 0 Python version 3 6 Bazel version 0 9 0 GCC Compiler version MSYS2 Shell GCC unknown CUDA cuDNN version N A GPU model and memory N A CPU is i7 8550U 8 GB memory Exact command to reproduce Any bazel build on Windows Please see Description Describe the problem Building TensorFlow on Windows has been a struggle with compatibility due to the fact that for many MSYS will not run patch when installed from the MSYS2 shell I have found a reliable way to resolve the issue using Choco to install patch moving patch exe to a folder FOLDERNAME within its default directory and then running FOLDERNAME patch exe with the flag binary to use CR LF line breaks with a custom batch script compiled into a executable bazel build now completes patch commands without issue But as it often is another hurdle exists to the finish line Bazel now attempts to recursively force remove a file using rm rf which obviously does not exist as a package in Choco as a bash command MSYS will run it but not from the command line Is there any way to get around the use of rm or make a compatible solution for Windows using del I have ensured that 15829 has been installed Still fails If this is better left to the Bazel developers please close this issue Source code patch bat,,"shivaniag,mrry,meteorcloudy",2018-01-08 15:32:59,2018-01-12 01:43:52
IS,tensorflow lite converter why empty lite file,I have a tensorflow pb file and try to use tflite converter to convert it to lite file but the result file is empty and no error I do not know why bazel run config opt copt msse4 1 copt msse4 2 tensorflow contrib lite toco toco input file Users Lavector code keras to tensorflow mobilenet regression pb output file tmp mobilenet regression lite input format TENSORFLOW GRAPHDEF output format TFLITE inference type FLOAT input shape 1 224 224 3 input array input output array output node0 WARNING Config values are not defined in any rc file opt INFO Analysed target tensorflow contrib lite toco toco 0 packages loaded INFO Found 1 target Target tensorflow contrib lite toco toco up to date bazel bin tensorflow contrib lite toco toco INFO Elapsed time 0 223s Critical Path 0 01s INFO Build completed successfully 1 total action INFO Running command line bazel bin tensorflow contrib lite toco toco ' input file Users Lavector code keras to tensorflow mobilenet regression pb' ' output file tmp mobilenet regression lite' ' input format TENSORFLOW GRAPHDEF' ' output format TFLITE' ' inference type FLOAT' ' input shape 1 224 224 3' ' input array input' ' output array output node0' 2017 12 21 11 20 11 351544 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 472 operators 695 arrays 0 quantized 2017 12 21 11 20 11 384604 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 85 operators 200 arrays 0 quantized 2017 12 21 11 20 11 387067 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before dequantization graph transformations 85 operators 200 arrays 0 quantized I use mobilenet to do regression and it is successful when test I test the example code of url and it is correct,,,2017-12-21 03:19:09,2018-01-12 02:08:18
IS,Code documentation for confusion matrix py misleading,Describe the problem The documentation for confusion matrix py says,,"shivaniag,mrry",2018-01-11 14:25:22,2018-01-12 02:11:58
PR,Branch 181629980,,,"frankchn,frankchn,frankchn",2018-01-11 19:10:21,2018-01-12 02:45:09
IS,AttentionWrapper zero state batch size tf float32 clone cell state encoder state fails when batch size is 1,Hello I believe to have found a small bug when using the zero state batch size tf float32 clone cell state encoder state command When batch size is 1 the error ValueError The shape for decoder while Merge 5 0 is not an invariant for the loop It enters the loop with shape 1 512 but has shape 512 after one iteration Provide shape invariants using either the shape invariants argument of tf while loop or set shape on the loop variables is thrown This error does not occur when batch size is 2 or larger The error also does not occur if I remove the clone command I tried investigating where the error is but could not find the cause I'm using this in context of trying to build a neural transducer but also get the same error for basic seq2seq Based on the NMT tutorial I believe this is an important issue as often times when experimenting with new seq2seq models I start off with trying to get it to work for a batch size of 1 Thanks Nikita,,"ebrevdo,ebrevdo,oahziur,ebrevdo,oahziur,ebrevdo,ebrevdo,oahziur",2017-12-30 18:04:33,2018-01-12 02:46:30
IS,NNAPI libneuralnetwors so does not work for other models than default mobilenet quant v1 224 tflite,I have made changes to tensorflowlite to force it use nnapi on my android 8 1 phone and the nnapi only worked normally for the default default mobilenet quant v1 224 tflite The nnapi libneuralnetworks so did not work for the tensorflow inception graph tflite inside the attached asserts zip which was built by toco from tensorflow inception graph pb of My steps 1 generated tensorflow inception graph tflite from tensorflow inception graph pb by toco 2 add 7 extra lines to labels txt a nb nc nd ne ng ng 3 copy new labels txt and tensorflow inception graph tflite to my bazel cache 4 apply the attached patch a txt to tensorflow 5 bazel build cxxopt std c 11 tensorflow contrib lite java demo app src main TfLiteCameraDemo config android arm64 cpu arm64 v8a fat apk cpu arm64 v8a 6 adb install r apk file If the nnapi is not forced to use then the apk run normally though the results are wrong But if I forced it to use nnapi then the apk crashed I guess the tensorflow inception graph tflite contained some operators which were not supported by nnapi libneuralnetwors so How can I confirm it Thank you a txt assets zip,,,2018-01-11 10:35:06,2018-01-12 02:50:35
PR,Branch 181679271,Merging internal changes,,"zheng-xq,caisq",2018-01-12 01:17:21,2018-01-12 04:00:51
IS,Feature request EASGD,EASGD is a very useful algorithm for distributed asynchronous training which based on an elastic force which links the parameters of workers with a center variable stored by the parameter server This allows the local variables to fluctuate further from the center variable which in theory allows for more exploration of the parameter space In practice I find it usually outperforms ordinary ASGD I have been working on it for some days and I can make a pull request if you are interested in it The link address of the paper Deep learning with Elastic Averaging SGD,,,2017-08-22 03:11:56,2018-01-12 04:16:45
IS,Which CUDA cuDNN version should I chose for tf 1 50,eo hqbj vt 49a35ztc,,,2018-01-12 01:36:36,2018-01-12 06:47:47
IS,raise PiCameraMMALError status prefix picamera exc PiCameraMMALError Failed to enable connection Out of resources,,,,2018-01-11 11:14:55,2018-01-12 06:55:18
PR,fix C2678 error on VS2017 15 5,fix build fail on Visual Studio 2017 15 5 error log 1 tf core kernels Debug x64 1 sparse column iterable cc 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 error C2678 ' ' 'const tensorflow boosted trees utils anonymous namespace' IndicesRowIterator' 1 C Users User tensorflow tensorflow contrib boosted trees lib utils sparse column iterable cc 54 note 'const int64 tensorflow boosted trees utils anonymous namespace' IndicesRowIterator operator void ' 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 note ' const tensorflow boosted trees utils anonymous namespace' IndicesRowIterator ' 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2439 note ' FwdIt std Lower bound unchecked Iter Ty Fn FwdIt FwdIt const Ty Pr ' 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Iter tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 Fn std less void 1 Pr std less void 1 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2447 note ' FwdIt std lower bound FwdIt Ty std less void FwdIt FwdIt const Ty Pr ' 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 Pr std less void 1 1 C Users User tensorflow tensorflow contrib boosted trees lib utils sparse column iterable cc 119 note ' FwdIt std lower bound tensorflow boosted trees utils anonymous namespace' IndicesRowIterator tensorflow int64 FwdIt FwdIt const Ty ' 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 error C2100 1 tf core kernels vcxproj 0 1 0 0,,fo40225,2018-01-11 14:51:39,2018-01-12 15:33:36
PR,Fix typo,,,"ManHyuk,mrry",2018-01-12 12:20:50,2018-01-12 16:54:22
PR,Show CCI badge in README,Fixes 7645,,martinwicke,2017-12-21 18:58:11,2018-01-12 18:41:36
PR,Windows Batch script for building the CUDA enabled C library,Follow up to PR 15878 to help resolve 11602,,asimshankar,2018-01-11 19:52:02,2018-01-12 19:00:13
PR,Update version strings and revert pom xml changes,The maven numbers will be updated manually later,,angersson,2018-01-10 22:27:51,2018-01-12 19:24:46
IS,Document Bazel Tensorflow Cuda interdependencies,Since each version of Tensorflow appears to require some specific release of bazel it would be helpful to have documentation like this tested source configurations also for people who are stuck on an older version of CUDA For instance I cannot upgrade to CUDA 8 on the machine I am using and am now left with the exercise of finding a working config in a space of 5 dimensions python version bazel version tf version cuda version cudnn version I had it once working with CUDA 7 0 and python 3 5 and I think bazel 0 3 but cannot reproduce now In this concrete case I am trying to build r0 11 with python 3 6 cuda 7 5 cudnn 6 and bazel 0 3 0 4 0 8 and nothing is working,,,2017-12-27 16:04:11,2018-01-12 20:01:36
PR,MKL DNN fix a concat issue which is related to negative concat dim,For a negative concat dim input the actual concat dim should be N concat dim with N being the dims of input tensors This PR fixes an issue of setting N properly,,,2018-01-12 19:37:56,2018-01-12 20:35:37
IS,TensorForest feature request multi output label support,Looking at the code for TensorForest it appears that it only allows multiclass including binary classification or regression scalar and vector However there does not seem to be an obvious way to do a multi output classification setup in which there are multiple binary tasks that should all be predicted by a single model Could this feature be implemented or would you be able to guide in the easiest hack to convert to a multi output setup Apologies if this should actually go to Stack Overflow please let me know Thank you,,shivaniag,2017-10-05 21:35:13,2018-01-12 20:46:17
PR,Update important RELNOTES and author list,,,angersson,2018-01-12 19:14:08,2018-01-12 20:51:36
PR,MKL Fixed 3 bugs picked up by the unit tests,There were 2 kinds of registrations for MatMul with and without the 'eigen' label Re added the registrations with the 'eigen' label when MKL is used Removed the ifdef that removed the check for the label when MKL was used The eigen op should be called when the eigen label is used In the selective registration header test unicode strings are not handled correctly so there is a u before the kernel class string that is compared to the hardcoded string This has been fixed,,vivek-rane,2018-01-11 22:10:37,2018-01-12 20:52:14
PR,Branch 181765083,,,"frankchn,frankchn,frankchn",2018-01-12 19:16:43,2018-01-12 21:26:35
IS,is there a way to restore and predict without doing dummy training,We are trying text classification py example of tensorflow and separated the training and prediction parts of the code and trained the model using model dir and tried to predict using the same model dir Model is being saved but when we comment the training code and try to predict something we get the following error InvalidArgumentError see above for traceback Assign requires shapes of both tensors to match lhs shape 10 50 rhs shape 5386 50 Node save Assign Assign T DT FLOAT class loc EmbedSequence embeddings use locking true validate shape true device job localhost replica 0 task 0 cpu 0 EmbedSequence embeddings save RestoreV2 Where 5386 and 10 are words count in training and prediction data But when we uncomment the preparation of train input fn without using it anywhere in the code without training the model but using the same model dir then prediction works fine train input fn tf estimator inputs numpy input fn x WORDS FEATURE x train y y train batch size len x train num epochs None shuffle True We are wondering what exactly is being done by this function which actually overcome the error without training the model using the function at all We have gone through many posts but following post looks more relevant where someone said that prediction can not be done without doing at least some training though the model was already trained and restored using model dir System information Tried both Python 2 7 6 Python 3 4 3 TF Version 1 3 0 python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 1 0 rc0 61 g1ec6ed5' '1 1 0',,"martinwicke,martinwicke,facaiy,ispirmustafa,ispirmustafa",2017-10-25 14:44:13,2018-01-13 00:22:55
PR,Disable flaky model analyzer test on windows,PiperOrigin RevId 180599588,,av8ramit,2018-01-13 00:28:54,2018-01-13 00:29:31
IS,TFGAN not compatible with eager execution mode,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Colaboratory Google Compute Engine backend not sure about OS here TensorFlow installed from source or binary binary non GPU version TensorFlow version use command below 1 5 0 dev20180102 Python version 3 Describe the problem When enabling eager execution mode because of the following lines L119 L121 Are there any plans to make TFGAN compatible with eager in the short term Is there any help wanted in this regard I would be happy to contribute,,"asimshankar,iganichev,iganichev,iganichev,joel-shor,joel-shor",2018-01-03 16:08:13,2018-01-13 00:53:50
PR,Fix typo,,,ManHyuk,2018-01-12 16:54:56,2018-01-13 01:52:30
PR,Optimize FusedBatchNormGrad,Reuse the output buffer and allocate only one temporary tensor when data format is NHWC and GPU is used This is based on the observation that cudnn can perform the backward computation in place The same idea is used in PR 15601 This lowers GPU memory consumption and may improve performance because fewer distinct memory addresses are accessed It also permits a higher batch size I have also added a new test for the gradient computation,,"codrut3,drpngx,zhangyaobit,zheng-xq,codrut3,nluehr,zhangyaobit",2017-12-24 10:38:20,2018-01-13 02:08:45
PR,the loss is nan,when i training the facenet build by myself the loss is normal on the first iteration but on the second and following iteration the loss became nan i do not know what happened please help me Thanks,,caisq,2018-01-12 05:50:20,2018-01-13 03:50:46
PR,Branch 181814918,,,zheng-xq,2018-01-13 02:23:26,2018-01-13 04:08:35
PR,Windows Override DEIGEN STRONG INLINE inline for tensorflow core kernels conv ops,This change reduces the Windows building time by more than 15 minutes Fix 10521,,"meteorcloudy,gunan,meteorcloudy,meteorcloudy,meteorcloudy,gunan,meteorcloudy,gunan,meteorcloudy,meteorcloudy",2018-01-08 15:22:06,2018-01-13 04:52:14
PR,add label image for tflite,label image for TensorFlow Lite is inspired by TensorFlow is label image a command line app to load and run classifier models,,"freedomtan,freedomtan,freedomtan,freedomtan,freedomtan,freedomtan,freedomtan,freedomtan,freedomtan,drpngx,freedomtan,drpngx",2017-12-04 12:30:47,2018-01-13 04:57:20
PR,improve py func,See 14448 Improved py func to accept nested structures as input and as output like in tf data Dataset form generator relable inp to args and Tout to output types add arguments kwargs and output shapes allow args kwargs output types output shapes to be a nested structure Open questions allow output types to be callable Dynamic output types inference from args kwargs new argument names backward compatibility for old names,,"boeddeker,alextp,alextp,alextp,boeddeker,boeddeker,boeddeker,alextp,drpngx,boeddeker,martinwicke,caisq,martinwicke,boeddeker,alextp,boeddeker,boeddeker,alextp,alextp,yifeif,yifeif,boeddeker,alextp,drpngx,boeddeker,martinwicke,drpngx,drpngx,yifeif,boeddeker,drpngx,boeddeker,yifeif",2017-12-05 10:08:33,2018-01-13 04:58:13
IS,CTC decoding with dictionary,Is there a possibility to use the CTC decoding algorithms provided by TF with a word dictionary I have seen that there is some testing code which seems to do just what I want Is there a Python interface for this task Or do I have to build a custom operation out of the code shown above to be usable in Python EDIT solved it by implementing custom op,,reedwm,2017-08-17 10:54:01,2018-01-13 10:29:51
PR,Address bad merge in Java install instructions,,,"asimshankar,av8ramit,av8ramit",2018-01-13 07:25:31,2018-01-13 18:36:04
IS,Keras tfdbg error Dump root directory does not exist,Problem I'm running the tf debugger and specifically am looking for nans and infs I'm doing this from keras using the tf backend by setting the keras sess to tf Session wrapped with the debugger MVCE Inside the debugger execute run f has inf or nan Traceback OSError Dump root directory tmp tfdbg dm3xvee9 does not exist Additional info 7615 references the same error a while ago and gives similar traceback System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Fedora 4 11 5 200 fc25 x86 64 TensorFlow installed from source or binary binary TensorFlow version use command below tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 Python version 3 6 CUDA cuDNN version Cuda 8 0 cuDNN v6 GPU model and memory Quadro M2000M 4042MiB,,"caisq,caisq",2017-10-10 10:29:17,2018-01-13 19:43:20
IS,Feature request add tf layers Group to group multiple layers under one name,Example usage relevant for networks with skip connection i e u net Currently you could either use network get output at however this requires to track node indices or parse network layers if encoders are not symmetric i e some encoder have no batch norm dropout inherit from tf layers Layer however documentation is not clear on how to forward variables for example,,"drpngx,martinwicke,yaroslavvb",2017-09-27 10:22:51,2018-01-13 20:44:11
IS,Shape must be rank 1 but is rank 0 for 'CTCLoss' op 'CTCLoss',Have I written custom code yes OS Windows 8 1 Tensorflow installed from conda Tensorflow version 1 4 I have successfully converted a Tensor into a SparseTensor with this code Unfortunately when I do this I encounter this error Shape must be rank 1 but is rank 0 for 'CTCLoss' op 'CTCLoss' with input shapes 80 1,,"selcouthlyBlue,selcouthlyBlue,selcouthlyBlue",2018-01-13 04:41:46,2018-01-13 23:20:07
PR,Optimize FusedBatchNorm and fix a bug,I discovered experimentally that cudnn computations can be performed in place Therefore there is no need to allocate two temporary tensors in FusedBatchNorm for GPU and data format NHWC One is enough This lowers memory consumption and hence increases the maximum possible batch size This might seem risky because NVIDIA does not mention the property but in fact the current implementation already uses it by doing forward input or allocate output in FusedBatchNormOp If data format is NCHW and the input is forwarded then cudnn would be forced to do the computation in place see line 247 This is how I discovered that the whole approach works I was trying to see if forwarding the input is a bug or not I added several tests to ensure that the change is correct While doing this I discovered that ops testutil does not properly synchronize at the end The reason seems to be the call context eigen gpu device synchronize Somehow it does nothing I think the problem is that Eigen is not compiled with the flag EIGEN CUDACC So I changed it to GPUUtil Sync device get,,"codrut3,drpngx,zhangyaobit,codrut3,drpngx",2017-12-23 13:22:22,2018-01-13 23:45:21
IS,Estimator does not not support sparse jobs,You need sparse jobs if you want async training to proceed without having all workers available This currently does not work because estimator uses json L379 to dump values into TF CONFIG env var and json does not allow numeric keys json dumps automatically converts numeric keys into strings However clusterspec for sparse job must have integers like local 37 localhost 0 and will crash if we have 37 instead of 37 Suggestion 1 Modify sparse job support to allow strings as task indices Suggestion 2 use pickle base16 encoding to transmit these values Base16 is shell friendly it allows you to copy paste the value into export TF in terminal cc,,"yaroslavvb,yaroslavvb,xiejw,xiejw,yaroslavvb,xiejw,yaroslavvb,xiejw",2017-11-12 18:04:38,2018-01-14 02:55:03
IS,R1 4 restore a model from r0 8 encounter NotFoundError see above for traceback Tensor name,When using tf1 4 to restore a model from tf0 8 I met a NotFoundError the related code as flow ema tf train ExponentialMovingAverage 1 0 saver tf train Saver ema variables to restore model checkpoint path ' model check point model 20160506 ckpt 500000' saver restore sess model checkpoint path The error as flow NotFoundError see above for traceback Tensor name incept3a in3 conv5x5 8 batch norm moments Squeeze ExponentialMovingAverage not found in checkpoint files model check point model 20160506 ckpt 500000 Node save RestoreV2 46 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 device CPU 0 arg save Const 0 0 save RestoreV2 46 tensor names save RestoreV2 46 shape and slices Node save RestoreV2 315 35 Recv client terminated false recv device job localhost replica 0 task 0 device GPU 0 send device job localhost replica 0 task 0 device CPU 0 send device incarnation 1 tensor name edge 702 save RestoreV2 315 tensor type DT FLOAT device job localhost replica 0 task 0 device GPU 0 How can I solve this problem,,,2018-01-14 09:50:49,2018-01-14 09:51:08
IS,Implement Scale Operate,System information Have I written custom code No OS Platform and Distribution openSUSE Leap 42 3 TensorFlow installed from binary TensorFlow version tensorflow gpu 1 4 0 Python version 2 7 13 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory 11GB Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request In Caffe Scale layer could do this top alpha bottom beta where bottom is the input top is the output alpha and beta are the learnable params In Tensorflow what operate could implement above layer Thanks Help a lot,,,2018-01-14 10:00:00,2018-01-15 00:02:38
IS,Feature Request Dense to Sparse and Dense to Sparse Tensor Ops,I think it would be helpful if there is a dense to sparse op in Tensorflow for ops like ctc loss that requires sparse labels I'm not really sure where else it can be used aside from that but in case only ctc loss uses it I think it would help if dense labels can be passed into ctc loss and do the conversion within,,"selcouthlyBlue,shivaniag,mrry,selcouthlyBlue,ebrevdo,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,ebrevdo,selcouthlyBlue,ebrevdo,selcouthlyBlue,ebrevdo,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,ebrevdo,selcouthlyBlue,ebrevdo,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue,selcouthlyBlue",2018-01-09 23:19:33,2018-01-15 04:43:23
PR,Disable stacktrace handler test becase stack trace is not generated on Windows,Fix,,"meteorcloudy,meteorcloudy,gunan,meteorcloudy",2018-01-15 08:16:44,2018-01-15 08:57:31
PR,fix typo,,,ManHyuk,2018-01-15 06:44:06,2018-01-15 08:58:22
PR,R1 5,just want to download the code as samples of how to access tensorflow using C code,,,2018-01-14 00:32:06,2018-01-15 08:58:36
PR,Windows Remove j option when zip libtensorflow package,Fix,,meteorcloudy,2018-01-11 12:05:11,2018-01-15 08:59:30
PR,Test remove force inline DO NOT MERGE,This is only a test for fixing please do not merge this PR,,"meteorcloudy,meteorcloudy,meteorcloudy,meteorcloudy,meteorcloudy",2017-12-11 09:28:47,2018-01-15 14:31:23
PR,fix comments and code matches,,,caisq,2018-01-12 13:39:17,2018-01-15 16:06:45
PR,Fix broken python3 build,Currently building tensorflow master branch with python3 fails with following error message It seems that the 3 newly added third party BUILD scripts from are missing srcs version PY2AND3 part which all the other py library modules have I'm using bazel 0 5 4 on linux ubuntu 16 04 to build the current master branch,,caisq,2018-01-15 11:00:22,2018-01-15 17:30:36
IS,Missing documentation for using the Dataset API in combination with image summaries,The Dataset API is now the recommended input pipeline however I am missing some guidance on how to include summaries of my images This is what I would do intuitively but since map uses a different thread and therefore a different tf Graph instance the summaries are lost What is the recommended way of adding image summaries when using the Dataset API I would like to request a comment example on that in the official docs,,"drpngx,MarkDaoust",2017-12-08 02:32:28,2018-01-15 21:06:34
IS,Python tensorflow module cannot be reloaded bug,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 confirmed on both Ubuntu 16 04 LTS in VirtualBox and OS X 10 12 6 TensorFlow installed from source or binary installed via pip TensorFlow version use command below 'v1 4 0 19 ga52c8d9b01' '1 4 1' Python version Python 2 7 13 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce import tensorflow as tf reload tf You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Simple bug Trying to reload the module causes a failure Not a major problem in general but troublesome for the task which is automated testing of the tensorflow Python API using TSTL The exact sequence is trivial import tensorflow as tf reload tf Traceback most recent call last File stdin line 1 in module File Library Frameworks Python framework Versions 2 7 lib python2 7 site packages tensorflow init py line 40 in module del python NameError name 'python' is not defined Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"gunan,drpngx,drpngx,drpngx",2017-12-30 22:51:59,2018-01-15 21:07:10
IS,download dependencies sh fails for r1 5 and master,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary Source TensorFlow version use command below r1 5 Python version 3 6 Anaconda Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 1 or 4 8 4 tried both CUDA cuDNN version CUDA 8 0 and cuDNN 6 0 21 or cuDNN 5 0 5 tried both GPU model and memory 4x NVIDIA GTX Titan X 12GB Exact command to reproduce sh tensorflow contrib makefile download dependencies sh Describe the problem I have put together a script to build a distribution of TensorFlow for C development Part of this script invokes tensorflow contrib makefile download dependencies sh However this fails with the following output truncated error is the same for each subsequent download downloading tensorflow contrib makefile download dependencies sh 61 tensorflow contrib makefile download dependencies sh not found tensorflow contrib makefile download dependencies sh 63 tensorflow contrib makefile download dependencies sh not found downloading p tensorflow contrib makefile download dependencies sh 61 tensorflow contrib makefile download dependencies sh not found tensorflow contrib makefile download dependencies sh 63 tensorflow contrib makefile download dependencies sh not found downloading tensorflow contrib makefile download dependencies sh 61 tensorflow contrib makefile download dependencies sh not found tensorflow contrib makefile download dependencies sh 63 tensorflow contrib makefile download dependencies sh not found downloading z tensorflow contrib makefile download dependencies sh 61 tensorflow contrib makefile download dependencies sh not found tensorflow contrib makefile download dependencies sh 63 tensorflow contrib makefile download dependencies sh not found downloading It appears that maybe the download URL is are out of date If this is indeed a bug it should be reproducible on Linux with the attached script which should be sufficiently commented Source code logs See attached script build tf txt,,,2018-01-15 19:28:34,2018-01-16 00:40:45
PR,Fix typo,fix typo,,ManHyuk,2018-01-16 01:15:27,2018-01-16 01:15:55
IS,Cannot compile with Visual Studio 15,If I build a version of the current tensorflow version 1 5 0RC on Windows with CMAKE and Visual Studio 15 following error is occurred 1 sparse column iterable cc 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 error C2678 binary ' ' no operator found which takes a left hand operand of type 'const tensorflow boosted trees utils anonymous namespace' IndicesRowIterator' or there is no acceptable conversion 1 D tensorflow tensorflow contrib boosted trees lib utils sparse column iterable cc 54 note could be 'const int64 tensorflow boosted trees utils anonymous namespace' IndicesRowIterator operator void ' 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 note while trying to match the argument list ' const tensorflow boosted trees utils anonymous namespace' IndicesRowIterator ' 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2439 note see reference to function template instantiation ' FwdIt std Lower bound unchecked Iter Ty Fn FwdIt FwdIt const Ty Pr ' being compiled 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Iter tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 Fn std less void 1 Pr std less void 1 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2447 note see reference to function template instantiation ' FwdIt std lower bound FwdIt Ty std less void FwdIt FwdIt const Ty Pr ' being compiled 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 Pr std less void 1 1 D tensorflow tensorflow contrib boosted trees lib utils sparse column iterable cc 119 note see reference to function template instantiation ' FwdIt std lower bound tensorflow boosted trees utils anonymous namespace' IndicesRowIterator tensorflow int64 FwdIt FwdIt const Ty ' being compiled 1 with 1 1 FwdIt tensorflow boosted trees utils anonymous namespace' IndicesRowIterator 1 Ty tensorflow int64 1 1 C Program Files x86 Microsoft Visual Studio 2017 Enterprise VC Tools MSVC 14 12 25827 include algorithm 2417 error C2100 illegal indirection 1 Done building project tf core kernels vcxproj FAILED This problem is also discussed in 12000 after closing this issue System information tensorflow 1 5 0RC Windows 10 VisualStudio Prof 2017 CMake 3 10 1,,,2018-01-11 19:21:34,2018-01-16 06:46:52
IS,Is it possible to train CNN model by using tensorflow JAVA API,Hello TF I have plane to train my CNN model by using tensorflow JAVA API I got success on simple model with a simple matmul operation between weights and bias BUT I failed to train CNN model,,asimshankar,2018-01-16 06:15:29,2018-01-16 07:20:47
IS,ValueError Labels are incompatible with given information,Have I written custom code yes OS Windows 8 1 Tensorflow installed from conda Tensorflow version 1 4 I am having problems in adding validation monitors to Estimator fit With this code I have It throws this error ValueError Labels are incompatible with given information Given labels Tensor random shuffle queue DequeueUpTo 3 shape 37 dtype int32 required signatures TensorSignature dtype tf int32 shape TensorShape Dimension None Dimension 33 is sparse False Which leads me to think that the dynamic label lengths are not accepted To reproduce this simply clone this repository and run the script specified in the readme,,"selcouthlyBlue,selcouthlyBlue",2018-01-16 08:43:19,2018-01-16 09:31:29
IS,While loop randomly does not evaluate tensors,Hello I believe to have found a bug in Tensorflow when running the code below I am currently trying to build a neural transducer and have stumbled across TF sometimes not returning any values for a tensor I have not had the chance yet to test this out on another machine no GPU TF 1 4 1 Ubuntu 17 10 The code is redacted a bit to highlight only the parts that fail I have also posted to StackOverflow but did not get any response there Notes I believe the bug occurs around line 160 in the body of the while loop in the function run full transducer The session is returning encoder outputs transducer outputs I do not use random functions As far as I can tell if I remove the Print OP in line 164 the output is always 0 Example of a correct return value more or less System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 10 Artful Aardvark TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce Execute the code block as a python file a few times Thanks Nikita,,"ebrevdo,ebrevdo",2018-01-09 19:58:14,2018-01-16 10:11:51
IS,Ca not access gs logfiles using tensorboard,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 2 1 Python version 3 6 Exact command to reproduce tensorboard logdir gs Describe the problem When trying to run tensorboard from a google cloud storage bucket the following error occurs tensorflow python framework errors impl UnimplementedError File system scheme gs not implemented Even after running gs authentication gcloud auth application default login Source code logs I was following this guide on training a pet object detector,,"drpngx,rinugun,jhseu,dandelionmane,jhseu,jhseu,drpngx,drpngx,jart",2017-07-04 20:45:25,2018-01-16 11:10:25
IS,q,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-16 12:22:34,2018-01-16 14:56:00
IS,fixed address empty,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-16 11:22:33,2018-01-16 14:56:31
IS,How can I batch images of arbitrary sizes in tensorflow,I want to realize arbitrary inputs that I can batch them in one batch,,,2018-01-15 07:02:24,2018-01-16 15:22:27
IS,tfcompile with config monolithic and fvisibility hidden results in undefined reference xla cpu runtime EigenMatMulF32,Some background first For DeepSpeech I have been experimenting simplification of our set of dependencies trying to do a config monolithic build The root cause for that was being able to run a SYCL enabled build on my system Ubuntu 17 10 Using OpenCL on this would trigger dependency load chain that in the end loads libmirprotobuf This would clash with the protobuf symbols already built in our libtensorflow framework libtensorflow cc To avoid this monolithic build and forcing visibility hidden seemed to be the best solution This allows us to move from those libraries non tfcompile build tfcompile adds libdeepspeech model so and all the XLA dependencies libdeepspeech so libdeepspeech utils so libtensorflow cc so libtensorflow framework so To just libdeepspeech so libdeepspeech utils so This way we have all needed TensorFlow bits within libdeepspeech so and those symbols are not re exported thus avoiding any unwanted interaction I could get SYCL build nearly working on Intel GPU Adding tfcompile in the equation however lead to linking issues Symptom would be that build completes but when one links binary against the model is so then it fails with Checking with objdump t bazel bin tensorflow compiler xla service cpu objs runtime matmul tensorflow compiler xla service cpu runtime matmul o grep EigenMatMul would show that the symbol is properly built into runtime matmul but that it is hidden I would be able to solve that by exposing xla cpu runtime EigenMatMulF32 and xla cpu runtime EigenMatMulF64 through TF EXPORT,,"skye,tatatodd,sanjoy,sanjoy,sanjoy,sanjoy,sanjoy,sanjoy",2018-01-05 11:07:28,2018-01-16 18:03:20
IS,Creating a specific 3 6 binary for Linux,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary Source TensorFlow version use command below Python version Python3 6 Bazel version if compiling from source GCC Compiler version if compiling from source NA CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce import tensorflow as tf Environment capture text tf env txt You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION This command also results in the same error home raju anaconda3 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds Describe the problem When importing tensorflow I get this error I found some information on Feature request nightly build for python 3 6 12935 Yes we unfortunately copy the 3 5 binary for 3 6 I will look into creating a specific 3 6 binary for Linux Source code logs import tensorflow as tf result is home raju anaconda3 lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds,,"asimshankar,gunan,av8ramit,av8ramit,av8ramit,av8ramit",2017-11-02 12:05:13,2018-01-16 19:16:49
IS,non max suppression is on CPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary By pip TensorFlow version use command below 1 4 1 Python version 3 5 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 61 6 0 21 GPU model and memory GTX 1080 Ti 11172MiB Exact command to reproduce python main py Describe the problem I train my RFCN by tensorflow My project need very high speed So I use the profile and I find that non max suppression is on CPU Is there a GPU version I think if you calculate all pairs of boxes IOU first then just for loop once will ultimately boost speed there have some trick in it just see the source code in I think cuda version of NMS is faster than CPU version,,qmick,2018-01-16 08:21:02,2018-01-16 19:33:57
IS,Documentation Java Tutorials,There is only one example for the Java API LabelImage java that is also outdated It would be great to add more examples for different tasks like text classification sentence matching seq2seq etc I have a small example that put the java api all together See tensorflow java,,asimshankar,2017-11-06 17:27:23,2018-01-16 19:59:22
PR,Branch 182086883,,,sb2nov,2018-01-16 19:51:59,2018-01-16 20:35:48
IS,Empty tensorflow python tools directory after build tf 1 5 from source,I rebuild Tensorflow GPU Version 1 5 0rc0 from source with Bazel Version 0 9 0 with CUDA 9 and cuDNN 7 to see changes from my previous version 1 4 also build from source with same prerequesites But now the tensorflow python tools directory is empty Has anybody experienced the same Or Did these scripts get moved to another directory,,,2018-01-12 11:11:14,2018-01-16 21:57:55
PR,Updating the docker login command The email flag is deprecated,PiperOrigin RevId 181769938,,av8ramit,2018-01-16 21:59:53,2018-01-16 22:58:49
IS,Key generator encoder 8 conv filter not found in checkpoint,I'm using python 3 6 3 win 10 64bit and tensorflow 1 2 1 and now I'm working on project and part 4 export model I'm taking this error NotFoundError see above for traceback Key generator encoder 8 conv filter not found in checkpoint how can I solve this problem what I run C Users hajum python C Users hajum Desktop face2face demo master reduce model py model input C Users hajum Desktop face2face model model output C Users hajum Desktop face2face reduced model same folder names with project but I have my own models what it shows,,aselle,2018-01-12 11:30:28,2018-01-16 23:01:50
PR,Make srcd in variable,,,"rajendraarora16,alextp,alextp",2018-01-13 10:00:11,2018-01-17 01:52:16
PR,FIX Typo,fix typo,,ManHyuk,2018-01-16 01:17:47,2018-01-17 02:12:34
PR,Add pos weights practical interpretation,The current weighted cross entropy with logits docs do not explain practically the relationship of pos weights 1 pos weights 1 to precision recall and class imbalance,,"4d55397500,4d55397500",2018-01-06 20:24:18,2018-01-17 04:47:00
PR,Update rules closure to fix bazel version check,Related issuecomment 357681237,,"meteorcloudy,jart,meteorcloudy",2018-01-16 11:31:14,2018-01-17 04:47:51
PR,MKL Fix for a compilation error caused by a previous commit,,,"agramesh1,agramesh1,agramesh1,agramesh1,gunan",2018-01-09 13:05:01,2018-01-17 05:27:30
PR,Intel MKL DNN fixes for several MKLDNN unit tests,Current MKLDNN element wise add results in several unit test failure A temporary workaround is provided by comment out the MKLDNN element wise add optimization,,jinghuangintel,2018-01-12 22:49:26,2018-01-17 05:47:39
PR,MKL DNN Implementing MKL DNN version of Softmax,New MKL DNN implementation of Softmax is added,,ashraf-bhuiyan,2018-01-04 18:45:43,2018-01-17 05:47:51
PR,MKL Fix LRN tensor shape when Eigen path is taken,On Eigen path the workspace tensor should only have one dimension of size 0,,"claynerobison,gunan,gunan",2018-01-10 21:22:47,2018-01-17 05:48:08
PR,Intel MKL Fixes for various MKLDNN unit test failures,1 MklLayout pass changes Making workspace type uint8 for MaxPool Handling duplicate control edge insertion 1 Handles case of inserting duplicate control edge fixing Mkl layout graph pass unit test 2 Enables uint8 as workspace tensor type makes consistent with LRN workspace handling Workspace tensor type change is also performed in MaxPool and MaxPoolGrad operators 2 Handling MklReshape failing case MklReshape was failing on a unit test when Mkl layout and Tensorflow layout for input tensors were same but shape of input tensor and output tensor was different No reorder is required in such case but reshape is needed Before this fix we were asserting that reorder is performed 3 Adding support for empty input filter tensors in Convolution backprop operators,,nhasabni,2018-01-12 00:47:26,2018-01-17 05:48:52
PR,MKL DNN fix batchnorm unit test failures,Fix failures of all 9 fuse batchnorm test cases handle corner case empty input tensors handle inference case properly bwd bug related to fwd primitive creation as a hint refactor moving output tensor allocation to separate methods to avoid duplicated code,,"qmick,gunan",2018-01-13 01:02:12,2018-01-17 05:49:23
PR,MKL DNN fix concat issue related to negative input concat dim,For a negative concat dim input the actual concat dim should be N concat dim with N being the dims of input tensors This PR fixes an issue of setting N properly,,,2018-01-12 20:40:28,2018-01-17 06:50:27
IS,Crash in TF lite demo android app when using preprocessing layer,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 14 04 TensorFlow installed from source or binary pip TensorFlow version use command below v1 4 0 rc0 21 g1e25994 1 4 0 rc1 Python version Python 3 6 2 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 6 GPU model and memory Titan X Pascal 12 GB Exact command to reproduce Describe the problem I have a problem adding preprocessing layers to MobileNetV1 model that is quantized afterward As preprocessing method I would like to use inception preprocessing but TF lite does not support several operations sub div broadcasting so I modified following preprocessing This error does not seem to be related to added preprocessing layer but without adding preprocessing layer no error occurs and app can run,,,2018-01-17 05:09:08,2018-01-17 08:15:46
PR,Fix docstring typo of losses impl py,Add missing to the docstring,,"qmick,qmick,caisq",2018-01-17 12:58:14,2018-01-17 14:58:11
PR,Addresses S3 timeout configurability discussed in 15868,This provides the ability to specify S3 timeouts via environment variables as requested in 15868,,"jhseu,jhseu,jhseu,jhseu,caisq",2018-01-06 00:54:44,2018-01-17 15:11:54
PR,Add tfexample decoder Image support for shape keys,Allow for the shape of an image decoded with the tfexample decoder Image decoder to be determined by fields in the serialized example being decoded The functionality mirrors the use of the shape keys kwarg of the Tensor decoder,,"rmlarsen,rmlarsen,sb2nov,rmlarsen,martinwicke,rmlarsen,rmlarsen,martinwicke,drpngx,drpngx",2017-09-30 02:50:02,2018-01-17 18:05:24
PR,Comment out dynamic slice tests that rely on wrapping,The wrapping behaviour has not yet been specified so it can not be tested See topic xla dev XQ7LbZOg9Nc,,"gunan,martinwicke,martinwicke,martinwicke,drpngx,drpngx",2017-11-01 12:32:34,2018-01-17 18:05:44
PR,little modify,Modify the list ' ' ' ' to the tuple ' ' ' ',,"jhseu,drpngx,drpngx",2017-11-17 16:09:33,2018-01-17 18:22:50
PR,Implements safe casting of to dtypes 12235,saturate cast supports SparseTensor to float to double to int32 to int36 to bfloat16 supports safe casting,,"ebrevdo,ebrevdo,ebrevdo,drpngx,sb2nov,martinwicke,martinwicke,drpngx",2017-08-24 07:55:02,2018-01-17 18:30:08
PR,Fixing deprecated URL link,,,rajendraarora16,2018-01-17 16:40:18,2018-01-17 18:32:09
IS,when will we have multi gpu support under eager mode Pytorch has it,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"asimshankar,asimshankar",2018-01-13 03:22:07,2018-01-17 18:51:42
IS,tf case raising IllegalArgumentError 'None of the conditions evaluated as True' when used with Dataset,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 64bit TensorFlow installed from source or binary via pip TensorFlow version use command below 1 4 0 Python version 3 5 When I use tf case within a tf data Dataset I get an IllegalArgumentError 'None of the conditions evaluated as True' However when I use the same code without the Dataset it works fine Furthermore if I understand the error message correctly it already tells me that one condition evaluated to true see the end of the first line I also found this question which seems to be the same problem,,"andreas-eberle,aselle,mrry",2018-01-16 14:01:26,2018-01-17 19:01:54
IS,Eager eager mode considerably slower than standard TensorFlow for large matrix multiplications,We have been benchmarking eager mode versus standard TensorFlow for large square matrix multiplications specifically the time to run m tf matmul A B in eager mode versus m sess run self c feed dict self A A self B B in non eager mode We find that while runtimes are comparable for small matrices eager mode is considerably slower for repeated multiplications of large matrices eg of dimension 15 000 The first multiplication is fast but subsequent multiplications take much longer even after resetting the computation graph Is this expected behavior We are running everything on a GPU,,"asimshankar,asimshankar",2017-12-12 01:46:28,2018-01-17 19:22:14
IS,Distributed training fault tolerance,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 5 LTS TensorFlow installed from source or binary Binary TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version Python 3 6 3 Bazel version if compiling from source NA GCC Compiler version if compiling from source NA CUDA cuDNN version release 8 0 V8 0 44 libcudnn v6 0 21 GPU model and memory Titan X Pascal 12 GB Exact command to reproduce In the description Describe the problem I am using the parameter server master worker paradigm to run model training in distributed mode The master node does the training and evaluation while the worker nodes only do the training on their shard of the data I should also note that I am using the tf contrib learn Experiment interface This model of distributed training works as expected however sometimes one or more of the worker nodes fail While they have failed the master node and other worker nodes continue the training The problem is that when this occurs even when only one of the worker nodes have failed the loss suddenly becomes zero and as a result gradients as well become zero while the metrics suddenly change to the value of a random model as can be seen in the figures below Loss curve As can be seen one or more of the workers have failed three times during the training loss fail Gradient norm curve gradient fail Accuracy on the validation set accuracy fail Is there a way to prevent this behavior either by stopping the training when one of the workers fails or pausing the training until the failed worker comes back online again like in the beginning of the training when training only starts when all of the workers come online Source code logs As indicated above I use the experiment interface This is the configuration for distributed training,,"asimshankar,xiejw",2017-12-27 16:10:38,2018-01-17 19:54:38
IS,How to initialize embeddings layer within Estimator API,I'm trying to use existing embeddings within tensorflow model the size of embedding is greater than 2Gb and this makes my original try of doing this unsuccessful Which gave me this error Cannot create a tensor proto whose content is larger than 2GB I'm using AWS SageMaker which based on the Estimator API and the actual running of the graph in session happens behind the scene so I'm not sure how to initialize some placeholders for embedding given that Would be helpful if someone will be able to share the way how to do such initialization in term of EstimatorAPI Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,ispirmustafa,2018-01-12 00:22:23,2018-01-17 21:04:57
IS,Building 1 2 1 with bazel 0 5 2 fails with Genrules without outputs do not make sense,Hello I'm trying to build Tensorflow on a Debian Stretch system usng the distribution provided CUDA packages I'm using tensorflow 1 2 1 from git clone recursive and bazel 0 5 2 The build fails with Genrules without outputs do not make sense error,,"shivaniag,ebrevdo,shivaniag,av8ramit",2017-08-03 16:01:17,2018-01-17 22:26:43
IS,TensorFlow fails to build with MPI,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 CentOS 7 4 TensorFlow installed from source or binary Source TensorFlow version use command below r1 5 Python version 2 7 5 Bazel version if compiling from source 0 9 0 0 7 0 GCC Compiler version if compiling from source 6 3 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build copt mfma copt mavx2 copt O3 verbose failures s c opt tensorflow tools pip package build pip package Describe the problem TensorFlow fails to build with MPI with the following error This error persists even when Bazel 0 7 0 is used to build TensorFlow,,"skye,gunan,av8ramit,av8ramit",2018-01-04 22:51:23,2018-01-17 22:32:45
PR,Branch 182265266,,,sb2nov,2018-01-17 22:47:33,2018-01-17 23:39:29
IS,tf contrib lookup HashTable kv initializer does not work in eager mode,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow,,"aselle,alextp,alextp",2018-01-16 13:11:57,2018-01-17 23:40:09
IS,Naming issue of tensorflow python layers core Dense,Since I think this issue has nothing to do with the system information I would temporarily ignore them TensorFlow version use command below v1 2 1 4 g4acb96a 1 2 1 Describe the problem The Dense layers defined in tensorflow python layers core build kernel and bias in build function while the build function is called in call function The may cause that sometime one define a layer but not call it immediately which causes an unexpected variable naming issue Source code logs For example when I try to implement a toy seq2seq model the following code in inference mode So I can not restore a training checkpoint when inference due to NotFoundError see above for traceback Key basic seq2seq decoder rnn output layer kernel not found in checkpoint,,facaiy,2017-09-11 04:22:21,2018-01-18 00:44:58
IS,Tensorflow lite breaks Android module,Inserting Tensorflow lite inside an android module library like this Results in this error when including the module and trying to running for Android API 19 Error Error converting bytecode to dex Cause com android dex DexException Multiple dex files define LR The module I am trying to include contains no classes files or other dependencies All it has I a dependency of Tensorflow lite If I insert tensorflow lite directly inside the app the problem goes away The problem does not happen in API 21 and it only happens for API 19 I am using android gradle plugin 3 0 1 but I also trying with 3 1 0 alpha 04 5 6 7 Is there a solution or work around to this problem,,,2018-01-08 18:45:03,2018-01-18 13:57:51
PR,fix typo,fix typo,,ManHyuk,2018-01-18 04:56:40,2018-01-18 14:38:20
IS,RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds,System information OS Platform and Distribution Linux Ubuntu 17 10 TensorFlow installed from Anaconda followed this tutorial InstallingAnaconda TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version Python 3 6 4 Anaconda Inc CUDA cuDNN version not using GPU version GPU model and memory 2GB GT720 python c import tensorflow as tf print tf GIT VERSION tf VERSION result home pankaja anaconda3 envs tensorflow lib python3 6 importlib bootstrap py 219 RuntimeWarning compiletime version 3 5 of module 'tensorflow python framework fast tensor util' does not match runtime version 3 6 return f args kwds v1 4 0 19 ga52c8d9 1 4 1 Describe the problem Followed Official tensorflow documentation to install tensorflow on Ubuntu 17 10 python3 python 3 6 and with CPU support Used conda environment Followed this InstallingAnaconda and in the 4th step this is the command I used pip install ignore installed upgrade it installed successfully But when I try to import tensorflow in python I'm getting this error Why can not I use the tensorflow for python 3 6 in python 3 6 How to fix this,,,2018-01-17 05:05:21,2018-01-18 16:20:50
IS,nightly installed TF is the new 1 5 TF,today I heard that there are a new version 1 5 TF which is with good support dynamic graph And I also find there is a new nightly installed method So this nightly installing method is install the new Version TF,,,2018-01-06 07:58:38,2018-01-18 16:34:47
PR,Branch 182280342,,,benoitsteiner,2018-01-18 00:02:16,2018-01-18 16:54:03
PR,added CMake options to provide external zlib GRPC Eigen,Here are changes necessary to build tensorflow with different version of GRPC Protobuf Eigen zlib etc It is not possible to compile project using two different versions of protobuf for example To deal with that I have chosen approach similar to one in GRPC library Also for some reason I do not see changes from in master thus changes from that branch are also here might know something,,"mrry,jhseu,mrry,mrry,mrry,mrry,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-11-10 20:21:58,2018-01-18 18:00:03
PR,Fixing a typo for the argument to docker push,,,av8ramit,2018-01-18 01:19:25,2018-01-18 18:27:07
PR,Branch 182384458,,,benoitsteiner,2018-01-18 16:57:40,2018-01-18 18:30:55
PR,Branch 182305106,,,sb2nov,2018-01-18 04:24:22,2018-01-18 18:33:18
PR,Cleanup CocoaPods dependency from TFLite iOS examples,,,"miaout17,miaout17",2018-01-05 19:47:50,2018-01-18 18:59:20
IS,Issue when the saving the model when the session is made by with statement,i use tensorflow to train LSTM network The training run well but when i want to save the model i get error below After i changed the with statement with the sess tf Session the problem gone,,"yaroslavvb,reedwm",2017-10-03 17:10:00,2018-01-18 19:22:10
IS,Bug Op type not registered 'BlockLSTM' in binary,Describe the problem I want to load and run a single tensorflow model within another C project To do this I defined the tensorflow all library in tensorflow BUILD which should include all the necessary dependencies Details below When loading the tensorflow model via the C API LoadSavedModel the following runtime error occurs LoadSavedModel L50 I was hoping that BlockLSTM was included in tensorflow contrib contrib ops op lib but that appears not to be the case OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 2 LTS TensorFlow installed from source or binary source TensorFlow version Master branch commit bb88ec7ecc4dc7ba72548a5115fb86e20b14de5b Python version 3 5 Bazel version if compiling from source 0 4 5 CUDA cuDNN version 5 1 GPU model and memory GeForce GTX 980 4GB Exact command to reproduce Sorry Not that easy to reproduce,,"reedwm,reedwm",2017-07-28 12:25:41,2018-01-18 19:24:19
IS,Slow Hessian,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I have written custom code OS Platform and Distribution e g Linux Ubuntu 16 04 4 4 0 47 generic 68 Ubuntu and Also macOS Sierra 10 12 3 CPU only TensorFlow installed from source or binary Binary TensorFlow version use command below 1 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version cuda 8 0 and cudnn 5 1 GPU model and memory 12GB memory 100GB Exact command to reproduce tf hessians ys xs You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem The command tf hessians ys xs is used to add nodes to the graph in order to compute hessians of ys with respect to xs where both ys and xs are list of tensors Currently computing hessian with respect to a vector is not possible The trick is to unstack the input tensor x into a list of one dimensional tensors xs and compute hessian with respect to each of them separately then stack them together Tensorflow gets stuck in the phase of graph construction even when the dimension of x length of list xs is about one hundred In the implementation of Hessian in gradients impl py the second derivative is implemented as the derivative of partial derivative with respect to each member of xs I guess the slowness of graph construction is due to this line hess gradients gradient x kwargs 0 for gradient in gradients which may add several unnecessary intermediate nodes with overlapping functionality to the graph due to the for loop Is there any way other than looping over input dimensions that efficiently constructs the graph in a reasonable time Source code logs This source code can simulate the problem import tensorflow as tf import numpy as np in dimension 256 x tf placeholder tf float32 shape 1 in dimension x list tf unstack x axis 1 xx tf stack x list axis 1 y tf pow xx 3 hess tf hessians y x list sess tf Session print sess run hess feed dict x np random normal 0 1 size 1 in dimension,,"aselle,yaroslavvb,yaroslavvb,yaroslavvb",2017-07-30 23:14:18,2018-01-18 19:36:56
IS,NaNs only on GPU with large convolution kernel,Consider the following silly autoencoder style network which performs a strided convolution followed by a transposed convolution This code is the minimal example that I could reproduce the error with I am running tensorflow gpu 1 2 1 installed via pip on Ubuntu 16 04 2 with Python version 2 7 12 CUDA is 8 0 61 1 from the nVidia repo and cuDNN is 5 1 10 My GPU is an nVidia GTX 1080 Ti with 11172 MiB of memory To reproduce the error run the above code with CUDA enabled My suspicion is that when the kernel is too large with respect to the input or the output of the strided convolution a bug is triggered I am not entirely sure how the size of the kernel must relate to the other convolution parameters but I could produce errors both in the conv2d and the conv2d transpose op,,"aselle,aselle,aselle,reedwm,reedwm",2017-08-04 15:32:52,2018-01-18 19:41:24
IS,feature request Any way to control the order of send recv host to device data transfer explicitly,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 2 Python version 3 5 Bazel version if compiling from source 0 5 2 CUDA cuDNN version 8 0 GPU model and memory GTX 1070 Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Overlapping the host to device data transfer with GPU calculation is an important method to improve the performance of inference workload But I found it very difficult to control the order of data transfers explicitly at this moment I understand the send recv operations are added implicitly when the original graph is split optimized into sub graphs I tried to use control dependency identity assign operation as suggested here to hand control send recv order But it seems impossible to achieve this goal For example In the following code we would like to overlap the H2D memcpy of B B GPU with the matmul calculation But it turned out that H2D memcpy A A GPU is not ensured to launch first Actually among the 50 iterations I noticed the order of transferring A A GPU and transferring B B GPU is randomly performed if we use multiple threads because the two transfers are handled in different threads and no dependency could be built between them If A A GPU launches first the matmul op could be overlapped with B B GPU image otherwise the matmul op has to wait until all H2D memcpys finished image Only if we can control the order of send node explicitly the overlap can be ensured Please let me know if I did not use the identity operation correctly Thanks,,,2017-09-05 11:02:48,2018-01-18 19:56:54
IS,Custom op linking flags,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Clean master b5214cab6151fc9c0471829a05bab4872e2e3bc4 OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 3 TensorFlow installed from source or binary Source TensorFlow version use command below not relevant Python version Python 3 5 2 Bazel version if compiling from source CUDA cuDNN version CUDA 7 cudnn 6 GPU model and memory 1080 Ti Exact command to reproduce not relevant Describe the problem It is a feature request I'm compiling TF from source for optimal performance And I need custom op so I'm following compile the op using bazel tensorflow source installation by adding a bazel BUILD file in user ops directory But at the same time my custom op needs some other libraries like opencv I could easily install opencv using my system is package manager and add a lopencv xxx flag during linking Currently I hacked definition of tf custom op library to add the extra linking flags But I hope that since I think this scenario is pretty common tf custom op library could expose something like extra link flags It should just be a few extra lines of code upstream I could submit a PR if you think it is mergable,,jart,2017-09-05 21:54:37,2018-01-18 20:23:45
PR,Fixing a typo for the argument to docker push 16204,,,av8ramit,2018-01-18 18:33:07,2018-01-18 20:31:56
IS,Problem with AddControlInput in python api h,asimshankar I'm observing an issue with AddControlInput in python api h It seems to not be working for me actually and I'm not sure why Everything is ok if I add the control dependency during op creation However if I add it right after it is not enforced during execution A simple example is creating a switch op creating two constant ops and adding one control dependency for each on each switch output and then feeding these two constant ops into a merge op The result will be whichever constant op was fed first into the merge op i e the control dependencies are not satisfied and both ops are executed If I add the control dependency during op construction all is good Note that the control input does show up in the GraphDef that I generated after the call It is simply not enforced during execution Do you have any idea why that might be happening I am aware that this is not part of the public API and thus is not stable but it is still unexpected behavior I am using that in my implementation of control flow ops and gradients I ended up re implementing it based on the Python version because I depend on it and the C functionality is currently very limited I will update on this later on once I release it,,"eaplatanios,eaplatanios,eaplatanios,eaplatanios,skye,eaplatanios,skye,eaplatanios,skye,eaplatanios,skye,eaplatanios,skye,eaplatanios,eaplatanios,eaplatanios",2017-10-05 02:12:32,2018-01-18 21:02:01
IS,TFGAN gan model tensor conversion necessary,I would like to use the Dataset API with the GANEstimator TFGAN I know that MakeIterator cannot be cast to a tensor but I would like to pass it to generator fn anyways Is the conversion of generator inputs to tensors really necessary With the plain Estimator API I also do not have this restriction I am passing the following object to gan model through generator inputs L104,,"angersson,angersson,angersson,mrry,joel-shor,joel-shor,joel-shor,joel-shor,mrry,joel-shor",2017-11-05 13:29:27,2018-01-18 21:27:31
IS,Cant install tensorflow on my laptop,pip3 install upgrade tensorflow gpu Collecting tensorflow gpu Could not find a version that satisfies the requirement tensorflow gpu from versions No matching distribution found for tensorflow gpu this is what it shows please help,,"Carmezim,shivaniag,tatatodd,tatatodd,tatatodd",2017-11-24 11:23:41,2018-01-18 22:06:39
IS,VERBS and OpenMPI not building anymore without CUDA,Hello When activating MPI or VERBS without CUDA build fails with the following error Is that expected Thanks,,"tatatodd,tatatodd,byronyi,tatatodd,tatatodd",2017-11-22 22:05:58,2018-01-18 22:08:41
IS,tensorflow for python 3 6 will cause Jupyter notebook not executing properly,Details refer to this issue I originally posted,,"aselle,gunan,caisq",2017-11-27 06:42:36,2018-01-18 22:58:51
IS,Tensorflow does not delete previous checkpoints,System information Linux Ubuntu 16 04 Tensorflow version 1 4 1 Python 3 5 2 Describe the problem A brief summary is that if I run multiple times my training script tensorflow does not delete the checkpoints created in previous runs of the script I am preparing a automatic script that every X days runs and train with the new data collected But I am facing a problem even that I have configured the saver to keep the 2 last checkpoints it does not work as I expected Example I configure to run 100 000 iterations and each 10 000 to save the checkpoint The system works and starts saving 10 000 20 000 And when get to 30 000 starts deleting the firsts checkpoints When the script ends I have the 2 last checkpoints 90 000 and 100 000 Then when I train again the system starts from the last checkpoint in this example the 100 000 and do the same as the previous 110 000 120 000 and when gets to the 130 000 starts to delete the 100 000 and so on But the 2 checkpoints from the previous run 90 000 and 100 000 remain there even that in the checkpoint txt are not listed there This will be repeated in every run of the script creating files that I do not need anymore and growing during the time This is an intended behavior expecting to the user to delete or manage manually or it is really a problem It exist any workaround Thank you for your time and amazing work,,aselle,2018-01-18 08:40:20,2018-01-18 23:24:11
PR,Docker patch 14,,,av8ramit,2018-01-18 23:20:38,2018-01-18 23:28:56
IS,tensorflow lite error when convert frozen model to lite format,Hi I build the freeze pb with the guide at with the below step python train image classifier py train dir home ubuntu train dataset dir home ubuntu vegetables dataset name vegetables dataset split name train num clones 2 clone on cpu True checkpoint path home ubuntu check point mobilenet v1 1 0 224 ckpt max number of steps 10 checkpoint exclude scopes MobilenetV1 Logits MobilenetV1 AuxLogits model name mobilenet v1 python tensorflow python tools freeze graph py input graph home ubuntu train mobilenet v1 224 pb input checkpoint home ubuntu check point mobilenet v1 1 0 224 ckpt input binary true output graph home ubuntu train frozen mobilenet v1 224 pb output node names MobilenetV1 Predictions Reshape 1 NOTE I download mobilenet v1 1 0 224 ckpt from But when I convert to lite mode with ubuntu ip 172 31 27 248 tensorflow bazel bin tensorflow contrib lite toco toco input format TENSORFLOW GRAPHDEF input format TENSORFLOW GRAPHDEF input file home ubuntu mobilenet v1 1 0 224 frozen mobilenet v1 224 pb output format TFLITE output file tmp mobilenet v1 1 0 224 lite inference type FLOAT inference input type FLOAT input arrays input output arrays MobilenetV1 Predictions Reshape 1 input shapes 1 224 224 3 2017 12 05 09 53 56 604720 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before general graph transformations 336 operators 502 arrays 0 quantized 2017 12 05 09 53 56 627922 I tensorflow contrib lite toco graph transformations graph transformations cc 39 After general graph transformations pass 1 31 operators 88 arrays 0 quantized 2017 12 05 09 53 56 628156 I tensorflow contrib lite toco graph transformations graph transformations cc 39 Before dequantization graph transformations 31 operators 88 arrays 0 quantized 2017 12 05 09 53 56 628327 I tensorflow contrib lite toco allocate transient arrays cc 312 Total transient array allocated size 6422528 bytes theoretical optimal value 4816896 bytes 2017 12 05 09 53 56 628487 I tensorflow contrib lite toco toco tooling cc 268 Estimated count of arithmetic ops 1 14264 billion note that a multiply add is counted as 2 ops 2017 12 05 09 53 56 628653 F tensorflow contrib lite toco tflite export cc 192 Unsupported operator Squeeze Aborted core dumped Pls help me my other question is when I download the pretrain freeze pb from It is work when I use toco tools where I can find guide which generate these freeze pb Pls Help,,"drpngx,aselle,powderluv",2017-12-05 10:24:56,2018-01-19 00:57:43
PR,Update LICENSE,This commit updates an instance of 2017 to 2018,,"ChrisAntaki,martinwicke",2018-01-12 18:37:25,2018-01-19 01:15:27
IS,calculation gradients of tf nn embedding lookup,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 2 7 Source code logs import tensorflow as tf types lookup table tf get variable types lookup table shape 234 10 initializer tf random normal initializer 0 1 dtype tf float32 trainable True embedding types tf nn embedding lookup types lookup table 2 3 4 1 2 3 opt tf train GradientDescentOptimizer 0 1 gradients tf gradients embedding types xs types lookup table train opt apply gradients gradients 0 types lookup table with tf Session as sess tf global variables initializer run h sess run gradients print sess run train right print sess run opt apply gradients h 0 types lookup table wrong Describe the problem I tried to calculate the gradients of tf nn embedding lookup but the result shown is an IndexedSliceValue with 3 elements img width 1250 alt 2017 12 04 9 23 45 src however the corresponding gradient without sess run is an indexSliceValue with 1 elements I do not know why img width 1226 alt 2017 12 04 9 27 31 src And therefore I can not sess run opt apply gradients h 0 types lookup table because the shape of calculation value does not match the shape of types lookup table however when I did not calculate the intermediate value and directly sess run train ps train opt apply gradients gradients types lookup table there is no problem But I need to calculate the intermediate value and do an add I do not know how Thanks,,facaiy,2017-12-04 01:47:48,2018-01-19 01:40:15
PR,Make build rule for tensorflow contrib lite tools benchmark model,Resolve issue Note that this benchmark model cc is not completed yet It does not load and models 1 With proper Android SDK and NDK settings in WORKSPACE we can build armeabi v7a or arm64 v8a binary e g bazel build cxxopt ' std c 11' crosstool top external android crosstool cpu arm64 v8a host crosstool top bazel tools tools cpp toolchain tensorflow contrib lite tools benchmark model 2 It is also possible to build this for Linux or OS X e g bazel config opt cxxopt ' std c 11' tensorflow contrib lite tools benchmark model,,"freedomtan,drpngx,drpngx",2017-11-30 15:05:13,2018-01-19 01:43:44
PR,Branch 182456096,,,benoitsteiner,2018-01-19 00:52:44,2018-01-19 02:10:31
IS,Tensorboard issue with the official docker image 1 5 0 rc0 gpu py3,Hello everyone I have the exact same issue as stated here And on the official tensorboard repository The fact that I am using the official Docker Image and I did not build anything from scratch tensorflow tensorflow 1 5 0 rc0 gpu py3 9e770d59b136 6 days ago 2 85GB What I get when I try to launch Tensorboard as usual Resolution Idea I noticed that by simply running the command pip install tensorboard inside the container the problem is solved and I am able to normally launch Tensorboard Thanks a lot for the help All the best Jonathan,,"shivaniag,caisq,caisq,aselle,jart,jart",2018-01-10 16:29:58,2018-01-19 03:21:53
IS,Multiple runs of Configure with MKL enabled leads to cyclic symlinks,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Centos 7 TensorFlow installed from source or binary Compilation from source TensorFlow version use command below v1 2 1 and v1 3 0 r1 Python version Python 3 5 2 Bazel version if compiling from source 0 5 2 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce configure enter enter y y enter till complete twice Describe the problem Currently the way the configure script is written for the MKL decision branch it does not ensure no cyclic symbolic links are created for libdl so 2 This becomes a problem if MKL has been downloaded already upon a re run of the configure script and the first line of the locate output happens to be the symlink located in the third party mkl directory If that occurs then the ln sf command will create a cyclic symlink This can be fixed either by checking that loc is not the same string as PWD third party mkl libdl so 2 or by checking for the existence of the symlink before the ln command Source code logs configure line 276 277 loc locate e libdl so 2 sed n 1p can end up returning the destination file if it already exists ln sf loc third party mkl libdl so 2 if loc PWD third party mkl libdl so 2 creates cyclic link,,jart,2017-08-02 19:22:24,2018-01-19 04:56:29
IS,Feature request dilated pooling,Hi I posted initially in keras users but suggested that this would need to be implemented first at TensorFlow level topic keras users ZVtI8Ef6508 Similarly to dilated convolution dilated pooling uses a dilated kernel For example dilated kernel with pool size 3 2 dilation rate 2 4 non zero elements this is where values are sampled to compute max pooling 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 This was proposed in Li H Zhao R Wang X Highly efficient forward and backward propagation of convolutional neural networks for pixelwise classification arXiv preprint arXiv 14124526 2014 and it is used by DeepCell Van Valen et al 2016 PLoS Comput Biol Deep Learning Automates the Quantitative Analysis of Individual Cells in Live Cell Imaging Experiments DeepCell is state of the art for cell segmentation but it is implemented with Keras 1 and ad hoc code based on a bit outdated Theano To the best of my knowledge there is a lack of testing of whether dilation in pooling improves segmentation I have written one in Keras by shifting the kernel and slicing the image then running regular 2D pooling on each slice and reassembling the results code at the end of post but probably not very interesting However this approach is probably quite inefficient The question would be whether any TF developer would be willing to extend the current tf contrib keras backend pool2d,,"jart,fchollet,jart",2017-08-29 11:46:32,2018-01-19 05:26:44
IS,benchmark model tool not build successfully for android version,Hello I try to build the benchmark model for the android but I encounter some errors Please help is any setting not correct The configuration of the SDK and NDK in the WORKSPACE is android sdk repository name androidsdk api level 23 build tools version 26 0 1 path home kk android sdk android sdk linux android ndk repository name androidndk path home kk android sdk ndk android ndk r14 api level 14 Use the command to build bazel build cxxopt ' std c 11' c opt crosstool top external android crosstool cpu armeabi v7a host crosstool top bazel tools tools cpp toolchain tensorflow tools benchmark benchmark model There are three errors 1 external gif archive lib openbsd reallocarray c 33 19 error use of undeclared identifier 'SIZE MAX' 2 tensorflow core common runtime gpu gpu debug allocator cc 172 53 error no member named 'nanf' in namespace istd' did you mean simply 'nanf' 3 external androidndk ndk toolchains arm linux androideabi 4 9 prebuilt linux x86 64 lib gcc arm linux androideabi 4 9 x arm linux androideabi bin ld error cannot find lpthread Thanks Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 4 LTS TensorFlow installed from source or binary use the pip install TensorFlow version use command below 1 4 0 Python version Python 2 7 6 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source Ubuntu 4 8 4 2ubuntu1 14 04 3 4 8 4 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce NA You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,freedomtan,2018-01-17 09:46:35,2018-01-19 07:00:17
PR,Added ability to skip rescan bottleneks,,,drpngx,2017-11-29 21:43:54,2018-01-19 08:12:46
IS,Meaning of report tensor allocations upon oom output,Python 3 6 2 OS Ubuntu 16 04 Tensorflow 1 5 0rc1 When running a session with tf RunOptions and report tensor allocations upon oom True I get the following output at the end of my log 1 I am wondering why some entries occur multiple times How can a single node have multiple allocations Why are they not summed 2 Does Remaining 1252 nodes with 98 80MiB mean that all 1252 nodes together use 98 80MiB or each single one uses that amount 3 When summing up all values I get 10 607822265625GiB but my free GPU space when starting my program is 11 92GiB so should not there still be enough space,,aselle,2018-01-18 14:39:30,2018-01-19 08:41:16
PR,Branch 182474037,,,"sb2nov,sb2nov,frankchn,gunan",2018-01-19 06:47:58,2018-01-19 09:01:12
PR,Suppress AWS curl init warning,This shows up each time we run the TensorBoard command even if we are not using anything AWS related,,"jart,yongtang",2018-01-18 18:56:07,2018-01-19 09:01:54
PR,Windows Add missing dependencies in lib proto parsing,Fix Culprit,,"meteorcloudy,meteorcloudy",2018-01-18 09:11:23,2018-01-19 09:07:14
PR,Merge changes from r1 5 into master,This change picks up the commits exclusive to the r1 5 branch and puts them back into master There were a bunch of merge conflicts here I favored master in most cases except those to do with obvious versioning differences I'm not sure if I did the merge correctly considering there are a great many CLs presented here,,"angersson,av8ramit,av8ramit,av8ramit,av8ramit,av8ramit,angersson,angersson",2018-01-17 00:46:21,2018-01-19 09:07:54
PR,macOS does not have wget,Make building easier on macOS by using curl instead of wget because wget is not part of macOS and wget installed from brew has trouble resolving certificates appropriately,,"yifeif,drpngx,caisq,gunan",2017-11-16 22:25:54,2018-01-19 14:58:59
PR,fix typo,fix typo,,ManHyuk,2018-01-19 14:07:51,2018-01-19 15:09:58
PR,Branch 182511847,,,"benoitsteiner,sb2nov,sb2nov",2018-01-19 16:35:22,2018-01-19 18:50:20
PR,Branch 182554969,,,"sb2nov,sb2nov",2018-01-19 19:00:38,2018-01-19 19:27:04
PR,Branch 182559534,,,sb2nov,2018-01-19 19:43:11,2018-01-19 20:16:28
IS,A potential null pointer deference bug in GraphProperties class,Dear developers I am studying the code of Tensorflow and found a potential null pointer dereference bug in tensorflow core grappler costs graph properties cc The problem The function updateEnter at line 70 of tensorflow core grappler costs graph properties cc calls the getContext function of the ShapeRefiner class which could return a null pointer line 79 of tensorflow core common runtime shape refiner h and get stored in the variable enter ctx At line 73 of the updateEnter function enter ctx is dereferenced in the for loop condition without being checked against null If the null pointer dereference is triggered the program might crash I noticed that for another call of the getContext function at line 255 of tensorflow core grappler costs graph properties cc the function return value which gets stored in the variable qctx is checked against null indicating that getContext can indeed return null pointer Source code I am analyzing the latest version of Tensorflow as of July 31 2017 and the two relevant files are 1 commit 4432623 on 1 July 2 commit e85d3df on 30 June Hope my report helps,,"aselle,aselle",2017-07-31 14:41:03,2018-01-19 20:24:27
IS,Unable to build Tensorflow Benchmark model for Android,I have been trying to benchmark the model on mobile but I'm not able to build the model for Android For desktop I have been able to build and run the benchmark model The machine I'm using is a MacBook pro 15 inch with High Sierra and tensorflow v 1 4 I have been following the directions given at the following links how to profile your model Edit Updated answer to the issue template Have I written custom code No custom code was written OS Platform and Distribution Mac OS High Sierra TensorFlow installed from Tensorflow installed from source TensorFlow version 1 4 Bazel version Bazel version 0 9 0 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce,,,2018-01-17 22:45:21,2018-01-19 20:32:12
IS,Benchmarking GPU ops in Tensorflow Graphs,I tried using the tool for benchmarking Tensorflow Graphs at Seems it only gives the memory profile for RAM per ops How can I get the GPU memory and utilization profile per ops using this tool,,,2018-01-19 16:03:21,2018-01-19 21:20:25
IS,Switching branch and run configure does not regenerate spec json,When building from source with TensorFlow and switch to another branch error returned even if I rerun configure You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"yongtang,shivaniag,jart,yongtang",2018-01-08 21:07:43,2018-01-19 21:40:07
PR,Fix issue of branch switching not working with bazel,This fix tries to address the issue raised in 15957 where bazel stops working after switching git branch and reconfigure with configure will not work as well This fix adds a quick fix as was suggested by having export TF CONFIG TIME date in configure py and add it to the environ list in git configure bzl This fix fixes 15957 Signed off by Yong Tang yong tang github outlook com,,"yongtang,case540,yongtang",2018-01-17 19:00:24,2018-01-19 21:40:07
PR,Branch 182576952,,,sb2nov,2018-01-19 21:20:06,2018-01-19 22:15:00
IS,tensorflow contrib modules break when running in a pyc only environment,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Amazon Linux 2016 09 TensorFlow installed from source or binary binary no gpu virtualenv method TensorFlow version use command below 1 2 1 Python version 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce python c from tensorflow contrib layers import fully connected You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem When building a python install for a disk space constrained environment it is fairly common to first compile all py files to pyc files and then only install the pyc files to save a few megabytes of space When attempting this for tensorflow it became unable to import it is contrib modules traceback below From some testing I did this appears to be due to differing behavior in this snippet from the get path to datafile function in python platform resource loader py data files path os path dirname inspect getfile sys getframe 1 when the py files are present this snippet produces an absolute path When only the pyc files are present it produces a relative path which is then concatenated with another path as the get path to datafile function is called twice Source code logs,,"aselle,aselle",2017-08-22 01:16:57,2018-01-19 22:15:48
IS,Bug while printing parameters and gradients,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary anaconda TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 6 4 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version using CPU GPU model and memory using CPU Exact command to reproduce see below Describe the problem The model is very simple I do digits classification with MNIST There is only one parameter matrix W no bias and no non linearities The model show convergence since the loss is decreasing I checked predictions and accuracy but I do not copy paste useless code here If I print the parameters before and after training they are the same however it should not be the case Moreover the gradient of the loss w r t parameters are zero but again it should not be the case since the model converges so there should be a non zero gradient I cannot explain why and my implementation seems correct that is why I am posting my code here Source code logs,,,2018-01-15 16:08:51,2018-01-19 22:26:56
IS,Tensorflow Lite tf nightly toco error for python3,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS High Sierra 10 13 2 TensorFlow installed from source or binary yes TensorFlow version use command below 1 6 0 dev20180119 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce toco help You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem I'm following the current tensorflow codelab 3 however it seems that toco does not run under a python 3 6 env according to the output of the terminal Source code logs command input output using sudo also does not help There is also a stackoverflow issue logged here,,aselle,2018-01-19 20:21:01,2018-01-19 23:07:38
IS,No OpKernel was registered to support Op 'AssignVariableOp' with DT BFLOAT16,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Arch linux TensorFlow installed from source or binary Source TensorFlow version use command below 1 5 0 rc1 Python version NA go bindings Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 7 2 1 CUDA cuDNN version na CPU GPU model and memory na Exact command to reproduce See below Describe the problem AssignVariableOp does not appear to appear to have a kernel for DT BFLOAT16 Source code logs,,aselle,2018-01-13 17:45:32,2018-01-20 00:39:43
IS,graph metrics py does not work well,I want to use function in graph metrics py I run corresponding test file graph metrics test py but I get the following assertion error for weight parameters metric has anyone encounter this problem,,,2018-01-19 12:35:24,2018-01-20 01:50:26
PR,AssignVariableOp supports DT BFLOAT16,Fix 16103,,"facaiy,facaiy",2018-01-17 08:06:26,2018-01-20 03:15:37
IS,Error when building from source Fedora 27 CUDA 9 1,System information OS Platform and Distribution Fedora 27 TensorFlow installed from source or binary binary TensorFlow version r1 4 Python version 3 6 3 Bazel version 0 8 1 GCC Compiler version 7 2 1 CUDA cuDNN version CUDA 9 1 cuDNN 7 0 5 GPU model and memory NVidia Geforce GTX 960 4GB Exact command to reproduce bazel build c opt config cuda verbose failures tensorflow tools pip package build pip package Describe the problem So I'm attempting to build tensorflow from source on fedora with the version of CUDA and cuDNN I already had installed to avoid have to also install an older version The build however errors with the following message I also tried the command bazel build config opt config cuda incompatible load argument is label false tensorflow tools pip package build pip package from here with the same end result Any guidance is appreciated as this is my first time using bazel and also trying to compile tensorflow,,aselle,2018-01-16 18:21:58,2018-01-20 18:26:12
PR,BeamSearchDecoder fix beam not full and add test module,fix issue mentioned in and add a test module for it,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,oahziur,oahziur,oahziur,oahziur,ebrevdo,ebrevdo,oahziur,oahziur,yifeif,drpngx,drpngx,drpngx,drpngx,drpngx,ebrevdo,adarob,drpngx,rmlarsen,adarob,drpngx,sb2nov,ebrevdo,ebrevdo,drpngx,drpngx,ebrevdo,drpngx,ebrevdo",2017-06-16 02:04:01,2018-01-20 22:06:16
PR,Extracting out tf bin values fixed width from tf histogram fixed width,,,"sb2nov,sb2nov,jhseu,jhseu,gunan,gunan,gunan,josh11b,josh11b,josh11b,gunan,gunan,martinwicke,gunan,drpngx,drpngx,drpngx,drpngx,jhseu,drpngx,jhseu,jhseu,drpngx,drpngx,drpngx",2017-09-27 04:06:36,2018-01-20 22:06:33
PR,Verbs w 0 copies,Verbs implementation to use direct tensor writes 0 copies Motivation Following HKUST research on the use of GPU direct and their GDR implementation we wish to adopt the 0 copies approach and apply it to the current verbs implementation while keeping the current implementation advantages such as configurability and the use of RDMA for control messages Performance Compared with the current GRPC verbs and GDR implementation the result implementation gave the best performance for every model with any number of nodes For VGG16 on 8 nodes with 4 P100 GPUs each the prototype beat the second place by over 15 Implementation requirements 1 Tensor writes need to be done directly from the source Tensor to the destination Tensor with no memory copies in between This should be done for all DMAble tensors which are located either on CPU or on a RDMA compatible GPU device GPU direct 2 Non DMAble tensors CanMemCopy false will be serialized to proto on the sender side RDMA written to a registered buffer on the receiver side and then deserialized by the receiver 3 Tensors which are located on a non RDMA compatible GPU will be RDMA written to a registered CPU proxy buffer on the receiver side and then copied to GPU by the receiver Implementation constrains For best stability and proof of correctness we will divide the implementation to two stages 1 At first stage we will keep changes to the current implementation to the minimum possible The expense will be that we may have unused or unnecessary code leftovers which may also affect performance 2 At second stage we will re iterate over the code and remove irrelevant code parts The design of the solution aims that we will achieve both stages with relative ease Design guidelines 1 Since we do not want to do any unnecessary memory copying we will no longer allocate a fixed CPU buffer as the destination for the RDMA write Instead we will do the writing directly to the result tensor or if the result tensor is on a device which does not support RDMA we will do the writing to a proxy CPU tensor and then copy its content to the result tensor 2 The address of the destination Tensor needs to be sent to the sender side for writing meaning that the result proxy tensor should be pre allocated on the receiver side prior to sending the tensor request In order to do that we need to know its meta data i e shape and data type for DMAble tensors and proto size for serialized tensors Unfortunately this information is only available on the sender side which complicates manners In order to avoid sending extra messages for querying the meta data on each step we store a local meta data cache per tensor Based on the assumption that the meta data of a tensor rarely changes between steps we expect that on most times the cache will only be updated once When the sender receives a request for a tensor if it is the first time this tensor is requested or in the rare case that the meta data did change the sender will first send a meta data response on which the receiver will update the local cache and reallocate the result proxy tensors if required When the receiver sends the tensor request it will contain also the meta data currently stored in its local cache so the sender can compare it to see if there was a change 3 When the sender writes the tensor content to the result tensor no additional data is being written with it That means we need to reside on ibverbs immediate uint32 t to indicate which request we are responding to in order to trigger the receive callback The easiest and most elegant way is to key the recv callback with a unique request index uint32 t instead of the current key with step id string 4 Since the sender no longer writes the tensor from to fixed buffers we no longer need to schedule the writes using the local remote status In addition we no longer rely on the RmdaTensorBuffer members as the source destination addresses and rkey lkey Instead each RdmaTensorBuffer will hold multiple Response objects one per step id from which we derive destination address and rkey The source address and lkey are always the ones of the source Tensor 5 With the addition of tensor pre allocation we noticed there is a large code similarity between sending the first tensor request and re sending the request in case of meta data changes After implementing a common method for tensor pre allocation it turned out that implementation becomes much simpler by encapsulating the process of request sending re sending meta data response callback and content response callback all in a single Request class The request class holds all the relevant request information which reduces excessive parameter passing and lambda capturing This decision is purely for elegance and code simplicity and we decided to implement it in first stage because it makes the implementation much easier 6 At phase 2 we adopt that approach for the sender side as well by encapsulate all the send and resend logic in the Response class and remove the RdmaTensorBuffer class completely This should make our design easier to understand and also hold common notions with the rest of the distributed implementations New types classes enum RdmaImmDataType Immediate types to distinguish between different RDMA writes on the remote side Ack writes and control message writes have a fixed immediate value The rest of the writes are tensor writes and the immediate value is the relevant request index enum RdmaWriteIDType Types to distinguish between different RDMA write complete events Ack control message tensor DMA write and tensor proto write class RdmaWriteID Context for RDMA write complete events Holds the RdmaWriteIDType and additional data class RemoteAddressContext Remote address information address mr Will be passed as write context for tensor proto writes class RdmaTensorMetaData Meta data for a tensor type shape is dead proto size class RdmaMemoryMgr Manages the meta data cache and the registered memory regions class RdmaTensorRequest Holds and manages information for a single tensor request throughout the entire receive cycle API Start Start the request sequence Allocate the result tensor and proxy tensor if required Send RDMA MESSAGE TENSOR REQUEST to the remote side RecvTensorMetaData Receive meta data from the remote side Update the local meta data cache Reallocate the result tensor and proxy tensor if required Re send the request to the remote side RecvTensorContent Receive tensor content from the remote side RDMA write was completed Decode proto if required and or move to GPU if the content was not written to it directly GPU direct is not avaliable Invoke the done callback class RdmaTensorResponse Holds and manages information for a single tensor response throughout the entire send cycle API Start Start the response sequence Find the tensor in the local tag match table Compare the tensor is meta data to the meta data in the message taken from the requester is local cache If meta data changed Clone the tensor to be sent later Send a meta data update message and wait for re request Else Send the tensor is content using direct RDMA write Resume Resume the response sequence after a re request Send the tensor is content that was cloned earlier Destroy Destroy the response is resources and remove it form the pending list Protocol changes The protocol messages themselves will remain mostly unchanged at the first stage but will be used differently as described below The current messages structures already have most of the required fields for the new implementation The only change is the buffer size field which is no longer used since we are no longer sending additional information with the tensor and thus it is now always equal to the tensor bytes field Instead we use that field to pass the request index Message structure type name size name step id request index remote addr rkey is dead data type tensor shape tensor bytes 1B 2B 512 8B 8B 8B 4B 1B XB XB 8B RDMA MESSAGE TENSOR REQUEST receiver sender The original tensor request type The message type name name size Name of the requested tensor step id Step ID request index Request index remote addr rkey Address rkey of the result proxy tensor Irrelevant for first time request is dead data type tensor shape tensor bytes The current meta data as stored in the receiver local cache The sender will use that information to know if the receiver is cache requires updating RDMA MESSAGE BUFFER REQUEST sender receiver The meta data update message in case meta data had changed or if it is the first time the tensor is requested type The message type request index Request index is dead data type tensor shape tensor bytes The up to date meta data Note At phase 2 this message is renamed to RDMA MESSAGE META DATA UPDATE RDMA MESSAGE BUFFER RESPONSE receiver sender Tensor re requset after meta data update and reallocation of result proxy tensors type The message type name name size Name of the requested tensor step id Step ID request index Request index remote addr rkey Address rkey of the reallocated result proxy tensor is dead data type tensor shape tensor bytes The new meta data Will be removed in the next phase Note At phase 2 this message is renamed to RDMA MESSAGE TENSOR RE REQUEST RDMA MESSAGE TENSOR WRITE sender receiver No longer sent There is only a direct write of the tensor content to the result proxy tensor Request index passed as the immediate value of the write RDMA MESSAGE TENSOR IDLE receiver sender No longer sent Phase 1 alt text Phase 1 transport protocol Phase 2 alt text Phase 2 transport protocol Second stage optimizations 1 Remove unused code leftovers Done 2 Remove the ACK buffer completely since we can rely completely on its immediate value Done Future optimizations 1 Map the tensor names to indexes to significantly reduce the request message size 2 Understand the purpose of empty tensors and if we can skip remote fetching for them 3 Consider concatenating multiple requests and or using multiple message buffers 4 Consider a no request architecture,,"yanivbl6,gunan,yanivbl6,byronyi",2018-01-10 12:15:07,2018-01-20 22:41:29
PR,XLA Separate out the dynamic slice wrapping tests,This is a set of changes to allow disabling of bfloat16 tests for backends which do not support bfloat16 Originally it was a change to the same set of tests to allow the wrapping behaviour tests to be disabled That change was made obsolete by some parallel work The original text was The XLA documentation says that the behaviour of dynamic slice and dynamic update slice is undefined when the indices wrap This separates out the tests which check for wrapping behaviour so that they can be ignored for backends which do not exhibit the test is expected results,,"DavidNorman,DavidNorman,DavidNorman,DavidNorman,hawkinsp",2018-01-12 09:26:37,2018-01-20 22:46:05
PR,Converting the real and imaginary float values from short test segmen,t spectrogram csv bin on big endian for spectrogram test,,"namrata-ibm,jhseu,namrata-ibm,jhseu,namrata-ibm,namrata-ibm,yifeif,namrata-ibm",2017-11-15 04:06:31,2018-01-20 22:47:48
PR,added scope filtering to summaries merge all,I found a use for filtering the ops returned by merge all by scope so this request implements that change You could also pass the collection to merge but I thought this was a bit nicer,,"sb2nov,martinwicke,sb2nov,martinwicke,martinwicke,martinwicke,drpngx,martinwicke,drpngx,drpngx",2017-09-27 02:06:07,2018-01-20 23:03:18
IS,FeatureRequest Support PathLike objects for directory arguments,With python 3 6 PEP 519 and the pathlib module it would be great if TensorFlow directory parameters accepted PathLike objects From the Backwards Compatibility backwards compatibility part of the documentation a suggested implementation is With such an implementation it seems path in the code above can be any file system representation of str bytes or pathlib Path For my case I was using looking at the tf estimator model dir L122 L126 parameter but for consistency I assume it would also need applying in all cases where a path is accepted such as tf gfile System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 macOS TensorFlow installed from source or binary pip TensorFlow version use command below v1 4 0 8 gbca50da6eb 1 4 0 Python version 3 6 3 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Problem is the pathlib module represents filesystem paths although is not accepted in parameters that refer to a directory or file in the TensorFlow API The proposed feature would enable accepting these objects while still maintaining compatibility with existing str type paths,,,2018-01-02 12:33:09,2018-01-20 23:36:15
PR,Accepts PathLike objects for model dir,Retrieves the file system path representation if PathLike object is passed to Estimator or RunConfig for model dir instead of str Closes 15784,,"jhseu,jhseu,drpngx,drpngx",2018-01-17 23:27:52,2018-01-20 23:36:15
PR,Model Average Optimizer,I have implemented model average optimizer and open a new pr since the original one is closed,,"alextp,alextp,yifeif,alextp,caisq,drpngx",2017-12-12 07:26:09,2018-01-20 23:39:20
PR,TensorBoard Modifications for Word2Vec Example,TensorBoard modifications are added to Word2Vec example for visualizing the loss graphic and embeddings with proper words in TensorBoard,,"jart,drpngx,nealwu,drpngx,drpngx,drpngx,drpngx",2017-11-27 11:13:14,2018-01-20 23:39:55
IS,tf nn leaky relu does not work with float64,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes see below OS Platform and Distribution e g Linux Ubuntu 16 04 Fedora 26 TensorFlow installed from source or binary binary pip3 install tensorflow TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version Python 3 6 3 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version None GPU model and memory Does not apply Exact command to reproduce See below Describe the problem tf nn leaky relu does not work with float64 It only seems to work with float32 I can not think of a reason why it should not work with float64 so I consider this a bug your mileage might vary I'm also not familiar enough with tf code to fix it myself without any help It seems at least ops py L926 L926 should be in a try block just as ops py L912 L912 Also the unit tests only test float32 Source code logs,,"facaiy,facaiy,angersson",2017-12-15 10:58:31,2018-01-20 23:43:09
PR,Fix bug leaky relu supports float64,Fix 15391 How to test x add test case pass all tests,,facaiy,2017-12-15 14:43:00,2018-01-20 23:43:09
PR,Small fix in the example,There is a typo in the example tflite modeL tflite model,,"yifeif,drpngx,caisq,drpngx",2017-12-18 20:11:34,2018-01-20 23:47:00
IS,Tensorflow should not depend on tensorboard,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow irrelevant OS Platform and Distribution e g Linux Ubuntu 16 04 linux TensorFlow installed from source or binary binary the issue is about pip dependencies TensorFlow version use command below 1 3 Python version 3 5 CUDA cuDNN version 8 0 6 0 GPU model and memory irrelevant Exact command to reproduce pip install tensorflow Describe the problem I wish to install tensorflow without having to install tensorboard Currently there is a circular dependency between tensorflow and tensorboard However tensorflow runs perfectly well without tensorboard therefore the dependency should be removed Additionally having a simpler dependency structure would facilitate packaging for NixOS Source code logs irrelevant,,"jart,martinwicke,jart",2017-08-24 19:58:25,2018-01-21 00:00:48
IS,Tensorflow building error,I am trying to build tensorflow with this statement bazel build c opt tensorflow examples android tensorflow demo the WORKSPACE is android sdk repository name androidsdk api level 23 build tools version 25 0 2 build tools version 26 0 1 path C Users ST AppData Local Android Sdk android ndk repository name androidndk path C Users ST Downloads Tensorflow Compile android ndk r12b api level 14 but I got an error message ERROR C msys64 tmp bazel st ztysx 6 external protobuf archive BUILD 93 1 C compilation of rule ' protobuf archive protobuf lite' failed Exit 3 This application has requested the Runtime to terminate it in an unusual way Please contact the application is support team for more information Cannot create temporary file in C WINDOWS Permission denied Target tensorflow examples android tensorflow demo failed to build Use verbose failures to see the command lines of failed build steps Elapsed time 5 465s Critical Path 0 63s I am using Windows 10 bazel 0 5 4 python 2 7 Is there anyway to fix this problem,,"martinwicke,martinwicke",2017-08-29 08:37:01,2018-01-21 00:26:35
IS,DataLossError Checksum does not match,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 windows 7 professional 64bit TensorFlow installed from source or binary binary TensorFlow version use command below 1 3 0 Python version 3 6 2 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem I trained on Ubuntu16 04 to get the model and then restore the model on Windows7 Professional but it occured such a mistake DataLossError see above for traceback Checksum does not match stored 1713499277 vs calculated on the restored bytes 1894941567 Node save RestoreV2 282 RestoreV2 dtypes DT FLOAT device job localhost replica 0 task 0 cpu 0 Both machines have the same version of python and TensorFlow and the model tested in another machine succeed but this machine failed how to solve it Thank you Source code logs Process finished with exit code 1,,"reedwm,martinwicke,martinwicke",2017-12-08 06:21:22,2018-01-21 00:35:23
IS,No module named tensorflow python platform,System information OS Linux 4 4 0 109 generic 132 Ubuntu SMP Tue Jan 9 19 52 39 UTC 2018 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial Tensorflow Installed from source git clone from this repository tf VERSION 1 5 0 rc1 tf GIT VERSION v1 5 0 rc1 1379 g20f6af3 tf COMPILER VERSION v1 5 0 rc1 1379 g20f6af3 Sanity check array 1 dtype int32 Python version Python 2 7 12 Bazel version Build label 0 9 0 GCC Compiler version gcc Ubuntu 5 4 1 2ubuntu1 16 04 5 4 1 20160904 nvcc Cuda compilation tools release 9 1 V9 1 85 CUDA cuDNN version CUDA Version 9 1 85 cuDNN Version 7 0 5 GPU model and memory GeForce 1080 Ti 11Gb Driver Version 387 26 Exact command to reproduce 1 git clone 2 configure,,,2018-01-21 05:47:58,2018-01-21 06:20:21
PR,udacity assignment 1 2,,,,2018-01-21 13:57:47,2018-01-21 13:58:28
PR,fix typo,fix typo,,ManHyuk,2018-01-19 15:54:08,2018-01-21 23:54:26
IS,adding placeholder with default in order to feed both via dataset and placeholders produces error on GPU,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow no OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 4 0 Python version 3 6 2 Bazel version if compiling from source 0 9 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version 9 1 85 GPU model and memory Titan V 12G Exact command to reproduce See below You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request The issue is when you want to train a classifier that takes both placeholder and dataset via queue to feed input The reason one may want to do that is to run inference via placeholders I added the following line under define the model section of train image classifier py of slim library Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem images tf placeholder with default image shape name 'input I get an error of the following kind when running on GPU Cannot assign a device for operation 'input' Could not satisfy explicit device specification ' device GPU 0',,sguada,2018-01-19 23:37:05,2018-01-22 00:02:36
PR,Weight normalization for RNN Cells,The current RNN implementation executes a user defined function the call method of subclasses of RNNCells inside a tf while loop Weight normalisation requires a one time normalization of the transition matrices prior to entering the while loop The following 2 edits have been made in tensorflow python ops to enable this functionality RNNCell now has a prepare method It does nothing as implemented in the base class A call to cell prepare has been added just before entering dynamic rnn loop Subclasses of RNNCell may implement normalization in the cell is prepare method One implementation with BasicLSTMCell and associated tests have been added to contrib Note that any wrappers to be used with a weight normalized cell need to be appropriately subclassed as illustrated with the PrepareableMultiRNNCell example in contrib,,"ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,vrv,ebrevdo,rmlarsen,ebrevdo,drpngx,sb2nov,sb2nov,gunan,gunan,gunan,gunan,gunan,gunan,ebrevdo,ebrevdo,drpngx,caisq,yifeif,caisq,drpngx",2017-07-18 11:26:51,2018-01-22 00:22:31
IS,tf pow x y edge case with negative x Bug,I am using tf pow for my project but my losses are 'nan' so I setup the test cases as shown below I found that whenever x is negative tf pow seems to output nan instead of the correct answer r tf pow 0 4 0 4 r2 tf pow 0 4 0 4 r3 tf pow 0 4 0 4 r4 tf pow 0 4 0 4 sess run r 0 69314486 sess run r2 nan sess run r3 1 4426999 sess run r4 nan I appreciate for anyone of the community who can address this issue Respectfully,,aselle,2018-01-21 18:03:16,2018-01-22 03:45:00
IS,ImportError cannot import name tf,System information Os version Linux Ubuntu 14 04 TensorFlow installed from binary sudo pip install upgrade TensorFlow version 1 4 1 Python version 2 7 Describe the problem After Install when i run the following command it throws error from tensorflow import tf It throws Traceback most recent call last File stdin line 1 in module ImportError cannot import name tf,,aselle,2018-01-21 06:37:52,2018-01-22 03:52:51
IS,ContentTooShortError urlopen error retrieval incomplete got only 246506328 out of 247336696 bytes,I have started UDACITY deep learning course I was copying the assignment 1 codes then I got the this error during downloading the notMNIST large tar gz Here are some screenshots of the code I am doing this on jupyter python3 notebook in ubuntu 1 2 error,,aselle,2018-01-21 12:36:47,2018-01-22 04:12:24
IS,Performance issues with TF1 5 on CPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 0 rc1 Python version 2 7 Bazel version if compiling from source 0 5 4 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version NA GPU model and memory NA Exact command to reproduce Hello I'm facing performance issues with the last releases of TF using a CPU I'm using the benchmark tool to calculate mean inference time of a model For example in order to evaluate mobilenet trained on a custom dataset I'm using this command bazel bin tensorflow tools benchmark benchmark model graph path to mobilenet graph input layer input input layer shape 1 224 224 3 input layer type float output layer MobilenetV1 Predictions Reshape 1 After setting CUDA VISIBLE DEVICES to in order to run on CPU With TF 1 4 1 I obtain a mean inference time equals to 26ms 13ms if I compile with optimization flags Using tf 1 5 I obtain a mean inference time equals to 51ms 45ms if I compile with optimization flags The loss is very important so I'm wondering if it is a known issue and how I can improve this I tried with tags v1 5 0 rc0 tags v1 5 0 rc1 and master and the problem is the same Thank you,,"aselle,tfboyd,tfboyd,tfboyd,tfboyd",2018-01-17 13:39:19,2018-01-22 09:01:17
IS,tf edit distance work wrang,System information cat etc issue Linux asr eval 4 4 77 1 el7 elrepo x86 64 1 SMP Sat Jul 15 11 17 37 EDT 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 16 04 3 LTS Xenial Xerus VERSION ID 16 04 VERSION CODENAME xenial are we in docker No compiler c Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 Copyright C 2015 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux asr eval 4 4 77 1 el7 elrepo x86 64 1 SMP Sat Jul 15 11 17 37 EDT 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 14 0 protobuf 3 5 1 tensorflow gpu 1 5 0rc1 tensorflow tensorboard 0 4 0rc3 check for virtualenv False tensorflow import tf VERSION 1 5 0 rc1 tf GIT VERSION v1 5 0 rc0 8 gc678970 tf COMPILER VERSION v1 5 0 rc0 8 gc678970 Sanity check array 1 dtype int32 usr local lib python2 7 dist packages h5py init py 36 FutureWarning Conversion of the second argument of issubdtype from float to np floating is deprecated In future it will be treated as np float64 np dtype float type from conv import register converters as register converters env LD LIBRARY PATH usr local nvidia lib64 usr local lib usr local cuda extras CUPTI lib64 usr local nvidia lib usr local nvidia lib64 DYLD LIBRARY PATH is unset nvidia smi Mon Jan 22 10 28 25 2018 NVIDIA SMI 384 98 Driver Version 384 98 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 TITAN Xp Off 00000000 0C 00 0 Off N A 23 29C P0 68W 250W 10MiB 12189MiB 0 Default Processes GPU Memory GPU PID Type Process name Usage No running processes found cuda libs usr local cuda 9 0 targets x86 64 linux lib libcudart so 9 0 176 You can obtain the TensorFlow version with 'v1 5 0 rc0 8 gc678970' '1 5 0 rc1' Describe the problem,,,2018-01-22 10:28:53,2018-01-22 10:58:11
IS,Feature Request Distributed Tensorflow with Data Parallelism and DMA,Hi I have a machine with multiple GPUs and deployed a distributed Tensorflow exploiting data parallelism I use ClusterConfig to configure the cluster is topology and pass this to Experiment to run the distributed training I wanted to make one of the GPUs as the parameter server and use the rest for the workers each of which uses one GPU I did this through launching multiple processes for parameter server and workers while setting up the env variable CUDA VISIBLE DEVICES to one of the GPUs In this case I noticed that the GPUs do not communicate to each other via DMA and I guess this is because the DMA is only available between visible devices to Tensorflow I also tried device count GPU 1 to make Tensorflow see all the GPUs while using only one GPU but this still seems to occupy the whole resource of all visible GPUs preventing another Tensorflow process to be launched over the idle GPU It would be great if there is a way to use only one GPU for a Tensorflow process but still enable DMA with the other GPUs sitting in the system Am I missing such feature even though it exists Thank you,,"byronyi,byronyi,byronyi,martinwicke",2017-06-30 22:35:42,2018-01-22 17:33:11
IS,TF build fails for simulator architectures on master,When building TF for iOS from master with build all ios sh The build fails with MacOS Sierra 10 12 6 16G29 Xcode Version 8 3 3 8E3004b Apple LLVM version 8 1 0 clang 802 0 42 Target x86 64 apple darwin16 7 0 Thread model posix InstalledDir Applications Xcode app Contents Developer Toolchains XcodeDefault xctoolchain usr bin,,martinwicke,2017-08-28 13:56:36,2018-01-22 17:42:58
IS,pip package build error,System information OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source TensorFlow version 1 4 0 Python version 2 7 12 Bazel version Build label 0 9 0 Build target bazel out k8 fastbuild bin src main java com google devtools build lib bazel BazelServer deploy jar Build time Tue Dec 19 09 31 58 2017 1513675918 Build timestamp 1513675918 Build timestamp as int 1513675918 GCC Compiler version gcc version 5 4 0 20160609 Ubuntu 5 4 0 6ubuntu1 16 04 5 Describe the problem I am trying to build the pip package after configuration by using bazel build config opt tensorflow tools pip package build pip package but I am getting a weird error I have been using tensorflow but trying a fresh install gives me this output Terminal log,,,2018-01-22 14:57:26,2018-01-22 17:45:27
PR,Branch 182783262,,,benoitsteiner,2018-01-22 16:41:22,2018-01-22 17:48:36
PR,MKL Fixed convolutional recurrent test,This PR is to fix convolutional recurrent test unit test,,,2018-01-22 19:14:18,2018-01-22 19:18:55
PR,Branch 182802058,,,xiejw,2018-01-22 18:56:49,2018-01-22 19:43:11
IS,Exception when not providing optional parameter frequency skip in TimeFreqLSTMCell,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes see below OS Platform and Distribution TensorFlow installed from pip3 install user tensorflow gpu TensorFlow version 1 4 1 Python version 3 5 2 CUDA 8 0 GPU NVidia Titan X Describe the problem Using a TimeFreqLSTMCell in a dynamic rnn or static rcnn without providing the optional parameter frequency skip results in an exception,,"progwolff,qmick",2018-01-13 12:20:41,2018-01-22 20:27:14
PR,fix default parameters for TimeFreqLSTMCell fixes 16100,Resolve 16100 The default parameters for TimeFreqLSTMCell lead to a division by None which throws an exception,,"progwolff,progwolff",2018-01-15 10:24:06,2018-01-22 20:27:14
PR,MKL Fix convolutional recurrent test failure,This branch fixes the convolutional recurrent test failure,,claynerobison,2018-01-22 19:25:00,2018-01-22 20:49:41
PR,Removes redundant variable assignment,Addresses alert raised by lgtm com xb77a2f6647d782be 1 It does not seem like assigning attr tshape attr tshape does anything so there is no need to keep it in,,"rmlarsen,alextp",2018-01-22 13:26:57,2018-01-22 20:55:02
PR,Branch 182808673,,,rmlarsen,2018-01-22 20:40:22,2018-01-22 20:58:21
PR,minor spelling tweaks for lite docs,,,brettkoonce,2018-01-22 03:39:32,2018-01-22 20:59:56
PR,4d55397500 patch 1,Provide a practical meaning for the pos weights parameter The current weighted cross entropy with logits docs do not explain practically the relationship of pos weights 1 pos weights 1 to precision recall and class imbalance,,"4d55397500,rmlarsen",2018-01-17 04:52:42,2018-01-22 21:30:33
PR,GAN model move generated and real operations under discriminator namespace,Hi everybody gan model runs the discriminator on both the generated and real data This PR changes fixes the namespace of the generated graph Current The network variables and operations on generated data are in the Discriminator namespace but the operations on real data are in the Discriminator 1 namespace PR The network variables stay in the Discriminator namespace Operations on generated data are in Discriminator generated and operations on real data are in Discriminator real gan model only searches the Discriminator namespace for regularization Presumably if you were running activity regularization in your discriminator only the part on generated data would be picked up Plus the graph looks much better visually this way and you can tell which discriminator is which Cheers,,"bstriner,bstriner",2018-01-16 11:36:00,2018-01-22 21:31:35
PR,De Bazel pip smoke test sanity check,See issuecomment 354156560 for reference cc,,Androbin,2017-12-28 01:50:44,2018-01-22 21:37:10
PR,CMake Add sanity tests for python file lists,Replaces 15166 See discussion in 15368 Friendly ping,,"Androbin,martinwicke,martinwicke,gunan,gunan,gunan,mrry,Androbin,martinwicke",2017-12-27 22:04:32,2018-01-22 21:38:57
PR,Use Eigen version of the scalar pow op for pow ops,This fix use scalar pow op in Eigen to replace customerized scalar binary pow op google as scalar pow op seems to be in place in Eigen Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,rmlarsen,yongtang",2017-12-30 23:47:11,2018-01-22 22:01:41
IS,tf errors OutOfRangeError error not raised when using tf train MonitoredTrainingSession,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow I am providing a mini snippet to reproduce bug OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 64 bit TensorFlow installed from source or binary From binary for windows tensorflow gpu TensorFlow version use command below 1 4 0 Python version 3 6 Bazel version if compiling from source Not Applicable GCC Compiler version if compiling from source Not Applicable CUDA cuDNN version CUDA 8 5 GPU model and memory Titan X Exact command to reproduce Just run the snippet as it is Describe the problem When Dataset iterator reaches at the end it should raise tf errors OutOfRangeError But when using tf train MonitoredTrainingSession with custom hook I do not get the error Ideally I need to get the Error Source code logs Reproducible bug snippet,,,2018-01-22 18:44:30,2018-01-22 22:22:55
PR,Fix periodic resample,,,"drpngx,rmlarsen",2017-12-24 17:57:55,2018-01-22 22:46:37
PR,New features tf alphas and tf alphas like Related to 16128,This PR is related to the issue 16128 I send my work here for peer reviewing and discussion Please do not merge now A few interrogations before merging 1 Are the names I have chosen fine with everyone or you would like it to be changed to something else 2 Do my implementations seem fine 3 What kind of tests should I implement Where shall I put them 4 Is it a good idea to replace the function body of tf ones tf zeros and tf ones like tf zeros like by a function call to tf alphas and tf alphas like Not doing it would lead to code duplication however I would understand that you might be reluctant these functions are at the core of the library Why I created these functions I oftenly need to create similar tensors with a non zero one value A simple example would be cost functions in GANs with label smoothing applied As stated by in 16128 I could use I'm of course free for discussion over video calls It is the first time I try to make a change at the core of TF and I'm quite afraid of breaking everything Thanks for your help btw All the best Jonathan DEKHTIAR,,"rmlarsen,rmlarsen,josh11b,rmlarsen",2018-01-16 10:12:45,2018-01-22 22:47:28
PR,fix pooling1D dimension bug,When data format is channels last input is NWC so we have to expand dim 1 to make it become NHWC Then we apply pooling on W which is the 3rd dimention When data format is channels first input is NCW so we have to expand dim 2 to make it become NCHW Then we apply pooling on W which is the 4th dimention RELNOTES Fixed wrong handling of 1D pooling pooling was not happening on the correct dimension,,"martinwicke,martinwicke,rmlarsen",2017-12-20 06:27:33,2018-01-23 00:37:02
PR,R1 4,,,av8ramit,2018-01-22 01:06:46,2018-01-23 01:02:40
PR,Add test for float16 support with conv1d and update docstring,The float16 support for conv1d has already been in place However there was no test for float16 with conv1d This fix adds test case to cover float16 support with conv1d In addition float64 support with conv1d is not possible because conv1d calls conv2d which in turn does not support float64 yet See 12941 13097 and 12943 The previous docstring incorrectly claimed float64 support with conv1d This fix also updates related docstring to remove float64 part Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,yongtang,rmlarsen,yongtang",2018-01-21 22:33:02,2018-01-23 01:49:30
PR,Add LINM Loop Invariant Node Motion optimization pass in GraphOptim,izer,,,2018-01-23 01:59:38,2018-01-23 02:28:50
IS,Bug of tf data TFRecordDataset couldnot use tf reshape to reshape the output of tf data TFRecordDataset,,,,2018-01-23 03:09:23,2018-01-23 03:09:57
IS,After Working with Tensorflow cpu version for 2 days it gave me an error on installation today,I had installed and used Tensorflow successfully but today when I opened my computer it gave me this error message Traceback most recent call last File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File C Users asus AppData Local Programs Python Python36 32 lib imp py line 297 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ModuleNotFoundError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File C Users asus PycharmProjects untitled3 CNNCIFARTFNEW py line 2 in module import tensorflow as tf File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow init py line 24 in module from tensorflow python import File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python init py line 60 in module raise ImportError msg ImportError Traceback most recent call last File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 18 in swig import helper fp pathname description imp find module ' pywrap tensorflow' dirname file File C Users asus AppData Local Programs Python Python36 32 lib imp py line 297 in find module raise ImportError ERR MSG format name name name ImportError No module named ' pywrap tensorflow' During handling of the above exception another exception occurred Traceback most recent call last File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python init py line 54 in module from tensorflow python import pywrap tensorflow File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 28 in module pywrap tensorflow swig import helper File C Users asus AppData Local Programs Python Python36 32 lib site packages tensorflow python pywrap tensorflow py line 20 in swig import helper import pywrap tensorflow ModuleNotFoundError No module named ' pywrap tensorflow' Error importing tensorflow Unless you are using bazel you should not try to import tensorflow from its source directory please exit the tensorflow source tree and relaunch your python interpreter from there Please help This is urgent,,aselle,2018-01-22 07:38:03,2018-01-23 04:58:10
IS,ScipyOptimizer SLSQP supporting callback,The callback is deprecated when SLSQP method in scipy optimizer is selected see here L400 Actually SLSQP does support callback so,,"tatianashp,tatianashp",2018-01-22 18:49:22,2018-01-23 05:37:22
PR,Make unused variable warning an error during TF builds,We will need to eyeball build logs and see if this is really working as intended,,"gunan,drpngx,caisq,drpngx,caisq,gunan,drpngx,gunan,drpngx,rmlarsen,gunan",2017-12-31 23:44:09,2018-01-23 07:00:00
PR,Disable keras data utils test as it is flaky,,,"av8ramit,av8ramit,gunan,rmlarsen,av8ramit,gunan",2018-01-12 23:44:10,2018-01-23 07:01:30
PR,Repair compilation error of tensorflow built with MKL DNN,When we compile tensorflow with Intel MKL DNN it will meet a failure bazel build copt O3 copt DINTEL MKL DNN config mkl c opt tensorflow tools pip package build pip package error 'mkldnn algorithm' is not a namespace using mkldnn algorithm lrn across channels Removing the 'algorithm' field in tensorflow core kernels mkl lrn op cc can solve this problem and lead to successful compilation,,"claynerobison,rmlarsen,claynerobison,rmlarsen",2018-01-22 07:27:10,2018-01-23 07:02:18
PR,Transpose for high dimensional tensors using eigen,In our library we rely heavily on fast transposes of high dimensional tensors so we have added few extra cases to the CPU and GPU transpose functors Previously it was done up to dimension 5 and we included dimensions 6 7 8 similarly to the TENSORFLOW USE SYCL case,,rmlarsen,2018-01-05 22:41:55,2018-01-23 14:19:36
PR,Fix a pessimizing move warning in GetDeviceLapackInfo,clang reports pre tensorflow core kernels cuda solvers h 430 10 warning moving a local object in a return statement prevents copy elision Wpessimizing move return std move new dev info tensorflow core kernels cuda solvers h 430 10 note remove std move call here return std move new dev info pre,,"dtrebbien,caisq,dtrebbien",2018-01-03 20:39:18,2018-01-23 14:25:15
PR,Removing os path,,,rajendraarora16,2018-01-23 14:46:41,2018-01-23 14:49:56
IS,Bug in session initialization,Initializing a variable depending on a placeholder does not work Error Message tensorflow python framework errors impl InvalidArgumentError You must feed a value for placeholder tensor 'Placeholder' with dtype float Node Placeholder Placeholder dtype DT FLOAT shape unknown device job localhost replica 0 task 0 device CPU 0 The interesting part about this is that the first initialization works but the second one does not This is really annoying if you do not know that behaviour and you try to build some application with interactive python shells System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 17 10 TensorFlow installed from source or binary binary TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 6 3,,,2018-01-22 15:02:36,2018-01-23 16:03:00
PR,Branch 182892876,resolved one merge conflict in histogram ops py,,xiejw,2018-01-23 16:37:06,2018-01-23 17:23:04
PR,fix typo,,,,2018-01-16 05:36:10,2018-01-23 17:35:39
PR,Add C toolchain for portable Linux builds,See 15777,,"jart,case540,jart,case540,rmlarsen,jart,case540,jart,case540,jart,jart,case540,jart",2018-01-17 02:10:01,2018-01-23 17:51:19
IS,tf pow edge case failure,The tf pow function has an edge case which causes it to hang with no error message If you try to evaluate tf pow x y when x is an integer and thus the output tensor is also an integer while y is a negative value tensorflow hangs trying to cast the fraction as an integer Examples sess run tf pow 5 2 2 3 sess run tf pow 5 2 sess run tf pow 5 2 sess run tf pow tf constant 5 tf constant 2,,"rohan100jain,facaiy,yongtang",2017-08-09 19:57:41,2018-01-23 18:00:18
PR,Fix tf pow x y edge case with integer x and negative integer y,This fix tries to address the issue raised in 12156 and 9560 and PR 11852 where pow x y hangs with an integer x and a negative value of y This fix tries to throw out an error like numpy in this case This fix adds error to the C functor like safe div mod so that and InvalidArgument error could be triggered if any one of the values of y is negative NOTE Similar to safe div mod this fix also does not cover GPU not working yet This fix fix 12156 This fix is also related to 9560 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,rmlarsen,rmlarsen,yongtang",2017-12-24 00:17:32,2018-01-23 18:00:19
IS,Gif can not be decoded InvalidArgumentError Invalid GIF data,System information Have I written custom code yes OS Platform and Distribution Mac OS 10 12 3 TensorFlow installed from pip3 TensorFlow version 1 4 Bazel version N A CUDA cuDNN version N A GPU model and memory N A Describe the problem 0071qvrrgy1fn3h6v55gag308w0adx6p The gif can be decoded by PIL but the error occurred when I used tf image decode gif to decode,,"yongtang,yongtang,yongtang,yongtang",2018-01-04 07:27:19,2018-01-23 18:01:19
PR,Propagate the error string of GIF processing for decode gif,This fix tries to improve the error thrown by decode gif to include the error string generated by GIF processing Previously the error was not very indicative as the error string returned by GIF processing was hidden This fix fixes 15838 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,yongtang",2018-01-14 18:39:01,2018-01-23 18:01:19
IS,Dataset from string generator raises Exception with python 2,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 MacOS X 10 12 6 TensorFlow installed from source or binary binary cpu version from pypi TensorFlow version use command below 'v1 5 0 rc0 9 gf9472619f6' '1 5 0 rc1' Python version 2 7 14 Describe the problem I'm reading text data from file in generator Encoding UTF 8 After some preprocessing i return it in generator manner Next i'm trying to create Dataset from this generator Code below produce exception in both Python 2 3 for TensorFlow 1 4 For TF 1 5 rc1 Python 3 there is no errors For TF 1 5 rc1 Python 2 error exist Source code logs,,yongtang,2018-01-16 08:27:13,2018-01-23 18:02:10
PR,Fix unicode string conversion issue in Python 2,This fix tries to address the issue raised in 16149 where the unicode string conversion with Python 2 does not match the behavior with Python 3 The issue was that in Python 3 TensorFlow tries to do a unicode conversion in UTF8 while in Python 2 the default conversion was used This fix addresses the issue so that behaviors of TensorFlow with Python 2 and Python 3 match This fix fixes 16149 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,yongtang",2018-01-16 19:32:09,2018-01-23 18:02:10
PR,Fix compilation error and warnings with CUDA 0,There is a compilation error when compiling verbs with CUDA 0 This is rarely used but we still want it to compile of course Also there are some compilation warnings that should not exist Mostly about 'unused functions' when setting unsetting certain preprocessor defines,,,2018-01-21 11:37:02,2018-01-23 18:05:40
PR,Using math ops instead of defining separate mulop function,,,"rajendraarora16,hawkinsp,rmlarsen",2018-01-23 14:31:41,2018-01-23 18:10:16
PR,Enables 0 D indexing for Gather in TFLite,Hi This patch enables use of scalar 0 D index for Gather in TFLite Since Dims still works correctly which becomes 1 1 1 1 when calculating a scalar tensor no actual internal change is needed Still it only supports indexing the first dimension At here gather 0d expand 1 diff 3aa3a18bc0cba3f7fe969252dbd8ed09L51 int32 is changed to int32 t because my clang on OSX 10 12 complains that int32 is undefined,,"scottcjt,miaout17,miaout17,miaout17,scottcjt,scottcjt,scottcjt,scottcjt,miaout17,miaout17,miaout17,scottcjt,miaout17,scottcjt,scottcjt,miaout17",2017-12-19 23:27:10,2018-01-23 18:14:41
PR,Support for large number of classes when using tf metrics mean per class accuracy,tf metrics mean per class accuracy uses a num classes x num classes matrix to keep track of accuracies for each class This wastes a lot of memory and does not work well for large number of classes e g matrix size for 500k classes is 500000 2 4 1 terabyte By switching to two 1 D variables of size num classes instead memory usage is reduced considerably One variable keeps track of correct predictions for each class while the other variable keeps track of the total number of predictions for each class,,"alextp,alextp,rmlarsen,rmlarsen",2018-01-08 14:49:46,2018-01-23 18:22:08
PR,Clarify the description of batch norm in order to highlight the dimen,sion selection for normalization This should work now,,,2017-12-30 08:25:29,2018-01-23 18:26:23
PR,MKL DNN fixed a bug related to feature column test in python,The fix only affects one file mkl aggregate cc It fixes both MKL ML and MKL DNN unit test test case The test case is python feature column feature column test unit test With the test case now the test case passes,,ashraf-bhuiyan,2018-01-12 01:38:22,2018-01-23 18:28:08
PR,Update download dependencies sh to prevent crash from 403,The eigen bitbucket seems to have changed causing the scrip to crash with a unrecognized archive error Changing to grep v mirror bazel seems to fix this because otherwise we get a 403 forbidden error,,rmlarsen,2018-01-12 22:20:03,2018-01-23 18:28:28
PR,Minor improvements to TFRecord format docs,The TFRecord format documentation mentions that hashes are computed using a CRC32 but does not mention the polynomial used I added that detail so the documentation is now sufficient for a developer trying to write a parser writer for uncompressed TFRecord files,,"pwnall,pwnall,rmlarsen",2018-01-15 01:26:53,2018-01-23 18:29:39
PR,Load region from aws config if possible in S3,This fix tries to address the issue raised in issuecomment 354272697 where TensorFlow does not load region from aws config if exists The reason was that AWS C SDK does not use the config file by default This fix adds the loading of config file aws config explicitly if either AWS REGION or S3 REGION is not available In case none of the AWS REGION S3 REGION aws config is available then the default use east 1 is used by AWS C SDK This fix is related to 15562 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,asimshankar,yongtang,jhseu,jhseu,yongtang",2017-12-30 01:58:15,2018-01-23 18:34:28
PR,Fix crash in tf contrib ffmpeg decode video,This fix fixes the crash in tf contrib ffmpeg decode video The reason for the crash was that decode video dumps the information about streaming etc as opposed to dump to stderr info a file and read from it As the loglevel was error the file was empty This fix addresses the issue The fix could be verifed by manually running With this fix the above test works Signed off by Yong Tang yong tang github outlook com,,"yongtang,yongtang",2018-01-13 19:55:57,2018-01-23 18:36:35
PR,tpu contrib fix,fix the issue in,,,2018-01-23 10:33:16,2018-01-23 18:51:28
PR,De Bazel check load py test sanity check,See issuecomment 354156560 for reference Friendly ping,,"Androbin,martinwicke,gunan,gunan,gunan,Androbin,martinwicke",2017-12-28 01:36:12,2018-01-23 19:15:58
PR,Turn check futures test into a sanity check,See issuecomment 354156560 for reference cc,,"Androbin,drpngx,Androbin,drpngx,drpngx,drpngx,drpngx,martinwicke,rmlarsen,Androbin,martinwicke",2017-12-27 22:23:12,2018-01-23 19:16:30
PR,Support Negativo17 Fedora Packaging,Support the Negativo17 Nvidia driver packaging for Fedora libdevice libraries are under usr share cuda includes are under usr include cuda and libraries are under usr lib64 This PR should help 8264 too In addition the gcc 5 3 in the Negativo17 repository installed as usr bin gcc53 only has a static non PIC version of libgomp a so I have this local patch to force Tensorflow to link to the global usr lib64 shared version,,"gunan,rmlarsen,gunan",2017-12-24 13:05:18,2018-01-23 19:21:34
IS,Published libtensorflow framework so binaries ABI Problem,The distributed libtensorflow framework so included in the JAR files published to Maven are built using the C 11 ABI in contrast to the main TF build I think that affects all continuous integration builds of the shared objects I believe the D GLIBCXX USE CXX11 ABI 0 compiler flag should be used for the CI builds as is done for the main build An example of its use is shown in commit 550df413158b32645ca5df4dcaabc67f1a48964d This causes some trouble when using these shared objects and developing custom ops as those are required to be built using that compiler flag It would be great if the use of the flag was consistent and all binaries were built using the same ABI Thanks,,"eaplatanios,eaplatanios",2018-01-23 06:57:28,2018-01-23 19:50:27
PR,Fixes 16314,Fixes 16314,,"eaplatanios,eaplatanios,gunan,eaplatanios",2018-01-23 18:47:02,2018-01-23 19:50:27
PR,Make platform a proper module,This fixes an issue where the nice error about importing tensorflow from the TF source directory is not displayed in Python 2 7 Fixes 16019,,"rmlarsen,rmlarsen,rmlarsen",2018-01-11 22:58:56,2018-01-23 20:00:35
IS,tf nightly and master cannot import tensorflow,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 TensorFlow installed from source or binary Binary TensorFlow version use command below tf nightly gpu 1 6 0 dev20180110 Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source CUDA cuDNN version 9 0 7 GPU model and memory V100 16GB Exact command to reproduce Source code logs N A,,pvaneck,2018-01-10 20:50:09,2018-01-23 20:01:03
PR,Adding meta graph be pb testdata for big endian for framework meta graph test,,,"namrata-ibm,namrata-ibm,drpngx,namrata-ibm,drpngx,namrata-ibm,drpngx,rmlarsen,rmlarsen",2018-01-10 09:11:05,2018-01-23 20:02:57
PR,Assert3DImage that adds a control dependency for the shape check,I noticed that the Check3DImage was always used in exactly the same way and extracted this into its own convenience function The only remaining use of Check3DImage was an import in gen image ops py saying TODO drpng remove these once internal use has discontinued so maybe it could be removed entirely,,rmlarsen,2018-01-07 12:32:26,2018-01-23 20:03:45
IS,Maven Nightlies,asimshankar Would it be possible to start releasing Maven nightlies for the Java API packages I only depend on the org tensorflow Proto package but I guess it would be more consistent to do that for all the Java API packages,,"eaplatanios,asimshankar,asimshankar",2017-12-21 05:39:27,2018-01-23 20:17:27
PR,fix doc for benchmark model for android,after configure py set framework shared object true benchmark model wo not build for Android without tweeks Add ' config monolithic' to avoid confusion,,"freedomtan,drpngx,gunan,allenlavoie,freedomtan,allenlavoie,freedomtan,allenlavoie",2017-12-26 09:53:39,2018-01-23 20:19:07
IS,Distributed Tensorflow using MPI,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy I have tried stackflow and Google group discussion forum but could get any reply or comment 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information OS Platform and Distribution e g Linux Ubuntu 16 04 Redhat 7 4 TensorFlow installed from source or binary from source with MPI TensorFlow version use command below 1 41 Python version 2 7 14 Bazel version if compiling from source GCC Compiler version if compiling from source GCC 6 0 CUDA cuDNN version 8 0 6 5 GPU model and memory NVIDIA SMI 384 81 Driver Version 384 81 GPU Name Persistence M Bus Id Disp A Volatile Uncorr ECC Fan Temp Perf Pwr Usage Cap Memory Usage GPU Util Compute M 0 Tesla K20Xm Off 00000000 08 00 0 Off 0 N A 34C P0 61W 235W 0MiB 5699MiB 72 Default Processes GPU Memory GPU PID Type Process name Usage No running processes found Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request I am using the following script to launch distributed computing bin bash module load openmpi 3 0 0 gnu host hostname s if host node06 then echo statring Node 6 python tf dis 2 py job name ps task index 0 elif host node07 then echo starting Node 7 as worker python tf dis 2 py job name worker task index 0 elif host node08 then echo starting Node 8 as worker python tf dis 2 py job name worker task index 1 fi I am running it on slurm with three nodes srun N 3 n 3 gres gpu 1 w node 06 08 test sh I am using MPI instead of GPRC I am getting the following message srun N 3 n 3 gres gpu 1 w node 06 08 test sh statring Node 6 starting Node 8 as worker starting Node 7 as worker 2018 01 15 11 34 59 961617 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name Tesla K20Xm major 3 minor 5 memoryClockRate GHz 0 732 pciBusID 0000 08 00 0 totalMemory 5 57GiB freeMemory 5 49GiB 2018 01 15 11 34 59 961674 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K20Xm pci bus id 0000 08 00 0 compute capability 3 5 E0115 11 35 00 020327488 36133 ev epoll1 linux c 1051 grpc epoll fd 22 2018 01 15 11 35 00 026716 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 node06 2222 2018 01 15 11 35 00 026760 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 node07 2223 1 localhost 2224 2018 01 15 11 35 00 029261 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 2224 2018 01 15 11 35 00 439045 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name Tesla K20Xm major 3 minor 5 memoryClockRate GHz 0 732 pciBusID 0000 08 00 0 totalMemory 5 57GiB freeMemory 5 49GiB 2018 01 15 11 35 00 439124 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K20Xm pci bus id 0000 08 00 0 compute capability 3 5 E0115 11 35 00 497022377 13701 ev epoll1 linux c 1051 grpc epoll fd 22 2018 01 15 11 35 00 503585 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 localhost 2222 2018 01 15 11 35 00 503622 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 node07 2223 1 node08 2224 2018 01 15 11 35 00 505803 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 2222 2018 01 15 11 33 39 681311 I tensorflow core common runtime gpu gpu device cc 1030 Found device 0 with properties name Tesla K20Xm major 3 minor 5 memoryClockRate GHz 0 732 pciBusID 0000 08 00 0 totalMemory 5 57GiB freeMemory 5 49GiB 2018 01 15 11 33 39 681375 I tensorflow core common runtime gpu gpu device cc 1120 Creating TensorFlow device device GPU 0 device 0 name Tesla K20Xm pci bus id 0000 08 00 0 compute capability 3 5 E0115 11 33 39 739196190 46236 ev epoll1 linux c 1051 grpc epoll fd 22 2018 01 15 11 33 39 745655 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job ps 0 node06 2222 2018 01 15 11 33 39 745697 I tensorflow core distributed runtime rpc grpc channel cc 215 Initialize GrpcChannelCache for job worker 0 localhost 2223 1 node08 2224 2018 01 15 11 33 39 747692 I tensorflow core distributed runtime rpc grpc server lib cc 324 Started server with target grpc 2223 Abid Malik Extracting MNIST data train images idx3 ubyte gz Extracting MNIST data train labels idx1 ubyte gz Extracting MNIST data t10k images idx3 ubyte gz Extracting MNIST data t10k labels idx1 ubyte gz Variables initialized Traceback most recent call last File tf dis 2 py line 102 in module sv tf train Supervisor is chief FLAGS task index 0 logdir tmp train logs global step global step init op init op File home amalik local lib python2 7 site packages tensorflow python training supervisor py line 336 in init self verify setup File home amalik local lib python2 7 site packages tensorflow python training supervisor py line 885 in verify setup their device set s op ValueError When using replicas all Variables must have their device set name weights Variable op VariableV2 attr key container value s attr key dtype value type DT FLOAT attr key shape value shape dim size 784 dim size 100 attr key shared name value s 2018 01 15 11 33 41 719083 E tensorflow core distributed runtime master cc 269 Master init Unavailable Endpoint read failed Extracting MNIST data train images idx3 ubyte gz Extracting MNIST data train labels idx1 ubyte gz Extracting MNIST data t10k images idx3 ubyte gz Extracting MNIST data t10k labels idx1 ubyte gz Variables initialized Traceback most recent call last File tf dis 2 py line 114 in module with sv prepare or wait for session server target as sess File home amalik local lib python2 7 site packages tensorflow python training supervisor py line 708 in prepare or wait for session init feed dict self init feed dict init fn self init fn File home amalik local lib python2 7 site packages tensorflow python training session manager py line 273 in prepare session config config File home amalik local lib python2 7 site packages tensorflow python training session manager py line 205 in restore checkpoint saver restore sess ckpt model checkpoint path File home amalik local lib python2 7 site packages tensorflow python training saver py line 1666 in restore self saver def filename tensor name save path File home amalik local lib python2 7 site packages tensorflow python client session py line 889 in run run metadata ptr File home amalik local lib python2 7 site packages tensorflow python client session py line 1120 in run feed dict tensor options run metadata File home amalik local lib python2 7 site packages tensorflow python client session py line 1317 in do run options run metadata File home amalik local lib python2 7 site packages tensorflow python client session py line 1336 in do call raise type e node def op message tensorflow python framework errors impl UnavailableError Endpoint read failed srun error node08 task 2 Exited with exit code 1 srun error node07 task 1 Exited with exit code 1 Why is it crashing I have been trying to solve this for the last three weeks by putting it on different forums and groups However could not get any reply I would be grateful if someone can guide me I apologize in advance if this is not the right forum Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Have I written custom code as opposed to using a stock example script provided in TensorFlow from future import print function import tensorflow as tf import sys import time print Abid Malik parameter servers node06 2222 workers node07 2223 node08 2224 cluster tf train ClusterSpec ps parameter servers worker workers tf app flags DEFINE string job name Either 'ps' or 'worker' tf app flags DEFINE integer task index 0 Index of task within the job FLAGS tf app flags FLAGS server tf train Server cluster job name FLAGS job name task index FLAGS task index batch size 100 learning rate 0 0005 training epochs 20 logs path tmp mnist 1 from tensorflow examples tutorials mnist import input data mnist input data read data sets 'MNIST data' one hot True if FLAGS job name ps server join elif FLAGS job name worker with tf device tf train replica device setter worker device job worker task d FLAGS task index cluster cluster global step tf get variable 'global step' initializer tf constant initializer 0 trainable False with tf name scope 'input' x tf placeholder tf float32 shape None 784 name x input y tf placeholder tf float32 shape None 10 name y input tf set random seed 1 with tf name scope weights W1 tf Variable tf random normal 784 100 W2 tf Variable tf random normal 100 10 with tf name scope biases b1 tf Variable tf zeros 100 b2 tf Variable tf zeros 10 with tf name scope softmax y is our prediction z2 tf add tf matmul x W1 b1 a2 tf nn sigmoid z2 z3 tf add tf matmul a2 W2 b2 y tf nn softmax z3 with tf name scope 'cross entropy' this is our cost cross entropy tf reduce mean tf reduce sum y tf log y reduction indices 1 with tf name scope 'train' grad op tf train GradientDescentOptimizer learning rate train op grad op minimize cross entropy global step global step with tf name scope 'Accuracy' accuracy correct prediction tf equal tf argmax y 1 tf argmax y 1 accuracy tf reduce mean tf cast correct prediction tf float32 tf summary scalar cost cross entropy tf summary scalar accuracy accuracy saver tf train Saver summary op tf summary merge all init op tf global variables initializer print Variables initialized sv tf train Supervisor is chief FLAGS task index 0 logdir tmp train logs global step global step init op init op begin time time time frequency 100 with sv prepare or wait for session server target as sess create log writer object this will log on every machine writer tf summary FileWriter logs path graph tf get default graph perform training cycles start time time time for epoch in range training epochs number of batches in one epoch batch count int mnist train num examples batch size count 0 for i in range batch count batch x batch y mnist train next batch batch size perform the operations we defined earlier on batch cost summary step sess run train op cross entropy summary op global step feed dict x batch x y batch y writer add summary summary step count 1 if count frequency 0 or i 1 batch count elapsed time time time start time start time time time print Step d step 1 Epoch 2d epoch 1 Batch 3d of 3d i 1 batch count Cost 4f cost AvgTime 3 2fms float elapsed time 1000 frequency count 0 print Test Accuracy 2 2f sess run accuracy feed dict x mnist test images y mnist test labels print Total Time 3 2fs float time time begin time print Final Cost 4f cost sv stop print done,,"aselle,jbedorf,mrry",2018-01-15 18:05:52,2018-01-23 20:26:01
PR,Apply final cherry picks for 1 5 0 release,,,angersson,2018-01-23 20:56:39,2018-01-23 20:57:36
PR,Fix crash on GPU out of GPU memory for softmax cross entropy with logits,This fix tries to address the issue raised in 6766 where softmax cross entropy with logits will trigger the crash on GPU out of GPU memory if the first dimension is 0 This fix fixes 6766 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-11 21:23:21,2018-01-23 21:12:41
IS,Cannot opened include file tensorflow contrib tpu proto tpu embedding config pb h no such file or directory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source TensorFlow version use command below current git master branch should be v1 4 1 or v1 5 0rc1 Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source MSVC2015 CUDA cuDNN version CPU build only gpu function is off GPU model and memory N A Exact command to reproduce Trying a minimal build with cmake with only snappy support and optimize for native arch turned on Describe the problem Build failing due to missing header files tensorflow contrib tpu proto tpu embedding config pb h Everything build succesful except for tpu project I do not really know how to generate the pb h file from protoc manually I trying to fix the problem by chaning cmake files but not sure which one is for tpu Source code logs 133 D MSVC source tensorflow tensorflow contrib tpu ops tpu embedding ops cc 16 fatal error C1083 Cannot open include file 'tensorflow contrib tpu proto tpu embedding config pb h' No such file or directory,,,2018-01-21 02:28:38,2018-01-23 21:28:01
IS,Remove Variables from a TF Server e g,I have a cluster of long lived TensorFlow servers tensorflow core distributed runtime rpc grpc tensorflow server My problem is how to reset variables on these server There is a behavior in distributed TensorFlow in which a variable defined on a worker e g PS outlives the session which defines it I understand this behavior is intentional to support between graph model replica However In my use case this behavior causes unexpected problem I have not found a mechanism to override this It there is I believe it is helpful to better reflect it in the documentation if there is not I hope I can make a case to motivate its existence In my use case different training jobs are ran sequentially i e one training job at a time on this cluster each using one client which connects to only one master The problem I have is if a variable is defined in two training job with a same name but different shape sizes the latter client gets the following error on Session creation This example fails,,mrry,2018-01-23 07:33:05,2018-01-23 21:29:30
IS,CMake external package PIC option not working,In many of external cmake files I will send a PR after some testing along with other fixes e g linking to ZLIB as shared object not static linking update requested from Have I written custom code No OS Platform and Distribution PR tested at Ubuntu 16 04 and Tizen TensorFlow installed from N A TensorFlow version github master branch of last week 00f8b97fc601381546aea89315dee549bdbbbdfc Bazel version N A doing it without bazel CUDA cuDNN version Tizen 9 7 Ubuntu 8 6 GPU model and memory Titan Xp Exact command to reproduce N A it is about build,,"myungjoo,myungjoo,myungjoo",2017-12-15 05:30:13,2018-01-23 21:40:45
PR,CMake fix fPIC control,if endif cannot be stated inside Use tensorflow ENABLE POSITION INDEPENDENT CODE itself to express ON or OFF it is already set as ON or OFF by tensorflow contrib cmake CMakeLists txt Fixes 15380 Signed off by MyungJoo Ham myungjoo ham samsung com,,myungjoo,2017-12-15 05:43:00,2018-01-23 21:40:45
PR,Add property to get cell wrapped by DropoutWrapper,Adding wrapped cell property as discussed in 15810,,"caisq,sherrym,drpngx,rmlarsen,rmlarsen",2018-01-10 12:20:19,2018-01-23 21:46:26
PR,Replace inception5h references with inception v1,In addition to bringing the name to the updated naming scheme the new archive contains a version of the graph which does not have the CPU attribute set meaning that it will run with GPU acceleration if available,,andrewharp,2018-01-23 01:28:01,2018-01-23 22:11:52
IS,Feature request optionally return all audio streams in tf contrib ffmpeg decode audio,I'm trying to read musdb18 with tf data and it comes in the form of mp4 files with multiple audio streams so ffmpeg map is needed tf contrib ffmpeg decode audio cannot be configured to choose the audio stream I wonder if we could have a tf contrib ffmpeg decode audios that returns every audio stream in the file or if we could have a new argument in tf contrib ffmpeg decode audio for choosing streams Being able to choose the audio stream is also important for getting the right language in a movie file is audio and similarly tf contrib ffmpeg decode video could need the same extension though multiple video streams is not as common AFAIK,,"carlthome,carlthome,shivaniag,vrv,yongtang",2018-01-12 16:28:55,2018-01-23 22:21:40
PR,Add stream selection support for tf contrib ffmpeg decode audio,This fix tries to address the issue raised in 16073 where it was not possible to selectively decode a perticular stream with tf contrib ffmpeg decode audio This fix adds an additional attribute stream which could be used to specify the stream to decode e g stream 1 By default stream which leaves the decision to ffmpeg This fix fixes 16073 Signed off by Yong Tang yong tang github outlook com,,"yongtang,carlthome,carlthome,yongtang,yongtang,carlthome,yongtang,fredbertsch,yongtang,rmlarsen,yongtang,yongtang",2018-01-13 15:50:52,2018-01-23 22:21:40
PR,Fix a bug that capture tpu profile only takes absolute logdir path,Also removed package dependancy on tensorflow for better compatibility,,,2018-01-23 21:23:02,2018-01-23 22:42:42
IS,Bug of tf data TFRecordDataset Could not use tf reshape after the operations of tf data TFRecordDataset,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 1 Python version 2 7 12 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory Nvidia GeForce GTX TITAN X 12GB Exact command to reproduce Describe the problem I want to use function tf profiler ProfileOptionBuilder float operation to show the flops of the model But it need a certain input shape while the the output shape of tf data TFrecordDataset is like 32 32 3 When I want to use tf reshape to reshape the output of tf data TFrecordDataset it generates an error Input to reshape is a tensor with 64512 values but the requested shape has 98304 Source code def dataset input self dataset type with tf variable scope batch dataset type def parser record features tf parse single example record features 'image' tf FixedLenFeature tf string 'label' tf FixedLenFeature tf int64 image label features 'image' features 'label' height width channels self input size self input size self input dim image tf decode raw image tf uint8 image tf reshape image height width channels return image label dataset tf data TFRecordDataset self dataset dir dataset type dataset dataset map parser dataset dataset shuffle buffer size 50000 dataset dataset batch self batch size dataset dataset repeat iterator dataset make one shot iterator features labels iterator get next features tf reshape features self batch size self input size self input size self input dim return features labels,,mrry,2018-01-23 06:26:49,2018-01-23 22:45:02
IS,Bug of tf data TFRecordDataset or my codes wrong,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 3 6 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory Nvidia Quadro K4000 Exact command to reproduce I tested to write dynamic numbers of variables into tfrecord But when I use the tf data TFRecordDataset to read VarLenFeature the program crashes However if I do not use dataset but just tf python io tf record iterator The program works without problem I wonder whether this is a bug of tf data TFRecordDataset or there is something wrong in my codes My writing codes are def test write writer tf python io TFRecordWriter 'test tfrecord' for i in range 3 val list for j in range i 1 val list append i j feature dict 'val' tf train Feature int64 list tf train Int64List value val list example tf train Example features tf train Features feature feature dict writer write example SerializeToString writer close The reading codes using tf data TFRecordDataset and causing error are def parse test example features 'val' tf VarLenFeature dtype tf int64 parsed features tf parse single example example features return parsed features def test read dataset tf data TFRecordDataset 'test tfrecord' dataset dataset map parse test dataset dataset batch 1 iterator dataset make one shot iterator feature dict iterator get next with tf Session as sess for in range 3 curr dict sess run feature dict print curr dict 'val' The error message is TypeError Failed to convert object of type class 'tensorflow python framework sparse tensor SparseTensor' to Tensor Contents SparseTensor indices Tensor ParseSingleExample Slice Indices val 0 shape 1 dtype int64 values Tensor ParseSingleExample ParseExample ParseExample 1 shape dtype int64 dense shape Tensor ParseSingleExample Squeeze Shape val 0 shape 1 dtype int64 Consider casting elements to a supported type The successful reading codes without using tf data TFRecordDataset are as below def test read2 with tf Session as sess for serialized example in tf python io tf record iterator 'test tfrecord' features tf parse single example serialized example features 'val' tf VarLenFeature dtype tf int64 temp features 'val' values sess run temp print values This code successfully print out SparseTensorValue indices array 0 dtype int64 values array 0 dtype int64 dense shape array 1 dtype int64 SparseTensorValue indices array 0 1 dtype int64 values array 1 2 dtype int64 dense shape array 2 dtype int64 SparseTensorValue indices array 0 1 2 dtype int64 values array 2 3 4 dtype int64 dense shape array 3 dtype int64 However I am still hoping to use the dataset structure to deal with the VarLenFeature Is there anything wrong with my reading codes or there is a bug in tf data TFRecordDataset Thank you,,mrry,2018-01-22 19:48:46,2018-01-23 22:48:02
IS,A new S3Client is created with all file operations,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 OS X 10 12 6 TensorFlow installed from source or binary source TensorFlow version use command below commit 4595f1cff635ce024e875f0f3d480172731b0b22 Python version 3 6 Bazel version if compiling from source 0 5 4 homebrew GCC Compiler version if compiling from source Apple LLVM version 9 0 0 clang 900 0 39 2 CUDA cuDNN version N A GPU model and memory N A Describe the problem The S3 filesystem creates a new Aws S3 S3Client object with all interactions with S3 This is a heavyweight object and takes relatively large amount of time to create and destroy This should be a singleton associated with the filesystem object Fix shortly,,,2018-01-18 23:39:21,2018-01-23 22:53:51
PR,Singleton S3Client,Fixes 16230 This drastically speeds up performance of interactions with S3 and eliminates a lot of spurious log warnings when interacting with S3 files The filesystem unit tests went from taking 40 seconds to taking 4 seconds with this change a 10X performance improvement Some items of note I updated the delete test to work on a bucket that had tests run previously Without this change a manual wipe of the file in quest was required after each run I moved the request timeout to a central location instead of being local to the Sync operation I eliminated the increased connection timeout for Sync which should not be needed Configuration is no longer a static variable protected by a mutex but instead created as needed This should be non functional given that config is only created once during normal operation now,,"drpngx,drpngx,drpngx,drpngx,rmlarsen,drpngx,drpngx,drpngx,rmlarsen",2018-01-18 23:54:26,2018-01-23 22:53:51
PR,Workaround 'too perfect forwarding' issue in variant op registry,In variant op registry h seems to be falling victim to 'too perfect forwarding' issue SO link Andrzej is blog with gcc 6 4 gcc 7 2 and clang 4 in ubuntu 17 10 and possibly others This PR works around the issue by replacing std tuple with a simple struct,,"samikama,samikama,rmlarsen,samikama",2018-01-23 03:08:35,2018-01-23 23:13:15
IS,Feature request add a local init feed dict to tf train Scaffold,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 0 Python version 3 6 1 Bazel version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See below Describe the problem Feature request add a local init feed dict to tf train Scaffold It would be useful to be able to create local variables which are not saved or restored and have them initialized by a tf train MonitoredTrainingSession with a feed dict In the example below the variable X var is forced to be part of the GLOBAL VARIABLES collection in order to be able to initialize the variable with a feed dict This has the undesirable consequence that the variable will be saved to disk Source code logs,,"reedwm,reedwm,ispirmustafa,reedwm",2017-07-21 11:37:38,2018-01-23 23:40:32
IS,Eager variable created in defun is invalid and raise error when print,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0dev20171230 Python version 3 6 Describe the problem I want to use defun to speed up static rnn compute in eager locate this error cost me much time please consider to fix it,,"alextp,alextp,akshayka",2017-12-31 08:13:11,2018-01-24 00:39:08
IS,Size of TFRecord is much more larger than CSV format,Testing Data adult data in Problem To use a tf contrib data TFRecordDataset i tried to convert adult data in CSV into a TFRecord but i just found that the TFRecord after converted is about 12MB while the original CSV is only about 3MB oops why the storage efficiency for TFRecord is so poor Source code for converting CSV to TFRecord System information OS Platform Mac OS X 10 12 5 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 3 0 Python version 2 7 Bazel version if compiling from source None CUDA cuDNN version None GPU model and memory None,,"reedwm,reedwm",2017-10-09 06:56:46,2018-01-24 03:01:00
IS,fake quant with min max vars does not change min max vars,System Information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary pip3 install upgrade tensorflow gpu TensorFlow version use command below v1 4 0 19 ga52c8d9 1 4 1 Python version 3 5 2 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source GCC 5 4 0 CUDA cuDNN version Cuda compilation tools release 8 0 V8 0 61 cuDNN 6 0 21 GPU model and memory Two GeForce GTX 1080 Ti devices Exact command to reproduce N A Problem description I have got a problem with tf lite conversion tool There is learned graph which should be converted in tflite format and quantinized I have read the answer where authors recommend to create new network with fake quant operations and retrain it However variables passed in tf fake quant with min max vars op did not change their values during training Here is modeling code which shows the problem Code to reproduce,,,2017-12-28 08:39:27,2018-01-24 04:46:01
PR,Loosen bounds on losses impl test fixes 16238,This should fix issue 16238 where this test fails on some architectures,,joel-shor,2018-01-24 06:12:24,2018-01-24 06:54:45
IS,Make a tools CLI for easy access to freeze graph saved model cli etc,Related to 6134 Right now the users of the tensorflow python tools scripts have these options Download and save a copy of the individual py file with whatever model project they are working on so that it is bundled with their code This causes tons of code duplication across projects Import the tools programmatically and use them there Being able to do this is extremely handy but often the most convenient way to use the tool and the way they are generally designed to be used are as ad hoc command line calls Build a binary using Bazel This is extremely inconvenient and does not really solve the problem of code reuse from above I would also argue that building a binary for what amounts to a Python script is overkill Create a custom CLI module alias that bundles these tools together or allows for a single tool to be called from anywhere This is convenient but complicates setting up a development environment and leads to divergent patterns across the user base I think having some sort of unified tool that is able to provide uniform access to the CLI of frequently used tools such as freeze graph py and saved model cli py would greatly improve UX as well as make it much easier to explain how to use these tools Additionally it would help prevent version mismatches of tooling as the correct version of the tool would already be at their fingertips instead of fumbling through GitHub branches I think having some sort of simple umbrella module let is call it tftools which provides access to the underlying python files would suffice E g This would be a little bit of legwork but I think the benefit out to effort in ratio is pretty large at least from a user perspective Not sure if the TensorFlow team would want to handle this or leave it to the community if I can get company approval I would be happy to take a crack at it,,"samjabrahams,carlthome,samjabrahams,yifeif,samjabrahams,yifeif,petewarden,samjabrahams,yifeif,carlthome",2017-09-25 06:36:50,2018-01-24 07:43:36
PR,Make graph transform tool accessible via command line for pip install,RELNOTE Make graph transform tool available from command line as transform graph for pip package Fix 13287,,"yifeif,gunan,yifeif,gunan,rmlarsen",2018-01-09 05:23:56,2018-01-24 07:43:36
PR,R1 4,,,,2018-01-24 01:52:08,2018-01-24 07:43:58
PR,Fix typo,,,ManHyuk,2018-01-24 00:31:07,2018-01-24 07:45:59
PR,Fix typos,This PR fixes some typos intializes nubmer varibale fuction Ouput avaliable ouput and Explictly,,taehoonlee,2018-01-24 03:36:43,2018-01-24 07:48:24
IS,Quantized graph on ssd mobilenet fails with InvalidArgumentError,I am using ssd mobilenet v1 coco 2017 11 17 and quantized it using following command bazel bin tensorflow tools graph transforms transform graph in graph ssd mobilenet v1 coco 2017 11 17 frozen inference graph pb out graph ssd mobilenet v1 coco 2017 11 17 frozen quant pb inputs 'image tensor' outputs wouldetection boxes detection scores detection classes' transforms 'add default attributes strip unused nodes type float shape 1 299 299 3 remove nodes op Identity op CheckNumerics fold constants ignore errors true fold batch norms fold old batch norms quantize weights quantize nodes strip unused nodes sort by execution order' I am using tensorflow v 1 4 1 for detecting bounding box and it throws following error InvalidArgumentError The node 'Preprocessor map while ResizeImage ResizeBilinear eightbit' has inputs from different frames The input 'Preprocessor map while ResizeImage size' is in frame 'Preprocessor map while while context' The input 'Preprocessor map while ResizeImage ResizeBilinear eightbit Preprocessor map while ResizeImage ExpandDims quantize' is in frame '',,,2017-12-13 08:24:37,2018-01-24 08:52:28
IS,The keys in end points of slim are not unified for different layers,Look at the code For max pool2d layer the key has prefix xx but for conv2d layer it do not have prefix xx Because in conv2d it uses variable scope but in max pool2d it uses name scope So the behavior looks inconsistent and may cause the code make mistake Do we need to unify the behavior For example if we use multi gpu to train the network and we have many clones of network which name scope is prefix are clone 1 clone 2 and so on If we want to use the key of end points to get the output of layer on different gpu We should deal with max pool2d and conv2d differently,,"aselle,sguada",2017-11-28 13:45:35,2018-01-24 09:04:05
IS,how to set ignore label in tensorflow,when i set the label 1 there is an error Received a label value of 1 which is outside the valid range of 0 8,,,2018-01-17 13:31:38,2018-01-24 13:24:20
IS,Gradient computation across multi GPU,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 Python version 2 7 6 CUDA cuDNN version 8 0 6 0 I am trying to compute global mean and global variance for batch normalization layer across GPUs both forward and backward should be considered With sigma 2 mean x 2 mean x 2 the gradient w r t each x can be computed independently in the GPU that x is attached to However when computing the gradients I met a problem without specifying GPU device tf gradient will use the gpu 0 I cannot specify each operation of gradient computation because the gradients are computed automatically by the optimizer and only gradients of parameters are computed My question is that if a node is explicitly attached to a GPU device why the gradient can not be attached to the same GPU device I tried this code and get two timeline files timelines zip and two snapshots bellow import tensorflow as tf import numpy as np from tensorflow python client import timeline N SAMPLES 100000000 def all reduce gpu num means x2s axs for i in range gpu num with tf device ' cpu 0' x tf placeholder dtype tf float32 shape N SAMPLES name 'local input d' i with tf device ' gpu d' i ax tf multiply 10 0 x name 'local multiply d' i mean tf reduce mean ax name 'local mean d' i x2 tf square ax name 'local square d' i axs append ax means append mean x2s append x2 with tf device ' gpu 0' global mean tf reduce mean means name 'global mean' global var tf subtract tf reduce mean x2s name 'global x2' tf square global mean name 'global mean square' name 'global sub' print global var get shape gs manually for i in range gpu num with tf device ' gpu d' i gradient wrt mean tf gradients global mean axs i gradient wrt var tf gradients global var axs i gs append gradient wrt mean gs append gradient wrt var auto by tf gradient wrt mean tf gradients global mean axs gradient wrt var tf gradients global var axs gs append gradient wrt var gs append gradient wrt mean for n in tf get default graph as graph def node print n name n device return global mean global var axs gs def main gpu num 2 mean op var op xs gs all reduce gpu num x np random randn N SAMPLES gpu num print np mean x np var x feed dict dict for i in range gpu num feed dict xs i x i N SAMPLES i 1 N SAMPLES run options tf RunOptions trace level tf RunOptions FULL TRACE run metadata tf RunMetadata gpu options tf GPUOptions allow growth False config tf ConfigProto log device placement False gpu options gpu options sess tf Session config config mean var g sess run mean op var op gs feed dict feed dict options run options run metadata run metadata print mean var g sess run gs feed dict feed dict options run options run metadata run metadata Create the Timeline object and write it to a json tl timeline Timeline run metadata step stats ctf tl generate chrome trace format with open 'timeline json' 'w' as f f write ctf if name ' main ' tf app run Two figures auto without specifying GPU device image manually specifying GPU device image If using tf gradient without specifying GPU devices only a tf reduce mean operation is done in gpu 1 So is there some easy way that the operations of gradient computation can be assigned automatically to the corresponded GPU device,,ppwwyyxx,2018-01-23 15:30:55,2018-01-24 14:15:40
IS,tf nn separable conv2d is slower than conv2d on GPU,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary binary TensorFlow version use command below TF 1 3 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version CUDA8 0 cuDNN6 GPU model and memory GTX1080ti 11G Describe the problem In theory separable conv2d should be more efficient than conv2d but when I test a simple model on Cifar10 the result shows that nn separable conv2d run slower on GPU but is indeed faster on CPU Here is my test results on GPU,,"vrv,carlthome,carlthome",2017-09-09 23:13:16,2018-01-24 14:53:54
IS,Distributed TF hangs because of CreateSession still waiting for response from worker,UPDATE The first 2 posts are no longer appropriate to describe the issue Please jump to my 3rd post Hi I followed the idea of this L1670 to implement a worker sync queue Everything seemed to work fine except when I increased the size of the dataset or number of workers all workers hang when they try to evaluate the sync op Typical example of my code is as follow For each worker I could occasionally see all workers hang after printing the finishing message My observation so far is that this only happened when dataset is huge or number of worker is big e g 10 TB dataset with 300 500 workers I have not been able to see why this occurred not sure if it is a TF issue or some network bottleneck that I was not aware of Any help would be much appreciated,,"drpngx,drpngx,drpngx,mrry,mrry",2017-11-17 18:57:03,2018-01-24 16:25:15
IS,Compilation failure with gcc 6 4 gcc 7 2 and clang 4 in ubuntu 17 10,When compiling master in ubuntu 17 10 compilation fails due to 'too perfect forwarding' in variant op registry std unordered map std tuple VariantXOp StringPiece StringPiece VariantXOpFn TupleHash A workaround by replacing tuple with a struct provided in PR 16309 for your review Thanks Sami,,"samikama,samikama",2018-01-23 17:17:44,2018-01-24 16:40:37
IS,Eager crashed when using embedding lookup in tfe defun in tfe GradientTape,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Win10 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0dev20171230 Python version 3 6 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version 9 0 7 0 GPU model and memory pascal Exact command to reproduce N A Describe the problem When I train a seq2seq model in eager backward will raise a error,,asimshankar,2018-01-04 16:01:07,2018-01-24 16:50:20
PR,Remove path to str from the public API,martinwicke fyi,,"jhseu,rmlarsen,rmlarsen,martinwicke",2018-01-23 23:48:50,2018-01-24 17:20:46
PR,tflite make calling NNAPI work again,calling PrepareOpsAndTensors before using NN API looks 1 unnecessary 2 will decrease next node to prepare so that the next will fail,,freedomtan,2018-01-20 00:01:05,2018-01-24 17:31:14
IS,I have an issue with always getting stuck,Can anyone help me with this issue I start up the Visualizing High Dimensional Space webstie and it loads until it says something about metadata and never does anything from there Plese help I'm so confused,,aselle,2018-01-24 14:35:43,2018-01-24 17:41:16
IS,Bug SDCAModel missbehave bug when mixing sparse and dense features,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Up to date Arch Linux TensorFlow installed from source or binary Binary TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Any toy problem using SDCAModel that mixes sparse and dense features Describe the problem It is a bug When using both sparse and dense features in SDCAModel the linear predictions method output a tensor of wrong shape This happens because the sparse results and dense results ranks are inconsistent in the current version and summing them trigger an unexpected broadcast fixes the bug,,,2017-09-25 09:50:03,2018-01-24 17:58:20
PR,Fix result shape of tf tensordot unknown when axes is an integer number,8452 add the function Tensordot partial shape inference solves the problem 6682 However the shape of result of tensordot is still unknown when axes is an integer N which is in common use For example The simplified is more common and the partial shape should be inferred correctly This PR solves the problem,,"lspvic,rmlarsen,lspvic,lspvic,rmlarsen,lspvic,rmlarsen",2018-01-18 12:10:26,2018-01-24 18:29:16
PR,Fix typo,fix typo,,"ManHyuk,rmlarsen",2018-01-24 12:25:33,2018-01-24 18:29:36
PR,Bazel Windows Do not use Wl lpthread and lm on Windows,,,"rongjiecomputer,rmlarsen",2018-01-24 00:48:57,2018-01-24 18:37:25
PR,support preconditioner for conjugated gradient in linear equations py,1 support preconditioner for conjugated gradient in tensorflow tensorflow contrib solvers python ops linear equations py 2 add identity operator in util py as default preconditioner 3 edit unit test files util test py linear equations test py to validate preconditioner,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen",2018-01-19 07:12:01,2018-01-24 18:39:00
PR,minor spelling tweaks for eager execution docs,,,"brettkoonce,rmlarsen",2018-01-24 06:35:52,2018-01-24 18:45:52
PR,Andrewharp patch 1,,,,2018-01-24 14:57:08,2018-01-24 18:45:53
PR,Apply final cherry picks for 1 5 0 release,,,"angersson,angersson,angersson,angersson,av8ramit,angersson",2018-01-23 21:10:12,2018-01-24 18:47:16
PR,Correct channels first format in 1d pooling for tf layers,The code was equivalent in the case of self data format 'channels last' or self data format 'channels first' My modifications fix it when data format 'channels first',,"martinwicke,rmlarsen,martinwicke,martinwicke",2017-12-12 12:10:03,2018-01-24 19:01:44
PR,Setting proper sonames on Linux,Setting proper soname prevents from linking with absolute path when using cmake The reference below contains long conversation about the issue with linking but the general idea is when a library has no DT SONAME field executable is linked with absolute path and can not be used in a different environment setting LD LIBRARY PATH does not help,,"allenlavoie,drpngx,gunan,martinwicke,drpngx",2017-12-12 11:33:48,2018-01-24 19:24:01
PR,Making string values in constant,We already have a constant py in session bundle since adding these string values as a constant,,"rajendraarora16,rajendraarora16,rmlarsen,rajendraarora16",2018-01-23 15:10:05,2018-01-24 19:24:31
PR,Revert 15967 Reduce pip package size,,,yifeif,2018-01-24 18:57:53,2018-01-24 19:34:36
IS,The 2015 Inception checkpoint gives incorrect results,Problems The 2015 Inception checkpoint file called classify image graph def pb which can be found in inception 2015 12 05 tgz gives weird results The tutorial on quantization how can you quantize your models together with this one needs corrections Explanation I originally wanted to try this tutorial on quantization how can you quantize your models to quantize the model and then check the result with label image Using the same name convention as in the tutorial the quantize step will quantize the original graph called classify image graph def pb into a quantized one called quantized graph pb So before checking the latter I wanted to first label image using this classify image graph def pb and this sample image The result should be the same as in this label image is README as shown below This example however uses a newer pre trained graph inception v3 2016 08 28 frozen pb from this compressed file In addition to the pb file the compressed tarball also contains imagenet slim labels txt containing 1 001 lines of label names e g military uniform Differences between checkpoint files There is also another Inception v3 checkpoint file inception v3 2016 03 01 tar gz according to this tutorial on how to fine tune Inception how to fine tune a pre trained model on a new task So I used import pb to tensorboard py to check why the two checkpoints are different Besides the difference in implementation e g how each layers are named the most important difference I noticed is in the last FC layer While inception v3 2016 08 28 frozen pb maps from 2048 to 1001 the 0th class is dummy classify image graph def pb maps from 2048 to 1008 I'm not sure what 1008 means but maybe it was trained with a different set of labels in a different order The naming difference also makes things a little more complicated When calling label image with classify image graph def pb I need to specify input layer Mul 0 output layer softmax 0 because these are the names of the input and output layers However with the new checkpoint that works we do not have to specify these two arguments because input layer input and output layer InceptionV3 Predictions Reshape 1 are already hard coded as the default values in the implementations C and python Related issues There are question related to the differences between these two checkpoints and why they give different performances on certain tasks I have found these issues in the tensorflow models repo 1314 1316 Quantization Now back to quantization Following the current code in the tutorial to quantize classify image graph def pb into quantized graph pb will give an error This is because the sample code is missing an inputs argument compared to this tutorial on graph transforms eight bit calculations The transform graph example needs inputs Mul Then it will work i e predicting toyshop as the top choice Actually this quantization process works with the new inception v3 2016 08 28 frozen pb predicting that the picture is military uniform by both original and quantized graphs Questions What are the actual differences between the three checkpoints Which one should we use Any clarification would be really helpful When different tutorials refer to different checkpoint files at first I thought all of them can be used interchangeably As it turns out they are actually not the same and this has caused a lot of confusion Why is the last layer in classify image graph def pb from 2015 have 1008 nodes not 1001 Is there a way to make classify image graph def pb work following the tutorial Did I miss any arguments or other settings Somewhat unrelated question The tutorial on quantization mentioned above seems to be the same as this one on tensorflow org except for the last few commits Therefore the tutorial on the website is not up to date Are they supposed to be the same How should the tutorials on quantization be updated Personally I think it can be fixed to use the new checkpoint then adjust the example codes accordingly Thank you,,"skye,tfboyd",2017-06-30 15:57:51,2018-01-24 19:39:55
PR,Allowing override of common env sh python directory,PiperOrigin RevId 180806246,,av8ramit,2018-01-24 19:00:49,2018-01-24 19:40:42
PR,Return type annotation,Added type annotations in the docstring to the return types of dataset functions Presented like this they can automatically be read by tools I have tested that this works in PyCharm to improve auto completion when coding This is really useful in case of datasets because they often result in long chained calls something like Dataset generate map repeat batch With this patch code completion works after every again I have only tested PyCharm,,rmlarsen,2018-01-24 11:42:09,2018-01-24 19:58:28
IS,tensorflow 1 4 tf keras gives different result compared with using keras directly,I have tensorflow 1 4 when running the following code the accuracy is different 78 vs 34 90 when I import Sequential Dense and model from json directly from keras uncomment first 3 lines compared with import from tensorflow python keras Why is the big discrepancy the data pima indians diabetes csv is available at from keras models import Sequential from keras layers import Dense from keras models import model from json from tensorflow python keras layers import Dense from tensorflow python keras models import Sequential model from json import numpy import os fix random seed for reproducibility numpy random seed 7 load pima indians dataset dataset numpy loadtxt pima indians diabetes csv delimiter split into input X and output Y variables X dataset 0 8 Y dataset 8 create model model Sequential model add Dense 12 input dim 8 kernel initializer 'uniform' activation arelu' model add Dense 8 kernel initializer 'uniform' activation arelu' model add Dense 1 kernel initializer 'uniform' activation isigmoid' Compile model model compile loss 'binary crossentropy' optimizer 'adam' metrics 'accuracy' Fit the model model fit X Y epochs 150 batch size 10 verbose 0 evaluate the model scores model evaluate X Y verbose 0 print s 2f model metrics names 1 scores 1 100 serialize model to JSON model json model to json with open model json w as json file json file write model json serialize weights to HDF5 model save weights model h5 print Saved model to disk,,"facaiy,shivaniag,fchollet,fchollet",2017-12-01 06:39:42,2018-01-24 20:13:33
IS,Typo in illustrating figure for XLA Concatenation operation,Illustrating image for Concatenate concatenate suggests Concat 2x4 2x8 dimension 0 is 2x12 Should be dimension 1 and same for the other examples,,skye,2017-06-28 04:26:13,2018-01-24 20:22:44
IS,tensorflow python framework errors NotFoundError No algorithm worked,I install the TensorFlow 0 10 0 on Ubuntu 14 0 4 with cuda 7 5 and cudnn 5 1 The GPU is GTX980 when I run a softmax example on minst dataset the TensorFlow can work but when i build CNN with TensorFlow it will cause error if you can help me solve the problem or give some advice it will be great,,"drpngx,yzhwang,yzhwang,yzhwang",2017-07-04 13:04:29,2018-01-24 21:14:42
PR,Update docs and test cases for missing types in tf zeros like,zeros like supports POD types as well as strings However some of the types are missing in the documentation This fix update docs for missing types in tf zeros like where half and string are supported but not listed Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-08 00:50:47,2018-01-24 21:31:34
PR,Documentation fix to contrib signals,Fixed very confusing little typo The input signals is segmented into variable number of frames with frame length 256 frame step is the stride not the size of a frame window,,"rryan,rryan,rryan,rmlarsen",2018-01-05 12:51:26,2018-01-24 21:31:51
PR,Fix a buildscript error which prevents macro being used by other workspaces,Converting to label and back to string will prepend current workspace e g tensorflow org tensorflow tensorflow Projects who integrate TensorFlow from another Bazel workspace and use macros like tflite copts need the prefix For more info please take a look at,,scottcjt,2018-01-19 13:58:49,2018-01-24 21:41:56
PR,R1 4,,,av8ramit,2018-01-24 21:03:18,2018-01-24 22:17:26
PR,Update version names to 1 5 0 from 1 5 0 rc1,,,angersson,2018-01-24 21:24:53,2018-01-24 22:19:01
PR,Branch 183115307,,,"xiejw,rmlarsen,yongtang,rmlarsen",2018-01-24 20:39:34,2018-01-24 22:47:19
IS,Unable to change reuse from True to False when using a variable scope to create new one,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary From source TensorFlow version use command below 'v1 3 0 rc1 633 gcf375f0' '1 2 1 rc1' Python version 2 7 6 Bazel version if compiling from source 0 5 3 CUDA cuDNN version CUDA 8 0 GPU model and memory N A Exact command to reproduce The line of code means that if reuse is None it will use name or scope reuse preventing users from changing reuse to None or False Note that None is the same as False for reuse and tensorflow replaces False with None beforehand at L1540 I think it should be changed to reuse Thank you,,"drpngx,drpngx,allenlavoie,drpngx",2017-10-14 14:11:43,2018-01-24 22:54:41
IS,Modify the TensorFlow Scheduler and Runtime to Change the Operations Priority,Hi I am trying to modify the TensorFlow scheduler and runtime to change the operation priorities As my understanding TensorFlow has inter operation and intra operation thread pool with a scheduler scheduling operations for different threads and there is also a FIFO queue of operations for operations waiting The workflow between them is that operations are sent to the inter op thread pool from the executor and then that work is running through XLA compiler to eventually be executed on the intra op thread pool Schedule is in inside a specific ThreadPool and is to schedule function for the threads in the pool The thread scheduler selects a subset of threads to run at any given moment When the tasks are passed to the ThreadPool they are added to one of the scheduler thread s FIFO queues and then the scheduler will pick up the tasks distributed to the available worker threads I have all the control and data dependencies got from the Graph in TensorFlow by using TensorBoard Now I am not sure whether my understanding for the TensorFlow scheduler and runtime is correct or not The problem is that I still have no clue how and where to modify the threadpool scheduler ready queue or others to change the operations priority sequence for different threads at the TensorFlow runtime by modifying the source code Does anyone have any ideas,,"drpngx,drpngx,drpngx,drpngx",2017-10-16 23:21:17,2018-01-24 22:56:27
IS,CUDNN STATUS INTERNAL ERROR,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 2 TensorFlow installed from source or binary binary via pip TensorFlow version use command below 'v1 3 0 rc2 20 g0787eee' '1 3 0' Python version 2 7 Bazel version if compiling from source n a CUDA cuDNN version Cuda 8 0 via pip cuDNN 6 0 21 GPU model and memory GeForce GTX 1060 6GB Host compiler version GCC 4 9 3 Exact steps to reproduce as per nvidia Tensorflow demo git clone b update models 1 0 cd models tutorials image imagenet python classify image py Describe the problem Tensorflow fails to run demo script despite having installed and re installed as per the manual Any help would be greatly appreciated Source code logs 2017 10 27 16 09 51 154970 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 1 instructions but these are available on your machine and could speed up CPU computations 2017 10 27 16 09 51 155000 W tensorflow core platform cpu feature guard cc 45 The TensorFlow library was not compiled to use SSE4 2 instructions but these are available on your machine and could speed up CPU computations 2017 10 27 16 09 51 349207 I tensorflow stream executor cuda cuda gpu executor cc 893 successful NUMA node read from SysFS had negative value 1 but there must be at least one NUMA node so returning NUMA node zero 2017 10 27 16 09 51 349589 I tensorflow core common runtime gpu gpu device cc 955 Found device 0 with properties name GeForce GTX 1060 6GB major 6 minor 1 memoryClockRate GHz 1 7845 pciBusID 0000 01 00 0 Total memory 5 93GiB Free memory 5 80GiB 2017 10 27 16 09 51 349610 I tensorflow core common runtime gpu gpu device cc 976 DMA 0 2017 10 27 16 09 51 349617 I tensorflow core common runtime gpu gpu device cc 986 0 Y 2017 10 27 16 09 51 349631 I tensorflow core common runtime gpu gpu device cc 1045 Creating TensorFlow device gpu 0 device 0 name GeForce GTX 1060 6GB pci bus id 0000 01 00 0 2017 10 27 16 09 51 672521 W tensorflow core framework op def util cc 333 Op BatchNormWithGlobalNormalization is deprecated It will cease to work in GraphDef version 9 Use tf nn batch normalization 2017 10 27 16 09 52 006440 E tensorflow stream executor cuda cuda dnn cc 371 could not create cudnn handle CUDNN STATUS INTERNAL ERROR 2017 10 27 16 09 52 006471 E tensorflow stream executor cuda cuda dnn cc 338 could not destroy cudnn handle CUDNN STATUS BAD PARAM 2017 10 27 16 09 52 006481 F tensorflow core kernels conv ops cc 672 Check failed stream parent GetConvolveAlgorithms conv parameters ShouldIncludeWinogradNonfusedAlgo T algorithms Aborted core dumped,,"asimshankar,asimshankar,asimshankar,asimshankar,jart,drpngx,drpngx",2017-10-27 23:19:18,2018-01-24 22:57:03
IS,foldl and foldr gives different results on gpu vs cpu in tensorflow 1 4,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 TensorFlow installed from source or binary source TensorFlow version use command below v1 4 0 3 g5addbae 1 4 0 Python version 2 7 12 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version default GPU model and memory 1080ti 11GB Exact command to reproduce See code below Describe the problem While testing foldl and foldr I get the expected result when run on cpu but get a zero result when running on gpu Source code logs import tensorflow as tf with tf device ' gpu 0' els tf constant 1 0 2 0 3 0 f tf foldl lambda a x a x els with tf Session as sess print tf GIT VERSION tf VERSION print sess run els f Result v1 4 0 3 g5addbae 1 4 0 array 1 2 3 dtype float32 0 0 The last number should be 6 0 ie the sum of the input array I get this if I change the device to cpu 0,,"drpngx,drpngx",2017-11-21 04:32:32,2018-01-24 22:58:56
IS,Building Tensorflow from source failed compilation error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 Red Hat Enterprise Linux Server release 6 9 Santiago TensorFlow installed from source or binary source TensorFlow version use command below Python version 2 7 13 Bazel version if compiling from source 0 6 1 GCC Compiler version if compiling from source 4 4 7 CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce bazel build config opt verbose failures tensorflow tools pip package build pip package Describe the problem The following errors appears at the building stage when I tried to install Tensorflow for CPU from source Source code logs Comments I checked that it is not a memory issue Related issues 8642,,"drpngx,drpngx,drpngx",2017-12-05 08:23:00,2018-01-24 22:59:15
PR,Apply non bfloat related final 1 5 0 cherry picks,,,angersson,2018-01-24 20:53:17,2018-01-24 23:14:39
IS,Import google protobuf any proto was not found or had errors,make f tensorflow contrib makefile Makefile HOST OS PI TARGET PI OPTFLAGS Os CXX g 4 8 PROTOC protoc CC PREFIX protoc tensorflow contrib boosted trees proto learner proto cpp out home a name tensorflow tensorflow contrib makefile gen proto protoc tensorflow contrib boosted trees proto quantiles proto cpp out home a name tensorflow tensorflow contrib makefile gen proto protoc tensorflow contrib boosted trees proto split info proto cpp out home a name tensorflow tensorflow contrib makefile gen proto protoc tensorflow contrib boosted trees proto tree config proto cpp out home a name tensorflow tensorflow contrib makefile gen proto protoc tensorflow core util test log proto cpp out home a name tensorflow tensorflow contrib makefile gen proto google protobuf any proto File not found tensorflow core util test log proto Import google protobuf any proto was not found or had errors tensorflow core util test log proto 132 12 google protobuf Any is not defined make home a name tensorflow tensorflow contrib makefile gen proto tensorflow core util test log pb cc Error 1,,"drpngx,drpngx,drpngx",2017-10-17 00:59:48,2018-01-24 23:22:08
IS,Running Model on tensorflow Distribution can not save model for tensorflow serving,System information OS Platform CentOS 7 1 TensorFlow installed from binary TensorFlow version 1 2 1 Python version 2 7 Bazel version 0 4 5 Describe the problem Situation One I add saving model for tensorflow serving based on mnist model distribution version when i run this model on the same machine and start one ps server and two workers saving model can work well Situation Two but if the model runs on three different machines eg A B C I start ps server on A machine and B C machine runs worker there is something wrong on saving model code Situation Three then I try another situation run ps server and one worker on A another worker on B the worker running on A machine saves model it can work well again Situation Four and run ps server on A the other worker on B it can also work I think it is an issue of tensorflow distribution on saving model using saved model builder Source code logs my mnist distribution code as bellow I Do not know what cause this problem how can i fix this issue thanks a lot,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx",2017-07-17 10:17:26,2018-01-24 23:38:08
IS,Generate benchmark model android arm64 v8a executable in case of tensorflow lite,Hello i tried the sameway defined in the Readme md of tensorflow contrib makefile folder to build benchmark model for tensorflow lite tensorflow contrib lite However it failed and seems that TARGET ANDROID is not working in caseof Makefile of tensorflow contrib lite folder ERROR LOG tensorflow tensorflow contrib lite downloads gemmlowp public internal internal kernel default h 89 2 error error SIMD not enabled you would be getting a slow software fallback Consider enabling SIMD extensions for example using msse4 if you are on modern x86 If that is not an option and you would like to continue with the slow fallback define GEMMLOWP ALLOW SLOW SCALAR FALLBACK error make tensorflow tensorflow contrib lite gen obj tensorflow contrib lite interpreter o Error 1,,"aselle,aselle,freedomtan",2017-11-15 10:25:24,2018-01-24 23:39:44
IS,Android tensorflow lite kernel util cc 34 input product scale output scale,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 0 TensorFlow installed from source or binary TensorFlow version use command below Python version 3 0 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce Describe the problem 1 down load Quantilized MobileNet model 0 75 224 from here 2 Transform the frozen pb model to tflite file bazel run config opt tensorflow contrib lite toco toco input file tmp mobilenet v1 0 75 224 frozen graph pb input format TENSORFLOW GRAPHDEF output format TFLITE output file tmp mobilenet v1 0 75 224 mobilenet v1 0 75 224 tflite inference type QUANTIZED UINT8 input type QUANTIZED UINT8 input arrays input default ranges min 0 default ranges max 6 output arrays MobilenetV1 Predictions Reshape 1 input shapes 1 224 224 3 3 Change the MODEL PATH in Tensorflow lite Android demo to mobilenet v1 0 75 224 tflite logs 4 Then run the demo make the error FATAL EXCEPTION CameraBackground Process android example com tflitecamerademo PID 13909 java lang NullPointerException Can not allocate memory for the given inputs tensorflow contrib lite kernels kernel util cc 34 input product scale output scale was not true at org tensorflow lite NativeInterpreterWrapper run Native Method at org tensorflow lite NativeInterpreterWrapper run NativeInterpreterWrapper java 95 at org tensorflow lite Interpreter runForMultipleInputsOutputs Interpreter java 112 at org tensorflow lite Interpreter run Interpreter java 93 at com example android tflitecamerademo ImageClassifier classifyFrame ImageClassifier java 109 at com example android tflitecamerademo Camera2BasicFragment classifyFrame Camera2BasicFragment java 663 at com example android tflitecamerademo Camera2BasicFragment wrap0 Camera2BasicFragment java at com example android tflitecamerademo Camera2BasicFragment 4 run Camera2BasicFragment java 558 at android os Handler handleCallback Handler java 739 at android os Handler dispatchMessage Handler java 95 at android os Looper loop Looper java 135 at android os HandlerThread run HandlerThread java 61 need your help Followed the same steps transform other mobilenet models only the mobilenet v1 1 0 128 can run successfully,,,2017-11-17 02:58:44,2018-01-24 23:41:17
IS,tensorflow contrib lite toco tflite export cc 192 Unsupported operator Sub,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 17 04 TensorFlow installed from source or binary pip TensorFlow version use command below 1 4 0 Python version 2 7 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version 8 0 6 0 GPU model and memory GTX 1060 with 6GB memory Exact command to reproduce bazel run config opt tensorflow contrib lite toco toco input file home wh gitmodel tensorflow wh frozen 1 pb input format TENSORFLOW GRAPHDEF output format TFLITE output file home wh gitmodel tensorflow wh frozen lite lite inference type FLOAT input type FLOAT input arrays image 1 output arrays InferenceTower output6 input shapes 1 320 480 3 Describe the problem I am trying to convert a graph from pb to lite format using toco but I get this error 2017 12 04 20 14 38 202653 F tensorflow contrib lite toco tflite export cc 192 Unsupported operator Sub I think Sub is the basic op Lite shoud support it Is it right,,"reedwm,aselle",2017-12-04 12:15:55,2018-01-24 23:54:12
PR,Branch 183148922,,,av8ramit,2018-01-24 23:22:43,2018-01-25 00:10:09
IS,Eager Invalid placement of vars consts depending on their types and not the tf device,Hi I'm currently testing eager execution on TF 1 5 0 rc1 built it with XLA and CUDA enabled and observe strange behavior variables and constants get created either on GPU or CPU depending on their types and not with tf device block Moreover on creation of int32 variable it fails completely For example when I run the following code As you can see the constants and variables get placed either on GPU 0 or CPU 0 despite all of them gathered inside the same tf device ' gpu 0' block,,"asimshankar,asimshankar,asimshankar,asimshankar,asimshankar",2018-01-13 20:28:29,2018-01-25 00:10:50
IS,tf cast zeroes out input tensor when GPU does not have any free memory,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution Linux Ubuntu 16 04 TensorFlow installed from source or binary tf nightly gpu binary from 10 31 2017 TensorFlow version use command below 'v1 3 0 rc1 4007 gc44f67a' '1 5 0 dev20171031' Python version 2 7 12 Bazel version if compiling from source N A CUDA cuDNN version CUDA v8 cuDNN v6 GPU model and memory 1080 Ti 11 GB Exact command to reproduce x tf cast tensor tf float32 x tf to float tensor Above commands return a tensor with all values of tensor set to zero WHEN The gpu is in full use by another tensorflow process I'm trying to cast the tensor from dtype tf uint16 to tf float32 using above commands but whenever this runs while the gpu is in full use i e I get a CUDA out of memory error the program completes execution normally but the casting commands set the tensor to zeros I upgraded from an older nightly gpu binary to the current one but did not help User should not try to use an already in use gpu but this error should at least be communicated to the user If I set the gpu to a different gpu with available memory or if I hide all gpus to force it to use CPU I do not observe this issue,,"asimshankar,yzhwang,yzhwang",2017-11-01 06:22:53,2018-01-25 00:14:13
IS,tf foldl should have more robust input handling like tf scan,System information Windows 10 x64 Installed from binary TensorFlow 1 4 0 Cpu version Python 3 6 1 Bug Description tf foldl and tf foldr are conceptually very very similar to tf scan Therefore the implementations are also very similar However tf scan accepts initializer lists or tuples with varying type arguments while tf foldl does not I think this is a simple oversight and it seems that cutting and pasting some code from tf scan to tf foldl fixes this problem Specifically the master tf foldl code is after removing the docstring,,tatianashp,2018-01-24 12:58:43,2018-01-25 00:37:32
PR,Parameterized docker build now supports a local pip whl file path,PiperOrigin RevId 183148798,,av8ramit,2018-01-25 00:24:37,2018-01-25 00:41:18
IS,Python Make an alias for tf variable with a lower v so the naming of it is consistent with tf placeholder tf constant,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow N A OS Platform and Distribution e g Linux Ubuntu 16 04 N A TensorFlow installed from source or binary N A TensorFlow version use command below N A Python version N A Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem Many developers learn the naming standards of the software so they can write code faster It does not make any sense to have to things tf placeholder and tf Variable named using different schema Constant Placeholder and Variable are similar entities and can be used interchangeably They should be named in same style even if tf Variable is a class Source code logs N A,,tatianashp,2018-01-24 12:20:59,2018-01-25 01:01:53
IS,BUG py func do not support unicode string results for python2,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Y OS Platform and Distribution e g Linux Ubuntu 16 04 Mac 10 11 TensorFlow installed from source or binary source TensorFlow version use command below master Python version 2 7 Bazel version if compiling from source N A GCC Compiler version if compiling from source N A CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce N A Describe the problem When I investigated 14116 I found that py func converts unicode strings result to bytes only for Python3 while raise an exception for Python 2 I'm curious why we do not the same thing for Python 2 Source code logs script,,"facaiy,facaiy,tatianashp,tatianashp",2018-01-23 10:31:25,2018-01-25 01:12:31
IS,init got multiple values for argument istrides',model Sequential model add ZeroPadding2D 1 1 input shape img width img height 3 print model output shape model add Convolution2D 64 3 3 strides 1 1 activation arelu' name 'conv1 1' above is my code I got error init got multiple values for argument istrides' If i do not use istrides' it is fine but the stride is 3 How should I set strides,,tatianashp,2018-01-22 06:57:46,2018-01-25 01:13:49
PR,Created dense to sparse in contrib layers,Added dense to sparse This does the conversion of dense labels into sparse ones to be passed into the core ctc loss function Addresses feature request,,"selcouthlyBlue,alextp,rmlarsen,selcouthlyBlue,selcouthlyBlue,rmlarsen,selcouthlyBlue",2018-01-15 04:41:50,2018-01-25 01:21:52
IS,Sample Distorted Bounding Box Bug,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Stock Example OS Platform and Distribution e g Linux Ubuntu 16 04 16 04 3 LTS TensorFlow installed from source or binary Source TensorFlow version use command below 1 4 0 Python version Python 3 5 2 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version cuda 9 0 176 384 81 cudnn 7 GPU model and memory GTX 755M 2gb Memory x2 Exact command to reproduce begin size bbox for draw tf image sample distorted bounding box tf shape image bounding boxes bounding boxes Describe the problem When using the tf image sample distorted bounding box function the parameter min object covered seems to default to value None which causes an error ValueError None values not supported If you give an argument for min object covered it seems to work fine There seems to be two versions of this function in the source v2 which takes min object covered L930 as a argument and a v1 L844 which has the default value of 0 1 as an attribute It appears v2 is the one being used L1536 Not sure what approach is best to take for fixing this bug but believe the root of the issue is coming from tensorflow core ops image ops cc Source code logs Attached boundingbox txt Examples of code being implemented here,,yongtang,2017-12-20 20:03:22,2018-01-25 01:22:28
PR,Fix sample distorted bounding box where min object covered could be None,This fix tried to address the issue raised in 15529 where not providing min object covered a value will result in a ValueError In the docstring however min object covered has been described as default to 0 1 The reason for the issue is that when sample distorted bounding box switched to V2 min object covered has been changed form an attr to an input As input could not have a default value min object covered None will result in an error This fix adds the check so that a default value 0 1 will be provided if min object covered None This fix fixes 15529 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen,yongtang,asimshankar,rmlarsen",2017-12-20 22:10:24,2018-01-25 01:22:28
PR,Fix a bug in ResolveConstantConcat,Changes to fix a bug in ResolveConstantConcat whereby shared tensors are removed without checking if they are used in other operators in the graph,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen",2018-01-10 18:10:58,2018-01-25 01:23:11
IS,ValueError Protocol message RewriterConfig has no layout optimizer field,I just start learning tensorflow object detection API And now I can use the train py script to train my model and use the eval py script to evaluate normally but when I use the export inference graph py script to export pb file the following error occurred my tf version is 1 4 and python version is 3 5 ubuntu14 04 thank you very much Traceback most recent call last File export inference graph py line 110 in module tf app run File home yj anaconda3 envs tensorflow3 4 lib python3 4 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File export inference graph py line 106 in main FLAGS output directory File home yj anaconda3 envs tensorflow3 4 models research object detection exporter py line 427 in export inference graph input shape optimize graph output collection name File home yj anaconda3 envs tensorflow3 4 models research object detection exporter py line 391 in export inference graph initializer nodes '' File home yj anaconda3 envs tensorflow3 4 models research object detection exporter py line 72 in freeze graph with def protos layout optimizer rewriter config pb2 RewriterConfig ON ValueError Protocol message RewriterConfig has no layout optimizer field I guess I installed a wrong protobuf version but I tried 2 6 0 2 6 1 3 5 1 and the same error occured,,,2018-01-21 12:16:20,2018-01-25 01:36:38
IS,Expected one attr with name u'T' in name swap out d 0,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux TensorFlow installed from source or binary source TensorFlow version use command below r1 2 Python version 2 7 Bazel version if compiling from source 0 4 5 CUDA cuDNN version CUDA8 0 GPU model and memory Tesla P100 16GB Describe the problem I used OptimizeGraph API in Grappler for inserting swap to host nodes in my graph When I import the new graph def generated from this API I got error mesage Expected one attr with name u'T' in swap out d 0 I think the new graph def misses some attribute information I am following this bug and handing on fixing it Source code logs source code,,"benoitsteiner,tatatodd",2017-06-30 04:00:46,2018-01-25 01:59:15
IS,Implement Audio Ops for Python Client,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Mac OS X 10 10 5 TensorFlow installed from source or binary binary TensorFlow version use command below 1 2 1 Python version 3 5 2 There are some very useful audio operations defined in tensorflow core ops audio ops cc It would be great if python client users could access these by default,,"asimshankar,andykernahan,rryan,andykernahan,petewarden,andykernahan,petewarden,rryan,rryan,rryan,rryan,rryan,rryan,tatatodd",2017-07-07 02:59:21,2018-01-25 02:12:28
IS,Feature request Add float16 support for Conv3D MaxPool3D and AvgPool3D ops,Support for tf float16 dtype was added 1300 to a bunch of ops Can we add it for conv3d too please conv3d is important to development of videos and medical images systems Since both consumes a lot of memory it would be good to have fp16 support to allow deeper models,,tatatodd,2017-07-07 03:48:06,2018-01-25 02:21:09
IS,Feature request Add a subclass of seq2seq Decoder to support regression,Currently seq2seq decoder class only supports classification which uses 1D softmax with embedding The library is very good for this particular task However seq2seq is also extremely useful in regression tasks by replacing embedding with a dense layer As of 1 2 the current architecture only allows 1D sequence data by supplying a Dense layer as embedding fn to TrainingHelper Currently training is working loss decreases but I have yet to find a way to decode I have tried to modify these following pieces to support 2D regression TrainingHelper BasicDecoder dynamic decode GreedyEmbeddingHelper used during decoding not working I had to change a lot of seq2seq internals but here is more or less my code It would be great if someone could sort it out and streamline the process,,"tatatodd,lukaszkaiser,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,ebrevdo,tatatodd,ebrevdo",2017-06-19 07:20:01,2018-01-25 02:38:08
IS,tweak validate shape to remove Assign requires shapes of both tensors to match lhs shape 12 rhs shape 3 error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No I am running the Audio recognition tutorial OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 14 04 TensorFlow installed from source or binary source TensorFlow version use command below 1 3 0 Python version 3 6 Bazel version if compiling from source 0 6 0 CUDA cuDNN version GPU model and memory Exact command to reproduce python tensorflow examples speech commands freeze py start checkpoint tmp speech commands train conv ckpt 18000 output file tmp my frozen graph pb I am asking about the error attached below here rather than on stackoverflow because of this related issue I want to know if my error can be resolved by tweaking the validate shape parameter by setting it to false If not please suggest alternatives The error is as follows Traceback most recent call last File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 1321 in do call return fn args File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 1300 in run fn status run metadata File home cogknit anaconda3 lib python3 6 contextlib py line 89 in exit next self gen File home cogknit anaconda3 lib python3 6 site packages tensorflow python framework errors impl py line 467 in raise exception on not ok status c api TF GetCode status status tensorflow python framework errors impl InvalidArgumentError Assign requires shapes of both tensors to match lhs shape 12 rhs shape 3 Node save Assign 5 Assign T DT FLOAT class loc Variable 5 use locking true validate shape true device job localhost replica 0 task 0 cpu 0 Variable 5 save RestoreV2 5 During handling of the above exception another exception occurred Traceback most recent call last File tensorflow examples speech commands freeze py line 180 in module tf app run main main argv sys argv 0 unparsed File home cogknit anaconda3 lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File tensorflow examples speech commands freeze py line 117 in main models load variables from checkpoint sess FLAGS start checkpoint File home cogknit tensorflow tensorflow examples speech commands models py line 123 in load variables from checkpoint saver restore sess start checkpoint File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 1657 in restore self saver def filename tensor name save path File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 889 in run run metadata ptr File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 1118 in run feed dict tensor options run metadata File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 1315 in do run options run metadata File home cogknit anaconda3 lib python3 6 site packages tensorflow python client session py line 1334 in do call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Assign requires shapes of both tensors to match lhs shape 12 rhs shape 3 Node save Assign 5 Assign T DT FLOAT class loc Variable 5 use locking true validate shape true device job localhost replica 0 task 0 cpu 0 Variable 5 save RestoreV2 5 Caused by op isave Assign 5' defined at File tensorflow examples speech commands freeze py line 180 in module tf app run main main argv sys argv 0 unparsed File home cogknit anaconda3 lib python3 6 site packages tensorflow python platform app py line 48 in run sys exit main sys argv 1 flags passthrough File tensorflow examples speech commands freeze py line 117 in main models load variables from checkpoint sess FLAGS start checkpoint File home cogknit tensorflow tensorflow examples speech commands models py line 122 in load variables from checkpoint saver tf train Saver tf global variables File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 1214 in init self build File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 1223 in build self build self filename build save True build restore True File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 1259 in build build save build save build restore build restore File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 747 in build internal restore sequentially reshape File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 435 in AddRestoreOps assign ops append saveable restore tensors shapes File home cogknit anaconda3 lib python3 6 site packages tensorflow python training saver py line 160 in restore self op get shape is fully defined File home cogknit anaconda3 lib python3 6 site packages tensorflow python ops state ops py line 276 in assign validate shape validate shape File home cogknit anaconda3 lib python3 6 site packages tensorflow python ops gen state ops py line 56 in assign use locking use locking name name File home cogknit anaconda3 lib python3 6 site packages tensorflow python framework op def library py line 787 in apply op helper op def op def File home cogknit anaconda3 lib python3 6 site packages tensorflow python framework ops py line 3082 in create op op def op def File home cogknit anaconda3 lib python3 6 site packages tensorflow python framework ops py line 1632 in init self traceback self graph extract stack pylint disable protected access InvalidArgumentError see above for traceback Assign requires shapes of both tensors to match lhs shape 12 rhs shape 3 Node save Assign 5 Assign T DT FLOAT class loc Variable 5 use locking true validate shape true device job localhost replica 0 task 0 cpu 0 Variable 5 save RestoreV2 5,,"reedwm,reedwm,tatatodd",2017-10-04 11:44:19,2018-01-25 02:54:37
IS,Tf Lite only support 4D l2 normalize,I build some feature extract network model and converted tflite using by toco successfully But I got error tensorflow contrib lite kernels l2norm cc 47 NumDimensions input 4 2 4 when run interpreter AllocateTensors I extract feature using by tf nn l2 normalize embeddings tf nn l2 normalize prelogits 1 1e 10 name 'embeddings' where prelogits is 2D tensor How can I extract normalized feature with tflite,,asimshankar,2017-12-25 04:05:11,2018-01-25 03:19:52
IS,tensorflow object detection issue,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-25 06:20:37,2018-01-25 06:28:42
IS,Golang API to serialize data into tf Example protos tfrecords,The Golang api WriteContentsTo Tensor WriteContentsTo can be used to writes the serialized contents of a tensor to io Writer where the tensor is built from golang scalars slices and arrays Yet there is not a Golang API to serialize data into tf Example protos tfrecords For example when i want serialize a libsvm into tf Example protos i can do this by BUT Golang api does not seem to be able to achieve this,,asimshankar,2018-01-24 02:53:13,2018-01-25 06:51:38
IS,Unittesting Models with Tensorflow How to clear the existing graph,Hello dear tensorflowers I have already asked the question of StackOverflow however it seams like nobody can answer my question So I hope you will forgive me about reposting it here I am developing unittests for a product I implemented with TF Each part of the model is tested separately then all together in different conditions Let is take the example of a simple GAN I have the following tests GeneratorTest Class With all tests concerning G inside DiscriminatorTest Class With all tests concerning D inside GAN Train Test Class G and D connected all together 1 training step is tested GAN Inference Test Class G and D connecteed all together 1 inference run is tested When the files are executed independently everything is working nicely and fine Tests are all fine Problems start occuring when I try to create one file to launch them all from one master file master test launcher py The error is quite simple to understand each test file is independant and thus create its own session and graph While testing only G or D there is no problem because they have different name scope variable scope However when testing the whole model Layers already have been defined by previous tests and thus leading to issue I would like to find a way to completely drop the graph and reset the whole TF state as brand new and clean However everything I try seem to fail I would like to avoid creating a new graph for each test leaving the old one in memory could lead to very high amount of memory waste after a few tests So my question is easy How can I reset the whole TF state and internal vars as clean as if you relaunch a new python shell By some black magic I can not find any way doing it after looking for it for hours For information here are the things I tried and which failed tf reset default graph cleaning everything in graph collections creating a new graph new session before executing each Test File A graph is still built somewhere containing my Layers and I can not manage to find it reading the TF code and trying to find any exit or close function which I did not find Thanks a lot Jonathan D,,asimshankar,2018-01-24 15:28:36,2018-01-25 07:03:15
IS,Dataset map func shape inference,System information Why does dataset map api dataset dataset map parse line only handle single record and pase line is shape inference does not include batch dimmension At present I need use different SetShapeFn in train and export savedmodel Can dataset map function add new feature to handle batch dimmension thanks sorry for bad description,,mrry,2018-01-24 06:31:42,2018-01-25 08:19:55
IS,TensorFlow Servering bazel build tensorflow serving ImportError No module named numpy,fong ubuntu serving bazel build tensorflow serving DEBUG home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external bazel tools tools build defs pkg pkg bzl 197 9 tensorflow serving model servers tensorflow model server tar you provided a non dictionary to the pkg tar files attribute This attribute was renamed to srcs Consider renaming it in your BUILD file ERROR home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py numpy BUILD 11 1 no such package ' local config python ' Traceback most recent call last File home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py python configure bzl line 291 create local python repository repository ctx File home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py python configure bzl line 255 in create local python repository get numpy include repository ctx python bin File home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py python configure bzl line 239 in get numpy include execute repository ctx python bin c 2 more arguments File home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py python configure bzl line 54 in execute fail n join error msg strip if File home fong cache bazel bazel fong 38e1867f819d663d91548408e483d3bf external org tensorflow third party py python configure bzl line 27 in fail fail sPython Configuration Error Python Configuration Error Problem getting numpy include path Traceback most recent call last File string line 1 in module ImportError No module named numpy Is numpy installed and referenced by ' org tensorflow third party py numpy headers' ERROR Analysis of target ' tensorflow serving example inception saved model' failed build aborted Loading failed INFO Elapsed time 35 784s FAILED Build did NOT complete successfully 149 packages loaded currently loading tensorflow contrib rnn 6 packages This is the error but my python paths and python library path is true python library path have numpy already fong ubuntu serving tensorflow configure You have bazel 0 9 0 installed Please specify the location of python Default is home fong anaconda3 bin python Found possible Python library paths home fong anaconda3 lib python3 5 site packages Please input the desired Python library path to use Default is home fong anaconda3 lib python3 5 site packages Do you wish to build TensorFlow with jemalloc as malloc support Y n y jemalloc as malloc support will be enabled for TensorFlow Do you wish to build TensorFlow with Google Cloud Platform support Y n y Google Cloud Platform support will be enabled for TensorFlow Do you wish to build TensorFlow with Hadoop File System support Y n y Hadoop File System support will be enabled for TensorFlow Do you wish to build TensorFlow with Amazon S3 File System support Y n y Amazon S3 File System support will be enabled for TensorFlow Do you wish to build TensorFlow with XLA JIT support y N y XLA JIT support will be enabled for TensorFlow Do you wish to build TensorFlow with GDR support y N y GDR support will be enabled for TensorFlow Do you wish to build TensorFlow with VERBS support y N y VERBS support will be enabled for TensorFlow Do you wish to build TensorFlow with OpenCL SYCL support y N n No OpenCL SYCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support y N n No CUDA support will be enabled for TensorFlow Do you wish to build TensorFlow with MPI support y N n No MPI support will be enabled for TensorFlow Please specify optimization flags to use during compilation when bazel option config opt is specified Default is march native Add config mkl to your bazel command to build with MKL support Please note that MKL on MacOS or windows is still not supported If you would like to use a local MKL instead of downloading please set the environment variable TF MKL ROOT every time before build Would you like to interactively configure WORKSPACE for Android builds y N n Not configuring the WORKSPACE for Android builds Configuration finished,,,2018-01-06 02:55:53,2018-01-25 11:27:45
IS,No module named 'tensorflow' Anaconda windows10 tensorflow gpu cuda8 cudnn6,I had anaconda on my windows 10 I installed CUDA 8 0 with cuDNN 6 and then followed url to activate tensorflow gpu environment Now when I import tensorflow in the console it works but with jupyter notebook opened right in this environment it throws the error I even upgraded setuptools as mentioned in a previous issue capture5 capture6 capture7 capture8,,,2018-01-24 22:27:17,2018-01-25 12:25:09
IS,doc link to How to Use t SNE Effectively from embeddings is broken,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow NO since Web page problem OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary binary TensorFlow version use command below 1 5 0rc0 Python version 3 5 1 Bazel version if compiling from source NOT USED GCC Compiler version if compiling from source NOT USED CUDA cuDNN version NOT USED GPU model and memory NOT USED Exact command to reproduce DOC Problem Just look Describe the problem Link to to How to Use t SNE Effectively is broken The page link is follows before junmping 404 page is following URL Original page should be follows the URL in embedding md should rewrite to follows Source code logs The problem code is follows L123,,yongtang,2018-01-25 10:17:07,2018-01-25 16:06:01
PR,Branch 183220585,,,xiejw,2018-01-25 15:47:42,2018-01-25 16:34:11
PR,Fix Conv3DTranspose in tf keras,,,"rmlarsen,rmlarsen",2018-01-23 02:53:57,2018-01-25 17:01:38
PR,RGB YIQ colorspace conversion,Implementation of functions for colorspace conversion RGB YIQ according to Formulas Wikipedia This PR adds CPP functions and python wrappers in tf image namespace,,"martinwicke,martinwicke,martinwicke,martinwicke,martinwicke,yifeif,drpngx,drpngx,martinwicke,asimshankar,martinwicke,drpngx,drpngx,drpngx,drpngx,drpngx,martinwicke,rmlarsen,rmlarsen",2017-12-21 14:11:06,2018-01-25 17:02:18
IS,,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-25 17:10:18,2018-01-25 17:10:25
IS,Using keras layers within an Estimator either causes training where it should not or corrupts weights,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Debian 3 16 36 TensorFlow installed from source or binary Binary TensorFlow version use command below 'v1 4 0 19 ga52c8d9' '1 4 1' Python version 2 7 9 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version N A GPU model and memory N A Exact command to reproduce See gist Describe the problem Hey there So I have a tf keras model that for use on Amazon SageMaker I'm trying to convert into an Estimator I know there is tf keras estimator model to estimator but I'm having separate issues with that In the easily run reproduction here I have as a demonstration a tf keras layers Embedding which is initialized with all zeros and has trainable False Followed by that is a Dense layer with use bias False because I could not figure out how to get predictions out of an Estimator without training it first and I can not train nothing apparently Since all of the embeddings are zero however and can not be trained the Dense layer should always produce a zero even after training it Instead it produces garbage In fact I have taken a few steps to ensure that no training takes place although ideally I would be able to just run the estimator without training 1 I have set the loss to be 0 initially l2 norm of what should start out as 0 2 Optimize with SGD using a learning rate of 0 3 One training example that should have zero loss The output I actually get is very much non zero If I inspect the embed embeddings 0 tensor in tfbdg I see this Even though it should not have budged from all zeroes So something about how I'm doing this is fundamentally broken I suspect that the issue is in line 61 where I start a new Session however this appears to be necessary since I need to ensure that the keras backend is using the same Graph as tensorflow get default graph due to the peculiarities of how the Estimator calls the model fn Notably those values hold between 1 Runs of the estimator 2 Successive runs with the same tf set random seed value The latter makes me think that somehow the Embedding layer is receiving a gradient despite my best efforts although it is hard to test this versus some sort of memory corruption If you need me to provide any more information let me know I'm sure I have left something out,,,2018-01-25 03:06:57,2018-01-25 17:23:21
PR,XLA Allow components in the plugins directory to create devices,Due to a change in the visibility of sub components of the XLA JIT the Graphcore device was unable to use the target needed for creating devices This change adds the plugin directory to the set of directories allowed to use the JIT,,"DavidNorman,DavidNorman,DavidNorman",2017-12-11 15:23:55,2018-01-25 17:25:30
IS,Source code logs,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,,2018-01-25 17:35:12,2018-01-25 17:35:18
PR,Improve SkipNBytes to RandomInputStream,This fix tries to address the issue raised in 14512 where SkipNBytes will takes a long time In existing implementation it needs to read through the file even though it is possible to random access the file itself This fix convert SkipNBytes in InputStreamInterface to pure virtual so that it is possible to have different implementations based on the underlying file type seekable vs no seekable This fix then have a specialized implementation in RandomInputStream so that 1 The SkipNBytes will first try to read 1 bytes from expected pos 1 if completed then return 2 If an out of range error returned from last step then we do not know how far away we are from the EOF We are forced to read through the file from the current pos all the way to expected pos This is similar to existing implementation Note Because RandomAccessFile only exposes Read with start offset not SizeOfFile it is not possible to just move the position marker as we wo not know where is the EOF One potential improvement could be to expose a SizeOfFile in RandomAccessFile That means adding additional changes It could be added if it is agreed This fix fixes 14512 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rohan100jain,martinwicke,drpngx,rmlarsen,yongtang",2017-11-14 18:48:17,2018-01-25 17:42:56
PR,cherrypick bfloat16 changes,,,"martinwicke,angersson",2018-01-25 04:12:26,2018-01-25 18:20:31
PR,Build libjpeg turbo ALTIVEC SIMD,The libjpeg turbo package has ALTIVEC SIMD and this updates the third party build to build the ALTIVEC SIMD on the appropriate platform,,rmlarsen,2018-01-25 16:12:29,2018-01-25 18:39:32
PR,Modified Implementation of ndlstm base dynamic,It now uses a BasicLSTMCell that has state is tuple True to address the deprecation thrown by having state is tuple False,,"selcouthlyBlue,ebrevdo",2018-01-25 12:13:47,2018-01-25 18:41:31
PR,Separate constant file for global variables,Created a separate common constants py which can be used globally under ops,,"rajendraarora16,rmlarsen,rajendraarora16",2018-01-25 11:36:25,2018-01-25 18:48:26
PR,fix typos,fix typos,,"ManHyuk,rmlarsen",2018-01-25 01:28:59,2018-01-25 18:52:07
PR,Separate constant file for common variable,Created a separate common constants py which can be used globally,,rajendraarora16,2018-01-25 19:00:00,2018-01-25 19:01:29
PR,Add additional argument to freeze graph,This PR fixes the failed testFreezeGraphV1 test for PR,,"tedhtchang,drpngx,rmlarsen,drpngx,rmlarsen,drpngx,tedhtchang,drpngx,tedhtchang,rmlarsen,drpngx,rmlarsen",2018-01-06 07:20:01,2018-01-25 19:05:09
PR,Fix of issue 13164,Fixes 13164 tf gather and tf gather nd now support int32 and int64 ref tensors when running on GPU tf scatter nd now supports int32 ref tensors when running on GPU int64 is not supported as some CudaAtomic operations are not supported The tests have been updated The fix was not tested with SYCL,,"dantkz,ebrevdo,ppwwyyxx,dantkz,zheng-xq,dantkz,zheng-xq,dantkz,sb2nov,ebrevdo,ebrevdo,dantkz,ebrevdo,dantkz,ebrevdo,dantkz,frankchn,dantkz,martinwicke,martinwicke,sb2nov,drpngx,Androbin,dantkz,Androbin,dantkz,drpngx,Androbin,drpngx,rmlarsen",2017-09-29 16:12:13,2018-01-25 19:07:56
PR,Add checkpoint file prefix check,V2 format refers checkpoint files by their file name prefix whereas V1 format refers checkpoint by actual file I added a check to verify the V2 checkpoint reference is not a file Also the return value for saver save has changed for V2 so I corrected the doc string,,"tedhtchang,drpngx,tedhtchang,tedhtchang,drpngx,tedhtchang,drpngx,tedhtchang,rmlarsen,drpngx,drpngx,rmlarsen,martinwicke,av8ramit,drpngx",2017-11-08 02:07:57,2018-01-25 19:16:27
PR,Disable bfloat16 for sparse matmul for 1 5 0,I'm using this PR to test out simple workarounds for the sparse matmul problem It does not need a reviewer yet Note it looks like we are going to try to release 1 5 0 with the fix anyway I will keep this PR available until that is finished,,"angersson,rmlarsen,angersson,rmlarsen",2018-01-25 00:00:18,2018-01-25 19:17:06
IS,Feature Request Make NDLSTM use state is tuple True,I have successfully used NDLSTM specifically lstm2d separable lstm in my own project but whenever I use it I enocunter this warning Using a concatenated state is slower and will soon be deprecated use state is tuple true The warning is caused by ndlstm base dynamic in lstm1d py Specifically this line lstm cell rnn cell BasicLSTMCell noutput state is tuple False I modified the code such that the deprecation warning wo not appear Before I make any pull requests is there a reason why the state is tuple argument is set to False in the code,,"selcouthlyBlue,selcouthlyBlue,aselle,ebrevdo,selcouthlyBlue,drpngx",2018-01-19 02:36:34,2018-01-25 19:27:43
PR,Separate constant file for global variables,Created a separate common constants py which can be used globally under ops P S I created the same pull request 16401 as after pushing my latest changes I was facing CLA issues,,"rajendraarora16,rajendraarora16,rmlarsen,rajendraarora16",2018-01-25 18:55:02,2018-01-25 19:29:35
PR,Making global constant py file for ops,Created a separate common constants py which can be used globally,,"rajendraarora16,rajendraarora16",2018-01-25 19:39:27,2018-01-25 19:39:59
IS,Tensorflow works in command prompt but not in Spyder,Hello I'm new to Python so maybe I have missed something but anyway here is my problem I have installed tensorflow in Anaconda prompt by using,,"tatianashp,tatianashp",2018-01-22 14:47:27,2018-01-25 19:40:16
IS,Documentation on build from source is unclear,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script python c import tensorflow as tf print tf GIT VERSION tf VERSION 'v1 4 1 7 gaa03bfc' '1 4 1' built and installed from source with git checkout r1 4 bazel build c opt copt march haswell config cuda verbose failures incompatible load argument is label false tensorflow tools pip package build pip package pip package build2 log 2 1 note incompatible path flag is required with R1 4 at this time per ubuntu 16 04 Cuda 9 1 cudnn 7 0 4 gcc version gcc Ubuntu 5 4 0 6ubuntu1 16 04 5 5 4 0 20160609 uname r 4 4 0 104 generic Bazel 0 9 Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request It is unclear how to build and install the entire package purely from source I will attempt to log what I have done so far clone and build TF R1 4 for cuda install wheel into local directory sudo pip install tmp tensorflow pkg tensorflow whl t mytf r1 4 c9 1 export PYTHONPATH mytf r1 4 c9 1 move tensorflow directory install common voice files to Common voice per native client build from source instructions git clone tensorflow cd tensorflow git checkout r1 4 ln s DeepSpeech native client configure edit native client BUILD comment out the following tfcompile flags select tensorflow rpi3 str ' target triple armv6 linux gnueabihf target cpu cortex a53 target features neon fp armv8 ' conditions default str '' bazel build c opt copt O3 incompatible load argument is label false tensorflow libtensorflow cc so tensorflow libtensorflow framework so native client deepspeech native client deepspeech utils native client libctc decoder with kenlm so native client generate trie at this point all the native client binaries are in tensorflow bazel bin native client levinth zt gpu lin DeepSpeech native client ls tensorflow bazel bin native client generate trie generate trie 2 params generate trie runfiles generate trie runfiles manifest libctc decoder with kenlm so libctc decoder with kenlm so 2 params libctc decoder with kenlm so runfiles libctc decoder with kenlm so runfiles manifest libdeepspeech a libdeepspeech a 2 params libdeepspeech pic a libdeepspeech pic a 2 params libdeepspeech so libdeepspeech so 2 params libdeepspeech utils a libdeepspeech utils a 2 params libdeepspeech utils pic a libdeepspeech utils pic a 2 params libdeepspeech utils so libdeepspeech utils so 2 params objs cd Deepspeech native client export TFDIR tensorflow make deepspeech at this point however the native client shared objects are still in bazel bin native client and have not been installed the invocation of Deepspeech py fails as it cannot find the shared objects python DeepSpeech py train files Common voice cv valid train csv Common voice cv other train csv dev files Common voice cv valid dev csv test files Common voice cv valid test csv deepspeech 1 log 2 1 tensorflow python framework errors impl NotFoundError native client libctc decoder with kenlm so cannot open shared object file No such file or directory the native client Makefile has sections for bindings and install so try sudo make install and this still generates the error as install does not put tensorflow bazel bin native client libctc decoder with kenlm so into usr local lib though deepspeech so and deepspeech utils so are installed there manually copy tensorflow bazel bin native client libctc decoder with kenlm so to DeepSpeech native client and set permissions at this point the invocation now starts running but complains about WARNING libdeepspeech failed to load resorting to deprecated code Refer to README md for instructions on installing libdeepspeech even though usr local lib is in the LD LIBRARY PATH invoking python DeepSpeech py train files Common voice cv valid train csv Common voice cv other train csv dev files Common voice cv valid dev csv test files Common voice cv valid test csv display step 1 validation step 10 WARNING libdeepspeech failed to load resorting to deprecated code Refer to README md for instructions on installing libdeepspeech I STARTING Optimization Loading the LM will be faster if you build a binary file Reading data lm lm binary 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 terminate called after throwing an instance of 'lm FormatLoadException' what native client kenlm lm read arpa cc 65 in void lm ReadARPACounts util FilePiece std vector long unsigned int threw FormatLoadException first non empty line was version not data Byte 43 I clearly have not figured this out,,tatianashp,2018-01-25 17:58:48,2018-01-25 19:45:03
PR,Do not load libcupti so from regular path on Android,Open to alternatives but as other methods in this file work similarly this does not seem too bad,,"andrewharp,rmlarsen,rmlarsen,gunan,rmlarsen,rmlarsen,andrewharp,andrewharp,andrewharp,andrewharp",2018-01-23 00:52:20,2018-01-25 19:56:23
PR,Remove calculation of unnecessary matrix columns in SVD gradient,The SVD gradient calculation when compute uv False currently uses the orthogonal U and V matrices returned by the SVD operation with full matrices True but it really requires only the full matrices False versions This pull request makes the calculation use the full matrices False versions pointed out that this change could be made in discussion r157067512,,"rmlarsen,rmlarsen,rmlarsen,rmlarsen",2018-01-03 01:41:42,2018-01-25 21:11:40
PR,Windows Add missing dependencies in lib proto parsing,,,,2018-01-25 21:14:30,2018-01-25 21:26:49
PR,R1 4,want to test,,av8ramit,2018-01-25 20:09:27,2018-01-25 21:33:32
IS,Creating placeholder with np uint32 dtype fails,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow yes custom snippet below OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 7 TensorFlow installed from source or binary binary TensorFlow version use command below 1 4 0 Python version 3 6 Bazel version if compiling from source not applicable GCC Compiler version if compiling from source not applicable CUDA cuDNN version CUDA 8 5 GPU model and memory Titan X Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem np uint32 dtype is not supported while creating placeholder Source code logs,,,2018-01-25 14:50:18,2018-01-25 22:20:04
PR,Windows Add missing dependencies in lib proto parsing,,,,2018-01-25 21:29:38,2018-01-25 22:21:50
PR,Update tensorboard dep to 1 5 0 1 6 0,This change fixes the tensorflow tensorboard dep now that TensorBoard 1 5 0 has been pushed to PyPI and ensures that TensorBoard releases installed as dependencies of TF stay in sync with their corresponding TF releases even once newer potentially backwards incompatible versions of TensorBoard are released by adding 1 6 0 as an upper bound cc,,nfelt,2018-01-25 21:28:25,2018-01-25 22:22:11
PR,make label image for tflite build again,1 add namespace to label image h to make label image for tflite build again 2 add config monolithic and mention NDK settings in label image md 3 fix a typo in display usage,,"freedomtan,freedomtan,freedomtan,freedomtan,rmlarsen",2018-01-18 02:33:26,2018-01-25 22:24:23
PR,Add missing library in Dockerfile,The local Dockerfile does not have all the dependencies for running the exercise notebooks in udacity assignments,,rmlarsen,2018-01-25 19:42:22,2018-01-25 23:31:26
PR,add URLEncode for the CopyObjectRequest of S3 Rename function,I found that tf gfile Rename did not work for S3 objects with UTF 8 names A NoSuchKey error will be reported in this case After debugging I believed the error should be related to the usage of CopyObjectRequest It is described that the CopySource must be URL encoded as in the AWS document ab3fd89c8e77ffa12d053925efbb099ae Thus I made a patch It worked well in my environment and now objects with UTF 8 names can be renamed by tf gfile Rename Also bazel test tensorflow core platform s3 s3 file system test passed Please take a look Thanks,,"rmlarsen,jhseu",2018-01-25 19:02:23,2018-01-25 23:32:11
PR,Implement LoggingAsync for GRPC Worker Services,This allow RecvTensor events to show up in StepStats and in turn in Chrome Tracing format,,"mrry,sb2nov,sb2nov,rmlarsen,rmlarsen",2017-11-16 02:33:14,2018-01-25 23:32:45
IS,tf contrib framework sort failing with has no attribute isort' in TF windows,Problem Ca not use tf contrib framework sort in my tensorflow code as it is failing to find the isort' attribute Source code System information I have been trying to use the tf contrib framework sort within a custom loss function but issue being reproduced with a simple call to the tf contrib framework sort Windows 10 64 bit TF installed with native pip3 TF version 1 4 0 Python version 3 6 2 TF with CPU support only,,mrry,2018-01-25 14:17:01,2018-01-25 23:57:30
IS,Unable to download the training images from curl,image,,"asimshankar,tatatodd",2017-10-30 11:27:08,2018-01-26 00:22:35
PR,import tensorflow as tf,These five files do not explicitly import tensorflow as tf yet they use they use tf methods or functions which drives linters like pylint and flake8 crazy unless special directives are put in place,,"cclauss,gunan,gunan,gunan,rmlarsen,cclauss,gunan,cclauss",2018-01-23 09:51:42,2018-01-26 00:31:42
IS,Improve documentation of tf gfile GFile vs tf gfile FastGFile,is not clear from the docs what is the difference between the two I assumed that one has thread locking GFile and the other does not but both say the same thing in the docs,,"Mistobaan,jart,jart,jart,aselle,Mistobaan,tatatodd,Mistobaan",2017-08-28 23:09:39,2018-01-26 00:40:40
IS,Windows 10 Cmake GPU nvcc exe error,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Windows 10 TensorFlow installed from source or binary source TensorFlow version use command below r1 5 Python version 3 6 GCC Compiler version if compiling from source Visual Studio 2017 CUDA cuDNN version 9 1 GPU model and memory 1080Ti Exact command to reproduce Cmake Command,,tatatodd,2018-01-25 21:55:09,2018-01-26 01:19:15
IS,Tensorflow or python having memory cleanup issues when using multiple models in iterative loop,System information Have I written custom code yes OS Platform and Distribution Linux Ubuntu 17 04 TensorFlow installed from source or binary binary TensorFlow version v1 3 0 rc2 20 g0787eee 1 3 0 Python version Python 3 6 1 Anaconda 4 4 0 64 bit CUDA cuDNN version none GPU model and memory none cat etc issue Linux Bragi 4 10 0 37 generic 41 Ubuntu SMP Fri Oct 6 20 20 37 UTC 2017 x86 64 x86 64 x86 64 GNU Linux VERSION 17 04 Zesty Zapus VERSION ID 17 04 VERSION CODENAME zesty are we in docker No compiler c Ubuntu 6 3 0 12ubuntu2 6 3 0 20170406 Copyright C 2016 Free Software Foundation Inc This is free software see the source for copying conditions There is NO warranty not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE uname a Linux Bragi 4 10 0 37 generic 41 Ubuntu SMP Fri Oct 6 20 20 37 UTC 2017 x86 64 x86 64 x86 64 GNU Linux check pips numpy 1 12 1 numpydoc 0 6 0 protobuf 3 4 0 tensorflow 1 3 0 tensorflow tensorboard 0 1 8 check for virtualenv False tensorflow import tf VERSION 1 3 0 tf GIT VERSION v1 3 0 rc2 20 g0787eee tf COMPILER VERSION v1 3 0 rc2 20 g0787eee Sanity check array 1 dtype int32 env LD LIBRARY PATH is unset DYLD LIBRARY PATH is unset nvidia smi tf env collect sh line 105 nvidia smi command not found Describe the problem I am working on a tensorflow model which takes pretty much RAM It is executed iteratively to process given tasks However with increasing time the whole process starts consuming more and more RAM although it should clean it up This sounds like as if I would keep data of one graph over the iterations but I am almost sure that the graphs are cleanly separated Problem I reduced the code to the following import tensorflow as tf import numpy as np reps 30 for i in range reps with tf Graph as default as graph with tf Session graph graph as sess tf constant np random random 1000 1000 200 1 I have 32GB RAM available working on a ubuntu 17 04 with CPU Tensorflow 1 3 This will give following error message after about the 25th or 27th iteration terminate called after throwing an instance of istd bad alloc' what std bad alloc Giving the process some time after each iteration results in no improvement import tensorflow as tf import numpy as np import time reps 30 for i in range reps with tf Graph as default as graph with tf Session graph graph as sess tf constant np random random 1000 1000 200 1 time sleep 1 However it works if I force garbage collection invocation after each repetition import tensorflow as tf import numpy as np import gc reps 30 for i in range reps with tf Graph as default as graph with tf Session graph graph as sess tf constant np random random 1000 1000 200 1 gc collect Question Now I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de referenced the graph object Back to my original model I am not sure yet if the gc invocation actually helps The memory usage grows pretty intense especially when I am about to persist the model to disk Thanks for any insights,,"asimshankar,allenlavoie,tatatodd,allenlavoie",2017-11-02 11:11:28,2018-01-26 01:19:36
IS,1D Convolution in Tensorflow Serving,System information OS Platform and Distribution e g Linux Ubuntu 16 04 Arch Linux TensorFlow installed from source or binary tensorflow binary TensorFlow version use command below 1 4 0 Python version 3 6 CUDA cuDNN version 9 0 7 0 GPU model and memory GTX 1050 Describe the problem The Problem is a little bit hard to reproduce I guess because so many steps are involved So the basic scenario is that I am using keras to train a model in python Here is the model I am using input Input shape 200 8 x Conv1D filters 128 kernel size 7 activation relu padding same input x Conv1D filters 128 kernel size 7 activation relu padding same x x Conv1D filters 128 kernel size 3 activation relu padding same x x Conv1D filters 128 kernel size 3 activation relu padding same x x Conv1D filters 128 kernel size 3 activation relu padding same x x Conv1D filters 2 kernel size 1 activation softmax x Now I extract the graph and I am saving graph and weights with the ModelBundleBuilder session K get session signature tf saved model signature def utils build signature def inputs 'input' tf saved model utils build tensor info self get model inputs 0 outputs 'output' tf saved model utils build tensor info self get model outputs 0 method name tf saved model signature constants PREDICT METHOD NAME b tf saved model builder SavedModelBuilder filename legacy init op tf group tf tables initializer name 'legacy init op' b add meta graph and variables session tf saved model tag constants SERVING signature def map tf saved model signature constants DEFAULT SERVING SIGNATURE DEF KEY signature legacy init op legacy init op b save If I am loading the model via python everything works as expected Now I am deploying the model into TF serving and using protobuf gRPC to make the prediction via Java I am converting a 3D float array to a TensorProto like this TensorShapeProto Dim dim1 TensorShapeProto Dim newBuilder setSize data length build TensorShapeProto Dim dim2 TensorShapeProto Dim newBuilder setSize data 0 length build TensorShapeProto Dim dim3 TensorShapeProto Dim newBuilder setSize data 0 0 length build TensorShapeProto shape TensorShapeProto newBuilder addDim dim1 addDim dim2 addDim dim3 build TensorProto Builder builder TensorProto newBuilder setDtype DataType DT FLOAT setTensorShape shape for int i 0 i data length i for int j 0 j data 0 length j for int k 0 k data 0 0 length k builder addFloatVal data k j i return builder build And do the predicition like this public class ModelClientImpl implements ModelClient private String host private Integer port private ManagedChannel channel private PredictionServiceGrpc PredictionServiceBlockingStub stub public void init channel ManagedChannelBuilder forAddress getHost getPort usePlaintext true build stub PredictionServiceGrpc newBlockingStub channel public Map String TensorProto predict final String signatureName Map String TensorProto inputs final Predict PredictResponse response stub predict createRequest signatureName inputs return response getOutputsMap protected Predict PredictRequest createRequest final String signatureName final Map String TensorProto inputs final Model ModelSpec modelSpec Model ModelSpec newBuilder setName signatureName setSignatureName serving default build final Predict PredictRequest Builder builder Predict PredictRequest newBuilder setModelSpec modelSpec putAllInputs inputs return builder build public String getHost return host public void setHost String host this host host public Integer getPort return port public void setPort Integer port this port port public void close throws Exception channel shutdown awaitTermination 5 TimeUnit DAYS But the prediction is totally different from python Does anybody know if this is a bug or is something wromg with 1dconv,,tatatodd,2018-01-25 12:50:42,2018-01-26 01:32:27
IS,Does TensorFlow 1 5 support CUDA 9 1,My notebook has an MX150 display adapter someone said that it is available with CUDA 9 1,,"qmick,tatatodd",2018-01-25 08:28:58,2018-01-26 01:42:20
IS,TfLiteCameraDemo failed to work with NNAPI after commit e6ff665dbe4888aa5fdff8f34c44405acca2ddd1,I am testing NNAPI by forcing TfLiteCameraDemo to invoking libneuralnetworks so It worked correctly though slower But since commit e6ff665dbe4888aa5fdff8f34c44405acca2ddd1 TfLiteCameraDemo crashes with error message like 01 24 03 39 36 393 19136 19153 E AndroidRuntime FATAL EXCEPTION CameraBackground 01 24 03 39 36 393 19136 19153 E AndroidRuntime Process com example android tflitecamerademo PID 19136 01 24 03 39 36 393 19136 19153 E AndroidRuntime java lang IllegalArgumentException Failed to run on the given Interpreter NNAPI was requested but dependent sized tensors being used 01 24 03 39 36 393 19136 19153 E AndroidRuntime 01 24 03 39 36 393 19136 19153 E AndroidRuntime at org tensorflow lite NativeInterpreterWrapper run Native Method 01 24 03 39 36 393 19136 19153 E AndroidRuntime at org tensorflow lite NativeInterpreterWrapper run NativeInterpreterWrapper java 95 01 24 03 39 36 393 19136 19153 E AndroidRuntime at org tensorflow lite Interpreter runForMultipleInputsOutputs Interpreter java 123 01 24 03 39 36 393 19136 19153 E AndroidRuntime at org tensorflow lite Interpreter run Interpreter java 104 01 24 03 39 36 393 19136 19153 E AndroidRuntime at com example android tflitecamerademo ImageClassifier classifyFrame ImageClassifier java 114 01 24 03 39 36 393 19136 19153 E AndroidRuntime at com example android tflitecamerademo Camera2BasicFragment classifyFrame Camera2BasicFragment java 663 01 24 03 39 36 393 19136 19153 E AndroidRuntime at com example android tflitecamerademo Camera2BasicFragment access 900 Camera2BasicFragment java 69 01 24 03 39 36 393 19136 19153 E AndroidRuntime at com example android tflitecamerademo Camera2BasicFragment 5 run Camera2BasicFragment java 558 01 24 03 39 36 393 19136 19153 E AndroidRuntime at android os Handler handleCallback Handler java 790 01 24 03 39 36 393 19136 19153 E AndroidRuntime at android os Handler dispatchMessage Handler java 99 01 24 03 39 36 393 19136 19153 E AndroidRuntime at android os Looper loop Looper java 164 01 24 03 39 36 393 19136 19153 E AndroidRuntime at android os HandlerThread run HandlerThread java 65 01 24 03 39 36 396 626 871 W ActivityManager Force finishing activity com example android tflitecamerademo CameraActivity Here is my patch index e44c5ae 1ed88eb 100644 a tensorflow contrib lite java demo app src main java com example android tflitecamerademo ImageClassifier java b tensorflow contrib lite java demo app src main java com example android tflitecamerademo ImageClassifier java 91 7 91 7 public class ImageClassifier Initializes an code ImageClassifier ImageClassifier Activity activity throws IOException tflite new Interpreter loadModelFile activity tflite new Interpreter loadModelFile activity true labelList loadLabelList activity imgData ByteBuffer allocateDirect diff git a tensorflow contrib lite java demo build gradle b tensorflow contrib lite java demo build gradle index dd883d6 9361c71 100644 a tensorflow contrib lite java src main java org tensorflow lite Interpreter java b tensorflow contrib lite java src main java org tensorflow lite Interpreter java 66 6 66 13 public final class Interpreter implements AutoCloseable wrapper new NativeInterpreterWrapper modelFile getAbsolutePath public Interpreter NotNull File modelFile boolean nn if modelFile null return wrapper new NativeInterpreterWrapper modelFile getAbsolutePath wrapper setUseNNAPI nn Initializes a code Interpreter with a code MappedByteBuffer to the model file 76 6 83 10 public final class Interpreter implements AutoCloseable public Interpreter NotNull MappedByteBuffer mappedByteBuffer wrapper new NativeInterpreterWrapper mappedByteBuffer public Interpreter NotNull MappedByteBuffer mappedByteBuffer boolean nn wrapper new NativeInterpreterWrapper mappedByteBuffer wrapper setUseNNAPI nn Runs model inference if the model takes only one input and provides only one output Runs model inference if the model takes only one input and provides only one output,,"freedomtan,tatatodd,freedomtan",2018-01-24 03:55:51,2018-01-26 02:12:56
PR,Lite Supporting Raspberry Pi,Now we can cross compiling or native compiling libtensorflow lite a for rpi,,,2018-01-26 02:14:22,2018-01-26 02:19:39
PR,Fix an imperfect implementation of tf losses mean pairwise squared error,Suggest a fix for an imperfect implementation of tf losses mean pairwise squared error 15968,,,2018-01-26 02:07:14,2018-01-26 02:30:11
IS,using string input producer with train dataset and validate dataset,I have two datasets files for train and validate respectively I can successfully load training set thru tf train string input producer set num epochs 5 Then I can iteratively get batch of data to optimize my model But I got stuck when trying to load my validation set by the same way the program keeps saying OutOfRange Error even I did not set num epochs in string input producer Can you supply an example that using string input producer with two or more dataset same as the question on stackoverflow here Please help me solve the problem Thank you very much,,,2018-01-18 03:21:26,2018-01-26 02:45:16
PR,import contextmanager in side effect guards py,Resolve the undefined name ' contextmanager ' in side effect guards py via from contextlib import contextmanager and remove the associated pylint directive flake8 count select E901 E999 F821 F822 F823 show source statistics,,cclauss,2018-01-26 01:42:22,2018-01-26 02:51:56
PR,Fix typo,fix typos,,ManHyuk,2018-01-26 00:58:51,2018-01-26 02:52:19
PR,Including common h with NEON 2 SSE h,Including common h to make sure that USE NEON is defined in case of NEON 2 SSE h is used otherwise USE NEON will not be propagated to this file and portable tensor utils h will be used,,"drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,rmlarsen,rmlarsen,rmlarsen,rmlarsen,rmlarsen,drpngx,rmlarsen,drpngx,drpngx",2017-12-31 00:15:31,2018-01-26 02:53:00
PR,Increase tolerance on TFGAN losses test fixes 16238,,,joel-shor,2018-01-26 02:59:38,2018-01-26 05:30:46
PR,Fix docstrings in scan,,,taehoonlee,2018-01-26 02:39:25,2018-01-26 05:30:56
PR,Updating error handling in normalize tuple,In normalize tuple we test to see if all values are an int or able to be cast to an int using int ValueError is thrown if int is called with an input like 'asdf' this is caught and gives a helpful error using the 'name' param to provide more context However when given an input other than a string or int a TypeError is thrown This is not caught making error messages much more esoteric than the helpful one written out here especially when coming from a very long stack trace For example before this change I was getting an error,,,2018-01-03 16:41:25,2018-01-26 05:31:40
IS,tensorflow contrib gan losses impl test fails with AssertionError,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Ubuntu 16 04 s390x TensorFlow installed from source or binary Source TensorFlow version use command below v1 4 1 Python version 2 7 12 Bazel version if compiling from source 0 7 0 GCC Compiler version if compiling from source 5 4 0 CUDA cuDNN version No GPU GPU model and memory NA Exact command to reproduce bazel test c opt tensorflow contrib gan losses impl test Describe the problem One of the sub test test stable global norm unchanged fails on s390x with AssertionError 110 709068 110 709084 0 000010 Seems like a minor difference so I tried changing the tolerance slightly as below,,"namrata-ibm,yifeif",2018-01-19 10:25:54,2018-01-26 05:31:42
PR,Hotfix fix android example for focus mode continuous picture 15487,,,rmlarsen,2017-12-19 18:22:40,2018-01-26 05:31:57
IS,Android Example breaks for old cameras not having support for FOCUS MODE CONTINUOUS PICTURE,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No fixed a bug OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu 16 04 Tried on Android 21 22 23 24 25 TensorFlow installed from source or binary Android App TensorFlow version use command below Latest in Android App Python version 3 2 Bazel version if compiling from source Not Applicable GCC Compiler version if compiling from source Not Applicable CUDA cuDNN version Not Applicable GPU model and memory Not Applicable Exact command to reproduce Compile the Android Example as it is and execute on any Android device with old camera not supporting FOCUS MODE CONTINUOUS PICTURE You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Android Example breaks for old cameras not having support for FOCUS MODE CONTINUOUS PICTURE Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem Creating a pull request for the fix,,jart,2017-12-19 18:00:02,2018-01-26 05:32:33
IS,Unable to build image retraining label image no such target,SUCCESS bazel build config opt tensorflow examples image retraining retrain SUCCESS bazel bin tensorflow examples image retraining retrain image dir flower photos FAILED bazel build tensorflow examples image retraining label image ERROR Skipping 'tensorflow examples image retraining label image' no such target ' tensorflow examples image retraining label image' target 'label image' not declared in package 'tensorflow examples image retraining' defined by Users jeff tensorflow tensorflow examples image retraining BUILD WARNING Target pattern parsing failed ERROR no such target ' tensorflow examples image retraining label image' target 'label image' not declared in package 'tensorflow examples image retraining' defined by Users jeff tensorflow tensorflow examples image retraining BUILD INFO Elapsed time 0 320s FAILED Build did NOT complete successfully 0 packages loaded,,,2018-01-26 07:19:18,2018-01-26 07:24:38
IS,Documentation update,The mean squared error is described as following mean squared error labels predictions weights 1 0 scope None loss collection tf GraphKeys LOSSES reduction Reduction SUM BY NONZERO WEIGHTS The default reduction method is MEAN in v1 4,,"facaiy,facaiy,facaiy",2018-01-26 06:42:29,2018-01-26 12:08:15
IS,Tegra Nvidia Jetson TX2 build python 2 7 new CUDA and CUDNN,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow No OS Platform and Distribution e g Linux Ubuntu 16 04 Linux4Tegra 28 2 TensorFlow installed from source or binary source TensorFlow version use command below 1 5 rc1 Python version 2 7 Bazel version if compiling from source 0 9 GCC Compiler version if compiling from source 5 4 CUDA cuDNN version 9 0 7 0 GPU model and memory Denver2 8GB Exact command to reproduce import tensorflow You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Clean installation with the new CUDA 9 and cudnn 7 from nvidia Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,"tatatodd,tatatodd,tatatodd",2018-01-24 17:58:38,2018-01-26 15:45:08
PR,Correct a small typo,Small typo leaved in the retrain example,,rmlarsen,2018-01-25 14:27:43,2018-01-26 16:16:46
PR,Branch 183374082,,,xiejw,2018-01-26 15:40:34,2018-01-26 16:30:33
PR,Fixing the url for the pip3,,,,2018-01-26 08:06:24,2018-01-26 16:33:30
PR,Update contrib HVX readme,I updated the README because of some imprecisions and to add clarifications of what I think will guide the users more appropriately First the very simple quick start guide does not work there is no X option at least publicly and so you always need to have the SDK installed manually Apart from that some clarifications and rewording were done to help the users understand what is happening cc,,"bryant1410,rmlarsen,rmlarsen",2018-01-15 15:59:50,2018-01-26 16:39:08
PR,Decoding contents of BMP file on big endian,As the BMP file contents are encoded in little endian format added byte swapping for reading the various header components correctly on big endian,,"namrata-ibm,rmlarsen,namrata-ibm,namrata-ibm,rmlarsen,namrata-ibm,rmlarsen",2018-01-16 06:29:25,2018-01-26 16:40:05
PR,Compare and bitpack function for bool for big endian,Added condition for endianness check and related conversion for Big Endian Removed the note from file NOTE ebrevdo This assumes memory is little endian Please let me know your feedback,,"namrata-ibm,rmlarsen",2018-01-25 08:22:19,2018-01-26 16:48:27
PR,Fix a couple minor typos for DataSet API,Fix a couple minor typos in docs of DataSet API,,,2018-01-26 16:17:33,2018-01-26 17:25:37
IS,Bug Tensorflow serving loads incorrect model weights when using saved model main op,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Linux Debian 3 16 36 x86 64 TensorFlow installed from source or binary Binary pip TensorFlow version use command below Git version 1 4 0 19 ga52c8d9 Release version 1 4 1 Python version 2 7 9 Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce See attached gist Hey there I have documented a lot of this bug over on this issue on the tensorflow serving repository which was closed with the direction to open an issue here Essentially the bug is as follows I have an embedding layer in Keras that uses some pre initialized weights When I export the model for use by TF serving I note the following behavior The keras model itself has no issue outputting the correct results The exported model itself upon inspection has the correct weights The result values from TF serving are incorrect I have narrowed it down to an issue with tensorflow python ops variables global variables initializer as follows When specifying the main op argument in tensorflow saved model builder SavedModelBuilder add meta graph and variables if I use tensorflow saved model main op main op I encounter this issue If instead I use a control flow group that excludes the global variables initializer as follows I do not encounter this issue I have attached the full code for reproducing this issue with the caveat of needing tensorflow model server running here Here is the example output with the global variables initializer If you comment out line 83 of the repro code and uncomment line 84 you should get the correct output as shown here Thanks for helpin out,,jart,2017-12-20 19:06:51,2018-01-26 17:32:16
PR,xrange was removed in Python 3,Each of these files contains at least one call to the Python 2 only builtin function xrange which was removed in Python 3 in favor of range To each of these files we add the line from six moves import xrange module six moves for compatibility with both Python 2 and Python 3,,"cclauss,cclauss",2018-01-26 03:43:34,2018-01-26 18:10:56
PR,Imported lstm1d and lstm2d in ndlstm init py,Makes importing ndlstm modules easier,,"selcouthlyBlue,selcouthlyBlue",2018-01-26 02:58:34,2018-01-26 18:11:11
PR,Make raw rnn accept scalar or TensorArray values for state,tf contrib seq2seq AttentionWrapper rnn cell cannot be passed to raw rnn the problem is related 11988 and the same problem in dynamic rnn been solved However in raw rnn it still exists as issuecomment 326887212 pointed When state is a tuple which contains a nested scalar state i e time state in tf contrib seq2seq AttentionWrapperState the codes tf where for scalars fail Current code in raw rnn This PR solves the problem add judgement as with dynamic rnn,,lspvic,2018-01-26 05:13:53,2018-01-26 18:11:30
IS,Parameter parsing error messages,Parameter parsing error messages probably can be improved e g bazel bin tensorflow core profiler profiler profile path tmp for tfprof profile 20 runs ok but if cd to bazel bin tensorflow core profiler and profiler profile path tmp for tfprof profile 20 results in profiler profile path tmp for tfprof profile 20 Reading Files Try to use a single profile path instead of graph path op log path run meta path 2018 01 26 01 43 29 458032 F tensorflow core profiler profiler cc 206 Non OK status ReadProtoFile Env Default FLAGS graph path graph get false status Not found No such file or directory Aborted core dumped,,yongtang,2018-01-26 10:01:37,2018-01-26 18:11:51
PR,Improve profiler error message when graph path is not available,This fix tries to address the issue raised in 16451 to provide a better error message when graph path is not available for profiler Previously if graph path is not available the process will crash with not very imformative message and a core dump and the process exit with 1 This fix fixes 16451 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen",2018-01-26 16:55:04,2018-01-26 18:11:51
IS,tf scatter update Error,Hi I use tf scatter update to update non trainable variables AS and AO in a code As I found when one uses scatter update the gradient misses so that there is no gradient Because of that I set both AL and AO as non trainable variables actually they are non trainable called the optimizer tf train AdamOptimizer config actor lr0 0 9 0 999 1e 8 minimize actor loss and I thought everything should be fine However I am getting error LookupError No gradient defined for operation 'actor encoder beer game flow 8 next scat j 2' op type ScatterUpdate Here are the lines of the code that I update AO and AS that gives the error self players k 1 AS tf scatter update self players k 1 AS self curTime leadTimeIn tf add self players k 1 AS self curTime leadTimeIn possible shipment name 'next scat j' self players k 1 AO tf scatter update self players k 1 AO self curTime leadTime tf add self players k 1 AO self curTime leadTime self players k actionValue self curTime self playType name 'handle scat j' Since both AS and AO are non trainable I do not need their gradient and AS and AO are the only variable in this op So I was wondering why TensorFlow want to obtain the gradient since there is no trainable variable here Is it something that you can fix it or is there any reason behind this behavior BTW I use python 2 7 with tf 1 4 0 on Debian 8 7 with a K80 with 12GB of memory Thanks Afshin,,tatatodd,2018-01-19 23:39:34,2018-01-26 18:31:42
PR,long was removed in Python 3,long was removed integers from Python 3 in favor of int Here we have replaced the tuple int long with six integer types six integer types which does the right thing in both Python 2 and Python 3,,cclauss,2018-01-26 04:04:38,2018-01-26 18:45:31
PR,Update README md,png sample index options are not available in google perftools 2 4 0ubuntu5 16 04 1 Also since Ubuntu 16 04 wrongly recommends to install pprof from 'tau' package The program 'pprof' is currently not installed You can install it by typing sudo apt install tau the typical user command should probably be google pprof pdf nodecount 100 filename,,,2018-01-26 03:40:22,2018-01-26 19:27:29
PR,Fix build errors in contrib mpi introduced by commit 6042b5d267f,The commit diff 7c00d4a3caee74eedf5bb638bce23e5a Introduced code to tensorflow contrib mpi mpi rendezvous mgr h to use the type RecentRequestIds without including the header tensorflow core distributed runtime recent request ids h,,"jhseu,rmlarsen",2018-01-26 01:43:01,2018-01-26 19:28:34
PR,Add a way to provide target nodes in Android,This is required when running some models as a step for initializing the graph etc,,"drpngx,drpngx,rmlarsen",2017-11-20 13:24:53,2018-01-26 20:01:56
PR,Switch over to max pool v2 in Python,This fix is a follow up to 11875 so that MaxPool in Python use v2 version As 11875 has been merged several months ago this fix conforms to the deprecation policy This fix is realted to 11875 and 4746 Signed off by Yong Tang yong tang github outlook com,,"yongtang,rmlarsen,rmlarsen,rmlarsen,rmlarsen,yongtang,yongtang,yongtang,drpngx,rmlarsen,yongtang,rmlarsen,rmlarsen,yongtang",2017-11-29 23:33:29,2018-01-26 20:08:48
PR,replace deprecated keep dims with keepdims in keras backend,This may not be important but it sometimes triggers warnings with conv nets built with keras,,,2018-01-26 03:37:11,2018-01-26 20:22:54
PR,Add KafkaReader for processing streaming data with Apache Kafka,This is a proposal to add KafkaReader so that it is possible to read data from Kafka like TextLineReader and TFRecordReader Apache Kafka is a widely used distributed streaming platform in open source community The goal of this fix is to create a contrib Reader ops inherits ReaderBase and is similiar to TextLineReader TFRecordReader so that it is possible to reader Kafka streaming data from TensorFlow in a similiar fashion This fix uses a C C Apache Kafka client library librdkafka which is released under the 2 clause BSD license and is widely used in a number of Kafka bindings such as Go Python C Net etc Below is a sample usage NOTE Because of 1419 the clean deps of tensorflow core framework and tensorflow core lib has been commented out temporarily so that it is possible to build with ReaderBase Any suggestions to address this issue is welcomed Signed off by Yong Tang yong tang github outlook com,,"yongtang,terrytangyuan,yongtang,jhseu,jhseu,jhseu,yongtang,martinwicke,jhseu,jhseu,yongtang,yongtang,jhseu,mrry,yongtang,drpngx,mrry,drpngx,drpngx,rohan100jain,drpngx,yongtang,jhseu",2017-10-30 16:42:57,2018-01-26 20:45:36
PR,Merge pull request 1 from tensorflow master,merge upstream changes,,rmlarsen,2018-01-26 21:12:26,2018-01-26 21:12:47
PR,Fix a bug in PR 15906,drpngx,,tedhtchang,2018-01-26 19:47:28,2018-01-26 21:15:47
PR,Branch 183429339,,,rmlarsen,2018-01-26 20:52:55,2018-01-26 21:32:17
IS,Control dependency does not ensure write observed by read,TF version 1 3 0 When a variable is read on another device TF seems to copy once regardless of dependencies I understand this is how TF works but I think it would be nice to have dependencies ensure memory access order,,"gaohuazuo,ppwwyyxx,tatatodd",2018-01-22 06:22:40,2018-01-26 21:40:10
PR,Fix build error with GCC 7 2 1 on AWS Linux 2,This fix fixes a build failure when compiling with GCC 7 2 1 on AWS Linux 2 This fix is related to 16046 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-26 20:58:46,2018-01-26 22:14:35
PR,Branch 183446593,,,rmlarsen,2018-01-26 22:48:26,2018-01-26 23:42:47
PR,MKL Making MKL DNN default,Make Tensroflow use MKL DNN by default if config mkl is used when building,,"agramesh1,rmlarsen,rmlarsen,agramesh1,agramesh1,rmlarsen,rmlarsen,agramesh1",2018-01-26 22:08:58,2018-01-26 23:43:30
PR,Placate pylint on jupyter notebook config py,Eliminate the following pylint issues,,cclauss,2018-01-26 09:09:47,2018-01-26 23:43:48
IS,Lack of clarity in tf while loop documentation,I believe that the documentation for tf while loop is lacking usage clarity and actually provides contradictory statements Specifically it seems that many people are using the tf while loop as a for loop see stackoverflow However the tf while loop while loop docs state For correct programs while loop should return the same result for any parallel iterations 0 A loop counter inside of the while loop body seems to violate this constraint despite the fact that this is given as an example usage in the docs python i tf constant 0 c lambda i tf less i 10 b lambda i tf add i 1 r tf while loop c b i So it seems that there are two bad outcomes here 1 If this is indeed the canonical way of creating a for loop then the example explicitly creates a dependency between iterations meaning that the while loop iterations cannot be run in parallel 1 The example is incorrect It seems like the while loop docs should have an example which better illustrates how to use it as a for loop if such usage is indeed intended or a warning on the implications of the provided example,,"tatianashp,tatianashp",2018-01-23 08:07:11,2018-01-27 00:00:02
IS,How to parse multivalve feature using tf feature column and tf data API,Please go to Stack Overflow for help and support If you open a GitHub issue here is our policy 1 It must be a bug or a feature request 2 The form below must be filled out 3 It should not be a TensorBoard issue Those go here Here is why we have that policy TensorFlow developers respond to issues We want to focus on work that benefits the whole community e g fixing bugs and adding features Support only helps individuals GitHub also notifies thousands of people when issues are filed We want them to see you communicating an interesting problem rather than being redirected to Stack Overflow System information Have I written custom code as opposed to using a stock example script provided in TensorFlow OS Platform and Distribution e g Linux Ubuntu 16 04 TensorFlow installed from source or binary TensorFlow version use command below Python version Bazel version if compiling from source GCC Compiler version if compiling from source CUDA cuDNN version GPU model and memory Exact command to reproduce You can collect some of this information using our environment capture script You can obtain the TensorFlow version with python c import tensorflow as tf print tf GIT VERSION tf VERSION Describe the problem Describe the problem clearly here Be sure to convey here why it is a bug in TensorFlow or a feature request Source code logs Include any logs or source code that would be helpful to diagnose the problem If including tracebacks please include the full traceback Large logs and files should be attached Try to provide a reproducible test case that is the bare minimum necessary to generate the problem,,tatianashp,2018-01-26 15:58:52,2018-01-27 01:02:00
IS,How to create a model checkpoint based on each step rather than time interval using TensorFlow Slim api,slim learning train train op logdir number of steps 1000 save summaries secs 300 save interval secs 600 The above api only supports to capture model checpoints periodically but I need to checkpoint based on each step How do achieve this using TesorFlow Slim API I am looking for parameters like this save summaries steps 10 save interval steps 10 where the value 10 is the number of steps and that should be configurable,,"tatianashp,tatianashp",2018-01-26 16:48:53,2018-01-27 01:03:49
PR,Simplify Android Tegra GPU makefile file lists,,,andrewharp,2018-01-26 21:08:29,2018-01-27 01:13:45
IS,ValueError Dimensions 1069539296 and 13528529576648672 are not compatible,Traceback most recent call last File home lihua local lib python3 5 site packages tensorflow python framework tensor shape py line 558 in merge with new dims append dim merge with other i File home lihua local lib python3 5 site packages tensorflow python framework tensor shape py line 133 in merge with self assert is compatible with other File home lihua local lib python3 5 site packages tensorflow python framework tensor shape py line 106 in assert is compatible with other ValueError Dimensions 1069539296 and 13528529576648672 are not compatible During handling of the above exception another exception occurred Traceback most recent call last File Train py line 117 in module train File Train py line 54 in train train op Evaluation trainning loss loss1 learning rate 0 0001 File home lihua Documents Projects Project2018 trafficSignClassification Evaluation py line 36 in trainning train op optimizer minimize loss global step global step File home lihua local lib python3 5 site packages tensorflow python training optimizer py line 315 in minimize grad loss grad loss File home lihua local lib python3 5 site packages tensorflow python training optimizer py line 386 in compute gradients colocate gradients with ops colocate gradients with ops File home lihua local lib python3 5 site packages tensorflow python ops gradients impl py line 560 in gradients in grad set shape t in get shape File home lihua local lib python3 5 site packages tensorflow python framework ops py line 443 in set shape self shape self shape merge with shape File home lihua local lib python3 5 site packages tensorflow python framework tensor shape py line 561 in merge with raise ValueError Shapes s and s are not compatible self other ValueError Shapes 128 4 4 1069539296 and 128 4 4 13528529576648672 are not compatible ubuntu16 04 tensorflow 1 4,,tatianashp,2018-01-26 13:37:31,2018-01-27 02:52:08
IS,quantize graph error in simple graph,when my graph is as follows it will fail to quantize the error info is AssertionError Failed to quantized constant ones 1 of type x tf ones 1000 1 'int32' ones tf ones 1 100 int32 x tf reshape x shape 1 1 when i change graph to the following it works x tf ones 1000 1 'int32' ones tf ones 1 100 int32 ones tf reshape ones shape 1 1 x tf reshape x shape 1 1 is there anyone can help me to find out the reason because even i change my code and successfully generated quantized graph the graph is wrong when importing BTW my graph is much more complex than the code above,,,2017-06-17 01:32:54,2018-01-27 02:53:15
IS,InvalidArgumentError see above for traceback sequence length 0 80 thrown by ctc loss,I am encountering this error thrown by ctc loss and I have no idea what it means nor how to resolve it,,"selcouthlyBlue,tatianashp",2018-01-26 09:49:04,2018-01-27 03:31:47
IS,embedding lookup table in tensorflow serving,Hi I am trying to serve a NLP model in tensorflow serving I am wondering how embedding matrix is being stored in tensorflow serving If I deploy model to two servers will the embedding matrix be a distributed table with sharding for looking up,,tatianashp,2018-01-26 08:36:01,2018-01-27 03:32:39
PR,cmake gpu build improvement,cmake build pass with gpu enabled python binding option can change to off now,,rmlarsen,2018-01-25 06:23:27,2018-01-27 03:56:45
IS,Request for updating keras datasets files to r1 5,System information executes Keras sample code imdb fasttext py Windows 7 TensorFlow installed from binary TensorFlow version 1 5 0rc0 Python version 3 5 1 Describe the problem Keras sample program does not work There is a bug for numpy arange method wrong usage Need to fix from arrange to arange This issue is already solved on master branch not in 1 5 0rc1 Would you update these source codes Source code logs Error messages are follows C Users sakaia work tensorflow keras python imdb fasttext py Loading data Traceback most recent call last File imdb fasttext py line 75 in module x train y train x test y test imdb load data num words max features File C Program Files Python35 lib site packages tensorflow python keras imp l keras datasets imdb py line 77 in load data indices np arrange len x train AttributeError module 'numpy' has no attribute 'arrange' Following are just checking np arrange not np arange git branch r1 5 grep rn np arrange tensorflow python keras impl keras datasets boston housing py 51 indices np arrange len x tensorflow python keras impl keras datasets reuters py 76 indices np arrange len xs tensorflow python keras impl keras datasets imdb py 77 indices np arrange len x train tensorflow python keras impl keras datasets imdb py 82 indices np arrange len x test git branch grep rn np arrange This line is intentionally blank,,tatianashp,2018-01-24 10:39:52,2018-01-27 06:18:20
IS,Failed install on Windows,Python 3 6 4 There is a strange error when I install tensorflow 1 5 Why the dependency is futures It does not have a verion of Python 3 6 4,,"tatianashp,tatianashp,tatianashp,tatianashp",2018-01-27 02:08:44,2018-01-27 10:16:51
PR,Tflite windows,Hi I have ported tensorflow lite to compile with msvc for my own development purposes It was relatively easy to get it to compile with Visual Studio 2017 The main differences issues were I chose to use cmake since I'm not so familiar with bazel I'm hoping the CMakeLists txt file can be used for other purposes than just compiling for msvc needed latest version of gemmlowp which is not dependent on POSIX functionality compiler errors due to narrowing conversions double float due to lack of f suffix on float numbers in unit tests Convolution generic optimized takes prohibitively long to compile with msvc added an operating systems abstraction layer on top of some of the OS functions which are used such as mmap files and loading of dynamic libraries All unit tests pass except for the ones with have the EXPECT DEATH macro The testdata filepaths in model test cc also need to be made cross platform,,,2018-01-27 11:43:46,2018-01-27 12:14:42
IS,Feature request tf data Dataset sort and skip buckets,Hi It would be useful to sort the variable length inputs by their lengths in order to accelerate the training process However I cannot find this functionality yet In 1 issuecomment 308789560 already suggested something similar through his code snippet yet the requested feature was batching inputs of similar length together regardless of the processing order of the batches and the solution of in 2 issuecomment 326098305 using group by window addressed this request just fine First question Would it be possible to make the iterator return the batches in the ascending order of their ids given by key func while maintaining the shuffling operation applied before batching Additionally I would like to skip the longer sentences early in training with a length threshold that would gradually increase depending on the global step Second question Could you reserve one batch id e g 1 in group by window to tag the batches that will be skipped At the moment it seems that all the ids are considered even the negative values and it would not be restrictive at all to allow only positive values as there would still be 63 bits left to group the inputs Thus in key func we could simply compare the input length with the threshold and return a negative value when it is above it Apologies if both functionalities are already available feel free to stackoverflow me,,"jart,jart",2017-11-04 21:25:34,2018-01-27 20:27:46
IS,Does 1 5 0 not suppurt CUDA 9 1 It worked with CUDA 9 0 but not 9 1,I installed 1 5 0 and tying to import tensorflow but it said that 'cannot find cudart64 90 dll' Then I installed the CUDA 9 0 and then everything works fine So I want to make sure than does 1 5 0 not support CUDA 9 1 or I have something installed wrong,,"ppwwyyxx,yongtang",2018-01-27 02:22:43,2018-01-27 23:01:32
PR,Update docs for installing CUDA CUDNN,This fix addresses the issue raised in 16479 where CUDA CUDNN versions from the docs do not match TensorFlow v1 5 0 From the Dockerfile and from the env of docker images the version of CUDA CUDNN for TensorFlow v1 5 0 This fix updates the doc so that CUDA version is changed from 8 0 9 0 CUDNN version is changed from 6 0 7 0 This fix fixes 16479 Signed off by Yong Tang yong tang github outlook com,,yongtang,2018-01-27 14:56:37,2018-01-27 23:01:32
PR,Add a rnn example on mnist dataset using tf library,A Recurrent Neural Network LSTM implementation example using TensorFlow library This example is using the MNIST database of handwritten digits Links Long Short Term Memory MNIST Dataset Training and evaluation log Extracting tmp mnist data train images idx3 ubyte gz Extracting tmp mnist data train labels idx1 ubyte gz Extracting tmp mnist data t10k images idx3 ubyte gz Extracting tmp mnist data t10k labels idx1 ubyte gz Step 1 Minibatch Loss 2 5586 Training Accuracy 0 258 Step 200 Minibatch Loss 0 2419 Training Accuracy 0 930 Step 400 Minibatch Loss 0 1863 Training Accuracy 0 938 Step 600 Minibatch Loss 0 1000 Training Accuracy 0 969 Step 800 Minibatch Loss 0 0935 Training Accuracy 0 977 Step 1000 Minibatch Loss 0 0773 Training Accuracy 0 969 Step 1200 Minibatch Loss 0 0500 Training Accuracy 0 984 Step 1400 Minibatch Loss 0 0550 Training Accuracy 0 977 Step 1600 Minibatch Loss 0 0615 Training Accuracy 0 984 Step 1800 Minibatch Loss 0 0635 Training Accuracy 0 977 Step 2000 Minibatch Loss 0 0550 Training Accuracy 0 992 Training Finished Testing Accuracy 0 992188,,"imsheridan,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,drpngx,imsheridan,imsheridan,imsheridan,imsheridan,imsheridan,imsheridan,imsheridan,imsheridan,drpngx,imsheridan,drpngx,ebrevdo,imsheridan,imsheridan,drpngx,imsheridan,rmlarsen,MarkDaoust,imsheridan",2018-01-21 18:23:28,2018-01-28 01:41:04
PR,Update LICENSE,2017 2018,,,2018-01-28 05:45:37,2018-01-28 05:47:16
IS,Undefined symbol ZN3Aws8Security14SecureMemClearEPhj,compiled tensorflow r 15 from source when import tensorflow in python got following error import tensorflow as tf Traceback most recent call last File stdin line 1 in module File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow init py line 24 in module from tensorflow python import File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python init py line 49 in module from tensorflow python import pywrap tensorflow File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python pywrap tensorflow py line 74 in module raise ImportError msg ImportError Traceback most recent call last File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python pywrap tensorflow py line 58 in module from tensorflow python pywrap tensorflow internal import File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python pywrap tensorflow internal py line 28 in module pywrap tensorflow internal swig import helper File usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python pywrap tensorflow internal py line 24 in swig import helper mod imp load module ' pywrap tensorflow internal' fp pathname description ImportError usr local lib python2 7 site packages tensorflow 1 5 0rc1 py2 7 freebsd 11 0 RELEASE p1 i386 egg tensorflow python pywrap tensorflow internal so Undefined symbol ZN3Aws8Security14SecureMemClearEPhj Failed to load the native TensorFlow runtime See common installation problems for some common reasons and solutions Include the entire stack trace thanks in advance,,,2018-01-16 06:04:50,2018-01-28 13:49:48
IS,Possibility to compile Tensorflow Native C Library to support Windows 10 UWP,Hello all When I was checking Deep Learning framework for Windows 10 UWP development somehow I came into this It was not hard to see their UWP example app as well Which really brings up the question Is it possible to compile the Tensorflow C library to add support for Windows 10 UWP development now Or at least to get some codes enough for the Model Evaluation to work Since it has been achieved by others Some similar cases are like OpenCV Numpy etc It can be really tricky solving dependencies and other unknown issues but since it is done before there is hope Many thanks in advance,,,2018-01-28 13:27:38,2018-01-28 14:06:23
PR,Fix typo,,,ManHyuk,2018-01-28 04:20:20,2018-01-28 22:50:49
PR,Merge pull request 2 from tensorflow master,Update from tensorflow origin,,,2018-01-29 02:39:49,2018-01-29 02:40:03
PR,Merge pull request 1 from tensorflow master,Update from tensorflow origin,,,2018-01-29 02:41:05,2018-01-29 02:41:31
PR,Merge pull request 1 from tensorflow master,Update from tensorflow origin,,,2018-01-29 02:42:48,2018-01-29 02:42:56
IS,Feature Request Loading weights for layers defined in tf layers api,Let is say I define a layer using the tf layers API as shown below Now I can build a whole network defining such layers Can you please introduce another functionality for the tf layers api so that for each layer we can set the weights in a single line like this conv1 set weights weights or something like this conv1 set params param values This would be very very useful,,"martinwicke,martinwicke,martinwicke",2017-09-01 07:46:32,2018-01-29 06:55:46
IS,Set training True in BatchNormalization layer causes evaluation error in custom Estimator model,System information Have I written custom code as opposed to using a stock example script provided in TensorFlow Yes OS Platform and Distribution e g Linux Ubuntu 16 04 Ubuntu16 04 TensorFlow installed from source or binary pip install TensorFlow version use command below 1 4 1 Python version 3 5 2 CUDA cuDNN version 8 0 6 GPU model and memory GeForce 1080ti 11G Describe the problem I define a custom estimator model for classification following this document Cifar10 dataset is used for test and network framework is xception rewritten in tensorflow But when using estimator train and evaluate to train and evaluate the model repeatedly I find evaluation accuracy dones't improve while training accuracy is normally increasing with training Inspired by tensorflow official resnet estimator example br,,,2018-01-26 14:58:00,2018-01-29 13:36:24
PR,Disable AWS S3 virtual addressing,The fix disables the virtual addressing of AWS S3 as was suggested in the comment issuecomment 360654674 Signed off by Yong Tang yong tang github outlook com,,"yongtang,drpngx,rmlarsen,drpngx,yongtang",2018-01-26 05:58:11,2018-01-29 16:24:14
